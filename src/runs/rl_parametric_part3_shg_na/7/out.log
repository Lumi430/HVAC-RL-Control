Using TensorFlow backend.
[2019-03-26 19:07:59,345] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='relu', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Shg-Train-v1', eval_act_func='part3_shg_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=0.001, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[64, 2], model_type='nn', num_threads=16, output='./Part3-NA-Shg-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Shg-Test-v1', 'Part3-NA-Shg-Test-v2', 'Part3-NA-Shg-Test-v3', 'Part3-NA-Shg-Test-v4'], test_mode='Multiple', train_act_func='part3_shg_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=29)
[2019-03-26 19:07:59,345] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-26 19:07:59.389540: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-26 19:08:18,288] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-26 19:08:18,288] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Shg-Train-v1', 'Part3-NA-Shg-Test-v1', 'Part3-NA-Shg-Test-v2', 'Part3-NA-Shg-Test-v3', 'Part3-NA-Shg-Test-v4'] ...
[2019-03-26 19:08:18,298] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation worker starts!
[2019-03-26 19:08:18,303] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation worker starts!
[2019-03-26 19:08:18,309] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation worker starts!
[2019-03-26 19:08:18,313] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation worker starts!
[2019-03-26 19:08:18,316] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation worker starts!
[2019-03-26 19:08:18,316] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:08:18,317] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-26 19:08:18,376] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:08:18,378] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run1
[2019-03-26 19:08:19,318] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:08:19,319] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-26 19:08:19,384] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:08:19,384] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run1
[2019-03-26 19:08:19,634] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 19:08:19,635] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:08:19,636] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:08:19,636] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:08:19,636] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:08:19,636] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:08:19,638] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:08:19,638] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:08:19,638] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:08:19,638] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:08:19,638] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:08:19,642] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run1
[2019-03-26 19:08:19,643] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run1
[2019-03-26 19:08:19,659] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run1
[2019-03-26 19:08:19,667] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run1
[2019-03-26 19:08:19,668] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run1
[2019-03-26 19:08:20,320] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:08:20,321] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-26 19:08:20,406] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:08:20,407] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run1
[2019-03-26 19:08:21,322] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:08:21,324] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-26 19:08:21,385] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:08:21,386] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run1
[2019-03-26 19:08:22,325] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:08:22,325] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-26 19:08:22,434] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:08:22,435] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run1
[2019-03-26 19:08:23,326] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:08:23,330] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-26 19:08:23,393] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:08:23,394] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run1
[2019-03-26 19:08:24,330] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:08:24,334] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-26 19:08:24,393] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:08:24,394] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run1
[2019-03-26 19:08:25,242] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:08:25,243] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.65, 66.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4403941368238054, 6.911199999999999, 6.9112, 168.912956510431, 395318.8824685939, 395318.8824685945, 144728.9452203237]
[2019-03-26 19:08:25,244] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:08:25,249] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.26884967 0.1828419  0.2422561  0.15992466 0.14612757], sampled 0.8909300904040194
[2019-03-26 19:08:25,333] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:08:25,337] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-26 19:08:25,401] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:08:25,403] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run1
[2019-03-26 19:08:26,337] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:08:26,344] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-26 19:08:26,408] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:08:26,409] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run1
[2019-03-26 19:08:27,345] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:08:27,350] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-26 19:08:27,411] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:08:27,412] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run1
[2019-03-26 19:08:28,349] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:08:28,355] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-26 19:08:28,419] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:08:28,421] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run1
[2019-03-26 19:08:29,353] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:08:29,357] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-26 19:08:29,417] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:08:29,418] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run1
[2019-03-26 19:08:30,356] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:08:30,360] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-26 19:08:30,426] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:08:30,427] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run1
[2019-03-26 19:08:31,361] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:08:31,365] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-26 19:08:31,425] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:08:31,426] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run1
[2019-03-26 19:08:32,366] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:08:32,370] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-26 19:08:32,435] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:08:32,436] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run1
[2019-03-26 19:08:33,371] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:08:33,374] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-26 19:08:33,434] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:08:33,435] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run1
[2019-03-26 19:08:41,964] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:08:41,966] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.45, 43.16666666666667, 1.0, 2.0, 0.17, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2741664473661291, 6.911200000000001, 6.9112, 168.912956510431, 490085.5394163093, 490085.5394163087, 187646.4802182293]
[2019-03-26 19:08:41,966] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:08:41,968] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.29886618 0.17230324 0.2587801  0.15207897 0.11797158], sampled 0.24740816055317305
[2019-03-26 19:08:44,309] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:08:44,310] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.55, 83.0, 1.0, 1.0, 0.17, 1.0, 1.0, 0.17, 1.0, 2.0, 0.1945833033931314, 6.911199999999999, 6.9112, 169.0403247858759, 508392.974165481, 508392.9741654816, 231146.2187936095]
[2019-03-26 19:08:44,311] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:08:44,316] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.28150743 0.1302618  0.3158566  0.14394407 0.12843014], sampled 0.4527547426506141
[2019-03-26 19:08:44,328] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:08:44,330] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.85, 70.0, 1.0, 2.0, 0.3399570737873855, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 528993.0575815059, 528993.0575815066, 169074.5487990631]
[2019-03-26 19:08:44,332] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:08:44,334] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.25584605 0.1437564  0.27600485 0.18874773 0.13564487], sampled 0.043723217444844864
[2019-03-26 19:08:49,519] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:08:49,520] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.41666666666666, 84.0, 1.0, 2.0, 0.255795269182497, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4520028510438948, 6.911199999999999, 6.9112, 168.912956510431, 781262.6364814884, 781262.6364814889, 214659.8256315466]
[2019-03-26 19:08:49,522] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:08:49,525] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.25260693 0.13752308 0.23034863 0.2167094  0.16281193], sampled 0.6990218295321218
[2019-03-26 19:08:50,342] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:08:50,343] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.5, 92.33333333333333, 1.0, 2.0, 0.2075515562628742, 0.0, 1.0, 0.0, 1.0, 2.0, 0.3575181605414197, 6.911200000000001, 6.9112, 168.912956510431, 609771.0122369053, 609771.0122369047, 199494.5265620593]
[2019-03-26 19:08:50,345] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:08:50,352] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.30339864 0.12284066 0.33226684 0.12553912 0.11595477], sampled 0.1658289677167113
[2019-03-26 19:08:54,814] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:08:54,815] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.16666666666667, 88.0, 1.0, 2.0, 0.17, 1.0, 1.0, 0.17, 1.0, 2.0, 0.2197309504253196, 6.9112, 6.9112, 169.0403247858759, 566768.4284202516, 566768.4284202516, 239855.3656947324]
[2019-03-26 19:08:54,817] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:08:54,820] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.30480865 0.14813551 0.3445915  0.09156043 0.1109039 ], sampled 0.3373785210965109
[2019-03-26 19:09:12,909] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:09:12,910] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.0, 66.83333333333334, 1.0, 2.0, 0.1976490801654119, 1.0, 1.0, 0.1976490801654119, 1.0, 2.0, 0.3432510886976962, 6.9112, 6.9112, 178.6582176852504, 828584.6723876457, 828584.6723876457, 271203.54218425]
[2019-03-26 19:09:12,910] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:09:12,912] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.26886988 0.17074768 0.30696473 0.15987228 0.09354543], sampled 0.6882842544784874
[2019-03-26 19:09:31,457] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:09:31,459] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.60704414, 69.47950730666666, 1.0, 2.0, 0.1965948624173629, 1.0, 1.0, 0.1965948624173629, 1.0, 2.0, 0.3414202611044718, 6.9112, 6.9112, 171.5212843490159, 824176.1375310642, 824176.1375310642, 269106.2287540176]
[2019-03-26 19:09:31,463] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:09:31,465] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.24473026 0.14296196 0.2935599  0.19145617 0.12729177], sampled 0.06908056591290046
[2019-03-26 19:10:16,552] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 3649.0532 3434508141.8486 1539.0000
[2019-03-26 19:10:16,702] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 4037.8077 3081312454.5720 783.0000
[2019-03-26 19:10:16,780] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 3929.7202 3220153028.6300 1135.0000
[2019-03-26 19:10:16,785] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 3821.1437 3280749079.0314 1468.0000
[2019-03-26 19:10:16,841] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 3861.0138 3128180290.6489 941.0000
[2019-03-26 19:10:17,856] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 3649.0532015586355, 3434508141.848573, 1539.0, 3929.7201560572607, 3220153028.6299767, 1135.0, 4037.8076669385746, 3081312454.571956, 783.0, 3821.1437033731295, 3280749079.031449, 1468.0, 3861.0137562310483, 3128180290.6489344, 941.0]
[2019-03-26 19:10:20,887] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.26559538 0.22761662 0.26042295 0.122627   0.12373812], sum to 1.0000
[2019-03-26 19:10:20,895] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1008
[2019-03-26 19:10:21,013] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.23333333333333, 85.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5469136460556863, 6.9112, 6.9112, 168.912956510431, 483166.3040385656, 483166.3040385656, 158184.4145506776], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 15000.0000, 
sim time next is 15600.0000, 
raw observation next is [21.26666666666667, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5173659901891493, 6.911200000000001, 6.9112, 168.912956510431, 456876.1405156444, 456876.1405156438, 154252.9221733297], 
processed observation next is [1.0, 0.17391304347826086, 0.2069510268562403, 0.8533333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4114219392550601, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12691003903212345, 0.12691003903212328, 0.2302282420497458], 
reward next is 0.7698, 
noisyNet noise sample is [array([-1.1968371], dtype=float32), -0.78272414]. 
=============================================
[2019-03-26 19:10:23,228] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0974589e-04 1.5540201e-03 9.9822801e-01 5.8780893e-06 2.2490049e-06], sum to 1.0000
[2019-03-26 19:10:23,235] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2167
[2019-03-26 19:10:23,341] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.43333333333333, 65.5, 1.0, 2.0, 0.503916484433464, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8688333782903443, 6.9112, 6.9112, 168.9129367532876, 1483130.573628132, 1483130.573628132, 314479.8417497822], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 54600.0000, 
sim time next is 55200.0000, 
raw observation next is [27.36666666666667, 66.0, 1.0, 2.0, 0.5521677024353089, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9516945268986255, 6.911200000000001, 6.9112, 168.9129565054976, 1624412.170501107, 1624412.170501106, 342310.181347033], 
processed observation next is [1.0, 0.6521739130434783, 0.49605055292259104, 0.66, 1.0, 1.0, 0.46044301498229984, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9410908864617383, 8.881784197001253e-17, 0.0, 0.8294399451280774, 0.4512256029169741, 0.4512256029169739, 0.5109107184284075], 
reward next is 0.4891, 
noisyNet noise sample is [array([0.35742226], dtype=float32), -0.8026543]. 
=============================================
[2019-03-26 19:10:25,058] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0949357e-06 3.0827494e-05 9.9996805e-01 3.1168339e-09 2.5171679e-11], sum to 1.0000
[2019-03-26 19:10:25,068] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1516
[2019-03-26 19:10:25,181] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.28333333333333, 89.0, 1.0, 2.0, 0.1720473210267907, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3070518891563538, 6.911199999999999, 6.9112, 168.912956510431, 533788.4978333927, 533788.4978333933, 195325.5563023438], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 85800.0000, 
sim time next is 86400.0000, 
raw observation next is [22.3, 89.0, 1.0, 2.0, 0.1727013775469943, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3081326802494744, 6.911200000000001, 6.9112, 168.912956510431, 535574.7656444098, 535574.7656444091, 195431.1278274775], 
processed observation next is [1.0, 0.0, 0.25592417061611383, 0.89, 1.0, 1.0, 0.0032546717433666124, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.15625936615789557, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1487707682345583, 0.1487707682345581, 0.2916882504887724], 
reward next is 0.7083, 
noisyNet noise sample is [array([0.61123276], dtype=float32), 1.3396088]. 
=============================================
[2019-03-26 19:10:34,439] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0912272e-08 1.0000000e+00 1.6804994e-18 8.0192150e-15 2.8710363e-21], sum to 1.0000
[2019-03-26 19:10:34,448] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2277
[2019-03-26 19:10:34,553] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 89.0, 1.0, 2.0, 0.3006138163358041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 478712.2646796132, 478712.2646796139, 165529.8364474007], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 241200.0000, 
sim time next is 241800.0000, 
raw observation next is [21.26666666666667, 89.0, 1.0, 2.0, 0.3001949018991961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 478264.1305440522, 478264.1305440522, 165501.1985853083], 
processed observation next is [0.0, 0.8260869565217391, 0.2069510268562403, 0.89, 1.0, 1.0, 0.15686132758939292, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13285114737334783, 0.13285114737334783, 0.2470167143064303], 
reward next is 0.7530, 
noisyNet noise sample is [array([0.29912773], dtype=float32), -0.22965519]. 
=============================================
[2019-03-26 19:10:34,619] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0002783e-08 1.0000000e+00 2.7901116e-14 4.2139032e-14 1.5005865e-17], sum to 1.0000
[2019-03-26 19:10:34,628] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4363
[2019-03-26 19:10:34,731] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 89.0, 1.0, 2.0, 0.2985970192955962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 476385.0334150187, 476385.0334150187, 165377.1718629935], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 243000.0000, 
sim time next is 243600.0000, 
raw observation next is [21.16666666666667, 89.0, 1.0, 2.0, 0.2972226638213607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 474524.5789758748, 474524.5789758748, 165249.8959981345], 
processed observation next is [0.0, 0.8260869565217391, 0.2022116903633494, 0.89, 1.0, 1.0, 0.1532803178570611, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13181238304885412, 0.13181238304885412, 0.24664163581811122], 
reward next is 0.7534, 
noisyNet noise sample is [array([0.12873885], dtype=float32), -0.48392844]. 
=============================================
[2019-03-26 19:10:37,828] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7936: loss 0.6312
[2019-03-26 19:10:37,889] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7936: learning rate 0.0010
[2019-03-26 19:10:37,896] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 7943: loss 0.7407
[2019-03-26 19:10:37,897] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 7943: learning rate 0.0010
[2019-03-26 19:10:37,912] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7951: loss 1.1845
[2019-03-26 19:10:37,914] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 7951: learning rate 0.0010
[2019-03-26 19:10:37,925] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 7958: loss 0.6817
[2019-03-26 19:10:37,929] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 7959: learning rate 0.0010
[2019-03-26 19:10:37,937] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 7961: loss 0.7266
[2019-03-26 19:10:37,939] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 7962: learning rate 0.0010
[2019-03-26 19:10:37,952] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 7969: loss 0.6089
[2019-03-26 19:10:37,955] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 7970: loss 0.6690
[2019-03-26 19:10:37,956] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 7970: learning rate 0.0010
[2019-03-26 19:10:37,958] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 7970: learning rate 0.0010
[2019-03-26 19:10:37,963] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7974: loss 0.5578
[2019-03-26 19:10:37,965] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 7974: learning rate 0.0010
[2019-03-26 19:10:37,989] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7982: loss 0.3655
[2019-03-26 19:10:37,994] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 7986: learning rate 0.0010
[2019-03-26 19:10:38,003] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 7989: loss 0.3724
[2019-03-26 19:10:38,006] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 7991: learning rate 0.0010
[2019-03-26 19:10:38,016] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7994: loss 0.1775
[2019-03-26 19:10:38,019] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 7996: learning rate 0.0010
[2019-03-26 19:10:38,022] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 7996: loss 0.3412
[2019-03-26 19:10:38,026] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 7998: learning rate 0.0010
[2019-03-26 19:10:38,039] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 8003: loss 0.0251
[2019-03-26 19:10:38,042] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 8003: learning rate 0.0010
[2019-03-26 19:10:38,075] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 8019: loss 0.0739
[2019-03-26 19:10:38,079] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 8021: learning rate 0.0010
[2019-03-26 19:10:38,132] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 8048: loss 0.0065
[2019-03-26 19:10:38,136] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 8049: learning rate 0.0010
[2019-03-26 19:10:38,229] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 8084: loss 0.2695
[2019-03-26 19:10:38,231] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 8086: learning rate 0.0010
[2019-03-26 19:10:40,894] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.9043472e-08 1.0000000e+00 9.9221367e-17 6.9424049e-16 1.7183968e-18], sum to 1.0000
[2019-03-26 19:10:40,906] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8391
[2019-03-26 19:10:40,912] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.53333333333333, 86.33333333333334, 1.0, 2.0, 0.2654771746370886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 431528.6926698316, 431528.692669831, 162369.0579879229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 346800.0000, 
sim time next is 347400.0000, 
raw observation next is [20.5, 86.5, 1.0, 2.0, 0.2644502284675434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 429946.2735186359, 429946.2735186366, 162267.0934253527], 
processed observation next is [1.0, 0.0, 0.1706161137440759, 0.865, 1.0, 1.0, 0.11379545598499204, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11942952042184331, 0.1194295204218435, 0.24218969167963092], 
reward next is 0.7578, 
noisyNet noise sample is [array([-0.38471615], dtype=float32), 0.36496332]. 
=============================================
[2019-03-26 19:10:41,472] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1241438e-11 1.0000000e+00 9.9374139e-22 7.0038137e-19 3.7300590e-25], sum to 1.0000
[2019-03-26 19:10:41,483] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4058
[2019-03-26 19:10:41,596] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333334, 89.16666666666667, 1.0, 2.0, 0.25517796528193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 415501.0883076111, 415501.0883076117, 161354.2605694449], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 360600.0000, 
sim time next is 361200.0000, 
raw observation next is [20.06666666666667, 89.33333333333334, 1.0, 2.0, 0.2549050236881701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 415034.4809460548, 415034.4809460548, 161326.1703894624], 
processed observation next is [1.0, 0.17391304347826086, 0.1500789889415484, 0.8933333333333334, 1.0, 1.0, 0.10229520926285551, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11528735581834855, 0.11528735581834855, 0.24078532893949614], 
reward next is 0.7592, 
noisyNet noise sample is [array([2.2045372], dtype=float32), 0.76013863]. 
=============================================
[2019-03-26 19:10:41,891] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.2093226e-11 1.0000000e+00 3.0515027e-24 8.8457506e-19 3.5667089e-25], sum to 1.0000
[2019-03-26 19:10:41,901] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5941
[2019-03-26 19:10:42,015] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.05, 89.5, 1.0, 2.0, 0.2628025625747001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 427839.1772719586, 427839.1772719593, 162122.1209462835], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 364200.0000, 
sim time next is 364800.0000, 
raw observation next is [20.1, 89.0, 1.0, 2.0, 0.2577437023177542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 419668.4362613151, 419668.4362613158, 161610.9908548877], 
processed observation next is [1.0, 0.21739130434782608, 0.15165876777251197, 0.89, 1.0, 1.0, 0.10571530399729417, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11657456562814307, 0.11657456562814326, 0.24121043411177268], 
reward next is 0.7588, 
noisyNet noise sample is [array([-0.5935098], dtype=float32), 0.10359613]. 
=============================================
[2019-03-26 19:10:47,696] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0615178e-08 1.0000000e+00 3.8107849e-19 3.2686408e-18 3.8786722e-20], sum to 1.0000
[2019-03-26 19:10:47,707] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5739
[2019-03-26 19:10:47,808] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.8, 77.5, 1.0, 2.0, 0.3972677704483104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 653737.6474729812, 653737.6474729812, 179071.1754221473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 462600.0000, 
sim time next is 463200.0000, 
raw observation next is [20.93333333333333, 76.66666666666667, 1.0, 2.0, 0.3979314826951001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 654638.7772868029, 654638.7772868029, 179169.1155806829], 
processed observation next is [1.0, 0.34782608695652173, 0.19115323854660338, 0.7666666666666667, 1.0, 1.0, 0.274616244210964, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1818441048018897, 0.1818441048018897, 0.26741659041892973], 
reward next is 0.7326, 
noisyNet noise sample is [array([0.17169447], dtype=float32), -1.6032827]. 
=============================================
[2019-03-26 19:10:51,149] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.6938552e-11 1.0000000e+00 3.3526222e-24 5.3784663e-23 2.7230717e-26], sum to 1.0000
[2019-03-26 19:10:51,154] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5954
[2019-03-26 19:10:51,274] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.81666666666667, 87.0, 1.0, 2.0, 0.2311405328509986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 383424.2429438421, 383424.2429438421, 158904.2438024592], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 517800.0000, 
sim time next is 518400.0000, 
raw observation next is [18.8, 87.0, 1.0, 2.0, 0.2299358285746499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 381481.9020643638, 381481.9020643638, 158786.4280343929], 
processed observation next is [1.0, 0.0, 0.09004739336492901, 0.87, 1.0, 1.0, 0.07221184165620467, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.10596719501787884, 0.10596719501787884, 0.2369946687080491], 
reward next is 0.7630, 
noisyNet noise sample is [array([-0.0671357], dtype=float32), -1.3823328]. 
=============================================
[2019-03-26 19:10:55,582] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6476119e-07 9.9999988e-01 5.8117371e-16 5.7942460e-17 8.8721821e-18], sum to 1.0000
[2019-03-26 19:10:55,593] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7906
[2019-03-26 19:10:55,699] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 76.33333333333334, 1.0, 2.0, 0.2369782164181012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 392469.1225712495, 392469.1225712489, 159516.5214232711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 593400.0000, 
sim time next is 594000.0000, 
raw observation next is [20.2, 77.0, 1.0, 2.0, 0.235071197854184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 389467.2819713699, 389467.2819713705, 159322.4572576308], 
processed observation next is [1.0, 0.9130434782608695, 0.15639810426540288, 0.77, 1.0, 1.0, 0.07839903355925783, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10818535610315831, 0.10818535610315848, 0.23779471232482208], 
reward next is 0.7622, 
noisyNet noise sample is [array([0.12249722], dtype=float32), 1.0260224]. 
=============================================
[2019-03-26 19:10:55,712] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[56.488174]
 [56.58768 ]
 [56.644703]
 [56.76649 ]
 [56.831852]], R is [[56.6337204 ]
 [56.82929993]
 [57.02272034]
 [57.21414948]
 [57.40355301]].
[2019-03-26 19:10:55,918] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 15903: loss 0.6515
[2019-03-26 19:10:55,922] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 15903: learning rate 0.0010
[2019-03-26 19:10:55,927] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 15906: loss 0.3977
[2019-03-26 19:10:55,928] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 15906: learning rate 0.0010
[2019-03-26 19:10:55,976] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 15927: loss 0.2445
[2019-03-26 19:10:55,978] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 15927: learning rate 0.0010
[2019-03-26 19:10:56,034] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 15955: loss 0.1550
[2019-03-26 19:10:56,036] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 15956: loss 0.1387
[2019-03-26 19:10:56,038] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 15956: learning rate 0.0010
[2019-03-26 19:10:56,039] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 15956: learning rate 0.0010
[2019-03-26 19:10:56,047] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 15958: loss 0.1295
[2019-03-26 19:10:56,052] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 15958: learning rate 0.0010
[2019-03-26 19:10:56,057] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 15961: loss 0.1371
[2019-03-26 19:10:56,060] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 15962: learning rate 0.0010
[2019-03-26 19:10:56,072] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 15971: loss 0.0039
[2019-03-26 19:10:56,073] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 15971: loss 0.0019
[2019-03-26 19:10:56,074] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 15971: learning rate 0.0010
[2019-03-26 19:10:56,074] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 15971: learning rate 0.0010
[2019-03-26 19:10:56,157] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 16004: loss 0.0401
[2019-03-26 19:10:56,161] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 16005: learning rate 0.0010
[2019-03-26 19:10:56,177] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 16011: loss 0.0829
[2019-03-26 19:10:56,181] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 16012: learning rate 0.0010
[2019-03-26 19:10:56,195] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 16019: loss 0.1102
[2019-03-26 19:10:56,198] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 16019: learning rate 0.0010
[2019-03-26 19:10:56,271] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 16058: loss 0.3784
[2019-03-26 19:10:56,274] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 16058: learning rate 0.0010
[2019-03-26 19:10:56,286] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 16065: loss 0.1807
[2019-03-26 19:10:56,288] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 16065: learning rate 0.0010
[2019-03-26 19:10:56,313] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 16076: loss 0.1746
[2019-03-26 19:10:56,315] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 16076: learning rate 0.0010
[2019-03-26 19:10:56,344] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 16087: loss 0.0407
[2019-03-26 19:10:56,345] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 16087: learning rate 0.0010
[2019-03-26 19:10:57,606] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.7865363e-10 1.0000000e+00 2.6771094e-22 3.4682980e-22 4.7333301e-25], sum to 1.0000
[2019-03-26 19:10:57,614] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2516
[2019-03-26 19:10:57,622] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 86.0, 1.0, 2.0, 0.2135148031529875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 355961.443750149, 355961.4437501484, 156949.4386614617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 626400.0000, 
sim time next is 627000.0000, 
raw observation next is [18.51666666666667, 85.0, 1.0, 2.0, 0.2146485999096978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 357625.0040675116, 357625.0040675116, 157118.3436851489], 
processed observation next is [1.0, 0.2608695652173913, 0.07661927330173794, 0.85, 1.0, 1.0, 0.05379349386710579, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.0993402789076421, 0.0993402789076421, 0.2345049905748491], 
reward next is 0.7655, 
noisyNet noise sample is [array([0.5678711], dtype=float32), 0.65468323]. 
=============================================
[2019-03-26 19:10:57,633] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[88.622246]
 [88.603966]
 [88.58368 ]
 [88.55984 ]
 [88.51759 ]], R is [[88.52315521]
 [88.40367126]
 [88.28578186]
 [88.16903687]
 [88.05269623]].
[2019-03-26 19:11:00,567] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.3632862e-08 9.9999988e-01 3.4921384e-16 2.1899633e-17 6.8126880e-19], sum to 1.0000
[2019-03-26 19:11:00,575] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6764
[2019-03-26 19:11:00,677] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.68333333333334, 75.83333333333333, 1.0, 2.0, 0.2418179191474085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 399429.7051594391, 399429.7051594391, 160052.8851681269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 677400.0000, 
sim time next is 678000.0000, 
raw observation next is [20.56666666666667, 76.66666666666667, 1.0, 2.0, 0.2428439831853793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 401142.3041803128, 401142.3041803128, 160150.2860547056], 
processed observation next is [1.0, 0.8695652173913043, 0.17377567140600336, 0.7666666666666667, 1.0, 1.0, 0.0877638351631076, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11142841782786467, 0.11142841782786467, 0.23903027769359042], 
reward next is 0.7610, 
noisyNet noise sample is [array([0.9004513], dtype=float32), 0.51709217]. 
=============================================
[2019-03-26 19:11:00,702] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[58.31142 ]
 [58.29862 ]
 [58.315804]
 [58.318188]
 [58.37209 ]], R is [[58.47256088]
 [58.64895248]
 [58.82363892]
 [58.99642944]
 [59.16734695]].
[2019-03-26 19:11:05,286] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3568269e-08 1.0000000e+00 1.2147584e-16 1.9619607e-19 7.1349465e-21], sum to 1.0000
[2019-03-26 19:11:05,293] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7539
[2019-03-26 19:11:05,299] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 50.0, 1.0, 2.0, 0.5632090907821332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 932419.665441059, 932419.6654410597, 207775.8769637052], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 752400.0000, 
sim time next is 753000.0000, 
raw observation next is [24.38333333333334, 51.5, 1.0, 2.0, 0.2965636525602371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 490864.6678054858, 490864.6678054858, 165764.7785930676], 
processed observation next is [1.0, 0.7391304347826086, 0.3546603475513432, 0.515, 1.0, 1.0, 0.15248632838582782, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13635129661263493, 0.13635129661263493, 0.24741011730308599], 
reward next is 0.7526, 
noisyNet noise sample is [array([1.2872628], dtype=float32), -0.80376136]. 
=============================================
[2019-03-26 19:11:05,310] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[71.32658]
 [71.32359]
 [71.289  ]
 [71.27162]
 [71.25956]], R is [[71.23854065]
 [71.21604156]
 [71.18738556]
 [71.15844727]
 [71.13257599]].
[2019-03-26 19:11:06,868] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.2766211e-08 1.0000000e+00 7.1402193e-16 1.2745415e-18 1.0099188e-20], sum to 1.0000
[2019-03-26 19:11:06,877] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9239
[2019-03-26 19:11:06,883] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 89.33333333333334, 1.0, 2.0, 0.2540526982891675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 417111.0264477726, 417111.0264477726, 161313.052710072], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 778200.0000, 
sim time next is 778800.0000, 
raw observation next is [19.5, 89.66666666666667, 1.0, 2.0, 0.2547393510533554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 418024.3709610438, 418024.3709610438, 161381.6543271054], 
processed observation next is [0.0, 0.0, 0.12322274881516594, 0.8966666666666667, 1.0, 1.0, 0.1020956036787414, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11611788082251216, 0.11611788082251216, 0.2408681407867245], 
reward next is 0.7591, 
noisyNet noise sample is [array([0.23060623], dtype=float32), 0.9744793]. 
=============================================
[2019-03-26 19:11:13,584] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 23856: loss 0.2240
[2019-03-26 19:11:13,587] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 23856: learning rate 0.0010
[2019-03-26 19:11:13,690] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 23906: loss 0.0297
[2019-03-26 19:11:13,694] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 23906: learning rate 0.0010
[2019-03-26 19:11:13,712] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 23917: loss 0.0046
[2019-03-26 19:11:13,715] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 23918: learning rate 0.0010
[2019-03-26 19:11:13,735] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 23927: loss 0.0020
[2019-03-26 19:11:13,739] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 23928: learning rate 0.0010
[2019-03-26 19:11:13,759] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23937: loss 0.0017
[2019-03-26 19:11:13,764] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 23938: loss 0.0326
[2019-03-26 19:11:13,765] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 23938: learning rate 0.0010
[2019-03-26 19:11:13,767] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 23938: learning rate 0.0010
[2019-03-26 19:11:13,830] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 23967: loss 0.1747
[2019-03-26 19:11:13,835] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 23969: learning rate 0.0010
[2019-03-26 19:11:13,847] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 23974: loss 0.0953
[2019-03-26 19:11:13,852] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 23974: learning rate 0.0010
[2019-03-26 19:11:13,878] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 23991: loss 0.2573
[2019-03-26 19:11:13,879] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 23991: learning rate 0.0010
[2019-03-26 19:11:13,896] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 23998: loss 0.1578
[2019-03-26 19:11:13,898] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 23998: learning rate 0.0010
[2019-03-26 19:11:13,969] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 24032: loss 0.1155
[2019-03-26 19:11:13,971] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 24032: learning rate 0.0010
[2019-03-26 19:11:13,973] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 24033: loss 0.3075
[2019-03-26 19:11:13,975] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 24033: learning rate 0.0010
[2019-03-26 19:11:13,979] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 24034: loss 0.2179
[2019-03-26 19:11:13,980] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 24034: learning rate 0.0010
[2019-03-26 19:11:14,002] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 24045: loss 0.1075
[2019-03-26 19:11:14,008] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 24048: learning rate 0.0010
[2019-03-26 19:11:14,027] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 24057: loss 0.0862
[2019-03-26 19:11:14,028] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 24057: learning rate 0.0010
[2019-03-26 19:11:14,267] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 24167: loss 0.2960
[2019-03-26 19:11:14,269] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 24168: learning rate 0.0010
[2019-03-26 19:11:16,047] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 19:11:16,049] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:11:16,049] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:11:16,054] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:11:16,055] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:11:16,055] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:11:16,055] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:11:16,051] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:11:16,059] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:11:16,060] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:11:16,061] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:11:16,079] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run2
[2019-03-26 19:11:16,081] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run2
[2019-03-26 19:11:16,101] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run2
[2019-03-26 19:11:16,102] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run2
[2019-03-26 19:11:16,140] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run2
[2019-03-26 19:11:45,452] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.17164642], dtype=float32), -0.16791591]
[2019-03-26 19:11:45,453] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.96666666666667, 86.66666666666667, 1.0, 2.0, 0.5002663313458996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 699044.5951192325, 699044.5951192325, 183636.9525629862]
[2019-03-26 19:11:45,454] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:11:45,456] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.0554883e-10 1.0000000e+00 1.2363428e-16 1.9613835e-20 8.1304802e-21], sampled 0.7457087831693776
[2019-03-26 19:12:04,601] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.17164642], dtype=float32), -0.16791591]
[2019-03-26 19:12:04,602] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.1, 81.66666666666666, 1.0, 2.0, 0.5068988926549669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 708315.6606207802, 708315.6606207802, 184683.6909122212]
[2019-03-26 19:12:04,604] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:12:04,607] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.6908148e-10 1.0000000e+00 3.0260920e-17 3.8777234e-21 1.4287894e-21], sampled 0.2285614068165951
[2019-03-26 19:12:28,555] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.17164642], dtype=float32), -0.16791591]
[2019-03-26 19:12:28,556] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.47044963166667, 63.07709232666667, 1.0, 2.0, 0.5342661920449485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 746570.821700006, 746570.8217000067, 189139.474337094]
[2019-03-26 19:12:28,558] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:12:28,560] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.82945089e-10 1.00000000e+00 1.51937660e-16 2.48473278e-20
 1.07366355e-20], sampled 0.13724971074971115
[2019-03-26 19:12:37,016] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.17164642], dtype=float32), -0.16791591]
[2019-03-26 19:12:37,016] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.55492989833333, 60.65381927333333, 1.0, 2.0, 0.5539273405147019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 774054.8516623371, 774054.8516623377, 192477.0156040193]
[2019-03-26 19:12:37,018] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:12:37,021] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.2521855e-10 1.0000000e+00 1.6694409e-16 2.8718153e-20 1.2214705e-20], sampled 0.8232489793649236
[2019-03-26 19:13:09,529] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.17164642], dtype=float32), -0.16791591]
[2019-03-26 19:13:09,529] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.4, 88.33333333333334, 1.0, 2.0, 0.5889801326749963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 823056.3979289265, 823056.3979289272, 198705.2032854495]
[2019-03-26 19:13:09,530] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:13:09,532] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.4178255e-10 1.0000000e+00 4.8201561e-17 5.5013577e-21 2.4914135e-21], sampled 0.18313742490662477
[2019-03-26 19:13:09,823] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 19:13:09,887] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.3130 3007656030.3370 1766.0000
[2019-03-26 19:13:09,943] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 19:13:10,108] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1746 3163992302.2432 1778.0000
[2019-03-26 19:13:10,137] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 19:13:11,154] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 25000, evaluation results [25000.0, 7884.174552150108, 3163992302.2431507, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7998.312951428424, 3007656030.3370423, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 19:13:11,444] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.653149e-11 1.000000e+00 5.657001e-17 1.002426e-21 3.632363e-21], sum to 1.0000
[2019-03-26 19:13:11,458] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5041
[2019-03-26 19:13:11,465] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.95, 93.0, 1.0, 2.0, 0.3407761778038421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527468.8128107061, 527468.8128107061, 168874.2556418068], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 945000.0000, 
sim time next is 945600.0000, 
raw observation next is [21.9, 93.33333333333334, 1.0, 2.0, 0.3397946603984714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 526082.1326077123, 526082.132607713, 168767.1717017065], 
processed observation next is [0.0, 0.9565217391304348, 0.23696682464454974, 0.9333333333333335, 1.0, 1.0, 0.2045718799981583, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14613392572436454, 0.14613392572436473, 0.25189130104732316], 
reward next is 0.7481, 
noisyNet noise sample is [array([1.241544], dtype=float32), 0.27691117]. 
=============================================
[2019-03-26 19:13:11,931] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6360876e-11 1.0000000e+00 8.7528100e-18 2.3884391e-22 2.5897990e-22], sum to 1.0000
[2019-03-26 19:13:11,936] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8080
[2019-03-26 19:13:11,942] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 94.83333333333333, 1.0, 2.0, 0.341666743957812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527903.3872326761, 527903.3872326761, 168880.8325417688], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 953400.0000, 
sim time next is 954000.0000, 
raw observation next is [21.8, 95.0, 1.0, 2.0, 0.3431374915803272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 529872.0780038765, 529872.0780038759, 169030.1340209157], 
processed observation next is [1.0, 0.043478260869565216, 0.23222748815165886, 0.95, 1.0, 1.0, 0.20859938744617734, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14718668833441015, 0.14718668833440998, 0.2522837821207697], 
reward next is 0.7477, 
noisyNet noise sample is [array([-0.33053133], dtype=float32), 0.116481744]. 
=============================================
[2019-03-26 19:13:11,955] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[81.0388 ]
 [80.9643 ]
 [80.84289]
 [80.75032]
 [80.69134]], R is [[81.33744049]
 [81.27200317]
 [81.20738983]
 [81.14344025]
 [81.08001709]].
[2019-03-26 19:13:13,691] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.11385914e-10 1.00000000e+00 3.38859542e-18 3.02991786e-23
 2.05783045e-24], sum to 1.0000
[2019-03-26 19:13:13,701] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6530
[2019-03-26 19:13:13,827] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 93.0, 1.0, 2.0, 0.4961679268021104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 769069.1211663409, 769069.1211663409, 191988.1119634396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 981000.0000, 
sim time next is 981600.0000, 
raw observation next is [21.9, 93.0, 1.0, 2.0, 0.5464192945959767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 846897.5477797518, 846897.5477797525, 201097.2470592801], 
processed observation next is [1.0, 0.34782608695652173, 0.23696682464454974, 0.93, 1.0, 1.0, 0.4535172224047912, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23524931882770883, 0.23524931882770903, 0.3001451448645972], 
reward next is 0.6999, 
noisyNet noise sample is [array([-0.43111423], dtype=float32), 1.326509]. 
=============================================
[2019-03-26 19:13:16,000] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.67598643e-10 1.00000000e+00 6.64665637e-18 1.22453096e-20
 5.10597040e-20], sum to 1.0000
[2019-03-26 19:13:16,009] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5245
[2019-03-26 19:13:16,015] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 96.0, 1.0, 2.0, 0.3544994367054833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 545390.8104076107, 545390.8104076107, 170241.8525517737], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1018800.0000, 
sim time next is 1019400.0000, 
raw observation next is [21.8, 96.0, 1.0, 2.0, 0.3532030349694134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 543413.2838072306, 543413.28380723, 170078.231363019], 
processed observation next is [1.0, 0.8260869565217391, 0.23222748815165886, 0.96, 1.0, 1.0, 0.22072654815591977, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1509481343908974, 0.15094813439089722, 0.25384810651196865], 
reward next is 0.7462, 
noisyNet noise sample is [array([-0.28281105], dtype=float32), -0.5369991]. 
=============================================
[2019-03-26 19:13:19,475] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7651271e-10 1.0000000e+00 1.9782117e-16 1.7146683e-21 3.7624801e-20], sum to 1.0000
[2019-03-26 19:13:19,492] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5249
[2019-03-26 19:13:19,496] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 79.0, 1.0, 2.0, 0.5602844662877203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 892231.1014334069, 892231.1014334069, 205940.6190739584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1076400.0000, 
sim time next is 1077000.0000, 
raw observation next is [22.76666666666667, 78.50000000000001, 1.0, 2.0, 0.5762714572907568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 916527.6782513242, 916527.6782513235, 209064.3108221342], 
processed observation next is [1.0, 0.4782608695652174, 0.2780410742496052, 0.7850000000000001, 1.0, 1.0, 0.4894836834828395, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25459102173647896, 0.25459102173647874, 0.3120362848091555], 
reward next is 0.6880, 
noisyNet noise sample is [array([1.279014], dtype=float32), -0.30569884]. 
=============================================
[2019-03-26 19:13:19,512] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[71.37298]
 [71.3168 ]
 [71.24012]
 [71.1598 ]
 [71.08325]], R is [[71.43598938]
 [71.41426086]
 [71.3921814 ]
 [71.37171936]
 [71.35614014]].
[2019-03-26 19:13:24,211] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7843249e-12 1.0000000e+00 8.1384365e-18 3.9860936e-24 2.3335704e-25], sum to 1.0000
[2019-03-26 19:13:24,217] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9587
[2019-03-26 19:13:24,327] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 78.0, 1.0, 2.0, 0.6821492543553236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1071185.225632032, 1071185.225632032, 231280.6963054911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1155600.0000, 
sim time next is 1156200.0000, 
raw observation next is [23.58333333333333, 77.16666666666667, 1.0, 2.0, 0.6333834938920408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 992957.2007269862, 992957.2007269862, 219962.0367019851], 
processed observation next is [1.0, 0.391304347826087, 0.31674565560821466, 0.7716666666666667, 1.0, 1.0, 0.5582933661349889, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.27582144464638503, 0.27582144464638503, 0.3283015473163957], 
reward next is 0.6717, 
noisyNet noise sample is [array([1.4897087], dtype=float32), -0.34216145]. 
=============================================
[2019-03-26 19:13:26,465] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 31849: loss 0.0276
[2019-03-26 19:13:26,468] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 31849: learning rate 0.0010
[2019-03-26 19:13:26,516] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 31872: loss 0.1255
[2019-03-26 19:13:26,518] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 31872: learning rate 0.0010
[2019-03-26 19:13:26,625] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31919: loss 0.0388
[2019-03-26 19:13:26,628] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 31920: learning rate 0.0010
[2019-03-26 19:13:26,676] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 31943: loss 0.0432
[2019-03-26 19:13:26,679] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 31944: learning rate 0.0010
[2019-03-26 19:13:26,690] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 31947: loss 0.0890
[2019-03-26 19:13:26,693] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 31947: learning rate 0.0010
[2019-03-26 19:13:26,710] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 31956: loss 0.2642
[2019-03-26 19:13:26,712] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 31956: learning rate 0.0010
[2019-03-26 19:13:26,743] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 31967: loss 0.2809
[2019-03-26 19:13:26,752] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 31970: learning rate 0.0010
[2019-03-26 19:13:26,762] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 31974: loss 0.2508
[2019-03-26 19:13:26,764] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 31974: learning rate 0.0010
[2019-03-26 19:13:26,780] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 31984: loss 0.3607
[2019-03-26 19:13:26,787] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 31985: learning rate 0.0010
[2019-03-26 19:13:26,839] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 32014: loss 0.3913
[2019-03-26 19:13:26,841] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 32015: loss 0.3804
[2019-03-26 19:13:26,842] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 32015: learning rate 0.0010
[2019-03-26 19:13:26,846] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 32015: learning rate 0.0010
[2019-03-26 19:13:26,870] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 32028: loss 0.3184
[2019-03-26 19:13:26,873] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 32029: learning rate 0.0010
[2019-03-26 19:13:26,882] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 32032: loss 0.2415
[2019-03-26 19:13:26,885] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 32032: learning rate 0.0010
[2019-03-26 19:13:26,910] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 32043: loss 0.1330
[2019-03-26 19:13:26,914] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 32043: learning rate 0.0010
[2019-03-26 19:13:27,019] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 32091: loss 0.0233
[2019-03-26 19:13:27,024] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 32091: learning rate 0.0010
[2019-03-26 19:13:27,137] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1157610e-11 1.0000000e+00 1.3241519e-17 2.9568198e-22 6.3391714e-23], sum to 1.0000
[2019-03-26 19:13:27,145] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2374
[2019-03-26 19:13:27,150] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 83.66666666666667, 1.0, 2.0, 0.3541673993488564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 546192.685384067, 546192.6853840663, 170345.9873198644], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1203600.0000, 
sim time next is 1204200.0000, 
raw observation next is [23.2, 84.5, 1.0, 2.0, 0.354696437771207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 546798.935816469, 546798.935816469, 170390.5290413429], 
processed observation next is [1.0, 0.9565217391304348, 0.29857819905213273, 0.845, 1.0, 1.0, 0.22252582864000844, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15188859328235252, 0.15188859328235252, 0.25431422244976554], 
reward next is 0.7457, 
noisyNet noise sample is [array([2.3891542], dtype=float32), 0.4410525]. 
=============================================
[2019-03-26 19:13:27,192] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 32152: loss 0.0584
[2019-03-26 19:13:27,195] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 32152: learning rate 0.0010
[2019-03-26 19:13:29,219] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3971190e-10 1.0000000e+00 4.5712459e-17 2.2003534e-19 1.9445764e-20], sum to 1.0000
[2019-03-26 19:13:29,229] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3221
[2019-03-26 19:13:29,346] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 88.0, 1.0, 2.0, 0.3865048400023153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 584469.8819849034, 584469.8819849034, 173343.6761196216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1234800.0000, 
sim time next is 1235400.0000, 
raw observation next is [23.55, 87.33333333333334, 1.0, 2.0, 0.4150440338059782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 626248.9733533538, 626248.9733533538, 177151.9139097347], 
processed observation next is [1.0, 0.30434782608695654, 0.3151658767772513, 0.8733333333333334, 1.0, 1.0, 0.29523377566985326, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17395804815370938, 0.17395804815370938, 0.2644058416563204], 
reward next is 0.7356, 
noisyNet noise sample is [array([0.9080101], dtype=float32), -0.8419166]. 
=============================================
[2019-03-26 19:13:38,701] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.0218811e-13 1.0000000e+00 5.9371422e-21 7.5008106e-22 7.3900371e-24], sum to 1.0000
[2019-03-26 19:13:38,712] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5865
[2019-03-26 19:13:38,719] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.28333333333333, 98.0, 1.0, 2.0, 0.3052578858737106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 485545.4604064184, 485545.460406419, 166012.4568929832], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1392600.0000, 
sim time next is 1393200.0000, 
raw observation next is [20.3, 98.0, 1.0, 2.0, 0.3055627625221013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 485848.896974797, 485848.8969747977, 166031.5411313304], 
processed observation next is [0.0, 0.13043478260869565, 0.16113744075829392, 0.98, 1.0, 1.0, 0.16332862954470034, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1349580269374436, 0.1349580269374438, 0.24780827034526925], 
reward next is 0.7522, 
noisyNet noise sample is [array([-0.9757441], dtype=float32), 0.11381899]. 
=============================================
[2019-03-26 19:13:39,189] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1760063e-16 1.0000000e+00 3.2769014e-28 3.1408638e-28 3.9902998e-28], sum to 1.0000
[2019-03-26 19:13:39,196] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0454
[2019-03-26 19:13:39,209] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.43333333333334, 93.66666666666667, 1.0, 2.0, 0.3272875263374947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 512773.1299449203, 512773.1299449197, 167891.275647502], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1406400.0000, 
sim time next is 1407000.0000, 
raw observation next is [21.51666666666667, 93.33333333333333, 1.0, 2.0, 0.3283729307895555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 513909.2603748629, 513909.2603748622, 167964.9492477559], 
processed observation next is [0.0, 0.2608695652173913, 0.21879936808846778, 0.9333333333333332, 1.0, 1.0, 0.19081075998741623, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1427525723263508, 0.1427525723263506, 0.2506939541011282], 
reward next is 0.7493, 
noisyNet noise sample is [array([1.3484377], dtype=float32), 0.5051519]. 
=============================================
[2019-03-26 19:13:39,225] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[70.56093]
 [70.53892]
 [70.51898]
 [70.49063]
 [70.46105]], R is [[70.62610626]
 [70.66925812]
 [70.71199036]
 [70.75437927]
 [70.79658508]].
[2019-03-26 19:13:39,434] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1534447e-19 1.0000000e+00 4.3554455e-32 9.1629038e-32 3.0053933e-34], sum to 1.0000
[2019-03-26 19:13:39,444] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1418
[2019-03-26 19:13:39,451] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.76666666666667, 92.0, 1.0, 2.0, 0.3310319007821896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 516816.3737775118, 516816.3737775118, 168158.4414166933], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1408800.0000, 
sim time next is 1409400.0000, 
raw observation next is [21.85, 91.5, 1.0, 2.0, 0.3324168960917796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 518687.3201661177, 518687.3201661177, 168297.0415119994], 
processed observation next is [0.0, 0.30434782608695654, 0.23459715639810438, 0.915, 1.0, 1.0, 0.19568300733949348, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1440798111572549, 0.1440798111572549, 0.2511896141970141], 
reward next is 0.7488, 
noisyNet noise sample is [array([0.37298846], dtype=float32), 2.1960816]. 
=============================================
[2019-03-26 19:13:44,175] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 39789: loss 0.0119
[2019-03-26 19:13:44,178] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 39790: learning rate 0.0010
[2019-03-26 19:13:44,355] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 39870: loss 0.1089
[2019-03-26 19:13:44,362] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 39872: learning rate 0.0010
[2019-03-26 19:13:44,422] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 39895: loss 0.1902
[2019-03-26 19:13:44,425] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 39895: learning rate 0.0010
[2019-03-26 19:13:44,524] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 39943: loss 0.0913
[2019-03-26 19:13:44,529] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 39947: learning rate 0.0010
[2019-03-26 19:13:44,559] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 39961: loss 0.0005
[2019-03-26 19:13:44,562] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 39961: learning rate 0.0010
[2019-03-26 19:13:44,565] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 39962: loss 0.0010
[2019-03-26 19:13:44,568] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 39962: learning rate 0.0010
[2019-03-26 19:13:44,597] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39973: loss 0.0079
[2019-03-26 19:13:44,602] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 39976: learning rate 0.0010
[2019-03-26 19:13:44,602] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 39976: loss 0.0043
[2019-03-26 19:13:44,606] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 39977: learning rate 0.0010
[2019-03-26 19:13:44,618] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 39980: loss 0.0404
[2019-03-26 19:13:44,624] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 39981: learning rate 0.0010
[2019-03-26 19:13:44,625] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 39981: loss 0.0174
[2019-03-26 19:13:44,629] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 39982: learning rate 0.0010
[2019-03-26 19:13:44,641] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 39990: loss 0.0058
[2019-03-26 19:13:44,644] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 39990: learning rate 0.0010
[2019-03-26 19:13:44,746] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 40041: loss 0.0900
[2019-03-26 19:13:44,753] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 40042: learning rate 0.0010
[2019-03-26 19:13:44,771] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 40049: loss 0.0856
[2019-03-26 19:13:44,774] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 40050: learning rate 0.0010
[2019-03-26 19:13:44,846] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 40080: loss 0.0217
[2019-03-26 19:13:44,847] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 40080: learning rate 0.0010
[2019-03-26 19:13:44,941] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 40123: loss 0.0006
[2019-03-26 19:13:44,943] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 40123: learning rate 0.0010
[2019-03-26 19:13:45,045] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 40170: loss 0.0276
[2019-03-26 19:13:45,052] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 40171: learning rate 0.0010
[2019-03-26 19:13:46,193] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.4201052e-18 1.0000000e+00 3.8380067e-27 1.1224249e-27 1.4546425e-29], sum to 1.0000
[2019-03-26 19:13:46,200] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2670
[2019-03-26 19:13:46,208] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.25, 58.66666666666667, 1.0, 2.0, 0.346292124444137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 534723.2371210987, 534723.2371210987, 169422.5073354292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1529400.0000, 
sim time next is 1530000.0000, 
raw observation next is [27.1, 59.0, 1.0, 2.0, 0.3437258197622903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 531896.1454583206, 531896.14545832, 169226.5476227], 
processed observation next is [0.0, 0.7391304347826086, 0.4834123222748816, 0.59, 1.0, 1.0, 0.20930821658107263, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14774892929397795, 0.1477489292939778, 0.25257693675029846], 
reward next is 0.7474, 
noisyNet noise sample is [array([0.58599734], dtype=float32), -0.04482774]. 
=============================================
[2019-03-26 19:13:46,217] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[70.619606]
 [70.59309 ]
 [70.56223 ]
 [70.53082 ]
 [70.491806]], R is [[70.69033051]
 [70.7305603 ]
 [70.77004242]
 [70.80873108]
 [70.84672546]].
[2019-03-26 19:13:47,405] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.9046971e-17 1.0000000e+00 1.0688948e-27 4.7768252e-26 2.7451369e-29], sum to 1.0000
[2019-03-26 19:13:47,413] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4186
[2019-03-26 19:13:47,417] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.18333333333334, 85.5, 1.0, 2.0, 0.3573930548972085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 548950.372092193, 548950.3720921937, 170512.9621013683], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1543800.0000, 
sim time next is 1544400.0000, 
raw observation next is [23.1, 86.0, 1.0, 2.0, 0.3561579235170261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 547306.5807380031, 547306.5807380031, 170382.9207291479], 
processed observation next is [0.0, 0.9130434782608695, 0.2938388625592418, 0.86, 1.0, 1.0, 0.22428665483979046, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15202960576055644, 0.15202960576055644, 0.25430286675992225], 
reward next is 0.7457, 
noisyNet noise sample is [array([0.7910089], dtype=float32), 1.2174318]. 
=============================================
[2019-03-26 19:13:55,490] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6077971e-15 1.0000000e+00 3.1031551e-23 2.6111356e-23 2.7855960e-26], sum to 1.0000
[2019-03-26 19:13:55,498] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9493
[2019-03-26 19:13:55,504] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666666, 89.0, 1.0, 2.0, 0.9251684943578017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1293140.94533404, 1293140.94533404, 276951.4914677984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1680000.0000, 
sim time next is 1680600.0000, 
raw observation next is [25.78333333333333, 88.5, 1.0, 2.0, 0.9213328693092347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1287776.504167697, 1287776.504167696, 275870.1029602659], 
processed observation next is [1.0, 0.43478260869565216, 0.4210110584518167, 0.885, 1.0, 1.0, 0.9052203244689575, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.35771569560213806, 0.3577156956021378, 0.411746422328755], 
reward next is 0.5883, 
noisyNet noise sample is [array([1.1730765], dtype=float32), -0.7256914]. 
=============================================
[2019-03-26 19:13:56,112] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.9750870e-13 1.0000000e+00 4.4278258e-20 3.6535314e-19 1.9909175e-21], sum to 1.0000
[2019-03-26 19:13:56,117] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5465
[2019-03-26 19:13:56,121] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.2, 79.0, 1.0, 2.0, 0.5805050214866686, 1.0, 2.0, 0.5805050214866686, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1623025.122089181, 1623025.122089181, 327160.3476170787], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1695600.0000, 
sim time next is 1696200.0000, 
raw observation next is [28.25, 78.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 8.472683201245568, 6.9112, 168.9040860259215, 2562189.346915605, 1454477.596520511, 310531.117300093], 
processed observation next is [1.0, 0.6521739130434783, 0.537914691943128, 0.7866666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.15614832012455676, 0.0, 0.8293963870124356, 0.7117192630321125, 0.40402155458903083, 0.4634792795523776], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.03432526], dtype=float32), -1.5329956]. 
=============================================
[2019-03-26 19:13:56,634] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.9481929e-08 9.9999988e-01 2.0075242e-13 1.4092600e-12 9.9100034e-15], sum to 1.0000
[2019-03-26 19:13:56,644] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2818
[2019-03-26 19:13:56,649] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.2, 78.0, 1.0, 2.0, 0.5045633154050175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 705050.9564022244, 705050.956402225, 184315.1357678926], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1706400.0000, 
sim time next is 1707000.0000, 
raw observation next is [28.06666666666667, 78.66666666666667, 1.0, 2.0, 0.5064215132278067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 707648.3718230554, 707648.371823056, 184609.1211600403], 
processed observation next is [1.0, 0.782608695652174, 0.529225908372828, 0.7866666666666667, 1.0, 1.0, 0.40532712437085144, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19656899217307094, 0.1965689921730711, 0.2755360017314034], 
reward next is 0.7245, 
noisyNet noise sample is [array([0.27852786], dtype=float32), -1.3522679]. 
=============================================
[2019-03-26 19:13:56,660] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[23.99162 ]
 [23.704084]
 [23.377922]
 [23.312016]
 [22.934172]], R is [[24.88661003]
 [25.36264801]
 [25.83553696]
 [26.3058548 ]
 [26.77353668]].
[2019-03-26 19:13:57,692] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.2392850e-16 1.0000000e+00 2.1255911e-25 4.7942723e-28 1.4920284e-27], sum to 1.0000
[2019-03-26 19:13:57,705] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0719
[2019-03-26 19:13:57,710] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.43333333333334, 94.0, 1.0, 2.0, 0.503261366934298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 703231.0780435816, 703231.0780435816, 184108.6900725193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1726800.0000, 
sim time next is 1727400.0000, 
raw observation next is [25.36666666666667, 94.0, 1.0, 2.0, 0.5013646783190098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 700579.8707358699, 700579.8707358692, 183810.1755656344], 
processed observation next is [1.0, 1.0, 0.40126382306477115, 0.94, 1.0, 1.0, 0.399234552191578, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19460551964885273, 0.19460551964885253, 0.27434354562034985], 
reward next is 0.7257, 
noisyNet noise sample is [array([-0.3135451], dtype=float32), 0.49923846]. 
=============================================
[2019-03-26 19:13:57,795] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3830314e-16 1.0000000e+00 2.3758783e-24 8.5740148e-28 8.5089135e-28], sum to 1.0000
[2019-03-26 19:13:57,803] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9138
[2019-03-26 19:13:57,923] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.9, 92.0, 1.0, 2.0, 0.5097685494312868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712326.9227911418, 712326.9227911412, 185140.8630280854], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1722000.0000, 
sim time next is 1722600.0000, 
raw observation next is [25.85, 92.5, 1.0, 2.0, 0.5100168059782505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 712673.9413427863, 712673.941342787, 185180.5133621522], 
processed observation next is [1.0, 0.9565217391304348, 0.4241706161137442, 0.925, 1.0, 1.0, 0.40965880238343433, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19796498370632953, 0.19796498370632973, 0.27638882591366004], 
reward next is 0.7236, 
noisyNet noise sample is [array([-0.98849237], dtype=float32), 0.32915464]. 
=============================================
[2019-03-26 19:13:58,904] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.9478619e-18 1.0000000e+00 3.4689773e-27 3.8997773e-31 1.4922773e-29], sum to 1.0000
[2019-03-26 19:13:58,911] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8350
[2019-03-26 19:13:59,036] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 94.0, 1.0, 2.0, 0.4775462822977513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 679988.2797720652, 679988.2797720659, 181780.5287206051], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1746000.0000, 
sim time next is 1746600.0000, 
raw observation next is [24.25, 93.83333333333334, 1.0, 2.0, 0.5569936859691708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 792635.6746041526, 792635.674604152, 194838.0820007253], 
processed observation next is [1.0, 0.21739130434782608, 0.3483412322274882, 0.9383333333333335, 1.0, 1.0, 0.4662574529749045, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22017657627893128, 0.2201765762789311, 0.2908031074637691], 
reward next is 0.7092, 
noisyNet noise sample is [array([-2.2083375], dtype=float32), -1.2512681]. 
=============================================
[2019-03-26 19:13:59,096] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3614575e-17 1.0000000e+00 3.9115344e-30 2.5868154e-31 8.6473201e-30], sum to 1.0000
[2019-03-26 19:13:59,104] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8988
[2019-03-26 19:13:59,108] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 94.0, 1.0, 2.0, 0.4768157272293644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 666265.7373571822, 666265.7373571828, 180042.9938791809], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1734600.0000, 
sim time next is 1735200.0000, 
raw observation next is [24.6, 94.0, 1.0, 2.0, 0.4742197296898489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 662885.1596225568, 662885.1596225568, 179687.1728541443], 
processed observation next is [1.0, 0.08695652173913043, 0.36492890995260674, 0.94, 1.0, 1.0, 0.3665297948070469, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18413476656182132, 0.18413476656182132, 0.2681898102300661], 
reward next is 0.7318, 
noisyNet noise sample is [array([1.0644157], dtype=float32), -0.19987178]. 
=============================================
[2019-03-26 19:13:59,180] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.7370568e-15 1.0000000e+00 1.7693699e-26 1.6322085e-28 1.5634773e-27], sum to 1.0000
[2019-03-26 19:13:59,185] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0718
[2019-03-26 19:13:59,194] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.35, 93.5, 1.0, 2.0, 0.4873468549343948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 691831.4654513524, 691831.465451353, 183027.3932835453], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1747800.0000, 
sim time next is 1748400.0000, 
raw observation next is [24.4, 93.33333333333334, 1.0, 2.0, 0.5124576535202783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726592.295516293, 726592.295516293, 186915.6330045822], 
processed observation next is [1.0, 0.21739130434782608, 0.3554502369668246, 0.9333333333333335, 1.0, 1.0, 0.4125995825545521, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20183119319897028, 0.20183119319897028, 0.278978556723257], 
reward next is 0.7210, 
noisyNet noise sample is [array([-0.030893], dtype=float32), 0.118661664]. 
=============================================
[2019-03-26 19:14:01,758] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6226588e-15 1.0000000e+00 1.7784892e-29 2.7404915e-29 2.0712146e-28], sum to 1.0000
[2019-03-26 19:14:01,767] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6338
[2019-03-26 19:14:01,772] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 93.0, 1.0, 2.0, 0.5709548202188928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 905379.7015858737, 905379.7015858737, 207764.8903681867], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1783800.0000, 
sim time next is 1784400.0000, 
raw observation next is [21.0, 93.33333333333334, 1.0, 2.0, 0.5371679581402501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 851030.6025076078, 851030.6025076078, 201084.4899458381], 
processed observation next is [1.0, 0.6521739130434783, 0.19431279620853087, 0.9333333333333335, 1.0, 1.0, 0.44237103390391574, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2363973895854466, 0.2363973895854466, 0.3001261043967733], 
reward next is 0.6999, 
noisyNet noise sample is [array([-0.21741223], dtype=float32), 0.5926274]. 
=============================================
[2019-03-26 19:14:02,223] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 47820: loss 0.2795
[2019-03-26 19:14:02,226] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 47821: learning rate 0.0010
[2019-03-26 19:14:02,298] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 47853: loss 0.0662
[2019-03-26 19:14:02,300] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 47854: learning rate 0.0010
[2019-03-26 19:14:02,311] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 47858: loss 0.0893
[2019-03-26 19:14:02,313] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 47858: learning rate 0.0010
[2019-03-26 19:14:02,345] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 47874: loss 0.0251
[2019-03-26 19:14:02,347] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 47876: learning rate 0.0010
[2019-03-26 19:14:02,356] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 47881: loss 0.0670
[2019-03-26 19:14:02,360] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 47882: learning rate 0.0010
[2019-03-26 19:14:02,387] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 47895: loss 0.0106
[2019-03-26 19:14:02,390] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 47895: learning rate 0.0010
[2019-03-26 19:14:02,560] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 47977: loss 0.1836
[2019-03-26 19:14:02,566] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 47977: learning rate 0.0010
[2019-03-26 19:14:02,569] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 47980: loss 0.2065
[2019-03-26 19:14:02,572] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 47981: learning rate 0.0010
[2019-03-26 19:14:02,596] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 47992: loss 0.1492
[2019-03-26 19:14:02,598] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 47993: learning rate 0.0010
[2019-03-26 19:14:02,607] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 47996: loss 0.1119
[2019-03-26 19:14:02,609] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 47997: learning rate 0.0010
[2019-03-26 19:14:02,693] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 48037: loss 0.0173
[2019-03-26 19:14:02,696] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 48037: learning rate 0.0010
[2019-03-26 19:14:02,706] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 48045: loss 0.0281
[2019-03-26 19:14:02,711] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 48046: learning rate 0.0010
[2019-03-26 19:14:02,854] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 48108: loss 0.0817
[2019-03-26 19:14:02,860] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 48110: learning rate 0.0010
[2019-03-26 19:14:02,911] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 48135: loss 0.0964
[2019-03-26 19:14:02,913] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 48135: learning rate 0.0010
[2019-03-26 19:14:02,955] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 48153: loss 0.0364
[2019-03-26 19:14:02,963] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 48155: learning rate 0.0010
[2019-03-26 19:14:02,979] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 48165: loss 0.0097
[2019-03-26 19:14:02,982] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 48165: learning rate 0.0010
[2019-03-26 19:14:06,894] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 19:14:06,898] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:14:06,899] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:14:06,901] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:14:06,901] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:14:06,903] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:14:06,905] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:14:06,904] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:14:06,903] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:14:06,908] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:14:06,910] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:14:06,919] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run3
[2019-03-26 19:14:06,919] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run3
[2019-03-26 19:14:06,957] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run3
[2019-03-26 19:14:06,958] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run3
[2019-03-26 19:14:06,975] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run3
[2019-03-26 19:14:43,877] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21669233], dtype=float32), -0.3860929]
[2019-03-26 19:14:43,878] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.6, 94.0, 1.0, 2.0, 0.4914845726403022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 687460.6183830122, 687460.6183830122, 182360.6946388401]
[2019-03-26 19:14:43,879] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:14:43,883] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.1965684e-11 1.0000000e+00 2.9782665e-18 5.3911487e-20 2.3050535e-19], sampled 0.08736347958407487
[2019-03-26 19:14:53,747] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21669233], dtype=float32), -0.3860929]
[2019-03-26 19:14:53,748] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.7, 71.0, 1.0, 2.0, 0.5392050694011464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 753474.7387567776, 753474.7387567776, 189966.0617758326]
[2019-03-26 19:14:53,749] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:14:53,751] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.5216556e-11 1.0000000e+00 1.0048669e-17 2.0621576e-19 8.3947241e-19], sampled 0.38267653036149063
[2019-03-26 19:15:41,357] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21669233], dtype=float32), -0.3860929]
[2019-03-26 19:15:41,359] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.83333333333334, 78.66666666666667, 1.0, 2.0, 0.6268411952826682, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.963127142298999, 6.9112, 168.9125643078965, 1752695.622048812, 1715856.805644611, 370183.3249687987]
[2019-03-26 19:15:41,359] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:15:41,363] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.6854557e-11 1.0000000e+00 6.2171457e-18 1.1274417e-19 6.4687525e-19], sampled 0.8793053236253673
[2019-03-26 19:15:41,367] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1752695.622048812 W.
[2019-03-26 19:15:51,135] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21669233], dtype=float32), -0.3860929]
[2019-03-26 19:15:51,138] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.46666666666667, 90.66666666666667, 1.0, 2.0, 0.3311335112969416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 522813.9779869437, 522813.9779869437, 168755.0481316826]
[2019-03-26 19:15:51,140] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:15:51,142] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.7257727e-11 1.0000000e+00 8.2501216e-18 1.6586472e-19 6.4529792e-19], sampled 0.6717822462039713
[2019-03-26 19:16:00,362] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 19:16:00,508] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 19:16:00,524] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 19:16:00,636] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1844 3164017094.3913 1778.0000
[2019-03-26 19:16:00,843] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 19:16:01,856] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 50000, evaluation results [50000.0, 7884.184409332408, 3164017094.3913355, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 19:16:04,554] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0912447e-14 1.0000000e+00 1.0594916e-22 4.5255949e-25 1.0211243e-23], sum to 1.0000
[2019-03-26 19:16:04,565] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8436
[2019-03-26 19:16:04,573] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.51666666666667, 93.33333333333334, 1.0, 2.0, 0.4608808574322754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 677225.1522928596, 677225.1522928596, 181884.2629197574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1919400.0000, 
sim time next is 1920000.0000, 
raw observation next is [23.63333333333333, 92.66666666666667, 1.0, 2.0, 0.4303234485036004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 631597.265746425, 631597.2657464244, 177259.1514627667], 
processed observation next is [1.0, 0.21739130434782608, 0.3191153238546602, 0.9266666666666667, 1.0, 1.0, 0.31364270904048236, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1754436849295625, 0.17544368492956233, 0.26456589770562194], 
reward next is 0.7354, 
noisyNet noise sample is [array([0.5406619], dtype=float32), -0.24436374]. 
=============================================
[2019-03-26 19:16:04,589] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[61.59017 ]
 [61.595234]
 [61.570618]
 [61.565956]
 [61.604694]], R is [[61.73215866]
 [61.84336853]
 [61.96304321]
 [62.08113861]
 [62.19718552]].
[2019-03-26 19:16:07,985] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6859140e-16 1.0000000e+00 4.3030556e-27 9.3383355e-28 1.1538477e-27], sum to 1.0000
[2019-03-26 19:16:07,994] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1897
[2019-03-26 19:16:07,999] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 98.0, 1.0, 2.0, 0.4427695656611675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 636530.7489122464, 636530.7489122457, 177409.2802272631], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1983600.0000, 
sim time next is 1984200.0000, 
raw observation next is [23.56666666666667, 97.83333333333334, 1.0, 2.0, 0.4458249436070488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 639476.8617077165, 639476.8617077158, 177668.092980041], 
processed observation next is [1.0, 1.0, 0.31595576619273325, 0.9783333333333334, 1.0, 1.0, 0.33231920916511903, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1776324615854768, 0.1776324615854766, 0.2651762581791657], 
reward next is 0.7348, 
noisyNet noise sample is [array([-1.2691076], dtype=float32), 0.717039]. 
=============================================
[2019-03-26 19:16:14,751] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 55822: loss 0.1524
[2019-03-26 19:16:14,758] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 55822: learning rate 0.0010
[2019-03-26 19:16:14,800] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 55842: loss 0.0892
[2019-03-26 19:16:14,801] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 55842: loss 0.0353
[2019-03-26 19:16:14,802] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 55842: learning rate 0.0010
[2019-03-26 19:16:14,803] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 55842: learning rate 0.0010
[2019-03-26 19:16:14,843] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 55858: loss 0.0033
[2019-03-26 19:16:14,845] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 55859: learning rate 0.0010
[2019-03-26 19:16:14,891] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 55882: loss 0.0053
[2019-03-26 19:16:14,895] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 55883: learning rate 0.0010
[2019-03-26 19:16:14,941] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 55904: loss 0.0045
[2019-03-26 19:16:14,944] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 55905: learning rate 0.0010
[2019-03-26 19:16:15,078] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 55965: loss 0.2581
[2019-03-26 19:16:15,080] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 55966: learning rate 0.0010
[2019-03-26 19:16:15,151] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 55997: loss 0.1294
[2019-03-26 19:16:15,152] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 55997: learning rate 0.0010
[2019-03-26 19:16:15,178] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 56007: loss 0.0446
[2019-03-26 19:16:15,180] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 56009: learning rate 0.0010
[2019-03-26 19:16:15,247] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 56041: loss 0.0007
[2019-03-26 19:16:15,248] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 56041: learning rate 0.0010
[2019-03-26 19:16:15,262] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 56047: loss 0.0249
[2019-03-26 19:16:15,265] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 56047: learning rate 0.0010
[2019-03-26 19:16:15,286] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 56057: loss 0.0005
[2019-03-26 19:16:15,288] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 56057: learning rate 0.0010
[2019-03-26 19:16:15,335] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 56077: loss 0.0120
[2019-03-26 19:16:15,337] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 56077: learning rate 0.0010
[2019-03-26 19:16:15,361] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 56087: loss 0.0724
[2019-03-26 19:16:15,364] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 56088: learning rate 0.0010
[2019-03-26 19:16:15,493] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 56150: loss 0.0891
[2019-03-26 19:16:15,495] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 56150: learning rate 0.0010
[2019-03-26 19:16:15,656] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 56224: loss 0.0023
[2019-03-26 19:16:15,660] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 56224: learning rate 0.0010
[2019-03-26 19:16:19,363] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4759866e-14 1.0000000e+00 1.9745084e-25 1.6317362e-27 1.4275560e-24], sum to 1.0000
[2019-03-26 19:16:19,372] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9188
[2019-03-26 19:16:19,378] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.35, 94.0, 1.0, 2.0, 0.5063296143861639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 707519.9141621374, 707519.9141621374, 184593.4038149681], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2166600.0000, 
sim time next is 2167200.0000, 
raw observation next is [25.3, 94.0, 1.0, 2.0, 0.5066144268144847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 707918.0295500153, 707918.029550016, 184638.4407051234], 
processed observation next is [1.0, 0.08695652173913043, 0.39810426540284366, 0.94, 1.0, 1.0, 0.4055595503788971, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1966438970972265, 0.19664389709722668, 0.2755797622464528], 
reward next is 0.7244, 
noisyNet noise sample is [array([-0.99617547], dtype=float32), 0.1905427]. 
=============================================
[2019-03-26 19:16:25,471] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1417459e-19 1.0000000e+00 1.2367882e-28 2.4273691e-27 3.3153009e-28], sum to 1.0000
[2019-03-26 19:16:25,480] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9082
[2019-03-26 19:16:25,486] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.03333333333333, 86.33333333333334, 1.0, 2.0, 0.5980096843371455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 835679.4958897944, 835679.4958897944, 200367.9193378125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2265600.0000, 
sim time next is 2266200.0000, 
raw observation next is [26.2, 85.5, 1.0, 2.0, 0.5981101342203867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 835819.9232756051, 835819.9232756051, 200386.6752005977], 
processed observation next is [1.0, 0.21739130434782608, 0.44075829383886256, 0.855, 1.0, 1.0, 0.5157953424342009, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2321722009098903, 0.2321722009098903, 0.2990845898516384], 
reward next is 0.7009, 
noisyNet noise sample is [array([-0.08285844], dtype=float32), 0.48254943]. 
=============================================
[2019-03-26 19:16:27,739] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2166369e-08 1.0000000e+00 1.7604239e-13 4.9643301e-10 4.3574402e-13], sum to 1.0000
[2019-03-26 19:16:27,748] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8288
[2019-03-26 19:16:27,757] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.55, 74.5, 1.0, 2.0, 0.5714326050483157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 798525.8016781245, 798525.8016781245, 195545.2215697849], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2316600.0000, 
sim time next is 2317200.0000, 
raw observation next is [30.43333333333333, 75.33333333333333, 1.0, 2.0, 0.5727263156361257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 800334.3272621585, 800334.3272621585, 195775.5309704226], 
processed observation next is [1.0, 0.8260869565217391, 0.6413902053712479, 0.7533333333333333, 1.0, 1.0, 0.4852124284772599, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22231509090615514, 0.22231509090615514, 0.2922022850304815], 
reward next is 0.7078, 
noisyNet noise sample is [array([0.8234263], dtype=float32), -0.4951442]. 
=============================================
[2019-03-26 19:16:28,169] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3353568e-10 1.0000000e+00 8.5308712e-16 8.9129338e-12 5.4221379e-16], sum to 1.0000
[2019-03-26 19:16:28,183] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0914
[2019-03-26 19:16:28,187] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.7, 78.0, 1.0, 2.0, 0.5704048126491973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 797089.0150994578, 797089.0150994578, 195362.0085995898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2322000.0000, 
sim time next is 2322600.0000, 
raw observation next is [29.6, 78.33333333333333, 1.0, 2.0, 0.5689007990590577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 794986.5059331937, 794986.5059331937, 195095.3099613687], 
processed observation next is [1.0, 0.9130434782608695, 0.6018957345971565, 0.7833333333333333, 1.0, 1.0, 0.4806033723603104, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2208295849814427, 0.2208295849814427, 0.29118702979308764], 
reward next is 0.7088, 
noisyNet noise sample is [array([1.2348287], dtype=float32), 0.86505723]. 
=============================================
[2019-03-26 19:16:30,416] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.2903474e-10 1.0000000e+00 4.2737789e-17 9.4846664e-10 3.8272658e-17], sum to 1.0000
[2019-03-26 19:16:30,427] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9599
[2019-03-26 19:16:30,432] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.7, 75.0, 1.0, 2.0, 0.7020375815863508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 981118.8380463118, 981118.8380463118, 221284.6010492296], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2358000.0000, 
sim time next is 2358600.0000, 
raw observation next is [28.83333333333334, 74.5, 1.0, 2.0, 0.781209157663075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1091820.399190727, 1091820.399190727, 239349.6336851854], 
processed observation next is [1.0, 0.30434782608695654, 0.5655608214849924, 0.745, 1.0, 1.0, 0.7363965754976807, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.30328344421964637, 0.30328344421964637, 0.35723825923162], 
reward next is 0.6428, 
noisyNet noise sample is [array([0.01002074], dtype=float32), 1.1241266]. 
=============================================
[2019-03-26 19:16:32,371] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 63761: loss 7.8022
[2019-03-26 19:16:32,373] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 63761: learning rate 0.0010
[2019-03-26 19:16:32,508] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 63826: loss 7.8567
[2019-03-26 19:16:32,511] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 63827: learning rate 0.0010
[2019-03-26 19:16:32,701] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 63912: loss 6.1329
[2019-03-26 19:16:32,702] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 63912: learning rate 0.0010
[2019-03-26 19:16:32,713] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 63915: loss 11.3320
[2019-03-26 19:16:32,715] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 63915: learning rate 0.0010
[2019-03-26 19:16:32,723] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 63917: loss 8.7516
[2019-03-26 19:16:32,725] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 63917: learning rate 0.0010
[2019-03-26 19:16:32,821] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 63964: loss 7.5314
[2019-03-26 19:16:32,824] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 63965: learning rate 0.0010
[2019-03-26 19:16:32,847] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 63978: loss 11.0987
[2019-03-26 19:16:32,849] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 63978: learning rate 0.0010
[2019-03-26 19:16:32,875] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 63990: loss 6.1516
[2019-03-26 19:16:32,877] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 63991: learning rate 0.0010
[2019-03-26 19:16:32,883] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 63992: loss 6.4814
[2019-03-26 19:16:32,886] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 63993: learning rate 0.0010
[2019-03-26 19:16:32,901] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 63998: loss 7.0977
[2019-03-26 19:16:32,904] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 63998: learning rate 0.0010
[2019-03-26 19:16:32,955] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 64019: loss 7.1172
[2019-03-26 19:16:32,956] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 64019: learning rate 0.0010
[2019-03-26 19:16:32,975] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 64027: loss 7.8567
[2019-03-26 19:16:32,982] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 64031: learning rate 0.0010
[2019-03-26 19:16:33,027] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 64050: loss 4.1594
[2019-03-26 19:16:33,031] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 64053: learning rate 0.0010
[2019-03-26 19:16:33,060] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 64066: loss 4.1010
[2019-03-26 19:16:33,067] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 64067: learning rate 0.0010
[2019-03-26 19:16:33,277] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2536710e-08 9.9976128e-01 9.7458491e-12 2.3876016e-04 5.6233707e-13], sum to 1.0000
[2019-03-26 19:16:33,277] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 64163: loss 3.3494
[2019-03-26 19:16:33,280] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 64163: learning rate 0.0010
[2019-03-26 19:16:33,286] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5549
[2019-03-26 19:16:33,291] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.8, 78.0, 1.0, 2.0, 0.5741745914193467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 802358.9288674291, 802358.9288674291, 196033.3951373182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2412000.0000, 
sim time next is 2412600.0000, 
raw observation next is [29.71666666666667, 78.33333333333333, 1.0, 2.0, 0.5741466427085284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 802319.8582302403, 802319.8582302403, 196028.3315380805], 
processed observation next is [1.0, 0.9565217391304348, 0.6074249605055293, 0.7833333333333333, 1.0, 1.0, 0.4869236659138897, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22286662728617787, 0.22286662728617787, 0.29257959931056793], 
reward next is 0.7074, 
noisyNet noise sample is [array([0.5304458], dtype=float32), -0.37896737]. 
=============================================
[2019-03-26 19:16:33,566] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 64296: loss 3.3595
[2019-03-26 19:16:33,572] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 64297: learning rate 0.0010
[2019-03-26 19:16:36,190] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.1195700e-11 1.0000000e+00 1.1206264e-15 3.5640397e-12 1.6298728e-16], sum to 1.0000
[2019-03-26 19:16:36,198] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5806
[2019-03-26 19:16:36,205] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1896748.309031399 W.
[2019-03-26 19:16:36,211] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.5, 87.83333333333334, 1.0, 2.0, 0.4522137481361139, 1.0, 2.0, 0.4522137481361139, 1.0, 2.0, 0.7726980317292991, 6.9112, 6.9112, 170.5573041426782, 1896748.309031399, 1896748.309031399, 381617.2010286258], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2454600.0000, 
sim time next is 2455200.0000, 
raw observation next is [26.4, 88.0, 1.0, 2.0, 0.6685825210345306, 1.0, 2.0, 0.6685825210345306, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1869494.469615545, 1869494.469615544, 360958.2940204999], 
processed observation next is [1.0, 0.43478260869565216, 0.45023696682464454, 0.88, 1.0, 1.0, 0.6007018325717236, 1.0, 1.0, 0.6007018325717236, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5193040193376514, 0.5193040193376511, 0.5387437224186566], 
reward next is 0.4613, 
noisyNet noise sample is [array([0.15548071], dtype=float32), 1.769529]. 
=============================================
[2019-03-26 19:16:37,301] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7140892e-06 9.9999785e-01 7.6464324e-10 4.9882362e-07 2.2267522e-12], sum to 1.0000
[2019-03-26 19:16:37,308] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1274
[2019-03-26 19:16:37,314] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1941034.85627031 W.
[2019-03-26 19:16:37,319] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.2, 85.66666666666667, 1.0, 2.0, 0.747096029483112, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.981409883323709, 6.9112, 168.9124799914019, 1941034.85627031, 1891225.689119429, 396075.1359294918], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2473800.0000, 
sim time next is 2474400.0000, 
raw observation next is [27.3, 85.33333333333334, 1.0, 2.0, 0.7167683843069328, 1.0, 1.0, 0.7167683843069328, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2004358.105619629, 2004358.105619629, 381382.1577506366], 
processed observation next is [1.0, 0.6521739130434783, 0.4928909952606636, 0.8533333333333334, 1.0, 1.0, 0.6587570895264251, 1.0, 0.5, 0.6587570895264251, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5567661404498969, 0.5567661404498969, 0.5692271011203531], 
reward next is 0.4308, 
noisyNet noise sample is [array([-0.44951612], dtype=float32), -0.17780456]. 
=============================================
[2019-03-26 19:16:38,122] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6283567e-12 1.0000000e+00 2.8275846e-19 2.3308521e-14 5.0367167e-19], sum to 1.0000
[2019-03-26 19:16:38,138] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0867
[2019-03-26 19:16:38,142] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666667, 91.66666666666667, 1.0, 2.0, 0.5531454007898564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 772961.776055016, 772961.776055016, 192341.8934636629], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2490000.0000, 
sim time next is 2490600.0000, 
raw observation next is [27.08333333333333, 92.33333333333333, 1.0, 2.0, 0.55378696632678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 773858.6221313174, 773858.6221313174, 192452.5599444059], 
processed observation next is [1.0, 0.8260869565217391, 0.4826224328593995, 0.9233333333333333, 1.0, 1.0, 0.4623939353334699, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2149607283698104, 0.2149607283698104, 0.28724262678269535], 
reward next is 0.7128, 
noisyNet noise sample is [array([0.96225244], dtype=float32), 0.5753159]. 
=============================================
[2019-03-26 19:16:39,232] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.22822168e-13 1.00000000e+00 4.61932228e-20 3.91126076e-10
 1.33913004e-20], sum to 1.0000
[2019-03-26 19:16:39,240] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4886
[2019-03-26 19:16:39,247] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 96.0, 1.0, 2.0, 0.691170751088145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 965925.2059823722, 965925.2059823722, 218951.8724616951], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2517600.0000, 
sim time next is 2518200.0000, 
raw observation next is [26.3, 96.0, 1.0, 2.0, 0.6858248433928761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 958450.8197995113, 958450.8197995106, 217816.1786139738], 
processed observation next is [1.0, 0.13043478260869565, 0.4454976303317536, 0.96, 1.0, 1.0, 0.621475714931176, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2662363388331976, 0.2662363388331974, 0.3250987740507072], 
reward next is 0.6749, 
noisyNet noise sample is [array([-0.79948133], dtype=float32), 0.8040496]. 
=============================================
[2019-03-26 19:16:44,243] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.3477815e-13 9.9999988e-01 1.0655723e-20 1.1875103e-07 8.0160047e-22], sum to 1.0000
[2019-03-26 19:16:44,254] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1659
[2019-03-26 19:16:44,258] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.13333333333333, 92.0, 1.0, 2.0, 0.4399230405821846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 634846.1989082854, 634846.1989082847, 177304.0313787904], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2602200.0000, 
sim time next is 2602800.0000, 
raw observation next is [24.1, 92.0, 1.0, 2.0, 0.4379643431404646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 632869.7156598038, 632869.7156598032, 177129.8350404189], 
processed observation next is [0.0, 0.13043478260869565, 0.3412322274881518, 0.92, 1.0, 1.0, 0.32284860619333083, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17579714323883439, 0.17579714323883425, 0.2643728881200282], 
reward next is 0.7356, 
noisyNet noise sample is [array([-1.136041], dtype=float32), 0.42184865]. 
=============================================
[2019-03-26 19:16:49,993] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 71704: loss 0.2107
[2019-03-26 19:16:49,995] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 71704: learning rate 0.0010
[2019-03-26 19:16:50,114] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 71756: loss 0.0554
[2019-03-26 19:16:50,117] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 71756: learning rate 0.0010
[2019-03-26 19:16:50,220] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6037351e-16 1.0000000e+00 1.4841184e-23 3.7180378e-19 1.5200339e-28], sum to 1.0000
[2019-03-26 19:16:50,228] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9659
[2019-03-26 19:16:50,235] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 97.66666666666667, 1.0, 2.0, 0.462076859757189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 650915.6321728296, 650915.632172829, 178546.2408703369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2695800.0000, 
sim time next is 2696400.0000, 
raw observation next is [24.0, 98.0, 1.0, 2.0, 0.4638759431771568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 652221.4458027497, 652221.4458027504, 178652.3929667745], 
processed observation next is [0.0, 0.21739130434782608, 0.3364928909952607, 0.98, 1.0, 1.0, 0.35406740141826126, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18117262383409716, 0.18117262383409732, 0.26664536263697686], 
reward next is 0.7334, 
noisyNet noise sample is [array([-0.42641708], dtype=float32), -1.1637938]. 
=============================================
[2019-03-26 19:16:50,378] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 71881: loss 0.2043
[2019-03-26 19:16:50,382] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 71881: learning rate 0.0010
[2019-03-26 19:16:50,451] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 71910: loss 0.2661
[2019-03-26 19:16:50,452] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 71911: learning rate 0.0010
[2019-03-26 19:16:50,525] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 71947: loss 0.1462
[2019-03-26 19:16:50,527] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 71947: loss 0.1989
[2019-03-26 19:16:50,532] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 71947: learning rate 0.0010
[2019-03-26 19:16:50,534] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 71948: learning rate 0.0010
[2019-03-26 19:16:50,560] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 71961: loss 0.1444
[2019-03-26 19:16:50,566] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 71962: learning rate 0.0010
[2019-03-26 19:16:50,572] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 71966: loss 0.1803
[2019-03-26 19:16:50,575] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 71966: learning rate 0.0010
[2019-03-26 19:16:50,589] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 71972: loss 0.2213
[2019-03-26 19:16:50,590] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 71972: learning rate 0.0010
[2019-03-26 19:16:50,608] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 71978: loss 0.2268
[2019-03-26 19:16:50,610] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 71979: learning rate 0.0010
[2019-03-26 19:16:50,630] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 71990: loss 0.1392
[2019-03-26 19:16:50,632] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 71991: learning rate 0.0010
[2019-03-26 19:16:50,757] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 72047: loss 0.0014
[2019-03-26 19:16:50,761] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 72049: learning rate 0.0010
[2019-03-26 19:16:50,765] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 72051: loss 0.0002
[2019-03-26 19:16:50,768] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 72052: learning rate 0.0010
[2019-03-26 19:16:50,917] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 72121: loss 0.0056
[2019-03-26 19:16:50,919] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 72121: learning rate 0.0010
[2019-03-26 19:16:51,025] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8734028e-18 1.0000000e+00 1.1437553e-27 1.4317516e-14 1.0115605e-29], sum to 1.0000
[2019-03-26 19:16:51,032] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3427
[2019-03-26 19:16:51,036] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 100.0, 1.0, 2.0, 0.4767107555814358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 666119.0120372076, 666119.0120372076, 180027.0951194802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2707800.0000, 
sim time next is 2708400.0000, 
raw observation next is [23.66666666666666, 100.0, 1.0, 2.0, 0.4681866242906509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 658817.9564229068, 658817.9564229074, 179357.1657760982], 
processed observation next is [0.0, 0.34782608695652173, 0.3206951026856238, 1.0, 1.0, 1.0, 0.3592609931212662, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1830049878952519, 0.18300498789525205, 0.2676972623523854], 
reward next is 0.7323, 
noisyNet noise sample is [array([-0.13150214], dtype=float32), 0.2637968]. 
=============================================
[2019-03-26 19:16:51,174] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 72236: loss 0.0879
[2019-03-26 19:16:51,179] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 72236: learning rate 0.0010
[2019-03-26 19:16:51,368] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 72322: loss 0.0039
[2019-03-26 19:16:51,371] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 72323: learning rate 0.0010
[2019-03-26 19:16:55,163] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.9154848e-15 1.0000000e+00 1.6448118e-25 1.7589211e-16 1.6145558e-25], sum to 1.0000
[2019-03-26 19:16:55,170] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6053
[2019-03-26 19:16:55,178] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.453426618058298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 698485.0806789106, 698485.0806789106, 184441.2760997399], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2772600.0000, 
sim time next is 2773200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3890464400127625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 599267.4437834781, 599267.4437834781, 174934.6697144199], 
processed observation next is [1.0, 0.08695652173913043, 0.2417061611374408, 0.94, 1.0, 1.0, 0.2639113735093524, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16646317882874392, 0.16646317882874392, 0.26109652196182076], 
reward next is 0.7389, 
noisyNet noise sample is [array([-0.72410476], dtype=float32), -0.14603454]. 
=============================================
[2019-03-26 19:16:55,561] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5425934e-13 1.0000000e+00 2.5445481e-21 5.7775250e-14 5.9864611e-24], sum to 1.0000
[2019-03-26 19:16:55,569] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7057
[2019-03-26 19:16:55,575] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 98.0, 1.0, 2.0, 0.3415665411043997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 529250.0020647112, 529250.0020647112, 169033.531024559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2780400.0000, 
sim time next is 2781000.0000, 
raw observation next is [21.5, 97.0, 1.0, 2.0, 0.3434163734979812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 531381.400996574, 531381.400996574, 169184.0196654944], 
processed observation next is [1.0, 0.17391304347826086, 0.21800947867298584, 0.97, 1.0, 1.0, 0.20893538975660386, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14760594472127056, 0.14760594472127056, 0.2525134621873051], 
reward next is 0.7475, 
noisyNet noise sample is [array([-0.16263846], dtype=float32), -0.7431323]. 
=============================================
[2019-03-26 19:16:55,602] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[71.543365]
 [71.674614]
 [71.78126 ]
 [71.95612 ]
 [72.10276 ]], R is [[71.49798584]
 [71.53071594]
 [71.55981445]
 [71.59374237]
 [71.62717438]].
[2019-03-26 19:16:57,303] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 19:16:57,304] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:16:57,305] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:16:57,305] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:16:57,306] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:16:57,309] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:16:57,308] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:16:57,310] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:16:57,309] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:16:57,312] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:16:57,313] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:16:57,324] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run4
[2019-03-26 19:16:57,342] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run4
[2019-03-26 19:16:57,359] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run4
[2019-03-26 19:16:57,378] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run4
[2019-03-26 19:16:57,378] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run4
[2019-03-26 19:17:14,142] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.18126081], dtype=float32), -0.5373098]
[2019-03-26 19:17:14,143] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.0, 89.0, 1.0, 2.0, 0.3004546686436339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 481467.423517141, 481467.423517141, 165759.9005148803]
[2019-03-26 19:17:14,146] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:17:14,150] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.10716574e-14 1.00000000e+00 1.16883272e-23 1.22624621e-13
 2.03113342e-25], sampled 0.5184741390942013
[2019-03-26 19:17:14,764] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.18126081], dtype=float32), -0.5373098]
[2019-03-26 19:17:14,765] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.8, 72.0, 1.0, 2.0, 0.281720104992064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 455521.5915965082, 455521.5915965089, 163965.1424269354]
[2019-03-26 19:17:14,765] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:17:14,770] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.0652967e-14 1.0000000e+00 6.7313785e-23 3.2042294e-13 1.2158151e-24], sampled 0.7271551875374119
[2019-03-26 19:17:14,960] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.18126081], dtype=float32), -0.5373098]
[2019-03-26 19:17:14,962] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.0803689, 57.44756689333333, 1.0, 2.0, 0.3730984615201574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 578139.9044554799, 578139.9044554799, 173130.093887092]
[2019-03-26 19:17:14,965] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:17:14,969] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.3555578e-14 1.0000000e+00 1.8124796e-23 1.4954208e-13 2.8711618e-25], sampled 0.8674180133853343
[2019-03-26 19:17:17,088] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.18126081], dtype=float32), -0.5373098]
[2019-03-26 19:17:17,091] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.2, 47.0, 1.0, 2.0, 0.3441306530754073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 564856.1773124506, 564856.1773124506, 171735.3854635477]
[2019-03-26 19:17:17,092] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:17:17,095] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.8982211e-14 1.0000000e+00 3.0481666e-22 7.6905799e-13 6.5415431e-24], sampled 0.81605038239907
[2019-03-26 19:17:33,264] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.18126081], dtype=float32), -0.5373098]
[2019-03-26 19:17:33,266] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.7, 76.0, 1.0, 2.0, 0.7870082751547443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1123252.819943018, 1123252.819943018, 243994.2101263765]
[2019-03-26 19:17:33,267] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:17:33,269] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.8945862e-14 1.0000000e+00 3.4541026e-23 2.0612871e-13 5.1361195e-25], sampled 0.5194649772420157
[2019-03-26 19:17:50,015] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.18126081], dtype=float32), -0.5373098]
[2019-03-26 19:17:50,017] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.16666666666667, 62.16666666666667, 1.0, 2.0, 0.5583365707365252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780218.5472938264, 780218.5472938264, 193240.6921484281]
[2019-03-26 19:17:50,020] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:17:50,024] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.1565376e-15 1.0000000e+00 7.6838074e-24 9.2900981e-14 1.1720328e-25], sampled 0.7517662775766736
[2019-03-26 19:18:15,797] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.18126081], dtype=float32), -0.5373098]
[2019-03-26 19:18:15,799] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.30712333666666, 85.69330979666667, 1.0, 2.0, 0.5666047055582574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 791776.7307080439, 791776.7307080439, 194689.2966570453]
[2019-03-26 19:18:15,801] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:18:15,805] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.4770429e-15 1.0000000e+00 4.0365744e-24 6.4132402e-14 5.7868864e-26], sampled 0.12223387306262523
[2019-03-26 19:18:22,743] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.18126081], dtype=float32), -0.5373098]
[2019-03-26 19:18:22,745] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.6, 91.0, 1.0, 2.0, 0.5130791033812663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 716954.4984407043, 716954.4984407043, 185669.5528703295]
[2019-03-26 19:18:22,746] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:18:22,749] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.9302154e-15 1.0000000e+00 3.2919430e-24 5.7974614e-14 4.8212556e-26], sampled 0.2458685856402273
[2019-03-26 19:18:30,004] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.18126081], dtype=float32), -0.5373098]
[2019-03-26 19:18:30,004] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.26666666666667, 63.16666666666666, 1.0, 2.0, 0.9952599575268863, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.9129564254823, 1391174.469515594, 1391174.469515594, 297487.3094692345]
[2019-03-26 19:18:30,005] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:18:30,010] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.6979372e-14 1.0000000e+00 6.1507251e-23 2.8655715e-13 9.6028215e-25], sampled 0.5984811966442622
[2019-03-26 19:18:42,728] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.18126081], dtype=float32), -0.5373098]
[2019-03-26 19:18:42,730] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.25291629833333, 93.81103313333332, 1.0, 2.0, 0.3676106595438436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 563004.2656610734, 563004.2656610734, 171659.6026221493]
[2019-03-26 19:18:42,732] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:18:42,734] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.4683957e-15 1.0000000e+00 8.2124483e-24 9.6253016e-14 1.2517747e-25], sampled 0.4018260464855895
[2019-03-26 19:18:49,235] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.18126081], dtype=float32), -0.5373098]
[2019-03-26 19:18:49,236] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.4, 61.0, 1.0, 2.0, 0.3136543251102086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 499704.7484001722, 499704.7484001728, 167061.3718151623]
[2019-03-26 19:18:49,239] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:18:49,242] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.6720139e-14 1.0000000e+00 5.3049476e-23 2.8061025e-13 9.5815617e-25], sampled 0.1863316287147787
[2019-03-26 19:18:50,687] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 19:18:50,693] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1685 3164067279.4129 1778.0000
[2019-03-26 19:18:51,210] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.4067 2927264152.9822 1338.0000
[2019-03-26 19:18:51,426] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 19:18:51,549] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 19:18:52,564] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 75000, evaluation results [75000.0, 7884.168455680242, 3164067279.4128904, 1778.0, 8254.406660643592, 2927264152.9821725, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 19:18:57,832] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3312641e-15 1.0000000e+00 4.2424095e-26 2.5907133e-18 5.8767552e-28], sum to 1.0000
[2019-03-26 19:18:57,840] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6512
[2019-03-26 19:18:57,846] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.526962387468613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 787175.6370659193, 787175.6370659193, 194221.3347785668], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2898000.0000, 
sim time next is 2898600.0000, 
raw observation next is [22.83333333333334, 94.00000000000001, 1.0, 2.0, 0.5686072264897417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 851744.2705237466, 851744.2705237466, 202139.1769588858], 
processed observation next is [1.0, 0.5652173913043478, 0.2812006319115327, 0.9400000000000002, 1.0, 1.0, 0.4802496704695683, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23659563070104073, 0.23659563070104073, 0.30170026411774], 
reward next is 0.6983, 
noisyNet noise sample is [array([0.41415453], dtype=float32), 1.368165]. 
=============================================
[2019-03-26 19:18:58,177] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0701407e-13 1.0000000e+00 1.6203466e-21 2.2836188e-12 8.6946842e-23], sum to 1.0000
[2019-03-26 19:18:58,184] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4296
[2019-03-26 19:18:58,189] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 97.0, 1.0, 2.0, 0.3315803871043239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 519262.2577181674, 519262.2577181674, 168389.7613645521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2917800.0000, 
sim time next is 2918400.0000, 
raw observation next is [21.0, 96.0, 1.0, 2.0, 0.327929369601104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515079.3029153354, 515079.3029153354, 168100.4300197184], 
processed observation next is [1.0, 0.782608695652174, 0.19431279620853087, 0.96, 1.0, 1.0, 0.1902763489169928, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14307758414314872, 0.14307758414314872, 0.2508961642085349], 
reward next is 0.7491, 
noisyNet noise sample is [array([-0.3935744], dtype=float32), -0.04074355]. 
=============================================
[2019-03-26 19:19:00,451] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.9233133e-14 1.0000000e+00 7.5099149e-22 2.0417926e-13 8.4970230e-25], sum to 1.0000
[2019-03-26 19:19:00,461] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3647
[2019-03-26 19:19:00,471] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 99.00000000000001, 1.0, 2.0, 0.3573354535617388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 568563.9135277172, 568563.9135277172, 172496.4618637447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2945400.0000, 
sim time next is 2946000.0000, 
raw observation next is [20.33333333333334, 98.0, 1.0, 2.0, 0.3173203459314302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 504281.4369892242, 504281.4369892236, 167387.4508776125], 
processed observation next is [1.0, 0.08695652173913043, 0.16271721958925783, 0.98, 1.0, 1.0, 0.17749439268847014, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14007817694145117, 0.140078176941451, 0.2498320162352425], 
reward next is 0.7502, 
noisyNet noise sample is [array([0.7025302], dtype=float32), -1.1724048]. 
=============================================
[2019-03-26 19:19:00,484] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.9671691e-15 1.0000000e+00 1.7055289e-21 2.4398250e-14 2.8625100e-26], sum to 1.0000
[2019-03-26 19:19:00,488] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[64.157196]
 [64.197556]
 [64.28602 ]
 [64.30006 ]
 [64.34059 ]], R is [[64.27997589]
 [64.3797226 ]
 [64.48848724]
 [64.59615326]
 [64.70275116]].
[2019-03-26 19:19:00,491] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3535
[2019-03-26 19:19:00,497] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.00000000000001, 1.0, 2.0, 0.3110690049642909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 491912.914583405, 491912.914583405, 166424.9596614277], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2949000.0000, 
sim time next is 2949600.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.3081062899933056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 487217.4252841523, 487217.425284153, 166080.1343062757], 
processed observation next is [1.0, 0.13043478260869565, 0.19431279620853087, 0.94, 1.0, 1.0, 0.16639312047386215, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1353381736900423, 0.1353381736900425, 0.24788079747205327], 
reward next is 0.7521, 
noisyNet noise sample is [array([1.8283119], dtype=float32), -0.26155585]. 
=============================================
[2019-03-26 19:19:02,983] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 79711: loss 0.0385
[2019-03-26 19:19:02,985] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 79712: learning rate 0.0010
[2019-03-26 19:19:03,104] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 79726: loss 0.0677
[2019-03-26 19:19:03,106] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 79728: learning rate 0.0010
[2019-03-26 19:19:03,479] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 79870: loss 0.2883
[2019-03-26 19:19:03,483] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 79871: learning rate 0.0010
[2019-03-26 19:19:03,585] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 79882: loss 0.2457
[2019-03-26 19:19:03,589] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 79883: learning rate 0.0010
[2019-03-26 19:19:03,720] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 79910: loss 0.1347
[2019-03-26 19:19:03,723] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 79911: learning rate 0.0010
[2019-03-26 19:19:03,820] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 79924: loss 0.1384
[2019-03-26 19:19:03,823] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 79924: learning rate 0.0010
[2019-03-26 19:19:03,910] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 79937: loss 0.1088
[2019-03-26 19:19:03,910] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 79937: loss 0.0819
[2019-03-26 19:19:03,912] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 79937: learning rate 0.0010
[2019-03-26 19:19:03,914] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 79937: learning rate 0.0010
[2019-03-26 19:19:04,141] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 79974: loss 0.0212
[2019-03-26 19:19:04,142] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 79974: learning rate 0.0010
[2019-03-26 19:19:04,276] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 80008: loss 0.0195
[2019-03-26 19:19:04,278] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 80009: learning rate 0.0010
[2019-03-26 19:19:04,278] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 80010: loss 0.0190
[2019-03-26 19:19:04,362] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 80013: learning rate 0.0010
[2019-03-26 19:19:04,582] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 80085: loss 0.0357
[2019-03-26 19:19:04,584] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 80087: learning rate 0.0010
[2019-03-26 19:19:04,701] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 80108: loss 0.0281
[2019-03-26 19:19:04,705] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 80110: learning rate 0.0010
[2019-03-26 19:19:04,709] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 80112: loss 0.0193
[2019-03-26 19:19:04,793] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 80112: learning rate 0.0010
[2019-03-26 19:19:05,202] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 80267: loss 0.1412
[2019-03-26 19:19:05,206] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 80269: learning rate 0.0010
[2019-03-26 19:19:05,330] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 80292: loss 0.1574
[2019-03-26 19:19:05,333] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 80292: learning rate 0.0010
[2019-03-26 19:19:09,053] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.2348570e-14 1.0000000e+00 3.8488074e-22 1.9475071e-14 1.5745842e-22], sum to 1.0000
[2019-03-26 19:19:09,070] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5498
[2019-03-26 19:19:09,073] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.8235318903294749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1195045.921058673, 1195045.921058672, 255959.9240597442], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3076200.0000, 
sim time next is 3076800.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.8334669727279125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1209470.981654011, 1209470.981654011, 258589.5951404254], 
processed observation next is [1.0, 0.6086956521739131, 0.28909952606635075, 1.0, 1.0, 1.0, 0.7993577984673644, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3359641615705586, 0.3359641615705586, 0.3859546196125752], 
reward next is 0.6140, 
noisyNet noise sample is [array([-1.418774], dtype=float32), 1.9593931]. 
=============================================
[2019-03-26 19:19:10,687] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.62676479e-16 1.00000000e+00 8.57182307e-28 1.10066646e-13
 1.49007671e-28], sum to 1.0000
[2019-03-26 19:19:10,699] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4013
[2019-03-26 19:19:10,707] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.3837926002778032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 578065.3288533741, 578065.3288533748, 172702.1588169946], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3103200.0000, 
sim time next is 3103800.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.3841203323757227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 578558.9167785364, 578558.9167785364, 172746.2695860706], 
processed observation next is [1.0, 0.9565217391304348, 0.2417061611374408, 1.0, 1.0, 1.0, 0.2579763040671358, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1607108102162601, 0.1607108102162601, 0.2578302531135382], 
reward next is 0.7422, 
noisyNet noise sample is [array([-0.37334028], dtype=float32), -2.5522285]. 
=============================================
[2019-03-26 19:19:14,868] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0251888e-09 1.0000000e+00 1.1632102e-16 8.1217491e-11 4.3366949e-17], sum to 1.0000
[2019-03-26 19:19:14,877] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6861
[2019-03-26 19:19:14,884] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.4806063155426771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.91295651043, 671564.0890506982, 671564.0890506975, 180614.9459829721], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3172800.0000, 
sim time next is 3173400.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.4777586850197099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 667583.7682886572, 667583.7682886572, 180186.501913135], 
processed observation next is [1.0, 0.7391304347826086, 0.4786729857819906, 0.84, 1.0, 1.0, 0.3707935964092891, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1854399356357381, 0.1854399356357381, 0.26893507748229106], 
reward next is 0.7311, 
noisyNet noise sample is [array([0.27737], dtype=float32), 2.1810036]. 
=============================================
[2019-03-26 19:19:19,272] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.80767070e-17 1.00000000e+00 1.10984409e-26 1.30225395e-20
 1.70092355e-27], sum to 1.0000
[2019-03-26 19:19:19,282] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5692
[2019-03-26 19:19:19,290] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333334, 71.66666666666667, 1.0, 2.0, 0.5996724398922827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 838004.0048726617, 838004.0048726617, 200685.6172654667], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3258600.0000, 
sim time next is 3259200.0000, 
raw observation next is [31.66666666666667, 72.33333333333334, 1.0, 2.0, 0.598822191377483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 836815.3687192408, 836815.3687192402, 200527.3486329291], 
processed observation next is [0.0, 0.7391304347826086, 0.6998420221169038, 0.7233333333333334, 1.0, 1.0, 0.5166532426234736, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23244871353312244, 0.23244871353312227, 0.2992945501984016], 
reward next is 0.7007, 
noisyNet noise sample is [array([-1.305434], dtype=float32), -0.18259472]. 
=============================================
[2019-03-26 19:19:20,568] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2426829e-19 1.0000000e+00 1.5039305e-28 5.9075240e-21 3.8862245e-28], sum to 1.0000
[2019-03-26 19:19:20,576] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8943
[2019-03-26 19:19:20,580] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 81.5, 1.0, 2.0, 0.5350485252847587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 747664.420231969, 747664.4202319696, 189269.4674526293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3270600.0000, 
sim time next is 3271200.0000, 
raw observation next is [28.0, 80.66666666666667, 1.0, 2.0, 0.530733519724695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 741632.6264427055, 741632.6264427049, 188551.2806606337], 
processed observation next is [0.0, 0.8695652173913043, 0.5260663507109005, 0.8066666666666668, 1.0, 1.0, 0.4346186984634879, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20600906290075152, 0.20600906290075138, 0.28141982188154285], 
reward next is 0.7186, 
noisyNet noise sample is [array([-0.00397734], dtype=float32), 1.6837182]. 
=============================================
[2019-03-26 19:19:21,682] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 87666: loss 0.2360
[2019-03-26 19:19:21,686] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 87666: learning rate 0.0010
[2019-03-26 19:19:21,811] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 87729: loss 0.2039
[2019-03-26 19:19:21,813] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 87730: learning rate 0.0010
[2019-03-26 19:19:22,128] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 87872: loss 0.1418
[2019-03-26 19:19:22,129] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 87872: learning rate 0.0010
[2019-03-26 19:19:22,160] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 87886: loss 0.2256
[2019-03-26 19:19:22,164] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 87886: learning rate 0.0010
[2019-03-26 19:19:22,194] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 87897: loss 0.2211
[2019-03-26 19:19:22,196] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 87898: learning rate 0.0010
[2019-03-26 19:19:22,244] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 87919: loss 0.1229
[2019-03-26 19:19:22,247] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 87919: learning rate 0.0010
[2019-03-26 19:19:22,334] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 87960: loss 0.0339
[2019-03-26 19:19:22,337] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 87962: learning rate 0.0010
[2019-03-26 19:19:22,337] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 87963: loss 0.0326
[2019-03-26 19:19:22,339] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 87963: learning rate 0.0010
[2019-03-26 19:19:22,347] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 87969: loss 0.0114
[2019-03-26 19:19:22,349] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 87969: learning rate 0.0010
[2019-03-26 19:19:22,450] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 88012: loss 0.0456
[2019-03-26 19:19:22,453] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 88013: learning rate 0.0010
[2019-03-26 19:19:22,480] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 88026: loss 0.0631
[2019-03-26 19:19:22,483] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 88027: learning rate 0.0010
[2019-03-26 19:19:22,524] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 88048: loss 0.0531
[2019-03-26 19:19:22,527] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 88048: learning rate 0.0010
[2019-03-26 19:19:22,565] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 88062: loss 0.0256
[2019-03-26 19:19:22,568] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 88063: learning rate 0.0010
[2019-03-26 19:19:22,720] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 88137: loss 0.0128
[2019-03-26 19:19:22,722] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 88137: learning rate 0.0010
[2019-03-26 19:19:23,112] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 88311: loss 0.0057
[2019-03-26 19:19:23,113] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 88312: learning rate 0.0010
[2019-03-26 19:19:23,179] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 88336: loss 0.0527
[2019-03-26 19:19:23,182] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 88336: learning rate 0.0010
[2019-03-26 19:19:23,904] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6477718e-15 1.0000000e+00 1.3540954e-25 1.2479649e-18 2.5870119e-24], sum to 1.0000
[2019-03-26 19:19:23,914] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9625
[2019-03-26 19:19:23,919] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 73.33333333333334, 1.0, 2.0, 0.4878208114317547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 681648.3319470783, 681648.331947079, 181710.0035530568], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3312600.0000, 
sim time next is 3313200.0000, 
raw observation next is [28.33333333333334, 72.66666666666667, 1.0, 2.0, 0.4904327901074785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 685299.3143714768, 685299.3143714775, 182110.7996345521], 
processed observation next is [0.0, 0.34782608695652173, 0.5418641390205374, 0.7266666666666667, 1.0, 1.0, 0.38606360253913075, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19036092065874355, 0.19036092065874374, 0.27180716363365987], 
reward next is 0.7282, 
noisyNet noise sample is [array([2.1274915], dtype=float32), 1.2347459]. 
=============================================
[2019-03-26 19:19:27,838] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.1432233e-14 1.0000000e+00 2.9021543e-21 8.1604155e-18 6.3463544e-24], sum to 1.0000
[2019-03-26 19:19:27,848] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5378
[2019-03-26 19:19:27,853] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.7724873724178252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1079624.607801491, 1079624.607801491, 237268.8230786504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3385800.0000, 
sim time next is 3386400.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.7506801962894162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1049131.948596385, 1049131.948596384, 232164.0864793828], 
processed observation next is [1.0, 0.17391304347826086, 0.4312796208530806, 0.94, 1.0, 1.0, 0.6996146943245978, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2914255412767736, 0.2914255412767733, 0.34651356190952654], 
reward next is 0.6535, 
noisyNet noise sample is [array([1.5670362], dtype=float32), -0.0075722183]. 
=============================================
[2019-03-26 19:19:39,674] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 95776: loss 1.8285
[2019-03-26 19:19:39,675] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 95776: learning rate 0.0010
[2019-03-26 19:19:39,817] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 95840: loss 2.5466
[2019-03-26 19:19:39,821] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 95842: learning rate 0.0010
[2019-03-26 19:19:39,948] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 95898: loss 0.0488
[2019-03-26 19:19:39,953] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 95899: learning rate 0.0010
[2019-03-26 19:19:39,955] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 95902: loss 1.4190
[2019-03-26 19:19:39,958] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 95903: learning rate 0.0010
[2019-03-26 19:19:39,973] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 95910: loss 0.0186
[2019-03-26 19:19:39,976] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 95910: learning rate 0.0010
[2019-03-26 19:19:40,057] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 95942: loss 0.4963
[2019-03-26 19:19:40,060] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 95942: learning rate 0.0010
[2019-03-26 19:19:40,075] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 95951: loss 0.0181
[2019-03-26 19:19:40,077] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 95953: learning rate 0.0010
[2019-03-26 19:19:40,082] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 95955: loss 0.4606
[2019-03-26 19:19:40,087] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 95956: learning rate 0.0010
[2019-03-26 19:19:40,099] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 95963: loss 0.0124
[2019-03-26 19:19:40,102] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 95963: learning rate 0.0010
[2019-03-26 19:19:40,124] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 95976: loss 0.0199
[2019-03-26 19:19:40,125] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 95976: learning rate 0.0010
[2019-03-26 19:19:40,172] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 95997: loss 0.0239
[2019-03-26 19:19:40,174] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 95997: learning rate 0.0010
[2019-03-26 19:19:40,179] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 95999: loss 0.0207
[2019-03-26 19:19:40,180] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 95999: learning rate 0.0010
[2019-03-26 19:19:40,279] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 96042: loss 0.1673
[2019-03-26 19:19:40,283] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 96043: learning rate 0.0010
[2019-03-26 19:19:40,394] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 96094: loss 0.0084
[2019-03-26 19:19:40,397] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 96094: learning rate 0.0010
[2019-03-26 19:19:40,677] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 96222: loss 0.0163
[2019-03-26 19:19:40,679] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 96222: learning rate 0.0010
[2019-03-26 19:19:40,910] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 96327: loss 0.1289
[2019-03-26 19:19:40,911] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 96327: learning rate 0.0010
[2019-03-26 19:19:41,482] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.8831175e-16 1.0000000e+00 8.4777390e-22 8.3490532e-12 5.1847567e-27], sum to 1.0000
[2019-03-26 19:19:41,490] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0200
[2019-03-26 19:19:41,496] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 78.16666666666667, 1.0, 2.0, 0.5243107355649014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 732654.5068667321, 732654.5068667321, 187492.39677599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3621000.0000, 
sim time next is 3621600.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5219144311735413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729304.8407424163, 729304.8407424163, 187100.5978990221], 
processed observation next is [1.0, 0.9565217391304348, 0.5260663507109005, 0.79, 1.0, 1.0, 0.42399329057053164, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20258467798400454, 0.20258467798400454, 0.27925462372988374], 
reward next is 0.7207, 
noisyNet noise sample is [array([-0.8581563], dtype=float32), -0.43993786]. 
=============================================
[2019-03-26 19:19:43,951] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.8019874e-15 1.0000000e+00 3.6268247e-21 2.7053086e-12 1.2667084e-26], sum to 1.0000
[2019-03-26 19:19:43,958] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4287
[2019-03-26 19:19:43,963] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 80.66666666666667, 1.0, 2.0, 0.6136135355518414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 857493.6615310544, 857493.6615310544, 203300.2973600092], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3649200.0000, 
sim time next is 3649800.0000, 
raw observation next is [26.83333333333333, 79.83333333333334, 1.0, 2.0, 0.6202235523851146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 866734.5923844696, 866734.5923844696, 204564.513677921], 
processed observation next is [1.0, 0.21739130434782608, 0.470774091627172, 0.7983333333333335, 1.0, 1.0, 0.5424380149218249, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.240759608995686, 0.240759608995686, 0.3053201696685388], 
reward next is 0.6947, 
noisyNet noise sample is [array([0.75408506], dtype=float32), 1.07006]. 
=============================================
[2019-03-26 19:19:45,976] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7807927e-13 3.4448978e-02 2.4624507e-17 9.6555102e-01 2.5254668e-24], sum to 1.0000
[2019-03-26 19:19:45,983] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6520
[2019-03-26 19:19:45,991] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 76.5, 1.0, 2.0, 0.5413980553911583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 756540.2662723038, 756540.2662723038, 190336.320302138], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3699000.0000, 
sim time next is 3699600.0000, 
raw observation next is [29.0, 75.66666666666666, 1.0, 2.0, 0.2684032224934635, 1.0, 1.0, 0.2684032224934635, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 750119.210353317, 750119.210353317, 244064.748108392], 
processed observation next is [1.0, 0.8260869565217391, 0.5734597156398105, 0.7566666666666666, 1.0, 1.0, 0.11855809938971504, 1.0, 0.5, 0.11855809938971504, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.20836644732036583, 0.20836644732036583, 0.3642757434453612], 
reward next is 0.6357, 
noisyNet noise sample is [array([0.92087805], dtype=float32), -0.40759072]. 
=============================================
[2019-03-26 19:19:49,057] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-26 19:19:49,059] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:19:49,060] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:19:49,061] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:19:49,062] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:19:49,063] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:19:49,064] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:19:49,065] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:19:49,064] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:19:49,068] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:19:49,071] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:19:49,082] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run5
[2019-03-26 19:19:49,101] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run5
[2019-03-26 19:19:49,102] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run5
[2019-03-26 19:19:49,137] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run5
[2019-03-26 19:19:49,157] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run5
[2019-03-26 19:20:10,727] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.18126081], dtype=float32), -0.5392285]
[2019-03-26 19:20:10,728] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.31666666666667, 72.33333333333333, 1.0, 2.0, 0.2749089355963183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 447565.1987122355, 447565.1987122361, 163388.4925926762]
[2019-03-26 19:20:10,729] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:20:10,735] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.1140156e-15 1.0000000e+00 7.1282265e-21 6.6051100e-16 1.2018463e-26], sampled 0.039725511472409436
[2019-03-26 19:20:44,508] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.18126081], dtype=float32), -0.5392285]
[2019-03-26 19:20:44,508] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.73333333333333, 69.66666666666667, 1.0, 2.0, 0.533771340681171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 745879.0854389833, 745879.0854389827, 189055.8117113524]
[2019-03-26 19:20:44,509] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:20:44,512] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.8591562e-15 1.0000000e+00 3.4409437e-20 1.3743931e-15 6.9491793e-26], sampled 0.7240565646422127
[2019-03-26 19:21:42,613] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 19:21:42,622] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9262 3163995690.6303 1778.0000
[2019-03-26 19:21:42,868] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 19:21:42,870] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0142 3007608811.4011 1766.0000
[2019-03-26 19:21:43,003] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.2912 2927339788.0998 1338.0000
[2019-03-26 19:21:44,018] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 100000, evaluation results [100000.0, 7884.926202492573, 3163995690.6303034, 1778.0, 8254.291174362113, 2927339788.099768, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7999.014205657292, 3007608811.4011106, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 19:21:45,273] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.9481512e-11 3.4315315e-06 1.2978714e-11 9.9999654e-01 2.0966427e-12], sum to 1.0000
[2019-03-26 19:21:45,285] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1234
[2019-03-26 19:21:45,292] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.83333333333334, 60.5, 1.0, 2.0, 0.8986699690531377, 1.0, 2.0, 0.8986699690531377, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2513570.82393344, 2513570.82393344, 470772.5481577385], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3769800.0000, 
sim time next is 3770400.0000, 
raw observation next is [33.66666666666667, 61.00000000000001, 1.0, 2.0, 0.9770631991962063, 1.0, 2.0, 0.9770631991962063, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2733075.720311314, 2733075.720311314, 515282.4154681229], 
processed observation next is [1.0, 0.6521739130434783, 0.7946287519747238, 0.6100000000000001, 1.0, 1.0, 0.9723653002363931, 1.0, 1.0, 0.9723653002363931, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7591877000864761, 0.7591877000864761, 0.7690782320419746], 
reward next is 0.2309, 
noisyNet noise sample is [array([-1.5944349], dtype=float32), 0.598402]. 
=============================================
[2019-03-26 19:21:52,453] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 103810: loss 0.0066
[2019-03-26 19:21:52,457] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 103811: learning rate 0.0010
[2019-03-26 19:21:52,655] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 103899: loss 0.0259
[2019-03-26 19:21:52,659] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 103900: learning rate 0.0010
[2019-03-26 19:21:52,662] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 103900: loss 0.0174
[2019-03-26 19:21:52,665] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 103901: learning rate 0.0010
[2019-03-26 19:21:52,686] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 103913: loss 0.0314
[2019-03-26 19:21:52,688] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 103914: learning rate 0.0010
[2019-03-26 19:21:52,700] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 103918: loss 0.0036
[2019-03-26 19:21:52,702] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 103918: learning rate 0.0010
[2019-03-26 19:21:52,708] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 103921: loss 0.0026
[2019-03-26 19:21:52,712] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 103921: learning rate 0.0010
[2019-03-26 19:21:52,722] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 103926: loss 0.0142
[2019-03-26 19:21:52,725] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 103927: learning rate 0.0010
[2019-03-26 19:21:52,741] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 103935: loss 0.0154
[2019-03-26 19:21:52,743] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 103935: learning rate 0.0010
[2019-03-26 19:21:52,756] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 103940: loss 0.0584
[2019-03-26 19:21:52,757] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 103940: learning rate 0.0010
[2019-03-26 19:21:52,807] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 103965: loss 0.0292
[2019-03-26 19:21:52,809] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 103965: learning rate 0.0010
[2019-03-26 19:21:52,866] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 103991: loss 0.0620
[2019-03-26 19:21:52,870] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 103993: learning rate 0.0010
[2019-03-26 19:21:53,017] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 104059: loss 0.0021
[2019-03-26 19:21:53,021] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 104059: learning rate 0.0010
[2019-03-26 19:21:53,032] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 104065: loss 0.0046
[2019-03-26 19:21:53,034] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 104066: learning rate 0.0010
[2019-03-26 19:21:53,078] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 104086: loss 0.0376
[2019-03-26 19:21:53,079] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 104086: learning rate 0.0010
[2019-03-26 19:21:53,319] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 104194: loss 0.0735
[2019-03-26 19:21:53,320] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 104194: learning rate 0.0010
[2019-03-26 19:21:53,537] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 104290: loss 0.0052
[2019-03-26 19:21:53,539] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 104290: learning rate 0.0010
[2019-03-26 19:21:53,969] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0783229e-13 1.0000000e+00 1.3838064e-20 1.1772464e-10 4.9343674e-25], sum to 1.0000
[2019-03-26 19:21:53,978] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8588
[2019-03-26 19:21:53,986] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666667, 76.33333333333334, 1.0, 2.0, 0.596136839469091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 833061.2910813255, 833061.2910813255, 200028.4995750689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3918000.0000, 
sim time next is 3918600.0000, 
raw observation next is [31.0, 75.0, 1.0, 2.0, 0.598966487685373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 837017.0929512661, 837017.0929512654, 200553.6879196656], 
processed observation next is [0.0, 0.34782608695652173, 0.6682464454976303, 0.75, 1.0, 1.0, 0.5168270935968349, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23250474804201837, 0.23250474804201818, 0.29933386256666505], 
reward next is 0.7007, 
noisyNet noise sample is [array([-0.16036104], dtype=float32), -0.57872736]. 
=============================================
[2019-03-26 19:21:57,306] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.9787401e-17 1.0000000e+00 4.1495622e-25 4.5386863e-16 4.5163569e-30], sum to 1.0000
[2019-03-26 19:21:57,314] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9505
[2019-03-26 19:21:57,317] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.5909416752724208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 825798.5749622694, 825798.5749622694, 199069.8323283244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3978600.0000, 
sim time next is 3979200.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.5900555595911859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 824559.8112500493, 824559.8112500499, 198907.3005377516], 
processed observation next is [1.0, 0.043478260869565216, 0.5734597156398105, 0.84, 1.0, 1.0, 0.5060910356520313, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2290443920139026, 0.22904439201390273, 0.29687656796679346], 
reward next is 0.7031, 
noisyNet noise sample is [array([0.25366217], dtype=float32), 0.28896296]. 
=============================================
[2019-03-26 19:21:58,319] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.1107899e-11 1.0000000e+00 3.1146018e-14 1.3469113e-10 1.9967791e-16], sum to 1.0000
[2019-03-26 19:21:58,326] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0483
[2019-03-26 19:21:58,335] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1706452.88074072 W.
[2019-03-26 19:21:58,338] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.4068805114629439, 1.0, 1.0, 0.4068805114629439, 1.0, 2.0, 0.7066168909698345, 6.9112, 6.9112, 170.5573041426782, 1706452.88074072, 1706452.88074072, 356730.5058650076], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3991800.0000, 
sim time next is 3992400.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.3925149674050764, 1.0, 2.0, 0.3925149674050764, 1.0, 2.0, 0.6816686916993343, 6.9112, 6.9112, 170.5573041426782, 1646157.65504171, 1646157.65504171, 348784.2075296319], 
processed observation next is [1.0, 0.21739130434782608, 0.5734597156398105, 0.84, 1.0, 1.0, 0.26809032217479084, 1.0, 1.0, 0.26809032217479084, 1.0, 1.0, 0.6117910874382124, 0.0, 0.0, 0.8375144448122397, 0.4572660152893639, 0.4572660152893639, 0.5205734440740775], 
reward next is 0.4794, 
noisyNet noise sample is [array([-1.4271414], dtype=float32), 0.50300884]. 
=============================================
[2019-03-26 19:21:58,375] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4899733e-14 1.0000000e+00 1.4005838e-19 2.2610854e-16 5.1179890e-25], sum to 1.0000
[2019-03-26 19:21:58,385] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1191
[2019-03-26 19:21:58,388] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.9114081067797528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1273896.022769302, 1273896.022769301, 273098.4465384181], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3994800.0000, 
sim time next is 3995400.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.9021881975391663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1261001.491076004, 1261001.491076004, 270543.7144273416], 
processed observation next is [1.0, 0.21739130434782608, 0.5734597156398105, 0.84, 1.0, 1.0, 0.8821544548664655, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.35027819196555665, 0.35027819196555665, 0.40379658869752477], 
reward next is 0.5962, 
noisyNet noise sample is [array([2.162536], dtype=float32), -0.10209968]. 
=============================================
[2019-03-26 19:22:04,326] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2445828e-15 9.9997401e-01 2.1232916e-17 2.5967778e-05 7.9932767e-26], sum to 1.0000
[2019-03-26 19:22:04,333] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9007
[2019-03-26 19:22:04,348] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2535776.863792947 W.
[2019-03-26 19:22:04,353] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.5, 79.0, 1.0, 2.0, 0.6044007897231782, 1.0, 2.0, 0.6044007897231782, 1.0, 1.0, 1.03, 6.933283323222656, 6.9112, 170.5573041426782, 2535776.863792947, 2519957.681076403, 489580.4100236094], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4095000.0000, 
sim time next is 4095600.0000, 
raw observation next is [30.66666666666666, 79.0, 1.0, 2.0, 0.659358014452563, 1.0, 2.0, 0.6502690467405441, 1.0, 2.0, 1.03, 7.005094527792086, 6.9112, 170.5573041426782, 2728428.277714526, 2661167.808071861, 508799.3940679212], 
processed observation next is [1.0, 0.391304347826087, 0.6524486571879934, 0.79, 1.0, 1.0, 0.5895879692199555, 1.0, 1.0, 0.5786374057114989, 1.0, 1.0, 1.0365853658536586, 0.009389452779208617, 0.0, 0.8375144448122397, 0.7578967438095905, 0.7392132800199614, 0.7594020806983899], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8290498], dtype=float32), -1.7106256]. 
=============================================
[2019-03-26 19:22:10,420] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 111867: loss -143.2179
[2019-03-26 19:22:10,422] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 111867: learning rate 0.0010
[2019-03-26 19:22:10,520] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 111910: loss -135.1826
[2019-03-26 19:22:10,523] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 111912: learning rate 0.0010
[2019-03-26 19:22:10,548] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 111924: loss -150.1043
[2019-03-26 19:22:10,549] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 111924: learning rate 0.0010
[2019-03-26 19:22:10,553] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 111925: loss -159.2719
[2019-03-26 19:22:10,555] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 111925: learning rate 0.0010
[2019-03-26 19:22:10,567] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 111931: loss -107.5540
[2019-03-26 19:22:10,569] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 111931: learning rate 0.0010
[2019-03-26 19:22:10,601] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 111946: loss -87.1565
[2019-03-26 19:22:10,604] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 111946: learning rate 0.0010
[2019-03-26 19:22:10,639] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 111960: loss -64.3757
[2019-03-26 19:22:10,643] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 111961: learning rate 0.0010
[2019-03-26 19:22:10,659] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 111970: loss -177.0599
[2019-03-26 19:22:10,661] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 111970: learning rate 0.0010
[2019-03-26 19:22:10,673] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 111973: loss -177.4924
[2019-03-26 19:22:10,674] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 111973: learning rate 0.0010
[2019-03-26 19:22:10,694] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 111984: loss -124.1172
[2019-03-26 19:22:10,697] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 111984: learning rate 0.0010
[2019-03-26 19:22:10,727] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 112000: loss -160.1354
[2019-03-26 19:22:10,729] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 112000: learning rate 0.0010
[2019-03-26 19:22:10,776] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 112021: loss -103.0322
[2019-03-26 19:22:10,779] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 112022: learning rate 0.0010
[2019-03-26 19:22:10,782] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 112023: loss -106.4695
[2019-03-26 19:22:10,784] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 112023: learning rate 0.0010
[2019-03-26 19:22:10,814] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 112034: loss -145.8741
[2019-03-26 19:22:10,816] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 112034: learning rate 0.0010
[2019-03-26 19:22:10,985] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 112113: loss -121.2027
[2019-03-26 19:22:10,987] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 112114: learning rate 0.0010
[2019-03-26 19:22:11,184] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 112201: loss -90.3904
[2019-03-26 19:22:11,186] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 112201: learning rate 0.0010
[2019-03-26 19:22:12,441] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.6591917e-21 1.0000000e+00 6.9782938e-26 2.2018318e-11 4.3036104e-36], sum to 1.0000
[2019-03-26 19:22:12,449] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8991
[2019-03-26 19:22:12,456] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666667, 74.33333333333333, 1.0, 2.0, 0.5988962928921273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 836918.9616015643, 836918.9616015643, 200540.7644253055], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4229400.0000, 
sim time next is 4230000.0000, 
raw observation next is [31.0, 75.0, 1.0, 2.0, 0.5977174704536253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 835270.9854980216, 835270.9854980216, 200321.6919845118], 
processed observation next is [1.0, 1.0, 0.6682464454976303, 0.75, 1.0, 1.0, 0.5153222535585847, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23201971819389489, 0.23201971819389489, 0.2989875999768833], 
reward next is 0.7010, 
noisyNet noise sample is [array([-0.10147031], dtype=float32), -0.4007391]. 
=============================================
[2019-03-26 19:22:12,476] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[62.769222]
 [62.94407 ]
 [63.162235]
 [63.31164 ]
 [63.537136]], R is [[62.72632599]
 [62.79974747]
 [62.87202454]
 [62.94306183]
 [63.01285553]].
[2019-03-26 19:22:20,150] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.6369159e-07 1.4562926e-02 2.3962792e-07 9.8543614e-01 5.1351395e-11], sum to 1.0000
[2019-03-26 19:22:20,158] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2794
[2019-03-26 19:22:20,165] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 3 has been changed to 4 for the demand 3367835.047087727 W.
[2019-03-26 19:22:20,170] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.83333333333334, 71.66666666666667, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.550521283657646, 6.9112, 170.5573041426782, 3367835.047087727, 2909863.205676652, 550147.9579150773], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4355400.0000, 
sim time next is 4356000.0000, 
raw observation next is [34.0, 71.0, 1.0, 2.0, 1.033690623181432, 1.0, 2.0, 0.8374353511049786, 1.0, 1.0, 1.03, 7.005124058115024, 6.9112, 170.5573041426782, 3514854.215605319, 3447572.592191116, 647477.6768283382], 
processed observation next is [1.0, 0.43478260869565216, 0.8104265402843602, 0.71, 1.0, 1.0, 1.0405911122667855, 1.0, 1.0, 0.8041389772349139, 1.0, 0.5, 1.0365853658536586, 0.009392405811502424, 0.0, 0.8375144448122397, 0.9763483932236997, 0.9576590533864211, 0.9663845922811017], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.51136655], dtype=float32), 0.79201293]. 
=============================================
[2019-03-26 19:22:20,185] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[13.054336]
 [12.957072]
 [12.579801]
 [12.143346]
 [11.784018]], R is [[12.34060478]
 [12.21719933]
 [12.09502792]
 [12.1901722 ]
 [12.06827068]].
[2019-03-26 19:22:20,596] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.1374699e-03 9.6835572e-01 7.9696171e-04 2.3541301e-02 1.6850277e-04], sum to 1.0000
[2019-03-26 19:22:20,604] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5711
[2019-03-26 19:22:20,611] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2645741.053771333 W.
[2019-03-26 19:22:20,618] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [37.0, 54.0, 1.0, 2.0, 0.6305829626618417, 1.0, 2.0, 0.6305829626618417, 1.0, 2.0, 1.03, 6.984401831363543, 6.9112, 170.5573041426782, 2645741.053771333, 2593303.604305508, 499336.0598252359], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4365600.0000, 
sim time next is 4366200.0000, 
raw observation next is [37.0, 54.0, 1.0, 2.0, 0.9501606933856225, 1.0, 2.0, 0.9501606933856225, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2657743.035680955, 2657743.035680955, 499611.4081809989], 
processed observation next is [1.0, 0.5217391304347826, 0.95260663507109, 0.54, 1.0, 1.0, 0.93995264263328, 1.0, 1.0, 0.93995264263328, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7382619543558208, 0.7382619543558208, 0.745688668926864], 
reward next is 0.2543, 
noisyNet noise sample is [array([-0.06635771], dtype=float32), 0.70992893]. 
=============================================
[2019-03-26 19:22:28,185] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 119865: loss 0.1736
[2019-03-26 19:22:28,187] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 119865: learning rate 0.0010
[2019-03-26 19:22:28,198] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 119871: loss 0.1751
[2019-03-26 19:22:28,203] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 119873: learning rate 0.0010
[2019-03-26 19:22:28,270] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 119902: loss 0.0999
[2019-03-26 19:22:28,273] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 119902: learning rate 0.0010
[2019-03-26 19:22:28,299] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 119917: loss 0.0150
[2019-03-26 19:22:28,305] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 119917: learning rate 0.0010
[2019-03-26 19:22:28,320] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 119928: loss 0.0346
[2019-03-26 19:22:28,322] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 119929: learning rate 0.0010
[2019-03-26 19:22:28,334] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 119933: loss 0.0698
[2019-03-26 19:22:28,339] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 119934: learning rate 0.0010
[2019-03-26 19:22:28,340] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 119934: loss 0.0478
[2019-03-26 19:22:28,343] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 119934: learning rate 0.0010
[2019-03-26 19:22:28,475] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 119996: loss 0.0567
[2019-03-26 19:22:28,478] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 119996: learning rate 0.0010
[2019-03-26 19:22:28,485] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 120000: loss 0.0216
[2019-03-26 19:22:28,486] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 120000: learning rate 0.0010
[2019-03-26 19:22:28,501] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 120006: loss 0.0346
[2019-03-26 19:22:28,510] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 120011: learning rate 0.0010
[2019-03-26 19:22:28,542] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 120023: loss 0.1551
[2019-03-26 19:22:28,544] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 120023: learning rate 0.0010
[2019-03-26 19:22:28,584] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 120040: loss 0.1507
[2019-03-26 19:22:28,590] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 120043: learning rate 0.0010
[2019-03-26 19:22:28,601] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 120049: loss 0.2974
[2019-03-26 19:22:28,602] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 120049: learning rate 0.0010
[2019-03-26 19:22:28,678] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 120085: loss 0.0256
[2019-03-26 19:22:28,680] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 120086: learning rate 0.0010
[2019-03-26 19:22:28,694] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 120092: loss 0.0032
[2019-03-26 19:22:28,697] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 120092: learning rate 0.0010
[2019-03-26 19:22:28,795] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 120134: loss 0.0063
[2019-03-26 19:22:28,797] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 120136: learning rate 0.0010
[2019-03-26 19:22:32,121] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.6862145e-30 9.9997711e-01 6.6939690e-30 2.2899865e-05 1.8397590e-37], sum to 1.0000
[2019-03-26 19:22:32,129] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8174
[2019-03-26 19:22:32,133] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.16666666666667, 73.33333333333334, 1.0, 2.0, 0.5285019838757005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738513.2547740127, 738513.2547740127, 188182.1144252415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4560600.0000, 
sim time next is 4561200.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.5273121755060175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 736850.0746077342, 736850.0746077342, 187985.7987345446], 
processed observation next is [0.0, 0.8260869565217391, 0.5734597156398105, 0.74, 1.0, 1.0, 0.43049659699520176, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20468057627992617, 0.20468057627992617, 0.28057581900678297], 
reward next is 0.7194, 
noisyNet noise sample is [array([-1.2672473], dtype=float32), -0.43795896]. 
=============================================
[2019-03-26 19:22:39,544] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 19:22:39,549] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:22:39,550] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:22:39,550] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:22:39,551] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:22:39,553] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:22:39,554] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:22:39,554] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:22:39,558] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:22:39,559] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:22:39,559] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:22:39,577] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run6
[2019-03-26 19:22:39,578] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run6
[2019-03-26 19:22:39,595] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run6
[2019-03-26 19:22:39,636] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run6
[2019-03-26 19:22:39,637] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run6
[2019-03-26 19:22:44,423] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56736976]
[2019-03-26 19:22:44,424] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [18.88138579, 97.55397287000001, 1.0, 2.0, 0.2730984842536156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 445400.8605887628, 445400.8605887628, 163224.3072725939]
[2019-03-26 19:22:44,425] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:22:44,427] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.4091482e-21 1.0000000e+00 1.3996629e-22 1.7012504e-13 1.3622406e-24], sampled 0.5613292146235208
[2019-03-26 19:22:51,596] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56736976]
[2019-03-26 19:22:51,598] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.2, 82.0, 1.0, 2.0, 0.4312494919988522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 630161.650939557, 630161.650939557, 177047.4515845739]
[2019-03-26 19:22:51,601] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:22:51,604] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1436286e-20 1.0000000e+00 8.6196905e-22 1.4353214e-12 1.1763385e-23], sampled 0.9702421201446121
[2019-03-26 19:23:13,063] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56736976]
[2019-03-26 19:23:13,064] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [33.76513844666667, 67.01846169833334, 1.0, 2.0, 0.8330994700017748, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005983595589171, 6.9112, 168.912315985339, 2061398.414632088, 1994155.924708872, 416200.8662000271]
[2019-03-26 19:23:13,065] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:23:13,067] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.1278377e-16 9.9945742e-01 8.2203399e-16 5.4255279e-04 2.4757942e-16], sampled 0.8663908091624895
[2019-03-26 19:23:13,068] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2061398.414632088 W.
[2019-03-26 19:23:16,799] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56736976]
[2019-03-26 19:23:16,799] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.8, 92.5, 1.0, 2.0, 0.4289859438025845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 625845.1367824614, 625845.1367824607, 176599.1175567735]
[2019-03-26 19:23:16,804] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:23:16,810] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.6808503e-20 1.0000000e+00 2.6180202e-21 1.2359304e-12 3.4922064e-23], sampled 0.11047775330849696
[2019-03-26 19:23:18,222] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56736976]
[2019-03-26 19:23:18,223] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.03333333333333, 83.66666666666666, 1.0, 2.0, 0.492803915151457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 688613.6462699765, 688613.6462699765, 182475.02472677]
[2019-03-26 19:23:18,223] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:23:18,225] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.3038365e-21 1.0000000e+00 2.9476190e-22 3.5258042e-12 4.6277787e-24], sampled 0.20424379560203554
[2019-03-26 19:23:31,944] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56736976]
[2019-03-26 19:23:31,945] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.90000000000001, 51.66666666666667, 1.0, 2.0, 0.7008030845475833, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.00276239083709, 6.9112, 168.9123371229272, 1876252.596380222, 1811295.323179027, 384942.1310306253]
[2019-03-26 19:23:31,947] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:23:31,950] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.4276588e-16 9.9975365e-01 2.8850350e-16 2.4637682e-04 7.6596733e-17], sampled 0.9255962200316817
[2019-03-26 19:23:31,953] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1876252.596380222 W.
[2019-03-26 19:23:41,947] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56736976]
[2019-03-26 19:23:41,948] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.76666666666667, 59.66666666666666, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.950475185128887, 6.9112, 168.9125401415302, 1481637.108744108, 1453774.009348582, 311354.5496980809]
[2019-03-26 19:23:41,949] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:23:41,952] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.8191287e-16 1.0000000e+00 3.3493999e-17 5.4953508e-09 1.6727158e-18], sampled 0.8140229599634363
[2019-03-26 19:23:42,000] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56736976]
[2019-03-26 19:23:42,002] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.16666666666667, 59.83333333333333, 1.0, 2.0, 0.6964648996900635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 973327.2769809135, 973327.2769809135, 220089.3975259496]
[2019-03-26 19:23:42,003] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:23:42,005] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.4718729e-22 9.9999928e-01 3.6927705e-22 7.7416303e-07 3.9295522e-23], sampled 0.9375859953570975
[2019-03-26 19:24:03,612] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56736976]
[2019-03-26 19:24:03,615] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.85773461, 78.346958255, 1.0, 2.0, 0.6319018931204741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 883061.3341917244, 883061.3341917244, 206841.6793527208]
[2019-03-26 19:24:03,616] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:24:03,619] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.3210621e-21 9.9996841e-01 7.9916665e-21 3.1537889e-05 1.5220628e-21], sampled 0.8980433615583524
[2019-03-26 19:24:06,380] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56736976]
[2019-03-26 19:24:06,382] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.94584753, 88.74904985, 1.0, 2.0, 0.9552080451606435, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9129565018987, 1335154.697097743, 1335154.697097744, 285570.4286452624]
[2019-03-26 19:24:06,384] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:24:06,389] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.57343598e-20 9.93136287e-01 2.58288083e-20 6.86370302e-03
 1.08908926e-20], sampled 0.1320450031356386
[2019-03-26 19:24:08,350] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56736976]
[2019-03-26 19:24:08,351] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.488189655, 84.766089535, 1.0, 2.0, 0.5122564076404725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 715804.5117416723, 715804.5117416716, 185537.6479441572]
[2019-03-26 19:24:08,352] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:24:08,353] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.8241658e-20 1.0000000e+00 4.7295675e-21 5.6991904e-11 1.1496855e-22], sampled 0.9242376240437791
[2019-03-26 19:24:25,936] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56736976]
[2019-03-26 19:24:25,937] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.13333333333333, 82.33333333333334, 1.0, 2.0, 0.8900136466947111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1243974.97643733, 1243974.976437329, 267208.5251794899]
[2019-03-26 19:24:25,937] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:24:25,941] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.2349309e-19 1.0000000e+00 1.1783351e-19 3.0184305e-10 3.7249050e-21], sampled 0.34893712996362447
[2019-03-26 19:24:32,486] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56736976]
[2019-03-26 19:24:32,488] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.06666666666667, 74.66666666666667, 1.0, 2.0, 0.739970497434048, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.984023818104038, 6.9112, 168.912464191928, 1931063.142546823, 1879399.570161988, 394354.2892235941]
[2019-03-26 19:24:32,491] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:24:32,495] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.1863457e-18 9.9945503e-01 6.2974931e-18 5.4491032e-04 1.8933333e-18], sampled 0.8786274733714496
[2019-03-26 19:24:32,496] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1931063.142546823 W.
[2019-03-26 19:24:33,234] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8001.4692 3155919684.0055 1397.0000
[2019-03-26 19:24:33,652] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8668.8663 2778007932.4087 894.0000
[2019-03-26 19:24:33,822] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8540.4632 2837189531.7748 976.0000
[2019-03-26 19:24:33,851] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8317.6320 2921326684.6099 1151.0000
[2019-03-26 19:24:33,942] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8111.3647 2994935184.3581 1400.0000
[2019-03-26 19:24:34,958] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 125000, evaluation results [125000.0, 8001.469154466778, 3155919684.005519, 1397.0, 8317.632045022483, 2921326684.609876, 1151.0, 8668.866328672348, 2778007932.408708, 894.0, 8111.364749496653, 2994935184.358118, 1400.0, 8540.463224235242, 2837189531.77485, 976.0]
[2019-03-26 19:24:41,285] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 127858: loss 4.7942
[2019-03-26 19:24:41,290] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 127859: learning rate 0.0010
[2019-03-26 19:24:41,307] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 127867: loss 4.7879
[2019-03-26 19:24:41,309] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 127868: learning rate 0.0010
[2019-03-26 19:24:41,440] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 127929: loss 4.5747
[2019-03-26 19:24:41,441] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 127929: learning rate 0.0010
[2019-03-26 19:24:41,453] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 127934: loss 2.9437
[2019-03-26 19:24:41,455] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 127935: learning rate 0.0010
[2019-03-26 19:24:41,477] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 127942: loss 4.1365
[2019-03-26 19:24:41,480] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 127942: learning rate 0.0010
[2019-03-26 19:24:41,533] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 127969: loss 2.5297
[2019-03-26 19:24:41,542] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 127970: learning rate 0.0010
[2019-03-26 19:24:41,560] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 127980: loss 2.3876
[2019-03-26 19:24:41,562] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 127980: loss 4.0342
[2019-03-26 19:24:41,562] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 127980: learning rate 0.0010
[2019-03-26 19:24:41,566] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 127981: loss 3.4165
[2019-03-26 19:24:41,569] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 127981: learning rate 0.0010
[2019-03-26 19:24:41,570] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 127981: learning rate 0.0010
[2019-03-26 19:24:41,591] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 127994: loss 2.3143
[2019-03-26 19:24:41,592] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 127994: learning rate 0.0010
[2019-03-26 19:24:41,682] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 128031: loss 1.5629
[2019-03-26 19:24:41,686] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 128032: learning rate 0.0010
[2019-03-26 19:24:41,688] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 128035: loss 2.4996
[2019-03-26 19:24:41,695] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 128036: learning rate 0.0010
[2019-03-26 19:24:41,722] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 128049: loss 2.4156
[2019-03-26 19:24:41,724] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 128050: learning rate 0.0010
[2019-03-26 19:24:41,780] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 128075: loss 1.7769
[2019-03-26 19:24:41,783] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 128075: learning rate 0.0010
[2019-03-26 19:24:41,793] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 128082: loss 1.7287
[2019-03-26 19:24:41,794] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 128082: learning rate 0.0010
[2019-03-26 19:24:41,814] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 128088: loss 1.5830
[2019-03-26 19:24:41,816] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 128089: learning rate 0.0010
[2019-03-26 19:24:43,006] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.0652311e-28 2.8542391e-07 7.7946974e-30 9.9999976e-01 9.7185103e-30], sum to 1.0000
[2019-03-26 19:24:43,017] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2410
[2019-03-26 19:24:43,023] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.2472412284529573, 1.0, 2.0, 0.2472412284529573, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 690957.7327918367, 690957.7327918367, 240492.7642915406], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4827600.0000, 
sim time next is 4828200.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.2468717146924758, 1.0, 2.0, 0.2468717146924758, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 689924.731525478, 689924.731525478, 240432.8801944461], 
processed observation next is [1.0, 0.9130434782608695, 0.5260663507109005, 0.74, 1.0, 1.0, 0.09261652372587444, 1.0, 1.0, 0.09261652372587444, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.1916457587570772, 0.1916457587570772, 0.3588550450663375], 
reward next is 0.6411, 
noisyNet noise sample is [array([-1.5229441], dtype=float32), -0.7774435]. 
=============================================
[2019-03-26 19:24:48,415] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0809132e-24 6.0391653e-04 3.2001397e-24 9.9939609e-01 2.9612941e-24], sum to 1.0000
[2019-03-26 19:24:48,429] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0934
[2019-03-26 19:24:48,436] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 81.5, 1.0, 2.0, 0.2498322559555383, 1.0, 2.0, 0.2498322559555383, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 698201.1572695323, 698201.157269533, 240916.0390648369], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4915800.0000, 
sim time next is 4916400.0000, 
raw observation next is [27.0, 82.33333333333334, 1.0, 2.0, 0.2516560932861675, 1.0, 2.0, 0.2516560932861675, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 703299.8696362243, 703299.8696362243, 241216.3367878796], 
processed observation next is [1.0, 0.9130434782608695, 0.4786729857819906, 0.8233333333333335, 1.0, 1.0, 0.09838083528453916, 1.0, 1.0, 0.09838083528453916, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.19536107489895121, 0.19536107489895121, 0.36002438326549197], 
reward next is 0.6400, 
noisyNet noise sample is [array([0.9627204], dtype=float32), -0.9169819]. 
=============================================
[2019-03-26 19:24:48,931] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2682932e-25 1.4245522e-04 2.3174684e-23 9.9985754e-01 7.8278021e-28], sum to 1.0000
[2019-03-26 19:24:48,939] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7945
[2019-03-26 19:24:48,943] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.2547950332166585, 1.0, 2.0, 0.2547950332166585, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 712075.1343383405, 712075.1343383405, 241738.0504635476], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4924200.0000, 
sim time next is 4924800.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.2549214989229626, 1.0, 2.0, 0.2549214989229626, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 712428.6851534894, 712428.68515349, 241759.1253860083], 
processed observation next is [1.0, 0.0, 0.4786729857819906, 0.84, 1.0, 1.0, 0.10231505894332844, 1.0, 1.0, 0.10231505894332844, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.19789685698708037, 0.19789685698708057, 0.3608345155015049], 
reward next is 0.6392, 
noisyNet noise sample is [array([-0.47658265], dtype=float32), 0.21849285]. 
=============================================
[2019-03-26 19:24:49,918] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6703455e-16 1.0000000e+00 1.7410912e-15 6.5721137e-11 1.1456220e-16], sum to 1.0000
[2019-03-26 19:24:49,926] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9162
[2019-03-26 19:24:49,930] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.6151211958055472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 859601.392528048, 859601.392528048, 203588.7240195037], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4940400.0000, 
sim time next is 4941000.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.6053667032932727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 845964.5439142855, 845964.5439142855, 201742.5127341375], 
processed observation next is [1.0, 0.17391304347826086, 0.4312796208530806, 0.89, 1.0, 1.0, 0.5245381967388827, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23499015108730154, 0.23499015108730154, 0.30110822796139924], 
reward next is 0.6989, 
noisyNet noise sample is [array([0.3711675], dtype=float32), 0.13209395]. 
=============================================
[2019-03-26 19:24:49,949] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[35.887794]
 [36.131313]
 [36.339317]
 [36.59304 ]
 [36.873997]], R is [[36.05044174]
 [36.38607407]
 [36.70934296]
 [37.01757812]
 [37.32071304]].
[2019-03-26 19:24:53,059] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2164426e-37 1.4570443e-18 2.0769956e-38 1.0000000e+00 2.7101146e-36], sum to 1.0000
[2019-03-26 19:24:53,071] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3761
[2019-03-26 19:24:53,076] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.16666666666667, 73.33333333333334, 1.0, 2.0, 0.2586010186843372, 1.0, 2.0, 0.2586010186843372, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 722715.2972435225, 722715.2972435225, 242379.7073330061], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4992600.0000, 
sim time next is 4993200.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.258749322954503, 1.0, 2.0, 0.258749322954503, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 723129.9046400326, 723129.9046400319, 242404.3884696466], 
processed observation next is [1.0, 0.8260869565217391, 0.5734597156398105, 0.74, 1.0, 1.0, 0.1069268951259072, 1.0, 1.0, 0.1069268951259072, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.2008694179555646, 0.2008694179555644, 0.3617975947308158], 
reward next is 0.6382, 
noisyNet noise sample is [array([-2.0252662], dtype=float32), 0.115672775]. 
=============================================
[2019-03-26 19:24:59,127] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 135880: loss 1.0492
[2019-03-26 19:24:59,128] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 135880: learning rate 0.0010
[2019-03-26 19:24:59,154] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 135892: loss 0.9088
[2019-03-26 19:24:59,158] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 135893: learning rate 0.0010
[2019-03-26 19:24:59,248] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 135935: loss 1.5594
[2019-03-26 19:24:59,250] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 135935: learning rate 0.0010
[2019-03-26 19:24:59,259] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 135938: loss 1.9243
[2019-03-26 19:24:59,264] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 135941: learning rate 0.0010
[2019-03-26 19:24:59,281] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 135948: loss 1.7957
[2019-03-26 19:24:59,283] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 135949: learning rate 0.0010
[2019-03-26 19:24:59,293] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 135953: loss 2.2932
[2019-03-26 19:24:59,295] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 135953: learning rate 0.0010
[2019-03-26 19:24:59,366] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 135985: loss 2.1963
[2019-03-26 19:24:59,371] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 135986: learning rate 0.0010
[2019-03-26 19:24:59,371] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 135987: loss 1.4166
[2019-03-26 19:24:59,376] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 135988: learning rate 0.0010
[2019-03-26 19:24:59,391] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 135993: loss 1.9031
[2019-03-26 19:24:59,398] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 135994: learning rate 0.0010
[2019-03-26 19:24:59,413] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 136002: loss 1.4302
[2019-03-26 19:24:59,415] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 136002: learning rate 0.0010
[2019-03-26 19:24:59,441] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 136015: loss 1.5318
[2019-03-26 19:24:59,446] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 136017: learning rate 0.0010
[2019-03-26 19:24:59,469] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 136029: loss 1.0758
[2019-03-26 19:24:59,474] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 136030: learning rate 0.0010
[2019-03-26 19:24:59,501] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 136047: loss 0.6649
[2019-03-26 19:24:59,504] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 136048: learning rate 0.0010
[2019-03-26 19:24:59,528] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 136060: loss 0.4551
[2019-03-26 19:24:59,531] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 136061: learning rate 0.0010
[2019-03-26 19:24:59,531] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 136061: loss 0.5107
[2019-03-26 19:24:59,535] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 136061: learning rate 0.0010
[2019-03-26 19:24:59,580] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 136079: loss 0.1461
[2019-03-26 19:24:59,585] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 136080: learning rate 0.0010
[2019-03-26 19:25:00,235] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2242698e-27 1.0000000e+00 2.3640379e-29 5.7533356e-13 1.4995279e-32], sum to 1.0000
[2019-03-26 19:25:00,244] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1544
[2019-03-26 19:25:00,253] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4835689770511917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 675829.8095865631, 675829.8095865624, 181077.0919183193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5112000.0000, 
sim time next is 5112600.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4830505893968829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 675104.7403194243, 675104.740319425, 180998.4027749045], 
processed observation next is [0.0, 0.17391304347826086, 0.4312796208530806, 0.84, 1.0, 1.0, 0.3771693848155216, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18752909453317343, 0.18752909453317362, 0.2701468698132903], 
reward next is 0.7299, 
noisyNet noise sample is [array([-2.2427504], dtype=float32), 0.57606304]. 
=============================================
[2019-03-26 19:25:02,462] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3018497e-31 1.0000000e+00 3.3533213e-34 2.3137323e-14 1.6832069e-33], sum to 1.0000
[2019-03-26 19:25:02,474] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8584
[2019-03-26 19:25:02,482] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 63.00000000000001, 1.0, 2.0, 0.5525213899601028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 772089.4704744226, 772089.4704744231, 192234.4598290622], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5149200.0000, 
sim time next is 5149800.0000, 
raw observation next is [32.0, 63.0, 1.0, 2.0, 0.5509749634307706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 769927.7218306224, 769927.7218306231, 191968.559560129], 
processed observation next is [0.0, 0.6086956521739131, 0.7156398104265403, 0.63, 1.0, 1.0, 0.45900598003707294, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21386881161961735, 0.21386881161961754, 0.28652023814944627], 
reward next is 0.7135, 
noisyNet noise sample is [array([-0.09958028], dtype=float32), 2.5319612]. 
=============================================
[2019-03-26 19:25:02,903] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1040293e-38 1.0000000e+00 0.0000000e+00 4.1214982e-17 0.0000000e+00], sum to 1.0000
[2019-03-26 19:25:02,910] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2004
[2019-03-26 19:25:02,916] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.5427956296079233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 758493.9095505218, 758493.9095505225, 190572.9430491542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5160000.0000, 
sim time next is 5160600.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.5417049376440679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 756969.2510182518, 756969.2510182523, 190388.4717676915], 
processed observation next is [0.0, 0.7391304347826086, 0.6682464454976303, 0.66, 1.0, 1.0, 0.4478372742699613, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2102692363939588, 0.21026923639395897, 0.28416189816073356], 
reward next is 0.7158, 
noisyNet noise sample is [array([0.66688526], dtype=float32), 0.48132116]. 
=============================================
[2019-03-26 19:25:03,402] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0955299e-26 1.0000000e+00 1.1050282e-26 1.0980533e-10 6.3943048e-30], sum to 1.0000
[2019-03-26 19:25:03,410] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7069
[2019-03-26 19:25:03,415] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333333, 77.33333333333333, 1.0, 2.0, 0.5227833462935365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 730519.4496325778, 730519.4496325784, 187242.60886876], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5168400.0000, 
sim time next is 5169000.0000, 
raw observation next is [28.16666666666667, 78.16666666666667, 1.0, 2.0, 0.5220866714079402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 729545.6058289391, 729545.6058289384, 187128.7836591793], 
processed observation next is [0.0, 0.8260869565217391, 0.5339652448657191, 0.7816666666666667, 1.0, 1.0, 0.4242008089252291, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20265155717470532, 0.20265155717470512, 0.2792966920286258], 
reward next is 0.7207, 
noisyNet noise sample is [array([0.6606498], dtype=float32), 0.63422173]. 
=============================================
[2019-03-26 19:25:03,423] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[73.48299 ]
 [73.42867 ]
 [73.38329 ]
 [73.32673 ]
 [73.277954]], R is [[73.51229858]
 [73.49771118]
 [73.48310852]
 [73.46827698]
 [73.45207214]].
[2019-03-26 19:25:04,608] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0177920e-22 1.0000000e+00 2.6556640e-25 6.7675721e-10 7.5431974e-28], sum to 1.0000
[2019-03-26 19:25:04,614] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7663
[2019-03-26 19:25:04,619] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5163661980249745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 721549.3020272445, 721549.3020272438, 186199.6390236945], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5190000.0000, 
sim time next is 5190600.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5161590341472515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 721259.7213000394, 721259.7213000394, 186166.1952553471], 
processed observation next is [1.0, 0.043478260869565216, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4170590772858452, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20034992258334428, 0.20034992258334428, 0.2778599929184285], 
reward next is 0.7221, 
noisyNet noise sample is [array([1.2136033], dtype=float32), 0.26704907]. 
=============================================
[2019-03-26 19:25:04,833] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.9737432e-20 1.0000000e+00 2.0632157e-23 4.0040589e-14 9.4744239e-23], sum to 1.0000
[2019-03-26 19:25:04,840] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9664
[2019-03-26 19:25:04,845] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5156102579911713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 720492.6236715536, 720492.623671553, 186077.6642661265], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5188800.0000, 
sim time next is 5189400.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5159126785277046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 720915.3571234473, 720915.3571234473, 186126.441042029], 
processed observation next is [1.0, 0.043478260869565216, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4167622632863911, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20025426586762426, 0.20025426586762426, 0.2778006582716851], 
reward next is 0.7222, 
noisyNet noise sample is [array([2.0236895], dtype=float32), -0.9099606]. 
=============================================
[2019-03-26 19:25:07,194] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.3700499e-17 5.7099539e-01 9.3135309e-17 4.2900461e-01 1.2589754e-15], sum to 1.0000
[2019-03-26 19:25:07,203] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7001
[2019-03-26 19:25:07,209] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.8837098603219602, 1.0, 2.0, 0.8837098603219602, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2471686.165809982, 2471686.165809982, 462685.2982689391], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5232000.0000, 
sim time next is 5232600.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.9310296446545802, 1.0, 2.0, 0.9310296446545802, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2604174.831817282, 2604174.831817282, 488705.1689742079], 
processed observation next is [1.0, 0.5652173913043478, 0.7156398104265403, 0.67, 1.0, 1.0, 0.9169031863308195, 1.0, 1.0, 0.9169031863308195, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7233818977270228, 0.7233818977270228, 0.7294106999615043], 
reward next is 0.2706, 
noisyNet noise sample is [array([-1.3919963], dtype=float32), -1.1849135]. 
=============================================
[2019-03-26 19:25:09,394] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.5700386e-28 1.0000000e+00 7.9273609e-30 6.1016125e-20 2.5052113e-30], sum to 1.0000
[2019-03-26 19:25:09,403] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6442
[2019-03-26 19:25:09,409] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 82.0, 1.0, 2.0, 0.5512454862350286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 770305.8851659923, 770305.885165993, 192014.7141803915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5265000.0000, 
sim time next is 5265600.0000, 
raw observation next is [28.5, 82.33333333333333, 1.0, 2.0, 0.5520011049038989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 771362.1638402259, 771362.1638402259, 192144.7478012505], 
processed observation next is [1.0, 0.9565217391304348, 0.5497630331753555, 0.8233333333333333, 1.0, 1.0, 0.46024229506493836, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21426726773339608, 0.21426726773339608, 0.2867832056735082], 
reward next is 0.7132, 
noisyNet noise sample is [array([1.0137739], dtype=float32), 0.2594661]. 
=============================================
[2019-03-26 19:25:10,537] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0217386e-20 1.0000000e+00 3.1001040e-22 2.3994465e-12 2.8549286e-20], sum to 1.0000
[2019-03-26 19:25:10,544] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1736
[2019-03-26 19:25:10,549] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 88.0, 1.0, 2.0, 0.8453244220013031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1181477.948575945, 1181477.948575945, 255344.3761271651], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5287800.0000, 
sim time next is 5288400.0000, 
raw observation next is [28.6, 88.0, 1.0, 2.0, 0.8386196192004669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1172101.727168837, 1172101.727168838, 253615.2669527114], 
processed observation next is [1.0, 0.21739130434782608, 0.5545023696682465, 0.88, 1.0, 1.0, 0.8055658062656228, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.32558381310245477, 0.325583813102455, 0.3785302491831513], 
reward next is 0.6215, 
noisyNet noise sample is [array([-0.61355096], dtype=float32), 0.6540861]. 
=============================================
[2019-03-26 19:25:12,669] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3567870e-14 9.9997604e-01 1.2412805e-15 2.4020053e-05 3.1297431e-17], sum to 1.0000
[2019-03-26 19:25:12,674] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4011
[2019-03-26 19:25:12,683] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3102431.809198635 W.
[2019-03-26 19:25:12,691] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.11666666666667, 52.83333333333334, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.180453735796751, 6.9112, 170.5573041426782, 3102431.809198635, 2909554.405705713, 552238.129599302], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5320200.0000, 
sim time next is 5320800.0000, 
raw observation next is [36.1, 53.0, 1.0, 2.0, 0.726033835886696, 1.0, 2.0, 0.6836069574576106, 1.0, 1.0, 1.03, 7.005099784989508, 6.9112, 170.5573041426782, 2868469.589289329, 2801205.3537023, 529678.6517973167], 
processed observation next is [1.0, 0.6086956521739131, 0.9099526066350712, 0.53, 1.0, 1.0, 0.6699202842008386, 1.0, 1.0, 0.6188035632019404, 1.0, 0.5, 1.0365853658536586, 0.009389978498950758, 0.0, 0.8375144448122397, 0.7967971081359247, 0.7781125982506389, 0.7905651519362936], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.81417894], dtype=float32), -1.3206657]. 
=============================================
[2019-03-26 19:25:12,714] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.5086377e-18 9.9999988e-01 2.7578117e-17 1.4003999e-07 3.6448724e-19], sum to 1.0000
[2019-03-26 19:25:12,719] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7268
[2019-03-26 19:25:12,727] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 3197025.475442735 W.
[2019-03-26 19:25:12,731] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.1, 53.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.31235133122056, 6.9112, 170.5573041426782, 3197025.475442735, 2909664.459096589, 551513.8260665198], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5323200.0000, 
sim time next is 5323800.0000, 
raw observation next is [36.1, 53.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.644671422077757, 6.9112, 170.5573041426782, 3435357.194339374, 2909941.778995204, 549567.6850369088], 
processed observation next is [1.0, 0.6086956521739131, 0.9099526066350712, 0.53, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.2195121951219512, 0.07334714220777575, 0.0, 0.8375144448122397, 0.9542658873164928, 0.808317160832001, 0.8202502761744908], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.24210317], dtype=float32), 0.54244304]. 
=============================================
[2019-03-26 19:25:15,163] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8236447e-33 1.0000000e+00 7.6090013e-36 1.2758410e-32 0.0000000e+00], sum to 1.0000
[2019-03-26 19:25:15,172] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4244
[2019-03-26 19:25:15,176] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.3, 86.0, 1.0, 2.0, 0.6006835132853975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 839417.4738056152, 839417.4738056146, 200873.6446078068], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5364000.0000, 
sim time next is 5364600.0000, 
raw observation next is [29.25, 86.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 11.41401588712133, 6.9112, 170.3810597889865, 4677914.128340551, 1455697.048234397, 301122.304110757], 
processed observation next is [1.0, 0.08695652173913043, 0.5853080568720379, 0.865, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.45028158871213303, 0.0, 0.8366490043505993, 1.2994205912057086, 0.4043602911762214, 0.44943627479217463], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8878948], dtype=float32), -1.4452494]. 
=============================================
[2019-03-26 19:25:16,985] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 143893: loss -14.8055
[2019-03-26 19:25:16,987] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 143893: learning rate 0.0010
[2019-03-26 19:25:17,012] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 143904: loss -30.7580
[2019-03-26 19:25:17,014] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 143904: learning rate 0.0010
[2019-03-26 19:25:17,041] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 143917: loss -1.2929
[2019-03-26 19:25:17,043] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 143918: learning rate 0.0010
[2019-03-26 19:25:17,125] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 143956: loss 37.9170
[2019-03-26 19:25:17,127] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 143957: learning rate 0.0010
[2019-03-26 19:25:17,142] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 143961: loss -10.3286
[2019-03-26 19:25:17,144] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 143961: learning rate 0.0010
[2019-03-26 19:25:17,170] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 143974: loss -48.7283
[2019-03-26 19:25:17,172] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 143975: learning rate 0.0010
[2019-03-26 19:25:17,201] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 143987: loss -18.6086
[2019-03-26 19:25:17,206] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 143987: learning rate 0.0010
[2019-03-26 19:25:17,211] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 143992: loss -28.7177
[2019-03-26 19:25:17,213] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 143992: learning rate 0.0010
[2019-03-26 19:25:17,228] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 144000: loss -66.7245
[2019-03-26 19:25:17,229] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 144000: learning rate 0.0010
[2019-03-26 19:25:17,242] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 144005: loss -21.6559
[2019-03-26 19:25:17,245] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 144005: learning rate 0.0010
[2019-03-26 19:25:17,254] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 144012: loss 3.2096
[2019-03-26 19:25:17,255] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 144012: learning rate 0.0010
[2019-03-26 19:25:17,283] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 144024: loss -32.9089
[2019-03-26 19:25:17,287] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 144024: learning rate 0.0010
[2019-03-26 19:25:17,288] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 144025: loss -27.0323
[2019-03-26 19:25:17,291] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 144025: learning rate 0.0010
[2019-03-26 19:25:17,301] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 144028: loss 5.6575
[2019-03-26 19:25:17,303] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 144030: learning rate 0.0010
[2019-03-26 19:25:17,336] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 144044: loss -1.5912
[2019-03-26 19:25:17,340] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 144045: learning rate 0.0010
[2019-03-26 19:25:17,463] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 144101: loss -51.8671
[2019-03-26 19:25:17,466] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 144103: learning rate 0.0010
[2019-03-26 19:25:20,280] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4986126e-25 1.0000000e+00 1.5447923e-25 1.2374970e-19 6.2236728e-25], sum to 1.0000
[2019-03-26 19:25:20,289] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6497
[2019-03-26 19:25:20,294] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 92.0, 1.0, 2.0, 1.020220102079698, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912856602807, 1426087.197637082, 1426087.197637082, 305150.9151187706], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5454000.0000, 
sim time next is 5454600.0000, 
raw observation next is [27.86666666666667, 92.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.945481483920778, 6.9112, 168.9125790459621, 1478091.993395194, 1453771.583172353, 311353.9108126464], 
processed observation next is [1.0, 0.13043478260869565, 0.519747235387046, 0.92, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0034281483920778123, 0.0, 0.8294380916289564, 0.41058110927644276, 0.40382543977009805, 0.464707329571114], 
reward next is 0.3639, 
noisyNet noise sample is [array([1.6087307], dtype=float32), 1.2408113]. 
=============================================
[2019-03-26 19:25:21,867] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.7542498e-09 9.9999583e-01 8.6178709e-09 4.1438511e-06 1.8004162e-08], sum to 1.0000
[2019-03-26 19:25:21,874] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0215
[2019-03-26 19:25:21,881] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2810881.447837377 W.
[2019-03-26 19:25:21,888] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.46666666666667, 68.66666666666667, 1.0, 2.0, 1.004847165207756, 1.0, 2.0, 1.004847165207756, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2810881.447837377, 2810881.447837377, 531932.836165648], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5478600.0000, 
sim time next is 5479200.0000, 
raw observation next is [33.7, 68.0, 1.0, 2.0, 0.9879810473190169, 1.0, 2.0, 0.9879810473190169, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2763649.291323984, 2763649.291323983, 521777.2788563376], 
processed observation next is [1.0, 0.43478260869565216, 0.7962085308056873, 0.68, 1.0, 1.0, 0.9855193341192975, 1.0, 1.0, 0.9855193341192975, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7676803587011066, 0.7676803587011064, 0.7787720579945338], 
reward next is 0.2212, 
noisyNet noise sample is [array([-1.1338032], dtype=float32), -0.6844846]. 
=============================================
[2019-03-26 19:25:24,193] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.9514276e-21 1.0000000e+00 7.7466683e-25 1.4589243e-14 1.6624081e-21], sum to 1.0000
[2019-03-26 19:25:24,201] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2011
[2019-03-26 19:25:24,207] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.96666666666667, 78.5, 1.0, 2.0, 0.5822848562401479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813696.6579454262, 813696.6579454262, 197492.1938883586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5515800.0000, 
sim time next is 5516400.0000, 
raw observation next is [29.83333333333334, 79.0, 1.0, 2.0, 0.5815143960302137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 812619.5893772576, 812619.589377257, 197352.7054057249], 
processed observation next is [1.0, 0.8695652173913043, 0.6129541864139023, 0.79, 1.0, 1.0, 0.49580047714483577, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22572766371590489, 0.22572766371590475, 0.29455627672496254], 
reward next is 0.7054, 
noisyNet noise sample is [array([0.61243176], dtype=float32), 0.07125934]. 
=============================================
[2019-03-26 19:25:26,365] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2463640e-26 1.0000000e+00 2.2064359e-29 2.2065324e-18 2.8217143e-25], sum to 1.0000
[2019-03-26 19:25:26,373] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9307
[2019-03-26 19:25:26,382] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 90.0, 1.0, 2.0, 0.6987487340141891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 976520.4605154968, 976520.4605154968, 220575.1261582956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5551200.0000, 
sim time next is 5551800.0000, 
raw observation next is [26.86666666666667, 89.33333333333333, 1.0, 2.0, 0.8164064319881933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1141038.651709217, 1141038.651709217, 247977.6576206631], 
processed observation next is [1.0, 0.2608695652173913, 0.4723538704581361, 0.8933333333333333, 1.0, 1.0, 0.778802930106257, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3169551810303381, 0.3169551810303381, 0.37011590689651214], 
reward next is 0.6299, 
noisyNet noise sample is [array([0.10348429], dtype=float32), 0.1066212]. 
=============================================
[2019-03-26 19:25:30,637] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 19:25:30,638] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:25:30,640] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:25:30,640] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:25:30,641] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:25:30,643] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:25:30,642] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:25:30,647] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:25:30,648] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:25:30,644] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:25:30,652] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:25:30,665] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run7
[2019-03-26 19:25:30,666] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run7
[2019-03-26 19:25:30,704] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run7
[2019-03-26 19:25:30,708] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run7
[2019-03-26 19:25:30,752] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run7
[2019-03-26 19:25:32,023] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.6180507]
[2019-03-26 19:25:32,024] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.93333333333333, 66.16666666666667, 1.0, 2.0, 0.4426115663496044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 643186.69618311, 643186.6961831107, 178250.1281482361]
[2019-03-26 19:25:32,026] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:25:32,028] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.3912147e-26 1.0000000e+00 3.0965959e-28 2.6942356e-17 2.6504884e-28], sampled 0.9238977609707422
[2019-03-26 19:25:39,207] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.6180507]
[2019-03-26 19:25:39,208] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.2, 67.5, 1.0, 2.0, 0.4726403767214698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777850.2612768414, 777850.2612768414, 191015.0072088683]
[2019-03-26 19:25:39,209] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:25:39,211] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.7269042e-26 1.0000000e+00 2.4685203e-28 5.1917077e-18 1.3987833e-28], sampled 0.9343290911873436
[2019-03-26 19:25:43,729] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.6180507]
[2019-03-26 19:25:43,730] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.970704455, 79.67751479833333, 1.0, 2.0, 0.36919094165473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 563658.368834658, 563658.3688346585, 171665.5067063825]
[2019-03-26 19:25:43,733] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:25:43,737] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.9345167e-28 1.0000000e+00 2.2368679e-30 7.7291581e-19 1.5893506e-30], sampled 0.002109355985278838
[2019-03-26 19:25:44,747] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.6180507]
[2019-03-26 19:25:44,747] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.55, 73.0, 1.0, 2.0, 0.344679662748107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 535731.3156585245, 535731.3156585252, 169601.5698973982]
[2019-03-26 19:25:44,749] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:25:44,751] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.8281642e-28 1.0000000e+00 1.4035925e-30 7.6865826e-19 1.0880351e-30], sampled 0.2024733542991699
[2019-03-26 19:26:12,243] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.6180507]
[2019-03-26 19:26:12,243] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.05, 53.5, 1.0, 2.0, 0.8551549308359105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1195225.411968925, 1195225.411968925, 257898.832423442]
[2019-03-26 19:26:12,245] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:26:12,248] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.0973795e-24 1.0000000e+00 1.2193538e-25 2.6953103e-13 5.2572772e-25], sampled 0.5233914052216927
[2019-03-26 19:26:14,488] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.6180507]
[2019-03-26 19:26:14,488] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.0, 95.0, 1.0, 2.0, 0.5296480638879271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 787887.8744350799, 787887.8744350792, 194310.1199839892]
[2019-03-26 19:26:14,490] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:26:14,492] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.2359094e-25 1.0000000e+00 1.8533070e-27 1.4728558e-15 3.8805824e-27], sampled 0.4479623766077472
[2019-03-26 19:26:23,608] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.6180507]
[2019-03-26 19:26:23,609] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.6, 68.0, 1.0, 2.0, 0.8903823568360509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1244490.625834642, 1244490.625834642, 267308.8385902786]
[2019-03-26 19:26:23,612] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:26:23,616] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.7724766e-23 1.0000000e+00 1.6845570e-24 1.7450635e-12 7.8164890e-24], sampled 0.8692059630880682
[2019-03-26 19:26:55,558] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.6180507]
[2019-03-26 19:26:55,559] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.64795648, 75.71977861, 1.0, 2.0, 0.5830357713800746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 814746.4044396526, 814746.4044396526, 197628.7282836535]
[2019-03-26 19:26:55,560] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:26:55,565] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.4045288e-24 1.0000000e+00 3.9883559e-26 5.0498028e-10 1.5176789e-24], sampled 0.4875081472579512
[2019-03-26 19:27:18,427] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.6180507]
[2019-03-26 19:27:18,427] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.25, 91.5, 1.0, 2.0, 0.3877300353579577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 579652.4909455976, 579652.4909455976, 172711.0493729905]
[2019-03-26 19:27:18,430] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:27:18,433] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.0507489e-28 1.0000000e+00 3.3453042e-30 3.7600715e-19 1.8463253e-30], sampled 0.7364978144787466
[2019-03-26 19:27:23,127] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.6180507]
[2019-03-26 19:27:23,128] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.1, 61.0, 1.0, 2.0, 0.2995045996463072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 480240.1397591506, 480240.1397591506, 165674.2809422359]
[2019-03-26 19:27:23,130] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:27:23,133] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.5571324e-27 1.0000000e+00 6.7271966e-30 5.3882963e-18 7.1726002e-30], sampled 0.01902652399198279
[2019-03-26 19:27:24,471] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8178.8538 3149490261.2334 966.0000
[2019-03-26 19:27:24,557] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8352.0360 2980471846.5509 864.0000
[2019-03-26 19:27:24,648] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8724.5129 2775064959.9458 763.0000
[2019-03-26 19:27:24,789] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8432.1622 2916114844.0785 897.0000
[2019-03-26 19:27:24,975] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8639.9625 2832936991.7925 751.0000
[2019-03-26 19:27:25,993] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 150000, evaluation results [150000.0, 8178.8538107675295, 3149490261.2334013, 966.0, 8432.162233338542, 2916114844.0784554, 897.0, 8724.512926229789, 2775064959.945827, 763.0, 8352.036029982624, 2980471846.5508895, 864.0, 8639.962517331642, 2832936991.7924705, 751.0]
[2019-03-26 19:27:30,070] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 151851: loss 0.0001
[2019-03-26 19:27:30,074] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 151852: learning rate 0.0010
[2019-03-26 19:27:30,184] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 151907: loss 0.0649
[2019-03-26 19:27:30,187] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 151908: learning rate 0.0010
[2019-03-26 19:27:30,207] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 151917: loss 0.1350
[2019-03-26 19:27:30,210] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 151917: learning rate 0.0010
[2019-03-26 19:27:30,284] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 151947: loss 0.0978
[2019-03-26 19:27:30,285] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 151947: learning rate 0.0010
[2019-03-26 19:27:30,338] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 151971: loss 0.0913
[2019-03-26 19:27:30,345] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 151972: learning rate 0.0010
[2019-03-26 19:27:30,364] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 151980: loss 0.0884
[2019-03-26 19:27:30,365] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 151980: learning rate 0.0010
[2019-03-26 19:27:30,393] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 151992: loss 0.0289
[2019-03-26 19:27:30,395] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 151992: learning rate 0.0010
[2019-03-26 19:27:30,409] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 152000: loss 0.0006
[2019-03-26 19:27:30,409] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 152000: loss 0.0028
[2019-03-26 19:27:30,410] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 152000: learning rate 0.0010
[2019-03-26 19:27:30,413] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 152000: learning rate 0.0010
[2019-03-26 19:27:30,415] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 152000: loss 0.0230
[2019-03-26 19:27:30,418] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 152002: learning rate 0.0010
[2019-03-26 19:27:30,448] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 152020: loss 0.0004
[2019-03-26 19:27:30,450] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 152020: loss 0.0019
[2019-03-26 19:27:30,451] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 152020: learning rate 0.0010
[2019-03-26 19:27:30,453] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 152021: learning rate 0.0010
[2019-03-26 19:27:30,482] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 152034: loss 0.0002
[2019-03-26 19:27:30,491] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 152034: learning rate 0.0010
[2019-03-26 19:27:30,502] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 152038: loss 0.0007
[2019-03-26 19:27:30,505] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 152038: learning rate 0.0010
[2019-03-26 19:27:30,513] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 152042: loss 0.0561
[2019-03-26 19:27:30,517] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 152045: learning rate 0.0010
[2019-03-26 19:27:30,633] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 152098: loss 0.0134
[2019-03-26 19:27:30,638] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 152101: learning rate 0.0010
[2019-03-26 19:27:36,338] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1574480e-20 1.0000000e+00 1.9213496e-20 2.6429692e-11 3.3129266e-19], sum to 1.0000
[2019-03-26 19:27:36,349] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1794
[2019-03-26 19:27:36,353] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 91.66666666666667, 1.0, 2.0, 0.3819106484658206, 1.0, 1.0, 0.3819106484658206, 1.0, 1.0, 0.655074150687757, 6.9112, 6.9112, 170.5573041426782, 1601651.262662901, 1601651.262662901, 342013.8145316627], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5800800.0000, 
sim time next is 5801400.0000, 
raw observation next is [26.35, 92.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.128495392506945, 6.9112, 168.9115555400722, 1608016.054500173, 1453860.50290801, 311349.8381904884], 
processed observation next is [1.0, 0.13043478260869565, 0.4478672985781992, 0.92, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.02172953925069452, 0.0, 0.8294330657464739, 0.44667112625004807, 0.40385013969666944, 0.4647012510305797], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8552046], dtype=float32), -0.25394264]. 
=============================================
[2019-03-26 19:27:37,217] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1379842e-20 1.0000000e+00 1.6113694e-24 3.5707696e-08 2.0467245e-21], sum to 1.0000
[2019-03-26 19:27:37,225] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5395
[2019-03-26 19:27:37,240] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.36666666666667, 86.33333333333334, 1.0, 2.0, 0.8800687012622707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1230066.84180666, 1230066.841806659, 264513.9030617427], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5811600.0000, 
sim time next is 5812200.0000, 
raw observation next is [27.55, 85.5, 1.0, 2.0, 0.956055345539492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1336339.767816107, 1336339.767816107, 285822.5644311356], 
processed observation next is [1.0, 0.2608695652173913, 0.504739336492891, 0.855, 1.0, 1.0, 0.9470546331801108, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3712054910600297, 0.3712054910600297, 0.4266008424345307], 
reward next is 0.5734, 
noisyNet noise sample is [array([0.541348], dtype=float32), 0.52700686]. 
=============================================
[2019-03-26 19:27:38,968] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 7.6684865e-33 0.0000000e+00 1.0000000e+00 1.2136113e-36], sum to 1.0000
[2019-03-26 19:27:38,980] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1719
[2019-03-26 19:27:38,986] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.55, 62.16666666666667, 1.0, 2.0, 0.8877548980970035, 1.0, 2.0, 0.8877548980970035, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2483011.147169054, 2483011.147169055, 464855.7422388227], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5843400.0000, 
sim time next is 5844000.0000, 
raw observation next is [32.5, 62.33333333333334, 1.0, 2.0, 0.8453105903781825, 1.0, 2.0, 0.8453105903781825, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2364183.99548175, 2364183.99548175, 442534.6685552174], 
processed observation next is [1.0, 0.6521739130434783, 0.7393364928909952, 0.6233333333333334, 1.0, 1.0, 0.8136272173231114, 1.0, 1.0, 0.8136272173231114, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6567177765227084, 0.6567177765227084, 0.6604995053062946], 
reward next is 0.3395, 
noisyNet noise sample is [array([0.9768446], dtype=float32), -0.0826679]. 
=============================================
[2019-03-26 19:27:39,000] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[101.7844  ]
 [100.881294]
 [100.620605]
 [100.49774 ]
 [100.33252 ]], R is [[101.89527893]
 [101.18251038]
 [100.3740387 ]
 [ 99.56916809]
 [ 98.77226257]].
[2019-03-26 19:27:39,437] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.9682125e-33 7.5114162e-19 1.4300021e-33 1.0000000e+00 1.1111469e-22], sum to 1.0000
[2019-03-26 19:27:39,448] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1449
[2019-03-26 19:27:39,454] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.8, 76.83333333333333, 1.0, 2.0, 0.2793049630917407, 1.0, 2.0, 0.2793049630917407, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 780597.9087455474, 780597.9087455474, 246009.8859832747], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5856600.0000, 
sim time next is 5857200.0000, 
raw observation next is [29.6, 78.0, 1.0, 2.0, 0.2796494235827841, 1.0, 2.0, 0.2796494235827841, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 781560.9532435107, 781560.9532435107, 246072.2300622698], 
processed observation next is [1.0, 0.8260869565217391, 0.6018957345971565, 0.78, 1.0, 1.0, 0.13210773925636637, 1.0, 1.0, 0.13210773925636637, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.21710026478986408, 0.21710026478986408, 0.3672719851675669], 
reward next is 0.6327, 
noisyNet noise sample is [array([-1.0132409], dtype=float32), -0.038215797]. 
=============================================
[2019-03-26 19:27:41,275] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5549432e-18 1.0000000e+00 2.2008727e-20 2.0853007e-11 1.7605410e-21], sum to 1.0000
[2019-03-26 19:27:41,282] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1113
[2019-03-26 19:27:41,287] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 92.66666666666667, 1.0, 2.0, 0.5262040121936707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 735301.0247756034, 735301.0247756029, 187803.544846052], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5880000.0000, 
sim time next is 5880600.0000, 
raw observation next is [26.15, 93.0, 1.0, 2.0, 0.5257780160128267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 734705.5451753035, 734705.545175304, 187733.5330950924], 
processed observation next is [1.0, 0.043478260869565216, 0.43838862559241704, 0.93, 1.0, 1.0, 0.4286482120636466, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20408487365980651, 0.20408487365980668, 0.2801993031270036], 
reward next is 0.7198, 
noisyNet noise sample is [array([1.3311099], dtype=float32), -0.4885078]. 
=============================================
[2019-03-26 19:27:43,476] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.4934524e-34 0.0000000e+00 1.0000000e+00 3.6763898e-34], sum to 1.0000
[2019-03-26 19:27:43,484] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4353
[2019-03-26 19:27:43,488] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.16666666666667, 72.16666666666667, 1.0, 2.0, 0.8985581483871018, 1.0, 2.0, 0.8985581483871018, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2513257.748115304, 2513257.748115305, 470709.4290765268], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5919000.0000, 
sim time next is 5919600.0000, 
raw observation next is [31.03333333333334, 72.33333333333334, 1.0, 2.0, 0.7938100133190397, 1.0, 2.0, 0.7938100133190397, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2220018.068483935, 2220018.068483935, 416874.9461326379], 
processed observation next is [1.0, 0.5217391304347826, 0.6698262243285943, 0.7233333333333334, 1.0, 1.0, 0.7515783293000478, 1.0, 1.0, 0.7515783293000478, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.616671685689982, 0.616671685689982, 0.6222014121382655], 
reward next is 0.3778, 
noisyNet noise sample is [array([-0.26056388], dtype=float32), 1.3071833]. 
=============================================
[2019-03-26 19:27:47,864] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 159842: loss 0.1349
[2019-03-26 19:27:47,868] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 159844: learning rate 0.0010
[2019-03-26 19:27:47,967] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 159891: loss 0.1770
[2019-03-26 19:27:47,969] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 159891: learning rate 0.0010
[2019-03-26 19:27:47,995] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 159903: loss 0.1763
[2019-03-26 19:27:47,997] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 159903: learning rate 0.0010
[2019-03-26 19:27:48,122] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 159958: loss 0.2466
[2019-03-26 19:27:48,125] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 159960: learning rate 0.0010
[2019-03-26 19:27:48,129] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 159962: loss 0.1077
[2019-03-26 19:27:48,132] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 159963: learning rate 0.0010
[2019-03-26 19:27:48,167] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 159977: loss 0.2892
[2019-03-26 19:27:48,169] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 159977: learning rate 0.0010
[2019-03-26 19:27:48,190] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 159987: loss 0.2547
[2019-03-26 19:27:48,191] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 159987: learning rate 0.0010
[2019-03-26 19:27:48,215] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 159993: loss 0.1687
[2019-03-26 19:27:48,218] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 159993: learning rate 0.0010
[2019-03-26 19:27:48,233] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 160000: loss 0.2884
[2019-03-26 19:27:48,238] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 160000: learning rate 0.0010
[2019-03-26 19:27:48,262] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 160012: loss 0.3199
[2019-03-26 19:27:48,265] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 160012: learning rate 0.0010
[2019-03-26 19:27:48,297] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 160026: loss 0.2956
[2019-03-26 19:27:48,297] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 160026: loss 0.3363
[2019-03-26 19:27:48,300] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 160026: learning rate 0.0010
[2019-03-26 19:27:48,300] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 160026: learning rate 0.0010
[2019-03-26 19:27:48,344] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 160050: loss 0.2517
[2019-03-26 19:27:48,344] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 160050: loss 0.3946
[2019-03-26 19:27:48,346] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 160050: learning rate 0.0010
[2019-03-26 19:27:48,347] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 160051: learning rate 0.0010
[2019-03-26 19:27:48,384] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 160065: loss 0.1517
[2019-03-26 19:27:48,386] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 160065: loss 0.2638
[2019-03-26 19:27:48,387] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 160065: learning rate 0.0010
[2019-03-26 19:27:48,388] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 160066: learning rate 0.0010
[2019-03-26 19:27:53,427] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 2.0073894e-29 0.0000000e+00 1.0000000e+00 4.8890985e-33], sum to 1.0000
[2019-03-26 19:27:53,435] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3329
[2019-03-26 19:27:53,443] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.46666666666667, 68.33333333333334, 1.0, 2.0, 0.664300702823733, 1.0, 2.0, 0.664300702823733, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1857511.245457109, 1857511.245457109, 359215.8143287394], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6085200.0000, 
sim time next is 6085800.0000, 
raw observation next is [30.6, 67.5, 1.0, 2.0, 0.670234487580457, 1.0, 2.0, 0.670234487580457, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1874117.748292412, 1874117.748292412, 361641.7309858361], 
processed observation next is [1.0, 0.43478260869565216, 0.6492890995260664, 0.675, 1.0, 1.0, 0.602692153711394, 1.0, 1.0, 0.602692153711394, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5205882634145589, 0.5205882634145589, 0.5397637775908002], 
reward next is 0.4602, 
noisyNet noise sample is [array([-1.1704465], dtype=float32), -1.4519635]. 
=============================================
[2019-03-26 19:27:57,869] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.0641227e-35 6.3205915e-19 1.1038692e-34 1.0000000e+00 1.6552840e-27], sum to 1.0000
[2019-03-26 19:27:57,876] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7726
[2019-03-26 19:27:57,879] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.3, 84.0, 1.0, 2.0, 0.734205014842494, 1.0, 2.0, 0.734205014842494, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2053164.307682266, 2053164.307682265, 389112.9682641824], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6166800.0000, 
sim time next is 6167400.0000, 
raw observation next is [28.38333333333334, 83.33333333333333, 1.0, 2.0, 0.6919938550228144, 1.0, 2.0, 0.6919938550228144, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1935016.497028113, 1935016.497028113, 370718.3132631826], 
processed observation next is [1.0, 0.391304347826087, 0.544233807266983, 0.8333333333333333, 1.0, 1.0, 0.6289082590636318, 1.0, 1.0, 0.6289082590636318, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5375045825078092, 0.5375045825078092, 0.553310915318183], 
reward next is 0.4467, 
noisyNet noise sample is [array([1.9987097], dtype=float32), 0.24940541]. 
=============================================
[2019-03-26 19:28:04,201] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 6.1249437e-24 0.0000000e+00 1.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 19:28:04,210] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8552
[2019-03-26 19:28:04,215] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.85, 63.0, 1.0, 2.0, 0.2594426341176778, 1.0, 2.0, 0.2594426341176778, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 725068.1647541542, 725068.1647541547, 242520.5756910857], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6269400.0000, 
sim time next is 6270000.0000, 
raw observation next is [30.86666666666667, 62.66666666666666, 1.0, 2.0, 0.2585057092810084, 1.0, 2.0, 0.2585057092810084, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 722448.8452324833, 722448.8452324833, 242361.8476108506], 
processed observation next is [0.0, 0.5652173913043478, 0.6619273301737759, 0.6266666666666666, 1.0, 1.0, 0.10663338467591374, 1.0, 1.0, 0.10663338467591374, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.20068023478680094, 0.20068023478680094, 0.3617341009117173], 
reward next is 0.6383, 
noisyNet noise sample is [array([-0.58092797], dtype=float32), -1.5728447]. 
=============================================
[2019-03-26 19:28:04,234] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[80.1183 ]
 [80.0981 ]
 [80.0709 ]
 [80.03689]
 [79.97874]], R is [[79.9863205 ]
 [79.82448578]
 [79.66400146]
 [79.50500488]
 [79.34748077]].
[2019-03-26 19:28:05,708] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 167854: loss 0.0750
[2019-03-26 19:28:05,718] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 167857: learning rate 0.0010
[2019-03-26 19:28:05,745] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 167871: loss 0.0051
[2019-03-26 19:28:05,747] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 167871: learning rate 0.0010
[2019-03-26 19:28:05,809] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 167899: loss 0.0402
[2019-03-26 19:28:05,813] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 167899: learning rate 0.0010
[2019-03-26 19:28:05,867] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 167926: loss 0.0034
[2019-03-26 19:28:05,869] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 167926: learning rate 0.0010
[2019-03-26 19:28:05,891] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 167937: loss 0.0112
[2019-03-26 19:28:05,892] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 167937: learning rate 0.0010
[2019-03-26 19:28:05,930] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 167951: loss 0.0322
[2019-03-26 19:28:05,933] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 167951: learning rate 0.0010
[2019-03-26 19:28:06,026] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 167995: loss 0.0016
[2019-03-26 19:28:06,026] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 167995: loss 0.0216
[2019-03-26 19:28:06,029] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 167995: learning rate 0.0010
[2019-03-26 19:28:06,031] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 167995: learning rate 0.0010
[2019-03-26 19:28:06,044] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 168000: loss 0.0047
[2019-03-26 19:28:06,046] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 168000: learning rate 0.0010
[2019-03-26 19:28:06,094] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 168025: loss 0.0001
[2019-03-26 19:28:06,096] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 168026: learning rate 0.0010
[2019-03-26 19:28:06,106] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 168029: loss 0.0015
[2019-03-26 19:28:06,109] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 168030: learning rate 0.0010
[2019-03-26 19:28:06,137] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 168043: loss 0.0004
[2019-03-26 19:28:06,138] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 168043: learning rate 0.0010
[2019-03-26 19:28:06,153] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 168048: loss 0.0005
[2019-03-26 19:28:06,161] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 168049: learning rate 0.0010
[2019-03-26 19:28:06,174] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 168057: loss 0.0270
[2019-03-26 19:28:06,176] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 168058: learning rate 0.0010
[2019-03-26 19:28:06,223] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 168080: loss 0.0591
[2019-03-26 19:28:06,226] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 168080: learning rate 0.0010
[2019-03-26 19:28:06,259] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 168097: loss 0.1267
[2019-03-26 19:28:06,263] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 168097: learning rate 0.0010
[2019-03-26 19:28:19,204] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.9867152e-25 1.4486272e-16 1.0544724e-28 1.0000000e+00 1.5437328e-24], sum to 1.0000
[2019-03-26 19:28:19,210] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5033
[2019-03-26 19:28:19,214] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.45, 61.5, 1.0, 2.0, 0.6841009981678501, 1.0, 2.0, 0.6841009981678501, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1912926.065718204, 1912926.065718204, 367383.3198422985], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6517800.0000, 
sim time next is 6518400.0000, 
raw observation next is [30.66666666666667, 60.0, 1.0, 2.0, 0.6957288522885704, 1.0, 2.0, 0.6957288522885704, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1945470.120498581, 1945470.12049858, 372291.6457996175], 
processed observation next is [1.0, 0.43478260869565216, 0.6524486571879939, 0.6, 1.0, 1.0, 0.6334082557693619, 1.0, 1.0, 0.6334082557693619, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5404083668051615, 0.5404083668051611, 0.55565917283525], 
reward next is 0.4443, 
noisyNet noise sample is [array([-1.8614235], dtype=float32), 1.3093638]. 
=============================================
[2019-03-26 19:28:20,415] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.5945550e-35 1.9390558e-22 8.9365414e-35 1.0000000e+00 8.5377121e-30], sum to 1.0000
[2019-03-26 19:28:20,426] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9374
[2019-03-26 19:28:20,431] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.5, 66.33333333333333, 1.0, 2.0, 0.2331297283397606, 1.0, 2.0, 0.2331297283397606, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 651508.7649585941, 651508.7649585934, 238263.6396805202], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6543600.0000, 
sim time next is 6544200.0000, 
raw observation next is [29.4, 66.66666666666667, 1.0, 2.0, 0.236540161707954, 1.0, 2.0, 0.236540161707954, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 661042.563570131, 661042.563570131, 238791.6470788582], 
processed observation next is [1.0, 0.7391304347826086, 0.5924170616113744, 0.6666666666666667, 1.0, 1.0, 0.08016886952765541, 1.0, 1.0, 0.08016886952765541, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.18362293432503637, 0.18362293432503637, 0.3564054434012809], 
reward next is 0.6436, 
noisyNet noise sample is [array([-1.0108353], dtype=float32), -0.972025]. 
=============================================
[2019-03-26 19:28:20,465] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7605034e-33 3.7487676e-21 1.0267795e-32 1.0000000e+00 5.0318516e-29], sum to 1.0000
[2019-03-26 19:28:20,472] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6790
[2019-03-26 19:28:20,478] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.25, 63.0, 1.0, 2.0, 0.6867850091605372, 1.0, 2.0, 0.6867850091605372, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1920437.991776498, 1920437.991776498, 368509.9292383704], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6539400.0000, 
sim time next is 6540000.0000, 
raw observation next is [30.13333333333333, 63.66666666666666, 1.0, 2.0, 0.6787257984288904, 1.0, 2.0, 0.6787257984288904, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1897882.283084588, 1897882.283084588, 365141.6401631382], 
processed observation next is [1.0, 0.6956521739130435, 0.6271721958925749, 0.6366666666666666, 1.0, 1.0, 0.6129226487095064, 1.0, 1.0, 0.6129226487095064, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5271895230790522, 0.5271895230790522, 0.5449875226315496], 
reward next is 0.4550, 
noisyNet noise sample is [array([-0.9741903], dtype=float32), 0.8192436]. 
=============================================
[2019-03-26 19:28:20,497] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[47.623917]
 [47.570305]
 [47.477444]
 [47.326305]
 [47.25532 ]], R is [[47.66181183]
 [47.63518143]
 [47.61101151]
 [47.58419418]
 [47.5223732 ]].
[2019-03-26 19:28:21,642] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 19:28:21,645] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:28:21,646] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:28:21,647] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:21,647] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:21,648] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:28:21,647] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:28:21,649] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:28:21,650] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:21,651] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:21,654] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:21,670] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run8
[2019-03-26 19:28:21,688] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run8
[2019-03-26 19:28:21,691] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run8
[2019-03-26 19:28:21,710] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run8
[2019-03-26 19:28:21,744] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run8
[2019-03-26 19:28:59,231] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.6310411]
[2019-03-26 19:28:59,234] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.15747238333334, 85.85190626333333, 1.0, 2.0, 0.2919673593916823, 1.0, 2.0, 0.2919673593916823, 0.0, 2.0, 0.0, 6.9112, 6.9112, 172.86236624, 815995.9336286129, 815995.9336286129, 248832.6370882285]
[2019-03-26 19:28:59,235] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:28:59,237] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.3408451e-31 8.1647756e-14 2.0179653e-33 1.0000000e+00 8.5366702e-30], sampled 0.08872311883490414
[2019-03-26 19:29:14,471] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.6310411]
[2019-03-26 19:29:14,473] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.120674955, 69.36021142999999, 1.0, 2.0, 0.2597423111842038, 1.0, 2.0, 0.2597423111842038, 0.0, 2.0, 0.0, 6.9112, 6.9112, 172.86236624, 725902.684601646, 725902.684601646, 243047.3502502787]
[2019-03-26 19:29:14,474] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:29:14,477] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.8780763e-32 2.2488878e-16 9.4921334e-34 1.0000000e+00 8.3663841e-30], sampled 0.5155963868304527
[2019-03-26 19:29:20,901] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.6310411]
[2019-03-26 19:29:20,904] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.27116354333333, 70.57738182333333, 1.0, 2.0, 0.283391166069218, 1.0, 2.0, 0.283391166069218, 0.0, 2.0, 0.0, 6.9112, 6.9112, 172.86236624, 792018.2932107545, 792018.2932107545, 247235.2772943627]
[2019-03-26 19:29:20,904] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:29:20,908] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.1353231e-33 3.2549570e-16 3.2351938e-35 1.0000000e+00 3.3857303e-31], sampled 0.12771718732138615
[2019-03-26 19:29:52,960] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.6310411]
[2019-03-26 19:29:52,962] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 66.0, 1.0, 2.0, 0.2683031263691343, 1.0, 2.0, 0.2683031263691343, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 749839.3691837883, 749839.3691837883, 244048.8613747112]
[2019-03-26 19:29:52,963] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:29:52,965] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.9132053e-30 1.9010423e-12 5.9701995e-32 1.0000000e+00 1.4116699e-28], sampled 0.8130347915022187
[2019-03-26 19:30:15,525] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 6701.0599 3429708688.0380 33.0000
[2019-03-26 19:30:15,867] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 6503.2956 3684592754.8713 228.0000
[2019-03-26 19:30:16,236] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 6857.2441 3474993395.0658 8.0000
[2019-03-26 19:30:16,271] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 6794.7133 3393663420.6697 9.0000
[2019-03-26 19:30:16,303] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6798.7741 3511243238.1342 0.0000
[2019-03-26 19:30:17,320] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 175000, evaluation results [175000.0, 6503.295605200641, 3684592754.8713183, 228.0, 6857.244101597982, 3474993395.065798, 8.0, 6794.7133353702575, 3393663420.6696663, 9.0, 6798.774095523391, 3511243238.1342273, 0.0, 6701.059852294064, 3429708688.0380054, 33.0]
[2019-03-26 19:30:18,625] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.25518625e-29 2.93677341e-17 1.16589662e-33 1.00000000e+00
 1.84056496e-31], sum to 1.0000
[2019-03-26 19:30:18,635] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8674
[2019-03-26 19:30:18,642] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.83333333333334, 92.33333333333334, 1.0, 2.0, 0.2845040190096817, 1.0, 2.0, 0.2845040190096817, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 795133.5492829222, 795133.5492829222, 246947.1438090159], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6582000.0000, 
sim time next is 6582600.0000, 
raw observation next is [25.8, 92.5, 1.0, 2.0, 0.2804705460691396, 1.0, 2.0, 0.2804705460691396, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 783856.6554054033, 783856.6554054033, 246209.4353303], 
processed observation next is [1.0, 0.17391304347826086, 0.42180094786729866, 0.925, 1.0, 1.0, 0.1330970434567947, 1.0, 1.0, 0.1330970434567947, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.21773795983483427, 0.21773795983483427, 0.3674767691497015], 
reward next is 0.6325, 
noisyNet noise sample is [array([-1.0386052], dtype=float32), 1.3272171]. 
=============================================
[2019-03-26 19:30:19,156] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 175831: loss 0.0464
[2019-03-26 19:30:19,158] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 175832: learning rate 0.0010
[2019-03-26 19:30:19,191] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 175847: loss 0.0825
[2019-03-26 19:30:19,194] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 175847: learning rate 0.0010
[2019-03-26 19:30:19,233] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 175862: loss 0.0942
[2019-03-26 19:30:19,234] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 175862: learning rate 0.0010
[2019-03-26 19:30:19,301] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 175895: loss 0.0933
[2019-03-26 19:30:19,302] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 175895: learning rate 0.0010
[2019-03-26 19:30:19,314] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 175900: loss 0.1042
[2019-03-26 19:30:19,316] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 175901: learning rate 0.0010
[2019-03-26 19:30:19,439] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.4669643e-30 1.5753273e-13 4.1247678e-33 1.0000000e+00 7.5201975e-32], sum to 1.0000
[2019-03-26 19:30:19,445] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9061
[2019-03-26 19:30:19,451] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.86666666666667, 86.0, 1.0, 2.0, 0.3169000010854329, 1.0, 2.0, 0.3169000010854329, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 885711.4222818569, 885711.4222818569, 253219.1102847212], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6594000.0000, 
sim time next is 6594600.0000, 
raw observation next is [26.93333333333333, 85.5, 1.0, 2.0, 0.313487516244504, 1.0, 2.0, 0.313487516244504, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 876169.8903749448, 876169.8903749448, 252529.4525564268], 
processed observation next is [1.0, 0.30434782608695654, 0.4755134281200631, 0.855, 1.0, 1.0, 0.17287652559578795, 1.0, 1.0, 0.17287652559578795, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.24338052510415134, 0.24338052510415134, 0.37690963068123406], 
reward next is 0.6231, 
noisyNet noise sample is [array([-1.0937139], dtype=float32), -0.7166369]. 
=============================================
[2019-03-26 19:30:19,454] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 175961: loss 0.1072
[2019-03-26 19:30:19,459] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 175963: learning rate 0.0010
[2019-03-26 19:30:19,538] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 176004: loss 0.0471
[2019-03-26 19:30:19,539] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 176004: loss 0.0425
[2019-03-26 19:30:19,540] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 176004: learning rate 0.0010
[2019-03-26 19:30:19,539] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 176004: loss 0.0382
[2019-03-26 19:30:19,543] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 176006: learning rate 0.0010
[2019-03-26 19:30:19,552] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 176008: learning rate 0.0010
[2019-03-26 19:30:19,580] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 176021: loss 0.0446
[2019-03-26 19:30:19,581] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 176022: learning rate 0.0010
[2019-03-26 19:30:19,611] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 176032: loss 0.0148
[2019-03-26 19:30:19,613] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 176033: learning rate 0.0010
[2019-03-26 19:30:19,682] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 176067: loss 0.0154
[2019-03-26 19:30:19,684] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 176068: loss 0.0214
[2019-03-26 19:30:19,684] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 176067: learning rate 0.0010
[2019-03-26 19:30:19,686] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 176068: learning rate 0.0010
[2019-03-26 19:30:19,723] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 176085: loss 0.0105
[2019-03-26 19:30:19,726] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 176087: learning rate 0.0010
[2019-03-26 19:30:19,742] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 176093: loss 0.0057
[2019-03-26 19:30:19,746] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 176093: learning rate 0.0010
[2019-03-26 19:30:19,785] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 176110: loss 0.0056
[2019-03-26 19:30:19,789] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 176112: learning rate 0.0010
[2019-03-26 19:30:22,045] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4160392e-19 5.6761146e-05 2.0442742e-22 9.9994326e-01 3.9047429e-20], sum to 1.0000
[2019-03-26 19:30:22,054] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9087
[2019-03-26 19:30:22,061] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.56666666666667, 87.0, 1.0, 2.0, 0.255115246257564, 1.0, 2.0, 0.255115246257564, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 712970.3304632597, 712970.3304632597, 241791.4717243263], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6646200.0000, 
sim time next is 6646800.0000, 
raw observation next is [26.53333333333334, 87.0, 1.0, 2.0, 0.2544136828447343, 1.0, 2.0, 0.2544136828447343, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 711009.022033546, 711009.0220335466, 241674.3570498307], 
processed observation next is [1.0, 0.9565217391304348, 0.4565560821484995, 0.87, 1.0, 1.0, 0.10170323234305338, 1.0, 1.0, 0.10170323234305338, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.19750250612042944, 0.1975025061204296, 0.36070799559676225], 
reward next is 0.6393, 
noisyNet noise sample is [array([-0.9300779], dtype=float32), -0.36714384]. 
=============================================
[2019-03-26 19:30:27,934] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.7117984e-22 1.5874740e-09 2.8100030e-27 1.0000000e+00 2.9536589e-25], sum to 1.0000
[2019-03-26 19:30:27,945] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9744
[2019-03-26 19:30:27,950] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.85, 81.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 512359.2288780213, 512359.2288780213, 236014.4606189807], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6744600.0000, 
sim time next is 6745200.0000, 
raw observation next is [22.7, 81.66666666666666, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 511210.2036776796, 511210.2036776796, 235766.6277257703], 
processed observation next is [1.0, 0.043478260869565216, 0.27488151658767773, 0.8166666666666665, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.14200283435491098, 0.14200283435491098, 0.35189048914294074], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8076447], dtype=float32), -1.6314409]. 
=============================================
[2019-03-26 19:30:28,832] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0843136e-18 9.9998987e-01 4.2091453e-25 1.0168495e-05 3.0612685e-22], sum to 1.0000
[2019-03-26 19:30:28,844] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0567
[2019-03-26 19:30:28,850] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.53333333333333, 81.66666666666667, 1.0, 2.0, 0.3487074423974252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 551949.6496468761, 551949.6496468768, 171103.700153481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6762000.0000, 
sim time next is 6762600.0000, 
raw observation next is [22.65, 81.0, 1.0, 2.0, 0.3434887855873461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 543394.8532013342, 543394.8532013348, 170404.7218079845], 
processed observation next is [1.0, 0.2608695652173913, 0.2725118483412322, 0.81, 1.0, 1.0, 0.20902263323776635, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1509430147781484, 0.15094301477814856, 0.25433540568355895], 
reward next is 0.7457, 
noisyNet noise sample is [array([0.9916789], dtype=float32), 0.6161302]. 
=============================================
[2019-03-26 19:30:36,815] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 183770: loss 0.3063
[2019-03-26 19:30:36,817] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 183770: learning rate 0.0010
[2019-03-26 19:30:36,968] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 183840: loss 0.0685
[2019-03-26 19:30:36,969] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 183840: learning rate 0.0010
[2019-03-26 19:30:37,048] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 183874: loss 0.0021
[2019-03-26 19:30:37,048] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 183874: learning rate 0.0010
[2019-03-26 19:30:37,069] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 183883: loss 0.0012
[2019-03-26 19:30:37,072] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 183884: learning rate 0.0010
[2019-03-26 19:30:37,139] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 183917: loss 0.0168
[2019-03-26 19:30:37,141] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 183917: learning rate 0.0010
[2019-03-26 19:30:37,179] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 183933: loss 0.0478
[2019-03-26 19:30:37,180] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 183934: learning rate 0.0010
[2019-03-26 19:30:37,306] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 183992: loss 0.0187
[2019-03-26 19:30:37,311] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 183994: learning rate 0.0010
[2019-03-26 19:30:37,322] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 183999: loss 0.0026
[2019-03-26 19:30:37,324] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 184000: learning rate 0.0010
[2019-03-26 19:30:37,397] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 184033: loss 0.0094
[2019-03-26 19:30:37,400] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 184033: learning rate 0.0010
[2019-03-26 19:30:37,413] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 184040: loss 0.0535
[2019-03-26 19:30:37,416] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 184040: learning rate 0.0010
[2019-03-26 19:30:37,441] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 184051: loss 0.0529
[2019-03-26 19:30:37,441] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 184051: loss 0.0721
[2019-03-26 19:30:37,443] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 184051: learning rate 0.0010
[2019-03-26 19:30:37,444] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 184051: learning rate 0.0010
[2019-03-26 19:30:37,458] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 184058: loss 0.0698
[2019-03-26 19:30:37,460] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 184058: learning rate 0.0010
[2019-03-26 19:30:37,525] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 184088: loss 0.0792
[2019-03-26 19:30:37,527] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 184088: learning rate 0.0010
[2019-03-26 19:30:37,556] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2233663e-38 1.0000000e+00 0.0000000e+00 7.6171867e-11 0.0000000e+00], sum to 1.0000
[2019-03-26 19:30:37,566] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7582
[2019-03-26 19:30:37,567] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 184105: loss 0.0729
[2019-03-26 19:30:37,569] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 184105: learning rate 0.0010
[2019-03-26 19:30:37,572] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 79.0, 1.0, 2.0, 0.4148880629131098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 609709.3112719102, 609709.3112719102, 175176.3442842608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6908400.0000, 
sim time next is 6909000.0000, 
raw observation next is [25.45, 79.33333333333334, 1.0, 2.0, 0.415919574448055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 610821.5112986965, 610821.5112986965, 175269.8816157605], 
processed observation next is [0.0, 1.0, 0.4052132701421801, 0.7933333333333334, 1.0, 1.0, 0.29628864391331927, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1696726420274157, 0.1696726420274157, 0.26159683823247837], 
reward next is 0.7384, 
noisyNet noise sample is [array([0.46656385], dtype=float32), 0.5874675]. 
=============================================
[2019-03-26 19:30:37,588] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[88.469536]
 [88.383354]
 [88.32556 ]
 [88.26151 ]
 [88.20736 ]], R is [[88.38754272]
 [88.24221039]
 [88.09861755]
 [87.9567337 ]
 [87.81652069]].
[2019-03-26 19:30:37,674] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 184151: loss 0.0005
[2019-03-26 19:30:37,677] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 184152: learning rate 0.0010
[2019-03-26 19:30:43,667] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0622861e-24 1.0000000e+00 4.5538087e-31 3.2077583e-09 9.1487700e-22], sum to 1.0000
[2019-03-26 19:30:43,676] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1517
[2019-03-26 19:30:43,685] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 83.0, 1.0, 2.0, 0.4602755579210497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 653117.9531069922, 653117.9531069922, 178890.5725801206], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7005600.0000, 
sim time next is 7006200.0000, 
raw observation next is [25.75, 83.16666666666667, 1.0, 2.0, 0.9417134402916928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1336893.568229379, 1336893.568229379, 284793.4860074467], 
processed observation next is [1.0, 0.08695652173913043, 0.41943127962085314, 0.8316666666666667, 1.0, 1.0, 0.9297752292670998, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3713593245081608, 0.3713593245081608, 0.4250649044887264], 
reward next is 0.5749, 
noisyNet noise sample is [array([-0.02497675], dtype=float32), 0.24212247]. 
=============================================
[2019-03-26 19:30:47,338] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5995758e-29 1.5483195e-11 3.0297506e-34 1.0000000e+00 1.3283257e-32], sum to 1.0000
[2019-03-26 19:30:47,351] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8039
[2019-03-26 19:30:47,357] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.9, 86.0, 1.0, 2.0, 0.2422277546278819, 1.0, 2.0, 0.2422277546278819, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 676942.3048893916, 676942.3048893916, 239685.5808449154], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7074000.0000, 
sim time next is 7074600.0000, 
raw observation next is [25.85, 86.16666666666667, 1.0, 2.0, 0.242796393825376, 1.0, 2.0, 0.242796393825376, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 678531.9562551177, 678531.956255117, 239776.0544627855], 
processed observation next is [1.0, 0.9130434782608695, 0.4241706161137442, 0.8616666666666667, 1.0, 1.0, 0.08770649858479034, 1.0, 1.0, 0.08770649858479034, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.1884810989597549, 0.1884810989597547, 0.3578747081534112], 
reward next is 0.6421, 
noisyNet noise sample is [array([1.2393641], dtype=float32), -0.050113715]. 
=============================================
[2019-03-26 19:30:54,695] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 191809: loss 0.0791
[2019-03-26 19:30:54,697] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 191809: learning rate 0.0010
[2019-03-26 19:30:54,719] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 191815: loss 0.0247
[2019-03-26 19:30:54,722] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 191816: learning rate 0.0010
[2019-03-26 19:30:54,889] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 191893: loss 0.0738
[2019-03-26 19:30:54,892] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 191893: learning rate 0.0010
[2019-03-26 19:30:55,001] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 191943: loss 0.0458
[2019-03-26 19:30:55,002] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 191943: loss 0.0339
[2019-03-26 19:30:55,002] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 191943: learning rate 0.0010
[2019-03-26 19:30:55,003] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 191943: learning rate 0.0010
[2019-03-26 19:30:55,053] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 191965: loss 0.0430
[2019-03-26 19:30:55,056] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 191967: learning rate 0.0010
[2019-03-26 19:30:55,078] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 191975: loss 0.0115
[2019-03-26 19:30:55,082] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 191976: learning rate 0.0010
[2019-03-26 19:30:55,085] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 191979: loss 0.0038
[2019-03-26 19:30:55,086] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 191979: learning rate 0.0010
[2019-03-26 19:30:55,112] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 191989: loss 0.0787
[2019-03-26 19:30:55,113] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 191989: learning rate 0.0010
[2019-03-26 19:30:55,172] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 192014: loss 0.0022
[2019-03-26 19:30:55,174] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 192014: learning rate 0.0010
[2019-03-26 19:30:55,226] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 192041: loss 0.0062
[2019-03-26 19:30:55,228] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 192041: learning rate 0.0010
[2019-03-26 19:30:55,246] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 192049: loss 0.0033
[2019-03-26 19:30:55,250] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 192050: learning rate 0.0010
[2019-03-26 19:30:55,295] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 192065: loss 0.0197
[2019-03-26 19:30:55,298] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 192066: learning rate 0.0010
[2019-03-26 19:30:55,307] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 192072: loss 0.0435
[2019-03-26 19:30:55,310] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 192072: learning rate 0.0010
[2019-03-26 19:30:55,370] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 192099: loss 0.0507
[2019-03-26 19:30:55,374] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 192099: learning rate 0.0010
[2019-03-26 19:30:55,486] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 192153: loss 0.0570
[2019-03-26 19:30:55,491] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 192154: learning rate 0.0010
[2019-03-26 19:30:56,003] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4531622e-26 4.8076716e-12 6.8111244e-28 1.0000000e+00 2.0000816e-22], sum to 1.0000
[2019-03-26 19:30:56,012] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2001
[2019-03-26 19:30:56,016] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.16666666666667, 77.0, 1.0, 2.0, 0.6676427784094223, 1.0, 2.0, 0.6676427784094223, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1866864.466395944, 1866864.466395944, 360581.0374375751], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7208400.0000, 
sim time next is 7209000.0000, 
raw observation next is [29.25, 76.0, 1.0, 2.0, 0.6519488778183834, 1.0, 2.0, 0.6519488778183834, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1822943.810494138, 1822943.810494138, 354232.7952051161], 
processed observation next is [1.0, 0.43478260869565216, 0.5853080568720379, 0.76, 1.0, 1.0, 0.5806612985763655, 1.0, 1.0, 0.5806612985763655, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5063732806928161, 0.5063732806928161, 0.5287056644852479], 
reward next is 0.4713, 
noisyNet noise sample is [array([-0.882269], dtype=float32), -1.2321088]. 
=============================================
[2019-03-26 19:30:56,036] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[44.85707 ]
 [44.88277 ]
 [44.86564 ]
 [44.975517]
 [44.91833 ]], R is [[44.89300919]
 [44.90589905]
 [44.92618561]
 [44.92724228]
 [44.95965195]].
[2019-03-26 19:30:59,615] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.9364956e-24 9.9999905e-01 2.1560125e-29 9.0660069e-07 6.5276386e-28], sum to 1.0000
[2019-03-26 19:30:59,621] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1240
[2019-03-26 19:30:59,626] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.68333333333333, 89.16666666666667, 1.0, 2.0, 0.3632090556018588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 573143.7943653135, 573143.7943653135, 172857.3420937126], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7269000.0000, 
sim time next is 7269600.0000, 
raw observation next is [21.66666666666667, 89.33333333333334, 1.0, 2.0, 0.3346299029941324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527978.7966770342, 527978.7966770342, 169154.4137763013], 
processed observation next is [1.0, 0.13043478260869565, 0.22590837282780438, 0.8933333333333334, 1.0, 1.0, 0.1983492807158222, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14666077685473172, 0.14666077685473172, 0.25246927429298704], 
reward next is 0.7475, 
noisyNet noise sample is [array([0.4842193], dtype=float32), -0.47613963]. 
=============================================
[2019-03-26 19:31:09,511] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.70211631e-31 1.00000000e+00 1.19129680e-35 1.25217625e-17
 2.96778341e-28], sum to 1.0000
[2019-03-26 19:31:09,520] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6419
[2019-03-26 19:31:09,526] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.21666666666667, 95.0, 1.0, 2.0, 0.3230113846010633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 506686.1879506215, 506686.1879506215, 167439.300956639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7449000.0000, 
sim time next is 7449600.0000, 
raw observation next is [21.23333333333333, 95.0, 1.0, 2.0, 0.3239423236257969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 507934.9275484583, 507934.9275484583, 167529.4040636521], 
processed observation next is [0.0, 0.21739130434782608, 0.2053712480252764, 0.95, 1.0, 1.0, 0.18547267906722517, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1410930354301273, 0.1410930354301273, 0.2500438866621673], 
reward next is 0.7500, 
noisyNet noise sample is [array([-0.48867962], dtype=float32), 0.82820123]. 
=============================================
[2019-03-26 19:31:09,731] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.2127525e-27 1.0000000e+00 1.4684489e-34 1.2868316e-13 3.8943778e-25], sum to 1.0000
[2019-03-26 19:31:09,740] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5852
[2019-03-26 19:31:09,745] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 94.33333333333334, 1.0, 2.0, 0.3224694210718491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 506162.5699249672, 506162.5699249672, 167407.5349259211], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7446000.0000, 
sim time next is 7446600.0000, 
raw observation next is [21.25, 94.5, 1.0, 2.0, 0.3226904336105356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 506466.2105589872, 506466.2105589872, 167429.6081203992], 
processed observation next is [0.0, 0.17391304347826086, 0.20616113744075834, 0.945, 1.0, 1.0, 0.1839643778440188, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14068505848860757, 0.14068505848860757, 0.24989493749313316], 
reward next is 0.7501, 
noisyNet noise sample is [array([-0.3754264], dtype=float32), -0.8151154]. 
=============================================
[2019-03-26 19:31:10,629] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.0398905e-37 1.0000000e+00 0.0000000e+00 8.9410515e-18 3.2929135e-37], sum to 1.0000
[2019-03-26 19:31:10,643] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6735
[2019-03-26 19:31:10,654] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 94.33333333333334, 1.0, 2.0, 0.3411922987100115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 528292.002205022, 528292.002205022, 168945.619375232], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7460400.0000, 
sim time next is 7461000.0000, 
raw observation next is [21.9, 94.0, 1.0, 2.0, 0.343530330741215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 531024.3913743892, 531024.3913743892, 169139.5427582343], 
processed observation next is [0.0, 0.34782608695652173, 0.23696682464454974, 0.94, 1.0, 1.0, 0.20907268764001805, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14750677538177476, 0.14750677538177476, 0.2524470787436333], 
reward next is 0.7476, 
noisyNet noise sample is [array([-0.961258], dtype=float32), -0.052774042]. 
=============================================
[2019-03-26 19:31:10,685] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[83.82266 ]
 [83.79933 ]
 [83.769585]
 [83.71109 ]
 [83.675354]], R is [[83.75525665]
 [83.6655426 ]
 [83.57714844]
 [83.48993683]
 [83.40362549]].
[2019-03-26 19:31:12,615] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 199819: loss 0.0994
[2019-03-26 19:31:12,616] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 199819: learning rate 0.0010
[2019-03-26 19:31:12,623] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 199822: loss 0.0565
[2019-03-26 19:31:12,625] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 199822: learning rate 0.0010
[2019-03-26 19:31:12,718] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 199863: loss 0.0090
[2019-03-26 19:31:12,721] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 199863: learning rate 0.0010
[2019-03-26 19:31:12,774] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 199891: loss 0.0011
[2019-03-26 19:31:12,779] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 199891: learning rate 0.0010
[2019-03-26 19:31:12,844] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 199923: loss 0.0201
[2019-03-26 19:31:12,847] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 199923: learning rate 0.0010
[2019-03-26 19:31:12,879] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 199937: loss 0.0522
[2019-03-26 19:31:12,881] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 199937: learning rate 0.0010
[2019-03-26 19:31:12,966] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 199980: loss 0.0841
[2019-03-26 19:31:12,968] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 199981: learning rate 0.0010
[2019-03-26 19:31:12,982] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 199985: loss 0.0986
[2019-03-26 19:31:12,988] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 199986: learning rate 0.0010
[2019-03-26 19:31:13,003] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 199997: loss 0.0839
[2019-03-26 19:31:13,012] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-26 19:31:13,013] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 199999: learning rate 0.0010
[2019-03-26 19:31:13,015] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:31:13,016] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:31:13,016] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:31:13,017] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:31:13,018] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:31:13,020] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:31:13,021] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:31:13,021] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:31:13,024] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:31:13,025] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:31:13,039] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run9
[2019-03-26 19:31:13,039] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run9
[2019-03-26 19:31:13,074] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run9
[2019-03-26 19:31:13,076] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run9
[2019-03-26 19:31:13,092] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run9
[2019-03-26 19:31:21,496] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.6070264]
[2019-03-26 19:31:21,496] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.16666666666666, 69.33333333333333, 1.0, 2.0, 0.2333689015814524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 387123.1741125777, 387123.1741125777, 159109.8274958585]
[2019-03-26 19:31:21,499] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:31:21,501] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.5784850e-32 1.0000000e+00 1.0886047e-36 1.4688776e-15 1.5132257e-34], sampled 0.9976152573368635
[2019-03-26 19:32:44,941] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.6070264]
[2019-03-26 19:32:44,942] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.985106985, 78.99269397500001, 1.0, 2.0, 0.5118028200446193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 715170.4750763668, 715170.4750763674, 185466.3905432429]
[2019-03-26 19:32:44,944] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:32:44,946] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6922775e-34 1.0000000e+00 0.0000000e+00 1.0305589e-16 1.9656883e-37], sampled 0.8201178360610929
[2019-03-26 19:32:45,780] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.6070264]
[2019-03-26 19:32:45,781] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.90744029, 74.21294503499999, 1.0, 2.0, 0.9556587161395896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129125802556, 1335785.024948088, 1335785.024948088, 285708.3225785705]
[2019-03-26 19:32:45,783] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:32:45,786] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.7639795e-34 1.0000000e+00 0.0000000e+00 1.5056117e-14 1.6893990e-36], sampled 0.04252585576543089
[2019-03-26 19:33:07,150] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.1213 3007729742.9886 1766.0000
[2019-03-26 19:33:07,274] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.0653 2927317329.7462 1338.0000
[2019-03-26 19:33:07,353] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.8889 2779256332.3854 933.0000
[2019-03-26 19:33:07,367] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.9993 3164535723.4518 1776.0000
[2019-03-26 19:33:07,464] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 19:33:08,482] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 200000, evaluation results [200000.0, 7881.99929362893, 3164535723.451782, 1776.0, 8255.065342017213, 2927317329.746172, 1338.0, 8659.888853383243, 2779256332.3854055, 933.0, 7998.121261362489, 3007729742.9886193, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 19:33:08,509] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 200013: loss 0.0670
[2019-03-26 19:33:08,513] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 200013: learning rate 0.0010
[2019-03-26 19:33:08,599] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 200061: loss 0.0047
[2019-03-26 19:33:08,602] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 200062: learning rate 0.0010
[2019-03-26 19:33:08,624] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 200073: loss 0.0042
[2019-03-26 19:33:08,628] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 200073: learning rate 0.0010
[2019-03-26 19:33:08,633] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 200075: loss 0.0025
[2019-03-26 19:33:08,637] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 200075: learning rate 0.0010
[2019-03-26 19:33:08,685] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 200089: loss 0.0285
[2019-03-26 19:33:08,688] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 200091: learning rate 0.0010
[2019-03-26 19:33:08,709] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 200100: loss 0.0494
[2019-03-26 19:33:08,712] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 200103: learning rate 0.0010
[2019-03-26 19:33:08,830] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 200159: loss 0.0160
[2019-03-26 19:33:08,832] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 200159: learning rate 0.0010
[2019-03-26 19:33:09,012] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.9040939e-31 1.0000000e+00 6.6129910e-34 2.6993279e-17 2.8875981e-37], sum to 1.0000
[2019-03-26 19:33:09,021] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0901
[2019-03-26 19:33:09,026] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 90.66666666666667, 1.0, 2.0, 0.4049397626363604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 596156.6687155137, 596156.6687155131, 173942.5359921775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7510800.0000, 
sim time next is 7511400.0000, 
raw observation next is [23.75, 91.0, 1.0, 2.0, 0.4047130699651731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 595962.373732491, 595962.373732491, 173928.9426337174], 
processed observation next is [0.0, 0.9565217391304348, 0.3246445497630332, 0.91, 1.0, 1.0, 0.2827868312833411, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16554510381458085, 0.16554510381458085, 0.2595954367667424], 
reward next is 0.7404, 
noisyNet noise sample is [array([1.297284], dtype=float32), -1.0079561]. 
=============================================
[2019-03-26 19:33:14,735] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.2243197e-29 1.0000000e+00 4.3403006e-33 7.6819341e-12 9.8850925e-36], sum to 1.0000
[2019-03-26 19:33:14,744] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7646
[2019-03-26 19:33:14,749] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.86666666666667, 95.0, 1.0, 2.0, 0.6949796039538882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 998002.8077480583, 998002.807748059, 223325.3828361238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7611000.0000, 
sim time next is 7611600.0000, 
raw observation next is [23.83333333333333, 95.0, 1.0, 2.0, 0.6089114984933186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 875500.9863100351, 875500.9863100344, 205584.2024865552], 
processed observation next is [1.0, 0.08695652173913043, 0.32859399684044216, 0.95, 1.0, 1.0, 0.5288090343292995, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2431947184194542, 0.243194718419454, 0.30684209326351525], 
reward next is 0.6932, 
noisyNet noise sample is [array([0.18061566], dtype=float32), -0.0017080868]. 
=============================================
[2019-03-26 19:33:14,994] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0726451e-26 1.0000000e+00 5.5204476e-28 4.2921149e-11 4.6086737e-35], sum to 1.0000
[2019-03-26 19:33:14,995] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8326
[2019-03-26 19:33:15,002] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.45, 93.5, 1.0, 2.0, 0.4621301086147338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 652642.8195107767, 652642.8195107767, 178766.3776916693], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7605000.0000, 
sim time next is 7605600.0000, 
raw observation next is [24.4, 93.66666666666667, 1.0, 2.0, 0.460480244997354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 651126.4823016808, 651126.4823016814, 178628.5229309812], 
processed observation next is [1.0, 0.0, 0.3554502369668246, 0.9366666666666668, 1.0, 1.0, 0.3499761987919928, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18086846730602246, 0.18086846730602263, 0.26660973571788243], 
reward next is 0.7334, 
noisyNet noise sample is [array([-1.0087589], dtype=float32), 1.3123673]. 
=============================================
[2019-03-26 19:33:18,197] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3247799e-19 6.6169418e-02 1.9720036e-20 9.3383062e-01 6.2449469e-14], sum to 1.0000
[2019-03-26 19:33:18,204] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9719
[2019-03-26 19:33:18,208] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.53333333333333, 80.66666666666667, 1.0, 2.0, 0.2551537666702446, 1.0, 2.0, 0.2551537666702446, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 713078.0192075577, 713078.0192075577, 241798.080558972], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7669200.0000, 
sim time next is 7669800.0000, 
raw observation next is [27.4, 81.5, 1.0, 2.0, 0.2547440593994971, 1.0, 2.0, 0.2547440593994971, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 711932.6306433236, 711932.630643323, 241729.7493410959], 
processed observation next is [1.0, 0.782608695652174, 0.4976303317535545, 0.815, 1.0, 1.0, 0.10210127638493628, 1.0, 1.0, 0.10210127638493628, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.1977590640675899, 0.1977590640675897, 0.36079067065835213], 
reward next is 0.6392, 
noisyNet noise sample is [array([-0.07201457], dtype=float32), -1.1450998]. 
=============================================
[2019-03-26 19:33:22,956] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.1587277e-27 1.3383657e-10 1.3286078e-27 1.0000000e+00 3.2704235e-26], sum to 1.0000
[2019-03-26 19:33:22,964] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0313
[2019-03-26 19:33:22,970] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.48333333333333, 60.16666666666666, 1.0, 2.0, 0.8243079078867558, 1.0, 2.0, 0.8243079078867558, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2305389.03070673, 2305389.03070673, 431871.6592440599], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7744200.0000, 
sim time next is 7744800.0000, 
raw observation next is [31.36666666666667, 60.33333333333334, 1.0, 2.0, 0.8571395145569499, 1.0, 2.0, 0.8571395145569499, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2397299.134791138, 2397299.134791139, 448639.2770827227], 
processed observation next is [1.0, 0.6521739130434783, 0.6856240126382308, 0.6033333333333334, 1.0, 1.0, 0.8278789332011445, 1.0, 1.0, 0.8278789332011445, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6659164263308717, 0.665916426330872, 0.6696108613174966], 
reward next is 0.3304, 
noisyNet noise sample is [array([0.08703613], dtype=float32), -3.2870307]. 
=============================================
[2019-03-26 19:33:25,847] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 207830: loss 0.1663
[2019-03-26 19:33:25,849] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 207830: learning rate 0.0010
[2019-03-26 19:33:25,850] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 207830: loss 0.0026
[2019-03-26 19:33:25,854] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 207831: learning rate 0.0010
[2019-03-26 19:33:25,964] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 207879: loss 0.0899
[2019-03-26 19:33:25,965] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 207879: learning rate 0.0010
[2019-03-26 19:33:26,086] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 207938: loss 0.0153
[2019-03-26 19:33:26,088] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 207938: loss 0.0149
[2019-03-26 19:33:26,090] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 207938: learning rate 0.0010
[2019-03-26 19:33:26,090] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 207938: learning rate 0.0010
[2019-03-26 19:33:26,115] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 207947: loss 0.0330
[2019-03-26 19:33:26,117] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 207947: learning rate 0.0010
[2019-03-26 19:33:26,197] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 207983: loss 0.0035
[2019-03-26 19:33:26,202] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 207984: learning rate 0.0010
[2019-03-26 19:33:26,237] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 208000: loss 0.0097
[2019-03-26 19:33:26,239] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 208000: loss 0.0076
[2019-03-26 19:33:26,241] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 208000: learning rate 0.0010
[2019-03-26 19:33:26,241] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 208000: learning rate 0.0010
[2019-03-26 19:33:26,251] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 208008: loss 0.0333
[2019-03-26 19:33:26,253] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 208008: learning rate 0.0010
[2019-03-26 19:33:26,260] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 208011: loss 0.0883
[2019-03-26 19:33:26,261] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 208011: learning rate 0.0010
[2019-03-26 19:33:26,303] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 208030: loss 0.0344
[2019-03-26 19:33:26,309] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 208030: learning rate 0.0010
[2019-03-26 19:33:26,374] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 208060: loss 0.0624
[2019-03-26 19:33:26,379] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 208061: learning rate 0.0010
[2019-03-26 19:33:26,488] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 208109: loss 0.0085
[2019-03-26 19:33:26,492] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 208110: learning rate 0.0010
[2019-03-26 19:33:26,505] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 208116: loss 0.0035
[2019-03-26 19:33:26,510] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 208119: learning rate 0.0010
[2019-03-26 19:33:26,530] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 208130: loss 0.1631
[2019-03-26 19:33:26,532] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 208130: learning rate 0.0010
[2019-03-26 19:33:26,646] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.9849975e-21 5.5106683e-04 3.7876663e-24 9.9944896e-01 2.1785044e-23], sum to 1.0000
[2019-03-26 19:33:26,653] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5108
[2019-03-26 19:33:26,657] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.9, 81.0, 1.0, 2.0, 0.5334225033405502, 1.0, 2.0, 0.5334225033405502, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1491296.24551342, 1491296.24551342, 310960.3327758114], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7806000.0000, 
sim time next is 7806600.0000, 
raw observation next is [28.0, 80.5, 1.0, 2.0, 0.6069257916430862, 1.0, 2.0, 0.6069257916430862, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1696953.035472877, 1696953.035472877, 336821.5385770213], 
processed observation next is [1.0, 0.34782608695652173, 0.5260663507109005, 0.805, 1.0, 1.0, 0.5264166164374533, 1.0, 1.0, 0.5264166164374533, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4713758431869103, 0.4713758431869103, 0.5027187142940616], 
reward next is 0.4973, 
noisyNet noise sample is [array([-0.19543442], dtype=float32), -0.8777913]. 
=============================================
[2019-03-26 19:33:28,903] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.740729e-33 2.807062e-16 7.341943e-36 1.000000e+00 2.778704e-29], sum to 1.0000
[2019-03-26 19:33:28,910] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3593
[2019-03-26 19:33:28,914] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.45, 73.0, 1.0, 2.0, 0.2411730988927984, 1.0, 2.0, 0.2411730988927984, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 673993.9830174411, 673993.9830174411, 239527.9214545118], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7839000.0000, 
sim time next is 7839600.0000, 
raw observation next is [29.3, 74.0, 1.0, 2.0, 0.2465408348413212, 1.0, 2.0, 0.2465408348413212, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 688999.7348681274, 688999.7348681267, 240387.8900386591], 
processed observation next is [1.0, 0.7391304347826086, 0.5876777251184835, 0.74, 1.0, 1.0, 0.09221787330279661, 1.0, 1.0, 0.09221787330279661, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.1913888152411465, 0.19138881524114632, 0.3587878955800882], 
reward next is 0.6412, 
noisyNet noise sample is [array([-0.6482472], dtype=float32), -1.3122107]. 
=============================================
[2019-03-26 19:33:35,780] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:33:35,780] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:33:35,781] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run2
[2019-03-26 19:33:35,830] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:33:35,830] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:33:35,832] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run2
[2019-03-26 19:33:35,864] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:33:35,865] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:33:35,866] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run2
[2019-03-26 19:33:35,918] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:33:35,918] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:33:35,919] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run2
[2019-03-26 19:33:35,982] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:33:35,982] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:33:35,983] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run2
[2019-03-26 19:33:36,029] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:33:36,029] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:33:36,031] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run2
[2019-03-26 19:33:36,051] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:33:36,051] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:33:36,052] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run2
[2019-03-26 19:33:36,066] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:33:36,066] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:33:36,069] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run2
[2019-03-26 19:33:36,092] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:33:36,093] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:33:36,094] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:33:36,094] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:33:36,092] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:33:36,094] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:33:36,097] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run2
[2019-03-26 19:33:36,115] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:33:36,116] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:33:36,117] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run2
[2019-03-26 19:33:36,137] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:33:36,138] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:33:36,138] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:33:36,138] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:33:36,139] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:33:36,152] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:33:36,151] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run2
[2019-03-26 19:33:36,153] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run2
[2019-03-26 19:33:36,150] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run2
[2019-03-26 19:33:36,193] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:33:36,246] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:33:36,248] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run2
[2019-03-26 19:33:36,289] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run2
[2019-03-26 19:33:36,346] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run2
[2019-03-26 19:33:42,362] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.279358e-32 4.380605e-10 9.868869e-33 1.000000e+00 3.604755e-29], sum to 1.0000
[2019-03-26 19:33:42,376] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1059
[2019-03-26 19:33:42,381] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.76666666666667, 82.33333333333334, 1.0, 2.0, 0.1854982270350368, 1.0, 2.0, 0.1854982270350368, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 562281.2726796047, 562281.2726796041, 239130.6161180436], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 71400.0000, 
sim time next is 72000.0000, 
raw observation next is [23.6, 83.0, 1.0, 2.0, 0.1844401989284413, 1.0, 2.0, 0.1844401989284413, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 560319.4096436611, 560319.4096436611, 239176.7165592999], 
processed observation next is [1.0, 0.8695652173913043, 0.3175355450236968, 0.83, 1.0, 1.0, 0.017397830034266606, 1.0, 1.0, 0.017397830034266606, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.15564428045657253, 0.15564428045657253, 0.35698017396910436], 
reward next is 0.6430, 
noisyNet noise sample is [array([0.69261676], dtype=float32), -1.5223521]. 
=============================================
[2019-03-26 19:33:42,406] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[61.197083]
 [61.264755]
 [61.317352]
 [61.334343]
 [61.377705]], R is [[61.17448425]
 [61.20582962]
 [61.23691177]
 [61.26767349]
 [61.29813766]].
[2019-03-26 19:33:46,152] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.5635518e-29 1.0000000e+00 7.6110159e-33 5.8137761e-09 7.0807539e-26], sum to 1.0000
[2019-03-26 19:33:46,159] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4827
[2019-03-26 19:33:46,164] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.56666666666667, 96.0, 1.0, 2.0, 0.7684594695932436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1153431.100435433, 1153431.100435433, 246902.4024887146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 145200.0000, 
sim time next is 145800.0000, 
raw observation next is [22.55, 96.0, 1.0, 2.0, 0.7553360354431568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1134393.075448903, 1134393.075448903, 243666.2669851979], 
processed observation next is [1.0, 0.6956521739130435, 0.26777251184834133, 0.96, 1.0, 1.0, 0.7052241390881406, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3151091876246953, 0.3151091876246953, 0.36368099550029537], 
reward next is 0.6363, 
noisyNet noise sample is [array([-1.7194943], dtype=float32), 0.2968115]. 
=============================================
[2019-03-26 19:33:48,087] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9006118e-26 1.0000000e+00 2.4482533e-29 6.9612510e-11 3.8676247e-33], sum to 1.0000
[2019-03-26 19:33:48,098] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7536
[2019-03-26 19:33:48,107] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 96.0, 1.0, 2.0, 0.2872358174508378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 462614.425810521, 462614.4258105204, 164451.5098731454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 183600.0000, 
sim time next is 184200.0000, 
raw observation next is [19.9, 96.0, 1.0, 2.0, 0.2869226459956143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 462157.2970068382, 462157.2970068382, 164420.2911017553], 
processed observation next is [0.0, 0.13043478260869565, 0.14218009478672985, 0.96, 1.0, 1.0, 0.1408706578260413, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12837702694634395, 0.12837702694634395, 0.24540341955485867], 
reward next is 0.7546, 
noisyNet noise sample is [array([0.5717278], dtype=float32), -0.8593364]. 
=============================================
[2019-03-26 19:33:53,384] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.3952954e-33 1.0000000e+00 0.0000000e+00 2.0259391e-12 0.0000000e+00], sum to 1.0000
[2019-03-26 19:33:53,394] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6623
[2019-03-26 19:33:53,399] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 92.0, 1.0, 2.0, 0.2855877156481978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 458898.6671830605, 458898.6671830605, 164194.8710287105], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 259200.0000, 
sim time next is 259800.0000, 
raw observation next is [20.5, 92.0, 1.0, 2.0, 0.2860133779352211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 459525.246932158, 459525.246932158, 164237.2160093909], 
processed observation next is [0.0, 0.0, 0.1706161137440759, 0.92, 1.0, 1.0, 0.13977515413882058, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12764590192559944, 0.12764590192559944, 0.24513017314834462], 
reward next is 0.7549, 
noisyNet noise sample is [array([-0.25824484], dtype=float32), -0.35549313]. 
=============================================
[2019-03-26 19:33:57,232] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7437765e-30 1.0000000e+00 7.9579119e-35 1.0750538e-11 3.8212533e-33], sum to 1.0000
[2019-03-26 19:33:57,239] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5891
[2019-03-26 19:33:57,244] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.28333333333333, 87.16666666666667, 1.0, 2.0, 0.2821006884393824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 459653.4282804437, 459653.4282804437, 164179.2948031635], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 353400.0000, 
sim time next is 354000.0000, 
raw observation next is [20.26666666666667, 87.33333333333334, 1.0, 2.0, 0.2630778905028809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 428627.6173948369, 428627.6173948369, 162163.38724596], 
processed observation next is [1.0, 0.08695652173913043, 0.15955766192733034, 0.8733333333333334, 1.0, 1.0, 0.11214203675045889, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11906322705412137, 0.11906322705412137, 0.24203490633725375], 
reward next is 0.7580, 
noisyNet noise sample is [array([-0.10405818], dtype=float32), -0.118289195]. 
=============================================
[2019-03-26 19:33:57,264] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[73.79076]
 [73.41694]
 [73.32149]
 [73.37953]
 [73.39729]], R is [[74.26456451]
 [74.27687836]
 [74.29251099]
 [74.30794525]
 [74.32320404]].
[2019-03-26 19:33:58,461] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.9902444e-38 1.0000000e+00 7.8820711e-37 7.0067075e-17 6.2152963e-33], sum to 1.0000
[2019-03-26 19:33:58,468] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9382
[2019-03-26 19:33:58,472] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.23333333333333, 87.66666666666667, 1.0, 2.0, 0.2570072202831113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 418694.6661228547, 418694.6661228547, 161545.5676615469], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 355200.0000, 
sim time next is 355800.0000, 
raw observation next is [20.21666666666667, 87.83333333333334, 1.0, 2.0, 0.2554891253045659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 416197.0379709683, 416197.0379709689, 161392.5708607158], 
processed observation next is [1.0, 0.08695652173913043, 0.15718799368088482, 0.8783333333333334, 1.0, 1.0, 0.1029989461500794, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11561028832526897, 0.11561028832526914, 0.24088443412047134], 
reward next is 0.7591, 
noisyNet noise sample is [array([-0.70654666], dtype=float32), -0.109363645]. 
=============================================
[2019-03-26 19:33:58,725] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.6702360e-29 1.0000000e+00 2.1309642e-34 3.0509408e-11 4.8123453e-33], sum to 1.0000
[2019-03-26 19:33:58,734] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7707
[2019-03-26 19:33:58,739] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.15, 88.5, 1.0, 2.0, 0.2560397980330008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 416996.7051916098, 416996.7051916098, 161443.9544366249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 358200.0000, 
sim time next is 358800.0000, 
raw observation next is [20.13333333333333, 88.66666666666666, 1.0, 2.0, 0.256341999938463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 417466.0831842221, 417466.0831842227, 161473.3418926864], 
processed observation next is [1.0, 0.13043478260869565, 0.15323854660347538, 0.8866666666666666, 1.0, 1.0, 0.10402650594995543, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11596280088450614, 0.1159628008845063, 0.24100498789953195], 
reward next is 0.7590, 
noisyNet noise sample is [array([0.89348316], dtype=float32), -1.2379932]. 
=============================================
[2019-03-26 19:33:59,003] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3830655e-30 9.9999976e-01 1.6003688e-29 1.8615304e-07 2.2997282e-36], sum to 1.0000
[2019-03-26 19:33:59,013] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4467
[2019-03-26 19:33:59,018] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.05, 89.5, 1.0, 2.0, 0.2628025625747001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 427839.1772719586, 427839.1772719593, 162122.1209462835], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 364200.0000, 
sim time next is 364800.0000, 
raw observation next is [20.1, 89.0, 1.0, 2.0, 0.2577437023177542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 419668.4362613151, 419668.4362613158, 161610.9908548877], 
processed observation next is [1.0, 0.21739130434782608, 0.15165876777251197, 0.89, 1.0, 1.0, 0.10571530399729417, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11657456562814307, 0.11657456562814326, 0.24121043411177268], 
reward next is 0.7588, 
noisyNet noise sample is [array([0.18982379], dtype=float32), -0.37258127]. 
=============================================
[2019-03-26 19:33:59,157] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.33528468e-32 1.00000000e+00 1.04377676e-32 3.33206401e-12
 7.49554161e-31], sum to 1.0000
[2019-03-26 19:33:59,163] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9991
[2019-03-26 19:33:59,169] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.28333333333333, 87.16666666666667, 1.0, 2.0, 0.2821006884393824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 459653.4282804437, 459653.4282804437, 164179.2948031635], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 353400.0000, 
sim time next is 354000.0000, 
raw observation next is [20.26666666666667, 87.33333333333334, 1.0, 2.0, 0.2630778905028809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 428627.6173948369, 428627.6173948369, 162163.38724596], 
processed observation next is [1.0, 0.08695652173913043, 0.15955766192733034, 0.8733333333333334, 1.0, 1.0, 0.11214203675045889, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11906322705412137, 0.11906322705412137, 0.24203490633725375], 
reward next is 0.7580, 
noisyNet noise sample is [array([-0.44869485], dtype=float32), -1.3694012]. 
=============================================
[2019-03-26 19:33:59,181] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[74.15755]
 [73.79345]
 [73.69024]
 [73.72632]
 [73.70961]], R is [[74.60416412]
 [74.61308289]
 [74.62535095]
 [74.6374588 ]
 [74.64942169]].
[2019-03-26 19:33:59,196] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.4088387e-31 1.0000000e+00 1.0044591e-35 4.1439838e-15 2.6559091e-31], sum to 1.0000
[2019-03-26 19:33:59,206] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9219
[2019-03-26 19:33:59,211] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.63333333333333, 77.0, 1.0, 2.0, 0.4164444057377109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 678175.7822122558, 678175.7822122563, 181800.0735574057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 379200.0000, 
sim time next is 379800.0000, 
raw observation next is [21.7, 76.5, 1.0, 2.0, 0.416809459428919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 678802.9976968332, 678802.9976968338, 181856.7601443976], 
processed observation next is [1.0, 0.391304347826087, 0.2274881516587678, 0.765, 1.0, 1.0, 0.2973607944926735, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18855638824912033, 0.1885563882491205, 0.27142800021551877], 
reward next is 0.7286, 
noisyNet noise sample is [array([-2.261164], dtype=float32), 1.5647647]. 
=============================================
[2019-03-26 19:34:06,517] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-26 19:34:06,519] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:34:06,520] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:34:06,520] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:34:06,521] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:34:06,523] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:34:06,524] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:34:06,526] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:34:06,526] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:34:06,527] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:34:06,528] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:34:06,547] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run10
[2019-03-26 19:34:06,566] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run10
[2019-03-26 19:34:06,584] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run10
[2019-03-26 19:34:06,584] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run10
[2019-03-26 19:34:06,625] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run10
[2019-03-26 19:34:25,209] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.44513226]
[2019-03-26 19:34:25,210] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.66666666666666, 35.33333333333334, 1.0, 2.0, 0.379837167541547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 630163.3183006065, 630163.318300607, 176371.4023408132]
[2019-03-26 19:34:25,211] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:34:25,214] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.00160244e-32 1.00000000e+00 3.11058753e-37 2.80273123e-14
 6.53733706e-36], sampled 0.3061231125539279
[2019-03-26 19:34:28,224] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.44513226]
[2019-03-26 19:34:28,225] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.8, 76.0, 1.0, 2.0, 0.2733311672238354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 445147.5125457734, 445147.5125457734, 163226.5794914156]
[2019-03-26 19:34:28,226] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:34:28,231] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.6429181e-34 1.0000000e+00 0.0000000e+00 2.3942860e-15 1.2338937e-37], sampled 0.8798718618618037
[2019-03-26 19:35:13,216] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.44513226]
[2019-03-26 19:35:13,217] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.877344875, 74.91632408333334, 1.0, 2.0, 0.4390548936840148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 620022.3447102415, 620022.3447102415, 175446.9363253427]
[2019-03-26 19:35:13,219] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:35:13,222] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.7547476e-33 1.0000000e+00 6.4563392e-38 5.9717210e-11 1.1082948e-35], sampled 0.5556845832682028
[2019-03-26 19:35:14,737] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.44513226]
[2019-03-26 19:35:14,737] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.75093975, 69.14109419, 1.0, 2.0, 0.5284047512450264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738377.3375093259, 738377.3375093259, 188165.6723840021]
[2019-03-26 19:35:14,742] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:35:14,744] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.9972390e-35 1.0000000e+00 0.0000000e+00 4.7545636e-15 2.4650449e-38], sampled 0.31634180211625984
[2019-03-26 19:35:22,952] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.44513226]
[2019-03-26 19:35:22,953] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.66666666666667, 61.0, 1.0, 2.0, 0.5816665999604069, 0.0, 2.0, 0.0, 1.0, 2.0, 1.010162524047185, 6.911199999999999, 6.9112, 168.9129401709992, 1626287.238157168, 1626287.238157168, 356031.0439259103]
[2019-03-26 19:35:22,954] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:35:22,956] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.9356879e-32 1.0000000e+00 7.6379914e-37 4.9795172e-12 5.3714622e-35], sampled 0.15834209774418695
[2019-03-26 19:35:23,125] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.44513226]
[2019-03-26 19:35:23,127] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.9, 68.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.967400653358294, 6.9112, 168.9123977855795, 1493652.778550328, 1453782.232663693, 311354.1324075502]
[2019-03-26 19:35:23,128] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:35:23,135] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0898980e-31 9.9999833e-01 2.0191829e-36 1.7271516e-06 1.7744030e-33], sampled 0.5250356423883387
[2019-03-26 19:35:26,210] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.44513226]
[2019-03-26 19:35:26,211] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.3, 81.5, 1.0, 2.0, 0.5864736439488645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 819552.4130455853, 819552.4130455846, 198252.4230382738]
[2019-03-26 19:35:26,212] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:35:26,214] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.0622899e-35 1.0000000e+00 0.0000000e+00 6.1541064e-15 3.4716320e-38], sampled 0.31523806781633423
[2019-03-26 19:35:37,461] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.44513226]
[2019-03-26 19:35:37,462] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.2, 87.0, 1.0, 2.0, 0.577553376354313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 807082.2800495934, 807082.2800495934, 196638.0128594472]
[2019-03-26 19:35:37,463] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:35:37,469] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.2009684e-35 1.0000000e+00 0.0000000e+00 3.0618009e-15 1.2084268e-38], sampled 0.9148706034619536
[2019-03-26 19:35:57,111] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.44513226]
[2019-03-26 19:35:57,112] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.326995775, 83.09618053, 1.0, 2.0, 0.5427437857664706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 758421.437934458, 758421.4379344586, 190564.8522492502]
[2019-03-26 19:35:57,113] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:35:57,116] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.3358574e-34 1.0000000e+00 0.0000000e+00 4.1568257e-14 1.3473116e-37], sampled 0.8522643770705564
[2019-03-26 19:35:59,419] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.44513226]
[2019-03-26 19:35:59,421] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.1, 65.33333333333334, 1.0, 2.0, 0.3528701720008025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 557452.4597651741, 557452.4597651741, 171546.1249492915]
[2019-03-26 19:35:59,422] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:35:59,424] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.1626727e-33 1.0000000e+00 1.1543350e-37 1.7934981e-14 2.4647652e-36], sampled 0.774426645359387
[2019-03-26 19:36:00,435] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8021.4236 3152804036.9439 1354.0000
[2019-03-26 19:36:00,494] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8157.2129 2991130225.4043 1303.0000
[2019-03-26 19:36:00,517] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8679.7703 2778098621.6261 875.0000
[2019-03-26 19:36:00,718] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8561.0997 2836249249.6923 942.0000
[2019-03-26 19:36:00,830] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8338.8784 2920956947.7594 1127.0000
[2019-03-26 19:36:01,845] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 225000, evaluation results [225000.0, 8021.423594827728, 3152804036.9438815, 1354.0, 8338.878372456653, 2920956947.7594094, 1127.0, 8679.770309961114, 2778098621.6261, 875.0, 8157.212896820122, 2991130225.4042697, 1303.0, 8561.099679786716, 2836249249.692307, 942.0]
[2019-03-26 19:36:12,370] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.0360477e-33 1.0000000e+00 2.3210570e-36 1.1685750e-14 4.5239001e-34], sum to 1.0000
[2019-03-26 19:36:12,378] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3640
[2019-03-26 19:36:12,389] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.18333333333333, 61.33333333333333, 1.0, 2.0, 0.2504187298447559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 412273.4695163005, 412273.4695163011, 160939.509386387], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 670200.0000, 
sim time next is 670800.0000, 
raw observation next is [22.96666666666667, 62.66666666666667, 1.0, 2.0, 0.2497542569032178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 411159.580403137, 411159.5804031377, 160874.469992949], 
processed observation next is [1.0, 0.782608695652174, 0.2875197472353872, 0.6266666666666667, 1.0, 1.0, 0.09608946614845515, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11421099455642696, 0.11421099455642715, 0.24011114924320745], 
reward next is 0.7599, 
noisyNet noise sample is [array([-0.32160935], dtype=float32), -0.039344378]. 
=============================================
[2019-03-26 19:36:13,163] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8031703e-29 1.0000000e+00 3.2074679e-37 1.5065748e-13 4.5088079e-34], sum to 1.0000
[2019-03-26 19:36:13,170] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6963
[2019-03-26 19:36:13,177] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 82.66666666666667, 1.0, 2.0, 0.2393789772093673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 395749.9689925067, 395749.9689925067, 159798.8369622887], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 682800.0000, 
sim time next is 683400.0000, 
raw observation next is [19.6, 83.33333333333333, 1.0, 2.0, 0.2397787823615639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 396477.27191647, 396477.2719164694, 159832.2482227832], 
processed observation next is [1.0, 0.9130434782608695, 0.127962085308057, 0.8333333333333333, 1.0, 1.0, 0.08407082212236615, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11013257553235278, 0.1101325755323526, 0.238555594362363], 
reward next is 0.7614, 
noisyNet noise sample is [array([0.2628675], dtype=float32), 0.717613]. 
=============================================
[2019-03-26 19:36:15,050] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.2644544e-36 1.0000000e+00 3.4867888e-38 1.1478579e-15 0.0000000e+00], sum to 1.0000
[2019-03-26 19:36:15,061] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3959
[2019-03-26 19:36:15,066] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.55, 92.0, 1.0, 2.0, 0.2250363663102666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 375212.4245053321, 375212.4245053321, 157944.9050268299], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 707400.0000, 
sim time next is 708000.0000, 
raw observation next is [17.53333333333333, 92.0, 1.0, 2.0, 0.2172313405602214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 362233.1496192599, 362233.1496192593, 157244.0798844782], 
processed observation next is [1.0, 0.17391304347826086, 0.030015797788309612, 0.92, 1.0, 1.0, 0.05690522959062817, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1006203193386833, 0.10062031933868314, 0.23469265654399732], 
reward next is 0.7653, 
noisyNet noise sample is [array([-0.24530809], dtype=float32), 0.029432073]. 
=============================================
[2019-03-26 19:36:15,078] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[79.2732 ]
 [79.28745]
 [79.31722]
 [79.35752]
 [79.35288]], R is [[79.16057587]
 [79.13323212]
 [79.10655975]
 [79.07912445]
 [79.05387115]].
[2019-03-26 19:36:21,373] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2819799e-37 1.0000000e+00 9.8077167e-36 1.5040474e-14 1.2941823e-34], sum to 1.0000
[2019-03-26 19:36:21,383] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7200
[2019-03-26 19:36:21,388] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 62.0, 1.0, 2.0, 0.2895444917947173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 463480.6529531262, 463480.6529531256, 164493.9486541766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 820800.0000, 
sim time next is 821400.0000, 
raw observation next is [24.96666666666667, 62.16666666666667, 1.0, 2.0, 0.28930423503913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 463132.4665881591, 463132.4665881597, 164470.3522888233], 
processed observation next is [0.0, 0.5217391304347826, 0.3823064770932071, 0.6216666666666667, 1.0, 1.0, 0.14374004221581926, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12864790738559975, 0.12864790738559992, 0.2454781377445124], 
reward next is 0.7545, 
noisyNet noise sample is [array([0.87637687], dtype=float32), 0.40081584]. 
=============================================
[2019-03-26 19:36:24,541] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7235183e-33 1.0000000e+00 5.9789844e-36 1.5859174e-14 0.0000000e+00], sum to 1.0000
[2019-03-26 19:36:24,551] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8162
[2019-03-26 19:36:24,556] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.95, 88.5, 1.0, 2.0, 0.2873202962730949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 461280.7366350644, 461280.7366350638, 164354.9904660491], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 876600.0000, 
sim time next is 877200.0000, 
raw observation next is [20.93333333333333, 88.33333333333334, 1.0, 2.0, 0.2867807129147474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 460748.844830786, 460748.844830786, 164320.6354003196], 
processed observation next is [0.0, 0.13043478260869565, 0.19115323854660338, 0.8833333333333334, 1.0, 1.0, 0.14069965411415347, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1279857902307739, 0.1279857902307739, 0.24525467970196954], 
reward next is 0.7547, 
noisyNet noise sample is [array([0.17517975], dtype=float32), 0.24843884]. 
=============================================
[2019-03-26 19:36:32,256] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3372751e-26 1.0000000e+00 4.3232649e-25 9.2622993e-11 1.2204514e-26], sum to 1.0000
[2019-03-26 19:36:32,268] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4655
[2019-03-26 19:36:32,277] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 95.0, 1.0, 2.0, 0.4035655307059746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 622761.6777443201, 622761.6777443201, 177079.374243855], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 995400.0000, 
sim time next is 996000.0000, 
raw observation next is [21.76666666666667, 95.0, 1.0, 2.0, 0.4490403868515986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 693652.4545397687, 693652.4545397687, 183952.0066599745], 
processed observation next is [1.0, 0.5217391304347826, 0.23064770932069528, 0.95, 1.0, 1.0, 0.33619323717060073, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19268123737215798, 0.19268123737215798, 0.27455523382085745], 
reward next is 0.7254, 
noisyNet noise sample is [array([-0.08107157], dtype=float32), 0.50458574]. 
=============================================
[2019-03-26 19:36:32,287] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[64.594055]
 [64.46364 ]
 [64.2385  ]
 [64.38285 ]
 [64.39155 ]], R is [[64.652771  ]
 [64.74194336]
 [64.81443787]
 [64.82216644]
 [64.86049652]].
[2019-03-26 19:36:33,288] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.3936977e-30 1.0000000e+00 6.1716759e-35 5.3059515e-11 4.9090476e-37], sum to 1.0000
[2019-03-26 19:36:33,297] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3936
[2019-03-26 19:36:33,303] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 97.5, 1.0, 2.0, 0.3724396340667769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 564686.0933807458, 564686.0933807465, 171638.2772160558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1035000.0000, 
sim time next is 1035600.0000, 
raw observation next is [22.13333333333333, 97.33333333333333, 1.0, 2.0, 0.372787209659153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 564968.6092827584, 564968.6092827584, 171655.3101044312], 
processed observation next is [1.0, 1.0, 0.24802527646129527, 0.9733333333333333, 1.0, 1.0, 0.24432193934837712, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15693572480076623, 0.15693572480076623, 0.25620195537974805], 
reward next is 0.7438, 
noisyNet noise sample is [array([-0.65981334], dtype=float32), -0.14349985]. 
=============================================
[2019-03-26 19:36:33,640] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2980601e-32 1.0000000e+00 2.3554843e-38 7.9653246e-12 0.0000000e+00], sum to 1.0000
[2019-03-26 19:36:33,650] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7203
[2019-03-26 19:36:33,656] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.91666666666667, 97.16666666666667, 1.0, 2.0, 0.3622591237435236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 553264.9287388698, 553264.9287388698, 170782.7768147032], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1030200.0000, 
sim time next is 1030800.0000, 
raw observation next is [21.93333333333333, 97.33333333333334, 1.0, 2.0, 0.3636611244506445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 554782.474965627, 554782.4749656275, 170892.6030231996], 
processed observation next is [1.0, 0.9565217391304348, 0.23854660347551332, 0.9733333333333334, 1.0, 1.0, 0.23332665596463195, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15410624304600748, 0.15410624304600765, 0.25506358660179046], 
reward next is 0.7449, 
noisyNet noise sample is [array([-0.7458949], dtype=float32), -1.453248]. 
=============================================
[2019-03-26 19:36:38,201] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.2900703e-29 1.0000000e+00 8.7028982e-34 3.2277551e-12 1.0247158e-35], sum to 1.0000
[2019-03-26 19:36:38,210] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1840
[2019-03-26 19:36:38,216] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 67.16666666666667, 1.0, 2.0, 0.797217510878386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1231854.706438085, 1231854.706438085, 258606.5675795001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1093800.0000, 
sim time next is 1094400.0000, 
raw observation next is [25.7, 67.0, 1.0, 2.0, 0.7950108555506639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1229328.373533733, 1229328.373533734, 258107.6580123094], 
processed observation next is [1.0, 0.6956521739130435, 0.4170616113744076, 0.67, 1.0, 1.0, 0.7530251271694746, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.34148010375937027, 0.34148010375937055, 0.38523531046613346], 
reward next is 0.6148, 
noisyNet noise sample is [array([-1.8678237], dtype=float32), -1.0208259]. 
=============================================
[2019-03-26 19:36:38,837] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3054369e-29 1.0000000e+00 9.9262378e-37 1.9605717e-09 2.1728422e-36], sum to 1.0000
[2019-03-26 19:36:38,844] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8452
[2019-03-26 19:36:38,853] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 72.5, 1.0, 2.0, 0.3301714180145942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 516698.9302897274, 516698.9302897268, 168180.979037402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1104600.0000, 
sim time next is 1105200.0000, 
raw observation next is [24.2, 73.0, 1.0, 2.0, 0.3295946731302897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 516485.2663641399, 516485.2663641393, 168181.3163408892], 
processed observation next is [1.0, 0.8260869565217391, 0.3459715639810427, 0.73, 1.0, 1.0, 0.19228273871119236, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14346812954559443, 0.14346812954559424, 0.2510168900610287], 
reward next is 0.7490, 
noisyNet noise sample is [array([-1.0075576], dtype=float32), 0.67706996]. 
=============================================
[2019-03-26 19:36:45,615] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.9527164e-30 1.0000000e+00 2.9236140e-34 1.3102919e-12 2.0598215e-35], sum to 1.0000
[2019-03-26 19:36:45,623] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8010
[2019-03-26 19:36:45,628] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.86666666666667, 92.33333333333334, 1.0, 2.0, 0.3665101887854174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 569940.3009527042, 569940.3009527042, 172461.4239260066], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1221600.0000, 
sim time next is 1222200.0000, 
raw observation next is [21.85, 92.5, 1.0, 2.0, 0.3702202436027319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 575654.3116356224, 575654.311635623, 172952.9782742802], 
processed observation next is [1.0, 0.13043478260869565, 0.23459715639810438, 0.925, 1.0, 1.0, 0.24122920915991797, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15990397545433957, 0.1599039754543397, 0.2581387735437018], 
reward next is 0.7419, 
noisyNet noise sample is [array([0.8675472], dtype=float32), -1.8119738]. 
=============================================
[2019-03-26 19:36:46,815] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8430038e-30 1.0000000e+00 1.0240794e-34 2.4538225e-13 3.4514833e-22], sum to 1.0000
[2019-03-26 19:36:46,823] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7035
[2019-03-26 19:36:46,828] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 81.33333333333333, 1.0, 2.0, 0.7862657705120224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1155656.439618069, 1155656.43961807, 248331.3772217134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1240800.0000, 
sim time next is 1241400.0000, 
raw observation next is [25.38333333333333, 80.66666666666667, 1.0, 2.0, 0.790140451536843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1156353.602854636, 1156353.602854637, 248658.5106076122], 
processed observation next is [1.0, 0.34782608695652173, 0.4020537124802526, 0.8066666666666668, 1.0, 1.0, 0.7471571705263168, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.32120933412628777, 0.32120933412628805, 0.3711321053844958], 
reward next is 0.6289, 
noisyNet noise sample is [array([-0.38679972], dtype=float32), -0.32367596]. 
=============================================
[2019-03-26 19:36:56,848] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 2.517774e-28 0.000000e+00], sum to 1.0000
[2019-03-26 19:36:56,853] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6850
[2019-03-26 19:36:56,860] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.26666666666667, 70.66666666666667, 1.0, 2.0, 0.4270259918218965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 617269.5286702916, 617269.5286702916, 175605.094778121], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1433400.0000, 
sim time next is 1434000.0000, 
raw observation next is [27.33333333333334, 70.33333333333334, 1.0, 2.0, 0.4272811100127285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 617414.2181239652, 617414.2181239659, 175612.5894926342], 
processed observation next is [0.0, 0.6086956521739131, 0.4944707740916275, 0.7033333333333335, 1.0, 1.0, 0.30997724097919094, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17150394947887923, 0.17150394947887942, 0.2621083425263197], 
reward next is 0.7379, 
noisyNet noise sample is [array([-0.37195668], dtype=float32), -2.1923945]. 
=============================================
[2019-03-26 19:36:56,890] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[76.99966]
 [77.01521]
 [77.01755]
 [77.03636]
 [77.04506]], R is [[76.95127869]
 [76.9196701 ]
 [76.8883667 ]
 [76.85729218]
 [76.82642365]].
[2019-03-26 19:36:57,400] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 19:36:57,402] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:36:57,403] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:36:57,404] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:36:57,405] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:36:57,406] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:36:57,405] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:36:57,409] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:36:57,406] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:36:57,409] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:36:57,413] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:36:57,427] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run11
[2019-03-26 19:36:57,427] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run11
[2019-03-26 19:36:57,427] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run11
[2019-03-26 19:36:57,464] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run11
[2019-03-26 19:36:57,503] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run11
[2019-03-26 19:37:05,154] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.46746913]
[2019-03-26 19:37:05,155] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.43333333333333, 67.66666666666667, 1.0, 2.0, 0.4671205029577186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 766549.5944158662, 766549.5944158655, 190072.9993363132]
[2019-03-26 19:37:05,158] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:37:05,161] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2552738e-27 0.0000000e+00], sampled 0.03855521102761206
[2019-03-26 19:37:15,234] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.46746913]
[2019-03-26 19:37:15,235] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.60119179333334, 82.93034093000001, 1.0, 2.0, 0.345863040543175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 565905.2125560676, 565905.2125560676, 171935.3946906426]
[2019-03-26 19:37:15,237] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:37:15,242] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7459948e-28 0.0000000e+00], sampled 0.02120272179649807
[2019-03-26 19:37:32,401] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.46746913]
[2019-03-26 19:37:32,402] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.36205593666667, 97.38638660666666, 1.0, 2.0, 0.6170174908128062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 862252.4465108439, 862252.4465108432, 203954.7958005008]
[2019-03-26 19:37:32,404] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:37:32,408] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 8.135349e-29 0.000000e+00], sampled 0.22973213533975967
[2019-03-26 19:37:43,771] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.46746913]
[2019-03-26 19:37:43,771] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.0, 94.0, 1.0, 2.0, 0.5216300405108971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 824621.5375973925, 824621.5375973919, 198019.8620681615]
[2019-03-26 19:37:43,772] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:37:43,775] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.9123624e-28 0.0000000e+00], sampled 0.9402676855297691
[2019-03-26 19:38:10,196] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.46746913]
[2019-03-26 19:38:10,197] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 79.00000000000001, 1.0, 2.0, 0.4864589666265494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 679744.7718240013, 679744.7718240013, 181501.3452180053]
[2019-03-26 19:38:10,198] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:38:10,201] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 2.401028e-29 0.000000e+00], sampled 0.525652876708595
[2019-03-26 19:38:21,967] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.46746913]
[2019-03-26 19:38:21,968] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.83333333333334, 79.66666666666667, 1.0, 2.0, 0.5134237457774172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 717436.249416491, 717436.2494164916, 185726.2133214409]
[2019-03-26 19:38:21,969] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:38:21,971] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.00000e+00 1.00000e+00 0.00000e+00 5.38042e-29 0.00000e+00], sampled 0.33748217595865004
[2019-03-26 19:38:29,258] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.46746913]
[2019-03-26 19:38:29,259] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.7, 56.0, 1.0, 2.0, 1.035789288977966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9128407187875, 1447865.008114324, 1447865.008114324, 310024.5710436031]
[2019-03-26 19:38:29,262] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:38:29,264] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 4.339018e-29 0.000000e+00], sampled 0.7767335697394758
[2019-03-26 19:38:32,717] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.46746913]
[2019-03-26 19:38:32,718] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.4, 82.0, 1.0, 2.0, 0.5193917096283556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 725778.4742334208, 725778.4742334208, 186689.7429614227]
[2019-03-26 19:38:32,721] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:38:32,723] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 8.298743e-30 0.000000e+00], sampled 0.006510192969657047
[2019-03-26 19:38:52,829] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.46746913]
[2019-03-26 19:38:52,830] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.26666666666667, 78.66666666666667, 1.0, 2.0, 0.6975143622545229, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005975128257893, 6.9112, 168.9123160543568, 1871650.515170465, 1804414.03221323, 384109.7986651143]
[2019-03-26 19:38:52,832] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:38:52,836] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.5421030e-38 1.0000000e+00 0.0000000e+00 1.5538637e-26 0.0000000e+00], sampled 0.7698542923090625
[2019-03-26 19:38:52,836] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1871650.515170465 W.
[2019-03-26 19:38:55,049] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.4752 2927712708.6915 1338.0000
[2019-03-26 19:38:55,303] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7732 2779589745.4232 933.0000
[2019-03-26 19:38:55,307] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.9210 2842890288.6408 1131.0000
[2019-03-26 19:38:55,413] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7880.4024 3164387323.3700 1778.0000
[2019-03-26 19:38:55,498] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.3731 3008038374.3173 1766.0000
[2019-03-26 19:38:56,513] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 250000, evaluation results [250000.0, 7880.402365377816, 3164387323.3700466, 1778.0, 8254.475224188334, 2927712708.691521, 1338.0, 8660.773226357216, 2779589745.4231777, 933.0, 7998.373066976429, 3008038374.3172884, 1766.0, 8496.920990814182, 2842890288.6407876, 1131.0]
[2019-03-26 19:38:57,712] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 2.969424e-29 0.000000e+00], sum to 1.0000
[2019-03-26 19:38:57,721] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3644
[2019-03-26 19:38:57,727] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 89.33333333333333, 1.0, 2.0, 0.3907755687023597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 584580.0612230237, 584580.0612230243, 173168.24205628], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1453200.0000, 
sim time next is 1453800.0000, 
raw observation next is [23.25, 90.66666666666667, 1.0, 2.0, 0.3877274178202514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 581494.2746672592, 581494.2746672592, 172934.328901482], 
processed observation next is [0.0, 0.8260869565217391, 0.30094786729857825, 0.9066666666666667, 1.0, 1.0, 0.2623221901448812, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.161526187407572, 0.161526187407572, 0.25811093865892837], 
reward next is 0.7419, 
noisyNet noise sample is [array([1.1471168], dtype=float32), 0.027828598]. 
=============================================
[2019-03-26 19:39:00,641] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 1.250123e-26 0.000000e+00], sum to 1.0000
[2019-03-26 19:39:00,651] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5746
[2019-03-26 19:39:00,656] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.53333333333333, 98.16666666666667, 1.0, 2.0, 0.3148335086808646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 497406.8588087675, 497406.8588087681, 166822.593909154], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1483800.0000, 
sim time next is 1484400.0000, 
raw observation next is [20.46666666666667, 98.33333333333334, 1.0, 2.0, 0.3131027740343431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 495233.7151540142, 495233.7151540136, 166672.5821964107], 
processed observation next is [0.0, 0.17391304347826086, 0.16903633491311232, 0.9833333333333334, 1.0, 1.0, 0.1724129807642688, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13756492087611505, 0.13756492087611488, 0.2487650480543443], 
reward next is 0.7512, 
noisyNet noise sample is [array([0.6367755], dtype=float32), -0.76312006]. 
=============================================
[2019-03-26 19:39:06,837] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0868787e-36 1.0000000e+00 0.0000000e+00 2.4333489e-27 6.5790878e-37], sum to 1.0000
[2019-03-26 19:39:06,853] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6615
[2019-03-26 19:39:06,861] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.68333333333333, 85.0, 1.0, 2.0, 0.8268311027735775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1253689.908224907, 1253689.908224907, 263925.0723206759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1594200.0000, 
sim time next is 1594800.0000, 
raw observation next is [23.7, 85.0, 1.0, 2.0, 0.8333633007763968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1262923.366575425, 1262923.366575424, 265653.1000151281], 
processed observation next is [1.0, 0.4782608695652174, 0.3222748815165877, 0.85, 1.0, 1.0, 0.7992328925016828, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3508120462709514, 0.35081204627095114, 0.39649716420168374], 
reward next is 0.6035, 
noisyNet noise sample is [array([-1.2265798], dtype=float32), -0.33415455]. 
=============================================
[2019-03-26 19:39:09,592] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.5733132e-28 0.0000000e+00], sum to 1.0000
[2019-03-26 19:39:09,607] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1200
[2019-03-26 19:39:09,614] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 99.00000000000001, 1.0, 2.0, 0.4387657657414944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 632192.7737544909, 632192.7737544916, 177013.8418019125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1653600.0000, 
sim time next is 1654200.0000, 
raw observation next is [23.3, 99.0, 1.0, 2.0, 0.4301957118243803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 619853.3233610058, 619853.3233610058, 175798.5548519476], 
processed observation next is [1.0, 0.13043478260869565, 0.3033175355450238, 0.99, 1.0, 1.0, 0.3134888094269642, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17218147871139047, 0.17218147871139047, 0.2623859027641009], 
reward next is 0.7376, 
noisyNet noise sample is [array([-0.12908639], dtype=float32), 0.63241935]. 
=============================================
[2019-03-26 19:39:13,401] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.305302e-32 1.000000e+00 0.000000e+00 5.609507e-18 4.624014e-34], sum to 1.0000
[2019-03-26 19:39:13,406] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1387
[2019-03-26 19:39:13,411] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.05, 84.0, 1.0, 2.0, 0.5082964139928445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 710269.1412918553, 710269.141291856, 184906.389975793], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1711800.0000, 
sim time next is 1712400.0000, 
raw observation next is [26.93333333333333, 84.66666666666666, 1.0, 2.0, 0.5090827636249359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 711368.3166479467, 711368.3166479474, 185031.53148485], 
processed observation next is [1.0, 0.8260869565217391, 0.4755134281200631, 0.8466666666666666, 1.0, 1.0, 0.4085334501505251, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1976023101799852, 0.1976023101799854, 0.2761664649027612], 
reward next is 0.7238, 
noisyNet noise sample is [array([-0.08135161], dtype=float32), -0.7022805]. 
=============================================
[2019-03-26 19:39:18,713] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.9480355e-24 0.0000000e+00], sum to 1.0000
[2019-03-26 19:39:18,724] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2138
[2019-03-26 19:39:18,731] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 95.16666666666667, 1.0, 2.0, 0.3628187414379867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 558332.0404360032, 558332.0404360032, 171333.4046020497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1825800.0000, 
sim time next is 1826400.0000, 
raw observation next is [21.9, 95.33333333333334, 1.0, 2.0, 0.3455716688716803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 531477.8385304972, 531477.8385304979, 169093.2739835533], 
processed observation next is [1.0, 0.13043478260869565, 0.23696682464454974, 0.9533333333333335, 1.0, 1.0, 0.21153213117069913, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1476327329251381, 0.1476327329251383, 0.2523780208709751], 
reward next is 0.7476, 
noisyNet noise sample is [array([-2.5861042], dtype=float32), 0.6526745]. 
=============================================
[2019-03-26 19:39:21,351] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.0008134e-37 1.0000000e+00 0.0000000e+00 1.5916869e-22 0.0000000e+00], sum to 1.0000
[2019-03-26 19:39:21,358] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3265
[2019-03-26 19:39:21,368] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.48333333333333, 90.33333333333333, 1.0, 2.0, 0.8876414164202816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1275697.956631741, 1275697.956631741, 271685.1948351348], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1849800.0000, 
sim time next is 1850400.0000, 
raw observation next is [24.6, 90.0, 1.0, 2.0, 0.8642812292572144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1238442.543499014, 1238442.543499014, 264706.07610416], 
processed observation next is [1.0, 0.43478260869565216, 0.36492890995260674, 0.9, 1.0, 1.0, 0.8364834087436318, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.34401181763861505, 0.34401181763861505, 0.39508369567785073], 
reward next is 0.6049, 
noisyNet noise sample is [array([1.379238], dtype=float32), 0.48996627]. 
=============================================
[2019-03-26 19:39:26,134] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7983417e-29 1.0000000e+00 9.1628551e-35 7.7950440e-18 3.1477891e-33], sum to 1.0000
[2019-03-26 19:39:26,145] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5988
[2019-03-26 19:39:26,154] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1795029.086004036 W.
[2019-03-26 19:39:26,162] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.46666666666667, 74.33333333333333, 1.0, 2.0, 0.4279826299264294, 1.0, 2.0, 0.4279826299264294, 1.0, 2.0, 0.7204167782940138, 6.911200000000001, 6.9112, 170.5573041426782, 1795029.086004036, 1795029.086004035, 365375.9525064499], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1950000.0000, 
sim time next is 1950600.0000, 
raw observation next is [27.53333333333333, 74.16666666666667, 1.0, 2.0, 0.4253455118683497, 1.0, 2.0, 0.4253455118683497, 1.0, 2.0, 0.7161315218124976, 6.9112, 6.9112, 170.5573041426782, 1783959.374743096, 1783959.374743096, 363890.3470896698], 
processed observation next is [1.0, 0.5652173913043478, 0.5039494470774091, 0.7416666666666667, 1.0, 1.0, 0.307645195022108, 1.0, 1.0, 0.307645195022108, 1.0, 1.0, 0.6538189290396311, 0.0, 0.0, 0.8375144448122397, 0.4955442707619711, 0.4955442707619711, 0.5431199210293579], 
reward next is 0.4569, 
noisyNet noise sample is [array([-1.8603504], dtype=float32), 0.19003059]. 
=============================================
[2019-03-26 19:39:30,481] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8265146e-37 1.0000000e+00 0.0000000e+00 4.3996967e-25 0.0000000e+00], sum to 1.0000
[2019-03-26 19:39:30,494] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1673
[2019-03-26 19:39:30,498] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 96.66666666666666, 1.0, 2.0, 0.4660310343147669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 656733.6792914147, 656733.6792914141, 179160.3661694448], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2002800.0000, 
sim time next is 2003400.0000, 
raw observation next is [24.05, 97.0, 1.0, 2.0, 0.4661282528298522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 657108.7704664328, 657108.7704664321, 179205.3507496878], 
processed observation next is [0.0, 0.17391304347826086, 0.3388625592417062, 0.97, 1.0, 1.0, 0.35678102750584606, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18253021401845354, 0.18253021401845335, 0.26747067276072806], 
reward next is 0.7325, 
noisyNet noise sample is [array([0.1946915], dtype=float32), -0.86783767]. 
=============================================
[2019-03-26 19:39:42,717] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.41468370e-20 1.00000000e+00 4.06970817e-24 8.53961433e-12
 1.12029095e-26], sum to 1.0000
[2019-03-26 19:39:42,725] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1938
[2019-03-26 19:39:42,735] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2002618.204014954 W.
[2019-03-26 19:39:42,738] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.48333333333333, 76.5, 1.0, 2.0, 0.477431178583599, 1.0, 2.0, 0.477431178583599, 1.0, 2.0, 0.82914006829627, 6.9112, 6.9112, 170.5573041426782, 2002618.204014954, 2002618.204014954, 399889.6081769278], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2195400.0000, 
sim time next is 2196000.0000, 
raw observation next is [29.6, 76.0, 1.0, 2.0, 0.7145402727406491, 1.0, 2.0, 0.7145402727406491, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1998121.644423944, 1998121.644423944, 380413.4272646828], 
processed observation next is [1.0, 0.43478260869565216, 0.6018957345971565, 0.76, 1.0, 1.0, 0.6560726177598182, 1.0, 1.0, 0.6560726177598182, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5550337901177622, 0.5550337901177622, 0.5677812347234071], 
reward next is 0.4322, 
noisyNet noise sample is [array([0.19361964], dtype=float32), -0.41950598]. 
=============================================
[2019-03-26 19:39:42,755] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[38.532085]
 [39.23608 ]
 [40.66183 ]
 [40.828194]
 [41.030685]], R is [[38.64796066]
 [38.66463089]
 [38.6803093 ]
 [38.71601486]
 [38.76848221]].
[2019-03-26 19:39:43,264] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8171494e-14 9.9999940e-01 8.1183079e-18 5.5497628e-07 5.5798121e-20], sum to 1.0000
[2019-03-26 19:39:43,273] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6040
[2019-03-26 19:39:43,279] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2554134.042993798 W.
[2019-03-26 19:39:43,284] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.98333333333333, 66.16666666666667, 1.0, 2.0, 0.9131576161879676, 1.0, 1.0, 0.9131576161879676, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2554134.042993798, 2554134.042993798, 478722.2459018106], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2214600.0000, 
sim time next is 2215200.0000, 
raw observation next is [31.96666666666667, 66.33333333333334, 1.0, 2.0, 0.5751210127117099, 1.0, 2.0, 0.5751210127117099, 1.0, 1.0, 0.9987950036549798, 6.911199999999999, 6.9112, 170.5573041426782, 2412814.309264848, 2412814.309264849, 470980.1073749951], 
processed observation next is [1.0, 0.6521739130434783, 0.7140600315955767, 0.6633333333333334, 1.0, 1.0, 0.4880976056767589, 1.0, 1.0, 0.4880976056767589, 1.0, 0.5, 0.9985304922621704, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6702261970180133, 0.6702261970180136, 0.7029553841417837], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5580331], dtype=float32), 0.030614043]. 
=============================================
[2019-03-26 19:39:46,363] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0909001e-30 1.0000000e+00 2.8636434e-35 4.1155848e-20 4.9637911e-36], sum to 1.0000
[2019-03-26 19:39:46,372] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5968
[2019-03-26 19:39:46,377] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.86666666666667, 87.16666666666667, 1.0, 2.0, 0.6251125631082837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 873569.57527318, 873569.5752731793, 205508.0825212715], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2265000.0000, 
sim time next is 2265600.0000, 
raw observation next is [26.03333333333333, 86.33333333333334, 1.0, 2.0, 0.5980096843371455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 835679.4958897944, 835679.4958897944, 200367.9193378125], 
processed observation next is [1.0, 0.21739130434782608, 0.4328593996840442, 0.8633333333333334, 1.0, 1.0, 0.5156743184784885, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23213319330272067, 0.23213319330272067, 0.2990565960265858], 
reward next is 0.7009, 
noisyNet noise sample is [array([-0.43677256], dtype=float32), 0.87952083]. 
=============================================
[2019-03-26 19:39:51,330] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.5028668e-32 1.0000000e+00 1.6031053e-38 1.9437170e-19 5.6844244e-34], sum to 1.0000
[2019-03-26 19:39:51,337] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1697
[2019-03-26 19:39:51,343] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.95, 81.0, 1.0, 2.0, 0.5278805504544675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 737644.5803271668, 737644.5803271674, 188079.6796327491], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2338200.0000, 
sim time next is 2338800.0000, 
raw observation next is [27.9, 81.0, 1.0, 2.0, 0.5258523360577524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 734809.4335724213, 734809.4335724219, 187745.7522814385], 
processed observation next is [1.0, 0.043478260869565216, 0.5213270142180094, 0.81, 1.0, 1.0, 0.4287377542864486, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2041137315478948, 0.20411373154789497, 0.2802175407185649], 
reward next is 0.7198, 
noisyNet noise sample is [array([-0.24976288], dtype=float32), -1.0711559]. 
=============================================
[2019-03-26 19:39:52,011] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 19:39:52,015] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:39:52,016] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:39:52,018] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:39:52,019] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:39:52,019] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:39:52,022] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:39:52,024] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:39:52,025] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:39:52,025] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:39:52,027] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:39:52,038] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run12
[2019-03-26 19:39:52,058] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run12
[2019-03-26 19:39:52,078] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run12
[2019-03-26 19:39:52,079] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run12
[2019-03-26 19:39:52,097] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run12
[2019-03-26 19:40:36,595] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.5501025]
[2019-03-26 19:40:36,596] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.98814969666667, 98.83301161666665, 1.0, 2.0, 0.4271043988056772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 624367.795857928, 624367.7958579273, 176489.6271454376]
[2019-03-26 19:40:36,597] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:40:36,600] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.6868342e-29 1.0000000e+00 6.7433468e-33 9.1226863e-18 2.0745066e-33], sampled 0.7351778954102052
[2019-03-26 19:40:45,702] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.5501025]
[2019-03-26 19:40:45,703] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.01666666666667, 79.5, 1.0, 2.0, 0.5699665331176168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 796476.3295593641, 796476.3295593641, 195283.1322256087]
[2019-03-26 19:40:45,704] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:40:45,707] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.9526772e-29 1.0000000e+00 3.2846148e-33 6.2183555e-18 9.9806624e-34], sampled 0.6410999412376878
[2019-03-26 19:41:16,924] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.5501025]
[2019-03-26 19:41:16,926] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.87367448, 77.06643718, 1.0, 2.0, 0.7970113051879113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1115178.854408976, 1115178.854408977, 243352.589681289]
[2019-03-26 19:41:16,926] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:41:16,929] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.7187941e-27 1.0000000e+00 8.7637110e-31 1.2201131e-16 2.9310893e-31], sampled 0.3980072304769231
[2019-03-26 19:41:26,516] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.5501025]
[2019-03-26 19:41:26,517] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.74510152666667, 61.73774275000001, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.868140496262816, 6.9112, 168.9078847982536, 2133086.116900139, 1454219.977473657, 311348.6274760471]
[2019-03-26 19:41:26,517] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:41:26,519] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.4205488e-25 1.0000000e+00 5.7790272e-28 3.8770845e-15 2.1607913e-28], sampled 0.2591396902264995
[2019-03-26 19:41:26,520] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2133086.116900139 W.
[2019-03-26 19:41:46,025] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2741 3008104656.7243 1766.0000
[2019-03-26 19:41:46,096] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7878.8875 3164502873.7783 1778.0000
[2019-03-26 19:41:46,224] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.2748 2927846980.7461 1338.0000
[2019-03-26 19:41:46,384] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.6708 2779658361.4638 933.0000
[2019-03-26 19:41:46,454] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8190 2842958600.4139 1131.0000
[2019-03-26 19:41:47,468] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 275000, evaluation results [275000.0, 7878.887539409773, 3164502873.778303, 1778.0, 8254.274818136657, 2927846980.7461457, 1338.0, 8660.670814356308, 2779658361.463785, 933.0, 7998.274138010797, 3008104656.724262, 1766.0, 8496.819032943851, 2842958600.4139094, 1131.0]
[2019-03-26 19:41:50,398] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.4223817e-27 1.0000000e+00 2.6178184e-30 4.1581360e-17 2.3555479e-30], sum to 1.0000
[2019-03-26 19:41:50,407] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5903
[2019-03-26 19:41:50,414] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.85, 80.0, 1.0, 2.0, 0.5530945427769307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 772890.6815433354, 772890.681543336, 192332.9599338659], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2422200.0000, 
sim time next is 2422800.0000, 
raw observation next is [28.8, 80.0, 1.0, 2.0, 0.5516432354518738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 770861.8983163009, 770861.8983163016, 192083.0174811172], 
processed observation next is [1.0, 0.043478260869565216, 0.5639810426540285, 0.8, 1.0, 1.0, 0.4598111270504503, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21412830508786138, 0.21412830508786157, 0.2866910708673391], 
reward next is 0.7133, 
noisyNet noise sample is [array([-2.3842208], dtype=float32), -0.36829123]. 
=============================================
[2019-03-26 19:41:51,006] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.0443102e-27 1.0000000e+00 2.6610697e-32 4.7280439e-17 3.3237056e-30], sum to 1.0000
[2019-03-26 19:41:51,014] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0473
[2019-03-26 19:41:51,019] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.3, 76.33333333333334, 1.0, 2.0, 0.5818054634330592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813026.4883291817, 813026.4883291817, 197405.3537050742], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2409000.0000, 
sim time next is 2409600.0000, 
raw observation next is [30.2, 76.66666666666667, 1.0, 2.0, 0.5805956275692469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 811335.1940017126, 811335.1940017126, 197186.6646657431], 
processed observation next is [1.0, 0.9130434782608695, 0.6303317535545023, 0.7666666666666667, 1.0, 1.0, 0.49469352719186366, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22537088722269794, 0.22537088722269794, 0.2943084547249897], 
reward next is 0.7057, 
noisyNet noise sample is [array([-0.82495344], dtype=float32), 3.0079355]. 
=============================================
[2019-03-26 19:41:53,131] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4739405e-14 9.9999940e-01 1.3319318e-18 5.9476537e-07 3.6255432e-17], sum to 1.0000
[2019-03-26 19:41:53,141] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6768
[2019-03-26 19:41:53,148] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1892564.5855308 W.
[2019-03-26 19:41:53,154] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.2, 85.66666666666667, 1.0, 2.0, 0.676825747171379, 1.0, 2.0, 0.676825747171379, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1892564.5855308, 1892564.5855308, 364358.1095302784], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2473800.0000, 
sim time next is 2474400.0000, 
raw observation next is [27.3, 85.33333333333334, 1.0, 2.0, 0.8093195828956886, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.983694348723276, 6.9112, 168.9125253293782, 2028116.612810653, 1976686.758047834, 410960.6091517977], 
processed observation next is [1.0, 0.6521739130434783, 0.4928909952606636, 0.8533333333333334, 1.0, 1.0, 0.770264557705649, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.007249434872327587, 0.0, 0.829437827855938, 0.563365725780737, 0.5490796550132873, 0.6133740435101458], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.418655], dtype=float32), 0.8658317]. 
=============================================
[2019-03-26 19:41:53,589] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0360694e-16 9.9999905e-01 2.2746473e-17 9.7238558e-07 3.1912111e-13], sum to 1.0000
[2019-03-26 19:41:53,596] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8030
[2019-03-26 19:41:53,606] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2699822.083478765 W.
[2019-03-26 19:41:53,610] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.26666666666667, 89.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.666592849268682, 6.9112, 168.9031309717789, 2699822.083478765, 1454558.420505565, 310093.9101274606], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2467200.0000, 
sim time next is 2467800.0000, 
raw observation next is [26.3, 89.0, 1.0, 2.0, 0.7797534484110238, 1.0, 1.0, 0.7797534484110238, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2180667.668756892, 2180667.668756892, 410126.8824782255], 
processed observation next is [1.0, 0.5652173913043478, 0.4454976303317536, 0.89, 1.0, 1.0, 0.7346427089289443, 1.0, 0.5, 0.7346427089289443, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6057410190991367, 0.6057410190991367, 0.6121296753406351], 
reward next is 0.3879, 
noisyNet noise sample is [array([-0.5884629], dtype=float32), 0.6322978]. 
=============================================
[2019-03-26 19:42:01,532] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4977617e-33 1.0000000e+00 2.7711888e-36 1.4983280e-16 1.9049901e-32], sum to 1.0000
[2019-03-26 19:42:01,544] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9322
[2019-03-26 19:42:01,550] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.9, 90.66666666666667, 1.0, 2.0, 0.5097320774808656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712275.9414929863, 712275.9414929857, 185134.6251956974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2587800.0000, 
sim time next is 2588400.0000, 
raw observation next is [25.8, 91.0, 1.0, 2.0, 0.5082032329436343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 710138.8910195903, 710138.8910195897, 184890.9914090777], 
processed observation next is [1.0, 1.0, 0.42180094786729866, 0.91, 1.0, 1.0, 0.40747377463088474, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1972608030609973, 0.19726080306099714, 0.27595670359563834], 
reward next is 0.7240, 
noisyNet noise sample is [array([0.783618], dtype=float32), 0.46894926]. 
=============================================
[2019-03-26 19:42:13,658] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.3453255e-27 1.0000000e+00 2.4937099e-32 6.4866840e-14 2.3366572e-36], sum to 1.0000
[2019-03-26 19:42:13,668] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7125
[2019-03-26 19:42:13,675] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3733463671546196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 575119.4601687302, 575119.4601687302, 172793.2798823809], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2792400.0000, 
sim time next is 2793000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3799617438694608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 585306.2526241723, 585306.2526241723, 173689.40024381], 
processed observation next is [1.0, 0.30434782608695654, 0.2417061611374408, 0.94, 1.0, 1.0, 0.25296595646922987, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16258507017338117, 0.16258507017338117, 0.2592379108116567], 
reward next is 0.7408, 
noisyNet noise sample is [array([0.6886928], dtype=float32), -0.63968897]. 
=============================================
[2019-03-26 19:42:13,692] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[65.64075 ]
 [65.67388 ]
 [65.684135]
 [65.70428 ]
 [65.793076]], R is [[65.67507172]
 [65.76041412]
 [65.84661865]
 [65.93160248]
 [66.01382446]].
[2019-03-26 19:42:14,802] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.6039264e-25 1.0000000e+00 5.1307045e-29 2.0336833e-11 3.3154795e-27], sum to 1.0000
[2019-03-26 19:42:14,812] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0123
[2019-03-26 19:42:14,817] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.7713855513912249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1136277.973138236, 1136277.973138236, 244897.0288183452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2824200.0000, 
sim time next is 2824800.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.7195063087567697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1059854.113421362, 1059854.113421363, 232299.514397812], 
processed observation next is [1.0, 0.6956521739130435, 0.3364928909952607, 0.89, 1.0, 1.0, 0.662055793682855, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.29440392039482277, 0.29440392039482305, 0.34671569313106265], 
reward next is 0.6533, 
noisyNet noise sample is [array([-0.6319139], dtype=float32), -0.23593672]. 
=============================================
[2019-03-26 19:42:16,250] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7007165e-34 1.0000000e+00 7.5789575e-37 5.3711811e-18 9.2245800e-35], sum to 1.0000
[2019-03-26 19:42:16,262] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0498
[2019-03-26 19:42:16,269] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 89.83333333333334, 1.0, 2.0, 0.40969293241241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 604490.5301258386, 604490.5301258386, 174756.7883453504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2837400.0000, 
sim time next is 2838000.0000, 
raw observation next is [23.66666666666666, 90.66666666666667, 1.0, 2.0, 0.4064164472869222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 600874.1257394182, 600874.1257394182, 174456.3596540048], 
processed observation next is [1.0, 0.8695652173913043, 0.3206951026856238, 0.9066666666666667, 1.0, 1.0, 0.28483909311677374, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1669094793720606, 0.1669094793720606, 0.2603826263492609], 
reward next is 0.7396, 
noisyNet noise sample is [array([-1.1139628], dtype=float32), 1.2764039]. 
=============================================
[2019-03-26 19:42:16,283] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[78.05537]
 [78.08289]
 [78.07933]
 [78.10026]
 [78.14607]], R is [[78.0320816 ]
 [77.99092865]
 [77.95000458]
 [77.90979767]
 [77.87019348]].
[2019-03-26 19:42:16,310] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0037104e-31 1.0000000e+00 1.2093358e-37 8.1260667e-16 0.0000000e+00], sum to 1.0000
[2019-03-26 19:42:16,317] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2438
[2019-03-26 19:42:16,322] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 89.83333333333334, 1.0, 2.0, 0.40969293241241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 604490.5301258386, 604490.5301258386, 174756.7883453504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2837400.0000, 
sim time next is 2838000.0000, 
raw observation next is [23.66666666666666, 90.66666666666667, 1.0, 2.0, 0.4064164472869222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 600874.1257394182, 600874.1257394182, 174456.3596540048], 
processed observation next is [1.0, 0.8695652173913043, 0.3206951026856238, 0.9066666666666667, 1.0, 1.0, 0.28483909311677374, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1669094793720606, 0.1669094793720606, 0.2603826263492609], 
reward next is 0.7396, 
noisyNet noise sample is [array([0.520211], dtype=float32), 0.11297345]. 
=============================================
[2019-03-26 19:42:16,334] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[77.99145 ]
 [78.01669 ]
 [78.01097 ]
 [78.029785]
 [78.073425]], R is [[77.9705658 ]
 [77.93003082]
 [77.8897171 ]
 [77.85011292]
 [77.81110382]].
[2019-03-26 19:42:18,192] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4672481e-29 1.0000000e+00 8.0439807e-35 1.5861587e-15 2.9205033e-27], sum to 1.0000
[2019-03-26 19:42:18,203] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2746
[2019-03-26 19:42:18,210] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3648769842953998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 562068.2695467542, 562068.2695467548, 171666.4570487527], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2870400.0000, 
sim time next is 2871000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3708309786404282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 571243.1525737698, 571243.1525737704, 172456.0830141283], 
processed observation next is [1.0, 0.21739130434782608, 0.2417061611374408, 0.94, 1.0, 1.0, 0.24196503450653997, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15867865349271384, 0.15867865349271398, 0.25739713882705717], 
reward next is 0.7426, 
noisyNet noise sample is [array([0.3411901], dtype=float32), -0.2737472]. 
=============================================
[2019-03-26 19:42:18,221] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.67777 ]
 [70.662186]
 [70.7569  ]
 [70.714905]
 [70.70116 ]], R is [[70.70983124]
 [70.74651337]
 [70.77906036]
 [70.8188858 ]
 [70.85820007]].
[2019-03-26 19:42:21,547] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3902386e-30 1.0000000e+00 1.4375266e-35 9.6809884e-16 0.0000000e+00], sum to 1.0000
[2019-03-26 19:42:21,568] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2216
[2019-03-26 19:42:21,574] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 97.0, 1.0, 2.0, 0.31207332160021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 495274.6924825286, 495274.6924825286, 166706.4719911926], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2926800.0000, 
sim time next is 2927400.0000, 
raw observation next is [20.58333333333334, 96.50000000000001, 1.0, 2.0, 0.312656314054623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 495910.2715004249, 495910.2715004249, 166748.6065074436], 
processed observation next is [1.0, 0.9130434782608695, 0.17456556082148533, 0.9650000000000002, 1.0, 1.0, 0.1718750771742446, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13775285319456246, 0.13775285319456246, 0.24887851717528894], 
reward next is 0.7511, 
noisyNet noise sample is [array([-0.17568177], dtype=float32), -0.030081995]. 
=============================================
[2019-03-26 19:42:24,206] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.7220970e-31 1.0000000e+00 6.8098481e-29 6.0703527e-16 1.0213760e-26], sum to 1.0000
[2019-03-26 19:42:24,217] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6058
[2019-03-26 19:42:24,225] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.5808879828875657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 912708.653975482, 912708.653975482, 209038.4272906284], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2980800.0000, 
sim time next is 2981400.0000, 
raw observation next is [21.66666666666667, 90.0, 1.0, 2.0, 0.6884180546139048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1083074.385866981, 1083074.385866981, 232968.1364439665], 
processed observation next is [1.0, 0.5217391304347826, 0.22590837282780438, 0.9, 1.0, 1.0, 0.6246000657998853, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3008539960741614, 0.3008539960741614, 0.3477136364835321], 
reward next is 0.6523, 
noisyNet noise sample is [array([0.46639776], dtype=float32), 1.0256399]. 
=============================================
[2019-03-26 19:42:26,155] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2846470e-31 1.0000000e+00 0.0000000e+00 4.9183222e-16 1.4649784e-36], sum to 1.0000
[2019-03-26 19:42:26,163] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4002
[2019-03-26 19:42:26,168] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.5037235837189078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 796358.1181283569, 796358.1181283569, 194773.7812918411], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2997000.0000, 
sim time next is 2997600.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.5604322365157103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 886033.3068963632, 886033.3068963637, 205436.9159682793], 
processed observation next is [1.0, 0.6956521739130435, 0.19431279620853087, 0.94, 1.0, 1.0, 0.4704002849586871, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24612036302676754, 0.2461203630267677, 0.3066222626392228], 
reward next is 0.6934, 
noisyNet noise sample is [array([-0.11660741], dtype=float32), 1.4287704]. 
=============================================
[2019-03-26 19:42:30,707] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.0350336e-33 1.0000000e+00 6.6873414e-35 9.0568490e-16 4.4751984e-37], sum to 1.0000
[2019-03-26 19:42:30,719] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0610
[2019-03-26 19:42:30,725] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 97.0, 1.0, 2.0, 0.4176422193116753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 613899.0158457832, 613899.0158457839, 175577.3353345396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3094200.0000, 
sim time next is 3094800.0000, 
raw observation next is [23.0, 96.0, 1.0, 2.0, 0.4113425000650328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 607420.662355208, 607420.662355208, 175045.2776978148], 
processed observation next is [1.0, 0.8260869565217391, 0.28909952606635075, 0.96, 1.0, 1.0, 0.29077409646389496, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16872796176533555, 0.16872796176533555, 0.2612616085042012], 
reward next is 0.7387, 
noisyNet noise sample is [array([0.5821513], dtype=float32), 0.080227174]. 
=============================================
[2019-03-26 19:42:33,178] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.22499246e-31 1.00000000e+00 1.02839446e-32 4.00250918e-14
 1.90168981e-36], sum to 1.0000
[2019-03-26 19:42:33,188] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6162
[2019-03-26 19:42:33,196] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 99.0, 1.0, 2.0, 0.3832877370347389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 576040.0824591557, 576040.0824591557, 172482.5858854541], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3120600.0000, 
sim time next is 3121200.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.3798861857858509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 571866.868337525, 571866.868337525, 172141.3025700911], 
processed observation next is [1.0, 0.13043478260869565, 0.2417061611374408, 1.0, 1.0, 1.0, 0.2528749226335553, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15885190787153475, 0.15885190787153475, 0.2569273172687927], 
reward next is 0.7431, 
noisyNet noise sample is [array([-0.8677574], dtype=float32), -0.6993675]. 
=============================================
[2019-03-26 19:42:40,753] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1204451e-33 1.0000000e+00 1.0087588e-37 2.7633710e-18 6.1972635e-23], sum to 1.0000
[2019-03-26 19:42:40,763] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2010
[2019-03-26 19:42:40,768] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333333, 73.66666666666667, 1.0, 2.0, 0.5970997092513171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 834407.3656158712, 834407.3656158712, 200207.3675610389], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3260400.0000, 
sim time next is 3261000.0000, 
raw observation next is [31.16666666666667, 74.33333333333333, 1.0, 2.0, 0.5986154564799745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 836526.3562738885, 836526.3562738892, 200488.5665501464], 
processed observation next is [0.0, 0.7391304347826086, 0.6761453396524489, 0.7433333333333333, 1.0, 1.0, 0.5164041644337042, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23236843229830237, 0.23236843229830256, 0.2992366664927558], 
reward next is 0.7008, 
noisyNet noise sample is [array([-0.55436933], dtype=float32), 0.5791867]. 
=============================================
[2019-03-26 19:42:40,784] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[73.83919 ]
 [73.75872 ]
 [73.678116]
 [73.602646]
 [73.53036 ]], R is [[73.86384583]
 [73.8263855 ]
 [73.78914642]
 [73.75196075]
 [73.71491241]].
[2019-03-26 19:42:40,982] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1632782e-36 1.0000000e+00 0.0000000e+00 4.5986918e-23 0.0000000e+00], sum to 1.0000
[2019-03-26 19:42:40,991] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7261
[2019-03-26 19:42:40,997] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.4875924157084424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 681329.0846189507, 681329.0846189507, 181674.5114991432], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3280800.0000, 
sim time next is 3281400.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.4870881078076754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 680624.172679582, 680624.172679582, 181597.4172454706], 
processed observation next is [0.0, 1.0, 0.4786729857819906, 0.79, 1.0, 1.0, 0.3820338648285246, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18906227018877278, 0.18906227018877278, 0.27104092126189644], 
reward next is 0.7290, 
noisyNet noise sample is [array([-0.35009933], dtype=float32), 1.2153106]. 
=============================================
[2019-03-26 19:42:43,024] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 19:42:43,026] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:42:43,027] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:42:43,027] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:42:43,029] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:42:43,029] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:42:43,030] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:42:43,031] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:42:43,031] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:42:43,032] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:42:43,033] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:42:43,050] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run13
[2019-03-26 19:42:43,068] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run13
[2019-03-26 19:42:43,089] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run13
[2019-03-26 19:42:43,090] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run13
[2019-03-26 19:42:43,131] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run13
[2019-03-26 19:42:50,714] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.51371366]
[2019-03-26 19:42:50,715] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.83333333333334, 75.66666666666667, 1.0, 2.0, 0.7442067099726382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1060081.550339031, 1060081.550339031, 233407.1373075156]
[2019-03-26 19:42:50,715] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:42:50,719] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.0492504e-30 1.0000000e+00 2.0455011e-34 4.8568096e-18 1.3269323e-33], sampled 0.07112318957405939
[2019-03-26 19:42:52,094] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.51371366]
[2019-03-26 19:42:52,096] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.68382343, 72.73897732, 1.0, 2.0, 0.3083129118766029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 506326.2109428213, 506326.2109428207, 167248.3394750218]
[2019-03-26 19:42:52,097] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:42:52,099] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.1034146e-31 1.0000000e+00 8.2610685e-36 9.2809179e-19 5.7659484e-35], sampled 0.2447616610626966
[2019-03-26 19:43:10,217] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.51371366]
[2019-03-26 19:43:10,219] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.47269644, 83.27025453, 1.0, 2.0, 0.3514755733548119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 572416.5011928972, 572416.5011928972, 172595.4562828523]
[2019-03-26 19:43:10,221] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:43:10,226] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.6850189e-31 1.0000000e+00 1.6577039e-35 1.3291563e-18 1.1387882e-34], sampled 0.9626585381552712
[2019-03-26 19:43:21,634] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.51371366]
[2019-03-26 19:43:21,634] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.491495855, 85.559088255, 1.0, 2.0, 0.5236334838446604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731707.8117310618, 731707.8117310624, 187380.256771968]
[2019-03-26 19:43:21,635] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:43:21,640] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0243896e-31 1.0000000e+00 2.3077609e-36 4.8081041e-19 1.6582858e-35], sampled 0.06442424777772093
[2019-03-26 19:43:23,247] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.51371366]
[2019-03-26 19:43:23,248] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.9, 89.0, 1.0, 2.0, 0.763174694854204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1066602.718238556, 1066602.718238555, 235072.206888042]
[2019-03-26 19:43:23,249] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:43:23,251] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.5616093e-30 1.0000000e+00 9.3694172e-35 3.2470293e-18 6.1872609e-34], sampled 0.8580870777802683
[2019-03-26 19:43:23,324] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.51371366]
[2019-03-26 19:43:23,325] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.0, 83.0, 1.0, 2.0, 0.8153726605854218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1193582.024290414, 1193582.024290413, 255233.7849349417]
[2019-03-26 19:43:23,326] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:43:23,329] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.7725153e-29 1.0000000e+00 8.6749233e-34 1.0231394e-17 5.4451194e-33], sampled 0.21651215105791488
[2019-03-26 19:43:33,374] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.51371366]
[2019-03-26 19:43:33,374] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.99225129, 75.56929797, 1.0, 2.0, 0.6042691654356707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 844430.1892874138, 844430.1892874131, 201544.005419832]
[2019-03-26 19:43:33,375] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:43:33,378] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.1885689e-32 1.0000000e+00 3.9081349e-37 1.9242405e-19 2.9243249e-36], sampled 0.2587762342092116
[2019-03-26 19:44:31,874] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.51371366]
[2019-03-26 19:44:31,875] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.48333333333333, 69.16666666666667, 1.0, 2.0, 0.5819903225922749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813284.9130822163, 813284.9130822163, 197438.5707288102]
[2019-03-26 19:44:31,875] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:44:31,877] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.6686887e-32 1.0000000e+00 2.8605398e-37 1.6382167e-19 2.1557520e-36], sampled 0.7766475795040921
[2019-03-26 19:44:37,043] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7878.8875 3164502873.7783 1778.0000
[2019-03-26 19:44:37,261] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.1744 2927914232.3319 1338.0000
[2019-03-26 19:44:37,297] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.4620 2779798268.0133 933.0000
[2019-03-26 19:44:37,409] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.6111 2843097899.6270 1131.0000
[2019-03-26 19:44:37,444] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.4169 3008223289.7646 1765.0000
[2019-03-26 19:44:38,459] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 300000, evaluation results [300000.0, 7878.887539409773, 3164502873.778303, 1778.0, 8254.174442635573, 2927914232.3318715, 1338.0, 8660.46199861073, 2779798268.0133233, 933.0, 7998.416857356147, 3008223289.7646136, 1765.0, 8496.611123670547, 2843097899.6270223, 1131.0]
[2019-03-26 19:44:46,379] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.2481934e-35 1.0000000e+00 0.0000000e+00 3.1223142e-19 1.0686597e-32], sum to 1.0000
[2019-03-26 19:44:46,386] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9897
[2019-03-26 19:44:46,390] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333333, 77.33333333333333, 1.0, 2.0, 0.5157695029439897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 720715.2215249649, 720715.2215249649, 186104.0597786985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3440400.0000, 
sim time next is 3441000.0000, 
raw observation next is [28.16666666666667, 78.16666666666667, 1.0, 2.0, 0.516028016286732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 721076.5801110404, 721076.5801110397, 186145.6822240083], 
processed observation next is [1.0, 0.8260869565217391, 0.5339652448657191, 0.7816666666666667, 1.0, 1.0, 0.41690122444184574, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20029905003084456, 0.20029905003084436, 0.2778293764537437], 
reward next is 0.7222, 
noisyNet noise sample is [array([-0.5907329], dtype=float32), -2.2389314]. 
=============================================
[2019-03-26 19:44:46,413] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.43208 ]
 [69.16756 ]
 [69.883705]
 [70.524956]
 [70.8454  ]], R is [[67.57077026]
 [67.61729431]
 [67.66313934]
 [67.70825195]
 [67.75255585]].
[2019-03-26 19:44:46,699] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1548909e-28 1.0000000e+00 1.3266691e-33 4.8311272e-17 6.6071981e-32], sum to 1.0000
[2019-03-26 19:44:46,708] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8215
[2019-03-26 19:44:46,714] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5078598009336115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709658.8352535367, 709658.8352535367, 184836.8505617697], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3459600.0000, 
sim time next is 3460200.0000, 
raw observation next is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.5074331952403807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709062.5180404293, 709062.5180404286, 184768.9709951507], 
processed observation next is [1.0, 0.043478260869565216, 0.470774091627172, 0.8483333333333333, 1.0, 1.0, 0.4065460183619044, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19696181056678594, 0.19696181056678574, 0.2757745835748518], 
reward next is 0.7242, 
noisyNet noise sample is [array([0.7196079], dtype=float32), 0.836275]. 
=============================================
[2019-03-26 19:44:56,967] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.9862702e-27 1.0000000e+00 1.7346059e-32 4.1312735e-17 2.6211959e-30], sum to 1.0000
[2019-03-26 19:44:56,977] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3435
[2019-03-26 19:44:56,980] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.5234008158471993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 731382.5773714219, 731382.5773714213, 187343.8294250153], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3615600.0000, 
sim time next is 3616200.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.5245965319221539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733054.0070592929, 733054.0070592923, 187539.6007289533], 
processed observation next is [1.0, 0.8695652173913043, 0.5734597156398105, 0.74, 1.0, 1.0, 0.4272247372556071, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2036261130720258, 0.20362611307202563, 0.27990985183425865], 
reward next is 0.7201, 
noisyNet noise sample is [array([1.5712075], dtype=float32), 0.25470337]. 
=============================================
[2019-03-26 19:44:58,639] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0693717e-35 1.0000000e+00 1.1333352e-36 1.8795317e-24 0.0000000e+00], sum to 1.0000
[2019-03-26 19:44:58,650] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5235
[2019-03-26 19:44:58,654] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 79.83333333333334, 1.0, 2.0, 0.6748815702130709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 943150.6355299543, 943150.6355299538, 215513.4039092174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3643800.0000, 
sim time next is 3644400.0000, 
raw observation next is [26.66666666666667, 80.66666666666667, 1.0, 2.0, 0.6450945540044076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 901505.4521294803, 901505.4521294803, 209436.7986959239], 
processed observation next is [1.0, 0.17391304347826086, 0.4628751974723541, 0.8066666666666668, 1.0, 1.0, 0.5724030771137442, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.25041818114707787, 0.25041818114707787, 0.3125922368595879], 
reward next is 0.6874, 
noisyNet noise sample is [array([1.2213316], dtype=float32), 0.58232194]. 
=============================================
[2019-03-26 19:45:02,321] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.0210183e-33 1.0000000e+00 9.9412111e-36 2.9639517e-18 2.5983218e-35], sum to 1.0000
[2019-03-26 19:45:02,329] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3945
[2019-03-26 19:45:02,338] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 76.5, 1.0, 2.0, 0.5105657294396888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 713441.2392319824, 713441.2392319817, 185267.6695008594], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3706200.0000, 
sim time next is 3706800.0000, 
raw observation next is [28.0, 75.66666666666666, 1.0, 2.0, 0.5054199822890488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 706248.4168026005, 706248.4168026012, 184449.2617156579], 
processed observation next is [1.0, 0.9130434782608695, 0.5260663507109005, 0.7566666666666666, 1.0, 1.0, 0.4041204605892154, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19618011577850014, 0.19618011577850034, 0.27529740554575804], 
reward next is 0.7247, 
noisyNet noise sample is [array([1.4876658], dtype=float32), 1.4533738]. 
=============================================
[2019-03-26 19:45:13,031] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2916018e-36 1.0000000e+00 0.0000000e+00 1.3977656e-34 0.0000000e+00], sum to 1.0000
[2019-03-26 19:45:13,040] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4142
[2019-03-26 19:45:13,044] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 92.33333333333334, 1.0, 2.0, 0.5751620359736044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 803739.3186089606, 803739.3186089612, 196209.1342637642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3904800.0000, 
sim time next is 3905400.0000, 
raw observation next is [27.16666666666666, 93.16666666666667, 1.0, 2.0, 0.5728608688741702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 800522.4243562263, 800522.4243562256, 195798.149770918], 
processed observation next is [0.0, 0.17391304347826086, 0.4865718799368086, 0.9316666666666668, 1.0, 1.0, 0.48537454081225323, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22236734009895176, 0.22236734009895157, 0.292236044434206], 
reward next is 0.7078, 
noisyNet noise sample is [array([-1.5463502], dtype=float32), -0.4189116]. 
=============================================
[2019-03-26 19:45:13,415] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.00000e+00 1.00000e+00 0.00000e+00 5.70834e-37 0.00000e+00], sum to 1.0000
[2019-03-26 19:45:13,424] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6398
[2019-03-26 19:45:13,431] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.33333333333334, 63.33333333333333, 1.0, 2.0, 0.5572060011874463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 778638.1123257191, 778638.1123257191, 193045.2620676647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3868800.0000, 
sim time next is 3869400.0000, 
raw observation next is [32.16666666666666, 65.16666666666667, 1.0, 2.0, 0.5640217650058872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 788165.9753220618, 788165.9753220612, 194235.5952034292], 
processed observation next is [0.0, 0.782608695652174, 0.7235387045813582, 0.6516666666666667, 1.0, 1.0, 0.4747250180793821, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21893499314501716, 0.218934993145017, 0.28990387343795404], 
reward next is 0.7101, 
noisyNet noise sample is [array([-0.2908206], dtype=float32), 2.6171114]. 
=============================================
[2019-03-26 19:45:18,994] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.6074606e-23 1.0000000e+00 4.5270216e-28 3.2151431e-18 5.4052948e-28], sum to 1.0000
[2019-03-26 19:45:19,004] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0713
[2019-03-26 19:45:19,012] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2138510.552105604 W.
[2019-03-26 19:45:19,018] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.66666666666667, 80.66666666666667, 1.0, 2.0, 0.5097960844704535, 1.0, 2.0, 0.5097960844704535, 1.0, 1.0, 0.8853472065838045, 6.9112, 6.9112, 170.5573041426782, 2138510.552105604, 2138510.552105604, 421986.882642235], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3984000.0000, 
sim time next is 3984600.0000, 
raw observation next is [29.83333333333333, 79.83333333333334, 1.0, 2.0, 0.716816297697881, 1.0, 2.0, 0.716816297697881, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2004492.215103357, 2004492.215103357, 381414.6146209703], 
processed observation next is [1.0, 0.08695652173913043, 0.6129541864139019, 0.7983333333333335, 1.0, 1.0, 0.6588148165034711, 1.0, 1.0, 0.6588148165034711, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5568033930842659, 0.5568033930842659, 0.5692755442104034], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3939469], dtype=float32), 0.5625742]. 
=============================================
[2019-03-26 19:45:25,166] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.6308588e-33 1.0000000e+00 1.9747977e-37 8.9287996e-29 3.0781463e-32], sum to 1.0000
[2019-03-26 19:45:25,175] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8475
[2019-03-26 19:45:25,181] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.735177323856685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1027455.038609861, 1027455.038609861, 228622.2823998151], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4089600.0000, 
sim time next is 4090200.0000, 
raw observation next is [28.33333333333334, 83.16666666666667, 1.0, 2.0, 0.7867123272419863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1099515.62842214, 1099515.62842214, 240676.6542889805], 
processed observation next is [1.0, 0.34782608695652173, 0.5418641390205374, 0.8316666666666667, 1.0, 1.0, 0.7430269002915497, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.30542100789503884, 0.30542100789503884, 0.35921888699847837], 
reward next is 0.6408, 
noisyNet noise sample is [array([-0.03473308], dtype=float32), 1.2951]. 
=============================================
[2019-03-26 19:45:26,126] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0878073e-10 9.9999166e-01 1.9098988e-11 8.3716441e-06 1.4221298e-10], sum to 1.0000
[2019-03-26 19:45:26,135] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1287
[2019-03-26 19:45:26,142] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3852165.997336903 W.
[2019-03-26 19:45:26,146] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.0, 69.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 8.225852549125783, 6.9112, 170.5573041426782, 3852165.997336903, 2910426.89975149, 545756.9849536415], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4109400.0000, 
sim time next is 4110000.0000, 
raw observation next is [34.0, 68.33333333333333, 1.0, 2.0, 0.9742068934888737, 1.0, 2.0, 0.8076934862586996, 1.0, 1.0, 1.03, 7.005119363082537, 6.9112, 170.5573041426782, 3389853.247157119, 3322574.986985669, 621944.0089672077], 
processed observation next is [1.0, 0.5652173913043478, 0.8104265402843602, 0.6833333333333332, 1.0, 1.0, 0.9689239680588839, 1.0, 1.0, 0.7683054051309633, 1.0, 0.5, 1.0365853658536586, 0.0093919363082537, 0.0, 0.8375144448122397, 0.9416259019880887, 0.9229374963849081, 0.9282746402495637], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.02953551], dtype=float32), 1.3760713]. 
=============================================
[2019-03-26 19:45:26,161] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[25.091906]
 [26.44021 ]
 [29.45098 ]
 [30.03932 ]
 [29.54587 ]], R is [[23.18455887]
 [22.95271301]
 [22.72318649]
 [22.49595451]
 [22.27099609]].
[2019-03-26 19:45:27,253] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.7091091e-06 9.8271126e-01 9.0482260e-08 1.7271068e-02 1.4912298e-05], sum to 1.0000
[2019-03-26 19:45:27,263] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1357
[2019-03-26 19:45:27,273] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3333206.180504852 W.
[2019-03-26 19:45:27,278] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.0, 67.66666666666667, 1.0, 2.0, 0.9472485110458276, 1.0, 2.0, 0.7942142950371762, 1.0, 1.0, 1.03, 7.005117235575027, 6.9112, 170.5573041426782, 3333206.180504852, 3265929.444353572, 610808.1087722722], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4110600.0000, 
sim time next is 4111200.0000, 
raw observation next is [34.0, 67.0, 1.0, 2.0, 0.8821419030000531, 1.0, 2.0, 0.7616609910142892, 1.0, 2.0, 1.03, 7.0051120982729, 6.9112, 170.5573041426782, 3196409.667867403, 3129136.611774609, 585034.6356048723], 
processed observation next is [1.0, 0.6086956521739131, 0.8104265402843602, 0.67, 1.0, 1.0, 0.8580022927711484, 1.0, 1.0, 0.7128445674870953, 1.0, 1.0, 1.0365853658536586, 0.00939120982728996, 0.0, 0.8375144448122397, 0.8878915744076119, 0.8692046143818358, 0.8731860232908542], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2528922], dtype=float32), 1.088693]. 
=============================================
[2019-03-26 19:45:34,142] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 19:45:34,143] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:45:34,144] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:45:34,144] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:45:34,144] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:45:34,145] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:45:34,146] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:45:34,145] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:45:34,148] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:45:34,146] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:45:34,149] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:45:34,167] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run14
[2019-03-26 19:45:34,186] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run14
[2019-03-26 19:45:34,208] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run14
[2019-03-26 19:45:34,209] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run14
[2019-03-26 19:45:34,248] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run14
[2019-03-26 19:45:47,498] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.43806976]
[2019-03-26 19:45:47,499] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.9, 95.0, 1.0, 2.0, 0.3601322940614678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 554301.9946029171, 554301.9946029171, 170995.0183208259]
[2019-03-26 19:45:47,500] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:45:47,501] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.5216041e-32 1.0000000e+00 3.9912578e-36 9.3555790e-31 2.0450481e-27], sampled 0.4383402653231283
[2019-03-26 19:45:58,694] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.43806976]
[2019-03-26 19:45:58,696] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.86666666666667, 81.50000000000001, 1.0, 2.0, 0.6295651609637904, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.959298778426604, 6.9112, 168.9125992260001, 1760318.353819709, 1726195.49714845, 371015.8318274947]
[2019-03-26 19:45:58,699] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:45:58,700] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.8605958e-19 1.0000000e+00 2.2621667e-21 1.5672309e-15 3.2679493e-14], sampled 0.37039714437907534
[2019-03-26 19:45:58,702] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1760318.353819709 W.
[2019-03-26 19:46:10,804] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.43806976]
[2019-03-26 19:46:10,808] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.40457560666667, 98.5662635, 1.0, 2.0, 0.8659336775693491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104075, 1210299.142106853, 1210299.142106852, 260735.4812088263]
[2019-03-26 19:46:10,809] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:46:10,812] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.2192305e-20 1.0000000e+00 6.0571921e-23 2.3978430e-10 2.6789493e-10], sampled 0.5240895383972363
[2019-03-26 19:46:14,687] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.43806976]
[2019-03-26 19:46:14,689] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.98001037333333, 93.21646902333333, 1.0, 2.0, 0.4069499413355669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 605985.2979856096, 605985.2979856103, 175053.9793712816]
[2019-03-26 19:46:14,690] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:46:14,693] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.8775030e-30 1.0000000e+00 8.0612179e-34 8.5018685e-29 1.1462462e-25], sampled 0.04245320374227601
[2019-03-26 19:46:33,049] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.43806976]
[2019-03-26 19:46:33,050] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [32.10686914, 71.435059215, 1.0, 2.0, 0.7215329372138084, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005976628009609, 6.9112, 168.9123160332099, 1905261.424999761, 1838023.878079493, 389395.3592577161]
[2019-03-26 19:46:33,052] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:46:33,054] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6048074e-14 9.9429792e-01 2.2766207e-16 5.2363891e-03 4.6568571e-04], sampled 0.10610690707395731
[2019-03-26 19:46:33,055] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1905261.424999761 W.
[2019-03-26 19:46:54,594] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.43806976]
[2019-03-26 19:46:54,595] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.492323065, 66.514592055, 1.0, 2.0, 0.581137047127627, 0.0, 2.0, 0.0, 1.0, 2.0, 1.004250358055401, 6.9112, 6.9112, 168.9129383911252, 1624805.523004652, 1624805.523004652, 354615.3008448206]
[2019-03-26 19:46:54,598] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:46:54,601] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.3572859e-18 1.0000000e+00 4.4710712e-21 3.6529015e-13 1.9204232e-12], sampled 0.23993211212275944
[2019-03-26 19:47:13,952] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.43806976]
[2019-03-26 19:47:13,956] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.93333333333333, 73.66666666666667, 1.0, 2.0, 0.503212935920093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 703163.3806820402, 703163.3806820402, 184099.908005244]
[2019-03-26 19:47:13,957] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:47:13,960] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.6154895e-32 1.0000000e+00 7.8576675e-36 1.6633774e-30 3.4185588e-27], sampled 0.18889431173031113
[2019-03-26 19:47:17,815] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.43806976]
[2019-03-26 19:47:17,816] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.45, 91.5, 1.0, 2.0, 0.3612032419229793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 553953.6647652133, 553953.6647652133, 170909.5404931365]
[2019-03-26 19:47:17,817] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:47:17,820] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.2150861e-32 1.0000000e+00 1.0967207e-35 2.2080429e-30 4.4022606e-27], sampled 0.31956748568737814
[2019-03-26 19:47:19,511] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.43806976]
[2019-03-26 19:47:19,512] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.9, 55.0, 1.0, 2.0, 0.8972157904570675, 1.0, 2.0, 0.8972157904570675, 0.0, 2.0, 0.0, 6.9112, 6.9112, 169.0403247858759, 2509522.032018709, 2509522.032018709, 469698.6235986202]
[2019-03-26 19:47:19,512] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:47:19,516] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2496717e-14 9.9999905e-01 1.2696066e-16 5.5050185e-07 4.0523886e-07], sampled 0.8856667711983233
[2019-03-26 19:47:19,517] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2509522.032018709 W.
[2019-03-26 19:47:28,042] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.3246 3164148779.3123 1762.0000
[2019-03-26 19:47:28,166] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8269.3626 2926459124.5068 1299.0000
[2019-03-26 19:47:28,465] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8002.1387 3007612908.3438 1753.0000
[2019-03-26 19:47:28,537] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8663.8413 2779382418.2493 923.0000
[2019-03-26 19:47:28,623] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8499.8946 2842777660.4116 1125.0000
[2019-03-26 19:47:29,638] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 325000, evaluation results [325000.0, 7881.324609850836, 3164148779.3123465, 1762.0, 8269.362620689772, 2926459124.5068283, 1299.0, 8663.841263997903, 2779382418.249261, 923.0, 8002.138742436081, 3007612908.3437524, 1753.0, 8499.894645795499, 2842777660.411625, 1125.0]
[2019-03-26 19:47:31,985] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0577947e-11 7.1141609e-10 9.9226113e-11 1.1636207e-02 9.8836374e-01], sum to 1.0000
[2019-03-26 19:47:31,994] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6454
[2019-03-26 19:47:32,000] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.33333333333334, 73.66666666666667, 1.0, 2.0, 0.7467456834714521, 1.0, 2.0, 0.6939628812499886, 1.0, 2.0, 1.03, 7.005101418299161, 6.9112, 170.5573041426782, 2911974.52614532, 2844709.120552149, 536502.3453087397], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4267200.0000, 
sim time next is 4267800.0000, 
raw observation next is [33.5, 73.0, 1.0, 2.0, 0.7490925587988072, 1.0, 2.0, 0.6951363189136662, 1.0, 2.0, 1.03, 7.005101603377903, 6.9112, 170.5573041426782, 2916904.199464536, 2849638.661291933, 537285.4663738246], 
processed observation next is [1.0, 0.391304347826087, 0.7867298578199052, 0.73, 1.0, 1.0, 0.697701878070852, 1.0, 1.0, 0.6326943601369472, 1.0, 1.0, 1.0365853658536586, 0.009390160337790299, 0.0, 0.8375144448122397, 0.8102511665179266, 0.7915662948033148, 0.8019186065280964], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.0743437], dtype=float32), 0.5862135]. 
=============================================
[2019-03-26 19:47:37,236] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.2506384e-04 7.1869581e-04 1.2229119e-03 1.0030880e-01 8.9702451e-01], sum to 1.0000
[2019-03-26 19:47:37,245] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8054
[2019-03-26 19:47:37,249] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.66666666666667, 68.66666666666667, 1.0, 2.0, 0.6709408803613333, 1.0, 2.0, 0.6560604796949293, 1.0, 2.0, 1.03, 7.005095440983322, 6.9112, 170.5573041426782, 2752755.006293586, 2685493.882494893, 512308.195355847], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4371600.0000, 
sim time next is 4372200.0000, 
raw observation next is [33.0, 65.5, 1.0, 2.0, 0.6443549842063873, 1.0, 2.0, 0.6427675316174563, 1.0, 2.0, 1.03, 7.005093345008496, 6.9112, 170.5573041426782, 2696919.107918584, 2629659.485551917, 504328.5953787944], 
processed observation next is [1.0, 0.6086956521739131, 0.7630331753554502, 0.655, 1.0, 1.0, 0.571512029164322, 1.0, 1.0, 0.5695994356836822, 1.0, 1.0, 1.0365853658536586, 0.0093893345008496, 0.0, 0.8375144448122397, 0.7491441966440511, 0.7304609682088659, 0.7527292468340215], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.78302234], dtype=float32), -1.1834501]. 
=============================================
[2019-03-26 19:47:39,499] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.13753286e-35 1.00000000e+00 0.00000000e+00 3.57529644e-37
 2.30727498e-30], sum to 1.0000
[2019-03-26 19:47:39,505] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0596
[2019-03-26 19:47:39,519] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.5853686592339303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 818007.6861553146, 818007.6861553151, 198051.4949600791], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4422000.0000, 
sim time next is 4422600.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.5831738709746941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 814939.4617405524, 814939.4617405524, 197652.9735506554], 
processed observation next is [0.0, 0.17391304347826086, 0.5734597156398105, 0.84, 1.0, 1.0, 0.49779984454782417, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22637207270570903, 0.22637207270570903, 0.2950044381353066], 
reward next is 0.7050, 
noisyNet noise sample is [array([-1.0447993], dtype=float32), 0.9400379]. 
=============================================
[2019-03-26 19:47:39,757] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.6997981e-37 1.0000000e+00 0.0000000e+00 1.5941077e-34 6.9353113e-31], sum to 1.0000
[2019-03-26 19:47:39,769] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4729
[2019-03-26 19:47:39,772] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 84.0, 1.0, 2.0, 0.6162549675906934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861186.4247549446, 861186.4247549446, 203813.6635075772], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4413600.0000, 
sim time next is 4414200.0000, 
raw observation next is [29.83333333333333, 84.83333333333333, 1.0, 2.0, 0.617766594828498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 863299.7090065364, 863299.709006537, 204102.6997208977], 
processed observation next is [0.0, 0.08695652173913043, 0.6129541864139019, 0.8483333333333333, 1.0, 1.0, 0.539477825094576, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23980547472403788, 0.23980547472403804, 0.3046308951058175], 
reward next is 0.6954, 
noisyNet noise sample is [array([0.422734], dtype=float32), 0.6291323]. 
=============================================
[2019-03-26 19:47:40,877] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.2903444e-34 1.0000000e+00 5.6146554e-37 2.7487361e-33 6.0591905e-27], sum to 1.0000
[2019-03-26 19:47:40,888] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2446
[2019-03-26 19:47:40,892] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.5821232008402634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813470.6709085847, 813470.6709085847, 197462.7016949702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4429200.0000, 
sim time next is 4429800.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.5814528363471861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 812533.5317684455, 812533.5317684455, 197341.4723990394], 
processed observation next is [0.0, 0.2608695652173913, 0.5734597156398105, 0.84, 1.0, 1.0, 0.49572630885203145, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2257037588245682, 0.2257037588245682, 0.29453951104334236], 
reward next is 0.7055, 
noisyNet noise sample is [array([-1.174348], dtype=float32), 0.07772045]. 
=============================================
[2019-03-26 19:47:48,564] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.5159724e-31], sum to 1.0000
[2019-03-26 19:47:48,572] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3233
[2019-03-26 19:47:48,577] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.5498011070409204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 768286.7916807865, 768286.791680786, 191766.3772246501], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4575600.0000, 
sim time next is 4576200.0000, 
raw observation next is [28.0, 84.0, 1.0, 2.0, 0.5507766209849794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 769650.4593724336, 769650.4593724343, 191933.6903364013], 
processed observation next is [0.0, 1.0, 0.5260663507109005, 0.84, 1.0, 1.0, 0.45876701323491487, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21379179427012043, 0.21379179427012063, 0.2864681945319423], 
reward next is 0.7135, 
noisyNet noise sample is [array([-0.7951032], dtype=float32), 0.4419109]. 
=============================================
[2019-03-26 19:47:49,810] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4226297e-18 1.0000000e+00 1.5283897e-20 2.1762632e-18 1.1964194e-14], sum to 1.0000
[2019-03-26 19:47:49,819] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1028
[2019-03-26 19:47:49,823] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 94.0, 1.0, 2.0, 0.9628427586335631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129564741287, 1345832.983168381, 1345832.98316838, 287810.8730659269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4595400.0000, 
sim time next is 4596000.0000, 
raw observation next is [27.0, 94.0, 1.0, 2.0, 0.9548348081645575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104219, 1334632.672216664, 1334632.672216664, 285468.5487487307], 
processed observation next is [1.0, 0.17391304347826086, 0.4786729857819906, 0.94, 1.0, 1.0, 0.9455841062223583, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.829439945152258, 0.3707312978379622, 0.3707312978379622, 0.426072460819001], 
reward next is 0.5739, 
noisyNet noise sample is [array([-1.3424602], dtype=float32), 0.16611782]. 
=============================================
[2019-03-26 19:47:49,839] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[43.090946]
 [42.20814 ]
 [41.13074 ]
 [39.02421 ]
 [37.759895]], R is [[43.94240189]
 [44.07341003]
 [44.18955994]
 [43.74766541]
 [43.31018829]].
[2019-03-26 19:47:49,953] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5600287e-21 1.0000000e+00 1.7534098e-21 1.4861310e-21 7.2943123e-15], sum to 1.0000
[2019-03-26 19:47:49,963] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4659
[2019-03-26 19:47:49,968] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 94.0, 1.0, 2.0, 0.9976301526291429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9127890931008, 1394489.705403513, 1394489.705403513, 298209.3153583678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4600800.0000, 
sim time next is 4601400.0000, 
raw observation next is [28.16666666666667, 93.16666666666667, 1.0, 2.0, 0.9919741131948946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129564686264, 1386578.516435549, 1386578.516435549, 296494.8538506472], 
processed observation next is [1.0, 0.2608695652173913, 0.5339652448657191, 0.9316666666666668, 1.0, 1.0, 0.9903302568613188, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399449470229, 0.3851606990098747, 0.3851606990098747, 0.4425296326129063], 
reward next is 0.5575, 
noisyNet noise sample is [array([0.34263092], dtype=float32), 1.5581036]. 
=============================================
[2019-03-26 19:47:50,408] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.9172914e-13 1.0000000e+00 7.2090317e-14 7.8758408e-13 2.8934888e-09], sum to 1.0000
[2019-03-26 19:47:50,414] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2656
[2019-03-26 19:47:50,418] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 84.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.917175427952253, 6.9112, 168.9126476262729, 1457996.99829592, 1453757.831800237, 311356.4027389151], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4608000.0000, 
sim time next is 4608600.0000, 
raw observation next is [30.33333333333333, 82.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.876816102995563, 6.9112, 168.9075742834826, 2139243.665847994, 1454224.196534584, 311356.9084134893], 
processed observation next is [1.0, 0.34782608695652173, 0.6366508688783569, 0.825, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0965616102995563, 0.0, 0.8294135159539919, 0.5942343516244427, 0.4039511657040511, 0.4647118036022228], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4110755], dtype=float32), -0.5229207]. 
=============================================
[2019-03-26 19:47:51,689] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5007288e-04 9.9906439e-01 1.5920226e-04 1.3799885e-04 4.8824260e-04], sum to 1.0000
[2019-03-26 19:47:51,697] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0030
[2019-03-26 19:47:51,705] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2811337.727411381 W.
[2019-03-26 19:47:51,710] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 75.0, 1.0, 2.0, 0.6988333807667875, 1.0, 2.0, 0.6700067298976563, 1.0, 1.0, 1.03, 7.005097640169315, 6.9112, 170.5573041426782, 2811337.727411381, 2744075.028246303, 520962.1331197109], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4611600.0000, 
sim time next is 4612200.0000, 
raw observation next is [32.0, 75.0, 1.0, 2.0, 0.950085284387321, 1.0, 2.0, 0.950085284387321, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2657531.88098107, 2657531.88098107, 499564.4930825355], 
processed observation next is [1.0, 0.391304347826087, 0.7156398104265403, 0.75, 1.0, 1.0, 0.939861788418459, 1.0, 1.0, 0.939861788418459, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7382033002725195, 0.7382033002725195, 0.745618646391844], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1803639], dtype=float32), -0.7056616]. 
=============================================
[2019-03-26 19:47:53,590] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.6903483e-14 9.9999905e-01 3.2297274e-13 1.6125538e-10 9.0923379e-07], sum to 1.0000
[2019-03-26 19:47:53,600] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7105
[2019-03-26 19:47:53,606] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.3967171986199033, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6888477908373848, 6.9112, 6.9112, 168.9129440116671, 1108915.354420224, 1108915.354420224, 258131.7454598161], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4641000.0000, 
sim time next is 4641600.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.5250169095498837, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.91295650731, 733641.6318382611, 733641.6318382606, 187611.8095142981], 
processed observation next is [1.0, 0.7391304347826086, 0.6682464454976303, 0.7, 1.0, 1.0, 0.42773121632516103, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451369772, 0.20378934217729477, 0.2037893421772946, 0.28001762614074344], 
reward next is 0.7200, 
noisyNet noise sample is [array([0.85167927], dtype=float32), 0.54127043]. 
=============================================
[2019-03-26 19:47:55,921] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.4462679e-32 1.0000000e+00 3.0253827e-28 4.8975194e-32 5.0390409e-27], sum to 1.0000
[2019-03-26 19:47:55,931] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8910
[2019-03-26 19:47:55,938] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.6436963845000729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 899550.7135327054, 899550.7135327049, 209161.7714681792], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4686000.0000, 
sim time next is 4686600.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.6461895460635244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 903036.3300000359, 903036.3300000359, 209659.2655917867], 
processed observation next is [1.0, 0.21739130434782608, 0.4786729857819906, 0.89, 1.0, 1.0, 0.5737223446548486, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.25084342500001, 0.25084342500001, 0.31292427700266673], 
reward next is 0.6871, 
noisyNet noise sample is [array([-0.22927539], dtype=float32), -0.024042068]. 
=============================================
[2019-03-26 19:47:57,156] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6800098e-21 1.0000000e+00 2.2730464e-23 2.3950927e-20 2.2005286e-20], sum to 1.0000
[2019-03-26 19:47:57,164] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4480
[2019-03-26 19:47:57,169] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 84.83333333333333, 1.0, 2.0, 0.7939864652292251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1109687.335726188, 1109687.335726188, 242440.7364978558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4690200.0000, 
sim time next is 4690800.0000, 
raw observation next is [28.0, 84.0, 1.0, 2.0, 0.8087786723191052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1130372.149146386, 1130372.149146385, 246077.820539602], 
processed observation next is [1.0, 0.30434782608695654, 0.5260663507109005, 0.84, 1.0, 1.0, 0.7696128582157894, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31399226365177385, 0.31399226365177363, 0.36728032916358505], 
reward next is 0.6327, 
noisyNet noise sample is [array([1.4633604], dtype=float32), 0.35097796]. 
=============================================
[2019-03-26 19:48:08,485] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0621204e-17 4.3904921e-10 5.4360787e-15 9.7778119e-10 1.0000000e+00], sum to 1.0000
[2019-03-26 19:48:08,493] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9181
[2019-03-26 19:48:08,499] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.5184535352259216, 1.0, 2.0, 0.5184535352259216, 1.0, 2.0, 0.8979624925126707, 6.9112, 6.9112, 170.5573041426782, 2174863.999472658, 2174863.999472658, 427687.2658119448], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4879200.0000, 
sim time next is 4879800.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.5221109210202572, 1.0, 2.0, 0.5221109210202572, 1.0, 2.0, 0.9044955144469603, 6.9112, 6.9112, 170.5573041426782, 2190222.076022087, 2190222.076022087, 430349.4051160432], 
processed observation next is [1.0, 0.4782608695652174, 0.6682464454976303, 0.66, 1.0, 1.0, 0.4242300253256111, 1.0, 1.0, 0.4242300253256111, 1.0, 1.0, 0.8835311151792198, 0.0, 0.0, 0.8375144448122397, 0.6083950211172464, 0.6083950211172464, 0.6423125449493182], 
reward next is 0.3577, 
noisyNet noise sample is [array([1.0838884], dtype=float32), -0.17199343]. 
=============================================
[2019-03-26 19:48:08,758] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2093091e-28 1.0000000e+00 3.0156824e-27 1.1036910e-29 1.6447729e-19], sum to 1.0000
[2019-03-26 19:48:08,768] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7966
[2019-03-26 19:48:08,776] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 80.66666666666667, 1.0, 2.0, 0.4957283208447902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 692701.3618745023, 692701.3618745023, 182929.238097918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4915200.0000, 
sim time next is 4915800.0000, 
raw observation next is [27.0, 81.5, 1.0, 2.0, 0.4994365494971811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 697884.722825183, 697884.722825183, 183507.6516266482], 
processed observation next is [1.0, 0.9130434782608695, 0.4786729857819906, 0.815, 1.0, 1.0, 0.39691150541829046, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1938568674514397, 0.1938568674514397, 0.2738920173532063], 
reward next is 0.7261, 
noisyNet noise sample is [array([1.750205], dtype=float32), -0.18638344]. 
=============================================
[2019-03-26 19:48:25,288] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 19:48:25,291] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:48:25,291] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:48:25,291] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:48:25,294] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:48:25,296] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:48:25,293] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:48:25,299] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:48:25,299] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:48:25,297] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:48:25,302] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:48:25,313] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run15
[2019-03-26 19:48:25,314] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run15
[2019-03-26 19:48:25,333] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run15
[2019-03-26 19:48:25,368] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run15
[2019-03-26 19:48:25,386] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run15
[2019-03-26 19:48:38,331] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.5331946]
[2019-03-26 19:48:38,332] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.0, 92.0, 1.0, 2.0, 0.3515970389853695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 545285.1096504586, 545285.1096504593, 170352.5879151331]
[2019-03-26 19:48:38,333] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:48:38,336] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2426864e-34 1.0000000e+00 2.0310632e-33 1.7869827e-37 4.7633915e-28], sampled 0.2153306392471368
[2019-03-26 19:48:53,436] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.5331946]
[2019-03-26 19:48:53,438] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.96666666666667, 87.66666666666667, 1.0, 2.0, 0.5133279620350568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733619.3829110729, 733619.3829110729, 187791.8007409923]
[2019-03-26 19:48:53,438] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:48:53,441] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.6856761e-31 1.0000000e+00 3.9547448e-30 2.3284300e-33 6.6762655e-24], sampled 0.5719029002885039
[2019-03-26 19:49:09,477] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.5331946]
[2019-03-26 19:49:09,477] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.86666666666667, 54.5, 1.0, 2.0, 0.4237375895234432, 1.0, 2.0, 0.4237375895234432, 1.0, 2.0, 0.7358920608400205, 6.911200000000001, 6.9112, 169.0403247858759, 1777223.15414692, 1777223.154146919, 366122.804971087]
[2019-03-26 19:49:09,478] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:49:09,480] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.6185685e-15 7.9280423e-04 5.4451972e-13 1.0775772e-11 9.9920720e-01], sampled 0.5365449211121591
[2019-03-26 19:49:11,329] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.5331946]
[2019-03-26 19:49:11,330] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.620258505, 76.49340077, 1.0, 2.0, 0.4009456559817233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 594686.5184675426, 594686.5184675419, 173942.6267914057]
[2019-03-26 19:49:11,331] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:49:11,333] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.7380943e-32 1.0000000e+00 7.6667397e-31 4.3309868e-34 2.9634114e-24], sampled 0.6160646857361238
[2019-03-26 19:49:27,529] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.5331946]
[2019-03-26 19:49:27,530] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [37.4, 48.0, 1.0, 2.0, 0.4247725490621791, 1.0, 2.0, 0.4247725490621791, 1.0, 2.0, 0.7376894432924552, 6.911200000000001, 6.9112, 178.6582176852504, 1781487.140613832, 1781487.140613832, 369064.1861190923]
[2019-03-26 19:49:27,531] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:49:27,533] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.5494056e-20 4.1325769e-08 2.2067524e-17 2.1041584e-15 1.0000000e+00], sampled 0.32613673921794195
[2019-03-26 19:49:39,809] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.5331946]
[2019-03-26 19:49:39,814] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.26666666666667, 70.33333333333334, 1.0, 2.0, 0.6941260589164745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 970057.1951526062, 970057.1951526057, 219588.4016556207]
[2019-03-26 19:49:39,815] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:49:39,817] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.27377645e-36 1.00000000e+00 1.83985931e-35 0.00000000e+00
 1.97315567e-30], sampled 0.2823981125785344
[2019-03-26 19:49:42,144] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.5331946]
[2019-03-26 19:49:42,147] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.25, 78.5, 1.0, 2.0, 0.6276846513960663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 877165.4491132319, 877165.4491132324, 206017.5566451002]
[2019-03-26 19:49:42,147] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:49:42,152] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 2.4853643e-38 0.0000000e+00 6.6966407e-33], sampled 0.084737106369152
[2019-03-26 19:50:18,659] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8314.4742 3002109351.1241 1010.0000
[2019-03-26 19:50:18,753] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8635.2287 2846639764.7938 720.0000
[2019-03-26 19:50:19,103] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8549.4742 2931979268.9347 649.0000
[2019-03-26 19:50:19,209] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8827.7757 2789616614.0465 469.0000
[2019-03-26 19:50:19,231] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8097.6262 3159618491.9790 1220.0000
[2019-03-26 19:50:20,249] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 350000, evaluation results [350000.0, 8097.626229065918, 3159618491.978955, 1220.0, 8549.474236086282, 2931979268.934674, 649.0, 8827.775693957052, 2789616614.0464554, 469.0, 8314.474239480785, 3002109351.1240964, 1010.0, 8635.228655599527, 2846639764.7937803, 720.0]
[2019-03-26 19:50:20,725] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 4.712852e-37], sum to 1.0000
[2019-03-26 19:50:20,737] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6310
[2019-03-26 19:50:20,745] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5171155593673222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722596.7855046365, 722596.7855046365, 186320.7193050761], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5186400.0000, 
sim time next is 5187000.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5168586989980881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 722237.7369859146, 722237.7369859153, 186279.1976108113], 
processed observation next is [1.0, 0.0, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4179020469856483, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2006215936071985, 0.2006215936071987, 0.27802865315046466], 
reward next is 0.7220, 
noisyNet noise sample is [array([-0.32172173], dtype=float32), 0.8178427]. 
=============================================
[2019-03-26 19:50:20,762] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[66.68568]
 [67.17599]
 [67.87715]
 [68.65354]
 [69.99391]], R is [[66.42899323]
 [66.48661041]
 [66.54382324]
 [66.60071564]
 [66.65740204]].
[2019-03-26 19:50:21,528] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0977482e-24 1.0000000e+00 6.0347149e-20 2.1680361e-17 1.3388929e-12], sum to 1.0000
[2019-03-26 19:50:21,535] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7490
[2019-03-26 19:50:21,539] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5163661980249745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 721549.3020272445, 721549.3020272438, 186199.6390236945], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5190000.0000, 
sim time next is 5190600.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5161590341472515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 721259.7213000394, 721259.7213000394, 186166.1952553471], 
processed observation next is [1.0, 0.043478260869565216, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4170590772858452, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20034992258334428, 0.20034992258334428, 0.2778599929184285], 
reward next is 0.7221, 
noisyNet noise sample is [array([0.09755705], dtype=float32), -0.04457093]. 
=============================================
[2019-03-26 19:50:22,872] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2763299e-11 1.9447060e-09 5.7367977e-10 4.1977097e-09 1.0000000e+00], sum to 1.0000
[2019-03-26 19:50:22,881] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6993
[2019-03-26 19:50:22,886] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.83333333333333, 67.5, 1.0, 2.0, 0.6005488769896321, 1.0, 2.0, 0.6005488769896321, 1.0, 2.0, 1.03, 6.925763164234365, 6.9112, 170.5573041426782, 2519599.784683873, 2509167.597751152, 488177.4632647521], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5226600.0000, 
sim time next is 5227200.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.6241021871604564, 1.0, 2.0, 0.6241021871604564, 1.0, 2.0, 1.03, 6.971748239342964, 6.9112, 170.5573041426782, 2618521.127108811, 2575147.96032254, 496883.3071814512], 
processed observation next is [1.0, 0.5217391304347826, 0.7156398104265403, 0.67, 1.0, 1.0, 0.5471110688680197, 1.0, 1.0, 0.5471110688680197, 1.0, 1.0, 1.0365853658536586, 0.006054823934296394, 0.0, 0.8375144448122397, 0.7273669797524475, 0.7153188778673721, 0.7416168763902257], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.98919386], dtype=float32), 0.63148546]. 
=============================================
[2019-03-26 19:50:40,672] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:50:40,682] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3797
[2019-03-26 19:50:40,690] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 89.0, 1.0, 2.0, 0.5497869995469871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 768267.0708748704, 768267.0708748698, 191764.1559140442], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5528400.0000, 
sim time next is 5529000.0000, 
raw observation next is [27.26666666666667, 89.5, 1.0, 2.0, 0.5498509575134044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 768356.4774477064, 768356.4774477064, 191775.1292037778], 
processed observation next is [1.0, 1.0, 0.4913112164297, 0.895, 1.0, 1.0, 0.4576517560402462, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2134323548465851, 0.2134323548465851, 0.2862315361250415], 
reward next is 0.7138, 
noisyNet noise sample is [array([-1.06094], dtype=float32), 1.2620409]. 
=============================================
[2019-03-26 19:50:40,708] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[46.585056]
 [46.719654]
 [46.87093 ]
 [47.03326 ]
 [47.19024 ]], R is [[46.69595718]
 [46.94277954]
 [47.1872673 ]
 [47.42934799]
 [47.66890717]].
[2019-03-26 19:50:41,486] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.9835112e-28 1.0000000e+00 2.7257519e-27 3.8749996e-30 1.4007729e-31], sum to 1.0000
[2019-03-26 19:50:41,497] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2953
[2019-03-26 19:50:41,506] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2011510.098922495 W.
[2019-03-26 19:50:41,511] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.26666666666667, 95.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.693277045166149, 6.9112, 169.6884640040826, 2011510.098922495, 1454130.398308694, 311494.5481175783], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5537400.0000, 
sim time next is 5538000.0000, 
raw observation next is [26.23333333333333, 95.0, 1.0, 2.0, 0.4039465503127977, 1.0, 1.0, 0.4039465503127977, 1.0, 1.0, 0.6961135284389518, 6.911199999999999, 6.9112, 170.5573041426782, 1694138.149786136, 1694138.149786137, 354318.8463266812], 
processed observation next is [1.0, 0.08695652173913043, 0.44233807266982617, 0.95, 1.0, 1.0, 0.2818633136298767, 1.0, 0.5, 0.2818633136298767, 1.0, 0.5, 0.6294067419987216, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4705939304961489, 0.47059393049614917, 0.5288340989950465], 
reward next is 0.4712, 
noisyNet noise sample is [array([2.468246], dtype=float32), -0.7155758]. 
=============================================
[2019-03-26 19:50:41,523] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[35.166508]
 [38.806152]
 [38.8659  ]
 [39.041653]
 [39.294064]], R is [[30.29720116]
 [29.99423027]
 [30.40960503]
 [30.82081223]
 [31.22801208]].
[2019-03-26 19:50:51,865] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:50:51,874] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1901
[2019-03-26 19:50:51,880] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 87.66666666666667, 1.0, 2.0, 0.5097269183795204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712268.7299873319, 712268.7299873313, 185133.8424928221], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5710800.0000, 
sim time next is 5711400.0000, 
raw observation next is [26.3, 88.0, 1.0, 2.0, 0.5099865169177973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712631.6026108376, 712631.6026108376, 185175.2902713618], 
processed observation next is [0.0, 0.08695652173913043, 0.4454976303317536, 0.88, 1.0, 1.0, 0.4096223095395148, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19795322294745488, 0.19795322294745488, 0.2763810302557639], 
reward next is 0.7236, 
noisyNet noise sample is [array([0.09033508], dtype=float32), 2.2108226]. 
=============================================
[2019-03-26 19:50:55,482] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:50:55,491] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7544
[2019-03-26 19:50:55,499] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 78.0, 1.0, 2.0, 0.5512923579204319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 770371.4070233355, 770371.4070233355, 192022.4183767498], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5772000.0000, 
sim time next is 5772600.0000, 
raw observation next is [28.8, 79.0, 1.0, 2.0, 0.5495153097932858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 767887.2769922784, 767887.276992279, 191717.473560603], 
processed observation next is [0.0, 0.8260869565217391, 0.5639810426540285, 0.79, 1.0, 1.0, 0.4572473611967298, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.213302021386744, 0.21330202138674417, 0.2861454829262731], 
reward next is 0.7139, 
noisyNet noise sample is [array([0.47145665], dtype=float32), -0.49266353]. 
=============================================
[2019-03-26 19:50:57,099] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 5.780969e-35 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-26 19:50:57,105] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9050
[2019-03-26 19:50:57,113] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.96666666666667, 88.66666666666666, 1.0, 2.0, 0.5385480237658156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 752556.2706470994, 752556.2706471, 189855.7897335218], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5791200.0000, 
sim time next is 5791800.0000, 
raw observation next is [26.93333333333333, 88.83333333333334, 1.0, 2.0, 0.5379146463188768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 751670.888473976, 751670.8884739766, 189749.3929585985], 
processed observation next is [1.0, 0.0, 0.4755134281200631, 0.8883333333333334, 1.0, 1.0, 0.44327065821551415, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2087974690205489, 0.20879746902054908, 0.28320804919193804], 
reward next is 0.7168, 
noisyNet noise sample is [array([1.3278806], dtype=float32), 2.0493834]. 
=============================================
[2019-03-26 19:51:00,461] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:51:00,467] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3057
[2019-03-26 19:51:00,471] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.8, 76.83333333333333, 1.0, 2.0, 0.5583851429277124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780286.446919334, 780286.446919334, 193250.050459017], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5856600.0000, 
sim time next is 5857200.0000, 
raw observation next is [29.6, 78.0, 1.0, 2.0, 0.5590737159651281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 781249.0115661294, 781249.0115661294, 193369.8562955442], 
processed observation next is [1.0, 0.8260869565217391, 0.6018957345971565, 0.78, 1.0, 1.0, 0.4687635132109977, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21701361432392482, 0.21701361432392482, 0.28861172581424505], 
reward next is 0.7114, 
noisyNet noise sample is [array([0.09995145], dtype=float32), -0.1022838]. 
=============================================
[2019-03-26 19:51:01,978] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 7.1201518e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 19:51:01,987] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0939
[2019-03-26 19:51:01,997] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.05, 93.66666666666667, 1.0, 2.0, 0.525196342282297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733892.4519447049, 733892.4519447049, 187638.0130278393], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5881800.0000, 
sim time next is 5882400.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.5250008546552274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 733619.1895011489, 733619.1895011495, 187605.9281109089], 
processed observation next is [1.0, 0.08695652173913043, 0.4312796208530806, 0.94, 1.0, 1.0, 0.4277118730785872, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20378310819476358, 0.20378310819476375, 0.2800088479267297], 
reward next is 0.7200, 
noisyNet noise sample is [array([-0.6630592], dtype=float32), 2.0791833]. 
=============================================
[2019-03-26 19:51:04,936] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3821137e-19 1.0000000e+00 1.1494774e-18 1.6092087e-22 2.4405715e-20], sum to 1.0000
[2019-03-26 19:51:04,942] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9541
[2019-03-26 19:51:04,953] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2296988.223480402 W.
[2019-03-26 19:51:04,958] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.26666666666667, 78.33333333333334, 1.0, 2.0, 0.8213068986825606, 1.0, 2.0, 0.8213068986825606, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2296988.223480402, 2296988.223480402, 430384.5555183012], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5934000.0000, 
sim time next is 5934600.0000, 
raw observation next is [30.3, 78.5, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.439459119609833, 6.9112, 168.9091129459914, 2658780.100572481, 2284023.427516987, 474938.1047303075], 
processed observation next is [1.0, 0.6956521739130435, 0.6350710900473934, 0.785, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.05282591196098334, 0.0, 0.8294210714913128, 0.7385500279368002, 0.634450952088052, 0.7088628428810559], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.25058687], dtype=float32), -1.6729039]. 
=============================================
[2019-03-26 19:51:04,980] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0205560e-15 1.0000000e+00 1.7477298e-14 1.0885167e-15 1.0304101e-15], sum to 1.0000
[2019-03-26 19:51:04,988] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0499
[2019-03-26 19:51:04,995] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2454846.514757056 W.
[2019-03-26 19:51:05,000] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.43333333333333, 71.66666666666666, 1.0, 2.0, 0.8776950343238015, 1.0, 2.0, 0.8776950343238015, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2454846.514757056, 2454846.514757056, 459474.3607298597], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5917800.0000, 
sim time next is 5918400.0000, 
raw observation next is [31.3, 72.0, 1.0, 2.0, 0.6046992427879906, 1.0, 2.0, 0.6046992427879906, 1.0, 1.0, 1.03, 6.93386600260629, 6.9112, 170.5573041426782, 2537030.301461533, 2520793.72180061, 489688.9983560219], 
processed observation next is [1.0, 0.5217391304347826, 0.6824644549763034, 0.72, 1.0, 1.0, 0.5237340274554103, 1.0, 1.0, 0.5237340274554103, 1.0, 0.5, 1.0365853658536586, 0.002266600260629037, 0.0, 0.8375144448122397, 0.7047306392948703, 0.7002204782779472, 0.7308791020239133], 
reward next is 0.1558, 
noisyNet noise sample is [array([0.73454684], dtype=float32), 1.2323074]. 
=============================================
[2019-03-26 19:51:05,651] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.09393186e-26 1.00000000e+00 1.14725174e-26 8.47903071e-30
 6.56881115e-28], sum to 1.0000
[2019-03-26 19:51:05,659] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2049
[2019-03-26 19:51:05,672] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2145994.967887642 W.
[2019-03-26 19:51:05,679] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.03333333333333, 78.5, 1.0, 2.0, 0.8935404553190295, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.005987327761655, 6.9112, 168.9123931466989, 2145994.967887642, 2078749.799524394, 432260.7000772187], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5907000.0000, 
sim time next is 5907600.0000, 
raw observation next is [30.2, 78.0, 1.0, 2.0, 0.5191500283660374, 1.0, 1.0, 0.5191500283660374, 1.0, 2.0, 0.9015919137339176, 6.9112, 6.9112, 170.5573041426782, 2177788.693087529, 2177788.693087529, 428642.0285954332], 
processed observation next is [1.0, 0.391304347826087, 0.6303317535545023, 0.78, 1.0, 1.0, 0.4206626847783583, 1.0, 0.5, 0.4206626847783583, 1.0, 1.0, 0.8799901386998993, 0.0, 0.0, 0.8375144448122397, 0.6049413036354248, 0.6049413036354248, 0.6397642217842286], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.92115813], dtype=float32), -0.5790351]. 
=============================================
[2019-03-26 19:51:13,222] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:51:13,227] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1770
[2019-03-26 19:51:13,230] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.06666666666667, 83.66666666666667, 1.0, 2.0, 0.7124276490214955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 995646.0795226158, 995646.0795226158, 223551.506195066], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6074400.0000, 
sim time next is 6075000.0000, 
raw observation next is [28.2, 83.0, 1.0, 2.0, 0.7095382681428593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 991606.1691697689, 991606.1691697689, 222918.5250526618], 
processed observation next is [1.0, 0.30434782608695654, 0.5355450236966824, 0.83, 1.0, 1.0, 0.650046106196216, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2754461581027136, 0.2754461581027136, 0.3327142164965102], 
reward next is 0.6673, 
noisyNet noise sample is [array([-0.28190213], dtype=float32), 0.08344445]. 
=============================================
[2019-03-26 19:51:13,252] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[47.98052 ]
 [47.840927]
 [47.34146 ]
 [46.778168]
 [47.298748]], R is [[48.31365204]
 [48.49685669]
 [48.68399048]
 [48.86246872]
 [49.01915741]].
[2019-03-26 19:51:15,861] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 19:51:15,862] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:51:15,863] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:51:15,864] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:51:15,864] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:51:15,866] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:51:15,867] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:51:15,868] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:51:15,869] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:51:15,870] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:51:15,870] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:51:15,889] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run16
[2019-03-26 19:51:15,909] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run16
[2019-03-26 19:51:15,911] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run16
[2019-03-26 19:51:15,948] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run16
[2019-03-26 19:51:15,974] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run16
[2019-03-26 19:51:46,777] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.59995705]
[2019-03-26 19:51:46,778] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.51666666666667, 87.33333333333333, 1.0, 2.0, 0.5458882343340453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 762817.0175572584, 762817.0175572584, 191098.1354574556]
[2019-03-26 19:51:46,778] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:51:46,781] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6297571230243038
[2019-03-26 19:52:04,429] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.59995705]
[2019-03-26 19:52:04,430] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.1, 81.66666666666666, 1.0, 2.0, 0.4930263275784424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 688924.5323875515, 688924.5323875515, 182511.1182568988]
[2019-03-26 19:52:04,430] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:52:04,431] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7470326127239986
[2019-03-26 19:52:09,949] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.59995705]
[2019-03-26 19:52:09,950] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.87923825166667, 72.71833781833334, 1.0, 2.0, 0.5285554968949208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 738588.058303121, 738588.0583031217, 188189.9834573503]
[2019-03-26 19:52:09,953] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:52:09,955] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.23112803707166574
[2019-03-26 19:52:16,957] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.59995705]
[2019-03-26 19:52:16,959] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.43333333333333, 47.0, 1.0, 2.0, 0.5257171106690818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 734620.408547886, 734620.408547886, 187722.8889884887]
[2019-03-26 19:52:16,961] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:52:16,965] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.15040176205948808
[2019-03-26 19:52:21,560] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.59995705]
[2019-03-26 19:52:21,562] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.83333333333334, 46.66666666666667, 1.0, 2.0, 0.5286260510557294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 738686.6829131611, 738686.6829131617, 188202.5717359383]
[2019-03-26 19:52:21,563] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:52:21,566] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.1845550865423624
[2019-03-26 19:53:09,086] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8493.1698 2842847906.5028 1131.0000
[2019-03-26 19:53:09,324] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7993.8735 3008074935.8820 1766.0000
[2019-03-26 19:53:09,512] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8657.0254 2779571564.5107 933.0000
[2019-03-26 19:53:09,590] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8249.9842 2927761875.2740 1338.0000
[2019-03-26 19:53:09,614] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7880.4023 3164369872.1585 1778.0000
[2019-03-26 19:53:10,630] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 375000, evaluation results [375000.0, 7880.402349447878, 3164369872.158471, 1778.0, 8249.984224632335, 2927761875.274041, 1338.0, 8657.025437658545, 2779571564.5106506, 933.0, 7993.873477747932, 3008074935.8820424, 1766.0, 8493.169770734836, 2842847906.5028043, 1131.0]
[2019-03-26 19:53:11,170] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:53:11,181] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7914
[2019-03-26 19:53:11,190] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 87.0, 1.0, 2.0, 0.5373321750653592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 750856.6674212178, 750856.6674212184, 189651.9503366337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6129600.0000, 
sim time next is 6130200.0000, 
raw observation next is [27.3, 87.0, 1.0, 2.0, 0.5368334427715126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 750159.5033260094, 750159.5033260094, 189568.362043944], 
processed observation next is [1.0, 0.9565217391304348, 0.4928909952606636, 0.87, 1.0, 1.0, 0.44196800333917174, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20837763981278037, 0.20837763981278037, 0.28293785379693137], 
reward next is 0.7171, 
noisyNet noise sample is [array([0.28175008], dtype=float32), 0.56316054]. 
=============================================
[2019-03-26 19:53:38,234] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:53:38,246] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1984
[2019-03-26 19:53:38,252] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 92.5, 1.0, 2.0, 0.5607225865789942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 783553.9914521124, 783553.9914521124, 193653.0624439428], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6582600.0000, 
sim time next is 6583200.0000, 
raw observation next is [25.76666666666667, 92.66666666666667, 1.0, 2.0, 0.5516146446212815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 770821.9312190055, 770821.9312190055, 192075.0497460303], 
processed observation next is [1.0, 0.17391304347826086, 0.42022116903633505, 0.9266666666666667, 1.0, 1.0, 0.45977668026660423, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2141172031163904, 0.2141172031163904, 0.28667917872541837], 
reward next is 0.7133, 
noisyNet noise sample is [array([-1.1445405], dtype=float32), 1.6894865]. 
=============================================
[2019-03-26 19:53:40,811] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.3776542e-35 1.0000000e+00 1.2183532e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 19:53:40,823] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6391
[2019-03-26 19:53:40,831] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2359879.031092306 W.
[2019-03-26 19:53:40,835] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.41666666666666, 60.5, 1.0, 2.0, 0.5625152056933829, 1.0, 2.0, 0.5625152056933829, 1.0, 2.0, 0.9661140610305675, 6.911199999999999, 6.9112, 170.5573041426782, 2359879.031092306, 2359879.031092307, 458837.4294683043], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6617400.0000, 
sim time next is 6618000.0000, 
raw observation next is [31.33333333333334, 61.00000000000001, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.342779117863287, 6.9112, 168.9104945049974, 2606669.280832512, 2300496.663523975, 475943.4213693975], 
processed observation next is [1.0, 0.6086956521739131, 0.6840442338072673, 0.6100000000000001, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.04315791178632873, 0.0, 0.8294278555785127, 0.7240748002312533, 0.6390268509788819, 0.7103633154767127], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.44187987], dtype=float32), -1.8391324]. 
=============================================
[2019-03-26 19:53:40,849] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[37.198242]
 [38.424496]
 [38.88248 ]
 [40.4802  ]
 [41.568596]], R is [[37.27662659]
 [37.21902847]
 [37.21769714]
 [37.21258926]
 [37.20025253]].
[2019-03-26 19:53:46,556] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:53:46,568] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8621
[2019-03-26 19:53:46,577] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1841680.291055385 W.
[2019-03-26 19:53:46,585] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.63333333333333, 66.66666666666667, 1.0, 2.0, 0.6586439490330911, 1.0, 1.0, 0.6586439490330911, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1841680.291055385, 1841680.291055385, 356914.893405098], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6713400.0000, 
sim time next is 6714000.0000, 
raw observation next is [29.6, 67.0, 1.0, 2.0, 0.4265640660109442, 1.0, 2.0, 0.4265640660109442, 1.0, 1.0, 0.7253563244100578, 6.911199999999999, 6.9112, 170.5573041426782, 1789074.430169842, 1789074.430169842, 365720.7299009895], 
processed observation next is [1.0, 0.7391304347826086, 0.6018957345971565, 0.67, 1.0, 1.0, 0.30911333254330625, 1.0, 1.0, 0.30911333254330625, 1.0, 0.5, 0.6650686883049486, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.49696511949162275, 0.49696511949162275, 0.5458518356731187], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.22977817], dtype=float32), 0.49954233]. 
=============================================
[2019-03-26 19:53:46,601] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[53.82344 ]
 [53.69212 ]
 [53.321987]
 [51.837704]
 [50.83062 ]], R is [[53.2795372 ]
 [52.74674225]
 [52.35224915]
 [52.31393051]
 [51.79079056]].
[2019-03-26 19:53:51,879] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:53:51,888] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5709
[2019-03-26 19:53:51,900] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.2, 49.0, 1.0, 2.0, 0.9046513252383885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1399623.417966495, 1399623.417966495, 289886.4719257845], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6796800.0000, 
sim time next is 6797400.0000, 
raw observation next is [29.18333333333333, 49.16666666666667, 1.0, 2.0, 0.8643341268109255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1336284.007303215, 1336284.007303216, 277656.5160724401], 
processed observation next is [1.0, 0.6956521739130435, 0.5821484992101105, 0.4916666666666667, 1.0, 1.0, 0.8365471407360547, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.37119000202867086, 0.37119000202867114, 0.4144127105558807], 
reward next is 0.5856, 
noisyNet noise sample is [array([-1.66866], dtype=float32), -2.5992398]. 
=============================================
[2019-03-26 19:54:01,870] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:54:01,881] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0122
[2019-03-26 19:54:01,891] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.96666666666667, 56.33333333333334, 1.0, 2.0, 0.3965311551739365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 591149.2877517611, 591149.2877517617, 173707.0568044419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6981600.0000, 
sim time next is 6982200.0000, 
raw observation next is [28.9, 56.0, 1.0, 2.0, 0.3939389622078006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 589670.6571792588, 589670.6571792588, 173642.7863888592], 
processed observation next is [0.0, 0.8260869565217391, 0.5687203791469194, 0.56, 1.0, 1.0, 0.2698059785636152, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16379740477201632, 0.16379740477201632, 0.2591683378938197], 
reward next is 0.7408, 
noisyNet noise sample is [array([-0.5070419], dtype=float32), 1.4956383]. 
=============================================
[2019-03-26 19:54:06,232] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 19:54:06,235] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:54:06,235] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:54:06,237] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:54:06,236] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:54:06,239] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:54:06,239] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:54:06,238] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:54:06,244] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:54:06,241] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:54:06,244] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:54:06,261] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run17
[2019-03-26 19:54:06,280] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run17
[2019-03-26 19:54:06,303] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run17
[2019-03-26 19:54:06,322] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run17
[2019-03-26 19:54:06,323] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run17
[2019-03-26 19:54:35,008] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.529142]
[2019-03-26 19:54:35,009] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.13333333333333, 94.83333333333333, 1.0, 2.0, 0.51760948734368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723287.2158594686, 723287.2158594686, 186399.7944994998]
[2019-03-26 19:54:35,009] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:54:35,010] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.39707750850732426
[2019-03-26 19:54:44,292] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.529142]
[2019-03-26 19:54:44,294] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.66666666666667, 82.33333333333334, 1.0, 2.0, 0.4869201134928406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 680389.353542873, 680389.3535428736, 181572.1421513857]
[2019-03-26 19:54:44,296] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:54:44,301] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.11144906006591326
[2019-03-26 19:55:17,688] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.529142]
[2019-03-26 19:55:17,689] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.76666666666667, 79.16666666666667, 1.0, 2.0, 0.5900554764587899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 824559.6950334675, 824559.6950334675, 198907.2818208466]
[2019-03-26 19:55:17,690] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:55:17,693] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4233544579696472
[2019-03-26 19:55:31,815] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.529142]
[2019-03-26 19:55:31,816] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.33333333333334, 81.33333333333334, 1.0, 2.0, 0.5666369186222883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 791821.7622108033, 791821.7622108033, 194695.9060357982]
[2019-03-26 19:55:31,818] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:55:31,820] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.47280715444508314
[2019-03-26 19:55:40,890] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.529142]
[2019-03-26 19:55:40,892] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.45, 81.66666666666667, 1.0, 2.0, 0.5095254918336827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 711987.1715569719, 711987.1715569724, 185102.2386850603]
[2019-03-26 19:55:40,893] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:55:40,895] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7219073845040761
[2019-03-26 19:56:00,187] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.0966 3007867509.5417 1766.0000
[2019-03-26 19:56:00,480] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.2482 2779349048.6670 933.0000
[2019-03-26 19:56:00,703] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.2074 2927546585.9425 1338.0000
[2019-03-26 19:56:00,743] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8494.6521 2842708650.5645 1131.0000
[2019-03-26 19:56:00,750] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.9141 3164254244.9626 1778.0000
[2019-03-26 19:56:01,765] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 400000, evaluation results [400000.0, 7881.914110821881, 3164254244.9625816, 1778.0, 8252.207390139796, 2927546585.9425, 1338.0, 8659.248225290772, 2779349048.6670237, 933.0, 7996.096616164504, 3007867509.5416894, 1766.0, 8494.652070649916, 2842708650.564488, 1131.0]
[2019-03-26 19:56:02,402] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:56:02,410] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3351
[2019-03-26 19:56:02,416] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.3, 88.5, 1.0, 2.0, 0.4739172688450439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 664048.1388739002, 664048.1388738996, 179847.0565907421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7083000.0000, 
sim time next is 7083600.0000, 
raw observation next is [25.26666666666667, 88.66666666666666, 1.0, 2.0, 0.4730573396743231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 663154.2918153381, 663154.2918153375, 179758.9218738756], 
processed observation next is [1.0, 1.0, 0.3965244865718801, 0.8866666666666666, 1.0, 1.0, 0.36512932490882305, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18420952550426056, 0.18420952550426042, 0.2682968983192173], 
reward next is 0.7317, 
noisyNet noise sample is [array([-0.7152525], dtype=float32), 0.4456878]. 
=============================================
[2019-03-26 19:56:07,276] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:56:07,283] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4107
[2019-03-26 19:56:07,287] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 85.66666666666667, 1.0, 2.0, 0.4558445268702861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 636953.4048898576, 636953.4048898583, 176968.2596178896], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7147200.0000, 
sim time next is 7147800.0000, 
raw observation next is [26.1, 85.5, 1.0, 2.0, 0.4571307578720981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 638751.2010035329, 638751.2010035329, 177153.0790117436], 
processed observation next is [1.0, 0.7391304347826086, 0.4360189573459717, 0.855, 1.0, 1.0, 0.3459406721350579, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17743088916764801, 0.17743088916764801, 0.26440758061454267], 
reward next is 0.7356, 
noisyNet noise sample is [array([-0.93864006], dtype=float32), 2.1127706]. 
=============================================
[2019-03-26 19:56:07,294] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:56:07,305] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8808
[2019-03-26 19:56:07,312] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 82.16666666666666, 1.0, 2.0, 0.5359684677292955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 763047.9393231751, 763047.9393231751, 191225.3700392197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7109400.0000, 
sim time next is 7110000.0000, 
raw observation next is [26.0, 81.0, 1.0, 2.0, 0.537309990994946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 765116.9800715566, 765116.9800715559, 191474.8870578634], 
processed observation next is [1.0, 0.30434782608695654, 0.4312796208530806, 0.81, 1.0, 1.0, 0.44254215782523615, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2125324944643213, 0.2125324944643211, 0.2857834135191991], 
reward next is 0.7142, 
noisyNet noise sample is [array([1.8284855], dtype=float32), -1.3407737]. 
=============================================
[2019-03-26 19:56:07,328] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[67.82946 ]
 [67.96693 ]
 [68.109146]
 [68.11447 ]
 [68.07691 ]], R is [[67.94980621]
 [67.98490143]
 [68.02200317]
 [68.06401062]
 [68.10526276]].
[2019-03-26 19:56:10,777] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:56:10,785] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2244
[2019-03-26 19:56:10,796] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1789277.703940513 W.
[2019-03-26 19:56:10,801] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 79.83333333333334, 1.0, 2.0, 0.4266124915821179, 1.0, 1.0, 0.4266124915821179, 1.0, 2.0, 0.7408848149712994, 6.911200000000001, 6.9112, 170.5573041426782, 1789277.703940513, 1789277.703940512, 368109.0534054863], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7206600.0000, 
sim time next is 7207200.0000, 
raw observation next is [29.0, 79.0, 1.0, 2.0, 0.7642198915809658, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.998022651819127, 6.9112, 168.9124401228415, 1964998.959738948, 1903404.170636788, 399494.9002213525], 
processed observation next is [1.0, 0.43478260869565216, 0.5734597156398105, 0.79, 1.0, 1.0, 0.715927580218031, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.00868226518191273, 0.0, 0.829437409452835, 0.54583304437193, 0.5287233807324411, 0.5962610451064964], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8513389], dtype=float32), 0.42853174]. 
=============================================
[2019-03-26 19:56:16,530] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:56:16,540] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6342
[2019-03-26 19:56:16,544] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.58333333333334, 59.5, 1.0, 2.0, 0.5314612537988196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 810713.4058482694, 810713.4058482688, 196925.4549290281], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7305000.0000, 
sim time next is 7305600.0000, 
raw observation next is [27.66666666666667, 59.00000000000001, 1.0, 2.0, 0.8192553128984903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1250146.897308022, 1250146.897308022, 262814.2048696524], 
processed observation next is [1.0, 0.5652173913043478, 0.5102685624012641, 0.5900000000000001, 1.0, 1.0, 0.782235316745169, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3472630270300061, 0.3472630270300061, 0.3922600072681379], 
reward next is 0.6077, 
noisyNet noise sample is [array([-0.96710837], dtype=float32), -0.037788413]. 
=============================================
[2019-03-26 19:56:20,090] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:56:20,099] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2834
[2019-03-26 19:56:20,107] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.98333333333333, 66.5, 1.0, 2.0, 0.3762490660728819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 562824.6120057555, 562824.6120057555, 171227.0679055988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7321800.0000, 
sim time next is 7322400.0000, 
raw observation next is [26.9, 67.0, 1.0, 2.0, 0.3800291821125275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 568403.7290773244, 568403.729077325, 171715.604130279], 
processed observation next is [1.0, 0.782608695652174, 0.4739336492890995, 0.67, 1.0, 1.0, 0.253047207364491, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15788992474370123, 0.1578899247437014, 0.256291946463103], 
reward next is 0.7437, 
noisyNet noise sample is [array([1.4958174], dtype=float32), 0.33618096]. 
=============================================
[2019-03-26 19:56:25,647] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:56:25,656] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7622
[2019-03-26 19:56:25,664] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 83.0, 1.0, 2.0, 0.2872973960283477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 462798.8579883144, 462798.8579883144, 164464.1637426504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7414200.0000, 
sim time next is 7414800.0000, 
raw observation next is [21.56666666666667, 82.66666666666667, 1.0, 2.0, 0.2874157617010465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 462797.0075401866, 462797.0075401873, 164463.9532688753], 
processed observation next is [1.0, 0.8260869565217391, 0.22116903633491333, 0.8266666666666667, 1.0, 1.0, 0.14146477313379094, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1285547243167185, 0.1285547243167187, 0.2454685869684706], 
reward next is 0.7545, 
noisyNet noise sample is [array([0.8158264], dtype=float32), -0.7421567]. 
=============================================
[2019-03-26 19:56:31,522] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:56:31,532] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1666
[2019-03-26 19:56:31,536] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.76666666666667, 74.83333333333334, 1.0, 2.0, 0.4738316320516899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 662094.6921360975, 662094.6921360975, 179598.1152550197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7555800.0000, 
sim time next is 7556400.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.4764315527761743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 665728.7532254775, 665728.7532254775, 179986.3776654281], 
processed observation next is [0.0, 0.4782608695652174, 0.5260663507109005, 0.74, 1.0, 1.0, 0.3691946418990052, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18492465367374375, 0.18492465367374375, 0.26863638457526584], 
reward next is 0.7314, 
noisyNet noise sample is [array([-2.1909027], dtype=float32), -0.50504994]. 
=============================================
[2019-03-26 19:56:34,796] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:56:34,806] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0929
[2019-03-26 19:56:34,809] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 91.0, 1.0, 2.0, 0.5626204026534609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 794781.8612301777, 794781.861230177, 195089.2512603661], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7632000.0000, 
sim time next is 7632600.0000, 
raw observation next is [25.06666666666667, 89.33333333333334, 1.0, 2.0, 0.5538310938006488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 780730.8434152335, 780730.843415233, 193333.0884085688], 
processed observation next is [1.0, 0.34782608695652173, 0.38704581358609813, 0.8933333333333334, 1.0, 1.0, 0.46244710096463704, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21686967872645377, 0.2168696787264536, 0.2885568483709982], 
reward next is 0.7114, 
noisyNet noise sample is [array([0.32463408], dtype=float32), -1.303226]. 
=============================================
[2019-03-26 19:56:39,458] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:56:39,466] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5932
[2019-03-26 19:56:39,470] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 93.0, 1.0, 2.0, 0.4756899223566954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 664692.13179326, 664692.1317932606, 179874.5957393567], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7694400.0000, 
sim time next is 7695000.0000, 
raw observation next is [24.75, 93.5, 1.0, 2.0, 0.4765910510135424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 665951.6936347912, 665951.6936347906, 180009.3996625681], 
processed observation next is [1.0, 0.043478260869565216, 0.3720379146919432, 0.935, 1.0, 1.0, 0.369386808450051, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18498658156521977, 0.1849865815652196, 0.268670745765027], 
reward next is 0.7313, 
noisyNet noise sample is [array([0.2207633], dtype=float32), 1.3356506]. 
=============================================
[2019-03-26 19:56:39,485] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[70.1691  ]
 [70.1668  ]
 [70.186745]
 [70.14044 ]
 [70.13299 ]], R is [[70.14096069]
 [70.17108154]
 [70.20085907]
 [70.23021698]
 [70.25909424]].
[2019-03-26 19:56:42,204] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.3432516e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 19:56:42,212] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9264
[2019-03-26 19:56:42,220] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2001196.821680424 W.
[2019-03-26 19:56:42,224] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.25, 74.5, 1.0, 2.0, 0.7156389484010772, 1.0, 2.0, 0.7156389484010772, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2001196.821680424, 2001196.821680424, 380889.5281965043], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7723800.0000, 
sim time next is 7724400.0000, 
raw observation next is [29.46666666666667, 73.33333333333333, 1.0, 2.0, 0.4842152748559776, 1.0, 2.0, 0.4842152748559776, 1.0, 1.0, 0.8354638024247912, 6.911200000000001, 6.9112, 170.5573041426782, 2031101.54210564, 2031101.542105639, 403450.6820801883], 
processed observation next is [1.0, 0.391304347826087, 0.5955766192733019, 0.7333333333333333, 1.0, 1.0, 0.3785726203084067, 1.0, 1.0, 0.3785726203084067, 1.0, 0.5, 0.799346100518038, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5641948728071222, 0.5641948728071219, 0.6021651971346094], 
reward next is 0.3978, 
noisyNet noise sample is [array([1.5420032], dtype=float32), 0.8010588]. 
=============================================
[2019-03-26 19:56:52,253] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.3620991e-37 0.0000000e+00 1.4417427e-37], sum to 1.0000
[2019-03-26 19:56:52,262] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8406
[2019-03-26 19:56:52,273] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2007601.33147838 W.
[2019-03-26 19:56:52,281] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.73333333333333, 72.0, 1.0, 2.0, 0.4786180614949215, 1.0, 2.0, 0.4786180614949215, 1.0, 2.0, 0.8268634617379501, 6.9112, 6.9112, 170.5573041426782, 2007601.33147838, 2007601.33147838, 399929.2390319413], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7904400.0000, 
sim time next is 7905000.0000, 
raw observation next is [29.76666666666667, 72.0, 1.0, 2.0, 0.7930624410510496, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.990745339973302, 6.9112, 168.9124828395285, 2005364.081201497, 1948932.037534036, 406700.7225159716], 
processed observation next is [1.0, 0.4782608695652174, 0.6097946287519749, 0.72, 1.0, 1.0, 0.7506776398205417, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007954533997330237, 0.0, 0.829437619211324, 0.557045578111527, 0.5413700104261211, 0.6070160037551815], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0418881], dtype=float32), -1.0082307]. 
=============================================
[2019-03-26 19:56:52,293] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[50.983437]
 [50.419174]
 [51.489113]
 [53.290268]
 [54.374706]], R is [[51.08012772]
 [50.97241974]
 [50.82716751]
 [50.31889725]
 [50.26747894]].
[2019-03-26 19:56:54,783] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:56:54,783] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:56:54,812] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run3
[2019-03-26 19:56:54,935] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:56:54,935] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:56:54,954] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run3
[2019-03-26 19:56:55,045] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:56:55,045] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:56:55,047] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run3
[2019-03-26 19:56:55,348] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:56:55,348] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:56:55,350] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run3
[2019-03-26 19:56:55,602] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:56:55,603] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:56:55,604] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run3
[2019-03-26 19:56:55,633] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:56:55,633] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:56:55,635] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run3
[2019-03-26 19:56:55,685] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:56:55,685] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:56:55,686] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run3
[2019-03-26 19:56:55,699] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:56:55,700] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:56:55,702] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run3
[2019-03-26 19:56:55,725] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:56:55,725] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:56:55,726] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run3
[2019-03-26 19:56:55,755] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:56:55,756] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:56:55,758] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run3
[2019-03-26 19:56:55,965] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:56:55,965] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:56:55,966] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run3
[2019-03-26 19:56:55,985] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:56:55,986] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:56:55,987] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run3
[2019-03-26 19:56:56,005] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:56:56,006] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:56:56,007] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run3
[2019-03-26 19:56:56,036] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:56:56,036] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:56:56,038] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run3
[2019-03-26 19:56:56,067] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:56:56,067] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:56:56,068] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run3
[2019-03-26 19:56:56,181] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:56:56,181] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:56:56,182] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run3
[2019-03-26 19:56:56,716] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2321882e-24 2.6614359e-01 1.4914621e-21 6.8598958e-15 7.3385644e-01], sum to 1.0000
[2019-03-26 19:56:56,717] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9966
[2019-03-26 19:56:56,718] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [20.55, 84.83333333333333, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.18, 6.911200000000001, 6.9112, 170.5573041426782, 459108.8362580346, 459108.8362580339, 222951.6136858409], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3000.0000, 
sim time next is 3600.0000, 
raw observation next is [20.2, 84.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.18, 6.911200000000001, 6.9112, 170.5573041426782, 443192.2454956224, 443192.2454956218, 219795.4616213473], 
processed observation next is [1.0, 0.043478260869565216, 0.15639810426540288, 0.84, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.12310895708211733, 0.12310895708211717, 0.32805292779305567], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.72925], dtype=float32), -1.7282264]. 
=============================================
[2019-03-26 19:56:58,642] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 19:56:58,649] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:56:58,650] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:56:58,651] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:56:58,653] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:56:58,653] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:56:58,655] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:56:58,655] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:56:58,658] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:56:58,655] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:56:58,662] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:56:58,674] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run18
[2019-03-26 19:56:58,675] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run18
[2019-03-26 19:56:58,710] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run18
[2019-03-26 19:56:58,729] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run18
[2019-03-26 19:56:58,730] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run18
[2019-03-26 19:57:07,246] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.40700266]
[2019-03-26 19:57:07,247] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [20.1, 76.0, 1.0, 2.0, 0.2290363796647551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 380212.3874429845, 380212.3874429839, 158673.4106363688]
[2019-03-26 19:57:07,248] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:57:07,252] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.528956814646129
[2019-03-26 19:57:08,706] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.40700266]
[2019-03-26 19:57:08,708] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.75, 77.5, 1.0, 2.0, 0.3299626021126095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 514859.5742660682, 514859.5742660688, 167998.1765352577]
[2019-03-26 19:57:08,709] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:57:08,711] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7239360707556268
[2019-03-26 19:57:18,256] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.40700266]
[2019-03-26 19:57:18,257] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.86666666666667, 48.66666666666667, 1.0, 2.0, 0.289633149338981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 474859.5319223051, 474859.5319223044, 165083.4154468953]
[2019-03-26 19:57:18,259] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:57:18,262] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9279388640810158
[2019-03-26 19:57:20,069] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.40700266]
[2019-03-26 19:57:20,070] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.75, 47.33333333333334, 1.0, 2.0, 0.2962381671518284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 475208.9047335431, 475208.9047335431, 165319.4594384755]
[2019-03-26 19:57:20,071] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:57:20,073] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4302009738337186
[2019-03-26 19:57:30,335] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.40700266]
[2019-03-26 19:57:30,337] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.34786726833333, 95.42939456333333, 1.0, 2.0, 0.5515646043063948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 771407.938191182, 771407.9381911826, 192148.9186429137]
[2019-03-26 19:57:30,339] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:57:30,341] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5045916393128694
[2019-03-26 19:57:39,974] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.40700266]
[2019-03-26 19:57:39,974] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.12148921833333, 90.81203385333335, 1.0, 2.0, 0.3177543296023934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 506384.9222501, 506384.9222501, 167561.9841630562]
[2019-03-26 19:57:39,975] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:57:39,978] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6790482948198383
[2019-03-26 19:57:40,080] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.40700266]
[2019-03-26 19:57:40,080] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.2, 58.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.121948948202007, 6.9112, 168.9116932885467, 1603368.760585525, 1453857.321447284, 311347.7789426416]
[2019-03-26 19:57:40,081] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:57:40,086] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.13466473039811944
[2019-03-26 19:57:40,165] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.40700266]
[2019-03-26 19:57:40,166] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.96897916333334, 95.30675409, 1.0, 2.0, 0.4009987312014427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 594117.4535476015, 594117.4535476008, 173869.8392544144]
[2019-03-26 19:57:40,167] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:57:40,169] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.05792247825075947
[2019-03-26 19:57:52,271] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.40700266]
[2019-03-26 19:57:52,271] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.33333333333334, 78.16666666666667, 1.0, 2.0, 0.7734726480349765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1108856.419180989, 1108856.419180989, 241347.843446347]
[2019-03-26 19:57:52,273] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:57:52,275] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9271443246113709
[2019-03-26 19:58:18,838] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.40700266]
[2019-03-26 19:58:18,839] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.45, 94.5, 1.0, 2.0, 0.629641901732847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 879901.7650858628, 879901.7650858628, 206397.7727407626]
[2019-03-26 19:58:18,842] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:58:18,845] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.0623321371211677
[2019-03-26 19:58:28,207] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.40700266]
[2019-03-26 19:58:28,208] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.48043525, 64.33524794666667, 1.0, 2.0, 0.5867910734859069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 819996.1679627359, 819996.1679627366, 198310.5691253005]
[2019-03-26 19:58:28,208] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:58:28,212] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.2908911913227977
[2019-03-26 19:58:49,946] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.40700266]
[2019-03-26 19:58:49,947] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.23253116666667, 86.00896068, 1.0, 2.0, 0.5121188218142325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 715612.1906169378, 715612.1906169384, 185515.4329525237]
[2019-03-26 19:58:49,948] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:58:49,951] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9068456912022076
[2019-03-26 19:58:52,538] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.2074 2927546585.9425 1338.0000
[2019-03-26 19:58:52,590] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8657.7669 2779497663.8967 933.0000
[2019-03-26 19:58:52,985] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8493.9112 2842778418.7734 1131.0000
[2019-03-26 19:58:53,019] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7995.3563 3007937057.5632 1766.0000
[2019-03-26 19:58:53,125] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.9141 3164254244.9626 1778.0000
[2019-03-26 19:58:54,143] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 425000, evaluation results [425000.0, 7881.914110821881, 3164254244.9625816, 1778.0, 8252.207390139796, 2927546585.9425, 1338.0, 8657.766851449904, 2779497663.8966665, 933.0, 7995.356252368326, 3007937057.5631742, 1766.0, 8493.911166823438, 2842778418.7733655, 1131.0]
[2019-03-26 19:58:54,258] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:58:54,265] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0916
[2019-03-26 19:58:54,271] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 65.66666666666666, 1.0, 2.0, 1.022795235846997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9128939175237, 1554033.728951713, 1554033.728951714, 324712.2155476182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 42000.0000, 
sim time next is 42600.0000, 
raw observation next is [26.7, 65.33333333333334, 1.0, 2.0, 1.021612509034909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1550388.656170097, 1550388.656170097, 324055.4728581236], 
processed observation next is [1.0, 0.4782608695652174, 0.46445497630331756, 0.6533333333333334, 1.0, 1.0, 1.0260391675119387, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.4306635156028047, 0.4306635156028047, 0.483664884862871], 
reward next is 0.5163, 
noisyNet noise sample is [array([-2.1473677], dtype=float32), 0.3588232]. 
=============================================
[2019-03-26 19:58:57,228] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:58:57,239] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6673
[2019-03-26 19:58:57,245] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.76666666666667, 78.33333333333334, 1.0, 2.0, 0.3816620748357473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 575991.1523182008, 575991.1523182008, 172551.5399395633], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 67800.0000, 
sim time next is 68400.0000, 
raw observation next is [24.6, 79.0, 1.0, 2.0, 0.3801840191386233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 574968.5705695054, 574968.570569506, 172496.9382077948], 
processed observation next is [1.0, 0.8260869565217391, 0.36492890995260674, 0.79, 1.0, 1.0, 0.25323375799834136, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15971349182486264, 0.15971349182486277, 0.2574581167280519], 
reward next is 0.7425, 
noisyNet noise sample is [array([-0.29478145], dtype=float32), 0.6058046]. 
=============================================
[2019-03-26 19:58:58,532] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:58:58,541] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2696
[2019-03-26 19:58:58,547] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.91666666666666, 91.00000000000001, 1.0, 2.0, 0.4676925561097179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 708839.6244483565, 708839.6244483565, 185466.9295031413], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 112200.0000, 
sim time next is 112800.0000, 
raw observation next is [22.93333333333333, 91.0, 1.0, 2.0, 0.4666124415444929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 706773.0203536035, 706773.020353603, 185245.6791247776], 
processed observation next is [1.0, 0.30434782608695654, 0.28593996840442326, 0.91, 1.0, 1.0, 0.35736438740300347, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1963258389871121, 0.19632583898711192, 0.27648608824593673], 
reward next is 0.7235, 
noisyNet noise sample is [array([0.817683], dtype=float32), -1.8433111]. 
=============================================
[2019-03-26 19:58:58,583] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:58:58,592] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3298
[2019-03-26 19:58:58,599] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 90.0, 1.0, 2.0, 0.3892994580637094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 599667.7422333704, 599667.7422333698, 174970.4936730671], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 99000.0000, 
sim time next is 99600.0000, 
raw observation next is [22.5, 90.0, 1.0, 2.0, 0.3837474741719324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 591120.1740616008, 591120.1740616008, 174207.1257026495], 
processed observation next is [1.0, 0.13043478260869565, 0.2654028436018958, 0.9, 1.0, 1.0, 0.25752707731558117, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16420004835044466, 0.16420004835044466, 0.2600106353770888], 
reward next is 0.7400, 
noisyNet noise sample is [array([1.4556757], dtype=float32), -1.9047017]. 
=============================================
[2019-03-26 19:59:22,377] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:59:22,386] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1532
[2019-03-26 19:59:22,394] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 82.0, 1.0, 2.0, 0.2388942770793331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 395431.8616058314, 395431.8616058314, 159716.1237722852], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 508800.0000, 
sim time next is 509400.0000, 
raw observation next is [19.6, 82.5, 1.0, 2.0, 0.2383751792109612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 394586.0703036775, 394586.0703036775, 159665.8583637842], 
processed observation next is [1.0, 0.9130434782608695, 0.127962085308057, 0.825, 1.0, 1.0, 0.08237973398910989, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.10960724175102153, 0.10960724175102153, 0.23830725128923017], 
reward next is 0.7617, 
noisyNet noise sample is [array([-0.21398365], dtype=float32), 0.43321025]. 
=============================================
[2019-03-26 19:59:30,458] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:59:30,472] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5979
[2019-03-26 19:59:30,480] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.53333333333333, 76.0, 1.0, 2.0, 0.2415907449897015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 399704.3218930089, 399704.3218930089, 159988.1921951164], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 632400.0000, 
sim time next is 633000.0000, 
raw observation next is [20.76666666666667, 75.0, 1.0, 2.0, 0.2451580971734862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 405215.5084417796, 405215.5084417796, 160358.747180089], 
processed observation next is [1.0, 0.30434782608695654, 0.18325434439178534, 0.75, 1.0, 1.0, 0.09055192430540504, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11255986345604989, 0.11255986345604989, 0.23934141370162537], 
reward next is 0.7607, 
noisyNet noise sample is [array([0.7205723], dtype=float32), 1.1972903]. 
=============================================
[2019-03-26 19:59:30,493] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[70.400276]
 [70.374916]
 [70.395935]
 [70.428734]
 [70.41297 ]], R is [[70.48428345]
 [70.54065704]
 [70.59683228]
 [70.6536026 ]
 [70.71118164]].
[2019-03-26 19:59:32,380] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:59:32,391] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8279
[2019-03-26 19:59:32,396] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.01666666666667, 73.83333333333333, 1.0, 2.0, 0.2422879635159711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 399902.8632683962, 399902.8632683962, 160113.5336271545], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 676200.0000, 
sim time next is 676800.0000, 
raw observation next is [20.8, 75.0, 1.0, 2.0, 0.2413351189298515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 398553.193688629, 398553.1936886283, 160011.0346077084], 
processed observation next is [1.0, 0.8695652173913043, 0.1848341232227489, 0.75, 1.0, 1.0, 0.0859459264215078, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11070922046906362, 0.11070922046906342, 0.2388224397129976], 
reward next is 0.7612, 
noisyNet noise sample is [array([-1.1014664], dtype=float32), 0.17776285]. 
=============================================
[2019-03-26 19:59:32,803] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:59:32,814] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9434
[2019-03-26 19:59:32,817] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.8, 75.0, 1.0, 2.0, 0.2413351189298515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 398553.193688629, 398553.1936886283, 160011.0346077084], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 676800.0000, 
sim time next is 677400.0000, 
raw observation next is [20.68333333333334, 75.83333333333333, 1.0, 2.0, 0.2418179191474085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 399429.7051594391, 399429.7051594391, 160052.8851681269], 
processed observation next is [1.0, 0.8695652173913043, 0.17930489731437638, 0.7583333333333333, 1.0, 1.0, 0.08652761343061263, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11095269587762198, 0.11095269587762198, 0.2388849032360103], 
reward next is 0.7611, 
noisyNet noise sample is [array([-0.7280629], dtype=float32), 0.27760532]. 
=============================================
[2019-03-26 19:59:34,527] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:59:34,538] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2473
[2019-03-26 19:59:34,541] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.03333333333333, 84.83333333333334, 1.0, 2.0, 0.2348593271863968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 389869.3055047795, 389869.3055047789, 159212.0337395614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 713400.0000, 
sim time next is 714000.0000, 
raw observation next is [19.26666666666667, 83.66666666666667, 1.0, 2.0, 0.2273105243081364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 377038.4691451734, 377038.4691451727, 158558.7234487081], 
processed observation next is [1.0, 0.2608695652173913, 0.1121642969984204, 0.8366666666666667, 1.0, 1.0, 0.06904882446763419, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1047329080958815, 0.1047329080958813, 0.23665481111747477], 
reward next is 0.7633, 
noisyNet noise sample is [array([0.08641246], dtype=float32), -1.1552343]. 
=============================================
[2019-03-26 19:59:34,557] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[77.274734]
 [77.37679 ]
 [77.39926 ]
 [77.43958 ]
 [77.48894 ]], R is [[77.25950623]
 [77.24928284]
 [77.24076843]
 [77.23265076]
 [77.22497559]].
[2019-03-26 19:59:39,998] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:59:40,004] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8096
[2019-03-26 19:59:40,009] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.65, 70.0, 1.0, 2.0, 0.2890485833937786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 463072.8546722764, 463072.8546722764, 164469.9306947154], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 811800.0000, 
sim time next is 812400.0000, 
raw observation next is [23.83333333333334, 69.0, 1.0, 2.0, 0.2896023743382179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 463720.3568616569, 463720.3568616569, 164512.0927808028], 
processed observation next is [0.0, 0.391304347826087, 0.32859399684044266, 0.69, 1.0, 1.0, 0.14409924619062395, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12881121023934913, 0.12881121023934913, 0.24554043698627284], 
reward next is 0.7545, 
noisyNet noise sample is [array([0.27570048], dtype=float32), 0.038125966]. 
=============================================
[2019-03-26 19:59:41,291] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:59:41,302] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4657
[2019-03-26 19:59:41,308] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.86666666666667, 62.66666666666667, 1.0, 2.0, 0.288554224655352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 462045.0355241917, 462045.0355241924, 164396.7581199094], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 823200.0000, 
sim time next is 823800.0000, 
raw observation next is [24.83333333333334, 62.83333333333333, 1.0, 2.0, 0.2893466080141956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 463352.7591582451, 463352.7591582457, 164487.1777494199], 
processed observation next is [0.0, 0.5217391304347826, 0.3759873617693526, 0.6283333333333333, 1.0, 1.0, 0.14379109399300674, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1287090997661792, 0.12870909976617936, 0.24550325037226853], 
reward next is 0.7545, 
noisyNet noise sample is [array([-0.8393085], dtype=float32), -0.3339452]. 
=============================================
[2019-03-26 19:59:49,560] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 19:59:49,569] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2841
[2019-03-26 19:59:49,572] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.88333333333333, 93.16666666666666, 1.0, 2.0, 0.3316361779264139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 514014.6031773683, 514014.6031773683, 167830.4349445109], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 964200.0000, 
sim time next is 964800.0000, 
raw observation next is [21.9, 93.0, 1.0, 2.0, 0.3315436675871201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 513924.8772747177, 513924.8772747171, 167825.1107573162], 
processed observation next is [1.0, 0.17391304347826086, 0.23696682464454974, 0.93, 1.0, 1.0, 0.19463092480375918, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14275691035408825, 0.14275691035408808, 0.25048523993629285], 
reward next is 0.7495, 
noisyNet noise sample is [array([0.71853495], dtype=float32), 1.0115112]. 
=============================================
[2019-03-26 19:59:49,708] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 19:59:49,708] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:59:49,710] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:59:49,710] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:59:49,710] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:59:49,711] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:59:49,713] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:59:49,713] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:59:49,714] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:59:49,715] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:59:49,716] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:59:49,738] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run19
[2019-03-26 19:59:49,739] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run19
[2019-03-26 19:59:49,757] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run19
[2019-03-26 19:59:49,794] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run19
[2019-03-26 19:59:49,812] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run19
[2019-03-26 20:00:02,523] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.39649525]
[2019-03-26 20:00:02,524] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.19665766, 79.89821685666668, 1.0, 2.0, 0.3438434348478732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 535564.90614204, 535564.9061420406, 169616.2159124248]
[2019-03-26 20:00:02,525] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:00:02,529] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7733009432537693
[2019-03-26 20:00:15,252] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.39649525]
[2019-03-26 20:00:15,255] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.11866719333334, 95.54050666, 1.0, 2.0, 0.7526222278093179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1063775.406624269, 1063775.406624269, 234253.0079003109]
[2019-03-26 20:00:15,256] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:00:15,258] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8975335014722059
[2019-03-26 20:00:36,966] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.39649525]
[2019-03-26 20:00:36,967] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.18272237333333, 87.53724194, 1.0, 2.0, 0.5096070995360632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712101.2445788793, 712101.2445788793, 185114.3389293423]
[2019-03-26 20:00:36,969] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:00:36,971] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5291083358347525
[2019-03-26 20:00:41,918] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.39649525]
[2019-03-26 20:00:41,919] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.88414707333333, 69.94988542666667, 1.0, 2.0, 0.7714294222766186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1078145.271200176, 1078145.271200176, 237018.3350331293]
[2019-03-26 20:00:41,920] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:00:41,922] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8442878423878125
[2019-03-26 20:00:44,145] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.39649525]
[2019-03-26 20:00:44,148] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [35.94106138333333, 58.64807492999999, 1.0, 2.0, 0.6935577278786914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 969262.5769539227, 969262.5769539227, 219469.8226563269]
[2019-03-26 20:00:44,150] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:00:44,154] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.06126225255363438
[2019-03-26 20:01:01,679] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.39649525]
[2019-03-26 20:01:01,680] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.33333333333334, 65.0, 1.0, 2.0, 0.508066914699337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709948.342770735, 709948.3427707345, 184870.064162707]
[2019-03-26 20:01:01,681] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:01:01,685] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6465234278427068
[2019-03-26 20:01:02,122] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.39649525]
[2019-03-26 20:01:02,124] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.140545565, 75.96264486, 1.0, 2.0, 0.54297271266073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 758741.4509476878, 758741.4509476884, 190602.7462035587]
[2019-03-26 20:01:02,125] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:01:02,127] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8734509309104372
[2019-03-26 20:01:02,887] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.39649525]
[2019-03-26 20:01:02,888] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.03333333333333, 73.33333333333334, 1.0, 2.0, 0.6071775903924442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 848496.1634830114, 848496.1634830114, 202089.6746038916]
[2019-03-26 20:01:02,889] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:01:02,895] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8360236959920797
[2019-03-26 20:01:43,794] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.5078 2779423486.9439 933.0000
[2019-03-26 20:01:43,827] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6674 3164193356.1757 1778.0000
[2019-03-26 20:01:43,861] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.0966 3007867509.5417 1766.0000
[2019-03-26 20:01:44,005] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.2074 2927546585.9425 1338.0000
[2019-03-26 20:01:44,044] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8494.6521 2842708650.5645 1131.0000
[2019-03-26 20:01:45,058] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 450000, evaluation results [450000.0, 7882.6673903550445, 3164193356.175722, 1778.0, 8252.207390139796, 2927546585.9425, 1338.0, 8658.507764904378, 2779423486.9438543, 933.0, 7996.096616164504, 3007867509.5416894, 1766.0, 8494.652070649916, 2842708650.564488, 1131.0]
[2019-03-26 20:01:54,108] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:01:54,119] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0741
[2019-03-26 20:01:54,124] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 73.0, 1.0, 2.0, 0.3295946731302897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 516485.2663641399, 516485.2663641393, 168181.3163408892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1105200.0000, 
sim time next is 1105800.0000, 
raw observation next is [24.06666666666667, 73.66666666666667, 1.0, 2.0, 0.3276070559093963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 513846.8382420852, 513846.8382420846, 167988.2240346978], 
processed observation next is [1.0, 0.8260869565217391, 0.3396524486571882, 0.7366666666666667, 1.0, 1.0, 0.18988801916794737, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14273523284502365, 0.1427352328450235, 0.2507286925891012], 
reward next is 0.7493, 
noisyNet noise sample is [array([-0.64605623], dtype=float32), 0.98829764]. 
=============================================
[2019-03-26 20:02:00,575] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:02:00,586] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7653
[2019-03-26 20:02:00,590] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.93333333333333, 91.66666666666667, 1.0, 2.0, 0.345449281210454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 537458.4168164312, 537458.4168164312, 169755.1575519492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1219800.0000, 
sim time next is 1220400.0000, 
raw observation next is [21.9, 92.0, 1.0, 2.0, 0.3420071343676661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 531989.4497294846, 531989.4497294846, 169310.1688530309], 
processed observation next is [1.0, 0.13043478260869565, 0.23696682464454974, 0.92, 1.0, 1.0, 0.2072375112863447, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14777484714707906, 0.14777484714707906, 0.25270174455676253], 
reward next is 0.7473, 
noisyNet noise sample is [array([1.1977432], dtype=float32), 0.49046087]. 
=============================================
[2019-03-26 20:02:01,488] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:02:01,495] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3417
[2019-03-26 20:02:01,502] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 94.0, 1.0, 2.0, 0.4536550556866039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 646032.0440954482, 646032.0440954489, 178216.6684105062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1303200.0000, 
sim time next is 1303800.0000, 
raw observation next is [24.21666666666667, 93.83333333333334, 1.0, 2.0, 0.7559299908264423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1076912.142342209, 1076912.142342209, 236186.4472046813], 
processed observation next is [1.0, 0.08695652173913043, 0.34676145339652464, 0.9383333333333335, 1.0, 1.0, 0.7059397479836654, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2991422617617247, 0.2991422617617247, 0.35251708538012133], 
reward next is 0.6475, 
noisyNet noise sample is [array([0.13505651], dtype=float32), 0.70110387]. 
=============================================
[2019-03-26 20:02:07,370] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:02:07,384] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6577
[2019-03-26 20:02:07,390] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.06666666666667, 95.0, 1.0, 2.0, 0.650022440921547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 963176.7206946, 963176.7206946007, 217447.8527135873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1326000.0000, 
sim time next is 1326600.0000, 
raw observation next is [23.05, 95.0, 1.0, 2.0, 0.732035705460625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1085236.327081783, 1085236.327081784, 236145.6492130463], 
processed observation next is [1.0, 0.34782608695652173, 0.2914691943127963, 0.95, 1.0, 1.0, 0.6771514523621988, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.30145453530049526, 0.30145453530049554, 0.352456192855293], 
reward next is 0.6475, 
noisyNet noise sample is [array([1.2335335], dtype=float32), 2.5175176]. 
=============================================
[2019-03-26 20:02:07,469] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:02:07,477] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6513
[2019-03-26 20:02:07,482] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 90.0, 1.0, 2.0, 0.6095514060263363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 954581.580616492, 954581.5806164913, 214705.5538799792], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1344000.0000, 
sim time next is 1344600.0000, 
raw observation next is [21.75, 89.5, 1.0, 2.0, 0.6325786714045516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 994203.1120139954, 994203.1120139954, 220021.807208456], 
processed observation next is [1.0, 0.5652173913043478, 0.2298578199052133, 0.895, 1.0, 1.0, 0.5573237004874115, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2761675311149987, 0.2761675311149987, 0.3283907570275463], 
reward next is 0.6716, 
noisyNet noise sample is [array([-0.36238384], dtype=float32), -0.37067178]. 
=============================================
[2019-03-26 20:02:10,293] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:02:10,301] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5273
[2019-03-26 20:02:10,304] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.46666666666667, 98.0, 1.0, 2.0, 0.313372102674091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 496429.3250085902, 496429.3250085902, 166776.1571103009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1396200.0000, 
sim time next is 1396800.0000, 
raw observation next is [20.5, 98.0, 1.0, 2.0, 0.3132743445435494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 495886.8030634278, 495886.8030634284, 166728.6082702915], 
processed observation next is [0.0, 0.17391304347826086, 0.1706161137440759, 0.98, 1.0, 1.0, 0.17261969222114387, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1377463341842855, 0.13774633418428567, 0.24884866906013656], 
reward next is 0.7512, 
noisyNet noise sample is [array([1.0225847], dtype=float32), -1.2849041]. 
=============================================
[2019-03-26 20:02:19,018] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:02:19,025] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3566
[2019-03-26 20:02:19,033] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.25, 58.66666666666667, 1.0, 2.0, 0.346292124444137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 534723.2371210987, 534723.2371210987, 169422.5073354292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1529400.0000, 
sim time next is 1530000.0000, 
raw observation next is [27.1, 59.0, 1.0, 2.0, 0.3437258197622903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 531896.1454583206, 531896.14545832, 169226.5476227], 
processed observation next is [0.0, 0.7391304347826086, 0.4834123222748816, 0.59, 1.0, 1.0, 0.20930821658107263, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14774892929397795, 0.1477489292939778, 0.25257693675029846], 
reward next is 0.7474, 
noisyNet noise sample is [array([0.43459305], dtype=float32), 0.24761714]. 
=============================================
[2019-03-26 20:02:19,056] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[69.095955]
 [69.12684 ]
 [69.1537  ]
 [69.18606 ]
 [69.22646 ]], R is [[69.1223526 ]
 [69.1782608 ]
 [69.23326874]
 [69.28733063]
 [69.34053802]].
[2019-03-26 20:02:19,488] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 8.3188044e-38], sum to 1.0000
[2019-03-26 20:02:19,502] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1447
[2019-03-26 20:02:19,506] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 83.0, 1.0, 2.0, 0.3586410818911617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 549815.2703252132, 549815.2703252139, 170554.578030716], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1540800.0000, 
sim time next is 1541400.0000, 
raw observation next is [23.51666666666667, 83.5, 1.0, 2.0, 0.3583791891732259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 549517.5405913909, 549517.5405913909, 170532.6455839205], 
processed observation next is [0.0, 0.8695652173913043, 0.31358609794628767, 0.835, 1.0, 1.0, 0.22696287852195893, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15264376127538637, 0.15264376127538637, 0.25452633669241864], 
reward next is 0.7455, 
noisyNet noise sample is [array([-0.7047209], dtype=float32), 0.4240083]. 
=============================================
[2019-03-26 20:02:25,878] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:02:25,886] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4433
[2019-03-26 20:02:25,894] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.55, 87.5, 1.0, 2.0, 0.5092486435614985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 711600.1871100579, 711600.1871100579, 185058.0255248951], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1715400.0000, 
sim time next is 1716000.0000, 
raw observation next is [26.5, 88.0, 1.0, 2.0, 0.508513914151567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 710573.1672812877, 710573.167281287, 184941.0680809185], 
processed observation next is [1.0, 0.8695652173913043, 0.4549763033175356, 0.88, 1.0, 1.0, 0.40784808933923733, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19738143535591327, 0.19738143535591307, 0.2760314448968933], 
reward next is 0.7240, 
noisyNet noise sample is [array([-0.54747427], dtype=float32), -1.7347125]. 
=============================================
[2019-03-26 20:02:25,911] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[74.210846]
 [74.04094 ]
 [74.10898 ]
 [74.25136 ]
 [73.94854 ]], R is [[74.19554901]
 [74.17739105]
 [74.15929413]
 [74.14172363]
 [74.12470245]].
[2019-03-26 20:02:32,712] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0608208e-37 1.0000000e+00 2.1941006e-34 0.0000000e+00 1.3768080e-36], sum to 1.0000
[2019-03-26 20:02:32,726] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7559
[2019-03-26 20:02:32,730] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.23333333333333, 85.83333333333334, 1.0, 2.0, 0.7594696038246377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1162191.58322926, 1162191.58322926, 247302.023874254], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1771800.0000, 
sim time next is 1772400.0000, 
raw observation next is [23.16666666666667, 85.66666666666667, 1.0, 2.0, 0.6935849271315306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1064085.705241788, 1064085.705241787, 231391.2392456986], 
processed observation next is [1.0, 0.5217391304347826, 0.2969984202211693, 0.8566666666666667, 1.0, 1.0, 0.6308252134114827, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.29557936256716333, 0.29557936256716305, 0.3453600585756696], 
reward next is 0.6546, 
noisyNet noise sample is [array([-1.1673819], dtype=float32), -0.5433093]. 
=============================================
[2019-03-26 20:02:40,681] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-26 20:02:40,686] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:02:40,687] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:02:40,688] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:02:40,688] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:02:40,689] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:02:40,690] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:02:40,691] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:02:40,692] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:02:40,694] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:02:40,689] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:02:40,706] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run20
[2019-03-26 20:02:40,707] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run20
[2019-03-26 20:02:40,725] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run20
[2019-03-26 20:02:40,742] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run20
[2019-03-26 20:02:40,775] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run20
[2019-03-26 20:03:24,391] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.33689347]
[2019-03-26 20:03:24,392] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.0, 100.0, 1.0, 2.0, 0.3300879593457952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 513241.08261196, 513241.0826119606, 167820.2310250227]
[2019-03-26 20:03:24,393] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:03:24,396] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5669658463801638
[2019-03-26 20:03:43,353] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.33689347]
[2019-03-26 20:03:43,354] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.0, 59.0, 1.0, 2.0, 0.6302051105377229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 880689.1553221784, 880689.1553221778, 206508.3735358223]
[2019-03-26 20:03:43,356] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.33689347]
[2019-03-26 20:03:43,356] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:03:43,357] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.74988257333333, 85.21653490333334, 1.0, 2.0, 0.6931490882293797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 968691.2333678192, 968691.2333678186, 219382.125401291]
[2019-03-26 20:03:43,359] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:03:43,360] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3838471072559031
[2019-03-26 20:03:43,361] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.0692662617908727
[2019-03-26 20:04:05,848] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.33689347]
[2019-03-26 20:04:05,848] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.55, 80.5, 1.0, 2.0, 0.7393261843622403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1033256.144428274, 1033256.144428274, 229566.2089398333]
[2019-03-26 20:04:05,849] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:04:05,851] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.01067325218293691
[2019-03-26 20:04:18,141] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.33689347]
[2019-03-26 20:04:18,144] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.98506899666667, 57.58447064333333, 1.0, 2.0, 0.5288650063204039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 807168.6243793704, 807168.6243793704, 196499.417728309]
[2019-03-26 20:04:18,148] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:04:18,152] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3513333311579022
[2019-03-26 20:04:24,400] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.33689347]
[2019-03-26 20:04:24,402] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.6, 92.66666666666666, 1.0, 2.0, 0.5816025895820179, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9680344864713892, 6.911200000000001, 6.9112, 168.9129564458975, 1626765.849168869, 1626765.849168868, 346699.9389117768]
[2019-03-26 20:04:24,404] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:04:24,405] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.39428468423782337
[2019-03-26 20:04:34,244] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.0966 3007867509.5417 1766.0000
[2019-03-26 20:04:34,883] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.5078 2779423486.9439 933.0000
[2019-03-26 20:04:34,941] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.9141 3164254244.9626 1778.0000
[2019-03-26 20:04:34,947] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8494.6521 2842708650.5645 1131.0000
[2019-03-26 20:04:35,043] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.2074 2927546585.9425 1338.0000
[2019-03-26 20:04:36,058] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 475000, evaluation results [475000.0, 7881.914110821881, 3164254244.9625816, 1778.0, 8252.207390139796, 2927546585.9425, 1338.0, 8658.507764904378, 2779423486.9438543, 933.0, 7996.096616164504, 3007867509.5416894, 1766.0, 8494.652070649916, 2842708650.564488, 1131.0]
[2019-03-26 20:04:37,045] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.4684702e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 20:04:37,054] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1382
[2019-03-26 20:04:37,064] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 82.0, 1.0, 2.0, 0.9743470879759385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1390709.438635488, 1390709.438635488, 295639.1465482148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1933200.0000, 
sim time next is 1933800.0000, 
raw observation next is [25.85, 81.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.009109463974895, 6.9112, 168.9124048539953, 1553421.696664891, 1483961.579989437, 316169.3551255277], 
processed observation next is [1.0, 0.391304347826087, 0.4241706161137442, 0.8166666666666668, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.009790946397489541, 0.0, 0.829437236266654, 0.4315060268513586, 0.41221154999706583, 0.4718945598888473], 
reward next is 0.0386, 
noisyNet noise sample is [array([-0.6721469], dtype=float32), -0.49256068]. 
=============================================
[2019-03-26 20:04:43,189] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:04:43,202] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4020
[2019-03-26 20:04:43,208] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 94.0, 1.0, 2.0, 0.5037652164897599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 703935.3643046204, 703935.3643046204, 184188.2834954883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2025000.0000, 
sim time next is 2025600.0000, 
raw observation next is [25.5, 94.0, 1.0, 2.0, 0.5033578552556454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 703365.9504080118, 703365.9504080118, 184124.0527852743], 
processed observation next is [0.0, 0.43478260869565216, 0.40758293838862564, 0.94, 1.0, 1.0, 0.4016359701875245, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19537943066889216, 0.19537943066889216, 0.27481201908249897], 
reward next is 0.7252, 
noisyNet noise sample is [array([1.7103077], dtype=float32), -0.33156994]. 
=============================================
[2019-03-26 20:04:44,973] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:04:44,983] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8345
[2019-03-26 20:04:44,990] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 74.5, 1.0, 2.0, 0.5522999413513621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 771779.907337789, 771779.9073377895, 192196.7328692878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2115000.0000, 
sim time next is 2115600.0000, 
raw observation next is [30.0, 74.66666666666667, 1.0, 2.0, 0.5532418400802809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 773096.5887330913, 773096.5887330906, 192359.046273165], 
processed observation next is [0.0, 0.4782608695652174, 0.6208530805687204, 0.7466666666666667, 1.0, 1.0, 0.46173715672322996, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21474905242585868, 0.21474905242585848, 0.28710305413905224], 
reward next is 0.7129, 
noisyNet noise sample is [array([-0.43184173], dtype=float32), 0.45243663]. 
=============================================
[2019-03-26 20:04:45,794] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:04:45,801] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4950
[2019-03-26 20:04:45,807] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.4, 75.0, 1.0, 2.0, 0.572840619621864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 800494.1171533844, 800494.1171533844, 195795.676688901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2129400.0000, 
sim time next is 2130000.0000, 
raw observation next is [30.43333333333333, 74.66666666666666, 1.0, 2.0, 0.5726233780259352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 800190.4268804025, 800190.4268804025, 195756.90941491], 
processed observation next is [0.0, 0.6521739130434783, 0.6413902053712479, 0.7466666666666666, 1.0, 1.0, 0.4850884072601629, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2222751185778896, 0.2222751185778896, 0.2921744916640448], 
reward next is 0.7078, 
noisyNet noise sample is [array([-0.09302478], dtype=float32), 0.10253308]. 
=============================================
[2019-03-26 20:04:45,822] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[68.19962 ]
 [68.17225 ]
 [68.152306]
 [68.16992 ]
 [68.14437 ]], R is [[68.25693512]
 [68.28213501]
 [68.30685425]
 [68.33029175]
 [68.35423279]].
[2019-03-26 20:04:47,043] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:04:47,054] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1443
[2019-03-26 20:04:47,060] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.93333333333333, 97.33333333333334, 1.0, 2.0, 0.4583683932920895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 648304.8621784303, 648304.8621784303, 178340.272852537], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2089200.0000, 
sim time next is 2089800.0000, 
raw observation next is [23.9, 97.5, 1.0, 2.0, 0.4569873957359317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 646711.1113267598, 646711.1113267604, 178184.7499755667], 
processed observation next is [0.0, 0.17391304347826086, 0.33175355450236965, 0.975, 1.0, 1.0, 0.3457679466697972, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1796419753685444, 0.17964197536854454, 0.26594738802323387], 
reward next is 0.7341, 
noisyNet noise sample is [array([-0.24999876], dtype=float32), 0.6451837]. 
=============================================
[2019-03-26 20:04:47,209] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:04:47,217] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2965
[2019-03-26 20:04:47,221] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.25, 75.0, 1.0, 2.0, 0.5683418105705752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 794205.0789347552, 794205.0789347552, 194996.6378245307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2136600.0000, 
sim time next is 2137200.0000, 
raw observation next is [30.06666666666666, 75.66666666666666, 1.0, 2.0, 0.5661459106881557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 791135.3693099535, 791135.3693099535, 194608.8102520434], 
processed observation next is [0.0, 0.7391304347826086, 0.6240126382306473, 0.7566666666666666, 1.0, 1.0, 0.47728422974476586, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21975982480832043, 0.21975982480832043, 0.2904609108239454], 
reward next is 0.7095, 
noisyNet noise sample is [array([1.0664337], dtype=float32), -0.016247958]. 
=============================================
[2019-03-26 20:04:51,874] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:04:51,881] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2048
[2019-03-26 20:04:51,889] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.5, 73.33333333333334, 1.0, 2.0, 0.5552965038335744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 775968.8113924285, 775968.8113924279, 192714.5463767894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2226000.0000, 
sim time next is 2226600.0000, 
raw observation next is [30.35, 74.0, 1.0, 2.0, 0.5545794842767985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 774966.4860106757, 774966.4860106757, 192590.4977421925], 
processed observation next is [1.0, 0.782608695652174, 0.637440758293839, 0.74, 1.0, 1.0, 0.4633487762371066, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21526846833629878, 0.21526846833629878, 0.28744850409282463], 
reward next is 0.7126, 
noisyNet noise sample is [array([-0.37757194], dtype=float32), 0.75402653]. 
=============================================
[2019-03-26 20:04:53,207] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.7938605e-32 1.0000000e+00 2.2333766e-26 4.0087965e-33 4.0467110e-28], sum to 1.0000
[2019-03-26 20:04:53,214] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0109
[2019-03-26 20:04:53,220] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 96.66666666666666, 1.0, 2.0, 0.5738524123772334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 801908.541795593, 801908.541795593, 195969.5670910848], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2176800.0000, 
sim time next is 2177400.0000, 
raw observation next is [24.55, 96.83333333333334, 1.0, 2.0, 0.5637536282232145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 787791.14109876, 787791.14109876, 194182.0596976558], 
processed observation next is [1.0, 0.17391304347826086, 0.3625592417061612, 0.9683333333333334, 1.0, 1.0, 0.47440196171471627, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21883087252743333, 0.21883087252743333, 0.28982396969799373], 
reward next is 0.7102, 
noisyNet noise sample is [array([-0.13773032], dtype=float32), -0.9138041]. 
=============================================
[2019-03-26 20:04:58,048] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.9606892e-32 1.0000000e+00 9.9375578e-31 8.9841511e-36 1.4974632e-26], sum to 1.0000
[2019-03-26 20:04:58,054] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4559
[2019-03-26 20:04:58,058] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.13333333333333, 86.33333333333334, 1.0, 2.0, 0.7262191595118556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1014929.476273502, 1014929.476273502, 226603.468039346], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2258400.0000, 
sim time next is 2259000.0000, 
raw observation next is [26.1, 86.5, 1.0, 2.0, 0.7114756872993393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 994315.052190677, 994315.0521906777, 223338.8088254442], 
processed observation next is [1.0, 0.13043478260869565, 0.4360189573459717, 0.865, 1.0, 1.0, 0.6523803461437823, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2761986256085214, 0.2761986256085216, 0.3333415057096182], 
reward next is 0.6667, 
noisyNet noise sample is [array([-0.73682207], dtype=float32), -2.1418262]. 
=============================================
[2019-03-26 20:04:58,071] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[58.97778 ]
 [59.135044]
 [59.57444 ]
 [59.515335]
 [59.40994 ]], R is [[58.98796844]
 [59.05987549]
 [59.12075424]
 [59.21009827]
 [59.29276276]].
[2019-03-26 20:04:58,826] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8993864e-34 1.0000000e+00 4.7446710e-30 6.8558213e-38 9.3579443e-29], sum to 1.0000
[2019-03-26 20:04:58,838] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9673
[2019-03-26 20:04:58,843] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.76666666666667, 77.33333333333333, 1.0, 2.0, 0.6467653924060522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 903841.4056028577, 903841.4056028584, 209771.9709028536], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2272200.0000, 
sim time next is 2272800.0000, 
raw observation next is [27.93333333333334, 76.66666666666667, 1.0, 2.0, 0.661238315044903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 924075.8179274382, 924075.8179274389, 212698.9042671591], 
processed observation next is [1.0, 0.30434782608695654, 0.5229067930489735, 0.7666666666666667, 1.0, 1.0, 0.5918533916203651, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2566877272020662, 0.25668772720206634, 0.31746105114501355], 
reward next is 0.6825, 
noisyNet noise sample is [array([1.4774855], dtype=float32), -0.962308]. 
=============================================
[2019-03-26 20:05:06,752] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 1.190003e-34 0.000000e+00 6.289336e-38], sum to 1.0000
[2019-03-26 20:05:06,762] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8822
[2019-03-26 20:05:06,768] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.43333333333334, 70.66666666666667, 1.0, 2.0, 0.5799419195826917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 810421.3417291143, 810421.3417291143, 197069.1712000144], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2402400.0000, 
sim time next is 2403000.0000, 
raw observation next is [31.3, 71.5, 1.0, 2.0, 0.5793604633452023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 809608.4945816617, 809608.4945816617, 196964.4400551743], 
processed observation next is [1.0, 0.8260869565217391, 0.6824644549763034, 0.715, 1.0, 1.0, 0.4932053775243401, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22489124849490602, 0.22489124849490602, 0.29397677620175267], 
reward next is 0.7060, 
noisyNet noise sample is [array([0.5364439], dtype=float32), -3.7421198]. 
=============================================
[2019-03-26 20:05:06,792] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[58.522762]
 [58.838524]
 [58.864285]
 [59.012157]
 [59.58466 ]], R is [[58.34870529]
 [58.47108841]
 [58.59238434]
 [58.71340179]
 [58.83403015]].
[2019-03-26 20:05:07,208] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 7.188034e-34 0.000000e+00 5.635911e-33], sum to 1.0000
[2019-03-26 20:05:07,221] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8214
[2019-03-26 20:05:07,225] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 82.66666666666667, 1.0, 2.0, 0.736007205789709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1028615.410809548, 1028615.410809548, 228809.0875869458], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2434800.0000, 
sim time next is 2435400.0000, 
raw observation next is [27.75, 83.0, 1.0, 2.0, 0.7142453982520539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 998187.6505371014, 998187.650537102, 223949.9227639498], 
processed observation next is [1.0, 0.17391304347826086, 0.514218009478673, 0.83, 1.0, 1.0, 0.6557173472916312, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.27727434737141704, 0.2772743473714172, 0.3342536160655967], 
reward next is 0.6657, 
noisyNet noise sample is [array([-0.4434104], dtype=float32), -0.13481835]. 
=============================================
[2019-03-26 20:05:09,123] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.4011501e-36 1.0000000e+00 1.2977996e-29 0.0000000e+00 2.6019209e-36], sum to 1.0000
[2019-03-26 20:05:09,132] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3696
[2019-03-26 20:05:09,137] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666666, 94.16666666666667, 1.0, 2.0, 0.5484156411384205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 766350.0565213942, 766350.0565213948, 191529.5675732923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2506200.0000, 
sim time next is 2506800.0000, 
raw observation next is [26.63333333333333, 94.33333333333334, 1.0, 2.0, 0.5478081280687839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 765500.8184588548, 765500.8184588548, 191425.7336431171], 
processed observation next is [1.0, 0.0, 0.46129541864139006, 0.9433333333333335, 1.0, 1.0, 0.4551905157455227, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2126391162385708, 0.2126391162385708, 0.2857100502136076], 
reward next is 0.7143, 
noisyNet noise sample is [array([1.7890986], dtype=float32), -1.3536166]. 
=============================================
[2019-03-26 20:05:19,186] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:05:19,195] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6158
[2019-03-26 20:05:19,201] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4741184900357455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 662626.665547584, 662626.665547584, 179657.0114156023], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2622000.0000, 
sim time next is 2622600.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4745087563260036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 663170.6458928146, 663170.6458928146, 179714.9691434588], 
processed observation next is [0.0, 0.34782608695652173, 0.4312796208530806, 0.84, 1.0, 1.0, 0.36687801966988387, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1842140683035596, 0.1842140683035596, 0.268231297229043], 
reward next is 0.7318, 
noisyNet noise sample is [array([-1.7183589], dtype=float32), -1.0379531]. 
=============================================
[2019-03-26 20:05:23,499] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:05:23,508] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1065
[2019-03-26 20:05:23,512] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 97.33333333333333, 1.0, 2.0, 0.4605251161129595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 649945.3692947906, 649945.3692947912, 178475.3750857814], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2695200.0000, 
sim time next is 2695800.0000, 
raw observation next is [24.0, 97.66666666666667, 1.0, 2.0, 0.462076859757189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 650915.6321728296, 650915.632172829, 178546.2408703369], 
processed observation next is [0.0, 0.17391304347826086, 0.3364928909952607, 0.9766666666666667, 1.0, 1.0, 0.35189983103275785, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.180809897825786, 0.18080989782578583, 0.26648692667214463], 
reward next is 0.7335, 
noisyNet noise sample is [array([-0.0932379], dtype=float32), 0.48027444]. 
=============================================
[2019-03-26 20:05:27,782] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4922420e-38 1.0000000e+00 2.1556934e-37 0.0000000e+00 3.4488530e-36], sum to 1.0000
[2019-03-26 20:05:27,790] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3579
[2019-03-26 20:05:27,799] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3359076187736589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 517463.466596218, 517463.4665962186, 167998.4663704457], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2785200.0000, 
sim time next is 2785800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3387719845445776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 521876.3759363471, 521876.3759363471, 168348.8799461964], 
processed observation next is [1.0, 0.21739130434782608, 0.2417061611374408, 0.94, 1.0, 1.0, 0.2033397404151537, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14496565998231864, 0.14496565998231864, 0.251266984994323], 
reward next is 0.7487, 
noisyNet noise sample is [array([-0.6509885], dtype=float32), 1.0839958]. 
=============================================
[2019-03-26 20:05:29,015] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.0266388e-38 0.0000000e+00 1.5837998e-31], sum to 1.0000
[2019-03-26 20:05:29,024] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5534
[2019-03-26 20:05:29,028] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.3307810144630378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 513519.0467604169, 513519.0467604169, 167817.558638361], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2779200.0000, 
sim time next is 2779800.0000, 
raw observation next is [21.16666666666667, 99.00000000000001, 1.0, 2.0, 0.358306491563518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 555958.1000476147, 555958.1000476147, 171247.8310646035], 
processed observation next is [1.0, 0.17391304347826086, 0.2022116903633494, 0.9900000000000001, 1.0, 1.0, 0.22687529104038315, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15443280556878186, 0.15443280556878186, 0.25559377770836345], 
reward next is 0.7444, 
noisyNet noise sample is [array([-0.48726097], dtype=float32), 0.23340087]. 
=============================================
[2019-03-26 20:05:29,717] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:05:29,726] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2195
[2019-03-26 20:05:29,732] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 83.0, 1.0, 2.0, 0.6701957018074916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1026873.463135121, 1026873.463135121, 225814.6117439364], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2806800.0000, 
sim time next is 2807400.0000, 
raw observation next is [23.83333333333333, 83.0, 1.0, 2.0, 0.699917861205047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1067141.025263553, 1067141.025263553, 232137.4131958989], 
processed observation next is [1.0, 0.4782608695652174, 0.32859399684044216, 0.83, 1.0, 1.0, 0.6384552544639119, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2964280625732092, 0.2964280625732092, 0.3464737510386551], 
reward next is 0.6535, 
noisyNet noise sample is [array([-1.2246941], dtype=float32), 0.7876281]. 
=============================================
[2019-03-26 20:05:31,730] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 20:05:31,734] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:05:31,735] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:05:31,735] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:05:31,736] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:05:31,736] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:05:31,737] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:05:31,738] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:05:31,737] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:05:31,738] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:05:31,739] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:05:31,747] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run21
[2019-03-26 20:05:31,748] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run21
[2019-03-26 20:05:31,765] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run21
[2019-03-26 20:05:31,782] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run21
[2019-03-26 20:05:31,816] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run21
[2019-03-26 20:05:40,513] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.3217067]
[2019-03-26 20:05:40,514] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [19.64540216, 81.32142433000001, 1.0, 2.0, 0.2290211361367389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 379162.4538327176, 379162.4538327169, 158791.3602147718]
[2019-03-26 20:05:40,516] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:05:40,519] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.14322148808240864
[2019-03-26 20:05:48,658] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.3217067]
[2019-03-26 20:05:48,660] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.93460414, 94.739570205, 1.0, 2.0, 0.3107979332917399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 493117.2650736825, 493117.2650736825, 166545.3992115085]
[2019-03-26 20:05:48,662] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:05:48,664] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.28484858157710147
[2019-03-26 20:06:14,681] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.3217067]
[2019-03-26 20:06:14,682] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.64567831666667, 95.50068749833333, 1.0, 2.0, 0.3810537608759284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 572558.4262883748, 572558.4262883748, 172169.0797015345]
[2019-03-26 20:06:14,686] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:06:14,689] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.40806767755516526
[2019-03-26 20:06:36,243] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.3217067]
[2019-03-26 20:06:36,245] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.5, 59.5, 1.0, 2.0, 0.8646531660992057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1208508.376857906, 1208508.376857906, 260405.5026196333]
[2019-03-26 20:06:36,246] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:06:36,248] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.0115368816224235
[2019-03-26 20:06:49,034] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.3217067]
[2019-03-26 20:06:49,036] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.471567655, 80.393748405, 1.0, 2.0, 0.4220683058947143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 620941.8913883708, 620941.8913883708, 176265.46343554]
[2019-03-26 20:06:49,038] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:06:49,041] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7127804609768746
[2019-03-26 20:07:19,849] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.3217067]
[2019-03-26 20:07:19,850] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [19.29946966666666, 89.87519880666667, 1.0, 2.0, 0.4075522532725361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 669383.5971597641, 669383.5971597636, 180588.6424893038]
[2019-03-26 20:07:19,851] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:07:19,855] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8016097727199873
[2019-03-26 20:07:26,266] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.3217067]
[2019-03-26 20:07:26,268] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.97211070166667, 73.06263382833333, 1.0, 2.0, 0.8382349316882268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1199589.311347537, 1199589.311347537, 257512.6973804204]
[2019-03-26 20:07:26,269] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:07:26,274] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.06857598985045255
[2019-03-26 20:07:27,794] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7994.6151 3008006107.9315 1766.0000
[2019-03-26 20:07:28,106] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8493.1698 2842847906.5028 1131.0000
[2019-03-26 20:07:28,128] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8657.7669 2779497663.8967 933.0000
[2019-03-26 20:07:28,218] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.1591 3164313068.1626 1778.0000
[2019-03-26 20:07:28,267] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8250.7258 2927690427.6328 1338.0000
[2019-03-26 20:07:29,282] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 500000, evaluation results [500000.0, 7881.159078603526, 3164313068.162566, 1778.0, 8250.725820219795, 2927690427.6327953, 1338.0, 8657.766851449904, 2779497663.8966665, 933.0, 7994.615069066108, 3008006107.9315424, 1766.0, 8493.169770734836, 2842847906.5028043, 1131.0]
[2019-03-26 20:07:29,811] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.00000e+00 1.00000e+00 3.42554e-36 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-26 20:07:29,821] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6008
[2019-03-26 20:07:29,827] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3502578939371979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 539562.0788390585, 539562.0788390585, 169780.5686765022], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2853600.0000, 
sim time next is 2854200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3499797968893803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 539133.7468120259, 539133.7468120259, 169745.3673435445], 
processed observation next is [1.0, 0.0, 0.2417061611374408, 0.94, 1.0, 1.0, 0.2168431287823859, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14975937411445164, 0.14975937411445164, 0.25335129454260374], 
reward next is 0.7466, 
noisyNet noise sample is [array([-0.09435907], dtype=float32), -0.3591685]. 
=============================================
[2019-03-26 20:07:31,003] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:07:31,014] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6557
[2019-03-26 20:07:31,021] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.3159174402727212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 499659.2191652672, 499659.2191652672, 167001.6353500614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2930400.0000, 
sim time next is 2931000.0000, 
raw observation next is [21.0, 94.00000000000001, 1.0, 2.0, 0.3162247988953518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 500056.7546586314, 500056.754658632, 167029.6317560708], 
processed observation next is [1.0, 0.9565217391304348, 0.19431279620853087, 0.9400000000000002, 1.0, 1.0, 0.17617445650042388, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13890465407184205, 0.13890465407184222, 0.2492979578448818], 
reward next is 0.7507, 
noisyNet noise sample is [array([-0.06199252], dtype=float32), 1.7754813]. 
=============================================
[2019-03-26 20:07:31,036] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[77.46165 ]
 [77.441986]
 [77.43319 ]
 [77.394615]
 [77.370155]], R is [[77.4163208 ]
 [77.39289856]
 [77.36963654]
 [77.34660339]
 [77.32397461]].
[2019-03-26 20:07:35,229] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:07:35,236] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3640
[2019-03-26 20:07:35,240] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.00000000000001, 1.0, 2.0, 0.3201091971202503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 506196.7057556303, 506196.7057556303, 167491.6476772758], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2952600.0000, 
sim time next is 2953200.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.3103552240950783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 490769.21008797, 490769.21008797, 166340.4255789926], 
processed observation next is [1.0, 0.17391304347826086, 0.19431279620853087, 0.94, 1.0, 1.0, 0.1691026796326245, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13632478057999167, 0.13632478057999167, 0.2482692919089442], 
reward next is 0.7517, 
noisyNet noise sample is [array([-1.1103095], dtype=float32), -0.88399655]. 
=============================================
[2019-03-26 20:07:37,812] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:07:37,820] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8811
[2019-03-26 20:07:37,827] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3055869598939788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 486628.50575581, 486628.5057558094, 166099.293527577], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3018600.0000, 
sim time next is 3019200.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3050170820939111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 485721.227767029, 485721.2277670284, 166033.5916795073], 
processed observation next is [1.0, 0.9565217391304348, 0.1469194312796209, 1.0, 1.0, 1.0, 0.162671183245676, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13492256326861918, 0.13492256326861898, 0.24781133086493629], 
reward next is 0.7522, 
noisyNet noise sample is [array([-1.7277793], dtype=float32), -0.051139254]. 
=============================================
[2019-03-26 20:07:41,034] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:07:41,044] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9829
[2019-03-26 20:07:41,050] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3539231406670067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 563599.6850036548, 563599.6850036555, 172083.1644948465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3031800.0000, 
sim time next is 3032400.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3275383449927264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 521563.783305758, 521563.783305758, 168714.6045830214], 
processed observation next is [1.0, 0.08695652173913043, 0.1469194312796209, 1.0, 1.0, 1.0, 0.18980523493099563, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1448788286960439, 0.1448788286960439, 0.25181284266122594], 
reward next is 0.7482, 
noisyNet noise sample is [array([1.926786], dtype=float32), -0.6898692]. 
=============================================
[2019-03-26 20:07:43,674] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0856662e-33 1.0000000e+00 2.2942953e-29 1.0856474e-37 1.0146024e-28], sum to 1.0000
[2019-03-26 20:07:43,684] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1067
[2019-03-26 20:07:43,690] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.7874252853470698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1174616.704686965, 1174616.704686964, 250870.7695471696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3065400.0000, 
sim time next is 3066000.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.7852241844331339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1171331.216517576, 1171331.216517575, 250300.4449124924], 
processed observation next is [1.0, 0.4782608695652174, 0.28909952606635075, 0.94, 1.0, 1.0, 0.741233957148354, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.32536978236599334, 0.32536978236599307, 0.37358275360073495], 
reward next is 0.6264, 
noisyNet noise sample is [array([-2.0880587], dtype=float32), -0.95240164]. 
=============================================
[2019-03-26 20:07:43,715] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[60.93431 ]
 [61.069187]
 [61.13716 ]
 [61.93798 ]
 [62.071575]], R is [[60.88972855]
 [60.90639496]
 [60.92657471]
 [60.93266678]
 [60.97953415]].
[2019-03-26 20:07:48,990] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:07:48,999] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6243
[2019-03-26 20:07:49,003] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 82.33333333333334, 1.0, 2.0, 0.5879840693374689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 831913.991455402, 831913.991455402, 199849.2379311827], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3156000.0000, 
sim time next is 3156600.0000, 
raw observation next is [26.0, 83.16666666666666, 1.0, 2.0, 0.5879904127852683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 827587.1979108624, 827587.197910863, 199290.3774250898], 
processed observation next is [1.0, 0.5217391304347826, 0.4312796208530806, 0.8316666666666666, 1.0, 1.0, 0.5036029069702027, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22988533275301734, 0.22988533275301748, 0.2974483245150594], 
reward next is 0.7026, 
noisyNet noise sample is [array([0.18318215], dtype=float32), -0.80430764]. 
=============================================
[2019-03-26 20:07:57,625] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 20:07:57,638] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3393
[2019-03-26 20:07:57,647] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.5880381520989124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 821739.5401817085, 821739.5401817085, 198538.2724028351], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3327000.0000, 
sim time next is 3327600.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.5758696029024122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 804728.4569005421, 804728.4569005414, 196337.1040093072], 
processed observation next is [0.0, 0.5217391304347826, 0.7156398104265403, 0.67, 1.0, 1.0, 0.48899952156917126, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22353568247237282, 0.22353568247237263, 0.29304045374523463], 
reward next is 0.7070, 
noisyNet noise sample is [array([-0.73954576], dtype=float32), -0.022232767]. 
=============================================
[2019-03-26 20:08:01,133] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.6009223e-28 1.0000000e+00 2.9714183e-29 1.6656052e-31 2.8844767e-26], sum to 1.0000
[2019-03-26 20:08:01,144] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3671
[2019-03-26 20:08:01,150] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2846785.037490111 W.
[2019-03-26 20:08:01,159] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.0, 61.0, 1.0, 2.0, 1.017667541635666, 1.0, 2.0, 1.017667541635666, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2846785.037490111, 2846785.037490111, 539757.8209319953], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3422400.0000, 
sim time next is 3423000.0000, 
raw observation next is [34.0, 60.5, 1.0, 2.0, 0.7232951234917071, 1.0, 2.0, 0.6822376012601161, 1.0, 1.0, 1.03, 7.005099569026683, 6.9112, 170.5573041426782, 2862717.076860587, 2795452.995976515, 528788.1714741496], 
processed observation next is [1.0, 0.6086956521739131, 0.8104265402843602, 0.605, 1.0, 1.0, 0.6666206307129001, 1.0, 1.0, 0.6171537364579712, 1.0, 0.5, 1.0365853658536586, 0.009389956902668306, 0.0, 0.8375144448122397, 0.7951991880168298, 0.7765147211045875, 0.789236076827089], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.319468], dtype=float32), -1.4081175]. 
=============================================
[2019-03-26 20:08:01,180] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[51.473434]
 [51.19404 ]
 [52.52235 ]
 [52.46817 ]
 [53.546124]], R is [[50.70763397]
 [50.20055771]
 [49.69855118]
 [49.20156479]
 [48.70954895]].
[2019-03-26 20:08:06,444] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 8.9384715e-38 0.0000000e+00 1.9305847e-35], sum to 1.0000
[2019-03-26 20:08:06,451] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2444
[2019-03-26 20:08:06,455] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5113292983090572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 714508.5743503075, 714508.574350308, 185390.1024351827], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3451200.0000, 
sim time next is 3451800.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5110902771966108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 714174.4647164326, 714174.4647164332, 185351.8733841149], 
processed observation next is [1.0, 0.9565217391304348, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4109521412007359, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1983817957545646, 0.19838179575456477, 0.27664458714047], 
reward next is 0.7234, 
noisyNet noise sample is [array([0.28046346], dtype=float32), -0.6391102]. 
=============================================
[2019-03-26 20:08:09,513] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.9056371e-33 1.0000000e+00 1.9831662e-33 5.0669041e-38 4.7739896e-31], sum to 1.0000
[2019-03-26 20:08:09,521] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1537
[2019-03-26 20:08:09,531] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 79.0, 1.0, 2.0, 0.7631696739617206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1066595.697582479, 1066595.697582479, 235069.5729072058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3567000.0000, 
sim time next is 3567600.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.7939722997936991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1109667.527557437, 1109667.527557437, 242435.3599111704], 
processed observation next is [1.0, 0.30434782608695654, 0.5260663507109005, 0.79, 1.0, 1.0, 0.7517738551731314, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.30824097987706583, 0.30824097987706583, 0.3618438207629409], 
reward next is 0.6382, 
noisyNet noise sample is [array([0.47915384], dtype=float32), -0.318621]. 
=============================================
[2019-03-26 20:08:15,101] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.68213656e-30 1.00000000e+00 4.50933325e-30 3.56576954e-33
 1.06130966e-26], sum to 1.0000
[2019-03-26 20:08:15,109] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4459
[2019-03-26 20:08:15,113] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 72.0, 1.0, 2.0, 0.8874003259451771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1240320.195969404, 1240320.195969404, 266492.5916803419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3655800.0000, 
sim time next is 3656400.0000, 
raw observation next is [28.66666666666666, 71.33333333333333, 1.0, 2.0, 0.7719786979650235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1078913.32569186, 1078913.32569186, 237146.3100996096], 
processed observation next is [1.0, 0.30434782608695654, 0.5576619273301735, 0.7133333333333333, 1.0, 1.0, 0.7252755397168957, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.29969814602551664, 0.29969814602551664, 0.3539497165665815], 
reward next is 0.6461, 
noisyNet noise sample is [array([-1.3204961], dtype=float32), -1.1507971]. 
=============================================
[2019-03-26 20:08:18,559] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1969028e-37 1.0000000e+00 1.0072809e-32 0.0000000e+00 3.1959619e-30], sum to 1.0000
[2019-03-26 20:08:18,564] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2039
[2019-03-26 20:08:18,567] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333334, 74.83333333333334, 1.0, 2.0, 0.5250013921539649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733619.94084384, 733619.9408438393, 187605.9176718834], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3701400.0000, 
sim time next is 3702000.0000, 
raw observation next is [28.66666666666667, 75.66666666666667, 1.0, 2.0, 0.5240767536253047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 732327.4355252552, 732327.4355252557, 187454.3107003784], 
processed observation next is [1.0, 0.8695652173913043, 0.5576619273301741, 0.7566666666666667, 1.0, 1.0, 0.4265984983437406, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2034242876459042, 0.20342428764590437, 0.27978255328414686], 
reward next is 0.7202, 
noisyNet noise sample is [array([-0.91275513], dtype=float32), 0.9340139]. 
=============================================
[2019-03-26 20:08:18,580] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[67.88398]
 [68.05043]
 [68.01315]
 [68.05253]
 [68.80117]], R is [[67.67906189]
 [67.72226715]
 [67.76480103]
 [67.80571747]
 [67.84494019]].
[2019-03-26 20:08:21,015] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.3481973e-33 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 20:08:21,022] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6044
[2019-03-26 20:08:21,028] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 75.66666666666667, 1.0, 2.0, 0.4904130667426979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 685271.7453175467, 685271.7453175472, 182107.3996066342], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3712800.0000, 
sim time next is 3713400.0000, 
raw observation next is [27.5, 76.5, 1.0, 2.0, 0.4905703973505663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 685491.6599443932, 685491.6599443926, 182131.5274935262], 
processed observation next is [1.0, 1.0, 0.5023696682464456, 0.765, 1.0, 1.0, 0.3862293943982726, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19041434998455367, 0.1904143499845535, 0.27183810073660625], 
reward next is 0.7282, 
noisyNet noise sample is [array([0.36405393], dtype=float32), 0.6179369]. 
=============================================
[2019-03-26 20:08:23,034] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7538745e-25 1.0000000e+00 1.7893732e-26 1.2444317e-27 3.6658373e-23], sum to 1.0000
[2019-03-26 20:08:23,041] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6525
[2019-03-26 20:08:23,048] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1997699.901792459 W.
[2019-03-26 20:08:23,052] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 70.0, 1.0, 2.0, 0.7143895955335277, 1.0, 1.0, 0.7143895955335277, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1997699.901792459, 1997699.90179246, 380337.0579605121], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3747600.0000, 
sim time next is 3748200.0000, 
raw observation next is [29.33333333333334, 68.83333333333334, 1.0, 2.0, 0.4170002574604792, 1.0, 2.0, 0.4170002574604792, 1.0, 1.0, 0.7078813455336952, 6.9112, 6.9112, 170.5573041426782, 1748929.631093716, 1748929.631093716, 360067.1115085815], 
processed observation next is [1.0, 0.391304347826087, 0.5892575039494474, 0.6883333333333335, 1.0, 1.0, 0.29759067163913155, 1.0, 1.0, 0.29759067163913155, 1.0, 0.5, 0.6437577384557259, 0.0, 0.0, 0.8375144448122397, 0.4858137864149211, 0.4858137864149211, 0.5374135992665395], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3283672], dtype=float32), -0.11267612]. 
=============================================
[2019-03-26 20:08:25,004] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 20:08:25,006] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:08:25,006] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:08:25,006] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:08:25,007] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:08:25,008] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:08:25,008] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:08:25,010] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:08:25,007] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:08:25,011] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:08:25,013] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:08:25,027] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run22
[2019-03-26 20:08:25,028] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run22
[2019-03-26 20:08:25,029] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run22
[2019-03-26 20:08:25,047] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run22
[2019-03-26 20:08:25,086] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run22
[2019-03-26 20:08:50,946] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.36609626]
[2019-03-26 20:08:50,946] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.3, 87.5, 1.0, 2.0, 0.4773347085769531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 673279.8978287958, 673279.8978287952, 180930.5758266034]
[2019-03-26 20:08:50,947] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:08:50,950] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.1243383e-35 1.0000000e+00 1.2102296e-32 1.5645791e-37 4.7793671e-30], sampled 0.07154255617372285
[2019-03-26 20:09:01,025] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.36609626]
[2019-03-26 20:09:01,025] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.28333333333333, 84.5, 1.0, 2.0, 0.4608227608288043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 661698.0000770678, 661698.0000770672, 179961.7693505241]
[2019-03-26 20:09:01,026] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:09:01,029] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0707269e-35 1.0000000e+00 4.4875500e-33 4.9769066e-38 1.9111206e-30], sampled 0.4908752670611407
[2019-03-26 20:09:06,537] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.36609626]
[2019-03-26 20:09:06,537] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.56666666666667, 71.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.042663164313307, 6.9112, 168.9119633301264, 1547082.744248375, 1453818.799251418, 311349.9900708033]
[2019-03-26 20:09:06,539] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:09:06,545] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.1778193e-29 1.0000000e+00 8.2355569e-27 8.4828111e-31 1.1708849e-24], sampled 0.9268979138914031
[2019-03-26 20:09:17,895] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.36609626]
[2019-03-26 20:09:17,897] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.33333333333334, 62.0, 1.0, 2.0, 0.5634343299824001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 787344.787336178, 787344.787336178, 194131.3432552084]
[2019-03-26 20:09:17,899] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:09:17,901] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1008188e-37 1.0000000e+00 6.4612522e-35 0.0000000e+00 3.7991478e-32], sampled 0.08795878922476719
[2019-03-26 20:09:32,005] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.36609626]
[2019-03-26 20:09:32,006] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.0, 75.0, 1.0, 2.0, 0.925532506029299, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.000958605181095, 6.9112, 168.9123504361537, 2190775.547024564, 2127097.931737924, 441423.2919498155]
[2019-03-26 20:09:32,007] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:09:32,009] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.1838972e-26 1.0000000e+00 2.6807856e-24 6.7509825e-28 2.4544898e-22], sampled 0.41828131135318813
[2019-03-26 20:09:32,013] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2190775.547024564 W.
[2019-03-26 20:09:50,940] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.36609626]
[2019-03-26 20:09:50,942] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.85571235, 95.70338887, 1.0, 2.0, 0.6329811125382967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 884570.134554273, 884570.134554273, 207052.1934059689]
[2019-03-26 20:09:50,943] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:09:50,945] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.1359009e-36 1.0000000e+00 1.8590651e-33 1.7993147e-38 8.4661304e-31], sampled 0.990863119752848
[2019-03-26 20:10:19,482] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7879.6450 3164426017.2998 1778.0000
[2019-03-26 20:10:19,538] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7993.1316 3008143638.3828 1766.0000
[2019-03-26 20:10:19,841] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8249.2424 2927833197.1978 1338.0000
[2019-03-26 20:10:19,883] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8655.5390 2779716974.6015 933.0000
[2019-03-26 20:10:19,924] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8491.6834 2842984501.9777 1131.0000
[2019-03-26 20:10:20,938] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 525000, evaluation results [525000.0, 7879.645043455771, 3164426017.2998238, 1778.0, 8249.242360207787, 2927833197.197803, 1338.0, 8655.539002596335, 2779716974.601524, 933.0, 7993.131616413509, 3008143638.3827953, 1766.0, 8491.68339128166, 2842984501.977716, 1131.0]
[2019-03-26 20:10:28,865] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.3349845e-37 0.0000000e+00 1.6501580e-35], sum to 1.0000
[2019-03-26 20:10:28,878] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6066
[2019-03-26 20:10:28,884] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.83333333333334, 79.83333333333334, 1.0, 2.0, 0.6345517343025823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 886765.9427293071, 886765.9427293071, 207359.2051816386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3971400.0000, 
sim time next is 3972000.0000, 
raw observation next is [30.66666666666667, 80.66666666666667, 1.0, 2.0, 0.6242372947493807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 872345.9207552606, 872345.9207552613, 205348.4448074379], 
processed observation next is [0.0, 1.0, 0.6524486571879939, 0.8066666666666668, 1.0, 1.0, 0.5472738490956394, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24231831132090573, 0.24231831132090592, 0.3064902161305043], 
reward next is 0.6935, 
noisyNet noise sample is [array([-1.2259164], dtype=float32), 1.4956585]. 
=============================================
[2019-03-26 20:10:28,897] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[74.444534]
 [74.549995]
 [74.56772 ]
 [74.58438 ]
 [74.57733 ]], R is [[74.41160583]
 [74.35799408]
 [74.30873108]
 [74.26070404]
 [74.21385193]].
[2019-03-26 20:10:37,855] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.3617847e-18 1.0000000e+00 3.1544741e-17 3.6715062e-15 2.7848241e-16], sum to 1.0000
[2019-03-26 20:10:37,864] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5165
[2019-03-26 20:10:37,872] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2586181.401809486 W.
[2019-03-26 20:10:37,878] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.5, 75.0, 1.0, 2.0, 0.9246033876608276, 1.0, 2.0, 0.9246033876608276, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2586181.401809486, 2586181.401809486, 485100.8140621254], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4098600.0000, 
sim time next is 4099200.0000, 
raw observation next is [31.66666666666666, 73.66666666666666, 1.0, 2.0, 0.964535629045208, 1.0, 2.0, 0.964535629045208, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2697995.319194643, 2697995.319194642, 507930.3636028414], 
processed observation next is [1.0, 0.43478260869565216, 0.6998420221169034, 0.7366666666666666, 1.0, 1.0, 0.9572718422231421, 1.0, 1.0, 0.9572718422231421, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7494431442207341, 0.7494431442207339, 0.7581050203027483], 
reward next is 0.2419, 
noisyNet noise sample is [array([0.7569764], dtype=float32), 0.18995911]. 
=============================================
[2019-03-26 20:10:42,499] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.3237927e-37 1.0000000e+00 6.0211385e-38 5.0341234e-34 1.7667679e-32], sum to 1.0000
[2019-03-26 20:10:42,508] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6254
[2019-03-26 20:10:42,512] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.5855470420180096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 818257.0583969193, 818257.0583969193, 198083.9477058538], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4144800.0000, 
sim time next is 4145400.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.5839874637341148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 816076.8301808379, 816076.8301808379, 197800.5362762454], 
processed observation next is [1.0, 1.0, 0.5734597156398105, 0.84, 1.0, 1.0, 0.4987800767880901, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2266880083835661, 0.2266880083835661, 0.2952246810093215], 
reward next is 0.7048, 
noisyNet noise sample is [array([0.43882138], dtype=float32), -2.1216447]. 
=============================================
[2019-03-26 20:10:44,048] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.10236694e-32 1.00000000e+00 1.14029076e-29 2.09392843e-27
 4.27953102e-20], sum to 1.0000
[2019-03-26 20:10:44,054] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2045
[2019-03-26 20:10:44,059] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 84.0, 1.0, 2.0, 0.8569236478978629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1197698.891135359, 1197698.891135359, 258369.2484678563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4172400.0000, 
sim time next is 4173000.0000, 
raw observation next is [30.33333333333333, 83.16666666666667, 1.0, 2.0, 0.957621953381459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1338530.896345231, 1338530.896345231, 286286.2908198257], 
processed observation next is [1.0, 0.30434782608695654, 0.6366508688783569, 0.8316666666666667, 1.0, 1.0, 0.9489421125077818, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3718141378736753, 0.3718141378736753, 0.4272929713728742], 
reward next is 0.5727, 
noisyNet noise sample is [array([-0.7803873], dtype=float32), -1.5124351]. 
=============================================
[2019-03-26 20:10:44,079] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[54.592552]
 [54.236984]
 [54.1552  ]
 [54.03357 ]
 [54.02234 ]], R is [[54.23883438]
 [54.31082153]
 [54.38599014]
 [54.47044754]
 [54.56448364]].
[2019-03-26 20:10:45,465] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.1724668e-23 1.0000000e+00 1.1508961e-23 2.6483060e-20 9.0283558e-16], sum to 1.0000
[2019-03-26 20:10:45,473] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8308
[2019-03-26 20:10:45,478] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 75.66666666666666, 1.0, 2.0, 0.5685495654897653, 0.0, 1.0, 0.0, 1.0, 2.0, 0.98706902836242, 6.911200000000001, 6.9112, 168.9129565104293, 1589585.732118708, 1589585.732118707, 347770.8981698806], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4243800.0000, 
sim time next is 4244400.0000, 
raw observation next is [30.0, 75.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.440011452030399, 6.9112, 168.9099495112963, 1829162.24713929, 1454011.8813528, 311352.6768955276], 
processed observation next is [1.0, 0.13043478260869565, 0.6208530805687204, 0.75, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0528811452030399, 0.0, 0.8294251794099412, 0.5081006242053583, 0.40389218926466663, 0.46470548790377253], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19410983], dtype=float32), -0.11126491]. 
=============================================
[2019-03-26 20:10:50,445] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.9666236e-13 1.0000000e+00 1.4290713e-12 2.3361221e-10 4.0469508e-09], sum to 1.0000
[2019-03-26 20:10:50,457] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6182
[2019-03-26 20:10:50,465] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2894563.976575692 W.
[2019-03-26 20:10:50,470] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.83333333333334, 57.5, 1.0, 2.0, 0.7384569487076226, 1.0, 2.0, 0.6898185138680738, 1.0, 2.0, 1.03, 7.005100764646556, 6.9112, 170.5573041426782, 2894563.976575692, 2827299.039220471, 533753.1604784], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4276200.0000, 
sim time next is 4276800.0000, 
raw observation next is [37.0, 57.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.247884763812026, 6.9112, 170.5573041426782, 3150791.659889818, 2909610.668110705, 551882.7092115207], 
processed observation next is [1.0, 0.5217391304347826, 0.95260663507109, 0.57, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.03366847638120261, 0.0, 0.8375144448122397, 0.8752199055249494, 0.808225185586307, 0.8237055361365981], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5845622], dtype=float32), -1.1659943]. 
=============================================
[2019-03-26 20:10:51,247] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1241136e-11 9.9999940e-01 3.3047321e-12 4.3633078e-10 5.5393201e-07], sum to 1.0000
[2019-03-26 20:10:51,254] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3326
[2019-03-26 20:10:51,260] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2734952.709483574 W.
[2019-03-26 20:10:51,273] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [37.5, 55.5, 1.0, 2.0, 0.6624645627300093, 1.0, 2.0, 0.6518223208792673, 1.0, 2.0, 1.03, 7.005094772708351, 6.9112, 170.5573041426782, 2734952.709483574, 2667692.064397425, 509737.6381493793], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4278600.0000, 
sim time next is 4279200.0000, 
raw observation next is [37.66666666666666, 55.0, 1.0, 2.0, 0.7548039072733624, 1.0, 2.0, 0.6979919931509437, 1.0, 2.0, 1.03, 7.005102053791051, 6.9112, 170.5573041426782, 2928901.118359112, 2861635.257537249, 539199.9964760432], 
processed observation next is [1.0, 0.5217391304347826, 0.9842022116903629, 0.55, 1.0, 1.0, 0.70458302081128, 1.0, 1.0, 0.6361349315071612, 1.0, 1.0, 1.0365853658536586, 0.009390205379105065, 0.0, 0.8375144448122397, 0.8135836439886422, 0.7948986826492358, 0.8047761141433482], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.03787515], dtype=float32), -1.2566175]. 
=============================================
[2019-03-26 20:10:53,587] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3237834e-15 9.9999976e-01 3.8569480e-15 4.6266867e-15 2.5596046e-07], sum to 1.0000
[2019-03-26 20:10:53,596] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2612
[2019-03-26 20:10:53,603] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3606631.571067888 W.
[2019-03-26 20:10:53,608] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.66666666666666, 68.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.8834894268214, 6.9112, 170.5573041426782, 3606631.571067888, 2910141.104430519, 548067.756321329], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4369200.0000, 
sim time next is 4369800.0000, 
raw observation next is [32.83333333333334, 71.5, 1.0, 2.0, 0.888556849194499, 1.0, 2.0, 0.764868464111512, 1.0, 1.0, 1.03, 7.005112604400705, 6.9112, 170.5573041426782, 3209887.546172363, 3142614.127519635, 587503.4509262341], 
processed observation next is [1.0, 0.5652173913043478, 0.7551342812006324, 0.715, 1.0, 1.0, 0.8657311436078301, 1.0, 1.0, 0.7167089929054361, 1.0, 0.5, 1.0365853658536586, 0.009391260440070503, 0.0, 0.8375144448122397, 0.8916354294923231, 0.8729483687554541, 0.8768708222779614], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4532057], dtype=float32), 0.09206383]. 
=============================================
[2019-03-26 20:11:03,864] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2877088e-34 1.0000000e+00 7.8099477e-35 4.7756649e-31 2.5901982e-19], sum to 1.0000
[2019-03-26 20:11:03,870] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4203
[2019-03-26 20:11:03,876] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.507745637686434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709499.2557531429, 709499.2557531429, 184818.0670325271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4500600.0000, 
sim time next is 4501200.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5079039030453599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 709720.4820082138, 709720.4820082145, 184843.2213397491], 
processed observation next is [0.0, 0.08695652173913043, 0.4312796208530806, 0.89, 1.0, 1.0, 0.4071131361992288, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19714457833561494, 0.19714457833561513, 0.27588540498470016], 
reward next is 0.7241, 
noisyNet noise sample is [array([-0.0874024], dtype=float32), -2.1496625]. 
=============================================
[2019-03-26 20:11:05,642] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.7639675e-36 1.0000000e+00 1.8776202e-37 8.6666809e-28 3.3648195e-24], sum to 1.0000
[2019-03-26 20:11:05,653] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0956
[2019-03-26 20:11:05,659] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 86.5, 1.0, 2.0, 0.5085835229625861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 710670.4678615045, 710670.4678615045, 184951.6564859185], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4516200.0000, 
sim time next is 4516800.0000, 
raw observation next is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.5096431343431829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712151.6148201709, 712151.6148201709, 185120.5779413317], 
processed observation next is [0.0, 0.2608695652173913, 0.4628751974723541, 0.8566666666666667, 1.0, 1.0, 0.4092085955941962, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19781989300560304, 0.19781989300560304, 0.2762993700616891], 
reward next is 0.7237, 
noisyNet noise sample is [array([-0.21725522], dtype=float32), -1.3373567]. 
=============================================
[2019-03-26 20:11:16,742] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 20:11:16,745] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:11:16,745] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:11:16,746] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:11:16,746] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:11:16,747] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:11:16,748] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:11:16,750] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:11:16,747] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:11:16,752] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:11:16,754] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:11:16,772] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run23
[2019-03-26 20:11:16,794] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run23
[2019-03-26 20:11:16,795] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run23
[2019-03-26 20:11:16,842] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run23
[2019-03-26 20:11:16,859] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run23
[2019-03-26 20:11:27,866] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.45226803]
[2019-03-26 20:11:27,867] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [15.8396115, 93.28156783, 1.0, 2.0, 0.1985846862061041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 332178.9508946795, 332178.9508946795, 133830.1076957567]
[2019-03-26 20:11:27,868] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:11:27,871] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.3544501e-27 1.0000000e+00 1.2929879e-27 2.0728169e-15 4.8058193e-16], sampled 0.36926870018467395
[2019-03-26 20:11:52,013] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.45226803]
[2019-03-26 20:11:52,014] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.35, 86.0, 1.0, 2.0, 0.4027804142624438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 594767.5411885501, 594767.5411885501, 173869.3017970506]
[2019-03-26 20:11:52,016] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:11:52,018] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.5356318e-26 1.0000000e+00 2.7670502e-27 3.1855672e-15 7.5682907e-16], sampled 0.6220178106007449
[2019-03-26 20:12:22,551] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.45226803]
[2019-03-26 20:12:22,555] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.35, 65.16666666666666, 1.0, 2.0, 0.5156419716330037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 720536.9540435895, 720536.9540435902, 186083.1725914174]
[2019-03-26 20:12:22,557] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:12:22,562] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.2967855e-28 1.0000000e+00 1.5253081e-28 6.1984209e-16 1.3418225e-16], sampled 0.1335039435363482
[2019-03-26 20:12:28,323] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.45226803]
[2019-03-26 20:12:28,323] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.50638669333333, 65.70352964666667, 1.0, 2.0, 0.536900336605653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 750253.0123421231, 750253.0123421238, 189581.1659595895]
[2019-03-26 20:12:28,324] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:12:28,328] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.1374137e-25 1.0000000e+00 4.2056874e-26 1.4814723e-14 3.8409010e-15], sampled 0.7753805861208939
[2019-03-26 20:12:28,582] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.45226803]
[2019-03-26 20:12:28,583] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.74738024333333, 66.46928465, 1.0, 2.0, 0.6094804160161824, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.942752479903065, 6.9112, 168.9126534573414, 1704114.589075477, 1681730.214040415, 366355.9074954162]
[2019-03-26 20:12:28,584] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:12:28,587] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.7559254e-20 1.0000000e+00 8.0354199e-21 1.4241659e-11 5.4550427e-12], sampled 0.6647919224120126
[2019-03-26 20:12:28,587] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1704114.589075477 W.
[2019-03-26 20:12:42,827] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.45226803]
[2019-03-26 20:12:42,829] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.24761802333333, 82.77409081, 1.0, 2.0, 0.5600577080434939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 782624.5476071058, 782624.5476071051, 193539.7813292411]
[2019-03-26 20:12:42,829] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:12:42,832] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.3569716e-27 1.0000000e+00 3.9891582e-28 1.0668564e-15 2.3818770e-16], sampled 0.14948227430548466
[2019-03-26 20:13:10,699] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7876.6154 3164650260.9350 1778.0000
[2019-03-26 20:13:10,976] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7990.1625 3008417738.7924 1766.0000
[2019-03-26 20:13:11,198] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8653.2987 2779927580.8313 933.0000
[2019-03-26 20:13:11,338] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8488.6935 2843245586.4942 1131.0000
[2019-03-26 20:13:11,376] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8246.2734 2928117667.3375 1338.0000
[2019-03-26 20:13:12,393] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 550000, evaluation results [550000.0, 7876.615395271476, 3164650260.93499, 1778.0, 8246.273358047021, 2928117667.3375263, 1338.0, 8653.298705978405, 2779927580.8313117, 933.0, 7990.162463052581, 3008417738.7924104, 1766.0, 8488.693495291653, 2843245586.494196, 1131.0]
[2019-03-26 20:13:13,465] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.1651096e-15 1.0000000e+00 2.1265275e-14 8.4042826e-09 7.4135857e-09], sum to 1.0000
[2019-03-26 20:13:13,473] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8714
[2019-03-26 20:13:13,481] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2045547.028491113 W.
[2019-03-26 20:13:13,485] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.7314836982065661, 1.0, 2.0, 0.7314836982065661, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2045547.028491113, 2045547.028491113, 387892.9526034787], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4792200.0000, 
sim time next is 4792800.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 1.00881517549566, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.991797532671896, 6.9112, 168.9124775410152, 2307340.530649931, 2250162.029155259, 466561.9904245081], 
processed observation next is [1.0, 0.4782608695652174, 0.6682464454976303, 0.66, 1.0, 1.0, 1.010620693368265, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.008059753267189596, 0.0, 0.8294375931931979, 0.6409279251805364, 0.625045008098683, 0.6963611797380718], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.34296978], dtype=float32), 0.41203356]. 
=============================================
[2019-03-26 20:13:17,031] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.8079694e-16 1.0000000e+00 2.6484023e-16 4.7960746e-09 8.9504599e-09], sum to 1.0000
[2019-03-26 20:13:17,040] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8053
[2019-03-26 20:13:17,052] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1928059.136616374 W.
[2019-03-26 20:13:17,057] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.66666666666666, 64.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.579323724291761, 6.9112, 168.9092440956237, 1928059.136616374, 1454079.589039982, 311351.7861432175], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4797600.0000, 
sim time next is 4798200.0000, 
raw observation next is [31.83333333333333, 63.5, 1.0, 2.0, 0.4055320973657978, 1.0, 1.0, 0.4055320973657978, 1.0, 1.0, 0.7034512184697054, 6.9112, 6.9112, 170.5573041426782, 1700793.157406323, 1700793.157406323, 355855.4515686854], 
processed observation next is [1.0, 0.5217391304347826, 0.7077409162717218, 0.635, 1.0, 1.0, 0.28377361128409373, 1.0, 0.5, 0.28377361128409373, 1.0, 0.5, 0.6383551444752503, 0.0, 0.0, 0.8375144448122397, 0.4724425437239786, 0.4724425437239786, 0.5311275396547543], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.1344526], dtype=float32), -0.7815623]. 
=============================================
[2019-03-26 20:13:26,029] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.2202670e-16 9.9999952e-01 2.2574067e-14 4.6342780e-07 2.2054548e-10], sum to 1.0000
[2019-03-26 20:13:26,036] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6208
[2019-03-26 20:13:26,043] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2034200.159170058 W.
[2019-03-26 20:13:26,052] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 68.66666666666667, 1.0, 2.0, 0.8136663400486942, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.98410579061679, 6.9112, 168.9125229509847, 2034200.159170058, 1982478.414840621, 412035.1050560275], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4959600.0000, 
sim time next is 4960200.0000, 
raw observation next is [30.0, 69.33333333333333, 1.0, 2.0, 0.4924774870750362, 1.0, 1.0, 0.4924774870750362, 1.0, 2.0, 0.8470362740616076, 6.911199999999999, 6.9112, 170.5573041426782, 2065791.840347832, 2065791.840347832, 408516.23562079], 
processed observation next is [1.0, 0.391304347826087, 0.6208530805687204, 0.6933333333333332, 1.0, 1.0, 0.3885270928614894, 1.0, 0.5, 0.3885270928614894, 1.0, 1.0, 0.8134588708068384, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5738310667632867, 0.5738310667632867, 0.6097257248071493], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.1999357], dtype=float32), -1.7314236]. 
=============================================
[2019-03-26 20:13:37,523] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4026840e-28 1.0000000e+00 5.7635397e-24 1.1329616e-13 1.4603173e-09], sum to 1.0000
[2019-03-26 20:13:37,536] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1870
[2019-03-26 20:13:37,542] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 84.0, 1.0, 2.0, 0.4923487007868947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 687977.3519527548, 687977.3519527555, 182405.8863755389], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5121000.0000, 
sim time next is 5121600.0000, 
raw observation next is [26.66666666666667, 84.0, 1.0, 2.0, 0.4974532312340174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 695112.4379774907, 695112.4379774913, 183198.0284346595], 
processed observation next is [0.0, 0.2608695652173913, 0.4628751974723541, 0.84, 1.0, 1.0, 0.39452196534218964, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19308678832708076, 0.19308678832708093, 0.273429893186059], 
reward next is 0.7266, 
noisyNet noise sample is [array([-0.39256835], dtype=float32), 0.04356929]. 
=============================================
[2019-03-26 20:13:39,035] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1933496e-27 1.0000000e+00 6.8123112e-23 6.4354498e-12 1.2246848e-13], sum to 1.0000
[2019-03-26 20:13:39,043] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0751
[2019-03-26 20:13:39,052] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 63.0, 1.0, 2.0, 0.5516185973084917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 770827.45667694, 770827.4566769394, 192079.1430813605], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5155200.0000, 
sim time next is 5155800.0000, 
raw observation next is [31.83333333333334, 63.5, 1.0, 2.0, 0.5556764701865975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 776499.9687244205, 776499.9687244212, 192778.9960582308], 
processed observation next is [0.0, 0.6956521739130435, 0.7077409162717223, 0.635, 1.0, 1.0, 0.46467044600794877, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2156944357567835, 0.21569443575678368, 0.28772984486303105], 
reward next is 0.7123, 
noisyNet noise sample is [array([-0.71796024], dtype=float32), -0.41464224]. 
=============================================
[2019-03-26 20:13:39,796] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.8339859e-28 1.0000000e+00 4.6356664e-21 6.2661417e-12 1.5697827e-19], sum to 1.0000
[2019-03-26 20:13:39,806] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7279
[2019-03-26 20:13:39,813] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 79.0, 1.0, 2.0, 0.5152970779166053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 720054.8503580085, 720054.8503580092, 186026.9613251802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5178000.0000, 
sim time next is 5178600.0000, 
raw observation next is [27.5, 79.0, 1.0, 2.0, 0.5110061883386375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 714056.9232520408, 714056.9232520408, 185337.8384153096], 
processed observation next is [0.0, 0.9565217391304348, 0.5023696682464456, 0.79, 1.0, 1.0, 0.4108508293236596, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1983491453477891, 0.1983491453477891, 0.27662363942583523], 
reward next is 0.7234, 
noisyNet noise sample is [array([1.627588], dtype=float32), 0.7909084]. 
=============================================
[2019-03-26 20:13:39,911] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.3619604e-21 1.0000000e+00 2.5404991e-17 2.1230757e-13 8.9862985e-16], sum to 1.0000
[2019-03-26 20:13:39,920] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6282
[2019-03-26 20:13:39,927] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5161590341472515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 721259.7213000394, 721259.7213000394, 186166.1952553471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5190600.0000, 
sim time next is 5191200.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.51552657840625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 720375.6536032964, 720375.6536032964, 186064.1725502636], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.84, 1.0, 1.0, 0.41629708241716873, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20010434822313788, 0.20010434822313788, 0.27770772022427404], 
reward next is 0.7223, 
noisyNet noise sample is [array([0.63206136], dtype=float32), -0.09146166]. 
=============================================
[2019-03-26 20:13:43,453] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8430885e-13 1.0000000e+00 5.8222563e-12 1.3965982e-08 2.0168662e-09], sum to 1.0000
[2019-03-26 20:13:43,460] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3774
[2019-03-26 20:13:43,470] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2516034.334230164 W.
[2019-03-26 20:13:43,473] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.16666666666667, 69.5, 1.0, 2.0, 0.8995498551386762, 1.0, 2.0, 0.8995498551386762, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2516034.334230164, 2516034.334230165, 471246.5991164661], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5224200.0000, 
sim time next is 5224800.0000, 
raw observation next is [31.33333333333334, 69.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 8.30672964004614, 6.9112, 168.9050813118145, 3274582.025682795, 2284591.426917626, 472653.932174427], 
processed observation next is [1.0, 0.4782608695652174, 0.6840442338072673, 0.69, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.13955296400461395, 0.0, 0.8294012743218142, 0.9096061182452208, 0.6346087296993406, 0.7054536301110851], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41006145], dtype=float32), -1.5050817]. 
=============================================
[2019-03-26 20:13:48,967] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4388752e-13 9.9998629e-01 3.4106915e-11 1.3685701e-05 6.2500827e-09], sum to 1.0000
[2019-03-26 20:13:48,976] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8013
[2019-03-26 20:13:48,986] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2276038.160631194 W.
[2019-03-26 20:13:48,990] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.2, 52.0, 1.0, 2.0, 0.9864511959997594, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.00599259176818, 6.9112, 168.9123930989401, 2276038.160631194, 2208789.257832014, 459168.7210722269], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5317200.0000, 
sim time next is 5317800.0000, 
raw observation next is [36.18333333333334, 52.16666666666667, 1.0, 2.0, 1.04, 1.0, 1.0, 1.04, 0.0, 1.0, 0.0, 7.004483001901961, 6.9112, 170.5573041426782, 2976230.000093373, 2909407.591321087, 553161.5974764419], 
processed observation next is [1.0, 0.5652173913043478, 0.9139020537124805, 0.5216666666666667, 1.0, 1.0, 1.0481927710843375, 1.0, 0.5, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.009328300190196082, 0.0, 0.8375144448122397, 0.8267305555814926, 0.8081687753669686, 0.8256143245917043], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.16934381], dtype=float32), -0.57269955]. 
=============================================
[2019-03-26 20:13:53,674] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.9620017e-04 8.4260088e-01 9.3578297e-04 1.3121432e-01 2.4652813e-02], sum to 1.0000
[2019-03-26 20:13:53,684] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6867
[2019-03-26 20:13:53,691] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3375370.704687957 W.
[2019-03-26 20:13:53,695] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [38.0, 54.0, 1.0, 2.0, 0.967314756794768, 1.0, 2.0, 0.8042474179116464, 1.0, 1.0, 1.03, 7.005118819149033, 6.9112, 170.5573041426782, 3375370.704687957, 3308092.8341582, 619071.9944963923], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5410800.0000, 
sim time next is 5411400.0000, 
raw observation next is [37.5, 53.83333333333333, 1.0, 2.0, 0.8576740629912881, 1.0, 2.0, 0.7494270710099066, 1.0, 2.0, 1.03, 7.005110167904228, 6.9112, 170.5573041426782, 3145003.780224822, 3077732.10693363, 575758.5735702727], 
processed observation next is [1.0, 0.6521739130434783, 0.976303317535545, 0.5383333333333333, 1.0, 1.0, 0.8285229674593833, 1.0, 1.0, 0.6981049048312127, 1.0, 1.0, 1.0365853658536586, 0.009391016790422757, 0.0, 0.8375144448122397, 0.8736121611735617, 0.8549255852593417, 0.8593411545824965], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1834805], dtype=float32), -0.33451942]. 
=============================================
[2019-03-26 20:14:02,030] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.6012304e-17 9.9999952e-01 5.7365620e-15 4.3385805e-07 1.6068178e-12], sum to 1.0000
[2019-03-26 20:14:02,037] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8823
[2019-03-26 20:14:02,043] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.86666666666667, 89.33333333333333, 1.0, 2.0, 0.8164064319881933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1141038.651709217, 1141038.651709217, 247977.6576206631], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5551800.0000, 
sim time next is 5552400.0000, 
raw observation next is [27.03333333333333, 88.66666666666667, 1.0, 2.0, 0.7850647749198626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1097211.806089695, 1097211.806089695, 240277.8492756816], 
processed observation next is [1.0, 0.2608695652173913, 0.48025276461295413, 0.8866666666666667, 1.0, 1.0, 0.7410418974938103, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3047810572471375, 0.3047810572471375, 0.35862365563534565], 
reward next is 0.6414, 
noisyNet noise sample is [array([-0.30637726], dtype=float32), -0.5481684]. 
=============================================
[2019-03-26 20:14:08,256] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 20:14:08,259] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:14:08,260] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:14:08,260] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:14:08,261] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:14:08,261] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:14:08,263] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:14:08,263] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:14:08,266] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:14:08,267] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:14:08,268] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:14:08,290] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run24
[2019-03-26 20:14:08,310] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run24
[2019-03-26 20:14:08,312] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run24
[2019-03-26 20:14:08,352] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run24
[2019-03-26 20:14:08,369] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run24
[2019-03-26 20:14:12,657] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.33207914]
[2019-03-26 20:14:12,659] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.607778755, 84.10258349, 1.0, 2.0, 0.3102917887195782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 496290.4715574562, 496290.4715574569, 166826.7453203378]
[2019-03-26 20:14:12,659] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:14:12,662] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.8923983e-19 1.8574772e-33], sampled 0.833853913469066
[2019-03-26 20:14:21,982] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.33207914]
[2019-03-26 20:14:21,983] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.05065218, 70.69023478, 1.0, 2.0, 0.3151210187466064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 499016.502123319, 499016.5021233196, 166965.1375124937]
[2019-03-26 20:14:21,985] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:14:21,988] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0959810e-19 3.3989116e-34], sampled 0.20995492167791885
[2019-03-26 20:14:25,402] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.33207914]
[2019-03-26 20:14:25,403] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.22740802, 60.92323455, 1.0, 2.0, 0.5601388520756075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 853938.5264638053, 853938.5264638053, 202222.2129482466]
[2019-03-26 20:14:25,405] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:14:25,406] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 2.5074492e-37 7.2962531e-17 2.9675442e-29], sampled 0.4310702893460727
[2019-03-26 20:14:33,696] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.33207914]
[2019-03-26 20:14:33,697] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.26666666666667, 82.83333333333334, 1.0, 2.0, 0.4450397809819127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 644504.3094031591, 644504.3094031591, 178329.0756518003]
[2019-03-26 20:14:33,698] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:14:33,700] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.8919713e-37 6.4245676e-17 2.3751743e-29], sampled 0.26482318816723704
[2019-03-26 20:15:11,829] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.33207914]
[2019-03-26 20:15:11,830] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.00251740833333, 84.7064955, 1.0, 2.0, 0.630036058174074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 880452.8127544809, 880452.8127544809, 206474.9348511965]
[2019-03-26 20:15:11,832] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:15:11,835] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5965245e-18 3.6928387e-32], sampled 0.21147038251257022
[2019-03-26 20:15:22,031] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.33207914]
[2019-03-26 20:15:22,034] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.57155237, 81.96318642333333, 1.0, 2.0, 0.4436480460355017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 643079.1545725921, 643079.1545725928, 178200.4607981545]
[2019-03-26 20:15:22,036] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:15:22,038] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.2229989e-18 6.5911373e-32], sampled 0.8992591693914794
[2019-03-26 20:15:38,420] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.33207914]
[2019-03-26 20:15:38,421] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.7, 83.5, 1.0, 2.0, 0.5766090974436819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 805762.2291614377, 805762.2291614383, 196468.4865428588]
[2019-03-26 20:15:38,422] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:15:38,425] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5959408e-17 2.0757842e-30], sampled 0.9420377548557203
[2019-03-26 20:15:43,471] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.33207914]
[2019-03-26 20:15:43,473] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.94501338166667, 91.06093814166667, 1.0, 2.0, 0.5262968708140424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 735430.8274252691, 735430.8274252691, 187817.6051763331]
[2019-03-26 20:15:43,474] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:15:43,478] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 6.2803215e-38 3.9038683e-17 9.9325225e-30], sampled 0.6650542195235141
[2019-03-26 20:16:02,116] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8487.8419 2843388159.1415 1131.0000
[2019-03-26 20:16:02,814] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8650.9417 2780192181.4574 933.0000
[2019-03-26 20:16:03,060] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7991.1793 3008594365.1484 1766.0000
[2019-03-26 20:16:03,125] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8247.2838 2928293311.1787 1338.0000
[2019-03-26 20:16:03,141] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7874.2549 3164907195.1427 1778.0000
[2019-03-26 20:16:04,160] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 575000, evaluation results [575000.0, 7874.25493406606, 3164907195.142727, 1778.0, 8247.283841780014, 2928293311.178663, 1338.0, 8650.941674342437, 2780192181.4574094, 933.0, 7991.179294820579, 3008594365.1484313, 1766.0, 8487.8418525275, 2843388159.141459, 1131.0]
[2019-03-26 20:16:21,563] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.7819595e-27 9.9980110e-01 3.0810603e-23 1.9886451e-04 6.2462629e-18], sum to 1.0000
[2019-03-26 20:16:21,574] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4224
[2019-03-26 20:16:21,579] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.93333333333333, 93.83333333333334, 1.0, 2.0, 0.6643650645838307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 928447.3380341934, 928447.3380341934, 213340.6206680305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5979000.0000, 
sim time next is 5979600.0000, 
raw observation next is [25.9, 94.0, 1.0, 2.0, 0.6603204725723009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 922792.5823845468, 922792.5823845468, 212512.677932431], 
processed observation next is [1.0, 0.21739130434782608, 0.42654028436018954, 0.94, 1.0, 1.0, 0.5907475573160251, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.25633127288459634, 0.25633127288459634, 0.31718310139168804], 
reward next is 0.6828, 
noisyNet noise sample is [array([0.08209663], dtype=float32), -0.34646007]. 
=============================================
[2019-03-26 20:16:22,076] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2675013e-38 9.9993408e-01 2.3043137e-33 6.5918495e-05 2.8819643e-27], sum to 1.0000
[2019-03-26 20:16:22,091] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3308
[2019-03-26 20:16:22,097] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.68333333333334, 80.33333333333334, 1.0, 2.0, 0.5710748388473635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 798025.667698816, 798025.667698816, 195481.9636586174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5940600.0000, 
sim time next is 5941200.0000, 
raw observation next is [29.56666666666667, 80.66666666666667, 1.0, 2.0, 0.5706608332825299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 797446.9150249014, 797446.9150249014, 195408.2689506001], 
processed observation next is [1.0, 0.782608695652174, 0.6003159557661929, 0.8066666666666668, 1.0, 1.0, 0.4827238955211204, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2215130319513615, 0.2215130319513615, 0.2916541327620897], 
reward next is 0.7083, 
noisyNet noise sample is [array([-0.9000964], dtype=float32), -1.972229]. 
=============================================
[2019-03-26 20:16:33,822] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.0631206e-26 9.9990392e-01 7.3384747e-26 9.6038741e-05 2.9184923e-15], sum to 1.0000
[2019-03-26 20:16:33,836] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1098
[2019-03-26 20:16:33,840] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 90.66666666666667, 1.0, 2.0, 0.5369747140129834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 750356.9824451448, 750356.9824451454, 189592.1813109072], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6139200.0000, 
sim time next is 6139800.0000, 
raw observation next is [26.8, 91.0, 1.0, 2.0, 0.538071823698464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 751890.6026538422, 751890.6026538422, 189776.2377056621], 
processed observation next is [1.0, 0.043478260869565216, 0.4691943127962086, 0.91, 1.0, 1.0, 0.4434600285523662, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20885850073717838, 0.20885850073717838, 0.2832481159786001], 
reward next is 0.7168, 
noisyNet noise sample is [array([-0.8212292], dtype=float32), 0.9915486]. 
=============================================
[2019-03-26 20:16:33,909] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0127690e-21 2.7033007e-01 3.8554409e-18 7.2966993e-01 4.3028901e-12], sum to 1.0000
[2019-03-26 20:16:33,919] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5225
[2019-03-26 20:16:33,923] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.66666666666667, 92.0, 1.0, 2.0, 0.4292659083253552, 1.0, 1.0, 0.4292659083253552, 1.0, 1.0, 0.7405334519567189, 6.9112, 6.9112, 170.5573041426782, 1800415.887093655, 1800415.887093655, 368927.6024771989], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6142800.0000, 
sim time next is 6143400.0000, 
raw observation next is [26.65, 92.0, 1.0, 2.0, 0.5018834552426503, 1.0, 2.0, 0.5018834552426503, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1403064.408106404, 1403064.408106404, 300839.4337263106], 
processed observation next is [1.0, 0.08695652173913043, 0.462085308056872, 0.92, 1.0, 1.0, 0.39985958462969917, 1.0, 1.0, 0.39985958462969917, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.38974011336289, 0.38974011336289, 0.4490140801885233], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7069963], dtype=float32), -0.010567255]. 
=============================================
[2019-03-26 20:16:44,160] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.9792841e-38 1.0000000e+00 5.2694808e-34 1.5952291e-09 1.0390866e-29], sum to 1.0000
[2019-03-26 20:16:44,167] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2448
[2019-03-26 20:16:44,172] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666667, 86.66666666666667, 1.0, 2.0, 0.531298477050887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742422.358375934, 742422.3583759333, 188645.1469677149], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6316800.0000, 
sim time next is 6317400.0000, 
raw observation next is [27.13333333333333, 86.83333333333333, 1.0, 2.0, 0.5313407538515516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742481.4554994003, 742481.4554994003, 188652.1362509135], 
processed observation next is [0.0, 0.08695652173913043, 0.484992101105845, 0.8683333333333333, 1.0, 1.0, 0.4353503058452428, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2062448487498334, 0.2062448487498334, 0.2815703526133037], 
reward next is 0.7184, 
noisyNet noise sample is [array([0.76756555], dtype=float32), 0.008142761]. 
=============================================
[2019-03-26 20:16:53,223] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5256348e-30 9.9970406e-01 5.3032915e-25 2.9590999e-04 1.0543668e-18], sum to 1.0000
[2019-03-26 20:16:53,224] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3819
[2019-03-26 20:16:53,234] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.95, 76.66666666666667, 1.0, 2.0, 0.5053332822338025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 706127.2262472076, 706127.2262472083, 184435.7964293429], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6466200.0000, 
sim time next is 6466800.0000, 
raw observation next is [27.9, 77.33333333333334, 1.0, 2.0, 0.5068638940061424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 708266.7389208385, 708266.7389208392, 184678.4127319815], 
processed observation next is [1.0, 0.8695652173913043, 0.5213270142180094, 0.7733333333333334, 1.0, 1.0, 0.4058601132604125, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.196740760811344, 0.1967407608113442, 0.2756394219880321], 
reward next is 0.7244, 
noisyNet noise sample is [array([-0.3880978], dtype=float32), -1.295816]. 
=============================================
[2019-03-26 20:16:56,873] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.39852040e-32 9.99897957e-01 6.66044322e-26 1.02070575e-04
 2.65165460e-20], sum to 1.0000
[2019-03-26 20:16:56,882] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8721
[2019-03-26 20:16:56,889] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.05, 86.0, 1.0, 2.0, 0.5197586279417052, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726291.3673899743, 726291.3673899743, 186749.9526150364], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6564600.0000, 
sim time next is 6565200.0000, 
raw observation next is [27.0, 86.33333333333334, 1.0, 2.0, 0.520269961060075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 727006.1297747858, 727006.1297747851, 186833.0678158203], 
processed observation next is [1.0, 1.0, 0.4786729857819906, 0.8633333333333334, 1.0, 1.0, 0.4220120012771987, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20194614715966272, 0.20194614715966253, 0.2788553250982393], 
reward next is 0.7211, 
noisyNet noise sample is [array([-0.22260253], dtype=float32), 0.7363667]. 
=============================================
[2019-03-26 20:16:57,248] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3608288e-28 8.7757474e-01 2.9254771e-25 1.2242523e-01 2.6760216e-17], sum to 1.0000
[2019-03-26 20:16:57,254] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7767
[2019-03-26 20:16:57,258] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.7, 65.66666666666667, 1.0, 2.0, 0.2314586418802454, 1.0, 2.0, 0.2314586418802454, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 646837.3069485797, 646837.3069485797, 238007.8546430743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6542400.0000, 
sim time next is 6543000.0000, 
raw observation next is [29.6, 66.0, 1.0, 2.0, 0.4578194734837097, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 639713.8366863262, 639713.8366863262, 177252.9447489907], 
processed observation next is [1.0, 0.7391304347826086, 0.6018957345971565, 0.66, 1.0, 1.0, 0.3467704499803732, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17769828796842393, 0.17769828796842393, 0.2645566339537175], 
reward next is 0.7354, 
noisyNet noise sample is [array([0.1329033], dtype=float32), -1.0703454]. 
=============================================
[2019-03-26 20:16:57,270] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[59.77214 ]
 [56.14505 ]
 [49.442715]
 [48.732544]
 [49.307434]], R is [[63.09022522]
 [63.10408783]
 [63.09414673]
 [62.46320724]
 [61.954216  ]].
[2019-03-26 20:17:00,007] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 20:17:00,009] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:17:00,010] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:17:00,011] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:00,012] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:17:00,013] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:17:00,012] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:00,014] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:17:00,017] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:00,021] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:00,018] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:00,037] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run25
[2019-03-26 20:17:00,038] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run25
[2019-03-26 20:17:00,057] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run25
[2019-03-26 20:17:00,098] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run25
[2019-03-26 20:17:00,099] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run25
[2019-03-26 20:17:20,760] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.32427415]
[2019-03-26 20:17:20,760] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.4, 82.0, 1.0, 2.0, 0.2849641668154601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 460932.100251351, 460932.1002513504, 164328.9578880786]
[2019-03-26 20:17:20,760] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:17:20,762] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 9.9999082e-01 1.9414019e-34 9.2046657e-06 5.3021448e-24], sampled 0.39107852326206616
[2019-03-26 20:17:22,963] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.32427415]
[2019-03-26 20:17:22,964] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.08333333333334, 96.0, 1.0, 2.0, 0.4126703675221082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 608315.5858651221, 608315.5858651227, 175098.835103869]
[2019-03-26 20:17:22,967] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:17:22,971] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.5973601e-36 9.9997163e-01 2.8767600e-32 2.8381850e-05 2.0952885e-22], sampled 0.4156048375771676
[2019-03-26 20:17:26,628] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.32427415]
[2019-03-26 20:17:26,632] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.04564258666667, 95.39381155000001, 1.0, 2.0, 0.457460235669568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 649118.7650768878, 649118.7650768884, 178476.2828719348]
[2019-03-26 20:17:26,633] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:17:26,636] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.4733417e-37 9.9998248e-01 3.3943579e-33 1.7536826e-05 4.3502912e-23], sampled 0.9491392070497859
[2019-03-26 20:17:28,946] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.32427415]
[2019-03-26 20:17:28,947] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.11074051333333, 89.97066229, 1.0, 2.0, 0.5007066883409659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 699660.1283532759, 699660.1283532759, 183705.0835985761]
[2019-03-26 20:17:28,949] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:17:28,952] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.3358497e-37 9.9997509e-01 1.6056041e-32 2.4887760e-05 1.3644132e-22], sampled 0.4933018789128668
[2019-03-26 20:18:06,308] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.32427415]
[2019-03-26 20:18:06,309] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.53333333333334, 85.0, 1.0, 2.0, 1.04, 1.0, 1.0, 1.04, 1.0, 1.0, 1.03, 12.24786211123054, 6.9112, 178.6582176852504, 7749255.486784304, 3744813.613824722, 652777.1782125215]
[2019-03-26 20:18:06,311] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:18:06,314] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9699329e-14 1.2443793e-02 7.4874516e-12 9.8755580e-01 4.7258115e-07], sampled 0.04924587125615698
[2019-03-26 20:18:06,317] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 0, 0, 1, 0] has been changed to [0, 0, 0, 0, 1] for the demand 7749255.486784304 W.
[2019-03-26 20:18:17,959] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.32427415]
[2019-03-26 20:18:17,960] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.3, 74.0, 1.0, 2.0, 0.8245608289578767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1152441.71156714, 1152441.71156714, 250031.3870685071]
[2019-03-26 20:18:17,963] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:18:17,966] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.5709541e-32 9.9978548e-01 2.2849401e-28 2.1457080e-04 1.5487253e-19], sampled 0.5439552772987816
[2019-03-26 20:18:52,830] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.6940 2928895463.3087 1338.0000
[2019-03-26 20:18:52,905] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7867.9829 3165519866.7258 1776.0000
[2019-03-26 20:18:53,147] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8486.9829 2843703950.0615 1126.0000
[2019-03-26 20:18:53,256] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8652.0363 2780467312.9457 930.0000
[2019-03-26 20:18:53,432] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.5509 3008944026.9589 1765.0000
[2019-03-26 20:18:54,447] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 600000, evaluation results [600000.0, 7867.982862109405, 3165519866.725827, 1776.0, 8252.694036693098, 2928895463.3087363, 1338.0, 8652.036338704107, 2780467312.9456897, 930.0, 7998.5508866252285, 3008944026.9589005, 1765.0, 8486.982896370237, 2843703950.061492, 1126.0]
[2019-03-26 20:18:54,650] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5750616e-22 9.9845159e-01 1.8015706e-18 1.5484494e-03 3.0438251e-14], sum to 1.0000
[2019-03-26 20:18:54,660] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2095
[2019-03-26 20:18:54,666] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2076190.349115588 W.
[2019-03-26 20:18:54,675] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.26666666666667, 73.16666666666667, 1.0, 2.0, 0.8436680878369414, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.985733105390921, 6.9112, 168.9125129092245, 2076190.349115588, 2023314.137784252, 419652.6172134328], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6603000.0000, 
sim time next is 6603600.0000, 
raw observation next is [29.43333333333334, 72.33333333333334, 1.0, 2.0, 0.9644793841238664, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.983490521092355, 6.9112, 168.9124660911467, 2245285.468026148, 2194000.233216709, 453381.9821370981], 
processed observation next is [1.0, 0.43478260869565216, 0.5939968404423385, 0.7233333333333334, 1.0, 1.0, 0.9572040772576703, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007229052109235479, 0.0, 0.8294375369691019, 0.6236904077850411, 0.6094445092268637, 0.6766895255777583], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2863785], dtype=float32), -1.0137737]. 
=============================================
[2019-03-26 20:19:00,341] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2882592e-26 1.0000000e+00 9.9171491e-23 1.7507045e-08 1.9889727e-15], sum to 1.0000
[2019-03-26 20:19:00,353] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5880
[2019-03-26 20:19:00,362] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1925974.094409144 W.
[2019-03-26 20:19:00,371] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.2, 78.0, 1.0, 2.0, 0.7363339680683881, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.978636387597992, 6.9112, 168.9124991895495, 1925974.094409144, 1878132.529594078, 393690.4319716908], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6688800.0000, 
sim time next is 6689400.0000, 
raw observation next is [28.36666666666667, 77.0, 1.0, 2.0, 0.6126822929603407, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.922463770696725, 6.9112, 168.912801422262, 1713074.299918658, 1705083.400654219, 367905.9071460977], 
processed observation next is [1.0, 0.43478260869565216, 0.543443917851501, 0.77, 1.0, 1.0, 0.5333521601931815, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0011263770696724683, 0.0, 0.8294391835983932, 0.4758539721996273, 0.4736342779595053, 0.549113294247907], 
reward next is 0.3946, 
noisyNet noise sample is [array([2.1038225], dtype=float32), -0.21720552]. 
=============================================
[2019-03-26 20:19:07,182] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2289918e-27 9.9680907e-01 2.0170995e-23 3.1909645e-03 6.4642163e-12], sum to 1.0000
[2019-03-26 20:19:07,190] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4042
[2019-03-26 20:19:07,196] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.11666666666667, 49.83333333333334, 1.0, 2.0, 0.9959389549247336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1536659.084714192, 1536659.084714191, 318770.0041731353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6799800.0000, 
sim time next is 6800400.0000, 
raw observation next is [29.1, 50.0, 1.0, 2.0, 0.9962828163074118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1536412.822916233, 1536412.822916233, 318786.9920947404], 
processed observation next is [1.0, 0.7391304347826086, 0.5781990521327015, 0.5, 1.0, 1.0, 0.9955214654306166, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.4267813396989536, 0.4267813396989536, 0.4758014807384185], 
reward next is 0.5242, 
noisyNet noise sample is [array([0.3775956], dtype=float32), 0.14629692]. 
=============================================
[2019-03-26 20:19:07,359] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 9.9998844e-01 0.0000000e+00 1.1540960e-05 2.0620861e-27], sum to 1.0000
[2019-03-26 20:19:07,366] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4256
[2019-03-26 20:19:07,373] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.45, 64.5, 1.0, 2.0, 0.3244562366740797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 510224.5839530903, 510224.5839530903, 167740.2925411642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6816600.0000, 
sim time next is 6817200.0000, 
raw observation next is [25.33333333333334, 65.33333333333333, 1.0, 2.0, 0.3265185474731737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 513167.4999976011, 513167.4999976018, 167959.746766201], 
processed observation next is [1.0, 0.9130434782608695, 0.3996840442338076, 0.6533333333333333, 1.0, 1.0, 0.18857656322069122, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1425465277771114, 0.1425465277771116, 0.25068618920328506], 
reward next is 0.7493, 
noisyNet noise sample is [array([-0.0622963], dtype=float32), -1.4864564]. 
=============================================
[2019-03-26 20:19:23,421] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 8.8171644e-38 1.0873920e-15 1.0493188e-23], sum to 1.0000
[2019-03-26 20:19:23,430] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6738
[2019-03-26 20:19:23,436] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.76666666666667, 81.0, 1.0, 2.0, 0.4831327692617746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 675095.4923229417, 675095.4923229422, 180995.5421858316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7067400.0000, 
sim time next is 7068000.0000, 
raw observation next is [26.63333333333333, 82.0, 1.0, 2.0, 0.4842626667678272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 676674.833879201, 676674.8338792004, 181167.0911568115], 
processed observation next is [1.0, 0.8260869565217391, 0.46129541864139006, 0.82, 1.0, 1.0, 0.3786297189973822, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18796523163311138, 0.1879652316331112, 0.2703986435176291], 
reward next is 0.7296, 
noisyNet noise sample is [array([-1.6058861], dtype=float32), 1.6282376]. 
=============================================
[2019-03-26 20:19:23,450] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[71.53942 ]
 [71.802284]
 [71.81223 ]
 [71.50057 ]
 [71.69307 ]], R is [[71.2394104 ]
 [71.25687408]
 [71.27438354]
 [71.29180908]
 [71.30921936]].
[2019-03-26 20:19:24,067] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.1281594e-17 7.2391118e-25], sum to 1.0000
[2019-03-26 20:19:24,075] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0882
[2019-03-26 20:19:24,079] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.46666666666667, 87.66666666666667, 1.0, 2.0, 0.4784223821799258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 668809.4186767162, 668809.4186767162, 180322.4065576535], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7080000.0000, 
sim time next is 7080600.0000, 
raw observation next is [25.43333333333333, 87.83333333333334, 1.0, 2.0, 0.4763658806335168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 666240.161627436, 666240.1616274355, 180053.5501212139], 
processed observation next is [1.0, 0.9565217391304348, 0.40442338072669815, 0.8783333333333334, 1.0, 1.0, 0.3691155188355624, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1850667115631767, 0.18506671156317653, 0.268736641971961], 
reward next is 0.7313, 
noisyNet noise sample is [array([1.701706], dtype=float32), 0.4565915]. 
=============================================
[2019-03-26 20:19:30,730] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4284810e-25 9.9999976e-01 1.3234261e-22 2.4929088e-07 5.5529301e-13], sum to 1.0000
[2019-03-26 20:19:30,740] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3684
[2019-03-26 20:19:30,750] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1979820.160724317 W.
[2019-03-26 20:19:30,758] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.7748103793313128, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005979955035142, 6.9112, 168.912316035653, 1979820.160724317, 1912580.253505605, 401701.4887373851], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7203600.0000, 
sim time next is 7204200.0000, 
raw observation next is [29.0, 83.16666666666667, 1.0, 2.0, 0.7327956772591324, 1.0, 1.0, 0.7327956772591324, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2049219.402445563, 2049219.402445564, 388485.8862273065], 
processed observation next is [1.0, 0.391304347826087, 0.5734597156398105, 0.8316666666666667, 1.0, 1.0, 0.6780670810350993, 1.0, 0.5, 0.6780670810350993, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5692276117904342, 0.5692276117904345, 0.5798296809362784], 
reward next is 0.4202, 
noisyNet noise sample is [array([0.6193076], dtype=float32), -0.13610868]. 
=============================================
[2019-03-26 20:19:35,482] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.0737516e-36 1.0896132e-08 8.2809820e-20], sum to 1.0000
[2019-03-26 20:19:35,491] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7086
[2019-03-26 20:19:35,500] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 85.66666666666667, 1.0, 2.0, 0.3202498099343761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 504565.0852633117, 504565.0852633124, 167330.6141950369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7285200.0000, 
sim time next is 7285800.0000, 
raw observation next is [22.25, 85.33333333333334, 1.0, 2.0, 0.3194155092829265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 503177.2750253567, 503177.2750253567, 167224.0212844154], 
processed observation next is [1.0, 0.30434782608695654, 0.2535545023696683, 0.8533333333333334, 1.0, 1.0, 0.18001868588304398, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1397714652848213, 0.1397714652848213, 0.24958809146927668], 
reward next is 0.7504, 
noisyNet noise sample is [array([-0.33105156], dtype=float32), 1.5106071]. 
=============================================
[2019-03-26 20:19:36,831] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.3224095e-27 1.0000000e+00 2.3352534e-25 2.4563901e-08 3.6926208e-13], sum to 1.0000
[2019-03-26 20:19:36,842] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8982
[2019-03-26 20:19:36,848] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.93333333333333, 58.00000000000001, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.964758930878284, 6.9112, 168.9124963630703, 1622594.904888347, 1584598.459476157, 331221.0055080327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7309200.0000, 
sim time next is 7309800.0000, 
raw observation next is [27.9, 58.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.16910805149819, 6.9112, 168.91136831862, 1764837.706487911, 1581870.578596328, 330829.8164752468], 
processed observation next is [1.0, 0.6086956521739131, 0.5213270142180094, 0.585, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.02579080514981902, 0.0, 0.8294321464034333, 0.49023269624664195, 0.4394084940545355, 0.493775845485443], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7114111], dtype=float32), -1.857911]. 
=============================================
[2019-03-26 20:19:37,400] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0126014e-27 9.9954361e-01 5.3046072e-24 4.5633459e-04 7.2345753e-15], sum to 1.0000
[2019-03-26 20:19:37,411] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1456
[2019-03-26 20:19:37,417] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 60.0, 1.0, 2.0, 0.5122263150738964, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8961078934279184, 6.9112, 6.9112, 168.9127596988931, 1540987.927778391, 1540987.927778391, 323877.1739966316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7311600.0000, 
sim time next is 7312200.0000, 
raw observation next is [27.76666666666667, 60.33333333333333, 1.0, 2.0, 0.8070539441775163, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9129564612865, 1216820.616689628, 1216820.616689628, 257667.7315468164], 
processed observation next is [1.0, 0.6521739130434783, 0.515007898894155, 0.6033333333333333, 1.0, 1.0, 0.7675348725030317, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8294399449109807, 0.33800572685823, 0.33800572685823, 0.3845787038012185], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3348783], dtype=float32), -0.6830217]. 
=============================================
[2019-03-26 20:19:38,039] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 2.26993564e-38 1.20467565e-08
 1.17145807e-22], sum to 1.0000
[2019-03-26 20:19:38,052] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0105
[2019-03-26 20:19:38,060] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666666, 90.66666666666667, 1.0, 2.0, 0.3343134563354721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 524635.574303105, 524635.5743031057, 168836.3574700976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7368000.0000, 
sim time next is 7368600.0000, 
raw observation next is [21.48333333333333, 90.83333333333334, 1.0, 2.0, 0.3277640517223998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 516408.1460469738, 516408.1460469738, 168237.0159392175], 
processed observation next is [1.0, 0.2608695652173913, 0.21721958925750387, 0.9083333333333334, 1.0, 1.0, 0.1900771707498793, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1434467072352705, 0.1434467072352705, 0.25110002378987684], 
reward next is 0.7489, 
noisyNet noise sample is [array([-0.9823159], dtype=float32), 0.7696797]. 
=============================================
[2019-03-26 20:19:40,113] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 9.9999785e-01 1.5332290e-33 2.0960761e-06 7.0710720e-12], sum to 1.0000
[2019-03-26 20:19:40,119] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0723
[2019-03-26 20:19:40,123] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.76666666666667, 87.0, 1.0, 2.0, 0.4187632833010237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 628245.6697787711, 628245.6697787705, 177263.7214131462], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7360800.0000, 
sim time next is 7361400.0000, 
raw observation next is [23.68333333333333, 88.0, 1.0, 2.0, 0.4133061746971389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 619006.4355631499, 619006.4355631499, 176363.4572957827], 
processed observation next is [1.0, 0.17391304347826086, 0.32148499210110576, 0.88, 1.0, 1.0, 0.2931399695146251, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17194623210087495, 0.17194623210087495, 0.26322904073997416], 
reward next is 0.7368, 
noisyNet noise sample is [array([0.15355624], dtype=float32), -1.7360004]. 
=============================================
[2019-03-26 20:19:49,520] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.5014803e-12 1.2737302e-25], sum to 1.0000
[2019-03-26 20:19:49,530] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6078
[2019-03-26 20:19:49,537] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 92.5, 1.0, 2.0, 0.4058138906486476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 596810.241652311, 596810.2416523115, 173983.2552016551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7515000.0000, 
sim time next is 7515600.0000, 
raw observation next is [23.6, 92.66666666666667, 1.0, 2.0, 0.4066744334745181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 597597.7098401077, 597597.7098401077, 174041.3197998646], 
processed observation next is [0.0, 1.0, 0.3175355450236968, 0.9266666666666667, 1.0, 1.0, 0.285149919848817, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16599936384447436, 0.16599936384447436, 0.25976316388039494], 
reward next is 0.7402, 
noisyNet noise sample is [array([-0.15913564], dtype=float32), 0.8843523]. 
=============================================
[2019-03-26 20:19:50,165] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 20:19:50,167] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:19:50,168] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:19:50,169] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:19:50,169] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:19:50,170] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:19:50,170] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:19:50,172] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:19:50,173] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:19:50,174] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:19:50,174] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:19:50,187] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run26
[2019-03-26 20:19:50,207] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run26
[2019-03-26 20:19:50,209] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run26
[2019-03-26 20:19:50,257] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run26
[2019-03-26 20:19:50,257] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run26
[2019-03-26 20:21:29,425] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.3107133]
[2019-03-26 20:21:29,426] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.081574, 50.60030628, 1.0, 2.0, 0.473051288425793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 662693.2075661977, 662693.2075661983, 179699.5957641838]
[2019-03-26 20:21:29,427] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:21:29,432] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.8757364e-38 9.7563606e-12 1.9770128e-23], sampled 0.45343756171405514
[2019-03-26 20:21:43,841] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8653.5743 2780429570.5853 933.0000
[2019-03-26 20:21:44,277] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.1216 3008876889.3043 1766.0000
[2019-03-26 20:21:44,365] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7871.1405 3165253654.0675 1778.0000
[2019-03-26 20:21:44,390] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8489.7239 2843725838.7279 1131.0000
[2019-03-26 20:21:44,564] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.2080 2928561770.3254 1338.0000
[2019-03-26 20:21:45,579] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 625000, evaluation results [625000.0, 7871.140521287784, 3165253654.067518, 1778.0, 8253.207968018407, 2928561770.3253736, 1338.0, 8653.574286246634, 2780429570.5853157, 933.0, 7997.121552070433, 3008876889.3043056, 1766.0, 8489.723891416836, 2843725838.7279377, 1131.0]
[2019-03-26 20:21:48,430] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 6.0981388e-37 6.1121179e-09 2.6257375e-24], sum to 1.0000
[2019-03-26 20:21:48,444] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4087
[2019-03-26 20:21:48,450] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.35, 74.5, 1.0, 2.0, 0.4594131902218633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 645908.7461473537, 645908.7461473542, 177994.9319047655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7583400.0000, 
sim time next is 7584000.0000, 
raw observation next is [27.23333333333333, 75.66666666666667, 1.0, 2.0, 0.4632503953924129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 649275.9558403647, 649275.9558403647, 178293.890136891], 
processed observation next is [0.0, 0.782608695652174, 0.4897314375987361, 0.7566666666666667, 1.0, 1.0, 0.35331372938844935, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18035443217787908, 0.18035443217787908, 0.26611028378640444], 
reward next is 0.7339, 
noisyNet noise sample is [array([0.81139296], dtype=float32), 0.74133295]. 
=============================================
[2019-03-26 20:21:48,471] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[72.445496]
 [72.523   ]
 [72.606606]
 [72.702965]
 [72.72511 ]], R is [[72.38072205]
 [72.39125061]
 [72.40205383]
 [72.41299438]
 [72.42395782]].
[2019-03-26 20:21:50,339] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6916451e-31 9.9999475e-01 2.5479851e-27 5.2333644e-06 1.1812283e-17], sum to 1.0000
[2019-03-26 20:21:50,351] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7931
[2019-03-26 20:21:50,356] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 94.66666666666666, 1.0, 2.0, 0.451311847112216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 644604.2572524298, 644604.2572524291, 178118.7040082693], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7609200.0000, 
sim time next is 7609800.0000, 
raw observation next is [23.96666666666667, 94.83333333333333, 1.0, 2.0, 0.448102153616107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 641251.1882009836, 641251.1882009836, 177809.1674965124], 
processed observation next is [1.0, 0.043478260869565216, 0.33491311216429714, 0.9483333333333333, 1.0, 1.0, 0.33506283568205664, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17812533005582876, 0.17812533005582876, 0.2653868171589738], 
reward next is 0.7346, 
noisyNet noise sample is [array([-1.3429726], dtype=float32), 0.78148174]. 
=============================================
[2019-03-26 20:21:52,597] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3049817e-27 9.9999964e-01 2.9333597e-23 4.0245035e-07 4.9874922e-15], sum to 1.0000
[2019-03-26 20:21:52,605] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1725
[2019-03-26 20:21:52,615] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1673875.131079417 W.
[2019-03-26 20:21:52,621] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.01666666666667, 62.33333333333334, 1.0, 2.0, 0.3991188513917397, 1.0, 2.0, 0.3991188513917397, 1.0, 1.0, 0.6742837772686829, 6.9112, 6.9112, 170.5573041426782, 1673875.131079417, 1673875.131079417, 349716.073997352], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7645800.0000, 
sim time next is 7646400.0000, 
raw observation next is [30.1, 62.0, 1.0, 2.0, 0.6334611335264201, 1.0, 2.0, 0.6334611335264201, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1771206.665474075, 1771206.665474075, 346929.8277045569], 
processed observation next is [1.0, 0.5217391304347826, 0.6255924170616115, 0.62, 1.0, 1.0, 0.5583869078631567, 1.0, 1.0, 0.5583869078631567, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.49200185152057635, 0.49200185152057635, 0.517805712991876], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0451033], dtype=float32), -0.5822121]. 
=============================================
[2019-03-26 20:21:54,540] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7602467e-34 9.9972004e-01 2.4083695e-31 2.7995754e-04 5.0216952e-16], sum to 1.0000
[2019-03-26 20:21:54,550] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5715
[2019-03-26 20:21:54,558] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.06666666666667, 88.83333333333334, 1.0, 2.0, 0.5033813306917474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 703398.7646157708, 703398.7646157702, 184127.4413848462], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7675800.0000, 
sim time next is 7676400.0000, 
raw observation next is [26.03333333333333, 88.66666666666667, 1.0, 2.0, 0.5023513730567796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 701959.0801179268, 701959.0801179275, 183965.1251545989], 
processed observation next is [1.0, 0.8695652173913043, 0.4328593996840442, 0.8866666666666667, 1.0, 1.0, 0.4004233410322645, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1949886333660908, 0.19498863336609099, 0.27457481366358044], 
reward next is 0.7254, 
noisyNet noise sample is [array([0.59474826], dtype=float32), 0.47452772]. 
=============================================
[2019-03-26 20:21:55,699] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7755653e-34 9.9347669e-01 7.3906201e-29 6.5233745e-03 9.8076634e-12], sum to 1.0000
[2019-03-26 20:21:55,709] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3222
[2019-03-26 20:21:55,713] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 94.00000000000001, 1.0, 2.0, 0.5280437127119593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742144.040853196, 742144.0408531955, 188653.3408578768], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7704600.0000, 
sim time next is 7705200.0000, 
raw observation next is [24.5, 94.0, 1.0, 2.0, 0.5017017369180252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 705140.2329091638, 705140.2329091632, 184387.8920264565], 
processed observation next is [1.0, 0.17391304347826086, 0.3601895734597157, 0.94, 1.0, 1.0, 0.399640646889187, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19587228691921216, 0.19587228691921202, 0.2752058089947112], 
reward next is 0.7248, 
noisyNet noise sample is [array([-0.89524037], dtype=float32), 0.16973807]. 
=============================================
[2019-03-26 20:22:02,689] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2685041e-23 9.9999988e-01 7.4226228e-21 1.2815532e-07 2.5762317e-10], sum to 1.0000
[2019-03-26 20:22:02,697] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4064
[2019-03-26 20:22:02,704] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1795803.099376648 W.
[2019-03-26 20:22:02,711] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.6433105096462534, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.003228753253159, 6.9112, 168.912330825992, 1795803.099376648, 1730514.976273643, 372945.3417437675], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7820400.0000, 
sim time next is 7821000.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.581000943209599, 1.0, 1.0, 0.581000943209599, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1624412.712880888, 1624412.712880888, 327346.5780693935], 
processed observation next is [1.0, 0.5217391304347826, 0.6682464454976303, 0.7, 1.0, 1.0, 0.49518185928867353, 1.0, 0.5, 0.49518185928867353, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.45122575357802447, 0.45122575357802447, 0.4885769821931247], 
reward next is 0.5114, 
noisyNet noise sample is [array([1.0508243], dtype=float32), 0.17974094]. 
=============================================
[2019-03-26 20:22:02,722] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[45.855747]
 [42.178886]
 [41.847828]
 [43.64012 ]
 [43.43431 ]], R is [[47.03798676]
 [46.56760788]
 [46.10193253]
 [45.9452095 ]
 [45.87262344]].
[2019-03-26 20:22:04,961] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3424532e-22 3.7746748e-01 1.6085053e-19 6.2253159e-01 9.4282791e-07], sum to 1.0000
[2019-03-26 20:22:04,971] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0736
[2019-03-26 20:22:04,981] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1918041.204685747 W.
[2019-03-26 20:22:04,988] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.06666666666667, 74.66666666666667, 1.0, 2.0, 0.7306652527876907, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.985416153953917, 6.9112, 168.9125147340557, 1918041.204685747, 1865389.848453114, 392191.1695331716], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7899600.0000, 
sim time next is 7900200.0000, 
raw observation next is [29.2, 74.0, 1.0, 2.0, 0.6880381936121137, 1.0, 1.0, 0.6880381936121137, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1923945.383279033, 1923945.383279033, 369043.5870087774], 
processed observation next is [1.0, 0.43478260869565216, 0.5829383886255924, 0.74, 1.0, 1.0, 0.6241424019423056, 1.0, 0.5, 0.6241424019423056, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5344292731330648, 0.5344292731330648, 0.5508113238936977], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.92153937], dtype=float32), -0.6652085]. 
=============================================
[2019-03-26 20:22:05,350] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.7967398e-28 9.8306757e-01 2.0858635e-26 1.6932383e-02 7.7047974e-10], sum to 1.0000
[2019-03-26 20:22:05,356] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9921
[2019-03-26 20:22:05,365] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.3, 89.0, 1.0, 2.0, 0.5071408397273727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 708653.8583693281, 708653.8583693281, 184722.7078784022], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7862400.0000, 
sim time next is 7863000.0000, 
raw observation next is [26.26666666666667, 89.33333333333334, 1.0, 2.0, 0.2539170916394295, 1.0, 1.0, 0.2539170916394295, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 709620.7412616409, 709620.7412616409, 241592.4476300147], 
processed observation next is [1.0, 0.0, 0.44391785150079005, 0.8933333333333334, 1.0, 1.0, 0.10110492968605962, 1.0, 0.5, 0.10110492968605962, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.19711687257267804, 0.19711687257267804, 0.36058574273136523], 
reward next is 0.6394, 
noisyNet noise sample is [array([1.2425927], dtype=float32), -0.7328492]. 
=============================================
[2019-03-26 20:22:05,378] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[61.67173 ]
 [62.066395]
 [61.94158 ]
 [61.837406]
 [61.759808]], R is [[60.63285065]
 [60.75081635]
 [60.86759567]
 [60.98330307]
 [61.09815598]].
[2019-03-26 20:22:06,220] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.7235278e-28 9.9999905e-01 4.1181125e-26 9.6561280e-07 9.5710549e-13], sum to 1.0000
[2019-03-26 20:22:06,229] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4490
[2019-03-26 20:22:06,235] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.25, 89.5, 1.0, 2.0, 0.5937695231609816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 829751.8329669524, 829751.8329669529, 199584.9481805256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7878600.0000, 
sim time next is 7879200.0000, 
raw observation next is [26.26666666666667, 89.33333333333333, 1.0, 2.0, 0.693426089341136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 969078.5251910627, 969078.5251910621, 219431.0477504276], 
processed observation next is [1.0, 0.17391304347826086, 0.44391785150079005, 0.8933333333333333, 1.0, 1.0, 0.6306338425796819, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.26918847921973965, 0.2691884792197395, 0.32750902649317554], 
reward next is 0.6725, 
noisyNet noise sample is [array([0.342941], dtype=float32), 1.7489133]. 
=============================================
[2019-03-26 20:22:08,251] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:22:08,253] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:22:08,299] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run4
[2019-03-26 20:22:08,559] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:22:08,560] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:22:08,585] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run4
[2019-03-26 20:22:08,866] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:22:08,867] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:22:08,892] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run4
[2019-03-26 20:22:09,456] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:22:09,457] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:22:09,472] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run4
[2019-03-26 20:22:10,082] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:22:10,083] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:22:10,098] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run4
[2019-03-26 20:22:10,149] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:22:10,150] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:22:10,159] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run4
[2019-03-26 20:22:10,231] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.5818498e-30 9.9659592e-01 9.3022977e-26 2.5588647e-03 8.4516173e-04], sum to 1.0000
[2019-03-26 20:22:10,231] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1698
[2019-03-26 20:22:10,233] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.25, 84.0, 1.0, 2.0, 0.3407849854143521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 539199.0849194026, 539199.0849194026, 170068.0473896108], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 28200.0000, 
sim time next is 28800.0000, 
raw observation next is [22.3, 84.0, 1.0, 2.0, 0.3294673708643176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 520693.2050942397, 520693.2050942397, 168598.3714292786], 
processed observation next is [1.0, 0.34782608695652173, 0.25592417061611383, 0.84, 1.0, 1.0, 0.19212936248712964, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14463700141506658, 0.14463700141506658, 0.25163936034220685], 
reward next is 0.7484, 
noisyNet noise sample is [array([-0.17418112], dtype=float32), -0.17483023]. 
=============================================
[2019-03-26 20:22:10,408] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:22:10,408] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:22:10,419] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run4
[2019-03-26 20:22:10,434] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:22:10,435] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:22:10,438] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:22:10,439] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:22:10,439] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:22:10,440] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:22:10,453] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run4
[2019-03-26 20:22:10,475] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run4
[2019-03-26 20:22:10,505] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run4
[2019-03-26 20:22:10,526] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:22:10,527] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:22:10,530] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:22:10,531] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:22:10,535] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run4
[2019-03-26 20:22:10,536] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run4
[2019-03-26 20:22:10,556] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:22:10,560] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:22:10,557] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:22:10,560] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:22:10,578] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:22:10,579] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:22:10,582] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run4
[2019-03-26 20:22:10,603] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:22:10,606] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:22:10,605] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run4
[2019-03-26 20:22:10,629] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run4
[2019-03-26 20:22:10,672] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run4
[2019-03-26 20:22:20,778] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3432256e-32 3.2248765e-01 1.8660674e-30 6.7751235e-01 6.6036183e-11], sum to 1.0000
[2019-03-26 20:22:20,787] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3214
[2019-03-26 20:22:20,794] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.58333333333334, 96.0, 1.0, 2.0, 0.8188058515441471, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1222329.738009549, 1222329.73800955, 259281.9894097141], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 144600.0000, 
sim time next is 145200.0000, 
raw observation next is [22.56666666666667, 96.0, 1.0, 2.0, 0.7686168487608611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1153430.746249281, 1153430.746249281, 246913.0105025868], 
processed observation next is [1.0, 0.6956521739130435, 0.26856240126382325, 0.96, 1.0, 1.0, 0.7212251189889893, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3203974295136892, 0.3203974295136892, 0.3685268813471445], 
reward next is 0.6315, 
noisyNet noise sample is [array([-0.84702533], dtype=float32), 1.5135305]. 
=============================================
[2019-03-26 20:22:22,532] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.2415479e-36 7.1749445e-10 2.4128068e-15], sum to 1.0000
[2019-03-26 20:22:22,541] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6430
[2019-03-26 20:22:22,549] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 96.0, 1.0, 2.0, 0.2866967877716635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 461796.446713019, 461796.446713019, 164395.6499334722], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 184800.0000, 
sim time next is 185400.0000, 
raw observation next is [19.9, 96.0, 1.0, 2.0, 0.2863924508741391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 461306.5985648271, 461306.5985648271, 164362.226335434], 
processed observation next is [0.0, 0.13043478260869565, 0.14218009478672985, 0.96, 1.0, 1.0, 0.14023186852305916, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1281407218235631, 0.1281407218235631, 0.24531675572452838], 
reward next is 0.7547, 
noisyNet noise sample is [array([0.45949012], dtype=float32), 0.1370198]. 
=============================================
[2019-03-26 20:22:29,105] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5972279e-37 1.0000000e+00 3.0756884e-35 6.2565495e-09 2.5476789e-11], sum to 1.0000
[2019-03-26 20:22:29,115] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2659
[2019-03-26 20:22:29,122] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.13333333333333, 77.66666666666667, 1.0, 2.0, 0.3094962625492548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 489258.1009426742, 489258.1009426742, 166226.0873306207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 315600.0000, 
sim time next is 316200.0000, 
raw observation next is [23.06666666666667, 77.83333333333333, 1.0, 2.0, 0.3080996017122549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 487513.7142572048, 487513.7142572048, 166108.3679744664], 
processed observation next is [0.0, 0.6521739130434783, 0.29225908372827825, 0.7783333333333333, 1.0, 1.0, 0.16638506230392158, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1354204761825569, 0.1354204761825569, 0.247922937275323], 
reward next is 0.7521, 
noisyNet noise sample is [array([0.42474133], dtype=float32), -0.5029715]. 
=============================================
[2019-03-26 20:22:32,659] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.9634102e-37 1.0000000e+00 1.0586781e-32 2.4215174e-10 1.9897221e-13], sum to 1.0000
[2019-03-26 20:22:32,667] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4524
[2019-03-26 20:22:32,674] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.53333333333333, 86.33333333333334, 1.0, 2.0, 0.2654771746370886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 431528.6926698316, 431528.692669831, 162369.0579879229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 346800.0000, 
sim time next is 347400.0000, 
raw observation next is [20.5, 86.5, 1.0, 2.0, 0.2644502284675434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 429946.2735186359, 429946.2735186366, 162267.0934253527], 
processed observation next is [1.0, 0.0, 0.1706161137440759, 0.865, 1.0, 1.0, 0.11379545598499204, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11942952042184331, 0.1194295204218435, 0.24218969167963092], 
reward next is 0.7578, 
noisyNet noise sample is [array([0.73912215], dtype=float32), -0.0417178]. 
=============================================
[2019-03-26 20:22:32,703] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7523466e-36 1.0000000e+00 3.6602487e-30 1.4215484e-09 2.9155061e-19], sum to 1.0000
[2019-03-26 20:22:32,713] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1020
[2019-03-26 20:22:32,721] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.28333333333333, 87.16666666666667, 1.0, 2.0, 0.2821006884393824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 459653.4282804437, 459653.4282804437, 164179.2948031635], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 353400.0000, 
sim time next is 354000.0000, 
raw observation next is [20.26666666666667, 87.33333333333334, 1.0, 2.0, 0.2630778905028809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 428627.6173948369, 428627.6173948369, 162163.38724596], 
processed observation next is [1.0, 0.08695652173913043, 0.15955766192733034, 0.8733333333333334, 1.0, 1.0, 0.11214203675045889, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11906322705412137, 0.11906322705412137, 0.24203490633725375], 
reward next is 0.7580, 
noisyNet noise sample is [array([0.02409138], dtype=float32), -1.5507716]. 
=============================================
[2019-03-26 20:22:32,732] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[68.63205]
 [66.9978 ]
 [66.59083]
 [66.61782]
 [66.72834]], R is [[70.19766998]
 [70.25065613]
 [70.30654907]
 [70.36184692]
 [70.41656494]].
[2019-03-26 20:22:33,639] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 9.9999857e-01 0.0000000e+00 4.7787769e-15 1.4709065e-06], sum to 1.0000
[2019-03-26 20:22:33,648] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6725
[2019-03-26 20:22:33,652] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.95, 80.66666666666667, 1.0, 2.0, 0.2629360286976634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 429372.7078993038, 429372.7078993038, 162180.3633512583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 373800.0000, 
sim time next is 374400.0000, 
raw observation next is [21.0, 80.0, 1.0, 2.0, 0.25827091080741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 421985.7443882529, 421985.7443882535, 161711.2830845121], 
processed observation next is [1.0, 0.34782608695652173, 0.19431279620853087, 0.8, 1.0, 1.0, 0.10635049494868673, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11721826233007025, 0.11721826233007042, 0.24136012400673448], 
reward next is 0.7586, 
noisyNet noise sample is [array([-0.942893], dtype=float32), -0.17967159]. 
=============================================
[2019-03-26 20:22:37,333] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.9930157e-37 1.0000000e+00 7.1348409e-35 1.2712660e-11 1.2031023e-20], sum to 1.0000
[2019-03-26 20:22:37,350] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1310
[2019-03-26 20:22:37,355] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 88.5, 1.0, 2.0, 0.2141789626914568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 356631.4660712971, 356631.4660712964, 157136.8971167101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 538200.0000, 
sim time next is 538800.0000, 
raw observation next is [18.4, 87.66666666666666, 1.0, 2.0, 0.2158356069159676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 359130.1103477972, 359130.1103477978, 157343.2921589192], 
processed observation next is [1.0, 0.21739130434782608, 0.07109004739336493, 0.8766666666666666, 1.0, 1.0, 0.05522362279032239, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.09975836398549923, 0.0997583639854994, 0.23484073456555107], 
reward next is 0.7652, 
noisyNet noise sample is [array([-1.3049452], dtype=float32), 0.5465162]. 
=============================================
[2019-03-26 20:22:40,280] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8482224e-36 1.0000000e+00 3.2720450e-34 3.6823861e-10 3.1778132e-14], sum to 1.0000
[2019-03-26 20:22:40,286] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3584
[2019-03-26 20:22:40,294] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 55.66666666666667, 1.0, 2.0, 0.5498549963960074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 898547.6938167696, 898547.6938167696, 205195.2833264635], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 480000.0000, 
sim time next is 480600.0000, 
raw observation next is [24.95, 55.0, 1.0, 2.0, 0.5787618109575396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 945408.8146812594, 945408.8146812594, 211038.9238447963], 
processed observation next is [1.0, 0.5652173913043478, 0.3815165876777251, 0.55, 1.0, 1.0, 0.49248410958739713, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.26261355963368316, 0.26261355963368316, 0.31498346842506914], 
reward next is 0.6850, 
noisyNet noise sample is [array([1.2594286], dtype=float32), -0.45135805]. 
=============================================
[2019-03-26 20:22:40,550] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 5.9200279e-34 2.8612965e-12 1.5219797e-18], sum to 1.0000
[2019-03-26 20:22:40,559] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7506
[2019-03-26 20:22:40,564] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 72.0, 1.0, 2.0, 0.2397650428501931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 395975.6637060771, 395975.6637060766, 159860.6397402199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 501600.0000, 
sim time next is 502200.0000, 
raw observation next is [21.0, 73.5, 1.0, 2.0, 0.2395569635656393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 395710.2236278414, 395710.2236278414, 159836.5058957534], 
processed observation next is [1.0, 0.8260869565217391, 0.19431279620853087, 0.735, 1.0, 1.0, 0.08380357056101119, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.10991950656328928, 0.10991950656328928, 0.23856194909813938], 
reward next is 0.7614, 
noisyNet noise sample is [array([0.06308849], dtype=float32), -0.87066275]. 
=============================================
[2019-03-26 20:22:40,967] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-26 20:22:40,969] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:22:40,970] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:22:40,971] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:22:40,972] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:22:40,972] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:22:40,974] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:22:40,974] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:22:40,973] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:22:40,976] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:22:40,978] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:22:40,997] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run27
[2019-03-26 20:22:41,018] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run27
[2019-03-26 20:22:41,020] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run27
[2019-03-26 20:22:41,020] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run27
[2019-03-26 20:22:41,088] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run27
[2019-03-26 20:22:42,376] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.23727557]
[2019-03-26 20:22:42,377] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.29149270333334, 79.83395094, 1.0, 2.0, 0.293184175275549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 471483.4413050678, 471483.4413050684, 165063.458012478]
[2019-03-26 20:22:42,379] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:22:42,381] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 4.6831894e-38 6.7463648e-12 4.7058216e-17], sampled 0.7007935202330013
[2019-03-26 20:23:06,962] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.23727557]
[2019-03-26 20:23:06,963] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.15000532, 92.795798215, 1.0, 2.0, 0.5961906851606508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 833136.566338875, 833136.5663388744, 200030.7442504216]
[2019-03-26 20:23:06,965] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:23:06,968] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.000000e+00 1.000000e+00 8.705537e-38 8.442991e-12 6.363128e-17], sampled 0.03204003114857035
[2019-03-26 20:23:32,135] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.23727557]
[2019-03-26 20:23:32,136] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.63569538666667, 66.64765211, 1.0, 2.0, 0.5651433474902618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 789733.8612333903, 789733.8612333903, 194427.2950185833]
[2019-03-26 20:23:32,137] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:23:32,139] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.3016073e-13 5.0062403e-19], sampled 0.314761502136656
[2019-03-26 20:23:36,507] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.23727557]
[2019-03-26 20:23:36,508] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [34.27709867666667, 57.91157114833333, 1.0, 2.0, 0.6224625778039776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 869864.8112776207, 869864.8112776213, 205003.7038691425]
[2019-03-26 20:23:36,509] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:23:36,514] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.2709597e-13 1.1498195e-18], sampled 0.015500981333854136
[2019-03-26 20:23:43,320] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.23727557]
[2019-03-26 20:23:43,322] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.18231081, 82.73417187666668, 1.0, 2.0, 1.04, 1.0, 1.0, 1.04, 1.0, 1.0, 1.03, 16.31661607523065, 6.9112, 184.5923449428631, 11039109.3632595, 3747204.567600967, 632870.9083749107]
[2019-03-26 20:23:43,324] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:23:43,328] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.2614703e-13 2.9910326e-01 5.5035192e-11 6.8894333e-01 1.1953347e-02], sampled 0.40415765842902684
[2019-03-26 20:23:43,329] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 0, 0, 1, 0] has been changed to [0, 0, 0, 0, 1] for the demand 11039109.3632595 W.
[2019-03-26 20:23:58,487] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.23727557]
[2019-03-26 20:23:58,488] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.5, 52.0, 1.0, 2.0, 0.6581686081886676, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005972671665523, 6.9112, 168.9123160826414, 1816593.48776713, 1749358.747583205, 375840.3338136103]
[2019-03-26 20:23:58,489] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:23:58,490] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 4.8365595e-35 8.3106563e-11 1.3785149e-15], sampled 0.7448416361768804
[2019-03-26 20:23:58,491] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1816593.48776713 W.
[2019-03-26 20:24:12,822] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.23727557]
[2019-03-26 20:24:12,824] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.3135325, 67.48150722, 1.0, 2.0, 0.5082452020218767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 710197.5562066642, 710197.5562066636, 184897.2562919626]
[2019-03-26 20:24:12,825] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:24:12,826] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.9086792e-12 8.6126740e-18], sampled 0.002186324954408514
[2019-03-26 20:24:14,673] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.23727557]
[2019-03-26 20:24:14,676] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.87871423, 85.96236060999999, 1.0, 2.0, 0.5764077105633096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 805480.701397891, 805480.701397891, 196433.8561203916]
[2019-03-26 20:24:14,679] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:24:14,683] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3479868e-12 5.3948984e-18], sampled 0.5742687057949267
[2019-03-26 20:24:20,163] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.23727557]
[2019-03-26 20:24:20,163] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.20913224, 73.80349185, 1.0, 2.0, 0.269378786942592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 442929.639826911, 442929.6398269117, 162880.8530077676]
[2019-03-26 20:24:20,164] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:24:20,166] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3661286e-12 5.4927899e-18], sampled 0.9337585163445556
[2019-03-26 20:24:35,244] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8251.8732 2928193357.7728 1338.0000
[2019-03-26 20:24:35,701] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7874.2549 3164921908.5803 1778.0000
[2019-03-26 20:24:35,926] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8655.5460 2780105654.4285 933.0000
[2019-03-26 20:24:35,972] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8493.0860 2843317058.9716 1131.0000
[2019-03-26 20:24:36,059] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7995.0366 3008577742.1100 1766.0000
[2019-03-26 20:24:37,076] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 650000, evaluation results [650000.0, 7874.254934002473, 3164921908.580304, 1778.0, 8251.873184964594, 2928193357.7728205, 1338.0, 8655.546018810906, 2780105654.428513, 933.0, 7995.036567555068, 3008577742.1100116, 1766.0, 8493.086021879199, 2843317058.9715824, 1131.0]
[2019-03-26 20:24:40,651] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.3982701e-37 2.8246086e-12 2.1190420e-17], sum to 1.0000
[2019-03-26 20:24:40,662] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7446
[2019-03-26 20:24:40,667] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.6, 84.0, 1.0, 2.0, 0.22190195719751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 369653.2720077017, 369653.2720077011, 157767.6579558848], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 601200.0000, 
sim time next is 601800.0000, 
raw observation next is [18.51666666666667, 84.5, 1.0, 2.0, 0.2206124718573001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 367596.1322680204, 367596.132268021, 157627.6287426749], 
processed observation next is [1.0, 1.0, 0.07661927330173794, 0.845, 1.0, 1.0, 0.06097888175578324, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10211003674111678, 0.10211003674111695, 0.23526511752638044], 
reward next is 0.7647, 
noisyNet noise sample is [array([-0.0825384], dtype=float32), 1.7915527]. 
=============================================
[2019-03-26 20:24:43,027] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3192789e-35 9.9999988e-01 1.5995200e-30 1.7815238e-07 2.7270231e-10], sum to 1.0000
[2019-03-26 20:24:43,038] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1769
[2019-03-26 20:24:43,049] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 93.0, 1.0, 2.0, 0.2334899960315701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 388733.2498148087, 388733.2498148087, 158874.2273807432], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 699600.0000, 
sim time next is 700200.0000, 
raw observation next is [17.65, 93.0, 1.0, 2.0, 0.2227443206335127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 370888.6993214728, 370888.6993214734, 157886.9921243822], 
processed observation next is [1.0, 0.08695652173913043, 0.035545023696682464, 0.93, 1.0, 1.0, 0.06354737425724422, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10302463870040911, 0.10302463870040929, 0.23565222705131672], 
reward next is 0.7643, 
noisyNet noise sample is [array([-0.33154905], dtype=float32), -0.20931642]. 
=============================================
[2019-03-26 20:24:52,663] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.6804872e-14 3.6963463e-18], sum to 1.0000
[2019-03-26 20:24:52,678] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3134
[2019-03-26 20:24:52,684] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.6, 80.5, 1.0, 2.0, 0.2554862561026551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 419403.3804272165, 419403.3804272165, 161456.5559875444], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 765000.0000, 
sim time next is 765600.0000, 
raw observation next is [20.53333333333333, 81.0, 1.0, 2.0, 0.2552438100066881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 419011.686924542, 419011.6869245426, 161432.2397282651], 
processed observation next is [1.0, 0.8695652173913043, 0.17219589257503945, 0.81, 1.0, 1.0, 0.10270338555022662, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11639213525681723, 0.11639213525681738, 0.24094364138547028], 
reward next is 0.7591, 
noisyNet noise sample is [array([-1.7193232], dtype=float32), -1.1709101]. 
=============================================
[2019-03-26 20:25:05,489] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.0079212e-16 2.0117604e-20], sum to 1.0000
[2019-03-26 20:25:05,497] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3045
[2019-03-26 20:25:05,503] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.86666666666667, 93.33333333333334, 1.0, 2.0, 0.3315436398908417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 513817.9847701254, 513817.9847701254, 167813.384624132], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 963600.0000, 
sim time next is 964200.0000, 
raw observation next is [21.88333333333333, 93.16666666666666, 1.0, 2.0, 0.3316361779264139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 514014.6031773683, 514014.6031773683, 167830.4349445109], 
processed observation next is [1.0, 0.13043478260869565, 0.2361769352290678, 0.9316666666666665, 1.0, 1.0, 0.1947423830438722, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14278183421593563, 0.14278183421593563, 0.2504931864843446], 
reward next is 0.7495, 
noisyNet noise sample is [array([-0.37596422], dtype=float32), -0.7957356]. 
=============================================
[2019-03-26 20:25:07,332] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.5936141e-35 5.1432823e-15 1.4224690e-15], sum to 1.0000
[2019-03-26 20:25:07,346] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5062
[2019-03-26 20:25:07,351] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.93333333333333, 94.66666666666666, 1.0, 2.0, 0.5663689881175034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 871975.5004917851, 871975.5004917858, 204341.0745419479], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 992400.0000, 
sim time next is 993000.0000, 
raw observation next is [21.91666666666666, 94.83333333333333, 1.0, 2.0, 0.5968879034950557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 918821.9658997034, 918821.9658997034, 210431.7754291751], 
processed observation next is [1.0, 0.4782608695652174, 0.23775671406003138, 0.9483333333333333, 1.0, 1.0, 0.5143227752952478, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2552283238610287, 0.2552283238610287, 0.31407727675996283], 
reward next is 0.6859, 
noisyNet noise sample is [array([-0.09211665], dtype=float32), -1.3223093]. 
=============================================
[2019-03-26 20:25:07,363] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[63.348976]
 [63.75887 ]
 [63.29695 ]
 [62.45841 ]
 [61.821613]], R is [[63.09465408]
 [63.15872192]
 [63.24363708]
 [63.32418442]
 [63.3825264 ]].
[2019-03-26 20:25:12,210] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.5652426e-36 7.8030806e-17 8.1789686e-23], sum to 1.0000
[2019-03-26 20:25:12,222] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7448
[2019-03-26 20:25:12,228] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 70.5, 1.0, 2.0, 0.6693726472986706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1036894.003653821, 1036894.003653821, 226848.2525376893], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1085400.0000, 
sim time next is 1086000.0000, 
raw observation next is [25.26666666666667, 70.0, 1.0, 2.0, 0.6543213605870494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1011252.448447034, 1011252.448447034, 223177.816186254], 
processed observation next is [1.0, 0.5652173913043478, 0.3965244865718801, 0.7, 1.0, 1.0, 0.5835197115506618, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.28090345790195387, 0.28090345790195387, 0.3331012181884388], 
reward next is 0.6669, 
noisyNet noise sample is [array([1.6289994], dtype=float32), -0.4938239]. 
=============================================
[2019-03-26 20:25:12,244] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[63.80626 ]
 [64.73977 ]
 [65.99775 ]
 [66.02679 ]
 [66.172386]], R is [[63.65424347]
 [63.67911911]
 [63.72673035]
 [63.81335068]
 [63.90037537]].
[2019-03-26 20:25:18,545] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.3720649e-17 6.3557953e-19], sum to 1.0000
[2019-03-26 20:25:18,556] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9855
[2019-03-26 20:25:18,563] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 74.66666666666667, 1.0, 2.0, 0.3513624789805923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 541945.5373656523, 541945.5373656517, 169996.6903790539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1196400.0000, 
sim time next is 1197000.0000, 
raw observation next is [24.5, 75.5, 1.0, 2.0, 0.3516749710018386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 542032.8963588405, 542032.8963588398, 169992.5359783983], 
processed observation next is [1.0, 0.8695652173913043, 0.3601895734597157, 0.755, 1.0, 1.0, 0.21888550723113082, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15056469343301127, 0.15056469343301107, 0.25372020295283326], 
reward next is 0.7463, 
noisyNet noise sample is [array([-0.18430856], dtype=float32), -0.3994942]. 
=============================================
[2019-03-26 20:25:18,582] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[81.7078  ]
 [81.742096]
 [81.956795]
 [81.97099 ]
 [82.11649 ]], R is [[81.59750366]
 [81.52780914]
 [81.45865631]
 [81.39022064]
 [81.32271576]].
[2019-03-26 20:25:20,383] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.6533252e-20 5.2782216e-23], sum to 1.0000
[2019-03-26 20:25:20,391] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5411
[2019-03-26 20:25:20,397] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.56666666666667, 98.0, 1.0, 2.0, 0.3146155162227376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 497157.3719752533, 497157.3719752527, 166806.0286991008], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1399200.0000, 
sim time next is 1399800.0000, 
raw observation next is [20.58333333333334, 98.0, 1.0, 2.0, 0.3146256245799867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 496975.2427550306, 496975.2427550299, 166788.3153678298], 
processed observation next is [0.0, 0.17391304347826086, 0.17456556082148533, 0.98, 1.0, 1.0, 0.17424774045781533, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13804867854306405, 0.13804867854306385, 0.24893778413108927], 
reward next is 0.7511, 
noisyNet noise sample is [array([0.9489298], dtype=float32), -1.1902432]. 
=============================================
[2019-03-26 20:25:26,406] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.0077357e-37 6.0734764e-17 1.4524619e-16], sum to 1.0000
[2019-03-26 20:25:26,417] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6176
[2019-03-26 20:25:26,424] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.85, 93.5, 1.0, 2.0, 0.5543588314973338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 802578.0055774802, 802578.0055774802, 196096.477506292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1319400.0000, 
sim time next is 1320000.0000, 
raw observation next is [23.76666666666667, 93.66666666666667, 1.0, 2.0, 0.536796362988044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779058.4267126544, 779058.4267126544, 193226.5869690716], 
processed observation next is [1.0, 0.2608695652173913, 0.32543443917851517, 0.9366666666666668, 1.0, 1.0, 0.4419233289012578, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2164051185312929, 0.2164051185312929, 0.2883978909986143], 
reward next is 0.7116, 
noisyNet noise sample is [array([-0.01829829], dtype=float32), 0.014883037]. 
=============================================
[2019-03-26 20:25:26,440] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[70.07499 ]
 [70.342285]
 [70.89957 ]
 [71.53772 ]
 [71.6087  ]], R is [[70.15279388]
 [70.15858459]
 [70.16835022]
 [70.18634033]
 [70.22115326]].
[2019-03-26 20:25:27,029] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.3108748e-37 9.9772241e-14 2.3114631e-12], sum to 1.0000
[2019-03-26 20:25:27,037] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0811
[2019-03-26 20:25:27,041] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 88.0, 1.0, 2.0, 0.6708684931586075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1065116.051333728, 1065116.051333728, 229682.4849613019], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1346400.0000, 
sim time next is 1347000.0000, 
raw observation next is [21.46666666666667, 88.16666666666667, 1.0, 2.0, 0.5704487401589996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 906774.0291150539, 906774.0291150539, 207844.0228276239], 
processed observation next is [1.0, 0.6086956521739131, 0.21642969984202226, 0.8816666666666667, 1.0, 1.0, 0.4824683616373489, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.25188167475418166, 0.25188167475418166, 0.3102149594442148], 
reward next is 0.6898, 
noisyNet noise sample is [array([-0.73703367], dtype=float32), 1.850965]. 
=============================================
[2019-03-26 20:25:27,055] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[72.98736 ]
 [73.10482 ]
 [73.484726]
 [74.08048 ]
 [74.48203 ]], R is [[73.70250702]
 [73.62267303]
 [73.54047394]
 [73.46211243]
 [73.39910126]].
[2019-03-26 20:25:28,017] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.11940020e-15
 1.03253784e-13], sum to 1.0000
[2019-03-26 20:25:28,029] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4381
[2019-03-26 20:25:28,034] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.48333333333333, 93.33333333333333, 1.0, 2.0, 0.7187401081279726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1092218.434412109, 1092218.434412109, 236227.0199749477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1338600.0000, 
sim time next is 1339200.0000, 
raw observation next is [22.4, 93.0, 1.0, 2.0, 0.77006259614506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1174780.441420588, 1174780.441420588, 249615.5148186972], 
processed observation next is [1.0, 0.5217391304347826, 0.2606635071090047, 0.93, 1.0, 1.0, 0.7229669833073012, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.32632790039460774, 0.32632790039460774, 0.37256046987865254], 
reward next is 0.6274, 
noisyNet noise sample is [array([2.3741956], dtype=float32), -1.1180481]. 
=============================================
[2019-03-26 20:25:28,111] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.6665516e-36 2.3427066e-15 6.8470049e-18], sum to 1.0000
[2019-03-26 20:25:28,123] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9158
[2019-03-26 20:25:28,127] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 89.5, 1.0, 2.0, 0.3064054166652293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 483867.5143219733, 483867.5143219727, 165820.8009257269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1571400.0000, 
sim time next is 1572000.0000, 
raw observation next is [21.6, 89.33333333333333, 1.0, 2.0, 0.307159065139851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 485294.8178840481, 485294.8178840481, 165930.2536523599], 
processed observation next is [1.0, 0.17391304347826086, 0.22274881516587688, 0.8933333333333333, 1.0, 1.0, 0.16525188571066382, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13480411607890225, 0.13480411607890225, 0.24765709500352226], 
reward next is 0.7523, 
noisyNet noise sample is [array([-0.45469463], dtype=float32), -1.0881928]. 
=============================================
[2019-03-26 20:25:28,146] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[76.57951]
 [76.74686]
 [76.95445]
 [76.86581]
 [77.07326]], R is [[76.33399963]
 [76.32316589]
 [76.31248474]
 [76.30116272]
 [76.28843689]].
[2019-03-26 20:25:29,905] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.7807979e-33 2.4659745e-13 1.5564922e-18], sum to 1.0000
[2019-03-26 20:25:29,914] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3731
[2019-03-26 20:25:29,918] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.76666666666667, 95.66666666666667, 1.0, 2.0, 0.3150424282966958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 498548.6015814939, 498548.6015814944, 166923.9400284876], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1377600.0000, 
sim time next is 1378200.0000, 
raw observation next is [20.73333333333333, 95.83333333333333, 1.0, 2.0, 0.3149105760068865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 498500.6409171044, 498500.6409171037, 166923.4013324424], 
processed observation next is [1.0, 0.9565217391304348, 0.18167456556082143, 0.9583333333333333, 1.0, 1.0, 0.1745910554299837, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13847240025475122, 0.13847240025475102, 0.2491394049737946], 
reward next is 0.7509, 
noisyNet noise sample is [array([1.2852495], dtype=float32), -0.12408327]. 
=============================================
[2019-03-26 20:25:31,354] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.4363365e-37 1.3207342e-13 2.1448631e-17], sum to 1.0000
[2019-03-26 20:25:31,364] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0754
[2019-03-26 20:25:31,376] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666666, 95.0, 1.0, 2.0, 0.4116493389435469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 607956.8027249908, 607956.8027249908, 175098.0413635816], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1626000.0000, 
sim time next is 1626600.0000, 
raw observation next is [23.18333333333333, 95.0, 1.0, 2.0, 0.4111974519779803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 606916.7836883408, 606916.7836883408, 174989.8254714457], 
processed observation next is [1.0, 0.8260869565217391, 0.29778830963665076, 0.95, 1.0, 1.0, 0.2905993397325064, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16858799546898356, 0.16858799546898356, 0.2611788439872324], 
reward next is 0.7388, 
noisyNet noise sample is [array([-0.73139334], dtype=float32), -1.5509639]. 
=============================================
[2019-03-26 20:25:32,791] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 20:25:32,793] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:25:32,794] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:25:32,795] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:25:32,795] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:25:32,796] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:25:32,797] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:25:32,796] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:25:32,798] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:25:32,798] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:25:32,802] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:25:32,824] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run28
[2019-03-26 20:25:32,824] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run28
[2019-03-26 20:25:32,825] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run28
[2019-03-26 20:25:32,846] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run28
[2019-03-26 20:25:32,909] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run28
[2019-03-26 20:26:23,737] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.19307639]
[2019-03-26 20:26:23,739] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.46461314, 79.03385822, 1.0, 2.0, 0.4886208692544546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 688616.2576464604, 688616.2576464604, 182583.9782510498]
[2019-03-26 20:26:23,739] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:26:23,742] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.4067862e-17 3.5483448e-19], sampled 0.2616303938929265
[2019-03-26 20:26:24,069] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.19307639]
[2019-03-26 20:26:24,071] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.66666666666667, 80.66666666666667, 1.0, 2.0, 0.5959326189443598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 832775.7947019509, 832775.7947019509, 199982.5151668325]
[2019-03-26 20:26:24,072] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:26:24,076] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.7657787e-38 1.6917702e-16 1.5936647e-18], sampled 0.28191467937726855
[2019-03-26 20:26:29,382] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.19307639]
[2019-03-26 20:26:29,384] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [36.0, 49.0, 1.0, 2.0, 0.5847262870682925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 817109.6751662266, 817109.6751662266, 197934.6919893911]
[2019-03-26 20:26:29,386] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:26:29,389] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.2865171e-18 3.3238366e-20], sampled 0.9228729167627152
[2019-03-26 20:26:34,332] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.19307639]
[2019-03-26 20:26:34,333] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [36.95, 48.0, 1.0, 2.0, 0.8460581253263009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1182503.988971924, 1182503.988971924, 255535.3865754806]
[2019-03-26 20:26:34,336] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:26:34,340] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.4418742e-17 3.5799149e-19], sampled 0.4422431359527109
[2019-03-26 20:26:49,759] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.19307639]
[2019-03-26 20:26:49,761] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.79360109, 83.33741476, 1.0, 2.0, 0.6661203068678487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 930901.3566557951, 930901.3566557951, 213710.3524947216]
[2019-03-26 20:26:49,761] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:26:49,763] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.5429813e-17 1.9204053e-19], sampled 0.8549796907365167
[2019-03-26 20:27:02,444] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.19307639]
[2019-03-26 20:27:02,445] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.71666666666667, 74.5, 1.0, 2.0, 0.8412762729374065, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.994774252086307, 6.9112, 168.9123913162312, 2072842.725911815, 2013552.473467888, 418717.7312775371]
[2019-03-26 20:27:02,446] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:27:02,450] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 7.8004461e-36 2.8096021e-15 3.6732815e-17], sampled 0.19401028880836602
[2019-03-26 20:27:02,452] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2072842.725911815 W.
[2019-03-26 20:27:15,339] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.19307639]
[2019-03-26 20:27:15,340] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.55, 48.0, 1.0, 2.0, 0.7039841398821349, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.941701255622585, 6.9112, 168.9127511773033, 1916256.358148526, 1894617.743941919, 391729.0506990736]
[2019-03-26 20:27:15,344] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:27:15,346] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.3727966e-35 3.6466602e-15 4.9149064e-17], sampled 0.4649359744360956
[2019-03-26 20:27:15,350] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1916256.358148526 W.
[2019-03-26 20:27:26,286] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8248.8402 2928097619.8215 1338.0000
[2019-03-26 20:27:27,275] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8492.6531 2843189204.4954 1131.0000
[2019-03-26 20:27:27,637] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7994.1196 3008333249.7797 1766.0000
[2019-03-26 20:27:27,709] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8657.1478 2779902905.6182 933.0000
[2019-03-26 20:27:27,748] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7876.6154 3164660858.3405 1778.0000
[2019-03-26 20:27:28,764] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 675000, evaluation results [675000.0, 7876.615402862868, 3164660858.3404922, 1778.0, 8248.84019698634, 2928097619.821522, 1338.0, 8657.147806274199, 2779902905.6182404, 933.0, 7994.1196179763165, 3008333249.779738, 1766.0, 8492.65313717663, 2843189204.495385, 1131.0]
[2019-03-26 20:27:32,761] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 5.777731e-19 4.088808e-21], sum to 1.0000
[2019-03-26 20:27:32,769] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5798
[2019-03-26 20:27:32,776] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.23333333333333, 51.00000000000001, 1.0, 2.0, 0.3512963936820009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 537565.9046053564, 537565.9046053557, 169504.0934773705], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1513200.0000, 
sim time next is 1513800.0000, 
raw observation next is [29.3, 51.0, 1.0, 2.0, 0.3526428651476576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 538711.9606284414, 538711.9606284414, 169568.5944270689], 
processed observation next is [0.0, 0.5217391304347826, 0.5876777251184835, 0.51, 1.0, 1.0, 0.22005164475621394, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14964221128567817, 0.14964221128567817, 0.25308745436875957], 
reward next is 0.7469, 
noisyNet noise sample is [array([-1.1933242], dtype=float32), -0.6300395]. 
=============================================
[2019-03-26 20:27:33,890] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5356672e-18 1.3416430e-24], sum to 1.0000
[2019-03-26 20:27:33,900] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0553
[2019-03-26 20:27:33,905] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.36666666666667, 51.0, 1.0, 2.0, 0.3545495643181173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 540696.9328101261, 540696.9328101267, 169702.3073243424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1514400.0000, 
sim time next is 1515000.0000, 
raw observation next is [29.43333333333333, 51.0, 1.0, 2.0, 0.356860421157582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 543278.6023775876, 543278.6023775876, 169886.0060121602], 
processed observation next is [0.0, 0.5217391304347826, 0.5939968404423379, 0.51, 1.0, 1.0, 0.2251330375392554, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15091072288266322, 0.15091072288266322, 0.25356120300322416], 
reward next is 0.7464, 
noisyNet noise sample is [array([0.9627889], dtype=float32), -0.018100936]. 
=============================================
[2019-03-26 20:27:33,915] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[79.75477]
 [79.73439]
 [79.7121 ]
 [79.70884]
 [79.7331 ]], R is [[79.70986938]
 [79.65948486]
 [79.60980225]
 [79.56071472]
 [79.51218414]].
[2019-03-26 20:27:38,776] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.0654340e-35 7.7614338e-16 1.0216919e-18], sum to 1.0000
[2019-03-26 20:27:38,787] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5589
[2019-03-26 20:27:38,795] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.91666666666667, 85.00000000000001, 1.0, 2.0, 0.7486606651701452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1126843.687314722, 1126843.687314722, 242303.078706332], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1599000.0000, 
sim time next is 1599600.0000, 
raw observation next is [23.93333333333333, 85.0, 1.0, 2.0, 0.6382923479185131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 960205.2470163631, 960205.2470163625, 216681.1652413676], 
processed observation next is [1.0, 0.5217391304347826, 0.3333333333333332, 0.85, 1.0, 1.0, 0.564207648094594, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2667236797267675, 0.26672367972676736, 0.32340472424084715], 
reward next is 0.6766, 
noisyNet noise sample is [array([-0.08391315], dtype=float32), -0.4760683]. 
=============================================
[2019-03-26 20:27:42,677] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.3200160e-18 1.0837586e-18], sum to 1.0000
[2019-03-26 20:27:42,687] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5820
[2019-03-26 20:27:42,692] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.31666666666667, 99.0, 1.0, 2.0, 0.4465584681719386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 643133.0587700157, 643133.0587700164, 178103.1880650497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1656600.0000, 
sim time next is 1657200.0000, 
raw observation next is [23.33333333333334, 99.00000000000001, 1.0, 2.0, 0.4301777949515875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 619112.6441190926, 619112.6441190919, 175705.510988684], 
processed observation next is [1.0, 0.17391304347826086, 0.3048973143759877, 0.9900000000000001, 1.0, 1.0, 0.3134672228332379, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17197573447752573, 0.17197573447752554, 0.26224703132639404], 
reward next is 0.7378, 
noisyNet noise sample is [array([-0.955089], dtype=float32), 2.215879]. 
=============================================
[2019-03-26 20:27:48,452] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2319316e-31 1.0000000e+00 1.2398315e-26 4.3857631e-10 6.3783453e-12], sum to 1.0000
[2019-03-26 20:27:48,459] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8742
[2019-03-26 20:27:48,467] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1756405.504503039 W.
[2019-03-26 20:27:48,474] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.05, 84.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.337521059127193, 6.9112, 168.9110588598789, 1756405.504503039, 1453962.070154995, 311348.8603486515], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1866600.0000, 
sim time next is 1867200.0000, 
raw observation next is [27.03333333333333, 84.33333333333334, 1.0, 2.0, 0.4067278992483989, 1.0, 1.0, 0.4067278992483989, 1.0, 1.0, 0.6955508872474537, 6.911200000000001, 6.9112, 170.5573041426782, 1705812.31718062, 1705812.31718062, 355091.8060222259], 
processed observation next is [1.0, 0.6086956521739131, 0.48025276461295413, 0.8433333333333334, 1.0, 1.0, 0.28521433644385413, 1.0, 0.5, 0.28521433644385413, 1.0, 0.5, 0.6287205942042118, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.47383675477239445, 0.47383675477239445, 0.5299877701824267], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.33198708], dtype=float32), -1.0064231]. 
=============================================
[2019-03-26 20:27:58,172] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 9.9999976e-01 2.5787246e-32 2.0325758e-07 7.5268421e-20], sum to 1.0000
[2019-03-26 20:27:58,178] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2603
[2019-03-26 20:27:58,182] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 94.0, 1.0, 2.0, 0.4170525105465058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 612808.8123020224, 612808.8123020229, 175467.4892080617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1918800.0000, 
sim time next is 1919400.0000, 
raw observation next is [23.51666666666667, 93.33333333333334, 1.0, 2.0, 0.4608808574322754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 677225.1522928596, 677225.1522928596, 181884.2629197574], 
processed observation next is [1.0, 0.21739130434782608, 0.31358609794628767, 0.9333333333333335, 1.0, 1.0, 0.35045886437623547, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18811809785912767, 0.18811809785912767, 0.27146904913396624], 
reward next is 0.7285, 
noisyNet noise sample is [array([-1.0857239], dtype=float32), -2.9191298]. 
=============================================
[2019-03-26 20:27:58,888] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3400709e-34 1.0000000e+00 1.7740094e-30 5.6253182e-08 1.1910908e-15], sum to 1.0000
[2019-03-26 20:27:58,896] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9999
[2019-03-26 20:27:58,906] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 82.0, 1.0, 2.0, 0.9743470879759385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1390709.438635488, 1390709.438635488, 295639.1465482148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1933200.0000, 
sim time next is 1933800.0000, 
raw observation next is [25.85, 81.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.009109463974895, 6.9112, 168.9124048539953, 1553421.696664891, 1483961.579989437, 316169.3551255277], 
processed observation next is [1.0, 0.391304347826087, 0.4241706161137442, 0.8166666666666668, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.009790946397489541, 0.0, 0.829437236266654, 0.4315060268513586, 0.41221154999706583, 0.4718945598888473], 
reward next is 0.0386, 
noisyNet noise sample is [array([-0.89237505], dtype=float32), -1.0211716]. 
=============================================
[2019-03-26 20:28:00,684] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8078505e-31 9.9998748e-01 1.0307446e-27 1.2481765e-05 1.6030569e-13], sum to 1.0000
[2019-03-26 20:28:00,692] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7499
[2019-03-26 20:28:00,703] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2117456.269744956 W.
[2019-03-26 20:28:00,707] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.76666666666667, 77.33333333333333, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.842718100487202, 6.9112, 168.9078628704263, 2117456.269744956, 1456625.197115624, 311736.0671148876], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1954200.0000, 
sim time next is 1954800.0000, 
raw observation next is [26.6, 78.0, 1.0, 2.0, 0.6253220354516484, 1.0, 1.0, 0.6253220354516484, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1748430.546880371, 1748430.546880371, 343779.4307152414], 
processed observation next is [1.0, 0.6521739130434783, 0.4597156398104266, 0.78, 1.0, 1.0, 0.5485807656043957, 1.0, 0.5, 0.5485807656043957, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.48567515191121413, 0.48567515191121413, 0.5131036279331961], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.00421356], dtype=float32), -1.4965066]. 
=============================================
[2019-03-26 20:28:04,556] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3651279e-38 9.9978977e-01 7.8890585e-34 2.1028251e-04 3.0837011e-19], sum to 1.0000
[2019-03-26 20:28:04,563] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4141
[2019-03-26 20:28:04,570] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 88.5, 1.0, 2.0, 0.4819775380918156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 673480.742453085, 673480.7424530843, 180820.3905261952], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2057400.0000, 
sim time next is 2058000.0000, 
raw observation next is [25.53333333333333, 88.66666666666666, 1.0, 2.0, 0.480554741605886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 671492.0006293404, 671492.0006293404, 180605.3452978999], 
processed observation next is [0.0, 0.8260869565217391, 0.4091627172195892, 0.8866666666666666, 1.0, 1.0, 0.37416233928420006, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18652555573037233, 0.18652555573037233, 0.26956021686253717], 
reward next is 0.7304, 
noisyNet noise sample is [array([0.9727279], dtype=float32), -0.87246364]. 
=============================================
[2019-03-26 20:28:04,582] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[79.32559 ]
 [79.281784]
 [79.26029 ]
 [79.26799 ]
 [79.219955]], R is [[79.31558228]
 [79.25254822]
 [79.18982697]
 [79.12741852]
 [79.06535339]].
[2019-03-26 20:28:08,350] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.9304824e-33 6.8021889e-14 4.2746386e-19], sum to 1.0000
[2019-03-26 20:28:08,356] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1483
[2019-03-26 20:28:08,362] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.63333333333333, 91.5, 1.0, 2.0, 0.4922107507916471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 687784.5268342736, 687784.5268342736, 182385.0354891311], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2099400.0000, 
sim time next is 2100000.0000, 
raw observation next is [25.76666666666667, 91.0, 1.0, 2.0, 0.4946767327523364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 691231.4569425497, 691231.4569425491, 182766.6217646147], 
processed observation next is [0.0, 0.30434782608695654, 0.42022116903633505, 0.91, 1.0, 1.0, 0.39117678644859816, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19200873803959714, 0.19200873803959698, 0.2727860026337533], 
reward next is 0.7272, 
noisyNet noise sample is [array([0.298508], dtype=float32), 0.28284398]. 
=============================================
[2019-03-26 20:28:08,387] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[71.19015 ]
 [71.203026]
 [71.16346 ]
 [71.13967 ]
 [71.10569 ]], R is [[71.21993256]
 [71.23551941]
 [71.25151062]
 [71.26792145]
 [71.28476715]].
[2019-03-26 20:28:11,095] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.6333780e-08 2.8690233e-20], sum to 1.0000
[2019-03-26 20:28:11,105] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1059
[2019-03-26 20:28:11,110] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.01666666666667, 89.33333333333334, 1.0, 2.0, 0.5373715115108973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 750911.6547711656, 750911.654771165, 189658.679064698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2149800.0000, 
sim time next is 2150400.0000, 
raw observation next is [26.93333333333334, 89.66666666666667, 1.0, 2.0, 0.5391069384648353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 753337.5638576915, 753337.5638576915, 189950.0373977612], 
processed observation next is [0.0, 0.9130434782608695, 0.4755134281200636, 0.8966666666666667, 1.0, 1.0, 0.4447071547769099, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2092604344049143, 0.2092604344049143, 0.2835075185041212], 
reward next is 0.7165, 
noisyNet noise sample is [array([-2.7070637], dtype=float32), -1.1604234]. 
=============================================
[2019-03-26 20:28:16,894] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.3275427e-32 9.6211153e-01 1.7251511e-28 3.7888426e-02 5.1760391e-11], sum to 1.0000
[2019-03-26 20:28:16,905] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3715
[2019-03-26 20:28:16,911] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.4, 82.0, 1.0, 2.0, 0.5457633867199854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 762642.4945186689, 762642.4945186696, 191077.0945698183], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2235600.0000, 
sim time next is 2236200.0000, 
raw observation next is [28.3, 82.33333333333334, 1.0, 2.0, 0.5445081688488133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 760887.8415388272, 760887.8415388279, 190863.5972684061], 
processed observation next is [1.0, 0.9130434782608695, 0.5402843601895735, 0.8233333333333335, 1.0, 1.0, 0.4512146612636304, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21135773376078532, 0.2113577337607855, 0.28487104069911356], 
reward next is 0.7151, 
noisyNet noise sample is [array([-1.5405047], dtype=float32), -0.38767755]. 
=============================================
[2019-03-26 20:28:21,784] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9631806e-36 1.1883284e-01 3.7716065e-32 8.8116711e-01 2.6828886e-10], sum to 1.0000
[2019-03-26 20:28:21,796] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9951
[2019-03-26 20:28:21,801] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 93.0, 1.0, 2.0, 0.2772721625542368, 1.0, 2.0, 0.2772721625542368, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 774914.6116525705, 774914.6116525705, 245640.6268341332], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2491200.0000, 
sim time next is 2491800.0000, 
raw observation next is [26.98333333333333, 93.0, 1.0, 2.0, 0.2777568531921441, 1.0, 2.0, 0.2777568531921441, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 776269.705418265, 776269.705418265, 245727.7308313216], 
processed observation next is [1.0, 0.8695652173913043, 0.4778830963665086, 0.93, 1.0, 1.0, 0.12982753396643867, 1.0, 1.0, 0.12982753396643867, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.21563047372729582, 0.21563047372729582, 0.36675780721092777], 
reward next is 0.6332, 
noisyNet noise sample is [array([0.05686946], dtype=float32), 0.116090916]. 
=============================================
[2019-03-26 20:28:24,518] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 20:28:24,521] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:28:24,522] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:28:24,523] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:28:24,524] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:28:24,525] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:28:24,526] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:28:24,528] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:28:24,528] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:28:24,527] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:28:24,531] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:28:24,544] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run29
[2019-03-26 20:28:24,564] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run29
[2019-03-26 20:28:24,583] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run29
[2019-03-26 20:28:24,584] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run29
[2019-03-26 20:28:24,602] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run29
[2019-03-26 20:28:34,645] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17746852]
[2019-03-26 20:28:34,646] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.395441125, 70.03964468000001, 1.0, 2.0, 0.2928231494241302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 473474.1948005774, 473474.1948005774, 165192.3063664452]
[2019-03-26 20:28:34,647] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:28:34,651] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.1369941e-37 1.0000000e+00 2.4985555e-33 1.0861044e-12 7.0062650e-21], sampled 0.28683014326888323
[2019-03-26 20:28:44,537] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17746852]
[2019-03-26 20:28:44,538] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.975459575, 94.93876928, 1.0, 2.0, 0.4185590118050752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 655625.6958036791, 655625.6958036784, 180226.4825858689]
[2019-03-26 20:28:44,541] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:28:44,543] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.69703369e-36 1.00000000e+00 1.14531544e-32 2.15041093e-12
 1.95437042e-20], sampled 0.8672835425413176
[2019-03-26 20:28:54,194] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17746852]
[2019-03-26 20:28:54,195] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.53333333333333, 81.50000000000001, 1.0, 2.0, 0.490343729179658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 685174.8262104837, 685174.826210483, 182096.2418256078]
[2019-03-26 20:28:54,197] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:28:54,200] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1482742e-37 1.0000000e+00 1.0093690e-33 7.2322969e-13 3.8042594e-21], sampled 0.9284353080686061
[2019-03-26 20:29:09,524] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17746852]
[2019-03-26 20:29:09,527] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.751480225, 89.98422936166666, 1.0, 2.0, 0.3754466032318077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 574799.6277643741, 574799.6277643747, 172678.2063729673]
[2019-03-26 20:29:09,527] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:29:09,529] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.8418938e-37 1.0000000e+00 1.5457174e-33 8.7560384e-13 5.0695388e-21], sampled 0.05989319802607207
[2019-03-26 20:29:24,336] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17746852]
[2019-03-26 20:29:24,337] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [33.54994173, 62.56750566, 1.0, 2.0, 0.8154608203620296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1139716.322001414, 1139716.322001414, 247746.4168197952]
[2019-03-26 20:29:24,338] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:29:24,343] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.0586379e-34 1.0000000e+00 2.6362375e-30 2.4671671e-11 7.6290056e-19], sampled 0.0425416569793341
[2019-03-26 20:29:31,519] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17746852]
[2019-03-26 20:29:31,520] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.16666666666666, 74.16666666666667, 1.0, 2.0, 0.9127263192643151, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.001447476360211, 6.9112, 168.9123469045359, 2172849.978089194, 2108825.543345491, 437777.9380527213]
[2019-03-26 20:29:31,520] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:29:31,524] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.7856092e-24 9.9999952e-01 2.6184085e-21 4.2780312e-07 1.3328154e-12], sampled 0.35949051833899803
[2019-03-26 20:29:31,526] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2172849.978089194 W.
[2019-03-26 20:29:32,773] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17746852]
[2019-03-26 20:29:32,774] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.15, 80.83333333333334, 1.0, 2.0, 0.6520209366583688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 911189.0717845376, 911189.0717845376, 210837.7767278042]
[2019-03-26 20:29:32,775] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:29:32,778] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.6200122e-37 1.0000000e+00 4.2273547e-33 1.3750821e-12 9.9852607e-21], sampled 0.0006203614826291171
[2019-03-26 20:29:47,675] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17746852]
[2019-03-26 20:29:47,675] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.22032389, 79.89353974, 1.0, 2.0, 0.3883143071902441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 589051.0496123554, 589051.0496123554, 173806.4579704464]
[2019-03-26 20:29:47,678] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:29:47,680] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 9.7699698e-35 2.5368824e-13 7.8880567e-22], sampled 0.4728776748774772
[2019-03-26 20:30:02,978] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17746852]
[2019-03-26 20:30:02,979] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.48333333333333, 35.83333333333334, 1.0, 2.0, 0.2694974462198418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 438744.8061118831, 438744.8061118825, 162815.8778717775]
[2019-03-26 20:30:02,981] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:30:02,982] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 3.1188844e-35 1.5199558e-13 3.6547386e-22], sampled 0.567438714535393
[2019-03-26 20:30:13,765] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17746852]
[2019-03-26 20:30:13,766] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.13333333333333, 76.66666666666666, 1.0, 2.0, 0.4838039509713575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 676033.6525013294, 676033.6525013294, 181096.7129716808]
[2019-03-26 20:30:13,766] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:30:13,767] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.4097849e-37 1.0000000e+00 3.3969043e-33 1.2465698e-12 8.6171629e-21], sampled 0.27756222167978895
[2019-03-26 20:30:18,642] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7875.0081 3164859047.8827 1778.0000
[2019-03-26 20:30:19,016] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8492.9776 2843378969.8112 1131.0000
[2019-03-26 20:30:19,058] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.4170 2928250869.2091 1338.0000
[2019-03-26 20:30:19,253] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8656.8290 2780079899.7209 933.0000
[2019-03-26 20:30:19,262] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.4188 3008499702.8754 1766.0000
[2019-03-26 20:30:20,279] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 700000, evaluation results [700000.0, 7875.008135704462, 3164859047.882678, 1778.0, 8252.416984994034, 2928250869.20911, 1338.0, 8656.829044373291, 2780079899.7208705, 933.0, 7996.418845919515, 3008499702.8753877, 1766.0, 8492.97764518503, 2843378969.811234, 1131.0]
[2019-03-26 20:30:22,517] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.2166161e-13 1.0620837e-25], sum to 1.0000
[2019-03-26 20:30:22,531] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8491
[2019-03-26 20:30:22,537] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.71666666666667, 78.33333333333333, 1.0, 2.0, 0.5741466427085284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 802319.8582302403, 802319.8582302403, 196028.3315380805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2412600.0000, 
sim time next is 2413200.0000, 
raw observation next is [29.63333333333334, 78.66666666666667, 1.0, 2.0, 0.5723458124047743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 799802.4074891193, 799802.4074891187, 195707.1499520162], 
processed observation next is [1.0, 0.9565217391304348, 0.6034755134281204, 0.7866666666666667, 1.0, 1.0, 0.4847539908491257, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22216733541364425, 0.22216733541364408, 0.2921002238089794], 
reward next is 0.7079, 
noisyNet noise sample is [array([-0.59118456], dtype=float32), 0.6435408]. 
=============================================
[2019-03-26 20:30:26,852] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6271618e-34 1.0000000e+00 2.5334633e-32 2.9682012e-10 1.9083766e-20], sum to 1.0000
[2019-03-26 20:30:26,865] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7449
[2019-03-26 20:30:26,877] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.25, 96.5, 1.0, 2.0, 0.6676652381900295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 933061.3424901541, 933061.3424901547, 214021.5692119592], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2525400.0000, 
sim time next is 2526000.0000, 
raw observation next is [26.26666666666667, 96.33333333333334, 1.0, 2.0, 0.7307054591673569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1021202.330666356, 1021202.330666356, 227613.4451615379], 
processed observation next is [1.0, 0.21739130434782608, 0.44391785150079005, 0.9633333333333334, 1.0, 1.0, 0.6755487459847673, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.28366731407398776, 0.28366731407398776, 0.3397215599425939], 
reward next is 0.6603, 
noisyNet noise sample is [array([0.90567285], dtype=float32), -0.15667702]. 
=============================================
[2019-03-26 20:30:26,892] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[57.838196]
 [57.84492 ]
 [57.249416]
 [58.355106]
 [58.4242  ]], R is [[57.35048676]
 [57.45754623]
 [57.57165527]
 [57.64567566]
 [57.75822449]].
[2019-03-26 20:30:32,580] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.15480506e-38 9.99988556e-01 5.35304982e-36 1.14570485e-05
 3.38026799e-18], sum to 1.0000
[2019-03-26 20:30:32,585] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8505
[2019-03-26 20:30:32,591] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 89.33333333333334, 1.0, 2.0, 0.5197959559566341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 726343.5460024896, 726343.546002489, 186755.3305043713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2585400.0000, 
sim time next is 2586000.0000, 
raw observation next is [26.2, 89.66666666666667, 1.0, 2.0, 0.5173097320172007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722868.206990218, 722868.206990218, 186352.1543742471], 
processed observation next is [1.0, 0.9565217391304348, 0.44075829383886256, 0.8966666666666667, 1.0, 1.0, 0.4184454602616875, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20079672416394945, 0.20079672416394945, 0.27813754384215983], 
reward next is 0.7219, 
noisyNet noise sample is [array([0.09716033], dtype=float32), 0.21020551]. 
=============================================
[2019-03-26 20:30:32,608] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[77.07055 ]
 [77.1222  ]
 [77.138824]
 [77.285576]
 [77.06857 ]], R is [[77.04355621]
 [76.99438477]
 [76.94525909]
 [76.89638519]
 [76.84757996]].
[2019-03-26 20:30:35,396] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0446095e-09 1.1176408e-25], sum to 1.0000
[2019-03-26 20:30:35,406] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0830
[2019-03-26 20:30:35,417] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 82.33333333333334, 1.0, 2.0, 0.4763915593832231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 665672.8520295065, 665672.8520295065, 179979.603333494], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2632800.0000, 
sim time next is 2633400.0000, 
raw observation next is [26.5, 81.5, 1.0, 2.0, 0.4773453548638306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 667006.0307422256, 667006.0307422249, 180122.5480859272], 
processed observation next is [0.0, 0.4782608695652174, 0.4549763033175356, 0.815, 1.0, 1.0, 0.3702956082696755, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18527945298395154, 0.18527945298395135, 0.2688396240088466], 
reward next is 0.7312, 
noisyNet noise sample is [array([-0.59128314], dtype=float32), 1.868034]. 
=============================================
[2019-03-26 20:30:35,759] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.4565417e-38 9.9945241e-01 1.3120956e-33 5.4755574e-04 7.7216337e-17], sum to 1.0000
[2019-03-26 20:30:35,768] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6228
[2019-03-26 20:30:35,776] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.357656080822618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 548574.3854320905, 548574.3854320912, 170458.4324271643], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2850000.0000, 
sim time next is 2850600.0000, 
raw observation next is [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.354584679752377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 544869.9315685949, 544869.9315685949, 170179.3055353848], 
processed observation next is [1.0, 1.0, 0.24960505529225935, 0.9316666666666668, 1.0, 1.0, 0.2223911804245506, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15135275876905413, 0.15135275876905413, 0.253998963485649], 
reward next is 0.7460, 
noisyNet noise sample is [array([0.6255667], dtype=float32), -0.0877799]. 
=============================================
[2019-03-26 20:30:43,313] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.1386233e-10 1.2234079e-24], sum to 1.0000
[2019-03-26 20:30:43,320] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1300
[2019-03-26 20:30:43,325] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 96.0, 1.0, 2.0, 0.361777469942939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 552609.0492098521, 552609.0492098528, 170729.5282432186], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2760000.0000, 
sim time next is 2760600.0000, 
raw observation next is [22.0, 95.0, 1.0, 2.0, 0.3568873499027899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 547143.1780567582, 547143.1780567582, 170330.9879352086], 
processed observation next is [0.0, 0.9565217391304348, 0.2417061611374408, 0.95, 1.0, 1.0, 0.22516548181059026, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1519842161268773, 0.1519842161268773, 0.25422535512717703], 
reward next is 0.7458, 
noisyNet noise sample is [array([-1.4663645], dtype=float32), -1.4882722]. 
=============================================
[2019-03-26 20:30:44,654] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.8850454e-36 1.1656746e-10 3.7884394e-24], sum to 1.0000
[2019-03-26 20:30:44,664] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3743
[2019-03-26 20:30:44,669] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3476887940397863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 535605.8759647226, 535605.8759647219, 169456.450300268], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2766600.0000, 
sim time next is 2767200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3479686845064236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 536037.1310052006, 536037.1310052006, 169491.6814487811], 
processed observation next is [1.0, 0.0, 0.2417061611374408, 0.94, 1.0, 1.0, 0.21442010181496818, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14889920305700016, 0.14889920305700016, 0.2529726588787778], 
reward next is 0.7470, 
noisyNet noise sample is [array([-0.46321926], dtype=float32), 0.5519392]. 
=============================================
[2019-03-26 20:30:46,930] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.1510606e-38 1.0000000e+00 3.1573659e-38 5.6415149e-14 5.2900821e-20], sum to 1.0000
[2019-03-26 20:30:46,940] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1095
[2019-03-26 20:30:46,945] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.4083411635024524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 601657.3465114563, 601657.3465114563, 174467.6989200493], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2830200.0000, 
sim time next is 2830800.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.4102168239075166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 604419.0189070036, 604419.018907003, 174725.3111859522], 
processed observation next is [1.0, 0.782608695652174, 0.3364928909952607, 0.89, 1.0, 1.0, 0.28941786012953813, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1678941719186121, 0.16789417191861195, 0.2607840465461973], 
reward next is 0.7392, 
noisyNet noise sample is [array([-0.73988616], dtype=float32), -0.2345333]. 
=============================================
[2019-03-26 20:30:51,611] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4178212e-37 1.0000000e+00 2.7479993e-35 8.0575456e-11 2.6489209e-21], sum to 1.0000
[2019-03-26 20:30:51,617] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4028
[2019-03-26 20:30:51,624] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5967660794159431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 919100.3964346413, 919100.3964346407, 210456.2377780009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2883000.0000, 
sim time next is 2883600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5847745970982471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 900618.5821089275, 900618.5821089275, 208019.128533037], 
processed observation next is [1.0, 0.391304347826087, 0.2417061611374408, 0.94, 1.0, 1.0, 0.4997284302388519, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.250171828363591, 0.250171828363591, 0.3104763112433388], 
reward next is 0.6895, 
noisyNet noise sample is [array([1.1606317], dtype=float32), -0.94011253]. 
=============================================
[2019-03-26 20:30:55,481] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 9.8434325e-37 3.1198402e-10 7.3571706e-20], sum to 1.0000
[2019-03-26 20:30:55,490] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9653
[2019-03-26 20:30:55,496] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3097695162867541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 493276.0703199785, 493276.0703199792, 166583.9649269864], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3003000.0000, 
sim time next is 3003600.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3110172995467023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 495273.0358376002, 495273.0358375995, 166730.9243207221], 
processed observation next is [1.0, 0.782608695652174, 0.1469194312796209, 1.0, 1.0, 1.0, 0.16990036089964133, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13757584328822228, 0.1375758432882221, 0.248852125851824], 
reward next is 0.7511, 
noisyNet noise sample is [array([-0.654622], dtype=float32), -1.3526754]. 
=============================================
[2019-03-26 20:31:06,024] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.4321573e-13 3.7128956e-25], sum to 1.0000
[2019-03-26 20:31:06,031] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0029
[2019-03-26 20:31:06,037] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5231463325092446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 731026.848608408, 731026.848608408, 187301.7586755215], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3358800.0000, 
sim time next is 3359400.0000, 
raw observation next is [27.83333333333334, 80.66666666666667, 1.0, 2.0, 0.5234511477541129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731452.9336891326, 731452.9336891333, 187351.8494333081], 
processed observation next is [0.0, 0.9130434782608695, 0.5181674565560824, 0.8066666666666668, 1.0, 1.0, 0.42584475633025654, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20318137046920348, 0.20318137046920368, 0.2796296260198628], 
reward next is 0.7204, 
noisyNet noise sample is [array([-0.1726385], dtype=float32), -1.2292923]. 
=============================================
[2019-03-26 20:31:08,779] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.0146527e-16 4.9073923e-25], sum to 1.0000
[2019-03-26 20:31:08,790] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4209
[2019-03-26 20:31:08,798] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.4862664657376061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 679475.6981089027, 679475.6981089032, 181472.2854978997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3198600.0000, 
sim time next is 3199200.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.4864275370605765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 679700.8402295926, 679700.840229592, 181496.8613062119], 
processed observation next is [0.0, 0.0, 0.38388625592417064, 0.94, 1.0, 1.0, 0.3812379964585259, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18880578895266462, 0.18880578895266445, 0.2708908377704655], 
reward next is 0.7291, 
noisyNet noise sample is [array([1.0886527], dtype=float32), 0.9028508]. 
=============================================
[2019-03-26 20:31:11,530] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.9354549e-09 7.3771555e-19], sum to 1.0000
[2019-03-26 20:31:11,542] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4076
[2019-03-26 20:31:11,547] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 76.5, 1.0, 2.0, 0.5067806721666409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 708150.4100429899, 708150.4100429906, 184666.289243801], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3231000.0000, 
sim time next is 3231600.0000, 
raw observation next is [28.66666666666666, 77.33333333333333, 1.0, 2.0, 0.5156798263094226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 720589.8685582536, 720589.8685582536, 186090.4566880261], 
processed observation next is [0.0, 0.391304347826087, 0.5576619273301735, 0.7733333333333333, 1.0, 1.0, 0.41648171844508736, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20016385237729267, 0.20016385237729267, 0.277746950280636], 
reward next is 0.7223, 
noisyNet noise sample is [array([-1.0713356], dtype=float32), -0.56750596]. 
=============================================
[2019-03-26 20:31:15,207] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.7130199e-37 7.7113816e-16 2.0489071e-18], sum to 1.0000
[2019-03-26 20:31:15,218] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6384
[2019-03-26 20:31:15,222] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 83.66666666666667, 1.0, 2.0, 0.4643756041318868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 658046.0924876723, 658046.092487673, 179383.2837849105], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3295200.0000, 
sim time next is 3295800.0000, 
raw observation next is [25.5, 83.5, 1.0, 2.0, 0.4553574347421961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 650414.1350752919, 650414.1350752924, 178714.4579361897], 
processed observation next is [0.0, 0.13043478260869565, 0.40758293838862564, 0.835, 1.0, 1.0, 0.3438041382436098, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18067059307646996, 0.18067059307647013, 0.2667379969196861], 
reward next is 0.7333, 
noisyNet noise sample is [array([-1.4614412], dtype=float32), 1.3849807]. 
=============================================
[2019-03-26 20:31:15,995] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 20:31:15,997] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:31:15,998] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:31:15,998] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:31:15,999] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:31:16,001] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:31:16,002] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:31:16,003] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:31:16,000] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:31:16,005] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:31:16,007] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:31:16,025] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run30
[2019-03-26 20:31:16,045] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run30
[2019-03-26 20:31:16,069] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run30
[2019-03-26 20:31:16,070] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run30
[2019-03-26 20:31:16,107] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run30
[2019-03-26 20:31:49,852] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.16302074]
[2019-03-26 20:31:49,853] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.9, 70.0, 1.0, 2.0, 0.5196521528473552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 763741.928069072, 763741.9280690713, 191448.2179910581]
[2019-03-26 20:31:49,855] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:31:49,859] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.04396813e-38 1.00000000e+00 1.16210344e-35 3.41521538e-12
 1.26732124e-20], sampled 0.03470019900645516
[2019-03-26 20:31:56,251] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.16302074]
[2019-03-26 20:31:56,252] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.54335099333334, 92.84954787499998, 1.0, 2.0, 0.3016661707617463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 484231.0911991388, 484231.0911991394, 165961.2801494255]
[2019-03-26 20:31:56,256] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:31:56,257] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.58233880e-38 1.00000000e+00 9.12451661e-36 3.05500959e-12
 1.07824415e-20], sampled 0.852669745839086
[2019-03-26 20:32:15,537] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.16302074]
[2019-03-26 20:32:15,539] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.937401545, 85.27178549499999, 1.0, 2.0, 0.6581572844371008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 919768.2352285556, 919768.2352285563, 212082.0334995577]
[2019-03-26 20:32:15,540] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:32:15,543] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.7976563e-36 1.4450896e-12 3.6426869e-21], sampled 0.0741453504166093
[2019-03-26 20:32:25,141] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.16302074]
[2019-03-26 20:32:25,142] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.80289152, 79.19795097, 1.0, 2.0, 0.5564084897820633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 777523.2642259982, 777523.2642259988, 192905.2753874115]
[2019-03-26 20:32:25,144] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:32:25,147] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 5.8504014e-37 8.6144378e-13 1.7208410e-21], sampled 0.276865604045765
[2019-03-26 20:32:35,804] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.16302074]
[2019-03-26 20:32:35,805] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.23333333333333, 60.66666666666667, 1.0, 2.0, 0.7561873666481005, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005978792033775, 6.9112, 168.9123160237241, 1953757.723058299, 1886518.640914405, 397330.3072003644]
[2019-03-26 20:32:35,806] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:32:35,809] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.3730356e-26 9.9999917e-01 5.1872728e-24 7.9796013e-07 7.6777490e-13], sampled 0.05895840101516414
[2019-03-26 20:32:35,811] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1953757.723058299 W.
[2019-03-26 20:32:42,898] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.16302074]
[2019-03-26 20:32:42,899] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.31666666666667, 87.66666666666667, 1.0, 2.0, 0.5438795897082672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 760009.1599010023, 760009.1599010017, 190756.434037076]
[2019-03-26 20:32:42,902] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:32:42,905] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 5.3114297e-37 8.2391505e-13 1.6132354e-21], sampled 0.7297481654265456
[2019-03-26 20:32:42,921] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.16302074]
[2019-03-26 20:32:42,923] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.36666666666667, 63.0, 1.0, 2.0, 0.897028045164024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1253784.812861649, 1253784.81286165, 269123.9397086793]
[2019-03-26 20:32:42,925] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:32:42,928] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.7699019e-35 1.0000000e+00 6.9275306e-33 6.4920659e-11 9.0550728e-19], sampled 0.05347520577721265
[2019-03-26 20:32:59,625] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.16302074]
[2019-03-26 20:32:59,627] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.56666666666667, 85.0, 1.0, 2.0, 0.7670448436310895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1072014.316463863, 1072014.316463863, 235985.0782339207]
[2019-03-26 20:32:59,629] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:32:59,631] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.00147484e-35 1.00000000e+00 4.04498773e-33 5.06646149e-11
 6.32121860e-19], sampled 0.8924944532027144
[2019-03-26 20:33:09,917] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.3198 2928314360.4977 1338.0000
[2019-03-26 20:33:10,364] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8655.4327 2780159343.4963 933.0000
[2019-03-26 20:33:10,475] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7995.6793 3008572576.9851 1766.0000
[2019-03-26 20:33:10,573] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7874.2549 3164930392.4171 1778.0000
[2019-03-26 20:33:10,574] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8491.5809 2843444954.4583 1131.0000
[2019-03-26 20:33:11,589] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 725000, evaluation results [725000.0, 7874.254934002473, 3164930392.4170628, 1778.0, 8252.319848496612, 2928314360.4977336, 1338.0, 8655.432663684038, 2780159343.4962626, 933.0, 7995.679306472705, 3008572576.985058, 1766.0, 8491.580877992481, 2843444954.4583273, 1131.0]
[2019-03-26 20:33:13,132] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 7.917146e-15 9.991842e-23], sum to 1.0000
[2019-03-26 20:33:13,139] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8724
[2019-03-26 20:33:13,145] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.5741437883975836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 802315.8680732055, 802315.8680732049, 196028.4719071925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3330000.0000, 
sim time next is 3330600.0000, 
raw observation next is [32.0, 67.66666666666667, 1.0, 2.0, 0.5811754934602593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 812145.819240161, 812145.819240161, 197291.8184000549], 
processed observation next is [0.0, 0.5652173913043478, 0.7156398104265403, 0.6766666666666667, 1.0, 1.0, 0.49539216079549314, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22559606090004472, 0.22559606090004472, 0.29446540059709686], 
reward next is 0.7055, 
noisyNet noise sample is [array([-0.73587644], dtype=float32), -2.3915865]. 
=============================================
[2019-03-26 20:33:25,126] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0145724e-17 4.9095237e-01 1.3695193e-15 5.0904757e-01 3.3915915e-11], sum to 1.0000
[2019-03-26 20:33:25,134] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5395
[2019-03-26 20:33:25,141] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.33333333333334, 68.66666666666667, 1.0, 2.0, 0.7748621066668048, 1.0, 2.0, 0.7748621066668048, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2166974.648026465, 2166974.648026465, 407816.0483993409], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3576000.0000, 
sim time next is 3576600.0000, 
raw observation next is [30.5, 68.0, 1.0, 2.0, 0.7752677914356922, 1.0, 2.0, 0.7752677914356922, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2168110.331787534, 2168110.331787534, 408007.896501869], 
processed observation next is [1.0, 0.391304347826087, 0.6445497630331753, 0.68, 1.0, 1.0, 0.7292383029345689, 1.0, 1.0, 0.7292383029345689, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6022528699409817, 0.6022528699409817, 0.6089670097042821], 
reward next is 0.3910, 
noisyNet noise sample is [array([-0.34414837], dtype=float32), -0.41457218]. 
=============================================
[2019-03-26 20:33:30,042] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.9712451e-34 2.4845633e-08 7.3470308e-24], sum to 1.0000
[2019-03-26 20:33:30,050] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7896
[2019-03-26 20:33:30,054] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.535962459009392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 748941.9802847204, 748941.9802847204, 189422.5201043372], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3822000.0000, 
sim time next is 3822600.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.5358341797314213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 748762.6625055039, 748762.6625055044, 189401.0652399772], 
processed observation next is [0.0, 0.21739130434782608, 0.4786729857819906, 0.89, 1.0, 1.0, 0.4407640719655678, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20798962847375108, 0.20798962847375124, 0.2826881570745928], 
reward next is 0.7173, 
noisyNet noise sample is [array([-0.83930093], dtype=float32), -0.864343]. 
=============================================
[2019-03-26 20:33:44,398] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.9287469e-10 7.7293293e-28], sum to 1.0000
[2019-03-26 20:33:44,405] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7509
[2019-03-26 20:33:44,410] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 70.0, 1.0, 2.0, 0.5433314895713639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 759242.9792850231, 759242.9792850225, 190663.0707257695], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3874200.0000, 
sim time next is 3874800.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.538117117563818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 751953.9177811923, 751953.9177811918, 189783.508443075], 
processed observation next is [0.0, 0.8695652173913043, 0.6208530805687204, 0.7, 1.0, 1.0, 0.44351459947447947, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20887608827255344, 0.20887608827255327, 0.2832589678254851], 
reward next is 0.7167, 
noisyNet noise sample is [array([0.8956141], dtype=float32), 0.42868727]. 
=============================================
[2019-03-26 20:33:48,148] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.1933633e-13 1.2254325e-28], sum to 1.0000
[2019-03-26 20:33:48,158] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0303
[2019-03-26 20:33:48,164] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.0, 56.0, 1.0, 2.0, 0.5945514491222607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 830844.9477774323, 830844.9477774329, 199736.0541405589], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3937800.0000, 
sim time next is 3938400.0000, 
raw observation next is [35.0, 56.0, 1.0, 2.0, 0.5942153171896634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 830375.0427994833, 830375.0427994839, 199674.0139918176], 
processed observation next is [0.0, 0.6086956521739131, 0.8578199052132701, 0.56, 1.0, 1.0, 0.5111027917947751, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23065973411096757, 0.23065973411096774, 0.2980209164056979], 
reward next is 0.7020, 
noisyNet noise sample is [array([-0.5910578], dtype=float32), 0.5016465]. 
=============================================
[2019-03-26 20:33:56,372] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.5576127e-10 5.6030627e-28], sum to 1.0000
[2019-03-26 20:33:56,378] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1784
[2019-03-26 20:33:56,383] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 86.0, 1.0, 2.0, 0.5427630285483152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 758448.3370883181, 758448.3370883187, 190567.3412119676], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4068000.0000, 
sim time next is 4068600.0000, 
raw observation next is [27.56666666666667, 86.16666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.578196710368428, 6.9112, 169.2900105806816, 1928323.497414847, 1454076.800761533, 311420.3639341666], 
processed observation next is [1.0, 0.08695652173913043, 0.505529225908373, 0.8616666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.06669967103684282, 0.0, 0.8312914532533334, 0.5356454159485686, 0.4039102224337592, 0.464806513334577], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.83268464], dtype=float32), -0.89564]. 
=============================================
[2019-03-26 20:33:56,655] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.6882412e-18 1.7248140e-32], sum to 1.0000
[2019-03-26 20:33:56,664] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0233
[2019-03-26 20:33:56,669] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.5419617560366935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 757328.2525986155, 757328.2525986155, 190432.0600581613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4060800.0000, 
sim time next is 4061400.0000, 
raw observation next is [27.96666666666667, 84.16666666666667, 1.0, 2.0, 0.5423837146603072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 757918.1008522207, 757918.1008522207, 190503.3959678632], 
processed observation next is [1.0, 0.0, 0.524486571879937, 0.8416666666666667, 1.0, 1.0, 0.44865507790398457, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2105328057922835, 0.2105328057922835, 0.2843334268177063], 
reward next is 0.7157, 
noisyNet noise sample is [array([-2.825419], dtype=float32), 0.69780374]. 
=============================================
[2019-03-26 20:33:57,212] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.7672759e-36 1.0000000e+00 7.5251749e-36 4.4676819e-12 3.7126407e-25], sum to 1.0000
[2019-03-26 20:33:57,223] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9808
[2019-03-26 20:33:57,228] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.46666666666667, 86.66666666666667, 1.0, 2.0, 0.8849170889881192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565103971, 1236847.351900825, 1236847.351900826, 265822.8258896743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4070400.0000, 
sim time next is 4071000.0000, 
raw observation next is [27.43333333333333, 86.83333333333333, 1.0, 2.0, 0.8560973863711036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1196543.397142065, 1196543.397142065, 258146.9177549946], 
processed observation next is [1.0, 0.08695652173913043, 0.49921011058451803, 0.8683333333333333, 1.0, 1.0, 0.8266233570736188, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3323731658727958, 0.3323731658727958, 0.38529390709700684], 
reward next is 0.6147, 
noisyNet noise sample is [array([-0.02168047], dtype=float32), 0.50335956]. 
=============================================
[2019-03-26 20:33:57,240] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[62.917248]
 [61.615158]
 [61.69639 ]
 [64.213036]
 [70.2505  ]], R is [[63.87092972]
 [63.83546829]
 [63.19711304]
 [63.06245804]
 [62.43183517]].
[2019-03-26 20:34:07,374] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 20:34:07,375] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:34:07,376] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:34:07,378] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:34:07,379] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:34:07,380] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:34:07,379] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:34:07,383] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:34:07,383] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:34:07,377] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:34:07,388] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:34:07,401] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run31
[2019-03-26 20:34:07,402] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run31
[2019-03-26 20:34:07,441] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run31
[2019-03-26 20:34:07,443] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run31
[2019-03-26 20:34:07,443] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run31
[2019-03-26 20:34:40,138] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.006304911]
[2019-03-26 20:34:40,139] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.684780705, 89.60645611999999, 1.0, 2.0, 0.7063544972634889, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.981176340495336, 6.9112, 168.9124876509422, 1884021.022849922, 1834377.53630086, 386923.2441751388]
[2019-03-26 20:34:40,140] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:34:40,144] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.9443243e-26 1.0000000e+00 9.3945846e-26 3.5757175e-08 8.2448445e-16], sampled 0.6574259195823239
[2019-03-26 20:34:40,145] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1884021.022849922 W.
[2019-03-26 20:35:23,222] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.006304911]
[2019-03-26 20:35:23,223] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [35.15, 57.5, 1.0, 2.0, 0.5751589935797301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104099, 803735.065517487, 803735.0655174864, 196212.7232852759]
[2019-03-26 20:35:23,226] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:35:23,228] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.5001521e-37 1.0000000e+00 1.5281490e-37 2.9818535e-14 1.0183580e-24], sampled 0.7541159879538917
[2019-03-26 20:35:29,537] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.006304911]
[2019-03-26 20:35:29,538] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [33.059676305, 70.00078073666667, 1.0, 2.0, 0.6338325888724314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 885760.5407060952, 885760.5407060952, 207219.216113188]
[2019-03-26 20:35:29,538] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:35:29,540] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.8983130e-15 2.3459756e-26], sampled 0.5846090508433922
[2019-03-26 20:35:31,232] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.006304911]
[2019-03-26 20:35:31,236] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.57064417, 81.20572438333333, 1.0, 2.0, 0.591078782767124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 825990.2473444166, 825990.2473444166, 199092.7277489866]
[2019-03-26 20:35:31,237] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:35:31,239] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.7389153e-35 1.0000000e+00 1.7456955e-35 2.3408955e-13 2.7970897e-23], sampled 0.6808764171514142
[2019-03-26 20:35:39,054] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.006304911]
[2019-03-26 20:35:39,054] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.9, 90.33333333333334, 1.0, 2.0, 0.7192550265602135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1005192.127894601, 1005192.127894601, 225056.6899283132]
[2019-03-26 20:35:39,055] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:35:39,059] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.0708952e-34 1.0000000e+00 2.0325891e-34 7.5888568e-13 1.6899267e-22], sampled 0.5862533840590158
[2019-03-26 20:35:42,475] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.006304911]
[2019-03-26 20:35:42,476] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.8, 68.0, 1.0, 2.0, 0.7691874092931011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1075010.260832704, 1075010.260832704, 236489.1273032969]
[2019-03-26 20:35:42,479] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:35:42,484] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.8748735e-35 1.0000000e+00 1.8336093e-35 2.3958277e-13 2.8989868e-23], sampled 0.23958200103418936
[2019-03-26 20:36:01,223] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7874.2549 3164933419.7733 1778.0000
[2019-03-26 20:36:01,362] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.3222 3008558204.4413 1766.0000
[2019-03-26 20:36:01,717] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.0586 2928241882.8146 1338.0000
[2019-03-26 20:36:01,848] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8656.0742 2780141322.3502 933.0000
[2019-03-26 20:36:01,995] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8492.9778 2843378227.1976 1131.0000
[2019-03-26 20:36:03,010] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 750000, evaluation results [750000.0, 7874.254934002473, 3164933419.7732573, 1778.0, 8253.05861172702, 2928241882.8145804, 1338.0, 8656.074218006363, 2780141322.350202, 933.0, 7996.322233343432, 3008558204.4412923, 1766.0, 8492.97779728114, 2843378227.1976113, 1131.0]
[2019-03-26 20:36:04,020] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.7821369e-24 1.0000000e+00 2.8149197e-25 1.5551944e-08 1.9855157e-15], sum to 1.0000
[2019-03-26 20:36:04,027] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8600
[2019-03-26 20:36:04,032] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 75.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.941671190300175, 6.9112, 168.912485234512, 1475386.983507744, 1453769.732684788, 311352.5252626254], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4248000.0000, 
sim time next is 4248600.0000, 
raw observation next is [29.83333333333333, 75.66666666666667, 1.0, 2.0, 0.9893153650480473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129316994846, 1382859.705618216, 1382859.705618216, 295689.3685540853], 
processed observation next is [1.0, 0.17391304347826086, 0.6129541864139019, 0.7566666666666667, 1.0, 1.0, 0.9871269458410208, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294398233191974, 0.38412769600505997, 0.38412769600505997, 0.44132741575236617], 
reward next is 0.5587, 
noisyNet noise sample is [array([0.39667025], dtype=float32), 1.596591]. 
=============================================
[2019-03-26 20:36:13,637] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.4698369e-22 1.0171801e-27], sum to 1.0000
[2019-03-26 20:36:13,642] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7253
[2019-03-26 20:36:13,650] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.581932232265512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 813203.7054230262, 813203.7054230255, 197428.1532226166], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4423200.0000, 
sim time next is 4423800.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.5809484113354244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 811828.3690380023, 811828.3690380023, 197250.3394906312], 
processed observation next is [0.0, 0.17391304347826086, 0.5734597156398105, 0.84, 1.0, 1.0, 0.49511856787400527, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.225507880288334, 0.225507880288334, 0.2944034917770615], 
reward next is 0.7056, 
noisyNet noise sample is [array([0.31561837], dtype=float32), 0.083558746]. 
=============================================
[2019-03-26 20:36:16,399] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 8.037321e-21 4.774384e-26], sum to 1.0000
[2019-03-26 20:36:16,407] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1933
[2019-03-26 20:36:16,412] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666667, 72.33333333333334, 1.0, 2.0, 0.6465546392236101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 903546.7570592399, 903546.7570592399, 209737.4679518104], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4468200.0000, 
sim time next is 4468800.0000, 
raw observation next is [31.33333333333334, 73.66666666666667, 1.0, 2.0, 0.6069456993342348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 848171.9795230635, 848171.9795230641, 202046.9249382585], 
processed observation next is [0.0, 0.7391304347826086, 0.6840442338072673, 0.7366666666666667, 1.0, 1.0, 0.5264406016075118, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23560332764529543, 0.2356033276452956, 0.3015625745347142], 
reward next is 0.6984, 
noisyNet noise sample is [array([-0.61884063], dtype=float32), -0.85573703]. 
=============================================
[2019-03-26 20:36:16,633] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.9233292e-23 1.5172351e-29], sum to 1.0000
[2019-03-26 20:36:16,643] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6710
[2019-03-26 20:36:16,650] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 79.0, 1.0, 2.0, 0.5847947394891898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 817205.3689186447, 817205.368918644, 197946.8030978707], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4472400.0000, 
sim time next is 4473000.0000, 
raw observation next is [29.5, 79.0, 1.0, 2.0, 0.5792908206771125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 809511.1376075802, 809511.1376075802, 196950.6193577511], 
processed observation next is [0.0, 0.782608695652174, 0.5971563981042655, 0.79, 1.0, 1.0, 0.4931214706953162, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22486420489099448, 0.22486420489099448, 0.2939561482951509], 
reward next is 0.7060, 
noisyNet noise sample is [array([-2.1428394], dtype=float32), 0.34559634]. 
=============================================
[2019-03-26 20:36:16,679] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[79.5889  ]
 [79.52941 ]
 [79.559044]
 [79.461555]
 [79.38064 ]], R is [[79.57472229]
 [79.48353577]
 [79.39080811]
 [79.29989624]
 [79.20927429]].
[2019-03-26 20:36:23,467] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5344701e-18 9.9992967e-01 1.7237653e-17 7.0293536e-05 8.7889873e-09], sum to 1.0000
[2019-03-26 20:36:23,483] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7052
[2019-03-26 20:36:23,488] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 89.0, 1.0, 2.0, 0.3798637457501445, 1.0, 1.0, 0.3798637457501445, 1.0, 2.0, 0.6584836232869392, 6.9112, 6.9112, 170.5573041426782, 1593060.612078284, 1593060.612078284, 341863.0557029924], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4591800.0000, 
sim time next is 4592400.0000, 
raw observation next is [27.33333333333334, 90.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.345719164666725, 6.9112, 168.9104513219598, 1762224.335926823, 1453966.057436853, 311352.0513997599], 
processed observation next is [1.0, 0.13043478260869565, 0.4944707740916275, 0.9066666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.04345191646667246, 0.0, 0.8294276435300288, 0.4895067599796731, 0.4038794603991258, 0.46470455432799984], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8848889], dtype=float32), -0.15587574]. 
=============================================
[2019-03-26 20:36:25,494] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0663469e-15 9.9693310e-01 9.9571747e-15 3.0664958e-03 3.6136660e-07], sum to 1.0000
[2019-03-26 20:36:25,506] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0823
[2019-03-26 20:36:25,514] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3081681.975412983 W.
[2019-03-26 20:36:25,522] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.5, 61.5, 1.0, 2.0, 0.827533177827652, 1.0, 2.0, 0.7343566284280885, 1.0, 1.0, 1.03, 7.005107790183965, 6.9112, 170.5573041426782, 3081681.975412983, 3014412.005379535, 564637.0521225533], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4627800.0000, 
sim time next is 4628400.0000, 
raw observation next is [34.66666666666666, 61.0, 1.0, 2.0, 0.8089117751147976, 1.0, 2.0, 0.7250459270716615, 1.0, 2.0, 1.03, 7.005106321320092, 6.9112, 170.5573041426782, 3042562.60436552, 2975293.686539013, 557936.1524309991], 
processed observation next is [1.0, 0.5652173913043478, 0.842022116903633, 0.61, 1.0, 1.0, 0.7697732230298766, 1.0, 1.0, 0.6687300326164596, 1.0, 1.0, 1.0365853658536586, 0.009390632132009191, 0.0, 0.8375144448122397, 0.8451562789904222, 0.8264704684830592, 0.8327405260164166], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5683492], dtype=float32), -0.018730747]. 
=============================================
[2019-03-26 20:36:29,611] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.5896230e-21 9.9993205e-01 5.1452276e-23 6.7951056e-05 5.6316046e-11], sum to 1.0000
[2019-03-26 20:36:29,621] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1965
[2019-03-26 20:36:29,631] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2126197.823889785 W.
[2019-03-26 20:36:29,635] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.66666666666667, 66.0, 1.0, 2.0, 0.8793965900368647, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.988208072342857, 6.9112, 168.9124981871528, 2126197.823889785, 2071565.795193747, 429060.203672104], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4897200.0000, 
sim time next is 4897800.0000, 
raw observation next is [30.5, 66.0, 1.0, 2.0, 0.5111445254344309, 1.0, 1.0, 0.5111445254344309, 1.0, 2.0, 0.8787583528977609, 6.9112, 6.9112, 170.5573041426782, 2144172.701013858, 2144172.701013858, 421279.0677533136], 
processed observation next is [1.0, 0.6956521739130435, 0.6445497630331753, 0.66, 1.0, 1.0, 0.4110175005234107, 1.0, 0.5, 0.4110175005234107, 1.0, 1.0, 0.8521443328021475, 0.0, 0.0, 0.8375144448122397, 0.595603528059405, 0.595603528059405, 0.6287747279900202], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.28517815], dtype=float32), 0.6983194]. 
=============================================
[2019-03-26 20:36:46,191] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.1227617e-23 9.1653234e-01 1.3455745e-24 8.3467655e-02 4.8594761e-12], sum to 1.0000
[2019-03-26 20:36:46,203] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8867
[2019-03-26 20:36:46,212] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3026862.124979978 W.
[2019-03-26 20:36:46,219] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.46666666666667, 64.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 9.127373732079436, 6.9112, 168.9002453770475, 3026862.124979978, 1454750.518965166, 308939.7945660483], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4972800.0000, 
sim time next is 4973400.0000, 
raw observation next is [30.5, 64.5, 1.0, 2.0, 0.544728268978881, 1.0, 1.0, 0.544728268978881, 1.0, 1.0, 0.932928121128385, 6.9112, 6.9112, 170.5573041426782, 2285190.566983133, 2285190.566983133, 444837.3018803612], 
processed observation next is [1.0, 0.5652173913043478, 0.6445497630331753, 0.645, 1.0, 1.0, 0.45147984214323017, 1.0, 0.5, 0.45147984214323017, 1.0, 0.5, 0.918205025766323, 0.0, 0.0, 0.8375144448122397, 0.6347751574953148, 0.6347751574953148, 0.6639362714632258], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7250722], dtype=float32), -1.2740518]. 
=============================================
[2019-03-26 20:36:47,669] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4266465e-26 9.9997020e-01 8.2762571e-26 2.9810761e-05 1.1767930e-15], sum to 1.0000
[2019-03-26 20:36:47,681] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8359
[2019-03-26 20:36:47,690] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1999307.263592263 W.
[2019-03-26 20:36:47,696] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.9, 63.0, 1.0, 2.0, 0.7887346647977563, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.98068017119267, 6.9112, 168.9125478554993, 1999307.263592263, 1950015.758077584, 405975.9913264529], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4980600.0000, 
sim time next is 4981200.0000, 
raw observation next is [30.93333333333333, 63.0, 1.0, 2.0, 0.7521756401855689, 1.0, 1.0, 0.7521756401855689, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2103467.520964051, 2103467.520964051, 397255.0737021636], 
processed observation next is [1.0, 0.6521739130434783, 0.6650868878357029, 0.63, 1.0, 1.0, 0.7014164339585167, 1.0, 0.5, 0.7014164339585167, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5842965336011253, 0.5842965336011253, 0.5929180204509904], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.40005228], dtype=float32), 0.12835182]. 
=============================================
[2019-03-26 20:36:48,626] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0873482e-08 1.3394777e-27], sum to 1.0000
[2019-03-26 20:36:48,637] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5329
[2019-03-26 20:36:48,642] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4808737448191366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 672062.9188923375, 672062.9188923368, 180669.213913349], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5110800.0000, 
sim time next is 5111400.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.482364311720772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 674146.5682088706, 674146.5682088699, 180894.5739038551], 
processed observation next is [0.0, 0.13043478260869565, 0.4312796208530806, 0.84, 1.0, 1.0, 0.37634254424189395, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18726293561357515, 0.18726293561357496, 0.2699919013490375], 
reward next is 0.7300, 
noisyNet noise sample is [array([-1.9035144], dtype=float32), -1.1227944]. 
=============================================
[2019-03-26 20:36:50,411] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4465649e-12 1.9543168e-29], sum to 1.0000
[2019-03-26 20:36:50,418] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7327
[2019-03-26 20:36:50,423] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.508664754023036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 710784.0142643537, 710784.0142643544, 184964.7932893815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5035800.0000, 
sim time next is 5036400.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5095876984073302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712074.1252579205, 712074.1252579205, 185111.9381594009], 
processed observation next is [0.0, 0.30434782608695654, 0.4786729857819906, 0.84, 1.0, 1.0, 0.40914180531003635, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19779836812720014, 0.19779836812720014, 0.2762864748647774], 
reward next is 0.7237, 
noisyNet noise sample is [array([1.7464997], dtype=float32), -1.9547712]. 
=============================================
[2019-03-26 20:36:58,707] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 20:36:58,709] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:36:58,710] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:36:58,710] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:36:58,711] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:36:58,712] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:36:58,714] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:36:58,712] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:36:58,715] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:36:58,716] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:36:58,719] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:36:58,729] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run32
[2019-03-26 20:36:58,730] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run32
[2019-03-26 20:36:58,771] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run32
[2019-03-26 20:36:58,803] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run32
[2019-03-26 20:36:58,830] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run32
[2019-03-26 20:37:16,177] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), 0.046917412]
[2019-03-26 20:37:16,179] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.6, 61.0, 1.0, 2.0, 0.9160060260170056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1385697.653478942, 1385697.653478942, 289429.0482113513]
[2019-03-26 20:37:16,180] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:37:16,184] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.0604208e-33 1.0000000e+00 4.0815189e-34 6.2254063e-10 8.2742198e-21], sampled 0.6472919258879286
[2019-03-26 20:37:16,188] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), 0.046917412]
[2019-03-26 20:37:16,189] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [20.73333333333333, 77.5, 1.0, 2.0, 0.2575727465057806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 424167.4905855851, 424167.4905855851, 161651.7146285443]
[2019-03-26 20:37:16,190] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:37:16,192] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0598890e-12 4.0534977e-26], sampled 0.48437161123381656
[2019-03-26 20:37:28,923] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), 0.046917412]
[2019-03-26 20:37:28,926] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.99555461, 94.09787357, 1.0, 2.0, 0.648792314510923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 906675.1968600744, 906675.1968600738, 210190.7301429741]
[2019-03-26 20:37:28,927] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:37:28,930] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.4472902e-12 3.8913781e-25], sampled 0.11127486800248498
[2019-03-26 20:37:58,434] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), 0.046917412]
[2019-03-26 20:37:58,437] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [35.0, 56.66666666666667, 1.0, 2.0, 0.9341456396989677, 1.0, 2.0, 0.7876628593637466, 1.0, 1.0, 1.03, 7.005116201589427, 6.9112, 170.5573041426782, 3305674.328041233, 3238398.332575899, 605492.4773824506]
[2019-03-26 20:37:58,437] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:37:58,441] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.1031305e-20 9.9989820e-01 2.5239032e-20 1.0183239e-04 1.2256455e-11], sampled 0.41459965997979553
[2019-03-26 20:37:58,442] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 3305674.328041233 W.
[2019-03-26 20:38:42,591] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), 0.046917412]
[2019-03-26 20:38:42,593] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.67908108166667, 90.35661915666667, 1.0, 2.0, 0.6158719519537789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 882451.9984719885, 882451.9984719879, 206558.2300444112]
[2019-03-26 20:38:42,594] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:38:42,595] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.7890908e-38 1.0000000e+00 1.4825057e-38 2.0657878e-11 1.2058987e-23], sampled 0.8341365282740781
[2019-03-26 20:38:49,139] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), 0.046917412]
[2019-03-26 20:38:49,142] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.76906323, 92.34299742666666, 1.0, 2.0, 0.4285675626270312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 627385.3517349544, 627385.3517349544, 176806.2468638065]
[2019-03-26 20:38:49,143] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:38:49,146] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.3788198e-12 1.2665550e-24], sampled 0.3060623891923048
[2019-03-26 20:38:52,883] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.7003 2928231904.9171 1338.0000
[2019-03-26 20:38:53,117] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.1120 2780070553.5627 933.0000
[2019-03-26 20:38:53,264] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7873.5014 3164995964.7091 1778.0000
[2019-03-26 20:38:53,483] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.6078 3008551080.6251 1766.0000
[2019-03-26 20:38:53,491] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8493.5068 2843430346.4143 1131.0000
[2019-03-26 20:38:54,507] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 775000, evaluation results [775000.0, 7873.501410909826, 3164995964.709079, 1778.0, 8253.700304448676, 2928231904.9170933, 1338.0, 8658.112016599982, 2780070553.5627275, 933.0, 7997.607833681256, 3008551080.6250534, 1766.0, 8493.50677167813, 2843430346.4142575, 1131.0]
[2019-03-26 20:38:56,200] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.7293809e-26 1.0000000e+00 1.7051221e-25 5.9014702e-08 1.3835204e-14], sum to 1.0000
[2019-03-26 20:38:56,210] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9035
[2019-03-26 20:38:56,221] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2962863.311400098 W.
[2019-03-26 20:38:56,227] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.33333333333334, 72.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 9.037198697067522, 6.9112, 168.9010567260096, 2962863.311400098, 1454712.919962238, 309179.71382418], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5214000.0000, 
sim time next is 5214600.0000, 
raw observation next is [29.5, 72.0, 1.0, 2.0, 0.5735630686525022, 1.0, 1.0, 0.5735630686525022, 1.0, 1.0, 0.9874404293735684, 6.9112, 6.9112, 170.5573041426782, 2406271.948833141, 2406271.948833141, 467919.6483129376], 
processed observation next is [1.0, 0.34782608695652173, 0.5971563981042655, 0.72, 1.0, 1.0, 0.4862205646415689, 1.0, 0.5, 0.4862205646415689, 1.0, 0.5, 0.9846834504555712, 0.0, 0.0, 0.8375144448122397, 0.6684088746758725, 0.6684088746758725, 0.6983875347954293], 
reward next is 0.3016, 
noisyNet noise sample is [array([-1.4588182], dtype=float32), -1.3366807]. 
=============================================
[2019-03-26 20:39:00,020] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8521822e-28 1.0000000e+00 1.3230531e-29 1.2551768e-10 4.9616382e-19], sum to 1.0000
[2019-03-26 20:39:00,027] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3734
[2019-03-26 20:39:00,036] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1924132.619249038 W.
[2019-03-26 20:39:00,046] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.05, 88.5, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.573792740115749, 6.9112, 168.9092278978081, 1924132.619249038, 1454076.901045732, 311355.8992541993], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5367000.0000, 
sim time next is 5367600.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 0.6739526526938603, 1.0, 1.0, 0.6739526526938603, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1884523.669703183, 1884523.669703183, 363185.9905056847], 
processed observation next is [1.0, 0.13043478260869565, 0.5734597156398105, 0.89, 1.0, 1.0, 0.6071718707154943, 1.0, 0.5, 0.6071718707154943, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5234787971397731, 0.5234787971397731, 0.542068642545798], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2656909], dtype=float32), -0.23561749]. 
=============================================
[2019-03-26 20:39:04,217] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4758604e-33 1.0000000e+00 4.7034047e-37 2.7114108e-11 2.1026873e-25], sum to 1.0000
[2019-03-26 20:39:04,227] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9465
[2019-03-26 20:39:04,233] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333334, 78.33333333333334, 1.0, 2.0, 0.6295074414243633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 879713.7838530749, 879713.7838530749, 206372.6021989454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5343600.0000, 
sim time next is 5344200.0000, 
raw observation next is [31.25, 78.5, 1.0, 2.0, 0.6276846513960663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 877165.4491132319, 877165.4491132324, 206017.5566451002], 
processed observation next is [1.0, 0.8695652173913043, 0.6800947867298578, 0.785, 1.0, 1.0, 0.5514272908386341, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24365706919811997, 0.2436570691981201, 0.30748889051507494], 
reward next is 0.6925, 
noisyNet noise sample is [array([0.5762104], dtype=float32), 0.31620234]. 
=============================================
[2019-03-26 20:39:06,090] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.2984279e-13 9.9713755e-01 6.0559999e-13 2.8623610e-03 1.4619381e-07], sum to 1.0000
[2019-03-26 20:39:06,098] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5315
[2019-03-26 20:39:06,107] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 3201373.673354237 W.
[2019-03-26 20:39:06,113] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.46666666666667, 62.66666666666667, 1.0, 2.0, 0.8845045847171044, 1.0, 2.0, 0.7628423318728148, 1.0, 2.0, 1.03, 7.005112284682999, 6.9112, 170.5573041426782, 3201373.673354237, 3134100.483728306, 585941.820093168], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5394000.0000, 
sim time next is 5394600.0000, 
raw observation next is [34.65000000000001, 62.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.958188075379613, 6.9112, 170.5573041426782, 3660203.603161911, 2910203.456015544, 547576.9240166047], 
processed observation next is [1.0, 0.43478260869565216, 0.8412322274881523, 0.62, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.10469880753796126, 0.0, 0.8375144448122397, 1.0167232231005308, 0.8083898488932066, 0.8172789910695593], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.75622094], dtype=float32), 2.6418412]. 
=============================================
[2019-03-26 20:39:06,817] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.6156769e-14 9.9009621e-01 2.6565992e-14 9.9037569e-03 8.4982005e-10], sum to 1.0000
[2019-03-26 20:39:06,826] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8664
[2019-03-26 20:39:06,833] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2293373.086271169 W.
[2019-03-26 20:39:06,840] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.3, 66.66666666666667, 1.0, 2.0, 0.8200154618118384, 1.0, 2.0, 0.8200154618118384, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2293373.086271169, 2293373.086271169, 429746.2227219695], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5390400.0000, 
sim time next is 5391000.0000, 
raw observation next is [33.5, 66.0, 1.0, 2.0, 0.5515430469027414, 1.0, 2.0, 0.5515430469027414, 1.0, 1.0, 0.9578478743972452, 6.9112, 6.9112, 170.5573041426782, 2313805.719899366, 2313805.719899366, 452620.8014772006], 
processed observation next is [1.0, 0.391304347826087, 0.7867298578199052, 0.66, 1.0, 1.0, 0.45969041795511006, 1.0, 1.0, 0.45969041795511006, 1.0, 0.5, 0.9485949687771282, 0.0, 0.0, 0.8375144448122397, 0.6427238110831572, 0.6427238110831572, 0.6755534350405978], 
reward next is 0.3244, 
noisyNet noise sample is [array([-0.03987825], dtype=float32), -1.7228857]. 
=============================================
[2019-03-26 20:39:06,853] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[24.487492]
 [22.756348]
 [20.724258]
 [18.922405]
 [18.696785]], R is [[23.79811859]
 [23.91872406]
 [24.01781845]
 [24.02646637]
 [23.97432899]].
[2019-03-26 20:39:09,920] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 5.151180e-21 4.044534e-36], sum to 1.0000
[2019-03-26 20:39:09,929] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3960
[2019-03-26 20:39:09,933] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.83333333333334, 72.66666666666667, 1.0, 2.0, 0.541256075815571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 756341.7958374814, 756341.795837482, 190312.8282231646], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5649600.0000, 
sim time next is 5650200.0000, 
raw observation next is [30.0, 72.0, 1.0, 2.0, 0.5419428748475508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 757301.8589368007, 757301.8589368014, 190428.9813475051], 
processed observation next is [0.0, 0.391304347826087, 0.6208530805687204, 0.72, 1.0, 1.0, 0.44812394559945873, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21036162748244466, 0.21036162748244483, 0.28422236022015684], 
reward next is 0.7158, 
noisyNet noise sample is [array([-0.5633726], dtype=float32), 1.684738]. 
=============================================
[2019-03-26 20:39:13,197] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0015041e-09 4.6489509e-03 1.8647355e-09 9.9534988e-01 1.1838966e-06], sum to 1.0000
[2019-03-26 20:39:13,205] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3957
[2019-03-26 20:39:13,209] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.7, 58.0, 1.0, 2.0, 0.8277875674345669, 1.0, 2.0, 0.7344838232315462, 1.0, 1.0, 1.03, 7.005107810250957, 6.9112, 170.5573041426782, 3082216.39913812, 3014946.41472987, 564729.9197506675], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5486400.0000, 
sim time next is 5487000.0000, 
raw observation next is [35.8, 57.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.367246097955717, 6.9112, 170.5573041426782, 3236394.635664412, 2909710.26492953, 551208.4113800331], 
processed observation next is [1.0, 0.5217391304347826, 0.895734597156398, 0.57, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.0456046097955717, 0.0, 0.8375144448122397, 0.8989985099067811, 0.8082528513693139, 0.822699121462736], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.66669554], dtype=float32), 0.21379383]. 
=============================================
[2019-03-26 20:39:13,223] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[16.799051]
 [17.118488]
 [17.470581]
 [18.555967]
 [17.409782]], R is [[16.98807716]
 [16.81819725]
 [16.65001488]
 [16.48351479]
 [16.31867981]].
[2019-03-26 20:39:18,821] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 7.109252e-19 0.000000e+00], sum to 1.0000
[2019-03-26 20:39:18,828] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5026
[2019-03-26 20:39:18,840] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 78.0, 1.0, 2.0, 0.5512923579204319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 770371.4070233355, 770371.4070233355, 192022.4183767498], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5772000.0000, 
sim time next is 5772600.0000, 
raw observation next is [28.8, 79.0, 1.0, 2.0, 0.5495153097932858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 767887.2769922784, 767887.276992279, 191717.473560603], 
processed observation next is [0.0, 0.8260869565217391, 0.5639810426540285, 0.79, 1.0, 1.0, 0.4572473611967298, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.213302021386744, 0.21330202138674417, 0.2861454829262731], 
reward next is 0.7139, 
noisyNet noise sample is [array([0.01535737], dtype=float32), -0.53578347]. 
=============================================
[2019-03-26 20:39:21,304] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.3549806e-09 3.7404311e-33], sum to 1.0000
[2019-03-26 20:39:21,316] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0223
[2019-03-26 20:39:21,323] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 91.66666666666666, 1.0, 2.0, 0.522220160378864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729732.2027074888, 729732.2027074888, 187150.3899612127], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5618400.0000, 
sim time next is 5619000.0000, 
raw observation next is [26.05, 91.83333333333333, 1.0, 2.0, 0.5207622642880092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 727694.291853428, 727694.291853428, 186912.7021412179], 
processed observation next is [0.0, 0.0, 0.43364928909952616, 0.9183333333333333, 1.0, 1.0, 0.4226051376963966, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2021373032926189, 0.2021373032926189, 0.2789741823003252], 
reward next is 0.7210, 
noisyNet noise sample is [array([-0.36824328], dtype=float32), 0.109466426]. 
=============================================
[2019-03-26 20:39:21,345] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[68.6599  ]
 [68.67521 ]
 [68.57017 ]
 [68.373375]
 [67.819275]], R is [[68.66692352]
 [68.70092773]
 [68.73456573]
 [68.76774597]
 [68.80023193]].
[2019-03-26 20:39:27,561] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.0592222e-11 0.0000000e+00], sum to 1.0000
[2019-03-26 20:39:27,573] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5258
[2019-03-26 20:39:27,580] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.63333333333333, 75.83333333333333, 1.0, 2.0, 0.5236745060107719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731765.1544703929, 731765.1544703934, 187388.4692998539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5730600.0000, 
sim time next is 5731200.0000, 
raw observation next is [28.8, 75.0, 1.0, 2.0, 0.5239357236267489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 732130.2969789476, 732130.2969789482, 187431.2950984177], 
processed observation next is [0.0, 0.34782608695652173, 0.5639810426540285, 0.75, 1.0, 1.0, 0.42642858268282996, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20336952693859656, 0.20336952693859672, 0.27974820163942943], 
reward next is 0.7203, 
noisyNet noise sample is [array([1.5418705], dtype=float32), 0.030183814]. 
=============================================
[2019-03-26 20:39:29,717] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 3.683174e-13 4.771431e-35], sum to 1.0000
[2019-03-26 20:39:29,726] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8144
[2019-03-26 20:39:29,730] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.1, 82.66666666666667, 1.0, 2.0, 0.5468786600017321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 764201.5231817621, 764201.5231817621, 191266.5657343108], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5775600.0000, 
sim time next is 5776200.0000, 
raw observation next is [28.05, 83.0, 1.0, 2.0, 0.546436695655818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 763583.7056478023, 763583.7056478023, 191191.241292817], 
processed observation next is [0.0, 0.8695652173913043, 0.528436018957346, 0.83, 1.0, 1.0, 0.4535381875371301, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2121065849021673, 0.2121065849021673, 0.28536006163107014], 
reward next is 0.7146, 
noisyNet noise sample is [array([0.5981705], dtype=float32), -1.0391191]. 
=============================================
[2019-03-26 20:39:34,233] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2336488e-19 9.9108511e-01 3.1758104e-20 8.9148888e-03 1.0826789e-13], sum to 1.0000
[2019-03-26 20:39:34,241] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1161
[2019-03-26 20:39:34,250] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2413101.09298336 W.
[2019-03-26 20:39:34,256] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 71.0, 1.0, 2.0, 0.5751893048479085, 1.0, 2.0, 0.5751893048479085, 1.0, 1.0, 0.9989136045110023, 6.9112, 6.9112, 170.5573041426782, 2413101.09298336, 2413101.09298336, 471035.3250915896], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6019200.0000, 
sim time next is 6019800.0000, 
raw observation next is [31.83333333333334, 70.16666666666667, 1.0, 2.0, 0.887446255238561, 1.0, 2.0, 0.887446255238561, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2482147.029342678, 2482147.029342677, 464695.011125361], 
processed observation next is [1.0, 0.6956521739130435, 0.7077409162717223, 0.7016666666666667, 1.0, 1.0, 0.8643930786006759, 1.0, 1.0, 0.8643930786006759, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6894852859285217, 0.6894852859285214, 0.6935746434706881], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2560972], dtype=float32), -1.0096539]. 
=============================================
[2019-03-26 20:39:41,635] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.6588802e-28 1.0000000e+00 1.7063606e-30 1.3559498e-08 1.7331520e-23], sum to 1.0000
[2019-03-26 20:39:41,647] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8299
[2019-03-26 20:39:41,651] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.96666666666667, 93.66666666666667, 1.0, 2.0, 0.6710105856193039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 937738.5253616713, 937738.525361672, 214711.4824841856], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5978400.0000, 
sim time next is 5979000.0000, 
raw observation next is [25.93333333333333, 93.83333333333334, 1.0, 2.0, 0.6643650645838307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 928447.3380341934, 928447.3380341934, 213340.6206680305], 
processed observation next is [1.0, 0.17391304347826086, 0.42812006319115314, 0.9383333333333335, 1.0, 1.0, 0.5956205597395551, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2579020383428315, 0.2579020383428315, 0.31841883681795596], 
reward next is 0.6816, 
noisyNet noise sample is [array([1.3424473], dtype=float32), 1.1305021]. 
=============================================
[2019-03-26 20:39:41,672] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[50.364918]
 [50.38628 ]
 [50.27303 ]
 [50.131664]
 [50.422897]], R is [[50.52825546]
 [50.70250702]
 [50.87302017]
 [51.03664398]
 [51.18102646]].
[2019-03-26 20:39:49,856] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7722167e-19 6.8988961e-01 2.1918309e-21 3.1011033e-01 1.3299905e-14], sum to 1.0000
[2019-03-26 20:39:49,865] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2179
[2019-03-26 20:39:49,872] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2316606.245900053 W.
[2019-03-26 20:39:49,876] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.45, 68.0, 1.0, 2.0, 0.5522099915435533, 1.0, 2.0, 0.5522099915435533, 1.0, 2.0, 0.955279677090243, 6.911200000000001, 6.9112, 170.5573041426782, 2316606.245900053, 2316606.245900053, 452376.8785482061], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6107400.0000, 
sim time next is 6108000.0000, 
raw observation next is [30.4, 68.33333333333334, 1.0, 2.0, 0.8293444183850559, 1.0, 2.0, 0.8293444183850559, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2319487.999351577, 2319487.999351577, 434406.1122696155], 
processed observation next is [1.0, 0.6956521739130435, 0.6398104265402843, 0.6833333333333335, 1.0, 1.0, 0.7943908655241637, 1.0, 1.0, 0.7943908655241637, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6443022220421047, 0.6443022220421047, 0.6483673317456948], 
reward next is 0.3516, 
noisyNet noise sample is [array([1.814669], dtype=float32), -0.7036528]. 
=============================================
[2019-03-26 20:39:49,902] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[39.796825]
 [39.34372 ]
 [40.27384 ]
 [40.965908]
 [41.97734 ]], R is [[40.79367447]
 [40.7105484 ]
 [40.30344391]
 [39.9004097 ]
 [39.85993958]].
[2019-03-26 20:39:50,399] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 20:39:50,400] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:39:50,401] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:39:50,401] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:39:50,402] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:39:50,402] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:39:50,404] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:39:50,404] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:39:50,403] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:39:50,406] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:39:50,405] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:39:50,428] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run33
[2019-03-26 20:39:50,448] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run33
[2019-03-26 20:39:50,449] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run33
[2019-03-26 20:39:50,450] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run33
[2019-03-26 20:39:50,487] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run33
[2019-03-26 20:39:55,034] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), 0.036322355]
[2019-03-26 20:39:55,038] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.35489453333333, 93.70036553666667, 1.0, 2.0, 0.3466861557496351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 541639.524024408, 541639.524024408, 170147.4519388966]
[2019-03-26 20:39:55,040] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:39:55,044] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 8.109751e-15 0.000000e+00], sampled 0.23308820192470825
[2019-03-26 20:39:58,835] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), 0.036322355]
[2019-03-26 20:39:58,837] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.39805354666667, 79.75570011166667, 1.0, 2.0, 0.2518046877710969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 414620.1805650072, 414620.1805650072, 161075.0425179896]
[2019-03-26 20:39:58,838] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:39:58,841] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.1005574e-15 0.0000000e+00], sampled 0.18748797821576468
[2019-03-26 20:40:03,369] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), 0.036322355]
[2019-03-26 20:40:03,370] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.74475125, 79.45681274, 1.0, 2.0, 0.3918708215239612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 588476.8125130566, 588476.8125130573, 173589.7075831385]
[2019-03-26 20:40:03,370] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:40:03,376] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.02303166e-14
 0.00000000e+00], sampled 0.3202527913259605
[2019-03-26 20:40:23,438] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), 0.036322355]
[2019-03-26 20:40:23,440] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.77402521833334, 63.38117100500001, 1.0, 2.0, 0.5858544193948654, 0.0, 2.0, 0.0, 1.0, 1.0, 1.008820746121992, 6.9112, 6.9112, 168.9126983768342, 1638005.039907722, 1638005.039907722, 356801.1092609669]
[2019-03-26 20:40:23,441] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:40:23,444] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.5598744e-36 1.0000000e+00 9.4267287e-38 7.4513298e-11 1.9236132e-30], sampled 0.3052256484486603
[2019-03-26 20:40:48,627] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), 0.036322355]
[2019-03-26 20:40:48,628] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [36.0, 53.66666666666667, 1.0, 2.0, 0.9259681657672011, 1.0, 1.0, 0.9259681657672011, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2590002.739811298, 2590002.739811298, 485865.9905117985]
[2019-03-26 20:40:48,629] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:40:48,631] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.5457700e-29 1.0000000e+00 1.8995496e-30 3.4234269e-08 2.8129352e-24], sampled 0.06181693013438483
[2019-03-26 20:40:48,633] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2590002.739811298 W.
[2019-03-26 20:40:57,134] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), 0.036322355]
[2019-03-26 20:40:57,135] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.55, 84.16666666666667, 1.0, 2.0, 0.6453740872167867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 901896.2595108424, 901896.2595108418, 209503.8987273905]
[2019-03-26 20:40:57,135] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:40:57,139] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2236715e-13 5.8999764e-37], sampled 0.6241488131552402
[2019-03-26 20:41:27,065] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), 0.036322355]
[2019-03-26 20:41:27,067] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.1, 68.0, 1.0, 2.0, 0.3715438503338529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 565620.250718045, 565620.250718045, 171788.4464033191]
[2019-03-26 20:41:27,068] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:41:27,071] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.2500891e-14 4.9727694e-38], sampled 0.7333880908468468
[2019-03-26 20:41:34,581] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), 0.036322355]
[2019-03-26 20:41:34,582] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.86687778, 57.87084898666667, 1.0, 2.0, 0.7263734010952156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1108136.057028729, 1108136.057028729, 238587.3332902514]
[2019-03-26 20:41:34,584] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:41:34,588] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.8237954e-38 1.0000000e+00 0.0000000e+00 1.0032402e-11 1.7668622e-32], sampled 0.30884650095408506
[2019-03-26 20:41:42,705] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7875.3211 3164922268.7314 1778.0000
[2019-03-26 20:41:43,591] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.7003 2928231904.9171 1338.0000
[2019-03-26 20:41:43,608] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8493.5068 2843430346.4143 1131.0000
[2019-03-26 20:41:43,694] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.6078 3008551080.6251 1766.0000
[2019-03-26 20:41:43,706] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8657.3572 2780132369.7409 933.0000
[2019-03-26 20:41:44,723] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 800000, evaluation results [800000.0, 7875.321099382461, 3164922268.731367, 1778.0, 8253.700304448676, 2928231904.9170933, 1338.0, 8657.357172976928, 2780132369.740925, 933.0, 7997.607833681256, 3008551080.6250534, 1766.0, 8493.50677167813, 2843430346.4142575, 1131.0]
[2019-03-26 20:41:54,296] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.6014631e-32 9.9999964e-01 9.1986439e-35 3.0964449e-07 4.5616079e-26], sum to 1.0000
[2019-03-26 20:41:54,306] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0504
[2019-03-26 20:41:54,312] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 92.0, 1.0, 2.0, 0.6646483518587758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 928843.403911114, 928843.403911114, 213399.1069552598], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6499800.0000, 
sim time next is 6500400.0000, 
raw observation next is [26.36666666666667, 91.66666666666667, 1.0, 2.0, 0.643526251608902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 899312.8561165351, 899312.8561165351, 209127.188783195], 
processed observation next is [1.0, 0.21739130434782608, 0.4486571879936811, 0.9166666666666667, 1.0, 1.0, 0.5705135561553035, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24980912669903754, 0.24980912669903754, 0.3121301325122313], 
reward next is 0.6879, 
noisyNet noise sample is [array([-0.93677926], dtype=float32), -0.61608714]. 
=============================================
[2019-03-26 20:42:08,138] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1864058e-31 9.9998856e-01 6.0559635e-32 1.1487003e-05 6.2904539e-26], sum to 1.0000
[2019-03-26 20:42:08,152] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2956
[2019-03-26 20:42:08,156] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.13333333333333, 92.66666666666667, 1.0, 2.0, 0.655766349758343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 916425.4863003239, 916425.4863003232, 211586.4064488214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6496800.0000, 
sim time next is 6497400.0000, 
raw observation next is [26.11666666666667, 92.83333333333333, 1.0, 2.0, 0.6530760839191702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 912664.2571650674, 912664.257165068, 211042.0464341715], 
processed observation next is [1.0, 0.17391304347826086, 0.43680884676145365, 0.9283333333333332, 1.0, 1.0, 0.5820193782158677, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2535178492125187, 0.25351784921251885, 0.31498812900622614], 
reward next is 0.6850, 
noisyNet noise sample is [array([0.81848824], dtype=float32), -0.012817654]. 
=============================================
[2019-03-26 20:42:08,608] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.6385380e-22 9.4272465e-01 6.6573818e-24 5.7275329e-02 3.2181812e-17], sum to 1.0000
[2019-03-26 20:42:08,619] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6438
[2019-03-26 20:42:08,626] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1851038.587240945 W.
[2019-03-26 20:42:08,631] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.06666666666667, 79.66666666666667, 1.0, 2.0, 0.6619878874953385, 1.0, 2.0, 0.6619878874953385, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1851038.587240945, 1851038.587240945, 358272.6400172826], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6511200.0000, 
sim time next is 6511800.0000, 
raw observation next is [28.28333333333333, 77.83333333333333, 1.0, 2.0, 0.4460836314757233, 1.0, 2.0, 0.4460836314757233, 1.0, 1.0, 0.7625427178391065, 6.9112, 6.9112, 170.5573041426782, 1871013.928588384, 1871013.928588384, 377919.4063728312], 
processed observation next is [1.0, 0.34782608695652173, 0.5394944707740915, 0.7783333333333333, 1.0, 1.0, 0.3326308812960521, 1.0, 1.0, 0.3326308812960521, 1.0, 0.5, 0.7104179485842762, 0.0, 0.0, 0.8375144448122397, 0.5197260912745512, 0.5197260912745512, 0.5640588154818376], 
reward next is 0.4359, 
noisyNet noise sample is [array([0.8320931], dtype=float32), -1.6855333]. 
=============================================
[2019-03-26 20:42:10,373] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.4686906e-38 1.0000000e+00 0.0000000e+00 3.3461443e-09 2.8273242e-35], sum to 1.0000
[2019-03-26 20:42:10,381] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1403
[2019-03-26 20:42:10,385] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 73.0, 1.0, 2.0, 0.4830780110132218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 675018.9527168088, 675018.9527168088, 180987.1319754755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6552000.0000, 
sim time next is 6552600.0000, 
raw observation next is [27.95, 73.66666666666667, 1.0, 2.0, 0.4850318140300224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 677749.9294035789, 677749.9294035796, 181284.0457140137], 
processed observation next is [1.0, 0.8695652173913043, 0.523696682464455, 0.7366666666666667, 1.0, 1.0, 0.37955640244581007, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1882638692787719, 0.1882638692787721, 0.27057320255822936], 
reward next is 0.7294, 
noisyNet noise sample is [array([0.38228542], dtype=float32), 0.8279379]. 
=============================================
[2019-03-26 20:42:19,077] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.9327569e-12 2.7758837e-38], sum to 1.0000
[2019-03-26 20:42:19,085] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6043
[2019-03-26 20:42:19,092] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.11666666666667, 71.66666666666666, 1.0, 2.0, 0.3588082607352506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 552194.5937708472, 552194.5937708472, 170815.5840962378], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6735000.0000, 
sim time next is 6735600.0000, 
raw observation next is [25.0, 72.0, 1.0, 2.0, 0.3550359818122086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 547326.3541794426, 547326.3541794426, 170434.4798124389], 
processed observation next is [1.0, 1.0, 0.38388625592417064, 0.72, 1.0, 1.0, 0.22293491784603442, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1520350983831785, 0.1520350983831785, 0.25437982061558045], 
reward next is 0.7456, 
noisyNet noise sample is [array([0.40434223], dtype=float32), -0.197143]. 
=============================================
[2019-03-26 20:42:21,503] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.000000e+00 9.999999e-01 0.000000e+00 6.791514e-08 8.134632e-37], sum to 1.0000
[2019-03-26 20:42:21,515] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6541
[2019-03-26 20:42:21,518] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 67.0, 1.0, 2.0, 0.4229472398859399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 616878.4965556355, 616878.4965556355, 175726.7397801908], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6723000.0000, 
sim time next is 6723600.0000, 
raw observation next is [27.46666666666667, 67.0, 1.0, 2.0, 0.4170665138822869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 611146.1835130262, 611146.1835130256, 175261.3542101542], 
processed observation next is [1.0, 0.8260869565217391, 0.500789889415482, 0.67, 1.0, 1.0, 0.2976704986533577, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1697628287536184, 0.16976282875361823, 0.2615841107614242], 
reward next is 0.7384, 
noisyNet noise sample is [array([-0.9303112], dtype=float32), -0.92930657]. 
=============================================
[2019-03-26 20:42:31,903] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 9.608502e-10 1.211787e-31], sum to 1.0000
[2019-03-26 20:42:31,915] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6139
[2019-03-26 20:42:31,921] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 90.0, 1.0, 2.0, 0.4165771048668537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 612831.3522172116, 612831.3522172116, 175490.061568499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6926400.0000, 
sim time next is 6927000.0000, 
raw observation next is [23.85, 90.33333333333333, 1.0, 2.0, 0.416518356706541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 613002.4067127772, 613002.4067127772, 175513.5447305596], 
processed observation next is [0.0, 0.17391304347826086, 0.3293838862559243, 0.9033333333333333, 1.0, 1.0, 0.29701006832113375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17027844630910477, 0.17027844630910477, 0.2619605145232233], 
reward next is 0.7380, 
noisyNet noise sample is [array([-0.42338678], dtype=float32), -1.0414902]. 
=============================================
[2019-03-26 20:42:31,939] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[66.064354]
 [65.94938 ]
 [65.899315]
 [65.869   ]
 [65.82216 ]], R is [[66.21230316]
 [66.28825378]
 [66.36330414]
 [66.43746185]
 [66.51070404]].
[2019-03-26 20:42:36,010] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.6913909e-09 0.0000000e+00], sum to 1.0000
[2019-03-26 20:42:36,020] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9458
[2019-03-26 20:42:36,028] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666667, 53.66666666666667, 1.0, 2.0, 0.4729709186584572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 660891.6254807549, 660891.6254807543, 179469.7601195881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6966600.0000, 
sim time next is 6967200.0000, 
raw observation next is [31.33333333333334, 55.33333333333334, 1.0, 2.0, 0.4751808813675474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 663980.6151790711, 663980.6151790704, 179798.9960230589], 
processed observation next is [0.0, 0.6521739130434783, 0.6840442338072673, 0.5533333333333335, 1.0, 1.0, 0.36768780887656316, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1844390597719642, 0.184439059771964, 0.26835671048217746], 
reward next is 0.7316, 
noisyNet noise sample is [array([0.33419284], dtype=float32), -0.6792623]. 
=============================================
[2019-03-26 20:42:36,039] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.4736913e-11 1.7681760e-33], sum to 1.0000
[2019-03-26 20:42:36,047] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2324
[2019-03-26 20:42:36,055] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.45, 52.0, 1.0, 2.0, 0.4579014458159271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 647568.229588663, 647568.2295886637, 178262.1412250422], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6960600.0000, 
sim time next is 6961200.0000, 
raw observation next is [31.26666666666667, 52.0, 1.0, 2.0, 0.4516574988904564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 643087.5587748671, 643087.5587748665, 177912.960581691], 
processed observation next is [0.0, 0.5652173913043478, 0.6808846761453398, 0.52, 1.0, 1.0, 0.3393463842053692, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17863543299301865, 0.17863543299301848, 0.2655417322114791], 
reward next is 0.7345, 
noisyNet noise sample is [array([0.5257453], dtype=float32), 0.97793704]. 
=============================================
[2019-03-26 20:42:40,501] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 20:42:40,503] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:42:40,503] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:42:40,504] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:42:40,503] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:42:40,504] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:42:40,506] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:42:40,506] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:42:40,507] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:42:40,508] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:42:40,504] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:42:40,534] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run34
[2019-03-26 20:42:40,553] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run34
[2019-03-26 20:42:40,584] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run34
[2019-03-26 20:42:40,606] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run34
[2019-03-26 20:42:40,607] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run34
[2019-03-26 20:42:43,786] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.007971859]
[2019-03-26 20:42:43,787] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.0, 96.0, 1.0, 2.0, 0.3711299105779521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 567008.1271868538, 567008.1271868545, 171966.7106981881]
[2019-03-26 20:42:43,789] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:42:43,791] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.3028835e-16 3.5618740e-37], sampled 0.4484572611451022
[2019-03-26 20:42:45,230] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.007971859]
[2019-03-26 20:42:45,234] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.34419990333333, 91.17240058666667, 1.0, 2.0, 0.2971554161203396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 479223.1867496327, 479223.1867496327, 165603.4581633066]
[2019-03-26 20:42:45,234] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:42:45,237] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6911120e-16 1.3641133e-38], sampled 0.08445563503212661
[2019-03-26 20:42:53,542] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.007971859]
[2019-03-26 20:42:53,544] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.6, 96.0, 1.0, 2.0, 0.3925001534882189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 588982.6796473247, 588982.6796473254, 173623.1385807835]
[2019-03-26 20:42:53,545] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:42:53,552] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.1076321e-16 5.2986576e-38], sampled 0.7737348299607395
[2019-03-26 20:42:57,345] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.007971859]
[2019-03-26 20:42:57,345] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [20.5, 88.5, 1.0, 2.0, 0.2838623207071004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 459649.234667621, 459649.234667621, 164237.067426398]
[2019-03-26 20:42:57,347] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:42:57,348] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6339191e-16 1.2633612e-38], sampled 0.023117199757590523
[2019-03-26 20:43:01,780] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.007971859]
[2019-03-26 20:43:01,784] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.11552543666667, 88.42638113833333, 1.0, 2.0, 0.5931227267126302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 828847.6270097368, 828847.6270097368, 199472.9828337947]
[2019-03-26 20:43:01,787] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:43:01,790] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1685255e-15 1.0161011e-36], sampled 0.35505709877724856
[2019-03-26 20:43:07,340] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.007971859]
[2019-03-26 20:43:07,343] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.41599941, 93.17812686666667, 1.0, 2.0, 0.375866210163673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 572576.3393942625, 572576.3393942631, 172405.9830516815]
[2019-03-26 20:43:07,346] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:43:07,349] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.2592956e-16 1.0702603e-37], sampled 0.1079953366451003
[2019-03-26 20:43:08,666] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.007971859]
[2019-03-26 20:43:08,667] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.65835812, 92.32396494333334, 1.0, 2.0, 0.345152749104966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 540344.1845452079, 540344.1845452072, 170065.8467613844]
[2019-03-26 20:43:08,670] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:43:08,673] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.8812911e-16 4.4763742e-38], sampled 0.16048026752145728
[2019-03-26 20:43:22,336] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.007971859]
[2019-03-26 20:43:22,337] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.6864237728453633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1055366.531807516, 1055366.531807515, 229960.76234144]
[2019-03-26 20:43:22,338] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:43:22,341] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.0784154e-38 1.0000000e+00 0.0000000e+00 7.8467032e-14 1.2062474e-32], sampled 0.3981255465434723
[2019-03-26 20:43:22,930] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.007971859]
[2019-03-26 20:43:22,932] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.80278608, 98.71597801, 1.0, 2.0, 0.3232107814144812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 507698.7310041908, 507698.7310041908, 167533.9866911893]
[2019-03-26 20:43:22,933] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:43:22,936] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.4139102e-16 3.0165284e-38], sampled 0.21097560641399982
[2019-03-26 20:43:47,529] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.007971859]
[2019-03-26 20:43:47,529] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 68.0, 1.0, 2.0, 0.9106114270254874, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.997159136116382, 6.9112, 168.9123723012221, 2169889.668476625, 2108907.509746622, 437350.0266311595]
[2019-03-26 20:43:47,530] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:43:47,533] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0453569e-28 1.0000000e+00 3.2200699e-30 1.2553115e-09 2.7343477e-24], sampled 0.38464663301023716
[2019-03-26 20:43:47,535] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2169889.668476625 W.
[2019-03-26 20:43:58,288] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.007971859]
[2019-03-26 20:43:58,290] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.08333333333334, 92.33333333333333, 1.0, 2.0, 0.5916375406498293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 826771.375346926, 826771.375346926, 199198.4885205289]
[2019-03-26 20:43:58,293] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:43:58,295] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.3758664e-15 4.4699478e-35], sampled 0.9291515810588399
[2019-03-26 20:44:04,386] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.007971859]
[2019-03-26 20:44:04,388] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.25, 62.0, 1.0, 2.0, 0.8374158315135615, 1.0, 1.0, 0.8374158315135615, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 172.86236624, 2342053.797176626, 2342053.797176625, 439001.729916719]
[2019-03-26 20:44:04,389] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:44:04,392] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.3761551e-31 1.0000000e+00 2.8242874e-33 3.0755735e-11 4.5252451e-27], sampled 0.440793751516653
[2019-03-26 20:44:04,395] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2342053.797176626 W.
[2019-03-26 20:44:16,646] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.007971859]
[2019-03-26 20:44:16,648] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.3, 79.0, 1.0, 2.0, 0.7231211896200421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1010597.840290804, 1010597.840290803, 225917.2807647505]
[2019-03-26 20:44:16,649] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:44:16,651] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.9912247e-15 2.5892387e-35], sampled 0.2797645966779365
[2019-03-26 20:44:31,864] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.007971859]
[2019-03-26 20:44:31,865] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.21666666666667, 85.5, 1.0, 2.0, 0.6570326166987376, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.022631466098272, 6.9112, 143.6817159167873, 1815276.572667684, 1748031.782791968, 372574.7749933337]
[2019-03-26 20:44:31,869] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:44:31,871] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.7812581e-28 1.0000000e+00 2.3449073e-29 3.6653529e-09 1.6882892e-23], sampled 0.6641472888501904
[2019-03-26 20:44:31,873] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1815276.572667684 W.
[2019-03-26 20:44:34,273] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7874.2549 3164933419.7733 1778.0000
[2019-03-26 20:44:35,004] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.7003 2928231904.9171 1338.0000
[2019-03-26 20:44:35,032] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.6078 3008551080.6251 1766.0000
[2019-03-26 20:44:35,112] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8657.3572 2780132369.7409 933.0000
[2019-03-26 20:44:35,233] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8493.5068 2843430346.4143 1131.0000
[2019-03-26 20:44:36,248] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 825000, evaluation results [825000.0, 7874.254934002473, 3164933419.7732573, 1778.0, 8253.700304448676, 2928231904.9170933, 1338.0, 8657.357172976928, 2780132369.740925, 933.0, 7997.607833681256, 3008551080.6250534, 1766.0, 8493.50677167813, 2843430346.4142575, 1131.0]
[2019-03-26 20:44:37,143] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.1222468e-24 0.0000000e+00], sum to 1.0000
[2019-03-26 20:44:37,152] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6424
[2019-03-26 20:44:37,158] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.46666666666667, 87.66666666666667, 1.0, 2.0, 0.4784223821799258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 668809.4186767162, 668809.4186767162, 180322.4065576535], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7080000.0000, 
sim time next is 7080600.0000, 
raw observation next is [25.43333333333333, 87.83333333333334, 1.0, 2.0, 0.4763658806335168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 666240.161627436, 666240.1616274355, 180053.5501212139], 
processed observation next is [1.0, 0.9565217391304348, 0.40442338072669815, 0.8783333333333334, 1.0, 1.0, 0.3691155188355624, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1850667115631767, 0.18506671156317653, 0.268736641971961], 
reward next is 0.7313, 
noisyNet noise sample is [array([-0.9606331], dtype=float32), -1.607768]. 
=============================================
[2019-03-26 20:44:40,209] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5692287e-24 9.9999917e-01 4.5882548e-26 8.5942702e-07 2.7544634e-19], sum to 1.0000
[2019-03-26 20:44:40,220] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6234
[2019-03-26 20:44:40,227] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1676907.750686751 W.
[2019-03-26 20:44:40,233] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.9, 71.0, 1.0, 2.0, 0.3998413840172431, 1.0, 2.0, 0.3998413840172431, 1.0, 1.0, 0.6711739937625928, 6.911200000000001, 6.9112, 170.5573041426782, 1676907.750686751, 1676907.75068675, 349461.5108036282], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7128000.0000, 
sim time next is 7128600.0000, 
raw observation next is [27.78333333333333, 71.83333333333334, 1.0, 2.0, 0.6280787264126705, 1.0, 2.0, 0.6280787264126705, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1756144.703708345, 1756144.703708345, 344841.6482327541], 
processed observation next is [1.0, 0.5217391304347826, 0.5157977883096366, 0.7183333333333334, 1.0, 1.0, 0.5519020800152656, 1.0, 1.0, 0.5519020800152656, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.48781797325231807, 0.48781797325231807, 0.5146890272130658], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1615038], dtype=float32), 1.6368781]. 
=============================================
[2019-03-26 20:44:44,074] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.2880974e-12 8.8857941e-34], sum to 1.0000
[2019-03-26 20:44:44,083] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3324
[2019-03-26 20:44:44,091] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 89.16666666666667, 1.0, 2.0, 0.6429331572530604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 898483.67006563, 898483.67006563, 209006.9241447223], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7182600.0000, 
sim time next is 7183200.0000, 
raw observation next is [25.8, 89.33333333333334, 1.0, 2.0, 0.5550310196432704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 775597.6895465234, 775597.6895465241, 192663.0975303033], 
processed observation next is [1.0, 0.13043478260869565, 0.42180094786729866, 0.8933333333333334, 1.0, 1.0, 0.46389279475092815, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21544380265181204, 0.21544380265181223, 0.2875568619855273], 
reward next is 0.7124, 
noisyNet noise sample is [array([0.88177216], dtype=float32), -0.3692742]. 
=============================================
[2019-03-26 20:44:54,254] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2331838e-21 0.0000000e+00], sum to 1.0000
[2019-03-26 20:44:54,263] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0209
[2019-03-26 20:44:54,270] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 77.0, 1.0, 2.0, 0.3941799265309842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 603844.4343416754, 603844.4343416754, 175278.5936769881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7354800.0000, 
sim time next is 7355400.0000, 
raw observation next is [24.43333333333333, 78.0, 1.0, 2.0, 0.4173523204465318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 638088.4572700417, 638088.4572700424, 178426.5306008872], 
processed observation next is [1.0, 0.13043478260869565, 0.3570300157977882, 0.78, 1.0, 1.0, 0.2980148439114841, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1772467936861227, 0.1772467936861229, 0.26630825462818986], 
reward next is 0.7337, 
noisyNet noise sample is [array([-2.068017], dtype=float32), -0.25701663]. 
=============================================
[2019-03-26 20:45:03,289] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 6.349914e-24 3.955306e-36], sum to 1.0000
[2019-03-26 20:45:03,299] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9792
[2019-03-26 20:45:03,305] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.15, 90.0, 1.0, 2.0, 0.3728689970565986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 563456.4493623809, 563456.4493623809, 171472.3764390005], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7536600.0000, 
sim time next is 7537200.0000, 
raw observation next is [23.2, 90.0, 1.0, 2.0, 0.374328916147929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 564747.1899638186, 564747.1899638181, 171555.5652551689], 
processed observation next is [0.0, 0.21739130434782608, 0.29857819905213273, 0.9, 1.0, 1.0, 0.2461794170456976, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15687421943439406, 0.15687421943439392, 0.25605308247040137], 
reward next is 0.7439, 
noisyNet noise sample is [array([0.15215601], dtype=float32), -0.37863743]. 
=============================================
[2019-03-26 20:45:04,902] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3629926e-34 1.0000000e+00 7.2103815e-36 2.8307510e-16 1.2304659e-24], sum to 1.0000
[2019-03-26 20:45:04,913] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4139
[2019-03-26 20:45:04,921] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2587603.203969482 W.
[2019-03-26 20:45:04,928] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.13333333333333, 60.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.312600073994239, 6.9112, 168.9106321297878, 2587603.203969482, 2302840.094981178, 476104.5216707885], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7746000.0000, 
sim time next is 7746600.0000, 
raw observation next is [31.01666666666667, 60.83333333333334, 1.0, 2.0, 0.5747012635799811, 1.0, 1.0, 0.5747012635799811, 1.0, 2.0, 0.9829163166141266, 6.911200000000001, 6.9112, 170.5573041426782, 2411051.63020947, 2411051.630209469, 467428.3840518942], 
processed observation next is [1.0, 0.6521739130434783, 0.6690363349131123, 0.6083333333333334, 1.0, 1.0, 0.4875918838313025, 1.0, 0.5, 0.4875918838313025, 1.0, 1.0, 0.9791662397733251, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.669736563947075, 0.6697365639470747, 0.6976543045550659], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1904713], dtype=float32), 0.34838265]. 
=============================================
[2019-03-26 20:45:05,085] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.1938464e-20 0.0000000e+00], sum to 1.0000
[2019-03-26 20:45:05,098] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4785
[2019-03-26 20:45:05,108] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 76.5, 1.0, 2.0, 0.4702476916781942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 657085.2296747924, 657085.2296747918, 179066.041318213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7554600.0000, 
sim time next is 7555200.0000, 
raw observation next is [27.53333333333333, 75.66666666666666, 1.0, 2.0, 0.4717161429883107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 659137.7586540052, 659137.7586540047, 179283.6296646017], 
processed observation next is [0.0, 0.43478260869565216, 0.5039494470774091, 0.7566666666666666, 1.0, 1.0, 0.3635134252871214, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18309382184833478, 0.18309382184833461, 0.2675875069620921], 
reward next is 0.7324, 
noisyNet noise sample is [array([-1.3731905], dtype=float32), -1.4317418]. 
=============================================
[2019-03-26 20:45:07,721] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.5080927e-20 0.0000000e+00], sum to 1.0000
[2019-03-26 20:45:07,730] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4867
[2019-03-26 20:45:07,736] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.83333333333333, 61.5, 1.0, 2.0, 0.458272404193082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 641912.5485249424, 641912.548524943, 177519.9782074696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7570200.0000, 
sim time next is 7570800.0000, 
raw observation next is [30.0, 62.0, 1.0, 2.0, 0.4670701675409974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 652643.8563759451, 652643.8563759451, 178598.1383882726], 
processed observation next is [0.0, 0.6521739130434783, 0.6208530805687204, 0.62, 1.0, 1.0, 0.35791586450722573, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18128996010442922, 0.18128996010442922, 0.2665643856541382], 
reward next is 0.7334, 
noisyNet noise sample is [array([2.4550846], dtype=float32), -0.5584859]. 
=============================================
[2019-03-26 20:45:09,472] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.8003240e-16 1.1206272e-36], sum to 1.0000
[2019-03-26 20:45:09,485] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2098
[2019-03-26 20:45:09,494] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.65, 89.33333333333334, 1.0, 2.0, 0.6426093189449883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 898030.9224663615, 898030.9224663615, 208942.2316539853], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7791000.0000, 
sim time next is 7791600.0000, 
raw observation next is [25.6, 89.66666666666667, 1.0, 2.0, 0.5998932225081471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 838312.6562606614, 838312.656260662, 200718.202091726], 
processed observation next is [1.0, 0.17391304347826086, 0.4123222748815167, 0.8966666666666667, 1.0, 1.0, 0.5179436415760809, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23286462673907263, 0.2328646267390728, 0.29957940610705375], 
reward next is 0.7004, 
noisyNet noise sample is [array([-1.2858682], dtype=float32), 0.631219]. 
=============================================
[2019-03-26 20:45:14,820] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 1.893135e-13 9.317602e-33], sum to 1.0000
[2019-03-26 20:45:14,829] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8187
[2019-03-26 20:45:14,835] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 94.0, 1.0, 2.0, 0.4839619989981175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 680227.970374999, 680227.9703749996, 181632.8029373225], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7707600.0000, 
sim time next is 7708200.0000, 
raw observation next is [24.66666666666667, 93.50000000000001, 1.0, 2.0, 0.5144899568696594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 720863.7082075112, 720863.7082075119, 186144.7597249588], 
processed observation next is [1.0, 0.21739130434782608, 0.36808846761453423, 0.9350000000000002, 1.0, 1.0, 0.4150481408068185, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2002399189465309, 0.2002399189465311, 0.2778279995894907], 
reward next is 0.7222, 
noisyNet noise sample is [array([1.8139713], dtype=float32), -1.0832078]. 
=============================================
[2019-03-26 20:45:16,822] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.1845053e-25 1.0000000e+00 4.3745366e-28 4.5804438e-10 1.9363988e-18], sum to 1.0000
[2019-03-26 20:45:16,828] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8820
[2019-03-26 20:45:16,837] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2247627.278228564 W.
[2019-03-26 20:45:16,844] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.3, 63.0, 1.0, 2.0, 0.803673346289486, 1.0, 1.0, 0.803673346289486, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2247627.278228564, 2247627.278228564, 421653.3250387987], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7750800.0000, 
sim time next is 7751400.0000, 
raw observation next is [30.13333333333333, 64.16666666666667, 1.0, 2.0, 0.3488019946352044, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5885742150534586, 6.911200000000001, 6.9112, 168.9129564988923, 974919.9141144776, 974919.914114477, 236810.2124342005], 
processed observation next is [1.0, 0.7391304347826086, 0.6271721958925749, 0.6416666666666667, 1.0, 1.0, 0.215424089921933, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.4982612378700715, 8.881784197001253e-17, 0.0, 0.8294399450956423, 0.27081108725402153, 0.27081108725402137, 0.35344807826000074], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.112531], dtype=float32), 0.58535725]. 
=============================================
[2019-03-26 20:45:17,320] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.2973654e-23 9.9989235e-01 7.0804078e-23 1.0766439e-04 1.1416362e-19], sum to 1.0000
[2019-03-26 20:45:17,334] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1007
[2019-03-26 20:45:17,348] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2289324.2440199 W.
[2019-03-26 20:45:17,353] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.5, 62.33333333333334, 1.0, 2.0, 0.9959435092442908, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.974323148437224, 6.9112, 168.9125807242082, 2289324.2440199, 2244542.609614831, 463143.5699457467], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7749600.0000, 
sim time next is 7750200.0000, 
raw observation next is [30.4, 62.66666666666666, 1.0, 2.0, 1.010906375406937, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.970989644226503, 6.9112, 168.9125495756534, 2310267.576807024, 2267850.847580041, 467855.2940568507], 
processed observation next is [1.0, 0.6956521739130435, 0.6398104265402843, 0.6266666666666666, 1.0, 1.0, 1.013140211333659, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.005978964422650268, 0.0, 0.8294379469162492, 0.6417409935575067, 0.6299585687722336, 0.6982914836669414], 
reward next is 0.0028, 
noisyNet noise sample is [array([0.74092245], dtype=float32), -0.7602627]. 
=============================================
[2019-03-26 20:45:18,349] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:45:18,350] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:45:18,385] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run5
[2019-03-26 20:45:19,859] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:45:19,860] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:45:19,887] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run5
[2019-03-26 20:45:20,405] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0449633e-23 9.9135756e-01 2.3509002e-25 8.6423885e-03 5.6163587e-15], sum to 1.0000
[2019-03-26 20:45:20,412] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3779
[2019-03-26 20:45:20,418] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1812977.540113598 W.
[2019-03-26 20:45:20,422] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.2, 79.5, 1.0, 2.0, 0.6555844503505441, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.98534860541117, 6.9112, 168.9125144024416, 1812977.540113598, 1760374.10511997, 376072.6005285073], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7807800.0000, 
sim time next is 7808400.0000, 
raw observation next is [28.3, 79.0, 1.0, 2.0, 0.4074708823383705, 1.0, 1.0, 0.4074708823383705, 1.0, 2.0, 0.6995428892316515, 6.9112, 6.9112, 170.5573041426782, 1708930.864702475, 1708930.864702475, 355900.8251301261], 
processed observation next is [1.0, 0.391304347826087, 0.5402843601895735, 0.79, 1.0, 1.0, 0.28610949679321745, 1.0, 0.5, 0.28610949679321745, 1.0, 1.0, 0.6335888893068922, 0.0, 0.0, 0.8375144448122397, 0.4747030179729097, 0.4747030179729097, 0.5311952613882479], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.18515077], dtype=float32), 1.5609099]. 
=============================================
[2019-03-26 20:45:23,489] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:45:23,490] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:45:23,531] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run5
[2019-03-26 20:45:23,661] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4954037e-23 9.9823844e-01 7.8021468e-26 1.7616040e-03 6.4413236e-17], sum to 1.0000
[2019-03-26 20:45:23,666] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5183
[2019-03-26 20:45:23,676] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2201448.026074077 W.
[2019-03-26 20:45:23,680] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.33333333333334, 68.0, 1.0, 2.0, 0.5247842454185982, 1.0, 2.0, 0.5247842454185982, 1.0, 1.0, 0.9054045074084736, 6.911199999999999, 6.9112, 170.5573041426782, 2201448.026074077, 2201448.026074078, 431568.588262291], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7915200.0000, 
sim time next is 7915800.0000, 
raw observation next is [30.36666666666666, 67.5, 1.0, 2.0, 0.524476395985893, 1.0, 2.0, 0.524476395985893, 1.0, 2.0, 0.9046869812797739, 6.911200000000001, 6.9112, 170.5573041426782, 2200155.284204906, 2200155.284204905, 431310.8943386111], 
processed observation next is [1.0, 0.6086956521739131, 0.6382306477093204, 0.675, 1.0, 1.0, 0.4270799951637265, 1.0, 1.0, 0.4270799951637265, 1.0, 1.0, 0.8837646113167973, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6111542456124739, 0.6111542456124736, 0.6437476034904643], 
reward next is 0.3563, 
noisyNet noise sample is [array([-0.391173], dtype=float32), -1.1709936]. 
=============================================
[2019-03-26 20:45:26,258] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:45:26,259] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:45:26,303] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run5
[2019-03-26 20:45:27,059] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.1021167e-38 1.4161450e-01 0.0000000e+00 8.5838544e-01 8.6053710e-29], sum to 1.0000
[2019-03-26 20:45:27,063] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6851
[2019-03-26 20:45:27,069] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.25, 79.0, 1.0, 2.0, 0.2615902664146748, 1.0, 1.0, 0.2615902664146748, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 731072.2299619713, 731072.2299619713, 242887.3804992491], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7932600.0000, 
sim time next is 7933200.0000, 
raw observation next is [28.16666666666666, 79.66666666666667, 1.0, 2.0, 0.2618844118003648, 1.0, 2.0, 0.2618844118003648, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 731894.5651907506, 731894.5651907506, 242937.5856227361], 
processed observation next is [1.0, 0.8260869565217391, 0.5339652448657185, 0.7966666666666667, 1.0, 1.0, 0.11070411060284917, 1.0, 1.0, 0.11070411060284917, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.20330404588631962, 0.20330404588631962, 0.36259341137721807], 
reward next is 0.6374, 
noisyNet noise sample is [array([-0.5569004], dtype=float32), 0.40035805]. 
=============================================
[2019-03-26 20:45:27,291] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:45:27,293] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:45:27,322] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run5
[2019-03-26 20:45:27,825] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:45:27,827] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:45:27,852] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run5
[2019-03-26 20:45:28,037] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:45:28,037] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:45:28,063] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run5
[2019-03-26 20:45:28,093] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:45:28,095] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:45:28,109] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run5
[2019-03-26 20:45:28,533] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:45:28,534] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:45:28,552] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run5
[2019-03-26 20:45:28,588] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:45:28,589] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:45:28,606] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run5
[2019-03-26 20:45:28,621] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:45:28,623] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:45:28,634] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run5
[2019-03-26 20:45:28,657] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:45:28,658] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:45:28,681] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run5
[2019-03-26 20:45:28,702] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:45:28,706] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:45:28,715] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run5
[2019-03-26 20:45:28,785] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:45:28,785] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:45:28,788] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run5
[2019-03-26 20:45:28,942] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:45:28,942] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:45:28,944] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run5
[2019-03-26 20:45:29,001] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:45:29,001] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:45:29,002] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run5
[2019-03-26 20:45:30,552] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 20:45:30,560] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:45:30,560] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:45:30,561] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:45:30,561] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:45:30,560] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:45:30,563] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:45:30,562] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:45:30,562] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:45:30,564] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:45:30,567] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:45:30,585] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run35
[2019-03-26 20:45:30,585] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run35
[2019-03-26 20:45:30,622] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run35
[2019-03-26 20:45:30,624] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run35
[2019-03-26 20:45:30,657] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run35
[2019-03-26 20:45:50,479] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.045460675]
[2019-03-26 20:45:50,480] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.30286631, 93.25169237333333, 1.0, 2.0, 0.4332491128760608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 692469.8269800462, 692469.8269800462, 183637.4855703442]
[2019-03-26 20:45:50,481] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:45:50,484] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.7018505e-10 3.9948742e-33], sampled 0.9842014328580845
[2019-03-26 20:45:56,495] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.045460675]
[2019-03-26 20:45:56,497] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.60676944, 87.18844033, 1.0, 2.0, 0.9200747095848364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1286016.868882885, 1286016.868882885, 275520.3842509381]
[2019-03-26 20:45:56,498] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:45:56,501] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.7740140e-37 1.0000000e+00 0.0000000e+00 4.4666685e-08 2.5831496e-29], sampled 0.973625200097344
[2019-03-26 20:46:08,153] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.045460675]
[2019-03-26 20:46:08,154] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.0860296, 89.18349738, 1.0, 2.0, 0.4902391758273488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 687914.1509398469, 687914.1509398469, 182451.5890358495]
[2019-03-26 20:46:08,156] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:46:08,160] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.5855395e-11 5.2282516e-35], sampled 0.1272483572085944
[2019-03-26 20:46:46,333] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.045460675]
[2019-03-26 20:46:46,338] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.5, 75.0, 1.0, 2.0, 0.5538151683282866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 773898.0457974691, 773898.0457974698, 192456.7882176087]
[2019-03-26 20:46:46,340] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:46:46,344] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 8.9709434e-11 2.9825056e-34], sampled 0.33629280692078944
[2019-03-26 20:47:24,819] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7876.3391 3164548751.0494 1768.0000
[2019-03-26 20:47:25,157] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8494.1098 2843414596.5766 1130.0000
[2019-03-26 20:47:25,326] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8261.3910 2927530140.5753 1319.0000
[2019-03-26 20:47:25,346] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.7979 2779920135.0716 924.0000
[2019-03-26 20:47:25,361] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.9367 3008482456.9084 1764.0000
[2019-03-26 20:47:26,377] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 850000, evaluation results [850000.0, 7876.339125278887, 3164548751.0493984, 1768.0, 8261.39100827087, 2927530140.575255, 1319.0, 8658.797889512321, 2779920135.071585, 924.0, 7997.936664755855, 3008482456.908417, 1764.0, 8494.109836709371, 2843414596.5766215, 1130.0]
[2019-03-26 20:47:30,665] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 9.9707067e-01 0.0000000e+00 2.9293532e-03 7.3705766e-33], sum to 1.0000
[2019-03-26 20:47:30,675] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8644
[2019-03-26 20:47:30,681] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.86666666666667, 87.33333333333334, 1.0, 2.0, 0.3184106743305473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 503183.2770729339, 503183.2770729333, 167257.9517252924], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 220800.0000, 
sim time next is 221400.0000, 
raw observation next is [21.95, 87.0, 1.0, 2.0, 0.3201268575072396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 505418.0504865164, 505418.0504865164, 167417.2512629884], 
processed observation next is [0.0, 0.5652173913043478, 0.2393364928909953, 0.87, 1.0, 1.0, 0.18087573193643328, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14039390291292123, 0.14039390291292123, 0.24987649442237075], 
reward next is 0.7501, 
noisyNet noise sample is [array([-2.0891225], dtype=float32), 0.31847623]. 
=============================================
[2019-03-26 20:47:31,146] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1250117e-38 9.9976069e-01 0.0000000e+00 2.3927129e-04 4.0176645e-33], sum to 1.0000
[2019-03-26 20:47:31,155] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6542
[2019-03-26 20:47:31,164] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 90.0, 1.0, 2.0, 0.3837474741719324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 591120.1740616008, 591120.1740616008, 174207.1257026495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 99600.0000, 
sim time next is 100200.0000, 
raw observation next is [22.5, 90.0, 1.0, 2.0, 0.3810260201994432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 586932.2282260108, 586932.2282260101, 173833.5239642372], 
processed observation next is [1.0, 0.13043478260869565, 0.2654028436018958, 0.9, 1.0, 1.0, 0.2542482171077629, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16303673006278077, 0.16303673006278058, 0.25945302084214505], 
reward next is 0.7405, 
noisyNet noise sample is [array([-0.30456644], dtype=float32), -0.8735237]. 
=============================================
[2019-03-26 20:47:31,587] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.5048212e-37 1.0000000e+00 0.0000000e+00 1.8275713e-10 1.3266286e-33], sum to 1.0000
[2019-03-26 20:47:31,594] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4185
[2019-03-26 20:47:31,603] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.31666666666667, 89.0, 1.0, 2.0, 0.3437129169526595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 534126.1433099344, 534126.1433099338, 169468.9904006323], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 90600.0000, 
sim time next is 91200.0000, 
raw observation next is [22.33333333333334, 89.0, 1.0, 2.0, 0.3438353877293951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 534082.3449685606, 534082.3449685606, 169459.2737652238], 
processed observation next is [1.0, 0.043478260869565216, 0.2575039494470777, 0.89, 1.0, 1.0, 0.20944022617999408, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14835620693571128, 0.14835620693571128, 0.2529242892018266], 
reward next is 0.7471, 
noisyNet noise sample is [array([0.30584812], dtype=float32), -0.23106363]. 
=============================================
[2019-03-26 20:47:32,198] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.8233775e-08 8.7003465e-33], sum to 1.0000
[2019-03-26 20:47:32,208] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1855
[2019-03-26 20:47:32,213] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 75.0, 1.0, 2.0, 0.407138167310761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 663157.342125536, 663157.3421255352, 180406.5290903884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 381600.0000, 
sim time next is 382200.0000, 
raw observation next is [21.98333333333333, 74.5, 1.0, 2.0, 0.478043141022105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 778574.8402033462, 778574.8402033462, 191805.6140737044], 
processed observation next is [1.0, 0.43478260869565216, 0.24091627172195884, 0.745, 1.0, 1.0, 0.3711363144844638, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21627078894537394, 0.21627078894537394, 0.2862770359309021], 
reward next is 0.7137, 
noisyNet noise sample is [array([1.6797479], dtype=float32), 0.32737282]. 
=============================================
[2019-03-26 20:47:38,267] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 4.818586e-20 8.057862e-35], sum to 1.0000
[2019-03-26 20:47:38,277] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8077
[2019-03-26 20:47:38,281] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.03333333333333, 89.33333333333334, 1.0, 2.0, 0.2961501490464502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 473780.3036984643, 473780.3036984637, 165208.6884903521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 246000.0000, 
sim time next is 246600.0000, 
raw observation next is [21.0, 89.5, 1.0, 2.0, 0.2948494713123677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 471822.59639589, 471822.59639589, 165072.4082548655], 
processed observation next is [0.0, 0.8695652173913043, 0.19431279620853087, 0.895, 1.0, 1.0, 0.150421049773937, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13106183233219165, 0.13106183233219165, 0.24637672873860522], 
reward next is 0.7536, 
noisyNet noise sample is [array([-0.65121573], dtype=float32), -1.1919681]. 
=============================================
[2019-03-26 20:47:40,683] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 8.939701e-15 3.032053e-33], sum to 1.0000
[2019-03-26 20:47:40,694] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2641
[2019-03-26 20:47:40,706] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.95, 81.83333333333334, 1.0, 2.0, 0.2303358724793361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 380295.462992765, 380295.4629927656, 158986.5359185053], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 454200.0000, 
sim time next is 454800.0000, 
raw observation next is [20.0, 81.66666666666667, 1.0, 2.0, 0.2308156578175492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 380968.9817660752, 380968.9817660752, 159036.7521455919], 
processed observation next is [1.0, 0.2608695652173913, 0.1469194312796209, 0.8166666666666668, 1.0, 1.0, 0.07327187688861349, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1058247171572431, 0.1058247171572431, 0.2373682867844655], 
reward next is 0.7626, 
noisyNet noise sample is [array([-1.1952977], dtype=float32), 3.560042]. 
=============================================
[2019-03-26 20:47:42,934] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 2.490306e-10 0.000000e+00], sum to 1.0000
[2019-03-26 20:47:42,945] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2042
[2019-03-26 20:47:42,952] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 91.33333333333334, 1.0, 2.0, 0.2725676136235184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 440822.8523189685, 440822.8523189685, 162992.3844759037], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 281400.0000, 
sim time next is 282000.0000, 
raw observation next is [20.4, 90.66666666666667, 1.0, 2.0, 0.2773877877685151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 448052.7956005751, 448052.7956005757, 163469.7129210312], 
processed observation next is [0.0, 0.2608695652173913, 0.16587677725118483, 0.9066666666666667, 1.0, 1.0, 0.12938287682953623, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12445910988904864, 0.1244591098890488, 0.24398464615079282], 
reward next is 0.7560, 
noisyNet noise sample is [array([-2.898722], dtype=float32), 2.0178783]. 
=============================================
[2019-03-26 20:47:42,976] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[83.47264 ]
 [83.499596]
 [83.44272 ]
 [83.456505]
 [83.458   ]], R is [[83.35400391]
 [83.27719116]
 [83.20140839]
 [83.12666321]
 [83.05290985]].
[2019-03-26 20:47:45,444] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.3629469e-16 0.0000000e+00], sum to 1.0000
[2019-03-26 20:47:45,455] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8445
[2019-03-26 20:47:45,462] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 85.0, 1.0, 2.0, 0.2886586707403454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 462513.7222599693, 462513.72225997, 164432.0790236724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 329400.0000, 
sim time next is 330000.0000, 
raw observation next is [21.43333333333333, 85.33333333333333, 1.0, 2.0, 0.2878063677158854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 461361.9366500977, 461361.9366500982, 164355.0262740652], 
processed observation next is [0.0, 0.8260869565217391, 0.21484992101105835, 0.8533333333333333, 1.0, 1.0, 0.14193538279022339, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12815609351391602, 0.12815609351391616, 0.2453060093642764], 
reward next is 0.7547, 
noisyNet noise sample is [array([0.3815678], dtype=float32), 1.2921236]. 
=============================================
[2019-03-26 20:47:45,484] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[74.777596]
 [74.7523  ]
 [74.73274 ]
 [74.72212 ]
 [74.63142 ]], R is [[74.81278229]
 [74.81922913]
 [74.82549286]
 [74.83153534]
 [74.83726501]].
[2019-03-26 20:47:51,582] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.1684958e-12 1.0125383e-27], sum to 1.0000
[2019-03-26 20:47:51,589] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5909
[2019-03-26 20:47:51,595] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 85.0, 1.0, 2.0, 0.2376285661083507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 392091.3341572003, 392091.3341572003, 159676.3655643652], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 438600.0000, 
sim time next is 439200.0000, 
raw observation next is [19.6, 85.0, 1.0, 2.0, 0.2375883467431448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 392025.2315532363, 392025.2315532357, 159672.5643642883], 
processed observation next is [1.0, 0.08695652173913043, 0.127962085308057, 0.85, 1.0, 1.0, 0.08143174306402987, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10889589765367676, 0.10889589765367658, 0.2383172602452064], 
reward next is 0.7617, 
noisyNet noise sample is [array([-0.8045402], dtype=float32), -0.29829678]. 
=============================================
[2019-03-26 20:47:51,971] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.9094421e-10 3.7084727e-36], sum to 1.0000
[2019-03-26 20:47:51,980] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2067
[2019-03-26 20:47:51,984] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.63333333333333, 85.33333333333334, 1.0, 2.0, 0.2408108809142203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 396950.562634402, 396950.5626344027, 159993.4607243839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 434400.0000, 
sim time next is 435000.0000, 
raw observation next is [19.61666666666667, 85.16666666666667, 1.0, 2.0, 0.2397959677748113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 395445.2857745519, 395445.2857745519, 159890.7016942344], 
processed observation next is [1.0, 0.0, 0.12875197472353894, 0.8516666666666667, 1.0, 1.0, 0.08409152743953167, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.10984591271515332, 0.10984591271515332, 0.23864283834960356], 
reward next is 0.7614, 
noisyNet noise sample is [array([-1.8307664], dtype=float32), 0.6342343]. 
=============================================
[2019-03-26 20:47:51,995] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[69.173645]
 [69.24636 ]
 [69.40314 ]
 [69.81305 ]
 [70.96672 ]], R is [[69.15343475]
 [69.22309875]
 [69.29194641]
 [69.35997009]
 [69.42716217]].
[2019-03-26 20:47:55,909] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.2470961e-15 3.1415239e-35], sum to 1.0000
[2019-03-26 20:47:55,917] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6123
[2019-03-26 20:47:55,925] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.46666666666667, 83.5, 1.0, 2.0, 0.2371244943561485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 392546.6935223611, 392546.6935223617, 159545.2269239772], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 510600.0000, 
sim time next is 511200.0000, 
raw observation next is [19.4, 84.0, 1.0, 2.0, 0.2367450751573401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 391936.0690190203, 391936.0690190203, 159508.0170305053], 
processed observation next is [1.0, 0.9565217391304348, 0.11848341232227487, 0.84, 1.0, 1.0, 0.08041575320161458, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1088711302830612, 0.1088711302830612, 0.23807166720970938], 
reward next is 0.7619, 
noisyNet noise sample is [array([-0.13864575], dtype=float32), -0.11171521]. 
=============================================
[2019-03-26 20:47:55,968] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.3559527e-13 0.0000000e+00], sum to 1.0000
[2019-03-26 20:47:55,976] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2468
[2019-03-26 20:47:55,986] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.75, 70.5, 1.0, 2.0, 0.2499026127298319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 411276.6103205053, 411276.6103205059, 160891.6280815469], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 587400.0000, 
sim time next is 588000.0000, 
raw observation next is [21.6, 71.0, 1.0, 2.0, 0.2496570161819618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 411226.8252311549, 411226.8252311542, 160859.4074592386], 
processed observation next is [1.0, 0.8260869565217391, 0.22274881516587688, 0.71, 1.0, 1.0, 0.095972308652966, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1142296736753208, 0.11422967367532061, 0.24008866784960986], 
reward next is 0.7599, 
noisyNet noise sample is [array([0.92269516], dtype=float32), -1.0748925]. 
=============================================
[2019-03-26 20:47:55,999] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[79.81187]
 [79.9025 ]
 [79.76542]
 [79.77866]
 [79.8084 ]], R is [[79.79351044]
 [79.75543976]
 [79.71760559]
 [79.6798172 ]
 [79.6421051 ]].
[2019-03-26 20:47:58,999] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.0820417e-11 3.2390604e-34], sum to 1.0000
[2019-03-26 20:47:59,008] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7615
[2019-03-26 20:47:59,013] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 54.33333333333333, 1.0, 2.0, 0.5921154285601717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 968977.7556978606, 968977.75569786, 213881.6616905544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 562200.0000, 
sim time next is 562800.0000, 
raw observation next is [24.8, 54.66666666666667, 1.0, 2.0, 0.4082328409843701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 668352.9711337485, 668352.9711337485, 180665.8312832849], 
processed observation next is [1.0, 0.5217391304347826, 0.3744075829383887, 0.5466666666666667, 1.0, 1.0, 0.28702751925827724, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18565360309270793, 0.18565360309270793, 0.26965049445266404], 
reward next is 0.7303, 
noisyNet noise sample is [array([-1.3047371], dtype=float32), -0.23703232]. 
=============================================
[2019-03-26 20:48:01,378] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.9721733e-19 0.0000000e+00], sum to 1.0000
[2019-03-26 20:48:01,387] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0764
[2019-03-26 20:48:01,396] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 72.33333333333334, 1.0, 2.0, 0.3499500078984439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 577136.3519913014, 577136.351991302, 172492.5667516778], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 634800.0000, 
sim time next is 635400.0000, 
raw observation next is [21.5, 71.5, 1.0, 2.0, 0.3807037680022441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 627504.771609925, 627504.771609925, 176693.1715568655], 
processed observation next is [1.0, 0.34782608695652173, 0.21800947867298584, 0.715, 1.0, 1.0, 0.2538599614484869, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17430688100275693, 0.17430688100275693, 0.2637211515774112], 
reward next is 0.7363, 
noisyNet noise sample is [array([-0.75072175], dtype=float32), 0.005183677]. 
=============================================
[2019-03-26 20:48:01,460] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.2663166e-14 8.9776031e-37], sum to 1.0000
[2019-03-26 20:48:01,467] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4554
[2019-03-26 20:48:01,474] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.1, 87.0, 1.0, 2.0, 0.21592877989939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 360056.391797975, 360056.3917979744, 157132.8464596541], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 604800.0000, 
sim time next is 605400.0000, 
raw observation next is [18.03333333333333, 87.33333333333333, 1.0, 2.0, 0.2152333624153343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 358951.9704273189, 358951.9704273189, 157053.0264604676], 
processed observation next is [1.0, 0.0, 0.05371248025276459, 0.8733333333333333, 1.0, 1.0, 0.054498027006426863, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.09970888067425525, 0.09970888067425525, 0.23440750217980239], 
reward next is 0.7656, 
noisyNet noise sample is [array([-0.3529089], dtype=float32), -1.2691981]. 
=============================================
[2019-03-26 20:48:01,646] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.4739317e-16 0.0000000e+00], sum to 1.0000
[2019-03-26 20:48:01,660] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2192
[2019-03-26 20:48:01,664] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.73333333333333, 83.5, 1.0, 2.0, 0.2227071482667095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 370819.1397679032, 370819.1397679038, 157885.6006832933], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 600600.0000, 
sim time next is 601200.0000, 
raw observation next is [18.6, 84.0, 1.0, 2.0, 0.22190195719751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 369653.2720077017, 369653.2720077011, 157767.6579558848], 
processed observation next is [1.0, 1.0, 0.08056872037914704, 0.84, 1.0, 1.0, 0.06253247855121684, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1026814644465838, 0.10268146444658365, 0.23547411635206686], 
reward next is 0.7645, 
noisyNet noise sample is [array([1.5414674], dtype=float32), 0.30853465]. 
=============================================
[2019-03-26 20:48:01,805] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.6270765e-12 4.9902242e-34], sum to 1.0000
[2019-03-26 20:48:01,815] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7533
[2019-03-26 20:48:01,820] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.91666666666667, 48.16666666666666, 1.0, 2.0, 0.6114461933550479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1003030.436615798, 1003030.436615798, 218083.1726137713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 742200.0000, 
sim time next is 742800.0000, 
raw observation next is [25.83333333333334, 48.33333333333333, 1.0, 2.0, 0.5711676738858369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 937474.5379057351, 937474.5379057344, 209554.2178707939], 
processed observation next is [1.0, 0.6086956521739131, 0.42338072669826254, 0.4833333333333333, 1.0, 1.0, 0.4833345468504059, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2604095938627042, 0.260409593862704, 0.31276748935939386], 
reward next is 0.6872, 
noisyNet noise sample is [array([0.5213993], dtype=float32), -0.592077]. 
=============================================
[2019-03-26 20:48:09,883] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3995434e-10 0.0000000e+00], sum to 1.0000
[2019-03-26 20:48:09,892] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9689
[2019-03-26 20:48:09,899] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.56666666666667, 96.16666666666666, 1.0, 2.0, 0.3827724543523893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 574503.0928234248, 574503.0928234248, 172321.7144258202], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1043400.0000, 
sim time next is 1044000.0000, 
raw observation next is [22.6, 96.0, 1.0, 2.0, 0.3844018335886054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 576693.127541197, 576693.1275411964, 172509.1392122945], 
processed observation next is [1.0, 0.08695652173913043, 0.27014218009478685, 0.96, 1.0, 1.0, 0.2583154621549463, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16019253542811027, 0.16019253542811013, 0.2574763271825291], 
reward next is 0.7425, 
noisyNet noise sample is [array([-1.4878114], dtype=float32), 0.3429248]. 
=============================================
[2019-03-26 20:48:09,920] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[76.184845]
 [76.22395 ]
 [76.246025]
 [76.237114]
 [76.19368 ]], R is [[76.34363556]
 [76.32300568]
 [76.30276489]
 [76.28274536]
 [76.26292419]].
[2019-03-26 20:48:11,496] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 5.410397e-18 0.000000e+00], sum to 1.0000
[2019-03-26 20:48:11,504] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2940
[2019-03-26 20:48:11,510] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.4, 80.0, 1.0, 2.0, 0.2984134135397092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 475912.278578721, 475912.278578721, 165341.1375158966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 847800.0000, 
sim time next is 848400.0000, 
raw observation next is [22.33333333333334, 80.33333333333334, 1.0, 2.0, 0.297552861713451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 474741.94150616, 474741.94150616, 165261.1024417164], 
processed observation next is [0.0, 0.8260869565217391, 0.2575039494470777, 0.8033333333333335, 1.0, 1.0, 0.15367814664271207, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1318727615294889, 0.1318727615294889, 0.24665836185330803], 
reward next is 0.7533, 
noisyNet noise sample is [array([1.5443462], dtype=float32), 0.503593]. 
=============================================
[2019-03-26 20:48:17,219] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3137478e-12 0.0000000e+00], sum to 1.0000
[2019-03-26 20:48:17,234] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5033
[2019-03-26 20:48:17,238] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.65, 95.5, 1.0, 2.0, 0.5313514610631803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 822365.051914735, 822365.0519147357, 198156.9302293351], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 999000.0000, 
sim time next is 999600.0000, 
raw observation next is [21.63333333333333, 95.66666666666667, 1.0, 2.0, 0.5612675163992599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 868538.8901138138, 868538.8901138138, 203809.6542918139], 
processed observation next is [1.0, 0.5652173913043478, 0.2243285939968403, 0.9566666666666667, 1.0, 1.0, 0.4714066462641685, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24126080280939272, 0.24126080280939272, 0.30419351386837895], 
reward next is 0.6958, 
noisyNet noise sample is [array([0.4315348], dtype=float32), 0.85519195]. 
=============================================
[2019-03-26 20:48:20,575] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.4609730e-17 7.1355104e-38], sum to 1.0000
[2019-03-26 20:48:20,584] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3672
[2019-03-26 20:48:20,589] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 95.0, 1.0, 2.0, 0.3432621314945186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 529967.3369254038, 529967.3369254038, 169034.8521152187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 954600.0000, 
sim time next is 955200.0000, 
raw observation next is [21.8, 95.0, 1.0, 2.0, 0.3426359610186044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 528995.1205086668, 528995.1205086668, 168956.2888355418], 
processed observation next is [1.0, 0.043478260869565216, 0.23222748815165886, 0.95, 1.0, 1.0, 0.20799513375735468, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14694308903018524, 0.14694308903018524, 0.2521735654261818], 
reward next is 0.7478, 
noisyNet noise sample is [array([0.25605014], dtype=float32), 2.1746786]. 
=============================================
[2019-03-26 20:48:21,838] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.5313474e-14 4.7002124e-37], sum to 1.0000
[2019-03-26 20:48:21,849] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5710
[2019-03-26 20:48:21,852] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 76.66666666666667, 1.0, 2.0, 0.9627624593586369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1386511.577371322, 1386511.577371322, 293996.219844892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1244400.0000, 
sim time next is 1245000.0000, 
raw observation next is [26.6, 75.83333333333333, 1.0, 2.0, 0.9844087125408639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1413843.379648927, 1413843.379648927, 300052.910774734], 
processed observation next is [1.0, 0.391304347826087, 0.4597156398104266, 0.7583333333333333, 1.0, 1.0, 0.9812153163142939, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3927342721247019, 0.3927342721247019, 0.44784016533542387], 
reward next is 0.5522, 
noisyNet noise sample is [array([-0.6117316], dtype=float32), -1.8173692]. 
=============================================
[2019-03-26 20:48:21,874] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[68.26132 ]
 [68.42023 ]
 [68.409195]
 [68.7366  ]
 [68.63417 ]], R is [[68.06638336]
 [67.9469223 ]
 [67.83990479]
 [67.73355103]
 [67.6468811 ]].
[2019-03-26 20:48:22,202] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 20:48:22,204] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:48:22,204] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:48:22,205] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:48:22,206] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:48:22,206] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:48:22,206] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:48:22,207] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:48:22,207] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:48:22,208] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:48:22,209] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:48:22,229] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run36
[2019-03-26 20:48:22,249] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run36
[2019-03-26 20:48:22,250] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run36
[2019-03-26 20:48:22,292] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run36
[2019-03-26 20:48:22,293] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run36
[2019-03-26 20:48:29,618] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.040818956]
[2019-03-26 20:48:29,620] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.50298993, 76.58616857166666, 1.0, 2.0, 0.2545803065270565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 420117.6473921646, 420117.6473921652, 161321.4690810231]
[2019-03-26 20:48:29,620] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:48:29,624] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 3.189031e-16 0.000000e+00], sampled 0.7281626307356931
[2019-03-26 20:48:34,000] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.040818956]
[2019-03-26 20:48:34,002] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.2, 60.66666666666667, 1.0, 2.0, 0.4601105387390205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 642916.1243251144, 642916.124325115, 177583.0442719002]
[2019-03-26 20:48:34,004] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:48:34,007] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.3570574e-17 0.0000000e+00], sampled 0.16971112990162251
[2019-03-26 20:48:52,506] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.040818956]
[2019-03-26 20:48:52,507] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.01666666666667, 92.83333333333333, 1.0, 2.0, 0.4940152579731356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 690306.851622809, 690306.8516228095, 182662.9616250041]
[2019-03-26 20:48:52,508] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:48:52,511] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6725261e-16 0.0000000e+00], sampled 0.10301151355553562
[2019-03-26 20:48:52,840] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.040818956]
[2019-03-26 20:48:52,842] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.21828182, 100.0, 1.0, 2.0, 0.4980262206956388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 695913.3626489796, 695913.3626489802, 183286.706516056]
[2019-03-26 20:48:52,843] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:48:52,846] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7743536e-16 0.0000000e+00], sampled 0.8560746811137337
[2019-03-26 20:48:53,986] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.040818956]
[2019-03-26 20:48:53,987] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.51249777, 94.93504324, 1.0, 2.0, 0.5536077780800014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 773608.134354638, 773608.1343546386, 192421.0612007734]
[2019-03-26 20:48:53,990] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:48:53,992] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.10441006e-16
 0.00000000e+00], sampled 0.7533200882559584
[2019-03-26 20:48:57,446] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.040818956]
[2019-03-26 20:48:57,446] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.5, 94.0, 1.0, 2.0, 0.3827968489730174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 580759.6817606973, 580759.6817606973, 173064.4348713016]
[2019-03-26 20:48:57,447] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:48:57,452] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.9901025e-16 0.0000000e+00], sampled 0.6627639496131965
[2019-03-26 20:49:03,076] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.040818956]
[2019-03-26 20:49:03,077] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.95, 52.5, 1.0, 2.0, 0.9321104843129363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1302849.965528699, 1302849.965528698, 278921.5508193385]
[2019-03-26 20:49:03,079] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:49:03,081] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 8.1512765e-16 6.1598827e-38], sampled 0.4460868222672676
[2019-03-26 20:49:08,620] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.040818956]
[2019-03-26 20:49:08,622] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.73333333333333, 69.83333333333333, 1.0, 2.0, 0.5636859488495742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 787696.5306555631, 787696.5306555631, 194175.3103084056]
[2019-03-26 20:49:08,623] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:49:08,625] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.0447924e-17 0.0000000e+00], sampled 0.34448299401706706
[2019-03-26 20:49:08,880] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.040818956]
[2019-03-26 20:49:08,881] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [32.00084598833333, 71.49784611833333, 1.0, 2.0, 0.6036793558927813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 843605.6382344458, 843605.6382344452, 201434.1778937926]
[2019-03-26 20:49:08,882] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:49:08,886] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.9880538e-16 0.0000000e+00], sampled 0.5973392389695911
[2019-03-26 20:49:10,874] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.040818956]
[2019-03-26 20:49:10,875] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.981605445, 90.67264947000001, 1.0, 2.0, 0.6113568857929168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 854338.8401109033, 854338.8401109033, 202878.7201904071]
[2019-03-26 20:49:10,876] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:49:10,882] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6180222e-16 0.0000000e+00], sampled 0.38711450814075143
[2019-03-26 20:49:18,583] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.040818956]
[2019-03-26 20:49:18,585] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.66666666666666, 72.33333333333333, 1.0, 2.0, 0.605403271208467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 846015.6657879984, 846015.665787999, 201757.0875099954]
[2019-03-26 20:49:18,586] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:49:18,591] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 2.998388e-17 0.000000e+00], sampled 0.8861521916165268
[2019-03-26 20:49:34,501] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.040818956]
[2019-03-26 20:49:34,503] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.66666666666667, 79.66666666666666, 1.0, 2.0, 0.5895464429912006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 823848.081840867, 823848.081840867, 198813.9713125009]
[2019-03-26 20:49:34,504] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:49:34,505] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.05059224e-16
 0.00000000e+00], sampled 0.5444993778490167
[2019-03-26 20:49:38,513] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.040818956]
[2019-03-26 20:49:38,516] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [34.74060128333333, 54.20715804333334, 1.0, 2.0, 0.5994614429285191, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.923756716247718, 6.9112, 168.9127863330956, 1676079.297823491, 1667171.140123388, 364469.1601440799]
[2019-03-26 20:49:38,516] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:49:38,521] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5747751e-16 0.0000000e+00], sampled 0.37945334440290635
[2019-03-26 20:49:38,522] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1676079.297823491 W.
[2019-03-26 20:49:44,490] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.040818956]
[2019-03-26 20:49:44,492] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.36666666666667, 94.0, 1.0, 2.0, 0.6231605543561598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 870840.6035108891, 870840.6035108891, 205139.630513438]
[2019-03-26 20:49:44,494] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:49:44,497] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.5043773e-17 0.0000000e+00], sampled 0.6853700292454169
[2019-03-26 20:49:53,197] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.040818956]
[2019-03-26 20:49:53,199] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.8, 76.0, 1.0, 2.0, 0.5391995524211833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 753467.0267013926, 753467.0267013926, 189965.0309933735]
[2019-03-26 20:49:53,200] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:49:53,203] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.6334304e-17 0.0000000e+00], sampled 0.1351582658649817
[2019-03-26 20:49:55,330] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.040818956]
[2019-03-26 20:49:55,330] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.35, 73.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.396318442155311, 6.9112, 168.9101492845756, 1798144.647011047, 1453990.647373399, 311352.968396439]
[2019-03-26 20:49:55,332] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:49:55,334] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.2852287e-14 1.5442491e-34], sampled 0.31489827481407684
[2019-03-26 20:49:55,336] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1798144.647011047 W.
[2019-03-26 20:50:16,801] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7876.6154 3164676497.9081 1778.0000
[2019-03-26 20:50:16,922] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.9641 2779935595.8501 933.0000
[2019-03-26 20:50:17,099] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.9766 3008303976.5521 1766.0000
[2019-03-26 20:50:17,140] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.8629 2843167093.8007 1131.0000
[2019-03-26 20:50:17,169] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.0740 2927981547.8413 1338.0000
[2019-03-26 20:50:18,185] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 875000, evaluation results [875000.0, 7876.615402862808, 3164676497.9080544, 1778.0, 8254.073971726037, 2927981547.8412614, 1338.0, 8658.964140262613, 2779935595.8500915, 933.0, 7997.976645730424, 3008303976.5521116, 1766.0, 8495.862932155293, 2843167093.8007364, 1131.0]
[2019-03-26 20:50:32,762] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 5.374815e-12 1.298336e-34], sum to 1.0000
[2019-03-26 20:50:32,768] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2940
[2019-03-26 20:50:32,775] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.75, 94.33333333333334, 1.0, 2.0, 0.3727137809671536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 577912.448543163, 577912.448543163, 173118.2213656409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1228200.0000, 
sim time next is 1228800.0000, 
raw observation next is [21.9, 93.66666666666667, 1.0, 2.0, 0.3507683142374582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 542852.3509460131, 542852.3509460137, 170122.107738015], 
processed observation next is [1.0, 0.21739130434782608, 0.23696682464454974, 0.9366666666666668, 1.0, 1.0, 0.21779314968368457, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15079231970722587, 0.15079231970722604, 0.25391359363882837], 
reward next is 0.7461, 
noisyNet noise sample is [array([0.2679654], dtype=float32), -0.49525914]. 
=============================================
[2019-03-26 20:50:33,640] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.5085538e-16 3.4523656e-37], sum to 1.0000
[2019-03-26 20:50:33,647] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3286
[2019-03-26 20:50:33,652] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 90.0, 1.0, 2.0, 0.338512519037039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 527088.408291667, 527088.4082916677, 168931.7885704193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1216800.0000, 
sim time next is 1217400.0000, 
raw observation next is [22.06666666666667, 90.33333333333333, 1.0, 2.0, 0.4521071560793938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 704014.5907130953, 704014.5907130947, 185005.6770500243], 
processed observation next is [1.0, 0.08695652173913043, 0.2448657187993683, 0.9033333333333333, 1.0, 1.0, 0.3398881398546913, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19555960853141535, 0.19555960853141519, 0.27612787619406615], 
reward next is 0.7239, 
noisyNet noise sample is [array([-0.64272594], dtype=float32), -0.9665392]. 
=============================================
[2019-03-26 20:50:40,254] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6844282e-17 2.2663040e-36], sum to 1.0000
[2019-03-26 20:50:40,263] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7023
[2019-03-26 20:50:40,269] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 85.0, 1.0, 2.0, 0.808003420546072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1225805.69447403, 1225805.694474031, 258861.4250405442], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1593600.0000, 
sim time next is 1594200.0000, 
raw observation next is [23.68333333333333, 85.0, 1.0, 2.0, 0.8268311027735775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1253689.908224907, 1253689.908224907, 263925.0723206759], 
processed observation next is [1.0, 0.43478260869565216, 0.32148499210110576, 0.85, 1.0, 1.0, 0.791362774425997, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.34824719672914084, 0.34824719672914084, 0.3939180183890685], 
reward next is 0.6061, 
noisyNet noise sample is [array([1.4766549], dtype=float32), 1.9703285]. 
=============================================
[2019-03-26 20:50:44,661] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4450328e-18 0.0000000e+00], sum to 1.0000
[2019-03-26 20:50:44,668] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6871
[2019-03-26 20:50:44,674] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.65, 98.0, 1.0, 2.0, 0.4341939420624599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 619786.8178648998, 619786.817864899, 175622.3809237987], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1668600.0000, 
sim time next is 1669200.0000, 
raw observation next is [23.66666666666667, 98.0, 1.0, 2.0, 0.4493481692295083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 640961.0280242809, 640961.0280242809, 177726.5250660207], 
processed observation next is [1.0, 0.30434782608695654, 0.3206951026856243, 0.98, 1.0, 1.0, 0.33656405931266065, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1780447300067447, 0.1780447300067447, 0.26526347024779207], 
reward next is 0.7347, 
noisyNet noise sample is [array([-0.5884155], dtype=float32), -0.4222748]. 
=============================================
[2019-03-26 20:50:51,073] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 7.371815e-18 0.000000e+00], sum to 1.0000
[2019-03-26 20:50:51,083] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9799
[2019-03-26 20:50:51,091] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 86.0, 1.0, 2.0, 0.7947320367797845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1214071.774762889, 1214071.77476289, 256314.6138661358], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1771200.0000, 
sim time next is 1771800.0000, 
raw observation next is [23.23333333333333, 85.83333333333334, 1.0, 2.0, 0.7594696038246377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1162191.58322926, 1162191.58322926, 247302.023874254], 
processed observation next is [1.0, 0.5217391304347826, 0.3001579778830963, 0.8583333333333334, 1.0, 1.0, 0.7102043419573948, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.32283099534146115, 0.32283099534146115, 0.36910749831978207], 
reward next is 0.6309, 
noisyNet noise sample is [array([-0.4209721], dtype=float32), -0.22312061]. 
=============================================
[2019-03-26 20:50:52,555] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.8467239e-14 1.5035115e-36], sum to 1.0000
[2019-03-26 20:50:52,564] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1397
[2019-03-26 20:50:52,573] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 85.0, 1.0, 2.0, 0.7575287462398848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1135957.378612038, 1135957.378612038, 244002.6636194027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1603200.0000, 
sim time next is 1603800.0000, 
raw observation next is [24.05, 85.0, 1.0, 2.0, 0.7897740726728175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1183587.757241845, 1183587.757241845, 252176.5898389725], 
processed observation next is [1.0, 0.5652173913043478, 0.3388625592417062, 0.85, 1.0, 1.0, 0.7467157502082139, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3287743770116236, 0.3287743770116236, 0.3763829699089142], 
reward next is 0.6236, 
noisyNet noise sample is [array([0.69933957], dtype=float32), 1.0350108]. 
=============================================
[2019-03-26 20:50:53,764] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 8.020006e-16 0.000000e+00], sum to 1.0000
[2019-03-26 20:50:53,774] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8634
[2019-03-26 20:50:53,779] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.35, 84.5, 1.0, 2.0, 0.3581996044590471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 549699.2639673849, 549699.2639673844, 170561.4200263185], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1542600.0000, 
sim time next is 1543200.0000, 
raw observation next is [23.26666666666667, 85.0, 1.0, 2.0, 0.3581687164955957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 549893.545817771, 549893.5458177704, 170584.802836403], 
processed observation next is [0.0, 0.8695652173913043, 0.3017377567140602, 0.85, 1.0, 1.0, 0.2267092969826454, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15274820717160306, 0.1527482071716029, 0.2546041833379149], 
reward next is 0.7454, 
noisyNet noise sample is [array([0.5868691], dtype=float32), 1.0929424]. 
=============================================
[2019-03-26 20:50:54,077] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 4.801082e-20 0.000000e+00], sum to 1.0000
[2019-03-26 20:50:54,087] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6563
[2019-03-26 20:50:54,091] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 91.0, 1.0, 2.0, 0.3421657492197361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 531002.4731346571, 531002.4731346571, 169197.6043721182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1551600.0000, 
sim time next is 1552200.0000, 
raw observation next is [22.06666666666667, 91.00000000000001, 1.0, 2.0, 0.3411531859773741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 529851.4239202309, 529851.4239202302, 169116.6463757893], 
processed observation next is [0.0, 1.0, 0.2448657187993683, 0.9100000000000001, 1.0, 1.0, 0.20620865780406517, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14718095108895304, 0.14718095108895285, 0.2524129050384915], 
reward next is 0.7476, 
noisyNet noise sample is [array([1.6738191], dtype=float32), -0.080965795]. 
=============================================
[2019-03-26 20:50:57,274] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1223022e-17 0.0000000e+00], sum to 1.0000
[2019-03-26 20:50:57,284] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6681
[2019-03-26 20:50:57,290] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.41666666666666, 94.33333333333334, 1.0, 2.0, 0.3335875844193171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 521827.7258664079, 521827.7258664072, 168577.0882926433], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1807800.0000, 
sim time next is 1808400.0000, 
raw observation next is [21.43333333333333, 94.66666666666667, 1.0, 2.0, 0.3361926734803173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 525136.4967936483, 525136.4967936483, 168819.4305102034], 
processed observation next is [1.0, 0.9565217391304348, 0.21484992101105835, 0.9466666666666668, 1.0, 1.0, 0.20023213672327383, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14587124910934676, 0.14587124910934676, 0.25196929926896033], 
reward next is 0.7480, 
noisyNet noise sample is [array([0.09911839], dtype=float32), 0.2131776]. 
=============================================
[2019-03-26 20:50:59,752] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 9.549204e-16 0.000000e+00], sum to 1.0000
[2019-03-26 20:50:59,761] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7658
[2019-03-26 20:50:59,767] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 98.0, 1.0, 2.0, 0.4211168896421672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 614692.7642501778, 614692.7642501778, 175530.9628274303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1641000.0000, 
sim time next is 1641600.0000, 
raw observation next is [23.1, 98.0, 1.0, 2.0, 0.4209252236900972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 614413.0298833767, 614413.0298833773, 175504.1799133219], 
processed observation next is [1.0, 0.0, 0.2938388625592418, 0.98, 1.0, 1.0, 0.30231954661457494, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17067028607871573, 0.1706702860787159, 0.2619465371840625], 
reward next is 0.7381, 
noisyNet noise sample is [array([0.1889677], dtype=float32), 0.36179385]. 
=============================================
[2019-03-26 20:51:00,942] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.0652615e-17 3.0203543e-36], sum to 1.0000
[2019-03-26 20:51:00,950] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0180
[2019-03-26 20:51:00,956] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.28333333333333, 94.66666666666667, 1.0, 2.0, 0.9093030040862334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1285945.528602892, 1285945.528602891, 274744.5653379023], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1673400.0000, 
sim time next is 1674000.0000, 
raw observation next is [24.4, 94.0, 1.0, 2.0, 0.9075780463729445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1281737.819993569, 1281737.819993569, 273997.0819213995], 
processed observation next is [1.0, 0.391304347826087, 0.3554502369668246, 0.94, 1.0, 1.0, 0.8886482486421018, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.35603828333154697, 0.35603828333154697, 0.40895086853940227], 
reward next is 0.5910, 
noisyNet noise sample is [array([-0.5101355], dtype=float32), 0.35615623]. 
=============================================
[2019-03-26 20:51:00,969] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[63.93846 ]
 [64.254684]
 [64.75771 ]
 [65.876656]
 [67.99531 ]], R is [[63.89787674]
 [63.84883499]
 [63.80766296]
 [63.77772522]
 [63.78089142]].
[2019-03-26 20:51:06,251] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.8247850e-13 4.5021543e-35], sum to 1.0000
[2019-03-26 20:51:06,260] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1698
[2019-03-26 20:51:06,268] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 93.0, 1.0, 2.0, 0.4871256155342776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 688954.6414912388, 688954.6414912394, 182666.2265049748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1749600.0000, 
sim time next is 1750200.0000, 
raw observation next is [24.56666666666667, 92.66666666666667, 1.0, 2.0, 0.5490223477861003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 775670.7534867938, 775670.7534867938, 192719.2377094287], 
processed observation next is [1.0, 0.2608695652173913, 0.3633491311216432, 0.9266666666666667, 1.0, 1.0, 0.45665343106759065, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21546409819077605, 0.21546409819077605, 0.2876406532976548], 
reward next is 0.7124, 
noisyNet noise sample is [array([-0.9668242], dtype=float32), 0.45623383]. 
=============================================
[2019-03-26 20:51:06,574] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.7421443e-16 1.8462553e-37], sum to 1.0000
[2019-03-26 20:51:06,587] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6230
[2019-03-26 20:51:06,593] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.21666666666667, 87.00000000000001, 1.0, 2.0, 0.8346412022571453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1228578.621944959, 1228578.621944959, 261279.0360663521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1764600.0000, 
sim time next is 1765200.0000, 
raw observation next is [24.13333333333334, 86.0, 1.0, 2.0, 0.8258029945387197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1225044.500419657, 1225044.500419656, 260161.9662070169], 
processed observation next is [1.0, 0.43478260869565216, 0.3428120063191157, 0.86, 1.0, 1.0, 0.7901240898056864, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3402901390054603, 0.34029013900546, 0.3883014421000252], 
reward next is 0.6117, 
noisyNet noise sample is [array([-0.20183305], dtype=float32), -1.4340891]. 
=============================================
[2019-03-26 20:51:13,858] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 20:51:13,863] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:51:13,863] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:51:13,865] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:51:13,865] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:51:13,866] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:51:13,865] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:51:13,868] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:51:13,868] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:51:13,874] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:51:13,869] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:51:13,886] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run37
[2019-03-26 20:51:13,908] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run37
[2019-03-26 20:51:13,930] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run37
[2019-03-26 20:51:13,930] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run37
[2019-03-26 20:51:13,931] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run37
[2019-03-26 20:51:40,898] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.10304152]
[2019-03-26 20:51:40,901] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.91429402833333, 94.62019625166667, 1.0, 2.0, 0.3630646532544795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 559862.2268624716, 559862.226862471, 171493.5377069724]
[2019-03-26 20:51:40,901] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:51:40,904] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 2.526329e-19 0.000000e+00], sampled 0.17483022835509943
[2019-03-26 20:51:43,087] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.10304152]
[2019-03-26 20:51:43,090] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.48410472333333, 97.59010459666666, 1.0, 2.0, 0.4463071619200775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 645444.4072811874, 645444.4072811867, 178402.6437763749]
[2019-03-26 20:51:43,092] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:51:43,094] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 2.955291e-19 0.000000e+00], sampled 0.07821133653797796
[2019-03-26 20:51:46,247] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.10304152]
[2019-03-26 20:51:46,248] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [33.60134944333333, 67.53188418833334, 1.0, 2.0, 0.7646276138558379, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005979319124881, 6.9112, 168.9123160160255, 1965569.557331443, 1898330.101255459, 399310.7611594098]
[2019-03-26 20:51:46,250] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:51:46,253] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.1416932e-15 3.8884835e-33], sampled 0.7234306205466308
[2019-03-26 20:51:46,254] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1965569.557331443 W.
[2019-03-26 20:52:05,883] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.10304152]
[2019-03-26 20:52:05,884] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.82823961166667, 74.14351685333334, 1.0, 2.0, 0.463142553176667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 662997.2262725452, 662997.2262725446, 180052.5771558436]
[2019-03-26 20:52:05,887] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:52:05,891] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 1.274818e-19 0.000000e+00], sampled 0.38324611740393644
[2019-03-26 20:52:15,747] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.10304152]
[2019-03-26 20:52:15,747] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [40.57918976333333, 50.63723403333334, 1.0, 2.0, 0.8311606767071958, 1.0, 1.0, 0.8311606767071958, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 172.86236624, 2324543.557115409, 2324543.557115409, 435847.6488183968]
[2019-03-26 20:52:15,748] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:52:15,752] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.8418162e-15 2.8307158e-33], sampled 0.8734289893474876
[2019-03-26 20:52:15,753] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2324543.557115409 W.
[2019-03-26 20:52:20,677] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.10304152]
[2019-03-26 20:52:20,679] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 68.0, 1.0, 2.0, 0.9106114270254874, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.997159136116382, 6.9112, 168.9123723012221, 2169889.668476625, 2108907.509746622, 437350.0266311595]
[2019-03-26 20:52:20,681] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:52:20,684] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7700077e-15 2.6034043e-33], sampled 0.7418370311164622
[2019-03-26 20:52:20,686] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2169889.668476625 W.
[2019-03-26 20:52:24,366] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.10304152]
[2019-03-26 20:52:24,367] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.63765020666666, 97.69927730333333, 1.0, 2.0, 0.7954857214408353, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005981246293237, 6.9112, 168.9123160088559, 2008755.531730204, 1941514.708462699, 406746.4757577945]
[2019-03-26 20:52:24,369] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:52:24,372] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3250216e-16 1.1118773e-35], sampled 0.32203470746894014
[2019-03-26 20:52:24,373] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2008755.531730204 W.
[2019-03-26 20:52:37,149] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.10304152]
[2019-03-26 20:52:37,151] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.72029103, 68.65557794333333, 1.0, 2.0, 0.5616991093511317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 784919.0890029285, 784919.0890029285, 193826.6767380138]
[2019-03-26 20:52:37,154] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:52:37,155] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.00000e+00 1.00000e+00 0.00000e+00 8.71652e-19 0.00000e+00], sampled 0.25906161399952443
[2019-03-26 20:52:38,116] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.10304152]
[2019-03-26 20:52:38,117] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.0, 94.0, 1.0, 2.0, 0.50570475250594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 706646.4727101914, 706646.4727101908, 184493.6082041218]
[2019-03-26 20:52:38,118] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:52:38,122] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 2.873033e-19 0.000000e+00], sampled 0.2678143001614014
[2019-03-26 20:52:48,250] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.10304152]
[2019-03-26 20:52:48,251] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.0, 86.0, 1.0, 2.0, 0.9533838786844598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1332603.343969324, 1332603.343969324, 285043.1509984019]
[2019-03-26 20:52:48,254] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:52:48,260] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 4.509137e-18 0.000000e+00], sampled 0.8961723213681584
[2019-03-26 20:53:07,575] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7878.1300 3164560515.3511 1778.0000
[2019-03-26 20:53:07,944] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.2748 2927846980.7461 1338.0000
[2019-03-26 20:53:08,131] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.1751 3008171027.5419 1766.0000
[2019-03-26 20:53:08,240] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.7157 2843027813.7524 1131.0000
[2019-03-26 20:53:08,472] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.4620 2779798268.0133 933.0000
[2019-03-26 20:53:09,492] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 900000, evaluation results [900000.0, 7878.129995644267, 3164560515.3511353, 1778.0, 8254.274818136657, 2927846980.7461457, 1338.0, 8660.46199861073, 2779798268.0133233, 933.0, 7998.175077088882, 3008171027.5419445, 1766.0, 8496.715729453535, 2843027813.7524204, 1131.0]
[2019-03-26 20:53:13,219] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 7.903838e-15 0.000000e+00], sum to 1.0000
[2019-03-26 20:53:13,226] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3585
[2019-03-26 20:53:13,237] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.18333333333334, 92.66666666666666, 1.0, 2.0, 0.5262457040990456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 735359.3039055692, 735359.3039055692, 187810.3494373734], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2155800.0000, 
sim time next is 2156400.0000, 
raw observation next is [26.1, 93.0, 1.0, 2.0, 0.5246303416972946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733101.2680343774, 733101.2680343774, 187545.0784434577], 
processed observation next is [0.0, 1.0, 0.4360189573459717, 0.93, 1.0, 1.0, 0.4272654719244513, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20363924112066037, 0.20363924112066037, 0.2799180275275488], 
reward next is 0.7201, 
noisyNet noise sample is [array([-0.3341132], dtype=float32), 0.34332603]. 
=============================================
[2019-03-26 20:53:13,299] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.3844735e-19 0.0000000e+00], sum to 1.0000
[2019-03-26 20:53:13,309] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4198
[2019-03-26 20:53:13,314] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 96.66666666666666, 1.0, 2.0, 0.4587731826357281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 648564.1280802464, 648564.128080247, 178359.3039740096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2086800.0000, 
sim time next is 2087400.0000, 
raw observation next is [24.01666666666667, 96.83333333333334, 1.0, 2.0, 0.4598223004457416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 649923.4768743078, 649923.4768743071, 178497.0319980301], 
processed observation next is [0.0, 0.13043478260869565, 0.33728278041074267, 0.9683333333333334, 1.0, 1.0, 0.34918349451294173, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18053429913175217, 0.18053429913175198, 0.26641348059407477], 
reward next is 0.7336, 
noisyNet noise sample is [array([-0.88588285], dtype=float32), -0.44649592]. 
=============================================
[2019-03-26 20:53:13,565] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0424626e-34 1.0000000e+00 4.9073087e-36 2.4140060e-13 1.5978195e-29], sum to 1.0000
[2019-03-26 20:53:13,574] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0260
[2019-03-26 20:53:13,581] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.26666666666667, 79.66666666666667, 1.0, 2.0, 0.5835217977296676, 1.0, 2.0, 0.5835217977296676, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1631466.100810756, 1631466.100810756, 328231.2279278962], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1956000.0000, 
sim time next is 1956600.0000, 
raw observation next is [26.1, 80.5, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.893439996034282, 6.9112, 168.907467887197, 2165089.991872842, 1468277.775404582, 313603.690857724], 
processed observation next is [1.0, 0.6521739130434783, 0.4360189573459717, 0.805, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.09822399960342816, 0.0, 0.8294129934995211, 0.601413886631345, 0.4078549376123839, 0.4680652102354089], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3585356], dtype=float32), -1.6747371]. 
=============================================
[2019-03-26 20:53:18,355] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.0847493e-19 0.0000000e+00], sum to 1.0000
[2019-03-26 20:53:18,370] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2549
[2019-03-26 20:53:18,379] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2349110.924547573 W.
[2019-03-26 20:53:18,383] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.86666666666667, 65.0, 1.0, 2.0, 0.559950864149851, 1.0, 2.0, 0.559950864149851, 1.0, 1.0, 0.9724494724478221, 6.9112, 6.9112, 170.5573041426782, 2349110.924547573, 2349110.924547573, 459078.5804513382], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2298000.0000, 
sim time next is 2298600.0000, 
raw observation next is [31.9, 65.0, 1.0, 2.0, 0.8478019341463049, 1.0, 2.0, 0.8478019341463049, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2371158.453328004, 2371158.453328003, 443814.997313189], 
processed observation next is [1.0, 0.6086956521739131, 0.7109004739336492, 0.65, 1.0, 1.0, 0.8166288363208493, 1.0, 1.0, 0.8166288363208493, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6586551259244456, 0.6586551259244453, 0.6624104437510283], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7969377], dtype=float32), -0.7053087]. 
=============================================
[2019-03-26 20:53:23,369] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.1308871e-15 3.5203725e-32], sum to 1.0000
[2019-03-26 20:53:23,377] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9335
[2019-03-26 20:53:23,382] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.1, 77.0, 1.0, 2.0, 0.5793113965352257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 809539.9016293401, 809539.9016293401, 196955.0082168444], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2410200.0000, 
sim time next is 2410800.0000, 
raw observation next is [30.0, 77.33333333333334, 1.0, 2.0, 0.5780193806038082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 807733.7294120664, 807733.729412067, 196722.4401446359], 
processed observation next is [1.0, 0.9130434782608695, 0.6208530805687204, 0.7733333333333334, 1.0, 1.0, 0.4915896151853111, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22437048039224067, 0.22437048039224083, 0.2936155823054267], 
reward next is 0.7064, 
noisyNet noise sample is [array([-0.40966868], dtype=float32), 1.680325]. 
=============================================
[2019-03-26 20:53:25,331] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.7462326e-31 1.0000000e+00 1.1399182e-34 2.0759616e-12 3.8371703e-28], sum to 1.0000
[2019-03-26 20:53:25,340] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2055
[2019-03-26 20:53:25,350] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2058183.014306735 W.
[2019-03-26 20:53:25,357] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.7, 80.0, 1.0, 2.0, 0.8308020888640424, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.992143855976874, 6.9112, 168.9115868268401, 2058183.014306735, 2000759.1226476, 416112.479292169], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2191200.0000, 
sim time next is 2191800.0000, 
raw observation next is [28.8, 79.5, 1.0, 2.0, 0.7732730385611871, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.993006845986092, 6.9112, 168.9124036376243, 1977668.665799124, 1919632.263643125, 401835.6416177846], 
processed observation next is [1.0, 0.34782608695652173, 0.5639810426540285, 0.795, 1.0, 1.0, 0.7268349862182977, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008180684598609211, 0.0, 0.8294372302937155, 0.5493524071664233, 0.5332311843453125, 0.5997546889817681], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3559738], dtype=float32), 0.44002816]. 
=============================================
[2019-03-26 20:53:26,267] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.2178004e-16 2.3344298e-36], sum to 1.0000
[2019-03-26 20:53:26,277] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6341
[2019-03-26 20:53:26,282] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.45, 94.0, 1.0, 2.0, 0.5063128050034075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 707496.4177415373, 707496.4177415373, 184590.9725924404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2165400.0000, 
sim time next is 2166000.0000, 
raw observation next is [25.4, 94.0, 1.0, 2.0, 0.5054614807527384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 706306.4239431076, 706306.4239431082, 184456.0371933277], 
processed observation next is [1.0, 0.043478260869565216, 0.4028436018957346, 0.94, 1.0, 1.0, 0.40417045873823904, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19619622887308544, 0.1961962288730856, 0.27530751819899657], 
reward next is 0.7247, 
noisyNet noise sample is [array([0.01395489], dtype=float32), 0.5224322]. 
=============================================
[2019-03-26 20:53:26,294] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[59.01853 ]
 [59.30355 ]
 [59.50912 ]
 [59.820545]
 [59.996284]], R is [[58.77880859]
 [58.91551208]
 [59.050457  ]
 [59.18371582]
 [59.31536102]].
[2019-03-26 20:53:31,107] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.7687586e-36 1.0000000e+00 5.0429161e-38 3.5263974e-15 5.3116313e-30], sum to 1.0000
[2019-03-26 20:53:31,119] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0167
[2019-03-26 20:53:31,126] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333334, 85.33333333333334, 1.0, 2.0, 0.5162732218746887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 721419.3367865313, 721419.3367865313, 186184.9187354792], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2247600.0000, 
sim time next is 2248200.0000, 
raw observation next is [26.9, 85.5, 1.0, 2.0, 0.5158807715841106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 720870.7565319655, 720870.7565319655, 186121.5643318131], 
processed observation next is [1.0, 0.0, 0.4739336492890995, 0.855, 1.0, 1.0, 0.4167238211856754, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20024187681443484, 0.20024187681443484, 0.27779337959972106], 
reward next is 0.7222, 
noisyNet noise sample is [array([0.05619371], dtype=float32), 0.77989596]. 
=============================================
[2019-03-26 20:53:42,106] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.8270017e-34 1.0000000e+00 3.4255063e-33 3.7818134e-12 3.6151021e-26], sum to 1.0000
[2019-03-26 20:53:42,115] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3982
[2019-03-26 20:53:42,121] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 83.33333333333334, 1.0, 2.0, 0.72440626249048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1012394.649632712, 1012394.649632711, 226201.2772083527], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2436000.0000, 
sim time next is 2436600.0000, 
raw observation next is [27.65, 83.66666666666666, 1.0, 2.0, 0.7232866737916072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1010829.222722952, 1010829.222722953, 225951.7114248287], 
processed observation next is [1.0, 0.17391304347826086, 0.509478672985782, 0.8366666666666666, 1.0, 1.0, 0.6666104503513339, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.28078589520082, 0.28078589520082026, 0.33724136033556523], 
reward next is 0.6628, 
noisyNet noise sample is [array([0.11625277], dtype=float32), -0.30011794]. 
=============================================
[2019-03-26 20:53:44,232] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1895551e-24 1.0000000e+00 3.2260798e-24 2.6495549e-08 8.1626878e-18], sum to 1.0000
[2019-03-26 20:53:44,241] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1365
[2019-03-26 20:53:44,253] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2699822.083478765 W.
[2019-03-26 20:53:44,256] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.26666666666667, 89.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.666592849268682, 6.9112, 168.9031309717789, 2699822.083478765, 1454558.420505565, 310093.9101273886], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2467200.0000, 
sim time next is 2467800.0000, 
raw observation next is [26.3, 89.0, 1.0, 2.0, 0.519835632274016, 1.0, 1.0, 0.519835632274016, 1.0, 1.0, 0.8874504807507809, 6.911199999999999, 6.9112, 170.5573041426782, 2180667.668756892, 2180667.668756892, 426213.747204425], 
processed observation next is [1.0, 0.5652173913043478, 0.4454976303317536, 0.89, 1.0, 1.0, 0.42148871358315176, 1.0, 0.5, 0.42148871358315176, 1.0, 0.5, 0.8627444887204644, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6057410190991367, 0.6057410190991367, 0.6361399212006343], 
reward next is 0.3639, 
noisyNet noise sample is [array([0.6397154], dtype=float32), -0.5576001]. 
=============================================
[2019-03-26 20:53:52,153] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.8669115e-13 4.9687925e-36], sum to 1.0000
[2019-03-26 20:53:52,161] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3926
[2019-03-26 20:53:52,164] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5835624193741584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 898725.3745763114, 898725.3745763114, 207772.7548374229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2911800.0000, 
sim time next is 2912400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.6698743651496316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1031683.842355097, 1031683.842355097, 226323.6684308749], 
processed observation next is [1.0, 0.7391304347826086, 0.2417061611374408, 0.94, 1.0, 1.0, 0.6022582712646164, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.286578845098638, 0.286578845098638, 0.33779652004608196], 
reward next is 0.6622, 
noisyNet noise sample is [array([0.08444927], dtype=float32), -0.99565816]. 
=============================================
[2019-03-26 20:54:03,254] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.9401607e-13 3.0731280e-30], sum to 1.0000
[2019-03-26 20:54:03,265] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6691
[2019-03-26 20:54:03,274] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.7586531783133827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1117487.748113957, 1117487.748113958, 241722.7986918934], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2823600.0000, 
sim time next is 2824200.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.7713855513912249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1136277.973138236, 1136277.973138236, 244897.0288183452], 
processed observation next is [1.0, 0.6956521739130435, 0.3364928909952607, 0.89, 1.0, 1.0, 0.7245609052906323, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.31563277031617665, 0.31563277031617665, 0.3655179534602167], 
reward next is 0.6345, 
noisyNet noise sample is [array([-0.25262094], dtype=float32), 1.0744914]. 
=============================================
[2019-03-26 20:54:05,290] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 20:54:05,291] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:54:05,292] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:54:05,292] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:54:05,293] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:54:05,293] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:54:05,294] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:54:05,295] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:54:05,298] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:54:05,295] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:54:05,301] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:54:05,318] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run38
[2019-03-26 20:54:05,340] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run38
[2019-03-26 20:54:05,341] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run38
[2019-03-26 20:54:05,363] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run38
[2019-03-26 20:54:05,382] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run38
[2019-03-26 20:54:44,363] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.058863834]
[2019-03-26 20:54:44,365] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.76541263, 88.84586873, 1.0, 2.0, 0.3376283390598541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 530865.7923827062, 530865.7923827068, 169350.104611596]
[2019-03-26 20:54:44,367] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:54:44,370] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.6471326e-18 0.0000000e+00], sampled 0.4246819626993533
[2019-03-26 20:54:44,749] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.058863834]
[2019-03-26 20:54:44,750] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.0, 96.0, 1.0, 2.0, 0.3579552349395392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 548122.8818235274, 548122.8818235274, 170393.262155754]
[2019-03-26 20:54:44,750] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:54:44,753] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2584541e-17 2.0386729e-38], sampled 0.3451459925228293
[2019-03-26 20:55:05,143] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.058863834]
[2019-03-26 20:55:05,145] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.6, 69.0, 1.0, 2.0, 0.9808912634278423, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.993329508321703, 6.9112, 168.91240143774, 2268256.167853042, 2209990.859439059, 457959.6308338996]
[2019-03-26 20:55:05,147] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:55:05,150] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2026896e-27 1.0000000e+00 7.7452934e-29 4.5079451e-09 1.6461333e-21], sampled 0.14150490330309584
[2019-03-26 20:55:05,152] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2268256.167853042 W.
[2019-03-26 20:55:26,404] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.058863834]
[2019-03-26 20:55:26,405] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.93333333333334, 64.0, 1.0, 2.0, 0.5579368814429562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779659.8171915929, 779659.8171915929, 193171.5707137766]
[2019-03-26 20:55:26,406] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:55:26,410] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.8182475e-16 3.9966819e-36], sampled 0.7000390520135414
[2019-03-26 20:55:38,883] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.058863834]
[2019-03-26 20:55:38,886] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.8, 66.0, 1.0, 2.0, 0.7674160855249207, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.971263102317703, 6.9112, 168.9125490791335, 1969471.95343955, 1926861.224223597, 401119.8413126364]
[2019-03-26 20:55:38,888] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:55:38,890] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.3739370e-30 1.0000000e+00 6.3954204e-32 2.5708669e-10 5.7269176e-24], sampled 0.9985308618125518
[2019-03-26 20:55:38,892] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1969471.95343955 W.
[2019-03-26 20:55:59,126] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.9734 2928048931.2162 1338.0000
[2019-03-26 20:55:59,338] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.9641 2779935595.8501 933.0000
[2019-03-26 20:55:59,606] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7875.8585 3164735026.8284 1778.0000
[2019-03-26 20:55:59,790] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.8629 2843167093.8007 1131.0000
[2019-03-26 20:55:59,946] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.8772 3008370595.0632 1766.0000
[2019-03-26 20:56:00,962] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 925000, evaluation results [925000.0, 7875.858472249107, 3164735026.8283834, 1778.0, 8253.973399524697, 2928048931.2161584, 1338.0, 8658.964140262613, 2779935595.8500915, 933.0, 7997.87721511679, 3008370595.063247, 1766.0, 8495.862932155293, 2843167093.8007364, 1131.0]
[2019-03-26 20:56:05,494] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.0761644e-15 6.7156442e-34], sum to 1.0000
[2019-03-26 20:56:05,503] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9736
[2019-03-26 20:56:05,511] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 96.0, 1.0, 2.0, 0.3078368523663025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 488082.7785863078, 488082.7785863078, 166169.8120022653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2947200.0000, 
sim time next is 2947800.0000, 
raw observation next is [20.83333333333333, 95.0, 1.0, 2.0, 0.3073100318811158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 486690.1820198278, 486690.1820198271, 166057.2253637769], 
processed observation next is [1.0, 0.08695652173913043, 0.1864139020537123, 0.95, 1.0, 1.0, 0.1654337733507419, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13519171722772994, 0.13519171722772974, 0.24784660502056255], 
reward next is 0.7522, 
noisyNet noise sample is [array([-0.1873993], dtype=float32), 1.2474152]. 
=============================================
[2019-03-26 20:56:13,609] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1627582e-15 4.5145058e-26], sum to 1.0000
[2019-03-26 20:56:13,615] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1161
[2019-03-26 20:56:13,619] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 96.0, 1.0, 2.0, 0.7583974758994021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1123210.192958733, 1123210.192958733, 242446.031017916], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3072000.0000, 
sim time next is 3072600.0000, 
raw observation next is [23.0, 97.0, 1.0, 2.0, 0.8339151105066627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1229316.07873723, 1229316.078737229, 261326.0559229381], 
processed observation next is [1.0, 0.5652173913043478, 0.28909952606635075, 0.97, 1.0, 1.0, 0.7998977235020032, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.34147668853811947, 0.3414766885381192, 0.39003888943722104], 
reward next is 0.6100, 
noisyNet noise sample is [array([0.19414538], dtype=float32), 2.3655577]. 
=============================================
[2019-03-26 20:56:14,414] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.4067360e-18 1.5328614e-36], sum to 1.0000
[2019-03-26 20:56:14,418] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4100
[2019-03-26 20:56:14,427] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.4234433790790483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 614557.5426876508, 614557.5426876508, 175415.638473793], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3086400.0000, 
sim time next is 3087000.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.4221929928478546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 612799.3362681925, 612799.3362681925, 175248.3666270096], 
processed observation next is [1.0, 0.7391304347826086, 0.28909952606635075, 1.0, 1.0, 1.0, 0.30384697933476457, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1702220378522757, 0.1702220378522757, 0.26156472630896954], 
reward next is 0.7384, 
noisyNet noise sample is [array([0.12564324], dtype=float32), -0.073311225]. 
=============================================
[2019-03-26 20:56:14,452] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[71.50043 ]
 [70.111176]
 [67.19161 ]
 [66.90626 ]
 [66.97671 ]], R is [[71.99541473]
 [72.01364136]
 [72.01538086]
 [71.92034912]
 [71.81757355]].
[2019-03-26 20:56:15,627] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2068236e-38 1.0000000e+00 0.0000000e+00 4.5074608e-14 2.8804405e-34], sum to 1.0000
[2019-03-26 20:56:15,638] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2732
[2019-03-26 20:56:15,643] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.7874252853470698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1174616.704686965, 1174616.704686964, 250870.7695471696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3065400.0000, 
sim time next is 3066000.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.7852241844331339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1171331.216517576, 1171331.216517575, 250300.4449124924], 
processed observation next is [1.0, 0.4782608695652174, 0.28909952606635075, 0.94, 1.0, 1.0, 0.741233957148354, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.32536978236599334, 0.32536978236599307, 0.37358275360073495], 
reward next is 0.6264, 
noisyNet noise sample is [array([-2.0072234], dtype=float32), 0.29446942]. 
=============================================
[2019-03-26 20:56:15,659] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[64.36302 ]
 [64.47957 ]
 [64.400536]
 [65.52795 ]
 [65.62319 ]], R is [[64.33638763]
 [64.31858826]
 [64.30464172]
 [64.27695465]
 [64.29038239]].
[2019-03-26 20:56:25,720] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.7469082e-14 1.2572347e-33], sum to 1.0000
[2019-03-26 20:56:25,727] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0359
[2019-03-26 20:56:25,730] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5231976593354678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 731098.595647361, 731098.595647361, 187310.149921335], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3535200.0000, 
sim time next is 3535800.0000, 
raw observation next is [28.0, 79.00000000000001, 1.0, 2.0, 0.5205249772431118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 727362.6020245068, 727362.6020245062, 186874.2498524237], 
processed observation next is [1.0, 0.9565217391304348, 0.5260663507109005, 0.7900000000000001, 1.0, 1.0, 0.42231924969049606, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20204516722902965, 0.2020451672290295, 0.278916790824513], 
reward next is 0.7211, 
noisyNet noise sample is [array([-1.096182], dtype=float32), 2.0902054]. 
=============================================
[2019-03-26 20:56:30,150] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.6544220e-23 9.9999905e-01 2.6851431e-24 9.2520412e-07 6.0969734e-21], sum to 1.0000
[2019-03-26 20:56:30,159] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7996
[2019-03-26 20:56:30,168] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2168884.517977794 W.
[2019-03-26 20:56:30,180] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.5, 68.0, 1.0, 2.0, 0.7755443431276663, 1.0, 2.0, 0.7755443431276663, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2168884.517977794, 2168884.517977794, 408138.5048265292], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3576600.0000, 
sim time next is 3577200.0000, 
raw observation next is [30.66666666666666, 67.33333333333334, 1.0, 2.0, 0.8088594730178869, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.990286575900647, 6.9112, 168.9124852916676, 2027472.664048351, 1971366.081676289, 410624.5147499153], 
processed observation next is [1.0, 0.391304347826087, 0.6524486571879934, 0.6733333333333335, 1.0, 1.0, 0.7697102084552854, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.007908657590064738, 0.0, 0.8294376312524495, 0.563186851124542, 0.5476016893545247, 0.6128724100745004], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1152463], dtype=float32), 1.2560956]. 
=============================================
[2019-03-26 20:56:32,132] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3197466e-34 9.9999881e-01 0.0000000e+00 1.1491367e-06 1.2173294e-27], sum to 1.0000
[2019-03-26 20:56:32,142] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8650
[2019-03-26 20:56:32,148] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.7310351953082055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1021663.377300856, 1021663.377300855, 227686.0590640607], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3387600.0000, 
sim time next is 3388200.0000, 
raw observation next is [26.16666666666667, 93.16666666666667, 1.0, 2.0, 0.8525567548986385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1191591.978612995, 1191591.978612995, 257219.8526596784], 
processed observation next is [1.0, 0.21739130434782608, 0.4391785150078992, 0.9316666666666668, 1.0, 1.0, 0.822357536022456, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33099777183694307, 0.33099777183694307, 0.3839102278502663], 
reward next is 0.6161, 
noisyNet noise sample is [array([-1.1880823], dtype=float32), 0.26230115]. 
=============================================
[2019-03-26 20:56:33,299] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.3078068e-11 3.9443503e-37], sum to 1.0000
[2019-03-26 20:56:33,310] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5380
[2019-03-26 20:56:33,314] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.5377674587055347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 751465.138770296, 751465.138770296, 189724.9251875314], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3364800.0000, 
sim time next is 3365400.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.5373605047599435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 750896.2687323533, 750896.2687323539, 189656.6609110289], 
processed observation next is [0.0, 0.9565217391304348, 0.4786729857819906, 0.89, 1.0, 1.0, 0.4426030177830644, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20858229687009816, 0.20858229687009833, 0.2830696431507894], 
reward next is 0.7169, 
noisyNet noise sample is [array([0.33912015], dtype=float32), -0.07794951]. 
=============================================
[2019-03-26 20:56:37,521] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.83768834e-33 9.99993324e-01 1.42338418e-35 6.70864119e-06
 1.10967584e-26], sum to 1.0000
[2019-03-26 20:56:37,529] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6554
[2019-03-26 20:56:37,535] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.4946573118244739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 691204.310479273, 691204.3104792737, 182762.8828469088], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3628800.0000, 
sim time next is 3629400.0000, 
raw observation next is [27.83333333333334, 75.66666666666667, 1.0, 2.0, 0.4954583617351405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 692324.0140958324, 692324.0140958324, 182887.4061905441], 
processed observation next is [1.0, 0.0, 0.5181674565560824, 0.7566666666666667, 1.0, 1.0, 0.3921185081146272, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19231222613773122, 0.19231222613773122, 0.2729662778963345], 
reward next is 0.7270, 
noisyNet noise sample is [array([-0.9736486], dtype=float32), -0.53978074]. 
=============================================
[2019-03-26 20:56:41,343] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.8723543e-34 9.9999928e-01 1.4331342e-35 7.4514531e-07 2.0311298e-27], sum to 1.0000
[2019-03-26 20:56:41,351] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5494
[2019-03-26 20:56:41,358] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333333, 79.0, 1.0, 2.0, 0.5347848399878199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 747295.8228908767, 747295.8228908767, 189225.2850913939], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3534000.0000, 
sim time next is 3534600.0000, 
raw observation next is [28.16666666666667, 79.0, 1.0, 2.0, 0.5292705421878953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 739587.5896174719, 739587.5896174725, 188308.8996478552], 
processed observation next is [1.0, 0.9130434782608695, 0.5339652448657191, 0.79, 1.0, 1.0, 0.43285607492517497, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20544099711596442, 0.20544099711596459, 0.28105805917590326], 
reward next is 0.7189, 
noisyNet noise sample is [array([0.6389199], dtype=float32), -1.2013445]. 
=============================================
[2019-03-26 20:56:43,126] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.0177569e-35 9.9934155e-01 5.9622517e-36 6.5848936e-04 5.0709634e-26], sum to 1.0000
[2019-03-26 20:56:43,138] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2361
[2019-03-26 20:56:43,142] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 79.0, 1.0, 2.0, 0.5512261777908358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 770278.8939225607, 770278.8939225607, 192011.4572317818], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3531000.0000, 
sim time next is 3531600.0000, 
raw observation next is [29.0, 79.0, 1.0, 2.0, 0.5516599039562212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 770885.1992047711, 770885.1992047705, 192085.9950600215], 
processed observation next is [1.0, 0.9130434782608695, 0.5734597156398105, 0.79, 1.0, 1.0, 0.4598312095858087, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21413477755688085, 0.2141347775568807, 0.28669551501495744], 
reward next is 0.7133, 
noisyNet noise sample is [array([1.2132891], dtype=float32), 0.21395431]. 
=============================================
[2019-03-26 20:56:52,744] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.1013807e-17 1.7288402e-38], sum to 1.0000
[2019-03-26 20:56:52,752] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3978
[2019-03-26 20:56:52,764] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333334, 71.66666666666667, 1.0, 2.0, 0.638353093640639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 892080.4529525923, 892080.4529525923, 208107.0619841013], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3960600.0000, 
sim time next is 3961200.0000, 
raw observation next is [31.66666666666667, 72.33333333333334, 1.0, 2.0, 0.6120671115098942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 855331.7425388523, 855331.7425388523, 203015.3604700686], 
processed observation next is [0.0, 0.8695652173913043, 0.6998420221169038, 0.7233333333333334, 1.0, 1.0, 0.5326109777227641, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23759215070523673, 0.23759215070523673, 0.30300800070159495], 
reward next is 0.6970, 
noisyNet noise sample is [array([-0.28675327], dtype=float32), -0.09324496]. 
=============================================
[2019-03-26 20:56:53,262] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.3965066e-13 1.0783898e-32], sum to 1.0000
[2019-03-26 20:56:53,271] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4924
[2019-03-26 20:56:53,279] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 78.16666666666667, 1.0, 2.0, 0.5485338291444588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 766515.270746748, 766515.2707467487, 191549.6587717301], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3697800.0000, 
sim time next is 3698400.0000, 
raw observation next is [29.0, 77.33333333333334, 1.0, 2.0, 0.5458690742630228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 762790.2339132758, 762790.2339132765, 191094.7013062788], 
processed observation next is [1.0, 0.8260869565217391, 0.5734597156398105, 0.7733333333333334, 1.0, 1.0, 0.4528543063409913, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21188617608702104, 0.21188617608702123, 0.2852159720989236], 
reward next is 0.7148, 
noisyNet noise sample is [array([0.4774869], dtype=float32), -0.9700335]. 
=============================================
[2019-03-26 20:56:56,880] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 20:56:56,885] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:56:56,886] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:56:56,888] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:56:56,889] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:56:56,889] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:56:56,891] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:56:56,891] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:56:56,893] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:56:56,895] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:56:56,895] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:56:56,913] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run39
[2019-03-26 20:56:56,935] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run39
[2019-03-26 20:56:56,958] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run39
[2019-03-26 20:56:56,959] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run39
[2019-03-26 20:56:57,002] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run39
[2019-03-26 20:57:00,069] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.067322075]
[2019-03-26 20:57:00,070] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [19.840409835, 93.94808416000001, 1.0, 2.0, 0.3000175735058938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 486221.2797052862, 486221.2797052862, 166072.9488457477]
[2019-03-26 20:57:00,071] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:57:00,073] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.7266276e-21 0.0000000e+00], sampled 0.12416296116257752
[2019-03-26 20:57:08,137] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.067322075]
[2019-03-26 20:57:08,140] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.0, 56.5, 1.0, 2.0, 0.5711455446654399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 928565.8693541674, 928565.8693541674, 209314.956994964]
[2019-03-26 20:57:08,141] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:57:08,145] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1613025e-18 7.4180989e-35], sampled 0.5718923245494687
[2019-03-26 20:57:20,169] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.067322075]
[2019-03-26 20:57:20,172] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.05, 87.0, 1.0, 2.0, 0.4377536394675692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 650053.2685138287, 650053.2685138282, 179248.7142121781]
[2019-03-26 20:57:20,173] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:57:20,176] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 5.923323e-20 3.652216e-37], sampled 0.5314611257960449
[2019-03-26 20:57:21,745] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.067322075]
[2019-03-26 20:57:21,746] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.88045620666666, 77.65358253333335, 1.0, 2.0, 0.9135541574760684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1276897.410869284, 1276897.410869283, 273691.2598596346]
[2019-03-26 20:57:21,747] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:57:21,750] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.0414262e-17 1.0376313e-32], sampled 0.22562224321421953
[2019-03-26 20:57:24,894] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.067322075]
[2019-03-26 20:57:24,895] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.13750320666667, 93.38776799666667, 1.0, 2.0, 0.3699654810612316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 566337.2451267077, 566337.2451267083, 171939.0413159899]
[2019-03-26 20:57:24,896] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:57:24,899] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0690337e-19 1.0812215e-36], sampled 0.09826661653968805
[2019-03-26 20:57:43,558] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.067322075]
[2019-03-26 20:57:43,560] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [32.87453848, 65.81312572, 1.0, 2.0, 0.6003357689427444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 838931.3310163091, 838931.3310163091, 200808.9364321431]
[2019-03-26 20:57:43,561] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:57:43,565] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.1551337e-20 2.8292418e-37], sampled 0.015671983928234656
[2019-03-26 20:58:07,783] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.067322075]
[2019-03-26 20:58:07,785] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.82523647666667, 67.38149264, 1.0, 2.0, 0.7127990109451332, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.00597608264154, 6.9112, 168.9123160393431, 1893039.294107633, 1825802.134086335, 387438.2615936032]
[2019-03-26 20:58:07,786] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:58:07,787] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.3742022e-30 1.0000000e+00 2.7387121e-31 2.1005005e-12 4.5180596e-24], sampled 0.6285416744514588
[2019-03-26 20:58:07,788] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1893039.294107633 W.
[2019-03-26 20:58:50,358] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.4620 2779798268.0133 933.0000
[2019-03-26 20:58:50,624] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.0759 3008237470.0170 1766.0000
[2019-03-26 20:58:50,861] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.6111 2843097899.6270 1131.0000
[2019-03-26 20:58:50,910] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.1744 2927914232.3319 1338.0000
[2019-03-26 20:58:50,988] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7877.3726 3164618349.2034 1778.0000
[2019-03-26 20:58:52,002] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 950000, evaluation results [950000.0, 7877.372585301126, 3164618349.203418, 1778.0, 8254.174442635573, 2927914232.3318715, 1338.0, 8660.46199861073, 2779798268.0133233, 933.0, 7998.075909215718, 3008237470.0169654, 1766.0, 8496.611123670547, 2843097899.6270223, 1131.0]
[2019-03-26 20:58:54,766] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.2782499e-17 9.9698228e-01 1.2748464e-18 3.0177243e-03 7.1215040e-14], sum to 1.0000
[2019-03-26 20:58:54,775] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4183
[2019-03-26 20:58:54,784] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2521299.44711397 W.
[2019-03-26 20:58:54,788] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.66666666666667, 71.0, 1.0, 2.0, 0.6009535847395152, 1.0, 2.0, 0.6009535847395152, 1.0, 2.0, 1.03, 6.926553277930925, 6.9112, 170.5573041426782, 2521299.44711397, 2510301.269600633, 488325.9193986871], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4102800.0000, 
sim time next is 4103400.0000, 
raw observation next is [32.83333333333333, 71.0, 1.0, 2.0, 0.8950034023469962, 1.0, 2.0, 0.8950034023469962, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2503305.200947068, 2503305.200947068, 468786.3005976528], 
processed observation next is [1.0, 0.4782608695652174, 0.7551342812006318, 0.71, 1.0, 1.0, 0.8734980751168628, 1.0, 1.0, 0.8734980751168628, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.69536255581863, 0.69536255581863, 0.6996810456681385], 
reward next is 0.3003, 
noisyNet noise sample is [array([-0.42160872], dtype=float32), -0.5090832]. 
=============================================
[2019-03-26 20:59:02,229] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.7696034e-19 5.9011467e-37], sum to 1.0000
[2019-03-26 20:59:02,239] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9331
[2019-03-26 20:59:02,245] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 84.0, 1.0, 2.0, 0.6003891332512326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 839005.9337217159, 839005.9337217159, 200818.0299813241], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3976800.0000, 
sim time next is 3977400.0000, 
raw observation next is [29.16666666666667, 84.0, 1.0, 2.0, 0.5962188130494563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 833175.8885971106, 833175.8885971106, 200043.0258720054], 
processed observation next is [1.0, 0.0, 0.581358609794629, 0.84, 1.0, 1.0, 0.5135166422282607, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23143774683253074, 0.23143774683253074, 0.2985716804059782], 
reward next is 0.7014, 
noisyNet noise sample is [array([-0.15038458], dtype=float32), -0.13123481]. 
=============================================
[2019-03-26 20:59:02,937] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.0145376e-16 2.1776212e-29], sum to 1.0000
[2019-03-26 20:59:02,947] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5728
[2019-03-26 20:59:02,953] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.0, 56.0, 1.0, 2.0, 0.5984022742334975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 836228.3306087685, 836228.3306087685, 200449.1914506043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3945000.0000, 
sim time next is 3945600.0000, 
raw observation next is [35.0, 56.0, 1.0, 2.0, 0.5985692231426372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 836461.7227368458, 836461.7227368458, 200480.2081664106], 
processed observation next is [0.0, 0.6956521739130435, 0.8578199052132701, 0.56, 1.0, 1.0, 0.5163484616176351, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23235047853801274, 0.23235047853801274, 0.29922419129315014], 
reward next is 0.7008, 
noisyNet noise sample is [array([0.5628747], dtype=float32), -1.0718627]. 
=============================================
[2019-03-26 20:59:03,522] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.5242208e-14 2.2481257e-01 3.3544271e-15 7.7518743e-01 1.1965196e-10], sum to 1.0000
[2019-03-26 20:59:03,530] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7363
[2019-03-26 20:59:03,534] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.16666666666667, 77.66666666666667, 1.0, 2.0, 0.9261380621912924, 1.0, 2.0, 0.9261380621912924, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2590478.445550673, 2590478.445550673, 485961.8194006178], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4097400.0000, 
sim time next is 4098000.0000, 
raw observation next is [31.33333333333334, 76.33333333333334, 1.0, 2.0, 0.9248698547411895, 1.0, 2.0, 0.9248698547411895, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2586927.50077058, 2586927.500770579, 485250.5349826436], 
processed observation next is [1.0, 0.43478260869565216, 0.6840442338072673, 0.7633333333333334, 1.0, 1.0, 0.9094817527002284, 1.0, 1.0, 0.9094817527002284, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7185909724362722, 0.718590972436272, 0.7242545298248412], 
reward next is 0.2757, 
noisyNet noise sample is [array([-1.669502], dtype=float32), -1.0268579]. 
=============================================
[2019-03-26 20:59:03,545] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[35.08118 ]
 [34.528324]
 [33.774532]
 [33.818905]
 [33.482346]], R is [[35.47953033]
 [35.39942169]
 [35.31190491]
 [35.19473648]
 [35.08903122]].
[2019-03-26 20:59:05,634] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.4781507e-17 9.9971861e-01 7.9521000e-18 2.8141629e-04 1.1295137e-11], sum to 1.0000
[2019-03-26 20:59:05,642] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4166
[2019-03-26 20:59:05,654] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1836420.864966193 W.
[2019-03-26 20:59:05,660] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.6723382087368741, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.0059735132411, 6.9112, 168.9123928016504, 1836420.864966193, 1769185.497203946, 378759.2238208535], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3990600.0000, 
sim time next is 3991200.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.6229051109962863, 1.0, 1.0, 0.6229051109962863, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1741667.217727852, 1741667.217727853, 342874.2975874734], 
processed observation next is [1.0, 0.17391304347826086, 0.5734597156398105, 0.84, 1.0, 1.0, 0.5456688084292606, 1.0, 0.5, 0.5456688084292606, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4837964493688478, 0.483796449368848, 0.5117526829663782], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6294715], dtype=float32), -0.2203644]. 
=============================================
[2019-03-26 20:59:13,192] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.4025048e-38 1.0000000e+00 1.9118567e-38 3.1180596e-15 8.0555326e-26], sum to 1.0000
[2019-03-26 20:59:13,202] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9988
[2019-03-26 20:59:13,209] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.5, 81.5, 1.0, 2.0, 0.6199593662311755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 866365.2535100605, 866365.2535100605, 204523.6742513632], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4401000.0000, 
sim time next is 4401600.0000, 
raw observation next is [30.33333333333334, 82.33333333333334, 1.0, 2.0, 0.6188710837720963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 864843.8086701048, 864843.8086701054, 204314.6587111072], 
processed observation next is [1.0, 0.9565217391304348, 0.6366508688783573, 0.8233333333333335, 1.0, 1.0, 0.5408085346651763, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24023439129725135, 0.2402343912972515, 0.30494725180762267], 
reward next is 0.6951, 
noisyNet noise sample is [array([1.0911064], dtype=float32), 1.592936]. 
=============================================
[2019-03-26 20:59:13,437] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.36901423e-27 1.00000000e+00 1.07816515e-29 5.15103693e-08
 3.38035500e-20], sum to 1.0000
[2019-03-26 20:59:13,442] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0391
[2019-03-26 20:59:13,455] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2686948.683060544 W.
[2019-03-26 20:59:13,460] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.640617743256142, 6.9112, 169.6696770914696, 2686948.683060544, 1454543.732831527, 310321.7702259737], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4155000.0000, 
sim time next is 4155600.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.4585407525016811, 1.0, 1.0, 0.4585407525016811, 1.0, 1.0, 0.796333645351346, 6.9112, 6.9112, 170.5573041426782, 1923309.877128724, 1923309.877128724, 387660.8308080292], 
processed observation next is [1.0, 0.08695652173913043, 0.5734597156398105, 0.84, 1.0, 1.0, 0.34763946084539893, 1.0, 0.5, 0.34763946084539893, 1.0, 0.5, 0.751626396769934, 0.0, 0.0, 0.8375144448122397, 0.5342527436468678, 0.5342527436468678, 0.5785982549373571], 
reward next is 0.4214, 
noisyNet noise sample is [array([1.6370091], dtype=float32), -0.5055656]. 
=============================================
[2019-03-26 20:59:14,744] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.00000e+00 1.00000e+00 0.00000e+00 3.20912e-22 9.00202e-37], sum to 1.0000
[2019-03-26 20:59:14,752] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0162
[2019-03-26 20:59:14,758] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.5825627364649959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 814085.1222146007, 814085.1222146007, 197542.2599234823], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4141800.0000, 
sim time next is 4142400.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.5832246196768941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 815010.4062550204, 815010.4062550204, 197662.1721715487], 
processed observation next is [1.0, 0.9565217391304348, 0.5734597156398105, 0.84, 1.0, 1.0, 0.497860987562523, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22639177951528344, 0.22639177951528344, 0.29501816742022197], 
reward next is 0.7050, 
noisyNet noise sample is [array([-0.6844094], dtype=float32), 0.12986974]. 
=============================================
[2019-03-26 20:59:27,782] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.2448533e-10 2.2821923e-33], sum to 1.0000
[2019-03-26 20:59:27,791] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0298
[2019-03-26 20:59:27,797] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.5, 63.0, 1.0, 2.0, 0.5382246803433589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 752104.2770344032, 752104.2770344032, 189801.9792848361], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4390200.0000, 
sim time next is 4390800.0000, 
raw observation next is [31.33333333333333, 63.0, 1.0, 2.0, 0.5346285395900005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 747077.3355660398, 747077.3355660398, 189199.5498623884], 
processed observation next is [1.0, 0.8260869565217391, 0.6840442338072668, 0.63, 1.0, 1.0, 0.4393114934819282, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20752148210167773, 0.20752148210167773, 0.28238738785431106], 
reward next is 0.7176, 
noisyNet noise sample is [array([0.24145506], dtype=float32), -2.1847744]. 
=============================================
[2019-03-26 20:59:36,316] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 5.508519e-21 5.217425e-38], sum to 1.0000
[2019-03-26 20:59:36,331] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6523
[2019-03-26 20:59:36,338] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.507506380853706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709164.8182007936, 709164.8182007929, 184780.0542154979], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4502400.0000, 
sim time next is 4503000.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5074416623186471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 709074.3534734903, 709074.3534734909, 184769.774726508], 
processed observation next is [0.0, 0.08695652173913043, 0.4312796208530806, 0.89, 1.0, 1.0, 0.4065562196610205, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19696509818708066, 0.1969650981870808, 0.27577578317389256], 
reward next is 0.7242, 
noisyNet noise sample is [array([-0.21146616], dtype=float32), -0.69140106]. 
=============================================
[2019-03-26 20:59:36,349] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[79.0237  ]
 [79.119026]
 [79.23087 ]
 [78.84491 ]
 [77.53804 ]], R is [[78.82434845]
 [78.76031494]
 [78.69684601]
 [78.63399506]
 [78.57180786]].
[2019-03-26 20:59:39,585] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.1670033e-16 5.0369230e-36], sum to 1.0000
[2019-03-26 20:59:39,598] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4585
[2019-03-26 20:59:39,606] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333333, 68.16666666666667, 1.0, 2.0, 0.5316097653041234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742857.4964020469, 742857.4964020469, 188697.1334090805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4557000.0000, 
sim time next is 4557600.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.5325549707344602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 744178.764265495, 744178.764265495, 188854.1586855058], 
processed observation next is [0.0, 0.782608695652174, 0.6208530805687204, 0.7, 1.0, 1.0, 0.4368132177523617, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20671632340708196, 0.20671632340708196, 0.2818718786350833], 
reward next is 0.7181, 
noisyNet noise sample is [array([-1.9174976], dtype=float32), -0.008019034]. 
=============================================
[2019-03-26 20:59:46,713] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.2664955e-19 1.6591482e-02 7.8444722e-19 9.8340845e-01 8.7193409e-14], sum to 1.0000
[2019-03-26 20:59:46,727] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8425
[2019-03-26 20:59:46,731] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.16666666666666, 73.5, 1.0, 2.0, 0.791269185436653, 1.0, 1.0, 0.791269185436653, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2212905.941609609, 2212905.941609609, 415644.7708420611], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4719000.0000, 
sim time next is 4719600.0000, 
raw observation next is [30.0, 75.0, 1.0, 2.0, 0.801951812887187, 1.0, 2.0, 0.801951812887187, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2242808.358467985, 2242808.358467985, 420824.4225912035], 
processed observation next is [1.0, 0.6521739130434783, 0.6208530805687204, 0.75, 1.0, 1.0, 0.7613877263701048, 1.0, 1.0, 0.7613877263701048, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6230023217966625, 0.6230023217966625, 0.6280961531211993], 
reward next is 0.3719, 
noisyNet noise sample is [array([-1.2079619], dtype=float32), -0.24266145]. 
=============================================
[2019-03-26 20:59:47,894] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 20:59:47,895] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:59:47,897] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:59:47,897] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:59:47,898] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:59:47,900] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:59:47,901] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:59:47,902] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:59:47,902] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:59:47,903] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:59:47,902] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:59:47,927] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run40
[2019-03-26 20:59:47,928] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run40
[2019-03-26 20:59:47,947] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run40
[2019-03-26 20:59:47,966] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run40
[2019-03-26 20:59:48,006] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run40
[2019-03-26 20:59:56,929] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.08309895]
[2019-03-26 20:59:56,930] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.71666666666667, 57.16666666666666, 1.0, 2.0, 0.3115956537643351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 508002.9362410499, 508002.9362410499, 167565.3074400358]
[2019-03-26 20:59:56,930] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:59:56,932] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3094155e-15 1.8808642e-33], sampled 0.29297441659633383
[2019-03-26 21:00:04,701] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.08309895]
[2019-03-26 21:00:04,702] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.45, 91.33333333333334, 1.0, 2.0, 0.3483192195694967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 560963.5639090809, 560963.5639090802, 171829.06402252]
[2019-03-26 21:00:04,705] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:00:04,709] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6972201e-15 3.2445158e-33], sampled 0.3632384707018498
[2019-03-26 21:00:06,408] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.08309895]
[2019-03-26 21:00:06,409] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.23333333333334, 73.66666666666667, 1.0, 2.0, 0.5858543537126845, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9817998996662797, 6.911200000000001, 6.9112, 168.9126160012299, 1654672.817811926, 1654672.817811925, 351970.31968934]
[2019-03-26 21:00:06,410] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:00:06,415] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.4669003e-31 1.0000000e+00 2.0551616e-33 2.2055767e-11 1.4379239e-24], sampled 0.3585006800153424
[2019-03-26 21:00:35,910] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.08309895]
[2019-03-26 21:00:35,912] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.9, 57.0, 1.0, 2.0, 0.5184288382109958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 724432.535067838, 724432.5350678375, 186533.4585425569]
[2019-03-26 21:00:35,914] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:00:35,917] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.4931640e-16 4.3060783e-34], sampled 0.9370884348590958
[2019-03-26 21:01:26,307] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.08309895]
[2019-03-26 21:01:26,309] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.22249329666666, 68.61723293666667, 1.0, 2.0, 0.4743230147283076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 669332.9733435145, 669332.9733435152, 180514.4193994592]
[2019-03-26 21:01:26,310] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:01:26,315] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.9818987e-15 4.4946771e-33], sampled 0.22108139868248455
[2019-03-26 21:01:41,385] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.08309895]
[2019-03-26 21:01:41,388] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.63333333333333, 68.66666666666667, 1.0, 2.0, 0.3316482792530147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 522833.7477794597, 522833.7477794591, 168742.7077054101]
[2019-03-26 21:01:41,388] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:01:41,393] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.1965715e-15 1.2275823e-32], sampled 0.01956185509066577
[2019-03-26 21:01:42,075] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.4734 2779819857.1693 931.0000
[2019-03-26 21:01:42,459] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.5184 2927916749.3950 1338.0000
[2019-03-26 21:01:42,587] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.8629 2843167093.8007 1131.0000
[2019-03-26 21:01:42,630] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.9766 3008303976.5521 1766.0000
[2019-03-26 21:01:42,759] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7877.1551 3164638718.8196 1776.0000
[2019-03-26 21:01:43,774] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 975000, evaluation results [975000.0, 7877.155125466313, 3164638718.81958, 1776.0, 8254.518362806384, 2927916749.3949623, 1338.0, 8660.473395341205, 2779819857.1692877, 931.0, 7997.976645730424, 3008303976.5521116, 1766.0, 8495.862932155293, 2843167093.8007364, 1131.0]
[2019-03-26 21:01:44,741] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6165086e-17 3.5035148e-01 5.9073087e-18 6.4964855e-01 1.8987923e-12], sum to 1.0000
[2019-03-26 21:01:44,750] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1413
[2019-03-26 21:01:44,759] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2062218.320672034 W.
[2019-03-26 21:01:44,763] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 66.0, 1.0, 2.0, 0.7374395876912637, 1.0, 2.0, 0.7374395876912637, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2062218.320672034, 2062218.320672034, 390556.7156582015], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4899600.0000, 
sim time next is 4900200.0000, 
raw observation next is [29.83333333333333, 66.66666666666667, 1.0, 2.0, 0.3385061891092346, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5724356130925675, 6.9112, 6.9112, 168.912956510431, 946129.7776454339, 946129.7776454339, 233296.2228641873], 
processed observation next is [1.0, 0.7391304347826086, 0.6129541864139019, 0.6666666666666667, 1.0, 1.0, 0.20301950495088503, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.4785800159665457, 0.0, 0.0, 0.8294399451523027, 0.26281382712373164, 0.26281382712373164, 0.3482033177077422], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.22517954], dtype=float32), 0.10249162]. 
=============================================
[2019-03-26 21:01:48,970] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3055198e-23 1.0000000e+00 1.2433091e-24 2.2094400e-09 1.2521141e-17], sum to 1.0000
[2019-03-26 21:01:48,977] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2717
[2019-03-26 21:01:48,987] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1722035.484883404 W.
[2019-03-26 21:01:48,994] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.3, 65.0, 1.0, 2.0, 0.6158846692010641, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.925641299822568, 6.9112, 168.9127898535023, 1722035.484883404, 1711790.339866412, 368600.351743291], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4969800.0000, 
sim time next is 4970400.0000, 
raw observation next is [30.33333333333334, 65.0, 1.0, 2.0, 0.4361044622896948, 1.0, 1.0, 0.4361044622896948, 1.0, 2.0, 0.744559289499002, 6.9112, 6.9112, 170.5573041426782, 1829122.453056666, 1829122.453056666, 371774.7963159626], 
processed observation next is [1.0, 0.5217391304347826, 0.6366508688783573, 0.65, 1.0, 1.0, 0.32060778589119854, 1.0, 0.5, 0.32060778589119854, 1.0, 1.0, 0.6884869384134169, 0.0, 0.0, 0.8375144448122397, 0.5080895702935183, 0.5080895702935183, 0.5548877556954666], 
reward next is 0.4451, 
noisyNet noise sample is [array([-0.31021187], dtype=float32), 0.62470156]. 
=============================================
[2019-03-26 21:01:51,486] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.5606218e-38 1.0000000e+00 0.0000000e+00 2.5887863e-11 1.1893168e-28], sum to 1.0000
[2019-03-26 21:01:51,494] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5693
[2019-03-26 21:01:51,497] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 86.5, 1.0, 2.0, 0.6465221921074618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 903501.3935972198, 903501.3935972198, 209724.8204450519], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4861800.0000, 
sim time next is 4862400.0000, 
raw observation next is [27.0, 87.33333333333333, 1.0, 2.0, 0.6417696448468935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 896857.0028543914, 896857.0028543914, 208777.9244044003], 
processed observation next is [1.0, 0.2608695652173913, 0.4786729857819906, 0.8733333333333333, 1.0, 1.0, 0.5683971624661367, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24912694523733092, 0.24912694523733092, 0.31160884239462733], 
reward next is 0.6884, 
noisyNet noise sample is [array([-0.9212756], dtype=float32), 1.1961797]. 
=============================================
[2019-03-26 21:01:54,642] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.6807640e-14 9.4892454e-01 5.5151796e-14 5.1075380e-02 5.9475763e-10], sum to 1.0000
[2019-03-26 21:01:54,651] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3722
[2019-03-26 21:01:54,660] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2040305.540038189 W.
[2019-03-26 21:01:54,666] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 70.0, 1.0, 2.0, 0.7296111351860481, 1.0, 2.0, 0.7296111351860481, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2040305.540038189, 2040305.540038189, 387056.1318058739], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4874400.0000, 
sim time next is 4875000.0000, 
raw observation next is [30.16666666666666, 69.33333333333334, 1.0, 2.0, 0.7458961413623508, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.98799573869101, 6.9112, 168.912499053986, 1939355.68492743, 1884874.29234365, 395582.6681447471], 
processed observation next is [1.0, 0.43478260869565216, 0.6287519747235385, 0.6933333333333335, 1.0, 1.0, 0.6938507727257239, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.007679573869101031, 0.0, 0.8294376988317333, 0.5387099124798417, 0.5235761923176806, 0.5904218927533539], 
reward next is 0.0256, 
noisyNet noise sample is [array([-0.8590383], dtype=float32), 0.5073582]. 
=============================================
[2019-03-26 21:01:54,678] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[29.802128]
 [28.837606]
 [28.996626]
 [29.119255]
 [29.157444]], R is [[30.08586121]
 [30.20730782]
 [29.90523529]
 [29.60618401]
 [29.31012154]].
[2019-03-26 21:01:55,726] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.2675694e-33 1.0000000e+00 3.5887613e-34 5.1249881e-12 2.6000476e-27], sum to 1.0000
[2019-03-26 21:01:55,727] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6384
[2019-03-26 21:01:55,732] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.5940333328374745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 830120.6328028388, 830120.6328028388, 199632.858922759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4942200.0000, 
sim time next is 4942800.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5994737717057516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 837726.269262195, 837726.2692621943, 200640.8238202819], 
processed observation next is [1.0, 0.21739130434782608, 0.4312796208530806, 0.89, 1.0, 1.0, 0.5174382791635561, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23270174146172082, 0.23270174146172062, 0.29946391614967444], 
reward next is 0.7005, 
noisyNet noise sample is [array([-1.4762839], dtype=float32), 0.7254527]. 
=============================================
[2019-03-26 21:02:15,339] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.9859803e-20 3.3659176e-35], sum to 1.0000
[2019-03-26 21:02:15,347] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7542
[2019-03-26 21:02:15,351] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.85, 82.5, 1.0, 2.0, 0.567361603932105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 792834.8196694682, 792834.8196694682, 194822.9990674461], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5520600.0000, 
sim time next is 5521200.0000, 
raw observation next is [28.7, 83.0, 1.0, 2.0, 0.56496112017837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 789479.121331899, 789479.121331899, 194399.8114578796], 
processed observation next is [1.0, 0.9130434782608695, 0.5592417061611374, 0.83, 1.0, 1.0, 0.4758567712992409, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2192997559255275, 0.2192997559255275, 0.29014897232519343], 
reward next is 0.7099, 
noisyNet noise sample is [array([0.8401669], dtype=float32), 0.9058212]. 
=============================================
[2019-03-26 21:02:18,052] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 7.541461e-23 1.333785e-38], sum to 1.0000
[2019-03-26 21:02:18,061] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9576
[2019-03-26 21:02:18,064] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 83.16666666666667, 1.0, 2.0, 0.555245578425055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 775897.6224667907, 775897.6224667907, 192704.7612388712], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5267400.0000, 
sim time next is 5268000.0000, 
raw observation next is [28.5, 83.33333333333334, 1.0, 2.0, 0.5562804724793932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 777344.3078390054, 777344.307839006, 192884.0044816049], 
processed observation next is [1.0, 1.0, 0.5497630331753555, 0.8333333333333335, 1.0, 1.0, 0.46539815961372666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21592897439972372, 0.2159289743997239, 0.28788657385314165], 
reward next is 0.7121, 
noisyNet noise sample is [array([-0.5697431], dtype=float32), 1.2309031]. 
=============================================
[2019-03-26 21:02:18,083] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.50412 ]
 [70.508965]
 [70.41079 ]
 [70.41828 ]
 [70.41923 ]], R is [[70.51047516]
 [70.5177536 ]
 [70.52523041]
 [70.53294373]
 [70.54083252]].
[2019-03-26 21:02:19,704] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.9595429e-36 1.0000000e+00 2.2959746e-38 4.8146981e-17 5.6061300e-32], sum to 1.0000
[2019-03-26 21:02:19,713] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2185
[2019-03-26 21:02:19,719] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 81.16666666666666, 1.0, 2.0, 0.5891208125267886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 823253.063857509, 823253.063857509, 198736.6960920513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5439000.0000, 
sim time next is 5439600.0000, 
raw observation next is [29.6, 81.0, 1.0, 2.0, 0.585524400314107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 818225.4061662189, 818225.4061662189, 198080.1773798122], 
processed observation next is [1.0, 1.0, 0.6018957345971565, 0.81, 1.0, 1.0, 0.5006318076073578, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22728483504617192, 0.22728483504617192, 0.29564205579076447], 
reward next is 0.7044, 
noisyNet noise sample is [array([-1.7865176], dtype=float32), 0.0031923277]. 
=============================================
[2019-03-26 21:02:30,273] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.6878492e-18 0.0000000e+00], sum to 1.0000
[2019-03-26 21:02:30,282] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9335
[2019-03-26 21:02:30,287] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.8, 53.0, 1.0, 2.0, 0.5123013271457002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 715867.3014275094, 715867.3014275087, 185545.9111822582], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5752800.0000, 
sim time next is 5753400.0000, 
raw observation next is [33.0, 53.0, 1.0, 2.0, 0.5296397848215211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740103.7385129881, 740103.7385129888, 188369.5678431455], 
processed observation next is [0.0, 0.6086956521739131, 0.7630331753554502, 0.53, 1.0, 1.0, 0.4333009455680977, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20558437180916336, 0.20558437180916356, 0.2811486087211127], 
reward next is 0.7189, 
noisyNet noise sample is [array([-1.8663576], dtype=float32), -1.6423646]. 
=============================================
[2019-03-26 21:02:35,513] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6164734e-13 5.4181076e-08 9.2039400e-14 1.0000000e+00 4.5241971e-10], sum to 1.0000
[2019-03-26 21:02:35,514] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8582
[2019-03-26 21:02:35,518] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.5, 67.0, 1.0, 2.0, 0.7615581159909399, 1.0, 2.0, 0.7615581159909399, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2129731.80171736, 2129731.80171736, 401593.5945672185], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5566200.0000, 
sim time next is 5566800.0000, 
raw observation next is [31.7, 66.0, 1.0, 2.0, 0.8295522569508444, 1.0, 2.0, 0.8295522569508444, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2320069.816193835, 2320069.816193835, 434516.424106167], 
processed observation next is [1.0, 0.43478260869565216, 0.7014218009478673, 0.66, 1.0, 1.0, 0.7946412734347523, 1.0, 1.0, 0.7946412734347523, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6444638378316208, 0.6444638378316208, 0.6485319762778612], 
reward next is 0.3515, 
noisyNet noise sample is [array([-1.6141189], dtype=float32), 1.5424511]. 
=============================================
[2019-03-26 21:02:39,553] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.6432409e-22 0.0000000e+00], sum to 1.0000
[2019-03-26 21:02:39,559] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2116
[2019-03-26 21:02:39,563] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.61666666666667, 91.16666666666667, 1.0, 2.0, 0.5019505234115789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 701398.7692300805, 701398.7692300805, 183901.9238461858], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5629800.0000, 
sim time next is 5630400.0000, 
raw observation next is [25.6, 91.0, 1.0, 2.0, 0.4998949253814117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 698525.4422616044, 698525.4422616044, 183579.3229989482], 
processed observation next is [0.0, 0.17391304347826086, 0.4123222748815167, 0.91, 1.0, 1.0, 0.3974637655197732, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19403484507266788, 0.19403484507266788, 0.2739989895506689], 
reward next is 0.7260, 
noisyNet noise sample is [array([-0.24357156], dtype=float32), -0.2581409]. 
=============================================
[2019-03-26 21:02:39,736] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 21:02:39,737] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:02:39,738] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:02:39,739] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:02:39,740] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:02:39,740] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:02:39,741] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:02:39,742] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:02:39,742] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:02:39,745] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:02:39,746] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:02:40,276] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run41
[2019-03-26 21:02:40,303] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run41
[2019-03-26 21:02:40,469] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run41
[2019-03-26 21:02:40,486] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run41
[2019-03-26 21:02:40,544] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run41
[2019-03-26 21:02:55,906] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.20474927]
[2019-03-26 21:02:55,908] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.1, 97.5, 1.0, 2.0, 0.3724396340667769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 564686.0933807458, 564686.0933807465, 171638.2772160558]
[2019-03-26 21:02:55,911] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:02:55,914] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.1776444e-23 0.0000000e+00], sampled 0.6712936247089718
[2019-03-26 21:02:59,265] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.20474927]
[2019-03-26 21:02:59,266] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.65, 76.66666666666667, 1.0, 2.0, 0.4317444592857451, 1.0, 1.0, 0.4317444592857451, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1206873.593748378, 1206873.593748378, 280411.428857114]
[2019-03-26 21:02:59,267] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:02:59,270] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.8649604e-31 1.0000000e+00 3.7274691e-33 3.4695115e-13 1.6441365e-30], sampled 0.7768183278901959
[2019-03-26 21:03:00,022] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.20474927]
[2019-03-26 21:03:00,023] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.8, 51.0, 1.0, 2.0, 0.2056515171260029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 343724.4516716925, 343724.4516716925, 155849.2810393436]
[2019-03-26 21:03:00,024] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:03:00,028] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.09775655e-24
 0.00000000e+00], sampled 0.508855378976424
[2019-03-26 21:03:41,106] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.20474927]
[2019-03-26 21:03:41,110] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.75, 54.0, 1.0, 2.0, 0.708078664089272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 989565.3677340576, 989565.3677340576, 222602.1905018881]
[2019-03-26 21:03:41,110] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:03:41,115] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 8.347499e-18 0.000000e+00], sampled 0.02185054583472179
[2019-03-26 21:03:52,304] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.20474927]
[2019-03-26 21:03:52,306] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.2, 84.0, 1.0, 2.0, 0.5913937776984254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 826430.6014398711, 826430.6014398711, 199153.3841534985]
[2019-03-26 21:03:52,307] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:03:52,311] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 8.4108746e-20 0.0000000e+00], sampled 0.9309605740453875
[2019-03-26 21:04:31,302] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.20474927]
[2019-03-26 21:04:31,302] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.52597212, 72.15225610666667, 1.0, 2.0, 0.469123561841996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 669044.2032443894, 669044.2032443894, 180635.2181661369]
[2019-03-26 21:04:31,303] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:04:31,305] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.4041746e-19 0.0000000e+00], sampled 0.9570915399485075
[2019-03-26 21:04:34,628] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8664.5158 2779390412.4753 921.0000
[2019-03-26 21:04:35,054] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8261.0115 2927414458.7913 1327.0000
[2019-03-26 21:04:35,099] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7903.1528 3162062320.6445 1723.0000
[2019-03-26 21:04:35,129] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8000.6247 3007950249.2698 1761.0000
[2019-03-26 21:04:35,250] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8498.0789 2843018712.7339 1127.0000
[2019-03-26 21:04:36,265] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1000000, evaluation results [1000000.0, 7903.152845851217, 3162062320.6445174, 1723.0, 8261.01146308221, 2927414458.791339, 1327.0, 8664.51583888715, 2779390412.4752865, 921.0, 8000.624746848568, 3007950249.269781, 1761.0, 8498.078900375036, 2843018712.7338977, 1127.0]
[2019-03-26 21:04:37,181] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1567463e-22 0.0000000e+00], sum to 1.0000
[2019-03-26 21:04:37,192] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9885
[2019-03-26 21:04:37,195] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.4, 60.0, 1.0, 2.0, 0.5446811968666186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 761129.7150157875, 761129.7150157881, 190893.1658854079], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5668200.0000, 
sim time next is 5668800.0000, 
raw observation next is [32.36666666666667, 60.0, 1.0, 2.0, 0.5433957148214752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 759332.7587298921, 759332.7587298927, 190674.9880485581], 
processed observation next is [0.0, 0.6086956521739131, 0.7330173775671407, 0.6, 1.0, 1.0, 0.4498743552065966, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21092576631385893, 0.21092576631385906, 0.28458953440083296], 
reward next is 0.7154, 
noisyNet noise sample is [array([-1.5092756], dtype=float32), -1.3727298]. 
=============================================
[2019-03-26 21:04:46,894] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1613968e-20 1.0056836e-05 5.4575518e-22 9.9998999e-01 9.9248331e-18], sum to 1.0000
[2019-03-26 21:04:46,901] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3005
[2019-03-26 21:04:46,908] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.6, 62.0, 1.0, 2.0, 1.007866393103678, 1.0, 2.0, 1.007866393103678, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2819336.732213841, 2819336.732213841, 533754.4604043363], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5842800.0000, 
sim time next is 5843400.0000, 
raw observation next is [32.55, 62.16666666666667, 1.0, 2.0, 0.8877548980970035, 1.0, 2.0, 0.8877548980970035, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2483011.147169054, 2483011.147169055, 464855.7422388209], 
processed observation next is [1.0, 0.6521739130434783, 0.7417061611374406, 0.6216666666666667, 1.0, 1.0, 0.8647649374662693, 1.0, 1.0, 0.8647649374662693, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6897253186580705, 0.6897253186580709, 0.6938145406549565], 
reward next is 0.3062, 
noisyNet noise sample is [array([-0.8121999], dtype=float32), 1.471035]. 
=============================================
[2019-03-26 21:04:47,964] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 1.976813e-19 0.000000e+00], sum to 1.0000
[2019-03-26 21:04:47,971] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1269
[2019-03-26 21:04:47,977] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 90.0, 1.0, 2.0, 0.5293183546834279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 739654.4246990532, 739654.4246990532, 188317.2765606468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5875200.0000, 
sim time next is 5875800.0000, 
raw observation next is [26.63333333333333, 90.33333333333333, 1.0, 2.0, 0.5301574870471409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740827.4133099086, 740827.4133099093, 188456.0373991262], 
processed observation next is [1.0, 0.0, 0.46129541864139006, 0.9033333333333333, 1.0, 1.0, 0.4339246831893264, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20578539258608572, 0.2057853925860859, 0.2812776677598898], 
reward next is 0.7187, 
noisyNet noise sample is [array([0.19574542], dtype=float32), 1.9375085]. 
=============================================
[2019-03-26 21:04:50,334] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 4.261599e-18 0.000000e+00], sum to 1.0000
[2019-03-26 21:04:50,343] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8164
[2019-03-26 21:04:50,352] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666667, 87.66666666666667, 1.0, 2.0, 0.5391237589005263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 753361.0767429426, 753361.0767429426, 189952.7347433777], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5870400.0000, 
sim time next is 5871000.0000, 
raw observation next is [27.08333333333333, 87.83333333333334, 1.0, 2.0, 0.5359402213410656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 748910.894908808, 748910.8949088088, 189418.5853816767], 
processed observation next is [1.0, 0.9565217391304348, 0.4826224328593995, 0.8783333333333334, 1.0, 1.0, 0.44089183294104284, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20803080414133557, 0.20803080414133576, 0.282714306539816], 
reward next is 0.7173, 
noisyNet noise sample is [array([0.851254], dtype=float32), -1.9053206]. 
=============================================
[2019-03-26 21:04:50,372] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[68.0153 ]
 [68.02426]
 [68.0502 ]
 [68.10024]
 [68.1652 ]], R is [[68.04409027]
 [68.08013916]
 [68.1150589 ]
 [68.149086  ]
 [68.18261719]].
[2019-03-26 21:04:57,032] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3173569e-37 1.0000000e+00 3.7772866e-38 2.4998788e-12 9.5210001e-34], sum to 1.0000
[2019-03-26 21:04:57,042] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5552
[2019-03-26 21:04:57,050] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.63333333333333, 87.5, 1.0, 2.0, 0.7724593662494886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1079585.446619537, 1079585.446619537, 237264.1381100006], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5986200.0000, 
sim time next is 5986800.0000, 
raw observation next is [27.8, 87.0, 1.0, 2.0, 0.7406611294908749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1035122.725842849, 1035122.72584285, 229868.1972868438], 
processed observation next is [1.0, 0.30434782608695654, 0.5165876777251186, 0.87, 1.0, 1.0, 0.6875435295070782, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2875340905119025, 0.2875340905119028, 0.3430868616221549], 
reward next is 0.6569, 
noisyNet noise sample is [array([-1.4847304], dtype=float32), 1.4084307]. 
=============================================
[2019-03-26 21:05:02,835] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.0454201e-23 9.9609643e-01 3.0545956e-25 3.9035717e-03 1.2756874e-19], sum to 1.0000
[2019-03-26 21:05:02,843] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7027
[2019-03-26 21:05:02,850] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3542558.270254852 W.
[2019-03-26 21:05:02,856] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.86666666666667, 79.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 9.853983225804193, 6.9112, 168.8962106021904, 3542558.270254852, 1455053.541314377, 306783.9370471115], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6078000.0000, 
sim time next is 6078600.0000, 
raw observation next is [29.0, 78.5, 1.0, 2.0, 0.6362090056398496, 1.0, 1.0, 0.6362090056398496, 1.0, 1.0, 1.03, 6.995386797565336, 6.9112, 170.5573041426782, 2669371.496413226, 2609065.068817199, 501479.7684497423], 
processed observation next is [1.0, 0.34782608695652173, 0.5734597156398105, 0.785, 1.0, 1.0, 0.5616975971564453, 1.0, 0.5, 0.5616975971564453, 1.0, 0.5, 1.0365853658536586, 0.008418679756533631, 0.0, 0.8375144448122397, 0.7414920823370071, 0.7247402968936665, 0.7484772663428989], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.02760877], dtype=float32), -0.122780725]. 
=============================================
[2019-03-26 21:05:03,338] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8274453e-22 9.6869546e-01 5.8900422e-24 3.1304512e-02 3.7510818e-19], sum to 1.0000
[2019-03-26 21:05:03,346] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3777
[2019-03-26 21:05:03,357] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2015872.107969355 W.
[2019-03-26 21:05:03,364] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.73333333333333, 66.33333333333334, 1.0, 2.0, 0.4805879855294945, 1.0, 2.0, 0.4805879855294945, 1.0, 2.0, 0.8295584782410337, 6.9112, 6.9112, 170.5573041426782, 2015872.107969355, 2015872.107969355, 401106.7096744934], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6103200.0000, 
sim time next is 6103800.0000, 
raw observation next is [30.7, 66.5, 1.0, 2.0, 0.5004554482890019, 1.0, 2.0, 0.5004554482890019, 1.0, 2.0, 0.8641684924974001, 6.9112, 6.9112, 170.5573041426782, 2099289.728674488, 2099289.728674488, 414564.7071232815], 
processed observation next is [1.0, 0.6521739130434783, 0.6540284360189573, 0.665, 1.0, 1.0, 0.39813909432409866, 1.0, 1.0, 0.39813909432409866, 1.0, 1.0, 0.8343518201187805, 0.0, 0.0, 0.8375144448122397, 0.5831360357429134, 0.5831360357429134, 0.618753294213853], 
reward next is 0.3812, 
noisyNet noise sample is [array([0.6758599], dtype=float32), 1.3884115]. 
=============================================
[2019-03-26 21:05:03,797] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1677466e-19 1.4975637e-01 2.0790569e-21 8.5024363e-01 1.2031955e-16], sum to 1.0000
[2019-03-26 21:05:03,810] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2955
[2019-03-26 21:05:03,816] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 65.0, 1.0, 2.0, 0.5784561818489872, 1.0, 2.0, 0.5784561818489872, 1.0, 1.0, 1.00019564363103, 6.9112, 6.9112, 170.5573041426782, 2426819.984159267, 2426819.984159267, 472707.1318896275], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6089400.0000, 
sim time next is 6090000.0000, 
raw observation next is [31.0, 65.0, 1.0, 2.0, 0.8250101709943019, 1.0, 2.0, 0.8250101709943019, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2307354.903203788, 2307354.903203788, 432226.801122972], 
processed observation next is [1.0, 0.4782608695652174, 0.6682464454976303, 0.65, 1.0, 1.0, 0.7891688807160263, 1.0, 1.0, 0.7891688807160263, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6409319175566078, 0.6409319175566078, 0.6451146285417493], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1740981], dtype=float32), 0.8849901]. 
=============================================
[2019-03-26 21:05:03,837] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[46.37435 ]
 [47.15761 ]
 [46.75857 ]
 [48.097797]
 [48.95102 ]], R is [[47.16041565]
 [46.98328018]
 [46.83189011]
 [46.70672989]
 [46.66799545]].
[2019-03-26 21:05:05,003] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.268142e-37 1.000000e+00 1.512380e-38 1.898369e-15 1.368275e-34], sum to 1.0000
[2019-03-26 21:05:05,014] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0303
[2019-03-26 21:05:05,019] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.03333333333333, 83.0, 1.0, 2.0, 0.5110430279115776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 714108.4185074257, 714108.4185074263, 185344.0614224369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6399600.0000, 
sim time next is 6400200.0000, 
raw observation next is [27.01666666666667, 83.0, 1.0, 2.0, 0.510108049918798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712801.4841913255, 712801.4841913255, 185194.6590759626], 
processed observation next is [1.0, 0.043478260869565216, 0.4794628751974725, 0.83, 1.0, 1.0, 0.4097687348419253, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1980004122753682, 0.1980004122753682, 0.2764099389193472], 
reward next is 0.7236, 
noisyNet noise sample is [array([0.60728294], dtype=float32), 0.47559878]. 
=============================================
[2019-03-26 21:05:07,944] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.3375397e-21 0.0000000e+00], sum to 1.0000
[2019-03-26 21:05:07,953] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6442
[2019-03-26 21:05:07,958] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.85, 62.5, 1.0, 2.0, 0.5178005561098981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723554.2987983349, 723554.2987983349, 186431.8985461741], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6355800.0000, 
sim time next is 6356400.0000, 
raw observation next is [30.8, 62.33333333333333, 1.0, 2.0, 0.5156978665998968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 720615.0858719458, 720615.0858719453, 186091.9705653025], 
processed observation next is [0.0, 0.5652173913043478, 0.6587677725118484, 0.6233333333333333, 1.0, 1.0, 0.4165034537348154, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20017085718665162, 0.20017085718665145, 0.27774920979895895], 
reward next is 0.7223, 
noisyNet noise sample is [array([1.4588108], dtype=float32), -0.92997277]. 
=============================================
[2019-03-26 21:05:11,313] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 7.035626e-19 0.000000e+00], sum to 1.0000
[2019-03-26 21:05:11,324] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1906
[2019-03-26 21:05:11,329] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.61666666666667, 62.83333333333333, 1.0, 2.0, 0.5102231700791207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712962.4017829729, 712962.4017829729, 185213.3395992655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6277800.0000, 
sim time next is 6278400.0000, 
raw observation next is [30.6, 63.0, 1.0, 2.0, 0.5102283636509687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712969.6614769972, 712969.6614769972, 185214.2027767767], 
processed observation next is [0.0, 0.6956521739130435, 0.6492890995260664, 0.63, 1.0, 1.0, 0.4099136911457454, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19804712818805478, 0.19804712818805478, 0.2764391086220548], 
reward next is 0.7236, 
noisyNet noise sample is [array([0.0682207], dtype=float32), -1.0398438]. 
=============================================
[2019-03-26 21:05:13,752] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6045297e-17 0.0000000e+00], sum to 1.0000
[2019-03-26 21:05:13,760] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7665
[2019-03-26 21:05:13,773] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.4, 75.66666666666666, 1.0, 2.0, 0.5417871942861617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 757084.2360113957, 757084.2360113951, 190402.7467325003], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6255600.0000, 
sim time next is 6256200.0000, 
raw observation next is [29.55, 74.83333333333334, 1.0, 2.0, 0.5418757336280602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 757208.0034848315, 757208.0034848315, 190417.7333256967], 
processed observation next is [0.0, 0.391304347826087, 0.5995260663507109, 0.7483333333333334, 1.0, 1.0, 0.4480430525639279, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2103355565235643, 0.2103355565235643, 0.28420557212790554], 
reward next is 0.7158, 
noisyNet noise sample is [array([-2.0122979], dtype=float32), 0.31273273]. 
=============================================
[2019-03-26 21:05:25,299] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2309069e-17 0.0000000e+00], sum to 1.0000
[2019-03-26 21:05:25,311] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1050
[2019-03-26 21:05:25,316] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 71.5, 1.0, 2.0, 0.5065285289715604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 707797.9601494962, 707797.9601494956, 184625.491827253], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6460200.0000, 
sim time next is 6460800.0000, 
raw observation next is [28.9, 72.0, 1.0, 2.0, 0.5039603006425784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 704208.0551312147, 704208.0551312154, 184219.2377788638], 
processed observation next is [1.0, 0.782608695652174, 0.5687203791469194, 0.72, 1.0, 1.0, 0.4023618080031064, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19561334864755964, 0.19561334864755983, 0.27495408623711015], 
reward next is 0.7250, 
noisyNet noise sample is [array([0.7618886], dtype=float32), -0.24074976]. 
=============================================
[2019-03-26 21:05:31,695] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2857595e-30 1.0000000e+00 2.3406867e-31 6.2249583e-09 3.8854539e-28], sum to 1.0000
[2019-03-26 21:05:31,706] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6410
[2019-03-26 21:05:31,715] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 92.0, 1.0, 2.0, 0.7725671885780743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1079736.215193073, 1079736.215193073, 237286.6588786263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6585600.0000, 
sim time next is 6586200.0000, 
raw observation next is [25.9, 91.5, 1.0, 2.0, 0.754033857688654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1053821.267887807, 1053821.267887807, 232938.8551451454], 
processed observation next is [1.0, 0.21739130434782608, 0.42654028436018954, 0.915, 1.0, 1.0, 0.703655250227294, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2927281299688353, 0.2927281299688353, 0.34766993305245586], 
reward next is 0.6523, 
noisyNet noise sample is [array([-1.8233905], dtype=float32), 1.4017248]. 
=============================================
[2019-03-26 21:05:31,918] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 21:05:31,919] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:05:31,920] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:05:31,920] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:31,921] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:05:31,922] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:05:31,922] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:31,924] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:05:31,923] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:31,926] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:31,924] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:31,943] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run42
[2019-03-26 21:05:31,944] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run42
[2019-03-26 21:05:31,962] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run42
[2019-03-26 21:05:31,963] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run42
[2019-03-26 21:05:32,020] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run42
[2019-03-26 21:06:54,851] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.26578894]
[2019-03-26 21:06:54,854] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.3, 79.16666666666667, 1.0, 2.0, 0.4101873536573752, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7123597822721369, 6.911200000000001, 6.9112, 168.9127781073836, 1146587.849503701, 1146587.8495037, 264022.713566764]
[2019-03-26 21:06:54,856] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:06:54,860] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.1955669e-24 9.9999928e-01 1.0837705e-25 6.7342353e-07 1.6673471e-22], sampled 0.9543695000123624
[2019-03-26 21:07:24,181] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7933.6026 3158836977.1790 1627.0000
[2019-03-26 21:07:24,676] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8507.9321 2840994257.5069 1086.0000
[2019-03-26 21:07:24,719] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8263.3289 2927237231.0559 1317.0000
[2019-03-26 21:07:24,774] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8671.7605 2778480848.3602 897.0000
[2019-03-26 21:07:24,810] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8029.9981 3004941348.2067 1686.0000
[2019-03-26 21:07:25,825] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1025000, evaluation results [1025000.0, 7933.602577583876, 3158836977.1789756, 1627.0, 8263.328854052339, 2927237231.055892, 1317.0, 8671.760461477288, 2778480848.3601985, 897.0, 8029.998087660251, 3004941348.2066836, 1686.0, 8507.932123911858, 2840994257.506929, 1086.0]
[2019-03-26 21:07:38,845] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0155723e-17 0.0000000e+00], sum to 1.0000
[2019-03-26 21:07:38,852] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4740
[2019-03-26 21:07:38,858] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.91666666666666, 61.16666666666667, 1.0, 2.0, 0.3242004567002977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 511178.0306159031, 511178.0306159037, 167842.3541795695], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6814200.0000, 
sim time next is 6814800.0000, 
raw observation next is [25.8, 62.0, 1.0, 2.0, 0.3237298596240198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 510070.4290974017, 510070.4290974011, 167750.061073115], 
processed observation next is [1.0, 0.9130434782608695, 0.42180094786729866, 0.62, 1.0, 1.0, 0.1852166983421925, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1416862303048338, 0.14168623030483363, 0.2503732254822612], 
reward next is 0.7496, 
noisyNet noise sample is [array([-0.55991524], dtype=float32), 0.6807489]. 
=============================================
[2019-03-26 21:07:41,871] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.4793101e-18 0.0000000e+00], sum to 1.0000
[2019-03-26 21:07:41,879] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1281
[2019-03-26 21:07:41,883] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 82.0, 1.0, 2.0, 0.3373104225798131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 526188.2841999789, 526188.2841999796, 168885.4356389139], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6840000.0000, 
sim time next is 6840600.0000, 
raw observation next is [23.08333333333334, 82.33333333333334, 1.0, 2.0, 0.3384398181616116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527583.3709242905, 527583.3709242905, 168987.0938982597], 
processed observation next is [0.0, 0.17391304347826086, 0.2930489731437602, 0.8233333333333335, 1.0, 1.0, 0.20293953995374894, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1465509363678585, 0.1465509363678585, 0.2522195431317309], 
reward next is 0.7478, 
noisyNet noise sample is [array([0.12289391], dtype=float32), 0.10955262]. 
=============================================
[2019-03-26 21:07:50,277] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.05047684e-22
 0.00000000e+00], sum to 1.0000
[2019-03-26 21:07:50,282] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7787
[2019-03-26 21:07:50,287] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.96666666666667, 56.33333333333334, 1.0, 2.0, 0.3965311551739365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 591149.2877517611, 591149.2877517617, 173707.0568044419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6981600.0000, 
sim time next is 6982200.0000, 
raw observation next is [28.9, 56.0, 1.0, 2.0, 0.3939389622078006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 589670.6571792588, 589670.6571792588, 173642.7863888592], 
processed observation next is [0.0, 0.8260869565217391, 0.5687203791469194, 0.56, 1.0, 1.0, 0.2698059785636152, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16379740477201632, 0.16379740477201632, 0.2591683378938197], 
reward next is 0.7408, 
noisyNet noise sample is [array([-2.2448173], dtype=float32), 0.4085613]. 
=============================================
[2019-03-26 21:07:51,442] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.43082385e-36 1.00000000e+00 4.56214082e-37 5.22949883e-16
 8.62019223e-35], sum to 1.0000
[2019-03-26 21:07:51,452] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3313
[2019-03-26 21:07:51,460] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666666, 79.33333333333333, 1.0, 2.0, 0.4525203593305189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 646806.3773682071, 646806.3773682065, 178355.5033537819], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7000800.0000, 
sim time next is 7001400.0000, 
raw observation next is [26.13333333333334, 79.66666666666667, 1.0, 2.0, 0.4528319381208636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 646801.0828001656, 646801.0828001656, 178343.8153820888], 
processed observation next is [1.0, 0.0, 0.43759873617693557, 0.7966666666666667, 1.0, 1.0, 0.34076137122995614, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17966696744449046, 0.17966696744449046, 0.26618479907774445], 
reward next is 0.7338, 
noisyNet noise sample is [array([0.2252661], dtype=float32), 0.3572909]. 
=============================================
[2019-03-26 21:07:54,106] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.00000e+00 1.00000e+00 0.00000e+00 8.37278e-20 0.00000e+00], sum to 1.0000
[2019-03-26 21:07:54,111] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1120
[2019-03-26 21:07:54,115] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.65, 92.5, 1.0, 2.0, 0.5898481219932419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 830319.3067673407, 830319.30676734, 199647.9751432616], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7093800.0000, 
sim time next is 7094400.0000, 
raw observation next is [24.6, 92.66666666666667, 1.0, 2.0, 0.569235914044757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 802345.5808369551, 802345.5808369551, 196039.0806612568], 
processed observation next is [1.0, 0.08695652173913043, 0.36492890995260674, 0.9266666666666667, 1.0, 1.0, 0.48100712535512896, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22287377245470974, 0.22287377245470974, 0.2925956427779952], 
reward next is 0.7074, 
noisyNet noise sample is [array([-0.45608833], dtype=float32), -0.56517047]. 
=============================================
[2019-03-26 21:07:58,090] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.9507324e-17 7.8761028e-03 7.3922914e-18 9.9212390e-01 9.4606763e-14], sum to 1.0000
[2019-03-26 21:07:58,096] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8572
[2019-03-26 21:07:58,102] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 70.33333333333333, 1.0, 2.0, 0.6102216655711586, 1.0, 2.0, 0.6102216655711586, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1706175.572664806, 1706175.572664805, 338045.0806174761], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7120200.0000, 
sim time next is 7120800.0000, 
raw observation next is [28.1, 70.0, 1.0, 2.0, 0.6206221281829034, 1.0, 2.0, 0.6206221281829034, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1735278.739416648, 1735278.739416648, 341980.9641802596], 
processed observation next is [1.0, 0.43478260869565216, 0.5308056872037916, 0.7, 1.0, 1.0, 0.5429182267263897, 1.0, 1.0, 0.5429182267263897, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.48202187206018, 0.48202187206018, 0.5104193495227756], 
reward next is 0.4896, 
noisyNet noise sample is [array([-1.387371], dtype=float32), -0.0042730756]. 
=============================================
[2019-03-26 21:08:01,148] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2746915e-19 0.0000000e+00], sum to 1.0000
[2019-03-26 21:08:01,159] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0897
[2019-03-26 21:08:01,166] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 72.66666666666667, 1.0, 2.0, 0.3542607385432091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 545295.6405269419, 545295.6405269412, 170241.8241660794], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7350000.0000, 
sim time next is 7350600.0000, 
raw observation next is [24.98333333333333, 72.33333333333333, 1.0, 2.0, 0.3534448289554285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 544564.6543764675, 544564.6543764668, 170196.2865857596], 
processed observation next is [1.0, 0.043478260869565216, 0.3830963665086887, 0.7233333333333333, 1.0, 1.0, 0.22101786621135963, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15126795954901873, 0.15126795954901853, 0.2540243083369546], 
reward next is 0.7460, 
noisyNet noise sample is [array([-0.11420336], dtype=float32), 0.0866251]. 
=============================================
[2019-03-26 21:08:03,319] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.0549053e-38 1.0000000e+00 0.0000000e+00 4.0037378e-18 0.0000000e+00], sum to 1.0000
[2019-03-26 21:08:03,326] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8238
[2019-03-26 21:08:03,331] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 93.0, 1.0, 2.0, 0.6163464047426903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 972426.3776905333, 972426.3776905339, 216825.7324020278], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7387200.0000, 
sim time next is 7387800.0000, 
raw observation next is [21.16666666666667, 92.83333333333333, 1.0, 2.0, 0.6387313323200511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1008690.98886403, 1008690.988864029, 221827.4207823641], 
processed observation next is [1.0, 0.5217391304347826, 0.2022116903633494, 0.9283333333333332, 1.0, 1.0, 0.5647365449639169, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.28019194135111947, 0.28019194135111913, 0.3310857026602449], 
reward next is 0.6689, 
noisyNet noise sample is [array([-0.03957478], dtype=float32), -0.2871992]. 
=============================================
[2019-03-26 21:08:11,827] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.5179565e-28 0.0000000e+00], sum to 1.0000
[2019-03-26 21:08:11,837] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1845
[2019-03-26 21:08:11,842] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.98333333333333, 72.33333333333333, 1.0, 2.0, 0.3534448289554285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 544564.6543764675, 544564.6543764668, 170196.2865857596], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7350600.0000, 
sim time next is 7351200.0000, 
raw observation next is [25.0, 72.0, 1.0, 2.0, 0.3529430983346466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 544314.467373413, 544314.467373413, 170190.4459524591], 
processed observation next is [1.0, 0.08695652173913043, 0.38388625592417064, 0.72, 1.0, 1.0, 0.22041337148752602, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1511984631592814, 0.1511984631592814, 0.25401559097381954], 
reward next is 0.7460, 
noisyNet noise sample is [array([0.4933356], dtype=float32), 0.5334706]. 
=============================================
[2019-03-26 21:08:14,258] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7880674e-29 0.0000000e+00], sum to 1.0000
[2019-03-26 21:08:14,266] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4810
[2019-03-26 21:08:14,271] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 91.5, 1.0, 2.0, 0.3145421837505583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 496828.6231944223, 496828.6231944217, 166777.0656819067], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7435800.0000, 
sim time next is 7436400.0000, 
raw observation next is [21.36666666666667, 91.33333333333334, 1.0, 2.0, 0.3141037069787677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 496181.5054580989, 496181.5054580989, 166729.8703255484], 
processed observation next is [0.0, 0.043478260869565216, 0.21169036334913136, 0.9133333333333334, 1.0, 1.0, 0.17361892407080448, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13782819596058302, 0.13782819596058302, 0.2488505527246991], 
reward next is 0.7511, 
noisyNet noise sample is [array([-0.37082297], dtype=float32), 0.615213]. 
=============================================
[2019-03-26 21:08:18,162] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.00000e+00 1.00000e+00 0.00000e+00 5.08475e-33 0.00000e+00], sum to 1.0000
[2019-03-26 21:08:18,170] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9619
[2019-03-26 21:08:18,176] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 82.0, 1.0, 2.0, 0.394913388322563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 585719.1098138968, 585719.1098138962, 173115.0791195052], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7477200.0000, 
sim time next is 7477800.0000, 
raw observation next is [24.9, 81.66666666666667, 1.0, 2.0, 0.3972185431418468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 588120.0993658563, 588120.099365857, 173303.1534490435], 
processed observation next is [0.0, 0.5652173913043478, 0.3791469194312796, 0.8166666666666668, 1.0, 1.0, 0.2737572808937913, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1633666942682934, 0.1633666942682936, 0.2586614230582739], 
reward next is 0.7413, 
noisyNet noise sample is [array([-0.19926351], dtype=float32), 0.047928043]. 
=============================================
[2019-03-26 21:08:19,963] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.2905752e-32 0.0000000e+00], sum to 1.0000
[2019-03-26 21:08:19,969] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8729
[2019-03-26 21:08:19,975] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 90.0, 1.0, 2.0, 0.3607101615473272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 549408.6630846766, 549408.6630846772, 170409.6980436966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7466400.0000, 
sim time next is 7467000.0000, 
raw observation next is [23.0, 89.5, 1.0, 2.0, 0.362235323173999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 551038.4019061476, 551038.4019061476, 170525.2175578875], 
processed observation next is [0.0, 0.43478260869565216, 0.28909952606635075, 0.895, 1.0, 1.0, 0.2316088231012036, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15306622275170767, 0.15306622275170767, 0.25451525008639925], 
reward next is 0.7455, 
noisyNet noise sample is [array([1.8224455], dtype=float32), -3.392191]. 
=============================================
[2019-03-26 21:08:19,999] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[81.97683 ]
 [81.868   ]
 [81.858406]
 [81.84028 ]
 [81.84263 ]], R is [[81.88298035]
 [81.80980682]
 [81.7375412 ]
 [81.66613007]
 [81.59555054]].
[2019-03-26 21:08:20,668] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3415351e-32 0.0000000e+00], sum to 1.0000
[2019-03-26 21:08:20,677] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9392
[2019-03-26 21:08:20,682] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.05, 90.0, 1.0, 2.0, 0.3692852006950881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 559792.6163644551, 559792.6163644557, 171211.1128700213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7535400.0000, 
sim time next is 7536000.0000, 
raw observation next is [23.1, 90.0, 1.0, 2.0, 0.3711948784039869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 561825.6157539217, 561825.6157539217, 171359.5274785451], 
processed observation next is [0.0, 0.21739130434782608, 0.2938388625592418, 0.9, 1.0, 1.0, 0.24240346795661072, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15606267104275603, 0.15606267104275603, 0.2557604887739479], 
reward next is 0.7442, 
noisyNet noise sample is [array([-1.7772362], dtype=float32), -2.1866426]. 
=============================================
[2019-03-26 21:08:20,694] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[77.00525 ]
 [77.010895]
 [76.861595]
 [76.80584 ]
 [76.82123 ]], R is [[76.96520996]
 [76.9400177 ]
 [76.91516876]
 [76.89030457]
 [76.86540222]].
[2019-03-26 21:08:21,719] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 21:08:21,722] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:08:21,722] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:08:21,724] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:08:21,724] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:08:21,724] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:08:21,726] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:08:21,727] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:08:21,728] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:08:21,730] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:08:21,730] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:08:21,749] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run43
[2019-03-26 21:08:21,750] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run43
[2019-03-26 21:08:21,791] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run43
[2019-03-26 21:08:21,818] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run43
[2019-03-26 21:08:21,818] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run43
[2019-03-26 21:09:02,093] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.18917927]
[2019-03-26 21:09:02,095] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.05, 73.0, 1.0, 2.0, 0.7448860534151376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1041030.229583693, 1041030.229583693, 230831.1154615911]
[2019-03-26 21:09:02,095] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:09:02,098] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6419595e-25 0.0000000e+00], sampled 0.5387384117541224
[2019-03-26 21:09:04,596] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.18917927]
[2019-03-26 21:09:04,597] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.33333333333334, 98.0, 1.0, 2.0, 0.4793927355192894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742797.372358481, 742797.3723584805, 189103.1106037358]
[2019-03-26 21:09:04,598] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:09:04,601] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.7482042e-29 0.0000000e+00], sampled 0.8311846886796406
[2019-03-26 21:09:10,820] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.18917927]
[2019-03-26 21:09:10,822] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.36749526, 79.95759508, 1.0, 2.0, 0.9261086419191327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1294455.824155948, 1294455.824155948, 277225.7673835238]
[2019-03-26 21:09:10,825] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:09:10,826] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7375277e-23 0.0000000e+00], sampled 0.8651765498429749
[2019-03-26 21:10:06,298] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.18917927]
[2019-03-26 21:10:06,299] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.41666666666667, 74.0, 1.0, 2.0, 0.6829098421683427, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.988074666966231, 6.9112, 168.9124352404834, 1851213.884996809, 1796676.518733427, 381653.8280969222]
[2019-03-26 21:10:06,302] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:10:06,305] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.12618575e-29 1.00000000e+00 2.80065648e-30 1.08706655e-11
 4.28536399e-27], sampled 0.45140808234885355
[2019-03-26 21:10:06,308] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1851213.884996809 W.
[2019-03-26 21:10:15,125] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.18917927]
[2019-03-26 21:10:15,127] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.4, 71.0, 1.0, 2.0, 0.331549381078738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 521097.5879003964, 521097.5879003964, 168575.919186011]
[2019-03-26 21:10:15,128] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:10:15,132] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 5.195044e-30 0.000000e+00], sampled 0.9651195996058457
[2019-03-26 21:10:15,835] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8000.3614 3008257759.8898 1768.0000
[2019-03-26 21:10:16,136] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8664.9431 2779421571.3217 919.0000
[2019-03-26 21:10:16,144] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8260.5548 2927636896.2275 1326.0000
[2019-03-26 21:10:16,338] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.2099 2843143093.4172 1129.0000
[2019-03-26 21:10:16,438] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.1068 3164975987.6445 1770.0000
[2019-03-26 21:10:17,456] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1050000, evaluation results [1050000.0, 7882.106785907934, 3164975987.644517, 1770.0, 8260.55482184453, 2927636896.227545, 1326.0, 8664.943103899815, 2779421571.32169, 919.0, 8000.36137264863, 3008257759.889753, 1768.0, 8496.209854576988, 2843143093.417241, 1129.0]
[2019-03-26 21:10:24,597] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 9.9247884e-24 0.0000000e+00], sum to 1.0000
[2019-03-26 21:10:24,606] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5433
[2019-03-26 21:10:24,610] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.9, 88.0, 1.0, 2.0, 0.494073798632051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 690388.6793581739, 690388.6793581746, 182672.5519115474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7678800.0000, 
sim time next is 7679400.0000, 
raw observation next is [25.86666666666667, 88.00000000000001, 1.0, 2.0, 0.4925865389700069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 688309.7998596545, 688309.7998596552, 182442.4780367959], 
processed observation next is [1.0, 0.9130434782608695, 0.42496050552922615, 0.8800000000000001, 1.0, 1.0, 0.3886584806867553, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1911971666276818, 0.191197166627682, 0.2723022060250685], 
reward next is 0.7277, 
noisyNet noise sample is [array([0.16303803], dtype=float32), 0.79183125]. 
=============================================
[2019-03-26 21:10:26,756] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:10:26,757] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:10:26,843] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run6
[2019-03-26 21:10:28,189] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:10:28,191] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:10:28,270] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run6
[2019-03-26 21:10:30,805] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 8.794582e-25 0.000000e+00], sum to 1.0000
[2019-03-26 21:10:30,814] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4011
[2019-03-26 21:10:30,821] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.05, 83.66666666666667, 1.0, 2.0, 0.6462760089666977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 903157.2114684619, 903157.2114684612, 209674.6952352519], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7888200.0000, 
sim time next is 7888800.0000, 
raw observation next is [27.1, 83.33333333333334, 1.0, 2.0, 0.661616269386269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 924604.2363353607, 924604.2363353601, 212776.644352342], 
processed observation next is [1.0, 0.30434782608695654, 0.4834123222748816, 0.8333333333333335, 1.0, 1.0, 0.5923087582967097, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2568345100931557, 0.25683451009315555, 0.3175770811228985], 
reward next is 0.6824, 
noisyNet noise sample is [array([0.31017494], dtype=float32), 0.21854167]. 
=============================================
[2019-03-26 21:10:30,945] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.5181196e-23 0.0000000e+00], sum to 1.0000
[2019-03-26 21:10:30,957] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1691
[2019-03-26 21:10:30,963] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.25, 82.33333333333334, 1.0, 2.0, 0.6884623185816641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 962138.401794215, 962138.4017942144, 218372.8667873019], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7890600.0000, 
sim time next is 7891200.0000, 
raw observation next is [27.3, 82.0, 1.0, 2.0, 0.693768660305655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 969557.4943428776, 969557.4943428782, 219504.2672522336], 
processed observation next is [1.0, 0.34782608695652173, 0.4928909952606636, 0.82, 1.0, 1.0, 0.631046578681512, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2693215262063549, 0.2693215262063551, 0.32761830933169195], 
reward next is 0.6724, 
noisyNet noise sample is [array([2.0045295], dtype=float32), 1.4339004]. 
=============================================
[2019-03-26 21:10:33,095] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:10:33,096] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:10:33,171] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run6
[2019-03-26 21:10:34,496] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.477468e-17 9.999691e-01 4.043472e-19 3.082050e-05 3.154160e-17], sum to 1.0000
[2019-03-26 21:10:34,506] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1991
[2019-03-26 21:10:34,514] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1743303.995922912 W.
[2019-03-26 21:10:34,520] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.65, 77.0, 1.0, 2.0, 0.6234850928638141, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.950818614682857, 6.9112, 168.9126851894014, 1743303.995922912, 1715197.232246737, 369732.1980601398], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7810200.0000, 
sim time next is 7810800.0000, 
raw observation next is [28.76666666666667, 76.33333333333334, 1.0, 2.0, 0.5859183042835416, 1.0, 1.0, 0.5859183042835416, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1638171.604351366, 1638171.604351366, 329107.4657101447], 
processed observation next is [1.0, 0.391304347826087, 0.5624012638230649, 0.7633333333333334, 1.0, 1.0, 0.5011063907030622, 1.0, 0.5, 0.5011063907030622, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4550476678753794, 0.4550476678753794, 0.49120517270170855], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.312015], dtype=float32), 0.68234015]. 
=============================================
[2019-03-26 21:10:34,912] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.2895632e-26 1.0000000e+00 1.4507649e-27 1.1902734e-11 1.2514309e-25], sum to 1.0000
[2019-03-26 21:10:34,921] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5548
[2019-03-26 21:10:34,927] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2010954.94626976 W.
[2019-03-26 21:10:34,931] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.696094923887607, 6.9112, 168.9090522282963, 2010954.94626976, 1454136.343960603, 311353.130305023], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7821600.0000, 
sim time next is 7822200.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.6642529739603071, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.00271586825764, 6.9112, 168.9117735026306, 1825107.238559937, 1760183.186593606, 377214.1570230675], 
processed observation next is [1.0, 0.5217391304347826, 0.6682464454976303, 0.7, 1.0, 1.0, 0.5954855107955508, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.009151586825764025, 0.0, 0.8294341360424194, 0.5069742329333159, 0.4889397740537794, 0.5630062045120411], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3520408], dtype=float32), 0.11344083]. 
=============================================
[2019-03-26 21:10:35,209] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:10:35,211] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:10:35,279] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run6
[2019-03-26 21:10:35,796] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1058586: loss 0.7655
[2019-03-26 21:10:35,799] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1058586: learning rate 0.0010
[2019-03-26 21:10:35,856] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.8473613e-29 0.0000000e+00], sum to 1.0000
[2019-03-26 21:10:35,862] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6136
[2019-03-26 21:10:35,866] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.73333333333333, 78.0, 1.0, 2.0, 0.5261354190154246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 735205.1416437647, 735205.1416437647, 187793.2281707237], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7842000.0000, 
sim time next is 7842600.0000, 
raw observation next is [28.6, 79.0, 1.0, 2.0, 0.5261323101251307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 735200.7958745282, 735200.7958745282, 187792.7899914839], 
processed observation next is [1.0, 0.782608695652174, 0.5545023696682465, 0.79, 1.0, 1.0, 0.4290750724399165, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20422244329848008, 0.20422244329848008, 0.28028774625594616], 
reward next is 0.7197, 
noisyNet noise sample is [array([0.7291429], dtype=float32), 0.7143398]. 
=============================================
[2019-03-26 21:10:37,279] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1059339: loss 0.9519
[2019-03-26 21:10:37,283] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1059341: learning rate 0.0010
[2019-03-26 21:10:37,690] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:10:37,690] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:10:37,763] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run6
[2019-03-26 21:10:38,607] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.2452757e-15 4.3267542e-01 3.3636464e-16 5.6732452e-01 6.8600663e-14], sum to 1.0000
[2019-03-26 21:10:38,610] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1920
[2019-03-26 21:10:38,618] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2109511.729452129 W.
[2019-03-26 21:10:38,622] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.5, 65.5, 1.0, 2.0, 0.7543348531358043, 1.0, 2.0, 0.7543348531358043, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2109511.729452129, 2109511.729452129, 398247.2930493431], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7918200.0000, 
sim time next is 7918800.0000, 
raw observation next is [30.53333333333333, 65.0, 1.0, 2.0, 0.7024101506697246, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.981443476661921, 6.9112, 168.912537321678, 1878501.453495463, 1828668.437227766, 386051.4073403339], 
processed observation next is [1.0, 0.6521739130434783, 0.646129541864139, 0.65, 1.0, 1.0, 0.6414580128550899, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.00702434766619211, 0.0, 0.8294378867436201, 0.5218059593042953, 0.5079634547854905, 0.5761961303587073], 
reward next is 0.0726, 
noisyNet noise sample is [array([1.2404271], dtype=float32), 0.80328876]. 
=============================================
[2019-03-26 21:10:39,846] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:10:39,847] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:10:39,928] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run6
[2019-03-26 21:10:40,013] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:10:40,013] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:10:40,079] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run6
[2019-03-26 21:10:40,763] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:10:40,764] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:10:40,814] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run6
[2019-03-26 21:10:40,970] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1061244: loss 0.7425
[2019-03-26 21:10:40,972] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1061244: learning rate 0.0010
[2019-03-26 21:10:41,086] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0777747e-21 0.0000000e+00], sum to 1.0000
[2019-03-26 21:10:41,089] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1461
[2019-03-26 21:10:41,096] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.98333333333333, 91.16666666666667, 1.0, 2.0, 0.480370222992408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 725837.356430714, 725837.3564307146, 187275.9277884234], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 115800.0000, 
sim time next is 116400.0000, 
raw observation next is [22.96666666666667, 91.33333333333334, 1.0, 2.0, 0.6535443448802459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 987346.1738046781, 987346.1738046781, 220471.0667936307], 
processed observation next is [1.0, 0.34782608695652173, 0.2875197472353872, 0.9133333333333334, 1.0, 1.0, 0.5825835480484891, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.27426282605685504, 0.27426282605685504, 0.3290612937218369], 
reward next is 0.6709, 
noisyNet noise sample is [array([0.04127279], dtype=float32), 1.1776724]. 
=============================================
[2019-03-26 21:10:41,097] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:10:41,098] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:10:41,146] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run6
[2019-03-26 21:10:41,500] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:10:41,501] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:10:41,569] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run6
[2019-03-26 21:10:41,777] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:10:41,779] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:10:41,811] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run6
[2019-03-26 21:10:41,837] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:10:41,838] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:10:41,867] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:10:41,867] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:10:41,873] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run6
[2019-03-26 21:10:41,894] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:10:41,896] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:10:41,900] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:10:41,900] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:10:41,938] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run6
[2019-03-26 21:10:41,964] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run6
[2019-03-26 21:10:41,989] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run6
[2019-03-26 21:10:42,017] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:10:42,017] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:10:42,026] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run6
[2019-03-26 21:10:42,074] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1061813: loss 0.6440
[2019-03-26 21:10:42,078] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1061815: learning rate 0.0010
[2019-03-26 21:10:43,088] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 7.306326e-27 0.000000e+00], sum to 1.0000
[2019-03-26 21:10:43,093] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5303
[2019-03-26 21:10:43,096] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.03333333333333, 86.0, 1.0, 2.0, 0.2777831290618156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 447934.9116638265, 447934.9116638265, 163463.0103031926], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 336000.0000, 
sim time next is 336600.0000, 
raw observation next is [21.0, 86.0, 1.0, 2.0, 0.2767291524129772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 446506.1808600551, 446506.1808600551, 163368.3651714692], 
processed observation next is [0.0, 0.9130434782608695, 0.19431279620853087, 0.86, 1.0, 1.0, 0.12858934025659902, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12402949468334863, 0.12402949468334863, 0.2438333808529391], 
reward next is 0.7562, 
noisyNet noise sample is [array([2.0519583], dtype=float32), 1.1453949]. 
=============================================
[2019-03-26 21:10:43,380] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1062602: loss 0.7346
[2019-03-26 21:10:43,387] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1062602: learning rate 0.0010
[2019-03-26 21:10:46,965] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1064216: loss 1.0878
[2019-03-26 21:10:46,968] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1064217: learning rate 0.0010
[2019-03-26 21:10:47,293] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1064365: loss 0.4617
[2019-03-26 21:10:47,295] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1064365: learning rate 0.0010
[2019-03-26 21:10:47,986] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1064679: loss 0.0024
[2019-03-26 21:10:47,991] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1064679: learning rate 0.0010
[2019-03-26 21:10:49,086] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.9701637e-21 0.0000000e+00], sum to 1.0000
[2019-03-26 21:10:49,095] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6519
[2019-03-26 21:10:49,106] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 96.0, 1.0, 2.0, 0.2860759064107357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 460796.9032282293, 460796.9032282293, 164327.4826521666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 186000.0000, 
sim time next is 186600.0000, 
raw observation next is [19.9, 96.0, 1.0, 2.0, 0.286127378626733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 460879.9610897925, 460879.9610897932, 164333.1420590986], 
processed observation next is [0.0, 0.13043478260869565, 0.14218009478672985, 0.96, 1.0, 1.0, 0.1399125043695578, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12802221141383124, 0.12802221141383144, 0.2452733463568636], 
reward next is 0.7547, 
noisyNet noise sample is [array([-0.12292155], dtype=float32), 0.121034496]. 
=============================================
[2019-03-26 21:10:49,607] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1065404: loss 0.4722
[2019-03-26 21:10:49,609] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1065404: learning rate 0.0010
[2019-03-26 21:10:49,894] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1065539: loss 0.0039
[2019-03-26 21:10:49,898] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1065541: learning rate 0.0010
[2019-03-26 21:10:50,054] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1065615: loss 0.2756
[2019-03-26 21:10:50,057] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1065615: learning rate 0.0010
[2019-03-26 21:10:51,398] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1066210: loss 0.7907
[2019-03-26 21:10:51,399] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1066210: learning rate 0.0010
[2019-03-26 21:10:52,030] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1066494: loss 0.1018
[2019-03-26 21:10:52,032] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1066495: learning rate 0.0010
[2019-03-26 21:10:52,234] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1066588: loss 0.0975
[2019-03-26 21:10:52,237] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1066588: learning rate 0.0010
[2019-03-26 21:10:52,251] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1066592: loss 0.1029
[2019-03-26 21:10:52,252] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1066594: learning rate 0.0010
[2019-03-26 21:10:52,510] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1066709: loss 0.1445
[2019-03-26 21:10:52,514] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1066711: learning rate 0.0010
[2019-03-26 21:10:52,537] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1066721: loss 0.1010
[2019-03-26 21:10:52,538] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1066722: learning rate 0.0010
[2019-03-26 21:10:52,548] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1066725: loss 0.0954
[2019-03-26 21:10:52,554] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1066729: learning rate 0.0010
[2019-03-26 21:10:55,441] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1068015: loss 0.0022
[2019-03-26 21:10:55,444] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1068015: learning rate 0.0010
[2019-03-26 21:10:58,334] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1069319: loss 0.0026
[2019-03-26 21:10:58,339] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1069320: learning rate 0.0010
[2019-03-26 21:11:01,153] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1070582: loss 0.0067
[2019-03-26 21:11:01,158] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1070582: learning rate 0.0010
[2019-03-26 21:11:01,452] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.7589174e-21 0.0000000e+00], sum to 1.0000
[2019-03-26 21:11:01,458] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6245
[2019-03-26 21:11:01,463] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 76.0, 1.0, 2.0, 0.5188976835265001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 833468.6755814737, 833468.6755814737, 198534.5302903979], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 399600.0000, 
sim time next is 400200.0000, 
raw observation next is [22.55, 76.5, 1.0, 2.0, 0.522385142679708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 838717.0915180474, 838717.0915180481, 199160.1414957579], 
processed observation next is [1.0, 0.6521739130434783, 0.26777251184834133, 0.765, 1.0, 1.0, 0.4245604128671181, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23297696986612426, 0.23297696986612446, 0.297253942530982], 
reward next is 0.7027, 
noisyNet noise sample is [array([-0.24358858], dtype=float32), 0.0533651]. 
=============================================
[2019-03-26 21:11:04,730] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1072188: loss 0.0431
[2019-03-26 21:11:04,731] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1072188: learning rate 0.0010
[2019-03-26 21:11:05,087] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1072347: loss 0.0017
[2019-03-26 21:11:05,089] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1072347: learning rate 0.0010
[2019-03-26 21:11:05,889] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1072711: loss 4.0199
[2019-03-26 21:11:05,893] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1072711: learning rate 0.0010
[2019-03-26 21:11:07,390] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1073392: loss 0.0019
[2019-03-26 21:11:07,397] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1073393: learning rate 0.0010
[2019-03-26 21:11:07,771] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1073544: loss 3.0479
[2019-03-26 21:11:07,775] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1073545: learning rate 0.0010
[2019-03-26 21:11:08,113] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1073668: loss 0.0021
[2019-03-26 21:11:08,117] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1073669: learning rate 0.0010
[2019-03-26 21:11:09,383] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1074229: loss 0.0236
[2019-03-26 21:11:09,385] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1074229: learning rate 0.0010
[2019-03-26 21:11:09,832] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1074435: loss 0.0230
[2019-03-26 21:11:09,835] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1074435: learning rate 0.0010
[2019-03-26 21:11:10,135] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1074574: loss 0.0125
[2019-03-26 21:11:10,139] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1074575: learning rate 0.0010
[2019-03-26 21:11:10,155] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1074582: loss 0.0059
[2019-03-26 21:11:10,156] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1074582: learning rate 0.0010
[2019-03-26 21:11:10,370] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1074685: loss 0.0277
[2019-03-26 21:11:10,372] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1074686: learning rate 0.0010
[2019-03-26 21:11:10,443] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1074718: loss 0.0046
[2019-03-26 21:11:10,446] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1074719: learning rate 0.0010
[2019-03-26 21:11:10,455] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1074721: loss 0.0034
[2019-03-26 21:11:10,458] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1074722: learning rate 0.0010
[2019-03-26 21:11:11,060] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 21:11:11,062] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:11:11,062] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:11:11,063] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:11:11,065] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:11:11,065] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:11:11,066] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:11:11,067] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:11:11,067] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:11:11,068] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:11:11,070] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:11:11,093] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run44
[2019-03-26 21:11:11,116] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run44
[2019-03-26 21:11:11,136] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run44
[2019-03-26 21:11:11,167] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run44
[2019-03-26 21:11:11,167] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run44
[2019-03-26 21:11:30,663] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17528316]
[2019-03-26 21:11:30,664] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.16666666666667, 70.16666666666667, 1.0, 2.0, 0.2545285350105946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 417344.4070227034, 417344.4070227041, 161359.2172201032]
[2019-03-26 21:11:30,665] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:11:30,667] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.8482876e-25 0.0000000e+00], sampled 0.27813739209086563
[2019-03-26 21:11:36,683] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17528316]
[2019-03-26 21:11:36,684] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.92929874, 86.69787407666668, 1.0, 2.0, 0.4555950240072448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 657072.8609516602, 657072.8609516595, 179547.3604555922]
[2019-03-26 21:11:36,687] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:11:36,690] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.4942525e-27 0.0000000e+00], sampled 0.6440579231113172
[2019-03-26 21:12:05,922] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17528316]
[2019-03-26 21:12:05,923] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.83333333333333, 71.5, 1.0, 2.0, 0.5427197607385906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 758387.8537620524, 758387.8537620524, 190559.7242899053]
[2019-03-26 21:12:05,924] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:12:05,927] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.3803377e-27 0.0000000e+00], sampled 0.5186400506845056
[2019-03-26 21:12:08,799] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17528316]
[2019-03-26 21:12:08,801] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 89.0, 1.0, 2.0, 0.7492116210321024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1047078.492507196, 1047078.492507196, 231826.2129548819]
[2019-03-26 21:12:08,803] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:12:08,804] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.6611734e-23 0.0000000e+00], sampled 0.7290736954752579
[2019-03-26 21:12:14,485] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17528316]
[2019-03-26 21:12:14,485] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.48333333333333, 75.33333333333334, 1.0, 2.0, 0.5478595057094756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 765572.6388595215, 765572.6388595221, 191434.4672676616]
[2019-03-26 21:12:14,487] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:12:14,488] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 9.9512024e-26 0.0000000e+00], sampled 0.23048021036907318
[2019-03-26 21:12:20,755] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17528316]
[2019-03-26 21:12:20,757] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.14261106, 69.59503552, 1.0, 2.0, 0.5769622315949157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 806255.8914294239, 806255.8914294239, 196532.0449464339]
[2019-03-26 21:12:20,759] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:12:20,762] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 7.180222e-27 0.000000e+00], sampled 0.014041446298955318
[2019-03-26 21:12:50,433] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17528316]
[2019-03-26 21:12:50,433] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [37.0, 44.33333333333334, 1.0, 2.0, 0.5630426436644519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 786797.2410060572, 786797.2410060572, 194063.4748819417]
[2019-03-26 21:12:50,435] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:12:50,437] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 5.476341e-27 0.000000e+00], sampled 0.629161402540726
[2019-03-26 21:13:04,802] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17528316]
[2019-03-26 21:13:04,805] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.73333333333333, 72.0, 1.0, 2.0, 0.8333664670834602, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.98763216577812, 6.9112, 168.9124396145508, 2061772.102251322, 2007548.659187577, 416927.5204114142]
[2019-03-26 21:13:04,806] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:13:04,810] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.2017135e-35 1.0000000e+00 4.3779721e-37 8.1400899e-16 6.7582247e-35], sampled 0.34060331617768924
[2019-03-26 21:13:04,812] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2061772.102251322 W.
[2019-03-26 21:13:05,440] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7875.5479 3164832779.9872 1776.0000
[2019-03-26 21:13:05,943] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.6078 3008551080.6251 1766.0000
[2019-03-26 21:13:06,040] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.3646 2928274756.9043 1339.0000
[2019-03-26 21:13:06,169] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8494.2616 2843368869.3792 1131.0000
[2019-03-26 21:13:06,186] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.9780 2779795557.8698 926.0000
[2019-03-26 21:13:07,204] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1075000, evaluation results [1075000.0, 7875.547858307967, 3164832779.987157, 1776.0, 8254.364560983993, 2928274756.9042673, 1339.0, 8660.978046802229, 2779795557.8698077, 926.0, 7997.607833681256, 3008551080.6250534, 1766.0, 8494.261612308823, 2843368869.379151, 1131.0]
[2019-03-26 21:13:09,467] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1076016: loss 3.0578
[2019-03-26 21:13:09,469] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1076017: learning rate 0.0010
[2019-03-26 21:13:10,945] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 7.024485e-30 0.000000e+00], sum to 1.0000
[2019-03-26 21:13:10,956] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3323
[2019-03-26 21:13:10,962] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.63333333333333, 78.16666666666667, 1.0, 2.0, 0.2951472756626367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 471027.3742975031, 471027.3742975031, 165001.1317824985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 904200.0000, 
sim time next is 904800.0000, 
raw observation next is [22.76666666666667, 77.33333333333334, 1.0, 2.0, 0.2960186946083676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 472269.7981640099, 472269.7981640099, 165086.349841958], 
processed observation next is [0.0, 0.4782608695652174, 0.2780410742496052, 0.7733333333333334, 1.0, 1.0, 0.15182975254020192, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1311860550455583, 0.1311860550455583, 0.24639753707754924], 
reward next is 0.7536, 
noisyNet noise sample is [array([0.47476852], dtype=float32), -0.9651173]. 
=============================================
[2019-03-26 21:13:12,044] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.3730337e-21 0.0000000e+00], sum to 1.0000
[2019-03-26 21:13:12,053] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7136
[2019-03-26 21:13:12,058] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.15, 88.83333333333334, 1.0, 2.0, 0.2669562477402215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 434605.4772025349, 434605.4772025342, 162550.7975552343], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 798600.0000, 
sim time next is 799200.0000, 
raw observation next is [20.3, 88.0, 1.0, 2.0, 0.2680936876375796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 436119.7882263062, 436119.7882263068, 162655.294652], 
processed observation next is [0.0, 0.2608695652173913, 0.16113744075829392, 0.88, 1.0, 1.0, 0.11818516582840918, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1211443856184184, 0.12114438561841855, 0.24276909649552242], 
reward next is 0.7572, 
noisyNet noise sample is [array([-1.0681567], dtype=float32), -0.30777]. 
=============================================
[2019-03-26 21:13:12,423] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1077339: loss 2.5453
[2019-03-26 21:13:12,427] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1077340: learning rate 0.0010
[2019-03-26 21:13:15,013] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.0485172e-21 0.0000000e+00], sum to 1.0000
[2019-03-26 21:13:15,020] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0005
[2019-03-26 21:13:15,024] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.06666666666667, 58.33333333333334, 1.0, 2.0, 0.5886806297422197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 964628.6644423761, 964628.6644423761, 213178.2764068074], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 645600.0000, 
sim time next is 646200.0000, 
raw observation next is [24.1, 58.0, 1.0, 2.0, 0.6083669729066368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 997175.8916316932, 997175.8916316939, 217401.3184324259], 
processed observation next is [1.0, 0.4782608695652174, 0.3412322274881518, 0.58, 1.0, 1.0, 0.5281529794055865, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2769933032310259, 0.2769933032310261, 0.3244795797498894], 
reward next is 0.6755, 
noisyNet noise sample is [array([1.386894], dtype=float32), -0.2181312]. 
=============================================
[2019-03-26 21:13:15,208] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1078561: loss 1.6905
[2019-03-26 21:13:15,210] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1078562: learning rate 0.0010
[2019-03-26 21:13:18,916] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1080221: loss 1.2092
[2019-03-26 21:13:18,919] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1080222: learning rate 0.0010
[2019-03-26 21:13:19,237] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1080368: loss 1.3016
[2019-03-26 21:13:19,240] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1080369: learning rate 0.0010
[2019-03-26 21:13:20,081] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1080754: loss 0.0103
[2019-03-26 21:13:20,084] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1080754: learning rate 0.0010
[2019-03-26 21:13:21,442] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1081364: loss 1.4177
[2019-03-26 21:13:21,444] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1081364: learning rate 0.0010
[2019-03-26 21:13:21,855] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1081551: loss 0.0174
[2019-03-26 21:13:21,858] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1081553: learning rate 0.0010
[2019-03-26 21:13:22,261] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1081732: loss 1.1594
[2019-03-26 21:13:22,263] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1081733: learning rate 0.0010
[2019-03-26 21:13:23,233] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1082168: loss 0.6433
[2019-03-26 21:13:23,236] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1082169: learning rate 0.0010
[2019-03-26 21:13:23,737] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1082395: loss 0.8135
[2019-03-26 21:13:23,738] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1082395: learning rate 0.0010
[2019-03-26 21:13:24,182] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1082595: loss 0.6302
[2019-03-26 21:13:24,183] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1082596: learning rate 0.0010
[2019-03-26 21:13:24,203] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1082603: loss 0.6199
[2019-03-26 21:13:24,205] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1082604: learning rate 0.0010
[2019-03-26 21:13:24,235] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1082617: loss 0.5553
[2019-03-26 21:13:24,237] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1082618: learning rate 0.0010
[2019-03-26 21:13:24,436] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1082708: loss 0.5855
[2019-03-26 21:13:24,437] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1082708: learning rate 0.0010
[2019-03-26 21:13:24,565] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1082766: loss 0.6663
[2019-03-26 21:13:24,568] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1082768: learning rate 0.0010
[2019-03-26 21:13:27,422] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1084043: loss 0.0044
[2019-03-26 21:13:27,425] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1084044: learning rate 0.0010
[2019-03-26 21:13:30,274] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1085312: loss 0.0065
[2019-03-26 21:13:30,278] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1085312: learning rate 0.0010
[2019-03-26 21:13:30,510] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2054455e-27 0.0000000e+00], sum to 1.0000
[2019-03-26 21:13:30,521] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1344
[2019-03-26 21:13:30,529] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 85.0, 1.0, 2.0, 0.3024544091692027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 480719.1836881607, 480719.1836881614, 165658.2429373475], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 855000.0000, 
sim time next is 855600.0000, 
raw observation next is [21.86666666666667, 85.33333333333333, 1.0, 2.0, 0.3024213540901036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 480559.3748945583, 480559.3748945583, 165644.8633146615], 
processed observation next is [0.0, 0.9130434782608695, 0.23538704581358633, 0.8533333333333333, 1.0, 1.0, 0.15954380010855856, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1334887152484884, 0.1334887152484884, 0.24723113927561416], 
reward next is 0.7528, 
noisyNet noise sample is [array([-0.70315456], dtype=float32), 1.3472902]. 
=============================================
[2019-03-26 21:13:32,979] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1086531: loss 0.0071
[2019-03-26 21:13:32,985] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1086532: learning rate 0.0010
[2019-03-26 21:13:36,830] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1088253: loss 0.0044
[2019-03-26 21:13:36,833] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1088254: learning rate 0.0010
[2019-03-26 21:13:37,036] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1088348: loss 0.0033
[2019-03-26 21:13:37,038] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1088348: learning rate 0.0010
[2019-03-26 21:13:38,016] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1088783: loss 1.6908
[2019-03-26 21:13:38,019] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1088783: learning rate 0.0010
[2019-03-26 21:13:39,299] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1089357: loss 0.0136
[2019-03-26 21:13:39,305] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1089360: learning rate 0.0010
[2019-03-26 21:13:39,963] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1089665: loss 1.3562
[2019-03-26 21:13:39,965] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1089665: learning rate 0.0010
[2019-03-26 21:13:40,083] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1089719: loss 0.0022
[2019-03-26 21:13:40,087] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1089719: learning rate 0.0010
[2019-03-26 21:13:41,026] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1090140: loss 0.0023
[2019-03-26 21:13:41,029] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1090140: learning rate 0.0010
[2019-03-26 21:13:41,553] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1090376: loss 0.0022
[2019-03-26 21:13:41,558] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1090377: learning rate 0.0010
[2019-03-26 21:13:41,781] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3637043e-35 1.0000000e+00 3.1829580e-36 6.9848772e-17 2.2210481e-34], sum to 1.0000
[2019-03-26 21:13:41,784] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4135
[2019-03-26 21:13:41,788] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1761021.294742933 W.
[2019-03-26 21:13:41,795] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.66666666666667, 72.33333333333333, 1.0, 2.0, 0.6298213893824568, 1.0, 1.0, 0.6298213893824568, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1761021.294742933, 1761021.294742934, 345514.8906995728], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1248000.0000, 
sim time next is 1248600.0000, 
raw observation next is [27.88333333333333, 71.66666666666667, 1.0, 2.0, 0.4209957723986577, 1.0, 2.0, 0.4209957723986577, 1.0, 1.0, 0.7076121991048478, 6.9112, 6.9112, 170.5573041426782, 1765700.919873405, 1765700.919873405, 361230.4122876253], 
processed observation next is [1.0, 0.43478260869565216, 0.5205371248025275, 0.7166666666666667, 1.0, 1.0, 0.3024045450586237, 1.0, 1.0, 0.3024045450586237, 1.0, 0.5, 0.643429511103473, 0.0, 0.0, 0.8375144448122397, 0.4904724777426125, 0.4904724777426125, 0.5391498690860079], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.67447], dtype=float32), -1.1532563]. 
=============================================
[2019-03-26 21:13:41,848] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1090508: loss 0.0033
[2019-03-26 21:13:41,851] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1090509: learning rate 0.0010
[2019-03-26 21:13:41,996] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1090577: loss 0.0052
[2019-03-26 21:13:42,000] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1090577: learning rate 0.0010
[2019-03-26 21:13:42,123] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1090629: loss 0.0063
[2019-03-26 21:13:42,124] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1090630: learning rate 0.0010
[2019-03-26 21:13:42,329] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1090724: loss 0.0022
[2019-03-26 21:13:42,332] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1090725: learning rate 0.0010
[2019-03-26 21:13:42,438] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1090771: loss 0.0029
[2019-03-26 21:13:42,443] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1090771: learning rate 0.0010
[2019-03-26 21:13:43,428] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4490326e-21 0.0000000e+00], sum to 1.0000
[2019-03-26 21:13:43,433] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8010
[2019-03-26 21:13:43,442] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.43333333333333, 76.5, 1.0, 2.0, 0.6154148951735493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 970709.9612730056, 970709.9612730056, 216602.6874939174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1079400.0000, 
sim time next is 1080000.0000, 
raw observation next is [23.6, 76.0, 1.0, 2.0, 0.6042018325341043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 950976.3712487163, 950976.371248717, 214021.3898155386], 
processed observation next is [1.0, 0.5217391304347826, 0.3175355450236968, 0.76, 1.0, 1.0, 0.5231347379928968, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2641601031246434, 0.2641601031246436, 0.3194349101724457], 
reward next is 0.6806, 
noisyNet noise sample is [array([0.07916869], dtype=float32), -0.5338575]. 
=============================================
[2019-03-26 21:13:43,479] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[62.596592]
 [62.801468]
 [63.059628]
 [63.123642]
 [63.00354 ]], R is [[62.80233002]
 [62.85102081]
 [62.90369797]
 [62.96313095]
 [63.02612686]].
[2019-03-26 21:13:45,488] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1092125: loss 1.2894
[2019-03-26 21:13:45,491] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1092127: learning rate 0.0010
[2019-03-26 21:13:48,456] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1093456: loss 1.6146
[2019-03-26 21:13:48,458] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1093456: learning rate 0.0010
[2019-03-26 21:13:51,017] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1094610: loss 1.3007
[2019-03-26 21:13:51,021] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1094610: learning rate 0.0010
[2019-03-26 21:13:52,073] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.00000e+00 1.00000e+00 0.00000e+00 8.65027e-27 0.00000e+00], sum to 1.0000
[2019-03-26 21:13:52,083] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9367
[2019-03-26 21:13:52,087] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 93.66666666666667, 1.0, 2.0, 0.3507683142374582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 542852.3509460131, 542852.3509460137, 170122.107738015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1228800.0000, 
sim time next is 1229400.0000, 
raw observation next is [22.05, 93.0, 1.0, 2.0, 0.3535431868440564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 546104.3756138663, 546104.3756138663, 170362.8192823101], 
processed observation next is [1.0, 0.21739130434782608, 0.24407582938388633, 0.93, 1.0, 1.0, 0.2211363696916342, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15169565989274061, 0.15169565989274061, 0.25427286460046283], 
reward next is 0.7457, 
noisyNet noise sample is [array([0.5529791], dtype=float32), -1.2079389]. 
=============================================
[2019-03-26 21:13:54,780] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1096289: loss 0.7863
[2019-03-26 21:13:54,784] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1096291: learning rate 0.0010
[2019-03-26 21:13:54,934] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1096358: loss 0.8718
[2019-03-26 21:13:54,938] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1096358: learning rate 0.0010
[2019-03-26 21:13:55,013] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.2239123e-32 1.0000000e+00 2.6415675e-34 1.3520831e-09 1.7343958e-30], sum to 1.0000
[2019-03-26 21:13:55,023] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9229
[2019-03-26 21:13:55,031] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2111247.15061353 W.
[2019-03-26 21:13:55,037] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.1, 74.66666666666667, 1.0, 2.0, 0.8687150609881675, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.971243138945748, 6.9112, 168.9125985275383, 2111247.15061353, 2068650.57159661, 426693.4040022239], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1266000.0000, 
sim time next is 1266600.0000, 
raw observation next is [28.05, 74.83333333333333, 1.0, 2.0, 0.4954711268883986, 1.0, 1.0, 0.4954711268883986, 1.0, 2.0, 0.8413549699199876, 6.9112, 6.9112, 170.5573041426782, 2078361.421711283, 2078361.421711283, 408560.4235439116], 
processed observation next is [1.0, 0.6521739130434783, 0.528436018957346, 0.7483333333333333, 1.0, 1.0, 0.39213388781734776, 1.0, 0.5, 0.39213388781734776, 1.0, 1.0, 0.8065304511219361, 0.0, 0.0, 0.8375144448122397, 0.577322617142023, 0.577322617142023, 0.6097916769312114], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.14162138], dtype=float32), -0.80353785]. 
=============================================
[2019-03-26 21:13:55,605] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1096659: loss 0.0039
[2019-03-26 21:13:55,610] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1096659: learning rate 0.0010
[2019-03-26 21:13:57,110] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1097330: loss 0.8490
[2019-03-26 21:13:57,113] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1097330: learning rate 0.0010
[2019-03-26 21:13:57,650] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1097573: loss 0.0043
[2019-03-26 21:13:57,656] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1097573: learning rate 0.0010
[2019-03-26 21:13:57,923] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1097694: loss 0.6466
[2019-03-26 21:13:57,927] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1097695: learning rate 0.0010
[2019-03-26 21:13:58,861] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.4178787e-19 0.0000000e+00], sum to 1.0000
[2019-03-26 21:13:58,870] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2143
[2019-03-26 21:13:58,874] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 95.0, 1.0, 2.0, 0.8019855926611088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1191201.307154278, 1191201.307154278, 254015.6109170088], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1330800.0000, 
sim time next is 1331400.0000, 
raw observation next is [23.0, 95.0, 1.0, 2.0, 0.8186791100821583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1215964.151809479, 1215964.151809479, 258442.3912793213], 
processed observation next is [1.0, 0.391304347826087, 0.28909952606635075, 0.95, 1.0, 1.0, 0.7815410964845281, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33776781994707755, 0.33776781994707755, 0.385734912357196], 
reward next is 0.6143, 
noisyNet noise sample is [array([-0.11564932], dtype=float32), 0.6836147]. 
=============================================
[2019-03-26 21:13:58,967] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1098164: loss 0.7569
[2019-03-26 21:13:58,969] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1098164: learning rate 0.0010
[2019-03-26 21:13:59,512] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1098410: loss 0.8167
[2019-03-26 21:13:59,514] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1098411: learning rate 0.0010
[2019-03-26 21:13:59,695] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1098497: loss 0.5914
[2019-03-26 21:13:59,696] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1098497: learning rate 0.0010
[2019-03-26 21:13:59,970] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1098603: loss 0.5368
[2019-03-26 21:13:59,974] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1098604: learning rate 0.0010
[2019-03-26 21:14:00,027] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1098627: loss 0.4640
[2019-03-26 21:14:00,029] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1098628: learning rate 0.0010
[2019-03-26 21:14:00,436] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1098782: loss 0.7251
[2019-03-26 21:14:00,439] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1098782: learning rate 0.0010
[2019-03-26 21:14:00,504] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1098804: loss 0.7521
[2019-03-26 21:14:00,509] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1098806: learning rate 0.0010
[2019-03-26 21:14:02,234] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 4.698899e-24 0.000000e+00], sum to 1.0000
[2019-03-26 21:14:02,244] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9241
[2019-03-26 21:14:02,248] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 98.0, 1.0, 2.0, 0.3048391428512721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 485239.5302921806, 485239.53029218, 165995.854233575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1391400.0000, 
sim time next is 1392000.0000, 
raw observation next is [20.26666666666667, 98.0, 1.0, 2.0, 0.3050233257361261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 485352.8525933396, 485352.8525933389, 166001.3273036943], 
processed observation next is [0.0, 0.08695652173913043, 0.15955766192733034, 0.98, 1.0, 1.0, 0.16267870570617604, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13482023683148323, 0.13482023683148303, 0.24776317508014076], 
reward next is 0.7522, 
noisyNet noise sample is [array([1.089997], dtype=float32), -0.32336882]. 
=============================================
[2019-03-26 21:14:02,263] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[79.65766]
 [80.21741]
 [80.89302]
 [80.93775]
 [81.05251]], R is [[79.33381653]
 [79.29272461]
 [79.25205994]
 [79.21183014]
 [79.17199707]].
[2019-03-26 21:14:03,153] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 21:14:03,154] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:14:03,155] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:14:03,155] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:14:03,157] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:14:03,158] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:14:03,159] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:14:03,156] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:14:03,165] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:14:03,168] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:14:03,160] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:14:03,178] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run45
[2019-03-26 21:14:03,200] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run45
[2019-03-26 21:14:03,217] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run45
[2019-03-26 21:14:03,242] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run45
[2019-03-26 21:14:03,260] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run45
[2019-03-26 21:14:41,982] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.1805993]
[2019-03-26 21:14:41,983] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.0, 100.0, 1.0, 2.0, 0.4300009904569671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 624140.126048276, 624140.1260482754, 176346.2269402324]
[2019-03-26 21:14:41,983] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:14:41,986] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 2.708621e-25 0.000000e+00], sampled 0.07148908091701578
[2019-03-26 21:14:42,090] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.1805993]
[2019-03-26 21:14:42,091] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.36666666666667, 85.83333333333334, 1.0, 2.0, 0.5088106574395467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 710987.9610119676, 710987.961011967, 184987.2946880446]
[2019-03-26 21:14:42,092] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:14:42,096] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.1892015e-25 0.0000000e+00], sampled 0.7389901065750073
[2019-03-26 21:14:55,296] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.1805993]
[2019-03-26 21:14:55,297] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.96311688666666, 74.21658608666667, 1.0, 2.0, 0.7213037080927152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1008056.613880896, 1008056.613880896, 225507.8174962612]
[2019-03-26 21:14:55,299] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:14:55,304] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.3633586e-24 0.0000000e+00], sampled 0.5676376564945681
[2019-03-26 21:15:01,101] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.1805993]
[2019-03-26 21:15:01,103] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 93.16666666666667, 1.0, 2.0, 0.771459003842464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1078186.635213228, 1078186.635213228, 237027.3450362605]
[2019-03-26 21:15:01,104] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:15:01,108] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 9.659406e-24 0.000000e+00], sampled 0.9401321449402549
[2019-03-26 21:15:09,171] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.1805993]
[2019-03-26 21:15:09,173] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [35.0, 60.0, 1.0, 2.0, 0.7602284354855956, 1.0, 2.0, 0.7007042572570603, 1.0, 1.0, 1.03, 7.005102481592744, 6.9112, 170.5573041426782, 2940295.666362191, 2873029.499088574, 541027.9201352113]
[2019-03-26 21:15:09,173] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:15:09,178] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.6214704e-37 1.0000000e+00 0.0000000e+00 9.2839417e-16 4.3956773e-37], sampled 0.29241910200844223
[2019-03-26 21:15:09,179] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2940295.666362191 W.
[2019-03-26 21:15:13,527] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.1805993]
[2019-03-26 21:15:13,528] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.08333333333334, 54.66666666666666, 1.0, 2.0, 0.5357109461493575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 748590.3979827136, 748590.3979827136, 189380.264312998]
[2019-03-26 21:15:13,529] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:15:13,531] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 6.885769e-26 0.000000e+00], sampled 0.9574125710343493
[2019-03-26 21:15:35,501] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.1805993]
[2019-03-26 21:15:35,502] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.260919415, 74.65009071, 1.0, 2.0, 0.8962552792785848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1252704.07327624, 1252704.07327624, 268907.399741697]
[2019-03-26 21:15:35,502] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:15:35,505] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 7.964117e-25 0.000000e+00], sampled 0.9888830390784505
[2019-03-26 21:15:49,675] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.1805993]
[2019-03-26 21:15:49,676] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.1, 64.0, 1.0, 2.0, 0.7065831619513561, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005975694517467, 6.9112, 168.9123160413208, 1884341.010112643, 1817104.125438088, 386100.7582255003]
[2019-03-26 21:15:49,678] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:15:49,680] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 1.063787e-17 0.000000e+00], sampled 0.17319607547403504
[2019-03-26 21:15:49,683] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1884341.010112643 W.
[2019-03-26 21:15:54,780] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.1805993]
[2019-03-26 21:15:54,782] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.13333333333333, 59.33333333333334, 1.0, 2.0, 0.9555135278994065, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.98697509247299, 6.9112, 168.9124443024383, 2232736.69030135, 2178979.394736554, 450618.0945687414]
[2019-03-26 21:15:54,786] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:15:54,790] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.4087099e-37 1.0000000e+00 0.0000000e+00 6.4808900e-16 2.5444497e-37], sampled 0.5907668585544862
[2019-03-26 21:15:54,793] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2232736.69030135 W.
[2019-03-26 21:15:57,512] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8494.2616 2843368869.3792 1131.0000
[2019-03-26 21:15:57,724] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7875.0081 3164870559.0756 1778.0000
[2019-03-26 21:15:57,768] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.7044 3008486396.2608 1766.0000
[2019-03-26 21:15:57,841] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.7981 2928166400.6515 1338.0000
[2019-03-26 21:15:57,906] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.1120 2780070553.5627 933.0000
[2019-03-26 21:15:58,921] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1100000, evaluation results [1100000.0, 7875.008135704462, 3164870559.075631, 1778.0, 8253.798072009333, 2928166400.6514535, 1338.0, 8658.112016599982, 2780070553.5627275, 933.0, 7997.704377508541, 3008486396.260774, 1766.0, 8494.261612308823, 2843368869.379151, 1131.0]
[2019-03-26 21:15:59,009] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1100044: loss 0.0174
[2019-03-26 21:15:59,012] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1100045: learning rate 0.0010
[2019-03-26 21:16:01,992] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1101384: loss 0.0128
[2019-03-26 21:16:01,996] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1101385: learning rate 0.0010
[2019-03-26 21:16:04,513] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1102517: loss 0.0155
[2019-03-26 21:16:04,515] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1102519: learning rate 0.0010
[2019-03-26 21:16:07,154] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.8672282e-28 0.0000000e+00], sum to 1.0000
[2019-03-26 21:16:07,164] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9314
[2019-03-26 21:16:07,169] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.31666666666667, 87.0, 1.0, 2.0, 0.49862492834201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 696750.2368443463, 696750.2368443457, 183381.0535121461], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1879800.0000, 
sim time next is 1880400.0000, 
raw observation next is [26.23333333333333, 87.0, 1.0, 2.0, 0.4979567869974339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 695816.3081932284, 695816.3081932284, 183276.5572540208], 
processed observation next is [1.0, 0.782608695652174, 0.44233807266982617, 0.87, 1.0, 1.0, 0.39512865903305294, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19328230783145234, 0.19328230783145234, 0.2735471003791355], 
reward next is 0.7265, 
noisyNet noise sample is [array([0.78937984], dtype=float32), -0.23535733]. 
=============================================
[2019-03-26 21:16:08,400] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1104263: loss 0.0463
[2019-03-26 21:16:08,405] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1104263: learning rate 0.0010
[2019-03-26 21:16:08,502] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1104311: loss 0.0439
[2019-03-26 21:16:08,503] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1104311: learning rate 0.0010
[2019-03-26 21:16:09,574] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1104791: loss -119.3767
[2019-03-26 21:16:09,575] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1104792: learning rate 0.0010
[2019-03-26 21:16:10,753] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1105319: loss 0.0137
[2019-03-26 21:16:10,757] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1105319: learning rate 0.0010
[2019-03-26 21:16:11,490] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1105643: loss 0.0053
[2019-03-26 21:16:11,492] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1105643: learning rate 0.0010
[2019-03-26 21:16:11,777] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1105775: loss -37.0345
[2019-03-26 21:16:11,782] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1105776: learning rate 0.0010
[2019-03-26 21:16:12,548] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1106116: loss 0.0059
[2019-03-26 21:16:12,551] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1106116: learning rate 0.0010
[2019-03-26 21:16:13,106] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1106350: loss 0.0348
[2019-03-26 21:16:13,108] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1106351: learning rate 0.0010
[2019-03-26 21:16:13,237] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1106411: loss 0.0447
[2019-03-26 21:16:13,241] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1106411: learning rate 0.0010
[2019-03-26 21:16:13,510] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1106530: loss 0.0141
[2019-03-26 21:16:13,512] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1106530: learning rate 0.0010
[2019-03-26 21:16:13,566] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1106555: loss 0.0054
[2019-03-26 21:16:13,567] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1106556: learning rate 0.0010
[2019-03-26 21:16:13,883] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1106694: loss 0.0141
[2019-03-26 21:16:13,884] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1106695: learning rate 0.0010
[2019-03-26 21:16:14,003] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1106753: loss 0.0084
[2019-03-26 21:16:14,007] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1106755: learning rate 0.0010
[2019-03-26 21:16:14,092] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.0815307e-29 0.0000000e+00], sum to 1.0000
[2019-03-26 21:16:14,099] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3124
[2019-03-26 21:16:14,104] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666666, 89.0, 1.0, 2.0, 0.9251684943578017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1293140.94533404, 1293140.94533404, 276951.4914677984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1680000.0000, 
sim time next is 1680600.0000, 
raw observation next is [25.78333333333333, 88.5, 1.0, 2.0, 0.9213328693092347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1287776.504167697, 1287776.504167696, 275870.1029602659], 
processed observation next is [1.0, 0.43478260869565216, 0.4210110584518167, 0.885, 1.0, 1.0, 0.9052203244689575, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.35771569560213806, 0.3577156956021378, 0.411746422328755], 
reward next is 0.5883, 
noisyNet noise sample is [array([-2.2513902], dtype=float32), 0.18092792]. 
=============================================
[2019-03-26 21:16:15,798] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.3502415e-24 0.0000000e+00], sum to 1.0000
[2019-03-26 21:16:15,805] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7475
[2019-03-26 21:16:15,809] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 94.0, 1.0, 2.0, 0.5137183490508516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 721897.8675752864, 721897.8675752857, 186292.2935799577], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1738800.0000, 
sim time next is 1739400.0000, 
raw observation next is [24.46666666666667, 94.00000000000001, 1.0, 2.0, 0.5072102117221868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 713654.1920733452, 713654.1920733452, 185362.3277467391], 
processed observation next is [1.0, 0.13043478260869565, 0.3586097946287521, 0.9400000000000002, 1.0, 1.0, 0.406277363520707, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1982372755759292, 0.1982372755759292, 0.2766601906667748], 
reward next is 0.7233, 
noisyNet noise sample is [array([-0.98016953], dtype=float32), 0.07418407]. 
=============================================
[2019-03-26 21:16:17,252] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1108203: loss -36.6791
[2019-03-26 21:16:17,254] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1108204: learning rate 0.0010
[2019-03-26 21:16:20,396] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1109612: loss -32.0254
[2019-03-26 21:16:20,398] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1109612: learning rate 0.0010
[2019-03-26 21:16:21,597] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 5.103204e-28 0.000000e+00], sum to 1.0000
[2019-03-26 21:16:21,603] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7846
[2019-03-26 21:16:21,610] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.85, 93.0, 1.0, 2.0, 0.517420236584005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 723022.6742631162, 723022.6742631169, 186370.2758857028], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2159400.0000, 
sim time next is 2160000.0000, 
raw observation next is [25.8, 93.0, 1.0, 2.0, 0.5151240273938602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 719812.954775663, 719812.954775663, 185999.4616185058], 
processed observation next is [1.0, 0.0, 0.42180094786729866, 0.93, 1.0, 1.0, 0.4158120811974219, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1999480429932397, 0.1999480429932397, 0.2776111367440385], 
reward next is 0.7224, 
noisyNet noise sample is [array([-0.29791045], dtype=float32), -0.24647757]. 
=============================================
[2019-03-26 21:16:21,622] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[75.655266]
 [75.62726 ]
 [75.59745 ]
 [75.56801 ]
 [75.548836]], R is [[71.62665558]
 [71.63222504]
 [71.6373291 ]
 [71.64219666]
 [71.64674377]].
[2019-03-26 21:16:21,726] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.7257665e-24 0.0000000e+00], sum to 1.0000
[2019-03-26 21:16:21,732] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5227
[2019-03-26 21:16:21,737] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.63333333333333, 89.33333333333334, 1.0, 2.0, 0.3198937329153505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 505013.0015271572, 505013.0015271578, 167385.8123236103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1797000.0000, 
sim time next is 1797600.0000, 
raw observation next is [21.56666666666667, 89.66666666666667, 1.0, 2.0, 0.319945060754221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 505384.0424212043, 505384.0424212049, 167419.6411399539], 
processed observation next is [1.0, 0.8260869565217391, 0.22116903633491333, 0.8966666666666667, 1.0, 1.0, 0.18065669970388074, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14038445622811233, 0.14038445622811246, 0.24988006140291627], 
reward next is 0.7501, 
noisyNet noise sample is [array([0.9701138], dtype=float32), 0.48261145]. 
=============================================
[2019-03-26 21:16:22,588] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1110597: loss -250.0738
[2019-03-26 21:16:22,590] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1110597: learning rate 0.0010
[2019-03-26 21:16:26,457] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1112336: loss -178.7594
[2019-03-26 21:16:26,460] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1112337: learning rate 0.0010
[2019-03-26 21:16:26,577] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1112389: loss 13.8840
[2019-03-26 21:16:26,580] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1112390: learning rate 0.0010
[2019-03-26 21:16:27,614] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1112852: loss 4.8600
[2019-03-26 21:16:27,617] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1112852: learning rate 0.0010
[2019-03-26 21:16:28,697] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1113330: loss -275.5043
[2019-03-26 21:16:28,699] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1113331: learning rate 0.0010
[2019-03-26 21:16:29,422] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1113652: loss 3.7499
[2019-03-26 21:16:29,426] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1113654: learning rate 0.0010
[2019-03-26 21:16:29,707] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 4.306722e-25 0.000000e+00], sum to 1.0000
[2019-03-26 21:16:29,717] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4272
[2019-03-26 21:16:29,729] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 95.0, 1.0, 2.0, 0.396608801474673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 594971.5360482881, 594971.5360482887, 174166.8095628442], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1972800.0000, 
sim time next is 1973400.0000, 
raw observation next is [22.75, 95.16666666666667, 1.0, 2.0, 0.3969729916074312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 594916.8215369716, 594916.8215369722, 174144.8817710449], 
processed observation next is [1.0, 0.8695652173913043, 0.27725118483412325, 0.9516666666666667, 1.0, 1.0, 0.27346143567160386, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16525467264915877, 0.16525467264915894, 0.25991773398663415], 
reward next is 0.7401, 
noisyNet noise sample is [array([1.0102803], dtype=float32), 2.242004]. 
=============================================
[2019-03-26 21:16:29,735] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1113793: loss 4.8270
[2019-03-26 21:16:29,738] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1113796: learning rate 0.0010
[2019-03-26 21:16:30,627] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1114192: loss -20.8427
[2019-03-26 21:16:30,633] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1114193: learning rate 0.0010
[2019-03-26 21:16:31,142] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1114418: loss 41.7726
[2019-03-26 21:16:31,145] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1114418: learning rate 0.0010
[2019-03-26 21:16:31,262] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1114470: loss -21.0602
[2019-03-26 21:16:31,266] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1114471: learning rate 0.0010
[2019-03-26 21:16:31,271] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1114472: loss -104.4294
[2019-03-26 21:16:31,273] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1114473: learning rate 0.0010
[2019-03-26 21:16:31,355] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1114509: loss -64.3892
[2019-03-26 21:16:31,357] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1114509: learning rate 0.0010
[2019-03-26 21:16:31,528] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 2.420297e-26 0.000000e+00], sum to 1.0000
[2019-03-26 21:16:31,535] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2572
[2019-03-26 21:16:31,540] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.01666666666667, 89.33333333333334, 1.0, 2.0, 0.5373715115108973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 750911.6547711656, 750911.654771165, 189658.679064698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2149800.0000, 
sim time next is 2150400.0000, 
raw observation next is [26.93333333333334, 89.66666666666667, 1.0, 2.0, 0.5391069384648353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 753337.5638576915, 753337.5638576915, 189950.0373977612], 
processed observation next is [0.0, 0.9130434782608695, 0.4755134281200636, 0.8966666666666667, 1.0, 1.0, 0.4447071547769099, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2092604344049143, 0.2092604344049143, 0.2835075185041212], 
reward next is 0.7165, 
noisyNet noise sample is [array([-0.54255825], dtype=float32), 1.719632]. 
=============================================
[2019-03-26 21:16:31,716] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1114672: loss 5.0462
[2019-03-26 21:16:31,722] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1114673: learning rate 0.0010
[2019-03-26 21:16:31,909] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1114761: loss -165.4221
[2019-03-26 21:16:31,913] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1114762: learning rate 0.0010
[2019-03-26 21:16:35,216] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1116251: loss 4.8154
[2019-03-26 21:16:35,217] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1116251: learning rate 0.0010
[2019-03-26 21:16:38,004] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1117504: loss 3.2441
[2019-03-26 21:16:38,009] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1117504: learning rate 0.0010
[2019-03-26 21:16:39,418] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.7863223e-16 0.0000000e+00], sum to 1.0000
[2019-03-26 21:16:39,428] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2740
[2019-03-26 21:16:39,435] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.9, 77.66666666666666, 1.0, 2.0, 0.5762160637791944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 805212.7898215837, 805212.7898215842, 196398.7064164983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2411400.0000, 
sim time next is 2412000.0000, 
raw observation next is [29.8, 78.0, 1.0, 2.0, 0.5741745914193467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 802358.9288674291, 802358.9288674291, 196033.3951373182], 
processed observation next is [1.0, 0.9565217391304348, 0.6113744075829385, 0.78, 1.0, 1.0, 0.4869573390594538, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22287748024095255, 0.22287748024095255, 0.29258715692137044], 
reward next is 0.7074, 
noisyNet noise sample is [array([-0.00246688], dtype=float32), -0.35116753]. 
=============================================
[2019-03-26 21:16:39,457] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[63.703854]
 [63.89965 ]
 [63.655235]
 [63.484367]
 [63.258354]], R is [[64.0138855 ]
 [64.08061981]
 [64.14620209]
 [64.21077728]
 [64.27436066]].
[2019-03-26 21:16:40,282] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4108944e-21 0.0000000e+00], sum to 1.0000
[2019-03-26 21:16:40,290] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8916
[2019-03-26 21:16:40,298] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 76.33333333333334, 1.0, 2.0, 0.5635677638004177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 787531.3172691067, 787531.3172691074, 194155.6260370398], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2121600.0000, 
sim time next is 2122200.0000, 
raw observation next is [30.0, 76.5, 1.0, 2.0, 0.5654173247186274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 790116.860644358, 790116.8606443586, 194480.7021696262], 
processed observation next is [0.0, 0.5652173913043478, 0.6208530805687204, 0.765, 1.0, 1.0, 0.4764064153236474, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21947690573454387, 0.21947690573454404, 0.29026970473078534], 
reward next is 0.7097, 
noisyNet noise sample is [array([1.1588913], dtype=float32), -1.1660705]. 
=============================================
[2019-03-26 21:16:40,364] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1118557: loss 3.6599
[2019-03-26 21:16:40,366] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1118557: learning rate 0.0010
[2019-03-26 21:16:42,340] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.00000e+00 1.00000e+00 0.00000e+00 7.84359e-14 0.00000e+00], sum to 1.0000
[2019-03-26 21:16:42,348] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0553
[2019-03-26 21:16:42,353] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.46666666666667, 69.33333333333334, 1.0, 2.0, 0.5346947260411704, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104269, 747169.8554828215, 747169.8554828209, 189213.9751299256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2222400.0000, 
sim time next is 2223000.0000, 
raw observation next is [31.3, 70.0, 1.0, 2.0, 0.5267521497373326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 736067.240411562, 736067.240411562, 187897.6359255071], 
processed observation next is [1.0, 0.7391304347826086, 0.6824644549763034, 0.7, 1.0, 1.0, 0.4298218671534128, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.204463122336545, 0.204463122336545, 0.2804442327246374], 
reward next is 0.7196, 
noisyNet noise sample is [array([2.1452286], dtype=float32), 1.1448841]. 
=============================================
[2019-03-26 21:16:42,367] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[60.85038 ]
 [52.453243]
 [41.8932  ]
 [43.32611 ]
 [40.366943]], R is [[64.81648254]
 [64.88591003]
 [64.83226013]
 [64.18393707]
 [63.542099  ]].
[2019-03-26 21:16:42,663] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.27962135e-20
 0.00000000e+00], sum to 1.0000
[2019-03-26 21:16:42,674] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5613
[2019-03-26 21:16:42,678] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.68333333333333, 80.83333333333333, 1.0, 2.0, 0.5521788851898377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 771610.6828985944, 771610.682898595, 192175.1877840316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2328600.0000, 
sim time next is 2329200.0000, 
raw observation next is [28.6, 81.0, 1.0, 2.0, 0.5506626327980185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 769491.1155753976, 769491.1155753976, 191914.4735542212], 
processed observation next is [1.0, 1.0, 0.5545023696682465, 0.81, 1.0, 1.0, 0.4586296780699018, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2137475321042771, 0.2137475321042771, 0.2864395127674943], 
reward next is 0.7136, 
noisyNet noise sample is [array([-1.5277532], dtype=float32), 0.9923869]. 
=============================================
[2019-03-26 21:16:43,793] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.6939877e-18 0.0000000e+00], sum to 1.0000
[2019-03-26 21:16:43,806] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0363
[2019-03-26 21:16:43,809] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 90.33333333333334, 1.0, 2.0, 0.6942852340193061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 970279.7476539674, 970279.7476539667, 219615.0888536948], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2182800.0000, 
sim time next is 2183400.0000, 
raw observation next is [26.4, 89.5, 1.0, 2.0, 0.7177656982018268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1003109.739681735, 1003109.739681735, 224725.4000877046], 
processed observation next is [1.0, 0.2608695652173913, 0.45023696682464454, 0.895, 1.0, 1.0, 0.6599586725323214, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2786415943560375, 0.2786415943560375, 0.3354110449070218], 
reward next is 0.6646, 
noisyNet noise sample is [array([1.59963], dtype=float32), -0.7371705]. 
=============================================
[2019-03-26 21:16:44,238] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1120284: loss 2.8802
[2019-03-26 21:16:44,242] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1120284: learning rate 0.0010
[2019-03-26 21:16:44,304] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1120314: loss 2.9942
[2019-03-26 21:16:44,305] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1120314: learning rate 0.0010
[2019-03-26 21:16:46,339] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1121225: loss -44.2080
[2019-03-26 21:16:46,341] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1121226: learning rate 0.0010
[2019-03-26 21:16:46,411] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1121251: loss 3.0465
[2019-03-26 21:16:46,413] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1121252: learning rate 0.0010
[2019-03-26 21:16:46,816] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1121430: loss 2.1442
[2019-03-26 21:16:46,818] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1121431: learning rate 0.0010
[2019-03-26 21:16:48,148] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1122032: loss 5.4009
[2019-03-26 21:16:48,150] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1122032: learning rate 0.0010
[2019-03-26 21:16:48,216] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1122061: loss -293.4515
[2019-03-26 21:16:48,222] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1122062: learning rate 0.0010
[2019-03-26 21:16:48,667] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1122259: loss 3.4859
[2019-03-26 21:16:48,670] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1122259: learning rate 0.0010
[2019-03-26 21:16:48,805] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1122323: loss 3.9788
[2019-03-26 21:16:48,806] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1122323: loss 3.7128
[2019-03-26 21:16:48,807] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1122323: learning rate 0.0010
[2019-03-26 21:16:48,809] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1122326: learning rate 0.0010
[2019-03-26 21:16:48,912] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1122366: loss 3.9612
[2019-03-26 21:16:48,915] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1122367: learning rate 0.0010
[2019-03-26 21:16:49,192] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1122493: loss 3.6311
[2019-03-26 21:16:49,195] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1122493: learning rate 0.0010
[2019-03-26 21:16:49,573] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1122662: loss 4.1494
[2019-03-26 21:16:49,577] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1122664: learning rate 0.0010
[2019-03-26 21:16:51,816] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.5895023e-22 1.0000000e+00 1.2236279e-23 2.1226347e-09 1.8612903e-21], sum to 1.0000
[2019-03-26 21:16:51,825] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8284
[2019-03-26 21:16:51,835] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2017686.563741975 W.
[2019-03-26 21:16:51,843] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.93333333333333, 63.66666666666667, 1.0, 2.0, 0.8018671455296374, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.000038031036274, 6.9112, 168.912428743322, 2017686.563741975, 1954662.003876106, 408523.3086317382], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2292000.0000, 
sim time next is 2292600.0000, 
raw observation next is [31.91666666666666, 63.83333333333334, 1.0, 2.0, 0.7372011221914514, 1.0, 1.0, 0.7372011221914514, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2061550.820422323, 2061550.820422323, 390459.0099695661], 
processed observation next is [1.0, 0.5217391304347826, 0.7116903633491308, 0.6383333333333334, 1.0, 1.0, 0.6833748460137968, 1.0, 0.5, 0.6833748460137968, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5726530056728675, 0.5726530056728675, 0.582774641745621], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.25287047], dtype=float32), -0.6066]. 
=============================================
[2019-03-26 21:16:53,616] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1124416: loss -226.0361
[2019-03-26 21:16:53,618] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1124417: learning rate 0.0010
[2019-03-26 21:16:54,876] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 21:16:54,878] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:16:54,879] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:16:54,880] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:16:54,881] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:16:54,881] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:16:54,883] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:16:54,882] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:16:54,885] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:16:54,886] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:16:54,888] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:16:54,907] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run46
[2019-03-26 21:16:54,927] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run46
[2019-03-26 21:16:54,948] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run46
[2019-03-26 21:16:54,968] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run46
[2019-03-26 21:16:54,969] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run46
[2019-03-26 21:17:00,413] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17848648]
[2019-03-26 21:17:00,414] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.26449362166667, 75.22848746000001, 1.0, 2.0, 0.2969783175565405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 473441.4135700373, 473441.4135700373, 165163.9472349689]
[2019-03-26 21:17:00,415] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:17:00,417] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7585726e-23 0.0000000e+00], sampled 0.31516705681712265
[2019-03-26 21:17:14,418] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17848648]
[2019-03-26 21:17:14,420] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.83404112166667, 94.21340969666667, 1.0, 2.0, 0.5596654323732384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 807519.6183291347, 807519.6183291347, 196711.4471653251]
[2019-03-26 21:17:14,421] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:17:14,424] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 7.186844e-22 0.000000e+00], sampled 0.17750113459887507
[2019-03-26 21:17:23,649] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17848648]
[2019-03-26 21:17:23,650] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.63333333333333, 86.66666666666667, 1.0, 2.0, 0.6206899003834251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 867487.6459204779, 867487.6459204779, 204667.0481160179]
[2019-03-26 21:17:23,651] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:17:23,653] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6540582e-21 0.0000000e+00], sampled 0.38488123608266833
[2019-03-26 21:17:43,386] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17848648]
[2019-03-26 21:17:43,388] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.67799454, 90.57412400666666, 1.0, 2.0, 0.7697751312663901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1075832.072519859, 1075832.072519859, 236634.948825016]
[2019-03-26 21:17:43,391] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:17:43,395] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2414776e-20 0.0000000e+00], sampled 0.4641994903714638
[2019-03-26 21:18:05,163] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17848648]
[2019-03-26 21:18:05,163] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.03672105666667, 91.08338299, 1.0, 2.0, 0.6043211447080005, 0.0, 2.0, 0.0, 1.0, 1.0, 1.023083486227476, 6.9112, 6.9112, 168.9125467222781, 1689677.721614733, 1689677.721614733, 364581.2672681052]
[2019-03-26 21:18:05,164] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:18:05,166] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.3661634e-18 0.0000000e+00], sampled 0.0017766705369751667
[2019-03-26 21:18:05,170] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1689677.721614733 W.
[2019-03-26 21:18:26,221] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17848648]
[2019-03-26 21:18:26,222] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.56666666666667, 83.0, 1.0, 2.0, 0.5671090286293949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 792481.7376208721, 792481.7376208721, 194777.861272265]
[2019-03-26 21:18:26,225] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:18:26,230] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 3.443328e-23 0.000000e+00], sampled 0.08820990691249186
[2019-03-26 21:18:34,791] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17848648]
[2019-03-26 21:18:34,794] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.55231149833333, 60.57125590166667, 1.0, 2.0, 0.4531381055626799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 649658.0529550506, 649658.0529550499, 178695.8097996979]
[2019-03-26 21:18:34,795] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:18:34,799] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.5775076e-23 0.0000000e+00], sampled 0.9567496499611751
[2019-03-26 21:18:48,581] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7876.6154 3164676497.9081 1778.0000
[2019-03-26 21:18:48,893] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.7138 2779867804.7524 933.0000
[2019-03-26 21:18:49,154] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.17848648]
[2019-03-26 21:18:49,156] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.75712574666667, 64.32378248, 1.0, 2.0, 0.8395184890897291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1238544.693570351, 1238544.69357035, 262978.3897589429]
[2019-03-26 21:18:49,157] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:18:49,159] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.2525982e-20 0.0000000e+00], sampled 0.5529237100473132
[2019-03-26 21:18:49,448] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.8629 2843167093.8007 1131.0000
[2019-03-26 21:18:49,480] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.0740 2927981547.8413 1338.0000
[2019-03-26 21:18:49,563] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.9766 3008303976.5521 1766.0000
[2019-03-26 21:18:50,578] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1125000, evaluation results [1125000.0, 7876.615402862808, 3164676497.9080544, 1778.0, 8254.073971726037, 2927981547.8412614, 1338.0, 8659.713804063274, 2779867804.752359, 933.0, 7997.976645730424, 3008303976.5521116, 1766.0, 8495.862932155293, 2843167093.8007364, 1131.0]
[2019-03-26 21:18:52,004] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1125642: loss -281.2715
[2019-03-26 21:18:52,009] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1125642: learning rate 0.0010
[2019-03-26 21:18:52,435] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.8893473e-28 1.0000000e+00 5.5173921e-29 3.2469090e-12 8.4536584e-27], sum to 1.0000
[2019-03-26 21:18:52,443] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4251
[2019-03-26 21:18:52,453] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1864558.56580156 W.
[2019-03-26 21:18:52,457] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.9, 89.0, 1.0, 2.0, 0.6924463082902399, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.967065013234626, 6.9112, 168.9118001431194, 1864558.56580156, 1824926.274009545, 384296.56999391], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2462400.0000, 
sim time next is 2463000.0000, 
raw observation next is [25.95, 89.0, 1.0, 2.0, 0.4635521460552256, 1.0, 1.0, 0.4635521460552256, 1.0, 2.0, 0.7866802850288904, 6.911200000000001, 6.9112, 170.5573041426782, 1944348.811264633, 1944348.811264632, 387765.332605847], 
processed observation next is [1.0, 0.5217391304347826, 0.42890995260663506, 0.89, 1.0, 1.0, 0.3536772844038863, 1.0, 0.5, 0.3536772844038863, 1.0, 1.0, 0.7398540061327931, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5400968920179536, 0.5400968920179533, 0.5787542277699209], 
reward next is 0.4212, 
noisyNet noise sample is [array([0.21733741], dtype=float32), 2.0045664]. 
=============================================
[2019-03-26 21:18:52,469] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[37.73244 ]
 [36.94594 ]
 [34.141354]
 [35.68371 ]
 [34.110195]], R is [[33.95326614]
 [33.6137352 ]
 [33.27759933]
 [32.94482422]
 [32.61537552]].
[2019-03-26 21:18:54,349] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1126694: loss -294.8131
[2019-03-26 21:18:54,352] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1126694: learning rate 0.0010
[2019-03-26 21:18:55,869] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 9.5670965e-18 0.0000000e+00], sum to 1.0000
[2019-03-26 21:18:55,878] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2960
[2019-03-26 21:18:55,885] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 85.5, 1.0, 2.0, 0.7473744893047615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1044509.702720558, 1044509.702720558, 231403.9013687684], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2446200.0000, 
sim time next is 2446800.0000, 
raw observation next is [27.7, 85.66666666666666, 1.0, 2.0, 0.7379706602272049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1031360.79186168, 1031360.79186168, 229255.3350940973], 
processed observation next is [1.0, 0.30434782608695654, 0.5118483412322274, 0.8566666666666666, 1.0, 1.0, 0.6843020002737409, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2864891088504667, 0.2864891088504667, 0.34217214193148854], 
reward next is 0.6578, 
noisyNet noise sample is [array([-2.0662632], dtype=float32), -0.6864001]. 
=============================================
[2019-03-26 21:18:58,022] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1128335: loss -70.5846
[2019-03-26 21:18:58,023] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1128335: loss -54.5895
[2019-03-26 21:18:58,023] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1128335: learning rate 0.0010
[2019-03-26 21:18:58,025] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1128335: learning rate 0.0010
[2019-03-26 21:18:59,107] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1128819: loss 0.6380
[2019-03-26 21:18:59,115] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1128819: learning rate 0.0010
[2019-03-26 21:19:00,484] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1129432: loss -150.9243
[2019-03-26 21:19:00,486] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1129432: learning rate 0.0010
[2019-03-26 21:19:00,819] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1129588: loss -410.8070
[2019-03-26 21:19:00,824] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1129589: learning rate 0.0010
[2019-03-26 21:19:01,052] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1129690: loss 0.4218
[2019-03-26 21:19:01,055] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1129691: learning rate 0.0010
[2019-03-26 21:19:01,442] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 2.050595e-19 0.000000e+00], sum to 1.0000
[2019-03-26 21:19:01,454] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0829
[2019-03-26 21:19:01,457] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 96.0, 1.0, 2.0, 0.6481873136697233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 905829.3588800053, 905829.358880006, 210059.9434906598], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2519400.0000, 
sim time next is 2520000.0000, 
raw observation next is [26.3, 96.0, 1.0, 2.0, 0.6430358996279928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 898627.3108131714, 898627.310813172, 209030.992515251], 
processed observation next is [1.0, 0.17391304347826086, 0.4454976303317536, 0.96, 1.0, 1.0, 0.5699227706361358, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24961869744810317, 0.24961869744810333, 0.311986555992912], 
reward next is 0.6880, 
noisyNet noise sample is [array([0.26242042], dtype=float32), -1.1068876]. 
=============================================
[2019-03-26 21:19:01,470] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[59.777428]
 [59.682304]
 [59.579975]
 [59.066216]
 [59.153793]], R is [[60.00673676]
 [60.09314728]
 [60.17551804]
 [60.24866486]
 [60.31938553]].
[2019-03-26 21:19:02,057] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1130140: loss -49.8277
[2019-03-26 21:19:02,058] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1130140: learning rate 0.0010
[2019-03-26 21:19:02,732] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1130437: loss -82.0846
[2019-03-26 21:19:02,734] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1130438: learning rate 0.0010
[2019-03-26 21:19:02,777] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1130456: loss -75.9542
[2019-03-26 21:19:02,780] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1130458: learning rate 0.0010
[2019-03-26 21:19:02,896] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1130515: loss -84.8637
[2019-03-26 21:19:02,899] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1130515: learning rate 0.0010
[2019-03-26 21:19:02,917] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1130523: loss -168.0346
[2019-03-26 21:19:02,919] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1130523: learning rate 0.0010
[2019-03-26 21:19:03,203] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1130647: loss -114.9756
[2019-03-26 21:19:03,204] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1130647: learning rate 0.0010
[2019-03-26 21:19:03,716] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1130877: loss -42.9175
[2019-03-26 21:19:03,720] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1130879: learning rate 0.0010
[2019-03-26 21:19:06,419] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1132107: loss 0.5208
[2019-03-26 21:19:06,422] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1132108: learning rate 0.0010
[2019-03-26 21:19:07,841] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 5.337853e-23 0.000000e+00], sum to 1.0000
[2019-03-26 21:19:07,852] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6141
[2019-03-26 21:19:07,860] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4749715298666664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 663817.185979863, 663817.185979863, 179783.9465901326], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2623200.0000, 
sim time next is 2623800.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4754971946229017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 664551.669029083, 664551.6690290824, 179862.3850760613], 
processed observation next is [0.0, 0.34782608695652173, 0.4312796208530806, 0.84, 1.0, 1.0, 0.3680689091842189, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18459768584141195, 0.18459768584141178, 0.26845132100904673], 
reward next is 0.7315, 
noisyNet noise sample is [array([-0.6345516], dtype=float32), 0.111447]. 
=============================================
[2019-03-26 21:19:09,252] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.1182564e-26 0.0000000e+00], sum to 1.0000
[2019-03-26 21:19:09,261] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0418
[2019-03-26 21:19:09,271] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3989862227200194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 594915.4175127856, 594915.4175127856, 174057.6605508872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2664000.0000, 
sim time next is 2664600.0000, 
raw observation next is [23.0, 94.00000000000001, 1.0, 2.0, 0.3977482839684885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 593474.40523567, 593474.40523567, 173936.5160771536], 
processed observation next is [0.0, 0.8695652173913043, 0.28909952606635075, 0.9400000000000002, 1.0, 1.0, 0.2743955228536006, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16485400145435278, 0.16485400145435278, 0.25960674041366205], 
reward next is 0.7404, 
noisyNet noise sample is [array([0.6054963], dtype=float32), 0.36802995]. 
=============================================
[2019-03-26 21:19:09,398] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.2156785e-23 0.0000000e+00], sum to 1.0000
[2019-03-26 21:19:09,408] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6508
[2019-03-26 21:19:09,413] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.00000000000001, 1.0, 2.0, 0.3977482839684885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 593474.40523567, 593474.40523567, 173936.5160771536], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2664600.0000, 
sim time next is 2665200.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3971945146211823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 592670.2684337221, 592670.2684337215, 173863.0354437851], 
processed observation next is [0.0, 0.8695652173913043, 0.28909952606635075, 0.94, 1.0, 1.0, 0.27372833086889437, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16463063012047835, 0.16463063012047818, 0.2594970678265449], 
reward next is 0.7405, 
noisyNet noise sample is [array([-1.9317658], dtype=float32), 0.5675136]. 
=============================================
[2019-03-26 21:19:09,492] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1133466: loss 0.6235
[2019-03-26 21:19:09,495] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1133467: learning rate 0.0010
[2019-03-26 21:19:11,838] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1134512: loss 0.6133
[2019-03-26 21:19:11,841] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1134512: learning rate 0.0010
[2019-03-26 21:19:12,237] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1238363e-24 0.0000000e+00], sum to 1.0000
[2019-03-26 21:19:12,246] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4272
[2019-03-26 21:19:12,252] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 100.0, 1.0, 2.0, 0.4503384064312532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 643133.9493691779, 643133.9493691786, 177966.7730345486], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2709600.0000, 
sim time next is 2710200.0000, 
raw observation next is [23.16666666666667, 100.0, 1.0, 2.0, 0.4427102211633037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 636735.7042807669, 636735.7042807676, 177437.2248689152], 
processed observation next is [0.0, 0.34782608695652173, 0.2969984202211693, 1.0, 1.0, 1.0, 0.3285665315220526, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1768710289668797, 0.1768710289668799, 0.26483167890882864], 
reward next is 0.7352, 
noisyNet noise sample is [array([-1.3141831], dtype=float32), -1.0529463]. 
=============================================
[2019-03-26 21:19:15,715] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1136255: loss 0.4075
[2019-03-26 21:19:15,716] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1136255: learning rate 0.0010
[2019-03-26 21:19:15,761] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1136275: loss 0.3994
[2019-03-26 21:19:15,763] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1136275: learning rate 0.0010
[2019-03-26 21:19:16,803] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1136744: loss 9.0882
[2019-03-26 21:19:16,806] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1136744: learning rate 0.0010
[2019-03-26 21:19:16,908] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 6.722208e-26 0.000000e+00], sum to 1.0000
[2019-03-26 21:19:16,920] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5342
[2019-03-26 21:19:16,924] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.4094262076607182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 603250.7644546658, 603250.7644546658, 174616.0758322382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2833800.0000, 
sim time next is 2834400.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.4091672451503332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 602870.9496955557, 602870.9496955563, 174580.6887437804], 
processed observation next is [1.0, 0.8260869565217391, 0.3364928909952607, 0.89, 1.0, 1.0, 0.28815330741004, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1674641526932099, 0.16746415269321008, 0.2605681921548961], 
reward next is 0.7394, 
noisyNet noise sample is [array([-0.41357538], dtype=float32), 1.7518098]. 
=============================================
[2019-03-26 21:19:17,233] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1072147e-17 0.0000000e+00], sum to 1.0000
[2019-03-26 21:19:17,249] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0304
[2019-03-26 21:19:17,256] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 99.00000000000001, 1.0, 2.0, 0.3084446884230885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 490771.874960068, 490771.8749600674, 166395.1436372788], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3035400.0000, 
sim time next is 3036000.0000, 
raw observation next is [20.33333333333334, 98.0, 1.0, 2.0, 0.3012956036091493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 478834.0511005365, 478834.0511005365, 165522.358767957], 
processed observation next is [1.0, 0.13043478260869565, 0.16271721958925783, 0.98, 1.0, 1.0, 0.15818747422789073, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1330094586390379, 0.1330094586390379, 0.24704829666859252], 
reward next is 0.7530, 
noisyNet noise sample is [array([1.3092005], dtype=float32), 1.6805134]. 
=============================================
[2019-03-26 21:19:17,268] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[77.48585 ]
 [77.454285]
 [77.477036]
 [77.581535]
 [77.82132 ]], R is [[77.34873199]
 [77.32689667]
 [77.30473328]
 [77.28268433]
 [77.26025391]].
[2019-03-26 21:19:18,198] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1137370: loss 0.6673
[2019-03-26 21:19:18,200] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1137370: learning rate 0.0010
[2019-03-26 21:19:18,653] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1137574: loss 0.7945
[2019-03-26 21:19:18,655] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1137575: learning rate 0.0010
[2019-03-26 21:19:18,773] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1137627: loss 9.3190
[2019-03-26 21:19:18,777] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1137628: learning rate 0.0010
[2019-03-26 21:19:19,892] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1138130: loss 0.7697
[2019-03-26 21:19:19,895] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1138131: learning rate 0.0010
[2019-03-26 21:19:20,659] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1138471: loss 0.8522
[2019-03-26 21:19:20,661] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1138471: learning rate 0.0010
[2019-03-26 21:19:20,673] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1138477: loss 0.7541
[2019-03-26 21:19:20,675] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1138477: learning rate 0.0010
[2019-03-26 21:19:20,787] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1138525: loss 0.7190
[2019-03-26 21:19:20,790] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1138526: learning rate 0.0010
[2019-03-26 21:19:20,872] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1138562: loss 0.7032
[2019-03-26 21:19:20,880] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1138562: learning rate 0.0010
[2019-03-26 21:19:21,086] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1138660: loss 0.3397
[2019-03-26 21:19:21,089] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1138660: learning rate 0.0010
[2019-03-26 21:19:21,787] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1138973: loss 0.5045
[2019-03-26 21:19:21,791] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1138975: learning rate 0.0010
[2019-03-26 21:19:24,390] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1140129: loss 9.5421
[2019-03-26 21:19:24,392] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1140129: learning rate 0.0010
[2019-03-26 21:19:27,368] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1141469: loss 9.1888
[2019-03-26 21:19:27,369] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1141470: learning rate 0.0010
[2019-03-26 21:19:29,702] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1142514: loss 8.6586
[2019-03-26 21:19:29,704] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1142515: learning rate 0.0010
[2019-03-26 21:19:31,999] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1276558e-20 9.9999964e-01 2.6563055e-22 3.4834991e-07 1.5970576e-21], sum to 1.0000
[2019-03-26 21:19:32,011] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7209
[2019-03-26 21:19:32,023] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2711836.7202152 W.
[2019-03-26 21:19:32,026] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.16666666666667, 70.33333333333334, 1.0, 2.0, 0.6514580236105628, 1.0, 2.0, 0.646319051319544, 1.0, 1.0, 1.03, 7.005093904978501, 6.9112, 170.5573041426782, 2711836.7202152, 2644576.69671924, 506434.8893067393], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3409800.0000, 
sim time next is 3410400.0000, 
raw observation next is [32.33333333333334, 69.66666666666667, 1.0, 2.0, 0.9373127036161045, 1.0, 2.0, 0.9373127036161045, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2621767.559869938, 2621767.559869938, 492264.4031524216], 
processed observation next is [1.0, 0.4782608695652174, 0.7314375987361774, 0.6966666666666668, 1.0, 1.0, 0.9244731368868729, 1.0, 1.0, 0.9244731368868729, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7282687666305383, 0.7282687666305383, 0.7347229897797337], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.48573408], dtype=float32), -0.8960169]. 
=============================================
[2019-03-26 21:19:33,557] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1144239: loss 9.7576
[2019-03-26 21:19:33,561] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1144239: learning rate 0.0010
[2019-03-26 21:19:33,642] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1144272: loss 9.5441
[2019-03-26 21:19:33,646] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1144273: learning rate 0.0010
[2019-03-26 21:19:33,667] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.1466728e-17 0.0000000e+00], sum to 1.0000
[2019-03-26 21:19:33,676] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3501
[2019-03-26 21:19:33,681] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 97.0, 1.0, 2.0, 0.8339151105066627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1229316.07873723, 1229316.078737229, 261326.0559229381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3072600.0000, 
sim time next is 3073200.0000, 
raw observation next is [23.0, 98.0, 1.0, 2.0, 0.8501543741860447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1247407.785213543, 1247407.785213543, 264967.8854743962], 
processed observation next is [1.0, 0.5652173913043478, 0.28909952606635075, 0.98, 1.0, 1.0, 0.8194631014289695, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.34650216255931754, 0.34650216255931754, 0.3954744559319346], 
reward next is 0.6045, 
noisyNet noise sample is [array([0.90758616], dtype=float32), 0.8537962]. 
=============================================
[2019-03-26 21:19:34,963] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1144867: loss 7.0150
[2019-03-26 21:19:34,968] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1144867: learning rate 0.0010
[2019-03-26 21:19:35,925] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1145301: loss 9.7574
[2019-03-26 21:19:35,928] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1145302: learning rate 0.0010
[2019-03-26 21:19:36,427] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1145527: loss 9.6333
[2019-03-26 21:19:36,429] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1145527: learning rate 0.0010
[2019-03-26 21:19:37,071] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1145812: loss 7.1527
[2019-03-26 21:19:37,074] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1145812: learning rate 0.0010
[2019-03-26 21:19:37,695] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1146076: loss 9.9384
[2019-03-26 21:19:37,698] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1146076: learning rate 0.0010
[2019-03-26 21:19:38,327] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1146356: loss 9.8547
[2019-03-26 21:19:38,330] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1146357: learning rate 0.0010
[2019-03-26 21:19:38,547] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1146455: loss 9.4623
[2019-03-26 21:19:38,548] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1146455: learning rate 0.0010
[2019-03-26 21:19:38,594] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1146475: loss 9.4926
[2019-03-26 21:19:38,598] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1146475: learning rate 0.0010
[2019-03-26 21:19:38,634] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1146494: loss 9.6858
[2019-03-26 21:19:38,641] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1146497: learning rate 0.0010
[2019-03-26 21:19:38,929] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1146627: loss 9.9165
[2019-03-26 21:19:38,931] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1146627: learning rate 0.0010
[2019-03-26 21:19:39,624] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1146938: loss 10.3007
[2019-03-26 21:19:39,625] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1146938: learning rate 0.0010
[2019-03-26 21:19:39,949] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.0409973e-16 0.0000000e+00], sum to 1.0000
[2019-03-26 21:19:39,959] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0733
[2019-03-26 21:19:39,962] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 76.33333333333334, 1.0, 2.0, 0.5863564233374999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 819388.542952429, 819388.542952429, 198231.5427192179], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3262800.0000, 
sim time next is 3263400.0000, 
raw observation next is [30.0, 77.0, 1.0, 2.0, 0.578124993567868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 807881.3708210465, 807881.3708210465, 196741.2898296856], 
processed observation next is [0.0, 0.782608695652174, 0.6208530805687204, 0.77, 1.0, 1.0, 0.4917168597203228, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22441149189473514, 0.22441149189473514, 0.2936437161637098], 
reward next is 0.7064, 
noisyNet noise sample is [array([-0.19121067], dtype=float32), -0.24761532]. 
=============================================
[2019-03-26 21:19:42,547] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1148238: loss 7.5946
[2019-03-26 21:19:42,551] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1148238: learning rate 0.0010
[2019-03-26 21:19:42,898] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.7644402e-16 0.0000000e+00], sum to 1.0000
[2019-03-26 21:19:42,908] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4204
[2019-03-26 21:19:42,914] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 86.5, 1.0, 2.0, 0.5054346614254485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 706268.9355070761, 706268.9355070768, 184451.9452195093], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3461400.0000, 
sim time next is 3462000.0000, 
raw observation next is [26.33333333333334, 87.33333333333333, 1.0, 2.0, 0.5035865515859838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 703685.6245507251, 703685.6245507258, 184159.9167561295], 
processed observation next is [1.0, 0.043478260869565216, 0.44707740916271754, 0.8733333333333333, 1.0, 1.0, 0.40191150793492014, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19546822904186809, 0.19546822904186828, 0.2748655473972082], 
reward next is 0.7251, 
noisyNet noise sample is [array([0.00044209], dtype=float32), 0.3506976]. 
=============================================
[2019-03-26 21:19:42,931] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[62.185394]
 [62.110844]
 [62.04001 ]
 [62.15608 ]
 [62.178047]], R is [[62.34987259]
 [62.45107269]
 [62.55092621]
 [62.64964294]
 [62.74727249]].
[2019-03-26 21:19:45,646] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1149569: loss 6.8946
[2019-03-26 21:19:45,648] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1149569: learning rate 0.0010
[2019-03-26 21:19:46,583] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-26 21:19:46,586] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:19:46,588] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:19:46,589] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:19:46,589] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:19:46,589] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:19:46,591] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:19:46,592] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:19:46,593] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:19:46,593] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:19:46,594] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:19:46,617] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run47
[2019-03-26 21:19:46,618] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run47
[2019-03-26 21:19:46,661] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run47
[2019-03-26 21:19:46,662] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run47
[2019-03-26 21:19:46,704] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run47
[2019-03-26 21:19:54,195] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.14587168]
[2019-03-26 21:19:54,196] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.03333333333334, 53.0, 1.0, 2.0, 0.5232164997916068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 857609.5708894643, 857609.5708894636, 200104.891505163]
[2019-03-26 21:19:54,197] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:19:54,201] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.1957756e-15 0.0000000e+00], sampled 0.8750576625752784
[2019-03-26 21:19:57,685] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.14587168]
[2019-03-26 21:19:57,687] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.86666666666667, 74.66666666666667, 1.0, 2.0, 0.3515438377730944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 564027.5833029309, 564027.5833029303, 172104.511297253]
[2019-03-26 21:19:57,688] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:19:57,690] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3745556e-15 0.0000000e+00], sampled 0.7698810388524913
[2019-03-26 21:20:12,464] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.14587168]
[2019-03-26 21:20:12,465] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.43333333333333, 93.0, 1.0, 2.0, 0.4421237235730829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 652729.1447539162, 652729.1447539156, 179438.1233896531]
[2019-03-26 21:20:12,466] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:20:12,469] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6329667e-15 0.0000000e+00], sampled 0.574071261578851
[2019-03-26 21:21:38,497] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.14587168]
[2019-03-26 21:21:38,499] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.0, 86.0, 1.0, 2.0, 0.6047822414663392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 845147.4677606197, 845147.4677606197, 201634.1579898413]
[2019-03-26 21:21:38,500] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:21:38,503] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.0213196e-15 0.0000000e+00], sampled 0.570998903469019
[2019-03-26 21:21:40,504] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8002.7687 3007861007.2974 1756.0000
[2019-03-26 21:21:40,869] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7889.3812 3163232805.8263 1738.0000
[2019-03-26 21:21:40,967] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8665.1062 2779320443.3978 914.0000
[2019-03-26 21:21:41,084] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8267.7450 2926874354.5254 1306.0000
[2019-03-26 21:21:41,103] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8498.1123 2843085475.1306 1124.0000
[2019-03-26 21:21:42,123] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1150000, evaluation results [1150000.0, 7889.381230299712, 3163232805.826252, 1738.0, 8267.745034146692, 2926874354.525415, 1306.0, 8665.106220721344, 2779320443.3978086, 914.0, 8002.768729742936, 3007861007.297421, 1756.0, 8498.112336572485, 2843085475.130578, 1124.0]
[2019-03-26 21:21:42,513] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 8.090192e-15 0.000000e+00], sum to 1.0000
[2019-03-26 21:21:42,523] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7367
[2019-03-26 21:21:42,529] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 73.33333333333334, 1.0, 2.0, 0.4878208114317547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 681648.3319470783, 681648.331947079, 181710.0035530568], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3312600.0000, 
sim time next is 3313200.0000, 
raw observation next is [28.33333333333334, 72.66666666666667, 1.0, 2.0, 0.4904327901074785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 685299.3143714768, 685299.3143714775, 182110.7996345521], 
processed observation next is [0.0, 0.34782608695652173, 0.5418641390205374, 0.7266666666666667, 1.0, 1.0, 0.38606360253913075, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19036092065874355, 0.19036092065874374, 0.27180716363365987], 
reward next is 0.7282, 
noisyNet noise sample is [array([0.03231743], dtype=float32), -0.043389875]. 
=============================================
[2019-03-26 21:21:43,415] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1150577: loss 8.1676
[2019-03-26 21:21:43,419] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1150577: learning rate 0.0010
[2019-03-26 21:21:44,037] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 5.131298e-19 0.000000e+00], sum to 1.0000
[2019-03-26 21:21:44,047] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3906
[2019-03-26 21:21:44,051] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 75.0, 1.0, 2.0, 0.5964550567010019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 833506.1528253664, 833506.1528253664, 200087.6766423961], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3338400.0000, 
sim time next is 3339000.0000, 
raw observation next is [31.0, 75.0, 1.0, 2.0, 0.5949757077889694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 831438.0522696073, 831438.0522696073, 199814.0484636618], 
processed observation next is [0.0, 0.6521739130434783, 0.6682464454976303, 0.75, 1.0, 1.0, 0.512018925046951, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23095501451933537, 0.23095501451933537, 0.2982299230800923], 
reward next is 0.7018, 
noisyNet noise sample is [array([-1.6941762], dtype=float32), -0.6024754]. 
=============================================
[2019-03-26 21:21:44,075] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[70.07203]
 [70.07101]
 [70.06699]
 [69.93708]
 [69.91291]], R is [[70.11676025]
 [70.11695862]
 [70.11703491]
 [70.11743164]
 [70.11733246]].
[2019-03-26 21:21:47,056] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 8.881524e-19 0.000000e+00], sum to 1.0000
[2019-03-26 21:21:47,064] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1708
[2019-03-26 21:21:47,072] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5117892573419964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 715151.5167799335, 715151.516779934, 185463.7158761521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3453600.0000, 
sim time next is 3454200.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5108681047745739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 713863.9066937568, 713863.9066937568, 185316.3543068274], 
processed observation next is [1.0, 1.0, 0.4786729857819906, 0.84, 1.0, 1.0, 0.41068446358382393, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19829552963715466, 0.19829552963715466, 0.2765915735922797], 
reward next is 0.7234, 
noisyNet noise sample is [array([-0.64308614], dtype=float32), -0.2834811]. 
=============================================
[2019-03-26 21:21:47,170] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1152258: loss 7.4845
[2019-03-26 21:21:47,173] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1152259: learning rate 0.0010
[2019-03-26 21:21:47,173] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1152261: loss 7.9098
[2019-03-26 21:21:47,178] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1152263: learning rate 0.0010
[2019-03-26 21:21:49,209] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1153179: loss 22.5835
[2019-03-26 21:21:49,215] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1153183: learning rate 0.0010
[2019-03-26 21:21:49,358] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1153244: loss 5.4400
[2019-03-26 21:21:49,364] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1153244: learning rate 0.0010
[2019-03-26 21:21:49,845] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1153466: loss 4.5034
[2019-03-26 21:21:49,847] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1153466: learning rate 0.0010
[2019-03-26 21:21:50,985] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1153971: loss 5.6603
[2019-03-26 21:21:50,990] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1153972: learning rate 0.0010
[2019-03-26 21:21:51,118] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1154032: loss -16.2044
[2019-03-26 21:21:51,121] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1154033: learning rate 0.0010
[2019-03-26 21:21:51,476] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1154192: loss 4.8863
[2019-03-26 21:21:51,479] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1154193: learning rate 0.0010
[2019-03-26 21:21:51,755] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1154318: loss 5.6325
[2019-03-26 21:21:51,758] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1154319: learning rate 0.0010
[2019-03-26 21:21:51,792] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1154334: loss 5.9859
[2019-03-26 21:21:51,796] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1154334: learning rate 0.0010
[2019-03-26 21:21:52,027] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1154437: loss 5.6594
[2019-03-26 21:21:52,031] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1154438: learning rate 0.0010
[2019-03-26 21:21:52,162] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1154496: loss 5.9510
[2019-03-26 21:21:52,164] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1154497: learning rate 0.0010
[2019-03-26 21:21:52,964] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1154858: loss 6.7237
[2019-03-26 21:21:52,968] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1154858: learning rate 0.0010
[2019-03-26 21:21:56,448] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1156423: loss -10.7406
[2019-03-26 21:21:56,451] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1156423: learning rate 0.0010
[2019-03-26 21:21:57,958] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.3745863e-18 0.0000000e+00], sum to 1.0000
[2019-03-26 21:21:57,970] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9834
[2019-03-26 21:21:57,975] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.7268589847660603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1015824.093397069, 1015824.093397069, 226746.1007951709], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3553200.0000, 
sim time next is 3553800.0000, 
raw observation next is [26.91666666666666, 79.33333333333334, 1.0, 2.0, 0.7438852858019134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1039630.902383026, 1039630.902383027, 230599.472486983], 
processed observation next is [1.0, 0.13043478260869565, 0.4747235387045811, 0.7933333333333334, 1.0, 1.0, 0.6914280551830282, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.28878636177306277, 0.28878636177306305, 0.3441783171447507], 
reward next is 0.6558, 
noisyNet noise sample is [array([-0.619192], dtype=float32), 0.52511376]. 
=============================================
[2019-03-26 21:21:59,204] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1157656: loss 0.0710
[2019-03-26 21:21:59,206] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1157656: learning rate 0.0010
[2019-03-26 21:22:01,556] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1158695: loss -3.5164
[2019-03-26 21:22:01,559] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1158695: learning rate 0.0010
[2019-03-26 21:22:05,122] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1160289: loss 0.0493
[2019-03-26 21:22:05,126] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1160291: learning rate 0.0010
[2019-03-26 21:22:05,230] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1160336: loss 0.0595
[2019-03-26 21:22:05,234] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1160336: learning rate 0.0010
[2019-03-26 21:22:06,737] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.2162375e-17 9.9999988e-01 5.7898874e-19 6.1762115e-08 7.5755897e-18], sum to 1.0000
[2019-03-26 21:22:06,748] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3769
[2019-03-26 21:22:06,762] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2691583.961605778 W.
[2019-03-26 21:22:06,771] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.0, 59.0, 1.0, 2.0, 0.962246029634333, 1.0, 2.0, 0.962246029634333, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2691583.961605778, 2691583.961605778, 506586.0249939169], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3683400.0000, 
sim time next is 3684000.0000, 
raw observation next is [33.0, 59.0, 1.0, 2.0, 0.6708097502682426, 1.0, 2.0, 0.6559949146483839, 1.0, 1.0, 1.03, 7.005095430644848, 6.9112, 170.5573041426782, 2752479.599765052, 2685218.483372227, 512266.5814031787], 
processed observation next is [1.0, 0.6521739130434783, 0.7630331753554502, 0.59, 1.0, 1.0, 0.6033852412870393, 1.0, 1.0, 0.5855360417450408, 1.0, 0.5, 1.0365853658536586, 0.009389543064484761, 0.0, 0.8375144448122397, 0.7645776666014034, 0.7458940231589519, 0.7645769871689234], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7729827], dtype=float32), 1.0029663]. 
=============================================
[2019-03-26 21:22:06,789] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[25.89614 ]
 [26.068392]
 [25.145887]
 [25.166895]
 [25.239304]], R is [[24.93927193]
 [24.93378258]
 [24.98636246]
 [25.03917694]
 [25.07365227]].
[2019-03-26 21:22:06,871] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1161074: loss 0.0606
[2019-03-26 21:22:06,873] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1161074: learning rate 0.0010
[2019-03-26 21:22:07,485] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1161348: loss -6.8916
[2019-03-26 21:22:07,490] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1161349: learning rate 0.0010
[2019-03-26 21:22:07,744] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1161466: loss -2.2515
[2019-03-26 21:22:07,745] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1161466: learning rate 0.0010
[2019-03-26 21:22:08,725] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3088232e-27 0.0000000e+00], sum to 1.0000
[2019-03-26 21:22:08,735] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8394
[2019-03-26 21:22:08,740] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.5441111608541516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 760332.8697530448, 760332.8697530441, 190796.0943649762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4053600.0000, 
sim time next is 4054200.0000, 
raw observation next is [27.83333333333334, 84.83333333333333, 1.0, 2.0, 0.543206161525321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 759067.7852456463, 759067.785245647, 190642.5440530445], 
processed observation next is [1.0, 0.9565217391304348, 0.5181674565560824, 0.8483333333333333, 1.0, 1.0, 0.44964597774135057, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21085216256823508, 0.21085216256823527, 0.2845411105269321], 
reward next is 0.7155, 
noisyNet noise sample is [array([0.4532151], dtype=float32), 0.41926682]. 
=============================================
[2019-03-26 21:22:08,830] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1161951: loss 0.0519
[2019-03-26 21:22:08,831] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1161951: learning rate 0.0010
[2019-03-26 21:22:09,210] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1162123: loss 31.0432
[2019-03-26 21:22:09,212] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1162123: learning rate 0.0010
[2019-03-26 21:22:09,274] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1162147: loss 0.0223
[2019-03-26 21:22:09,277] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1162147: learning rate 0.0010
[2019-03-26 21:22:09,773] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1162373: loss 6.3759
[2019-03-26 21:22:09,776] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1162374: learning rate 0.0010
[2019-03-26 21:22:09,808] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1162388: loss 0.0085
[2019-03-26 21:22:09,812] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1162388: learning rate 0.0010
[2019-03-26 21:22:09,844] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1162406: loss 0.0018
[2019-03-26 21:22:09,846] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1162406: learning rate 0.0010
[2019-03-26 21:22:10,176] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1162555: loss -4.6649
[2019-03-26 21:22:10,177] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1162555: learning rate 0.0010
[2019-03-26 21:22:10,481] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4987425e-27 0.0000000e+00], sum to 1.0000
[2019-03-26 21:22:10,492] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4660
[2019-03-26 21:22:10,497] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.33333333333334, 61.66666666666667, 1.0, 2.0, 0.6165615271090111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861615.000578552, 861615.000578552, 203872.7903916272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3847200.0000, 
sim time next is 3847800.0000, 
raw observation next is [34.41666666666666, 61.33333333333334, 1.0, 2.0, 0.616739349210046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861863.599213231, 861863.599213231, 203906.8101970024], 
processed observation next is [0.0, 0.5217391304347826, 0.8301737756714056, 0.6133333333333334, 1.0, 1.0, 0.5382401797711398, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2394065553370086, 0.2394065553370086, 0.30433852268209316], 
reward next is 0.6957, 
noisyNet noise sample is [array([-0.4576301], dtype=float32), -0.7969873]. 
=============================================
[2019-03-26 21:22:11,150] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1162991: loss -5.5927
[2019-03-26 21:22:11,152] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1162991: learning rate 0.0010
[2019-03-26 21:22:12,407] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6264788e-10 9.4583201e-01 9.6310277e-12 5.4167937e-02 1.7030231e-10], sum to 1.0000
[2019-03-26 21:22:12,417] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2439
[2019-03-26 21:22:12,426] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2838724.448873446 W.
[2019-03-26 21:22:12,432] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 63.0, 1.0, 2.0, 0.7118723424355026, 1.0, 2.0, 0.6765262107320139, 1.0, 1.0, 1.03, 7.0050986682978, 6.9112, 170.5573041426782, 2838724.448873446, 2771461.013218112, 525105.139983118], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3774600.0000, 
sim time next is 3775200.0000, 
raw observation next is [33.0, 63.0, 1.0, 2.0, 0.9638084169544441, 1.0, 2.0, 0.9638084169544441, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2695958.969561437, 2695958.969561437, 507501.5272893501], 
processed observation next is [1.0, 0.6956521739130435, 0.7630331753554502, 0.63, 1.0, 1.0, 0.9563956830776434, 1.0, 1.0, 0.9563956830776434, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7488774915448436, 0.7488774915448436, 0.7574649661035077], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.55929637], dtype=float32), 0.83891225]. 
=============================================
[2019-03-26 21:22:14,238] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1164367: loss 0.1210
[2019-03-26 21:22:14,239] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1164367: learning rate 0.0010
[2019-03-26 21:22:14,958] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2938385e-24 0.0000000e+00], sum to 1.0000
[2019-03-26 21:22:14,969] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2779
[2019-03-26 21:22:14,977] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.0, 60.0, 1.0, 2.0, 0.6242965057945657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 872428.6997376153, 872428.6997376159, 205360.8338812141], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3852000.0000, 
sim time next is 3852600.0000, 
raw observation next is [35.0, 59.33333333333333, 1.0, 2.0, 0.6260128455368718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 874828.201770172, 874828.201770172, 205692.8945068055], 
processed observation next is [0.0, 0.6086956521739131, 0.8578199052132701, 0.5933333333333333, 1.0, 1.0, 0.5494130669118936, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2430078338250478, 0.2430078338250478, 0.3070043201594112], 
reward next is 0.6930, 
noisyNet noise sample is [array([1.4900746], dtype=float32), 0.3997582]. 
=============================================
[2019-03-26 21:22:16,799] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1165511: loss 0.0158
[2019-03-26 21:22:16,800] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1165511: learning rate 0.0010
[2019-03-26 21:22:19,383] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1166669: loss 0.0620
[2019-03-26 21:22:19,385] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1166671: learning rate 0.0010
[2019-03-26 21:22:21,738] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1408388e-22 0.0000000e+00], sum to 1.0000
[2019-03-26 21:22:21,746] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6113
[2019-03-26 21:22:21,751] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333334, 73.66666666666667, 1.0, 2.0, 0.6046563939403528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 844971.5333202941, 844971.5333202948, 201616.6447879491], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3964800.0000, 
sim time next is 3965400.0000, 
raw observation next is [31.5, 73.0, 1.0, 2.0, 0.6041539172788504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 844269.0728390906, 844269.0728390906, 201522.530803418], 
processed observation next is [0.0, 0.9130434782608695, 0.6919431279620853, 0.73, 1.0, 1.0, 0.5230770087696992, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23451918689974738, 0.23451918689974738, 0.3007798967215194], 
reward next is 0.6992, 
noisyNet noise sample is [array([0.29856405], dtype=float32), 1.9196571]. 
=============================================
[2019-03-26 21:22:22,521] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.0767448e-20 0.0000000e+00], sum to 1.0000
[2019-03-26 21:22:22,528] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0439
[2019-03-26 21:22:22,535] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.5452465447021885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 761920.0073329152, 761920.0073329152, 190988.9409948862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4047000.0000, 
sim time next is 4047600.0000, 
raw observation next is [28.0, 84.0, 1.0, 2.0, 0.5460180003994733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 762998.4160726334, 762998.4160726334, 191120.1916432304], 
processed observation next is [1.0, 0.8695652173913043, 0.5260663507109005, 0.84, 1.0, 1.0, 0.4530337354210522, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21194400446462036, 0.21194400446462036, 0.28525401737795586], 
reward next is 0.7147, 
noisyNet noise sample is [array([0.70423126], dtype=float32), 0.692701]. 
=============================================
[2019-03-26 21:22:23,009] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1168274: loss 0.3102
[2019-03-26 21:22:23,010] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1168274: learning rate 0.0010
[2019-03-26 21:22:23,204] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1168358: loss 0.3399
[2019-03-26 21:22:23,207] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1168359: learning rate 0.0010
[2019-03-26 21:22:24,952] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1169138: loss -10.1950
[2019-03-26 21:22:24,954] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1169138: learning rate 0.0010
[2019-03-26 21:22:25,178] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1169236: loss 0.0634
[2019-03-26 21:22:25,182] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1169237: learning rate 0.0010
[2019-03-26 21:22:25,730] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1169481: loss 0.1557
[2019-03-26 21:22:25,731] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1169481: learning rate 0.0010
[2019-03-26 21:22:26,858] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1169984: loss 0.0396
[2019-03-26 21:22:26,860] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1169984: learning rate 0.0010
[2019-03-26 21:22:27,193] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 2.286539e-27 0.000000e+00], sum to 1.0000
[2019-03-26 21:22:27,202] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2690
[2019-03-26 21:22:27,208] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1170141: loss -74.2984
[2019-03-26 21:22:27,209] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.7025231281703276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 981797.7178059865, 981797.7178059865, 221390.9508297546], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4081800.0000, 
sim time next is 4082400.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.6571349986278583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 918338.9833539705, 918338.9833539705, 211865.1391908308], 
processed observation next is [1.0, 0.2608695652173913, 0.4786729857819906, 0.89, 1.0, 1.0, 0.586909636901034, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2550941620427696, 0.2550941620427696, 0.31621662565795644], 
reward next is 0.6838, 
noisyNet noise sample is [array([-1.4807416], dtype=float32), 1.1584954]. 
=============================================
[2019-03-26 21:22:27,212] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1170141: learning rate 0.0010
[2019-03-26 21:22:27,236] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1170150: loss 0.0044
[2019-03-26 21:22:27,238] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1170150: learning rate 0.0010
[2019-03-26 21:22:27,526] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1170279: loss 0.0225
[2019-03-26 21:22:27,533] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1170281: learning rate 0.0010
[2019-03-26 21:22:27,577] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1170301: loss 0.0349
[2019-03-26 21:22:27,578] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1170301: learning rate 0.0010
[2019-03-26 21:22:27,682] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1170348: loss 0.0113
[2019-03-26 21:22:27,684] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1170348: learning rate 0.0010
[2019-03-26 21:22:28,059] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1170520: loss 0.0315
[2019-03-26 21:22:28,060] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1170520: learning rate 0.0010
[2019-03-26 21:22:28,435] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.8073515e-23 0.0000000e+00], sum to 1.0000
[2019-03-26 21:22:28,446] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5287
[2019-03-26 21:22:28,454] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1928323.497414847 W.
[2019-03-26 21:22:28,461] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.56666666666667, 86.16666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.578196710368428, 6.9112, 169.2900105806816, 1928323.497414847, 1454076.800761533, 311420.3639341666], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4068600.0000, 
sim time next is 4069200.0000, 
raw observation next is [27.53333333333333, 86.33333333333334, 1.0, 2.0, 0.5552209691416199, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9500166879224022, 6.9112, 6.9112, 168.912413409552, 1552293.578945326, 1552293.578945326, 336798.199211334], 
processed observation next is [1.0, 0.08695652173913043, 0.5039494470774091, 0.8633333333333334, 1.0, 1.0, 0.4641216495682167, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.9390447413687831, 0.0, 0.0, 0.8294372782783541, 0.4311926608181461, 0.4311926608181461, 0.5026838794199014], 
reward next is 0.4973, 
noisyNet noise sample is [array([-1.0234945], dtype=float32), -0.06761833]. 
=============================================
[2019-03-26 21:22:29,053] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1170961: loss 0.0248
[2019-03-26 21:22:29,056] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1170963: learning rate 0.0010
[2019-03-26 21:22:32,369] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1172438: loss 0.9437
[2019-03-26 21:22:32,372] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1172438: learning rate 0.0010
[2019-03-26 21:22:33,041] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.1443295e-31 0.0000000e+00], sum to 1.0000
[2019-03-26 21:22:33,050] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3948
[2019-03-26 21:22:33,056] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333334, 77.66666666666667, 1.0, 2.0, 0.6299860219547007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 880382.8599504848, 880382.8599504848, 206465.6320131386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4222200.0000, 
sim time next is 4222800.0000, 
raw observation next is [31.0, 79.0, 1.0, 2.0, 0.6253095733433646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 873845.0023829468, 873845.0023829468, 205556.1514635404], 
processed observation next is [1.0, 0.9130434782608695, 0.6682464454976303, 0.79, 1.0, 1.0, 0.5485657510161018, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24273472288415188, 0.24273472288415188, 0.30680022606498564], 
reward next is 0.6932, 
noisyNet noise sample is [array([0.7420731], dtype=float32), 0.7250197]. 
=============================================
[2019-03-26 21:22:35,062] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1173641: loss -122.4742
[2019-03-26 21:22:35,064] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1173641: learning rate 0.0010
[2019-03-26 21:22:37,770] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1174805: loss -84.0254
[2019-03-26 21:22:37,776] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1174806: learning rate 0.0010
[2019-03-26 21:22:38,197] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 21:22:38,199] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:22:38,200] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:22:38,200] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:22:38,201] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:22:38,202] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:22:38,204] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:22:38,204] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:22:38,205] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:22:38,203] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:22:38,209] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:22:38,224] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run48
[2019-03-26 21:22:38,225] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run48
[2019-03-26 21:22:38,245] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run48
[2019-03-26 21:22:38,286] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run48
[2019-03-26 21:22:38,287] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run48
[2019-03-26 21:22:40,409] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.5568119]
[2019-03-26 21:22:40,410] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.61666666666667, 87.33333333333333, 1.0, 2.0, 0.3503533535017277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 542928.806202112, 542928.8062021126, 170147.3838959649]
[2019-03-26 21:22:40,411] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:22:40,415] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2066853e-31 0.0000000e+00], sampled 0.513991902568154
[2019-03-26 21:23:14,669] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.5568119]
[2019-03-26 21:23:14,670] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.56666666666666, 93.50000000000001, 1.0, 2.0, 0.7417537951225357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1043921.097042158, 1043921.097042158, 231110.6408076962]
[2019-03-26 21:23:14,671] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:23:14,673] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.2250936e-25 0.0000000e+00], sampled 0.7996351081171139
[2019-03-26 21:23:48,131] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.5568119]
[2019-03-26 21:23:48,133] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 79.0, 1.0, 2.0, 0.4859292428987306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 679004.3352443101, 679004.3352443101, 181420.5453945243]
[2019-03-26 21:23:48,133] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:23:48,135] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 6.243921e-29 0.000000e+00], sampled 0.4327392160379482
[2019-03-26 21:23:48,917] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.5568119]
[2019-03-26 21:23:48,918] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.90000000000001, 59.16666666666666, 1.0, 2.0, 0.9535862768294205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1332886.425911356, 1332886.425911356, 285107.3610223809]
[2019-03-26 21:23:48,919] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:23:48,921] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3935933e-24 0.0000000e+00], sampled 0.2938812697401231
[2019-03-26 21:23:56,647] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.5568119]
[2019-03-26 21:23:56,649] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.0, 78.0, 1.0, 2.0, 0.7678260366776745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1073106.655827188, 1073106.655827188, 236167.519618182]
[2019-03-26 21:23:56,649] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:23:56,652] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.2969184e-25 0.0000000e+00], sampled 0.9854945148806443
[2019-03-26 21:23:59,761] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.5568119]
[2019-03-26 21:23:59,763] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.73518173666666, 93.66766902166668, 1.0, 2.0, 0.4916024094100246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 686934.1937756736, 686934.193775673, 182289.8068460805]
[2019-03-26 21:23:59,766] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:23:59,768] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7580641e-29 0.0000000e+00], sampled 0.14530260034643594
[2019-03-26 21:24:20,403] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.5568119]
[2019-03-26 21:24:20,404] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.86666666666667, 76.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.941662117651852, 6.9112, 168.9125731393694, 1475380.553397789, 1453769.727759226, 311358.1322184041]
[2019-03-26 21:24:20,406] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:24:20,409] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.3474102e-24 0.0000000e+00], sampled 0.4422836019357991
[2019-03-26 21:24:32,521] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.3751 2927779800.6357 1338.0000
[2019-03-26 21:24:32,589] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.6708 2779658361.4638 933.0000
[2019-03-26 21:24:32,720] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2741 3008104656.7243 1766.0000
[2019-03-26 21:24:33,018] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7878.8875 3164502873.7783 1778.0000
[2019-03-26 21:24:33,025] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8190 2842958600.4139 1131.0000
[2019-03-26 21:24:34,042] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1175000, evaluation results [1175000.0, 7878.887539409773, 3164502873.778303, 1778.0, 8254.375086958147, 2927779800.6357465, 1338.0, 8660.670814356308, 2779658361.463785, 933.0, 7998.274138010797, 3008104656.724262, 1766.0, 8496.819032943851, 2842958600.4139094, 1131.0]
[2019-03-26 21:24:37,016] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1176328: loss -84.0129
[2019-03-26 21:24:37,018] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1176328: learning rate 0.0010
[2019-03-26 21:24:37,078] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1176354: loss -101.3812
[2019-03-26 21:24:37,079] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1176354: learning rate 0.0010
[2019-03-26 21:24:38,227] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1176872: loss 2.0182
[2019-03-26 21:24:38,233] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1176874: learning rate 0.0010
[2019-03-26 21:24:38,595] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2218651e-30 1.0000000e+00 2.4857946e-35 4.5761336e-16 8.3865807e-37], sum to 1.0000
[2019-03-26 21:24:38,605] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9553
[2019-03-26 21:24:38,612] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 0.5595512296758571, 0.0, 1.0, 0.0, 1.0, 1.0, 0.971755439527635, 6.9112, 6.9112, 168.9129565103946, 1564409.092601331, 1564409.092601331, 342354.5742951194], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4340400.0000, 
sim time next is 4341000.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.305380937569641, 6.9112, 168.9106651588315, 1733588.185162693, 1453946.454859849, 311355.8895808959], 
processed observation next is [1.0, 0.21739130434782608, 0.5734597156398105, 0.89, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.039418093756964104, 0.0, 0.8294286935669639, 0.4815522736563036, 0.403874015238847, 0.464710282956561], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7862447], dtype=float32), -1.2864152]. 
=============================================
[2019-03-26 21:24:38,636] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[43.564575]
 [45.359703]
 [48.238388]
 [51.656956]
 [53.020752]], R is [[44.17610931]
 [44.2233696 ]
 [44.28061676]
 [44.33849335]
 [43.89510727]].
[2019-03-26 21:24:39,109] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1177264: loss -14.5471
[2019-03-26 21:24:39,112] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1177265: learning rate 0.0010
[2019-03-26 21:24:39,616] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1177491: loss -70.1256
[2019-03-26 21:24:39,621] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1177494: learning rate 0.0010
[2019-03-26 21:24:40,202] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5083650e-37 1.0000000e+00 0.0000000e+00 4.8460202e-18 0.0000000e+00], sum to 1.0000
[2019-03-26 21:24:40,211] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7704
[2019-03-26 21:24:40,215] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 0.9721588927334889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1358863.132388855, 1358863.132388855, 290563.2322844061], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4338000.0000, 
sim time next is 4338600.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.754425148317853, 6.9112, 168.908691235275, 2052362.533851051, 1454164.697731087, 311356.0814195776], 
processed observation next is [1.0, 0.21739130434782608, 0.5734597156398105, 0.89, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.08432251483178525, 0.0, 0.8294190006986353, 0.5701007038475142, 0.4039346382586353, 0.4647105692829516], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.61168987], dtype=float32), 2.2105083]. 
=============================================
[2019-03-26 21:24:40,628] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1177944: loss 0.7796
[2019-03-26 21:24:40,632] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1177944: learning rate 0.0010
[2019-03-26 21:24:40,874] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1178052: loss -68.4523
[2019-03-26 21:24:40,875] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1178052: learning rate 0.0010
[2019-03-26 21:24:41,286] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1178238: loss -64.4264
[2019-03-26 21:24:41,288] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1178240: learning rate 0.0010
[2019-03-26 21:24:41,527] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1178344: loss -59.6285
[2019-03-26 21:24:41,531] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1178345: learning rate 0.0010
[2019-03-26 21:24:41,602] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1178380: loss -23.4582
[2019-03-26 21:24:41,605] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1178380: learning rate 0.0010
[2019-03-26 21:24:41,707] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1178425: loss -30.1846
[2019-03-26 21:24:41,712] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1178425: learning rate 0.0010
[2019-03-26 21:24:41,829] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7157772e-10 2.5801144e-08 4.6599977e-11 1.0000000e+00 3.0010037e-09], sum to 1.0000
[2019-03-26 21:24:41,838] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2100
[2019-03-26 21:24:41,841] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [37.0, 54.00000000000001, 1.0, 2.0, 0.9422885544530144, 1.0, 2.0, 0.9422885544530144, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2635700.247046721, 2635700.247046721, 495103.181274304], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4364400.0000, 
sim time next is 4365000.0000, 
raw observation next is [37.0, 54.0, 1.0, 2.0, 0.8808890015560283, 1.0, 2.0, 0.8808890015560283, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2463788.606134657, 2463788.606134657, 461189.2330863352], 
processed observation next is [1.0, 0.5217391304347826, 0.95260663507109, 0.54, 1.0, 1.0, 0.8564927729590703, 1.0, 1.0, 0.8564927729590703, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6843857239262936, 0.6843857239262936, 0.6883421389348287], 
reward next is 0.3117, 
noisyNet noise sample is [array([-1.1127346], dtype=float32), 0.3814573]. 
=============================================
[2019-03-26 21:24:41,855] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[18.062712]
 [20.507864]
 [20.507864]
 [20.507864]
 [20.507864]], R is [[20.09926033]
 [20.15930748]
 [19.95771408]
 [19.75813675]
 [19.56055641]].
[2019-03-26 21:24:42,214] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1178651: loss -61.0405
[2019-03-26 21:24:42,215] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1178651: learning rate 0.0010
[2019-03-26 21:24:43,061] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1179022: loss -29.4888
[2019-03-26 21:24:43,062] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1179022: learning rate 0.0010
[2019-03-26 21:24:45,551] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.00000e+00 1.00000e+00 0.00000e+00 4.02151e-25 0.00000e+00], sum to 1.0000
[2019-03-26 21:24:45,563] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7105
[2019-03-26 21:24:45,567] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 70.0, 1.0, 2.0, 0.5263492198758447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 735504.0036963735, 735504.0036963728, 187826.8308498702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4649400.0000, 
sim time next is 4650000.0000, 
raw observation next is [29.0, 70.0, 1.0, 2.0, 0.5123961890151861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 715999.9018980737, 715999.9018980744, 185560.360413835], 
processed observation next is [1.0, 0.8260869565217391, 0.5734597156398105, 0.7, 1.0, 1.0, 0.41252552893395916, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19888886163835381, 0.198888861638354, 0.276955761811694], 
reward next is 0.7230, 
noisyNet noise sample is [array([-0.5207663], dtype=float32), 0.7541359]. 
=============================================
[2019-03-26 21:24:45,591] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[72.02313 ]
 [71.36534 ]
 [71.24716 ]
 [71.320984]
 [71.64079 ]], R is [[72.4045105 ]
 [72.4001236 ]
 [72.39237976]
 [72.38095093]
 [72.36808014]].
[2019-03-26 21:24:45,922] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1180301: loss 0.4707
[2019-03-26 21:24:45,927] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1180301: learning rate 0.0010
[2019-03-26 21:24:48,706] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1181546: loss 0.7705
[2019-03-26 21:24:48,711] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1181547: learning rate 0.0010
[2019-03-26 21:24:51,263] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1182696: loss 0.0766
[2019-03-26 21:24:51,267] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1182698: learning rate 0.0010
[2019-03-26 21:24:52,226] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.1253177e-12 7.2063034e-07 1.7014416e-12 9.9999928e-01 1.1772230e-10], sum to 1.0000
[2019-03-26 21:24:52,234] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0077
[2019-03-26 21:24:52,239] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 73.66666666666667, 1.0, 2.0, 0.9118096957904795, 1.0, 2.0, 0.9118096957904795, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2550360.014347896, 2550360.014347896, 477986.2850577785], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4616400.0000, 
sim time next is 4617000.0000, 
raw observation next is [32.0, 73.0, 1.0, 2.0, 0.9028977200939787, 1.0, 2.0, 0.9028977200939787, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2525407.750847121, 2525407.750847122, 473085.1327594805], 
processed observation next is [1.0, 0.43478260869565216, 0.7156398104265403, 0.73, 1.0, 1.0, 0.8830093013180467, 1.0, 1.0, 0.8830093013180467, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7015021530130892, 0.7015021530130895, 0.7060972130738515], 
reward next is 0.2939, 
noisyNet noise sample is [array([0.46969464], dtype=float32), -1.319682]. 
=============================================
[2019-03-26 21:24:52,255] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[21.781347]
 [21.340874]
 [20.673727]
 [20.091171]
 [19.685349]], R is [[22.16979408]
 [22.23468399]
 [22.29438972]
 [22.33212852]
 [22.34852219]].
[2019-03-26 21:24:54,708] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1184235: loss 0.1270
[2019-03-26 21:24:54,709] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1184235: learning rate 0.0010
[2019-03-26 21:24:54,735] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1184246: loss 0.0250
[2019-03-26 21:24:54,737] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1184248: learning rate 0.0010
[2019-03-26 21:24:56,602] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1185083: loss 217.4499
[2019-03-26 21:24:56,608] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1185083: learning rate 0.0010
[2019-03-26 21:24:56,978] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1185247: loss 0.0683
[2019-03-26 21:24:56,980] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1185247: learning rate 0.0010
[2019-03-26 21:24:57,552] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1185513: loss 0.5254
[2019-03-26 21:24:57,553] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1185513: learning rate 0.0010
[2019-03-26 21:24:58,610] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1185987: loss 214.9147
[2019-03-26 21:24:58,614] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1185987: learning rate 0.0010
[2019-03-26 21:24:58,653] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1186007: loss 0.6959
[2019-03-26 21:24:58,656] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1186007: learning rate 0.0010
[2019-03-26 21:24:59,141] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2562561e-19 0.0000000e+00], sum to 1.0000
[2019-03-26 21:24:59,155] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3950
[2019-03-26 21:24:59,160] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.16666666666667, 78.33333333333334, 1.0, 2.0, 1.012963877539185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1415937.514453931, 1415937.514453931, 302902.2274587305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4695000.0000, 
sim time next is 4695600.0000, 
raw observation next is [29.33333333333334, 77.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.746256089327783, 6.9112, 168.9086595192302, 2046563.186868673, 1454160.727247422, 311352.2580886176], 
processed observation next is [1.0, 0.34782608695652173, 0.5892575039494474, 0.7766666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.08350560893277832, 0.0, 0.8294188449583357, 0.568489774130187, 0.4039335353465061, 0.4647048628188322], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.70923626], dtype=float32), -0.26821476]. 
=============================================
[2019-03-26 21:24:59,160] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1186230: loss 0.0465
[2019-03-26 21:24:59,163] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1186231: learning rate 0.0010
[2019-03-26 21:24:59,384] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1186327: loss 0.1130
[2019-03-26 21:24:59,386] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1186328: learning rate 0.0010
[2019-03-26 21:24:59,397] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1186332: loss 0.0117
[2019-03-26 21:24:59,399] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1186333: learning rate 0.0010
[2019-03-26 21:24:59,476] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1186372: loss 0.0358
[2019-03-26 21:24:59,481] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1186374: learning rate 0.0010
[2019-03-26 21:25:00,015] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1186614: loss 0.0382
[2019-03-26 21:25:00,017] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1186614: learning rate 0.0010
[2019-03-26 21:25:00,844] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1186983: loss 0.1164
[2019-03-26 21:25:00,851] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1186985: learning rate 0.0010
[2019-03-26 21:25:01,723] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5915186e-20 0.0000000e+00], sum to 1.0000
[2019-03-26 21:25:01,732] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0289
[2019-03-26 21:25:01,738] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.6367575036421909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 889849.7268055704, 889849.726805571, 207786.8547402394], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4684800.0000, 
sim time next is 4685400.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.634153649034275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 886209.3990846409, 886209.3990846416, 207274.5878739175], 
processed observation next is [1.0, 0.21739130434782608, 0.4786729857819906, 0.89, 1.0, 1.0, 0.5592212638967168, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24616927752351137, 0.24616927752351156, 0.3093650565282351], 
reward next is 0.6906, 
noisyNet noise sample is [array([0.16049714], dtype=float32), -0.4928342]. 
=============================================
[2019-03-26 21:25:01,939] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3997452e-19 0.0000000e+00], sum to 1.0000
[2019-03-26 21:25:01,951] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3759
[2019-03-26 21:25:01,956] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 90.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.95280388078335, 6.9112, 168.9121469915918, 1483290.226422459, 1453775.142952008, 311350.9824840707], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4674000.0000, 
sim time next is 4674600.0000, 
raw observation next is [27.0, 91.5, 1.0, 2.0, 0.9047999428778082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129226059842, 1264654.139598119, 1264654.139598119, 271262.4333311477], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.915, 1.0, 1.0, 0.8853011359973593, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294397786659473, 0.3512928165550331, 0.3512928165550331, 0.4048693034793249], 
reward next is 0.5951, 
noisyNet noise sample is [array([-0.8881857], dtype=float32), 0.63213116]. 
=============================================
[2019-03-26 21:25:03,863] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1188331: loss 232.2075
[2019-03-26 21:25:03,865] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1188331: learning rate 0.0010
[2019-03-26 21:25:06,712] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1189603: loss 251.6834
[2019-03-26 21:25:06,714] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1189603: learning rate 0.0010
[2019-03-26 21:25:07,802] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.7929672e-16 9.9160504e-01 1.0688921e-17 8.3949203e-03 7.0078576e-17], sum to 1.0000
[2019-03-26 21:25:07,805] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4267
[2019-03-26 21:25:07,811] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2056567.401569931 W.
[2019-03-26 21:25:07,818] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.33333333333334, 68.66666666666667, 1.0, 2.0, 0.7354207833791548, 1.0, 1.0, 0.7354207833791548, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2056567.401569931, 2056567.401569931, 389654.7326917903], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4875600.0000, 
sim time next is 4876200.0000, 
raw observation next is [30.5, 68.0, 1.0, 2.0, 0.5051165193376541, 1.0, 2.0, 0.5051165193376541, 1.0, 1.0, 0.8725936884411689, 6.911199999999999, 6.9112, 170.5573041426782, 2118861.133059733, 2118861.133059734, 417857.1714056206], 
processed observation next is [1.0, 0.43478260869565216, 0.6445497630331753, 0.68, 1.0, 1.0, 0.4037548425754868, 1.0, 1.0, 0.4037548425754868, 1.0, 0.5, 0.8446264493184987, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.588572536961037, 0.5885725369610372, 0.6236674200083889], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7968804], dtype=float32), -0.5884018]. 
=============================================
[2019-03-26 21:25:09,091] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1190670: loss 288.4861
[2019-03-26 21:25:09,094] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1190672: learning rate 0.0010
[2019-03-26 21:25:12,564] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1192222: loss 266.4891
[2019-03-26 21:25:12,566] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1192222: learning rate 0.0010
[2019-03-26 21:25:12,738] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1192301: loss 230.2056
[2019-03-26 21:25:12,739] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1192301: learning rate 0.0010
[2019-03-26 21:25:14,131] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1192922: loss 0.0584
[2019-03-26 21:25:14,138] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1192923: learning rate 0.0010
[2019-03-26 21:25:14,714] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1193183: loss 234.0196
[2019-03-26 21:25:14,716] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1193184: learning rate 0.0010
[2019-03-26 21:25:15,475] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1193520: loss 232.2074
[2019-03-26 21:25:15,478] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1193521: learning rate 0.0010
[2019-03-26 21:25:16,344] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1193909: loss 0.4636
[2019-03-26 21:25:16,348] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1193911: learning rate 0.0010
[2019-03-26 21:25:16,552] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1194000: loss 214.3953
[2019-03-26 21:25:16,556] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1194000: learning rate 0.0010
[2019-03-26 21:25:17,198] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1194288: loss 221.3532
[2019-03-26 21:25:17,203] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1194289: learning rate 0.0010
[2019-03-26 21:25:17,340] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1194352: loss 229.8698
[2019-03-26 21:25:17,341] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1194352: learning rate 0.0010
[2019-03-26 21:25:17,381] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1194368: loss 231.1809
[2019-03-26 21:25:17,382] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1194368: learning rate 0.0010
[2019-03-26 21:25:17,410] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1194383: loss 293.9217
[2019-03-26 21:25:17,413] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1194383: learning rate 0.0010
[2019-03-26 21:25:17,989] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1194643: loss 223.1978
[2019-03-26 21:25:17,992] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1194643: learning rate 0.0010
[2019-03-26 21:25:18,687] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1194954: loss 213.4603
[2019-03-26 21:25:18,690] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1194954: learning rate 0.0010
[2019-03-26 21:25:20,690] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.9564257e-23 0.0000000e+00], sum to 1.0000
[2019-03-26 21:25:20,700] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6145
[2019-03-26 21:25:20,704] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.91666666666666, 84.0, 1.0, 2.0, 0.5113504572866356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 714538.1508985457, 714538.1508985457, 185393.2993440054], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5008200.0000, 
sim time next is 5008800.0000, 
raw observation next is [26.83333333333334, 84.0, 1.0, 2.0, 0.5094181981704583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 711837.194158794, 711837.1941587933, 185084.5378598327], 
processed observation next is [1.0, 1.0, 0.4707740916271725, 0.84, 1.0, 1.0, 0.4089375881571786, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19773255393299832, 0.19773255393299813, 0.2762455788952727], 
reward next is 0.7238, 
noisyNet noise sample is [array([0.7111742], dtype=float32), -1.7958832]. 
=============================================
[2019-03-26 21:25:21,604] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1196254: loss 0.2395
[2019-03-26 21:25:21,606] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1196254: learning rate 0.0010
[2019-03-26 21:25:22,290] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3552723e-27 0.0000000e+00], sum to 1.0000
[2019-03-26 21:25:22,301] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2215
[2019-03-26 21:25:22,310] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 80.66666666666667, 1.0, 2.0, 0.4982420050701053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 696214.9862049058, 696214.9862049058, 183320.6880899467], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5181600.0000, 
sim time next is 5182200.0000, 
raw observation next is [27.0, 81.5, 1.0, 2.0, 0.5017359629652348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 701098.8550179816, 701098.8550179822, 183868.1858325907], 
processed observation next is [0.0, 1.0, 0.4786729857819906, 0.815, 1.0, 1.0, 0.39968188309064434, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19474968194943934, 0.1947496819494395, 0.27443012810834433], 
reward next is 0.7256, 
noisyNet noise sample is [array([-0.76179296], dtype=float32), -1.2593123]. 
=============================================
[2019-03-26 21:25:24,722] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1197644: loss 0.6057
[2019-03-26 21:25:24,724] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1197645: learning rate 0.0010
[2019-03-26 21:25:26,992] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1198652: loss 0.8576
[2019-03-26 21:25:26,994] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1198652: learning rate 0.0010
[2019-03-26 21:25:30,118] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 21:25:30,121] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:25:30,122] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:25:30,124] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:25:30,126] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:25:30,124] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:25:30,126] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:25:30,128] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:25:30,130] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:25:30,128] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:25:30,132] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:25:30,153] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run49
[2019-03-26 21:25:30,175] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run49
[2019-03-26 21:25:30,176] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run49
[2019-03-26 21:25:30,177] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run49
[2019-03-26 21:25:30,177] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run49
[2019-03-26 21:25:36,330] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.5899416]
[2019-03-26 21:25:36,332] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.93333333333333, 69.33333333333333, 1.0, 2.0, 0.2459797860483239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 404781.7177733748, 404781.7177733748, 160508.8461100984]
[2019-03-26 21:25:36,333] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:25:36,336] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.7496946e-30 0.0000000e+00], sampled 0.785592779082518
[2019-03-26 21:26:17,734] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.5899416]
[2019-03-26 21:26:17,735] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.20556185, 77.32958426, 1.0, 2.0, 0.5052878203360025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 706063.6789732313, 706063.6789732313, 184427.1953661362]
[2019-03-26 21:26:17,738] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:26:17,742] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 7.464757e-30 0.000000e+00], sampled 0.6882108909051294
[2019-03-26 21:26:57,397] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.5899416]
[2019-03-26 21:26:57,398] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.59750081, 88.78422103, 1.0, 2.0, 0.4408472179236374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 635417.3122316065, 635417.3122316072, 177341.0886183339]
[2019-03-26 21:26:57,398] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:26:57,402] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.1855104e-29 0.0000000e+00], sampled 0.08438418354740196
[2019-03-26 21:27:06,433] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.5899416]
[2019-03-26 21:27:06,435] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.86666666666667, 93.66666666666667, 1.0, 2.0, 0.5381565603948456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 752009.0539014868, 752009.0539014868, 189786.5727289044]
[2019-03-26 21:27:06,436] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:27:06,440] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.00000e+00 1.00000e+00 0.00000e+00 3.68689e-29 0.00000e+00], sampled 0.28782561653740146
[2019-03-26 21:27:24,047] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.2748 2927846980.7461 1338.0000
[2019-03-26 21:27:25,047] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.5671 2779727878.6853 933.0000
[2019-03-26 21:27:25,054] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2741 3008104656.7243 1766.0000
[2019-03-26 21:27:25,079] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.7157 2843027813.7524 1131.0000
[2019-03-26 21:27:25,231] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7878.8875 3164502873.7783 1778.0000
[2019-03-26 21:27:26,250] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1200000, evaluation results [1200000.0, 7878.887539409773, 3164502873.778303, 1778.0, 8254.274818136657, 2927846980.7461457, 1338.0, 8660.567057309232, 2779727878.685327, 933.0, 7998.274138010797, 3008104656.724262, 1766.0, 8496.715729453535, 2843027813.7524204, 1131.0]
[2019-03-26 21:27:26,678] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1200199: loss 0.5637
[2019-03-26 21:27:26,682] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1200200: learning rate 0.0010
[2019-03-26 21:27:26,925] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1200307: loss 0.3195
[2019-03-26 21:27:26,932] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1200309: learning rate 0.0010
[2019-03-26 21:27:28,671] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1201090: loss 0.5979
[2019-03-26 21:27:28,673] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1201090: learning rate 0.0010
[2019-03-26 21:27:29,055] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1201264: loss 1.8079
[2019-03-26 21:27:29,057] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1201264: learning rate 0.0010
[2019-03-26 21:27:29,673] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1201543: loss 0.6851
[2019-03-26 21:27:29,677] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1201545: learning rate 0.0010
[2019-03-26 21:27:30,620] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1201965: loss 1.1117
[2019-03-26 21:27:30,626] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1201965: learning rate 0.0010
[2019-03-26 21:27:30,792] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1202043: loss 0.6275
[2019-03-26 21:27:30,801] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1202043: learning rate 0.0010
[2019-03-26 21:27:31,220] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1202235: loss 0.0875
[2019-03-26 21:27:31,223] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1202237: learning rate 0.0010
[2019-03-26 21:27:31,337] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1202286: loss 0.5794
[2019-03-26 21:27:31,340] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1202287: learning rate 0.0010
[2019-03-26 21:27:31,358] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1202296: loss 0.6224
[2019-03-26 21:27:31,361] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1202296: learning rate 0.0010
[2019-03-26 21:27:31,442] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1202332: loss 2.4735
[2019-03-26 21:27:31,445] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1202332: learning rate 0.0010
[2019-03-26 21:27:32,101] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1202626: loss 0.0507
[2019-03-26 21:27:32,107] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1202628: learning rate 0.0010
[2019-03-26 21:27:32,908] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1202984: loss 0.5050
[2019-03-26 21:27:32,914] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1202985: learning rate 0.0010
[2019-03-26 21:27:33,127] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9492081e-30 1.0000000e+00 2.4770318e-33 1.9794508e-15 1.0338925e-34], sum to 1.0000
[2019-03-26 21:27:33,140] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8015
[2019-03-26 21:27:33,147] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.9, 71.66666666666667, 1.0, 2.0, 0.4352652608926945, 1.0, 2.0, 0.4352652608926945, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1216721.024483988, 1216721.024483988, 281383.7620923197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5418600.0000, 
sim time next is 5419200.0000, 
raw observation next is [30.9, 72.33333333333334, 1.0, 2.0, 0.5467727236260793, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129564857762, 764053.4357502268, 764053.4357502274, 191251.3152134893], 
processed observation next is [1.0, 0.7391304347826086, 0.6635071090047393, 0.7233333333333334, 1.0, 1.0, 0.45394304051334855, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399450312363, 0.21223706548617413, 0.21223706548617427, 0.28544972419923775], 
reward next is 0.7146, 
noisyNet noise sample is [array([0.02267478], dtype=float32), 0.71111006]. 
=============================================
[2019-03-26 21:27:33,428] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.4260627e-28 0.0000000e+00], sum to 1.0000
[2019-03-26 21:27:33,435] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2944
[2019-03-26 21:27:33,439] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.55, 70.0, 1.0, 2.0, 0.5429226798948982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 758671.5109867644, 758671.5109867644, 190595.2286941819], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5596200.0000, 
sim time next is 5596800.0000, 
raw observation next is [30.26666666666667, 71.66666666666667, 1.0, 2.0, 0.5476704144670246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 765308.3097198021, 765308.3097198021, 191402.5517945992], 
processed observation next is [1.0, 0.782608695652174, 0.6334913112164299, 0.7166666666666667, 1.0, 1.0, 0.4550245957434031, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21258564158883392, 0.21258564158883392, 0.2856754504397003], 
reward next is 0.7143, 
noisyNet noise sample is [array([-2.0393257], dtype=float32), 0.10478619]. 
=============================================
[2019-03-26 21:27:34,677] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3141126e-25 0.0000000e+00], sum to 1.0000
[2019-03-26 21:27:34,686] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1963
[2019-03-26 21:27:34,691] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 88.33333333333334, 1.0, 2.0, 0.58828882238829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 822089.9688113108, 822089.9688113108, 198584.6308239584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5446200.0000, 
sim time next is 5446800.0000, 
raw observation next is [28.5, 89.0, 1.0, 2.0, 0.587981458989028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 821660.2851378199, 821660.2851378199, 198528.4640222481], 
processed observation next is [1.0, 0.043478260869565216, 0.5497630331753555, 0.89, 1.0, 1.0, 0.5035921192638891, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22823896809383887, 0.22823896809383887, 0.2963111403317136], 
reward next is 0.7037, 
noisyNet noise sample is [array([-0.11454123], dtype=float32), 0.19984435]. 
=============================================
[2019-03-26 21:27:35,852] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1204300: loss 1.2621
[2019-03-26 21:27:35,853] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1204300: learning rate 0.0010
[2019-03-26 21:27:36,635] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.1358118e-29 0.0000000e+00], sum to 1.0000
[2019-03-26 21:27:36,650] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7561
[2019-03-26 21:27:36,658] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.25, 78.5, 1.0, 2.0, 0.6276846513960663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 877165.4491132319, 877165.4491132324, 206017.5566451002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5344200.0000, 
sim time next is 5344800.0000, 
raw observation next is [31.16666666666666, 78.66666666666667, 1.0, 2.0, 0.6261678895408834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 875044.9588910389, 875044.9588910383, 205722.8452377084], 
processed observation next is [1.0, 0.8695652173913043, 0.6761453396524484, 0.7866666666666667, 1.0, 1.0, 0.549599866916727, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2430680441363997, 0.24306804413639954, 0.30704902274284834], 
reward next is 0.6930, 
noisyNet noise sample is [array([-0.27441925], dtype=float32), 0.19803262]. 
=============================================
[2019-03-26 21:27:37,581] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.4251144e-37 0.0000000e+00], sum to 1.0000
[2019-03-26 21:27:37,590] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7044
[2019-03-26 21:27:37,596] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.33333333333333, 60.0, 1.0, 2.0, 0.5424108588292609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 757956.0452014727, 757956.0452014727, 190508.1461050543], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5669400.0000, 
sim time next is 5670000.0000, 
raw observation next is [32.3, 60.0, 1.0, 2.0, 0.5416232201597805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 756855.0197158619, 756855.0197158626, 190374.9048115258], 
processed observation next is [0.0, 0.6521739130434783, 0.7298578199052131, 0.6, 1.0, 1.0, 0.447738819469615, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2102375054766283, 0.2102375054766285, 0.28414164897242655], 
reward next is 0.7159, 
noisyNet noise sample is [array([-0.45276886], dtype=float32), 0.27343026]. 
=============================================
[2019-03-26 21:27:37,607] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[76.96351 ]
 [76.884796]
 [76.77782 ]
 [76.663475]
 [76.556595]], R is [[77.09306335]
 [77.03779602]
 [76.98282623]
 [76.92808533]
 [76.87332153]].
[2019-03-26 21:27:38,946] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1205679: loss 1.0862
[2019-03-26 21:27:38,953] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1205681: learning rate 0.0010
[2019-03-26 21:27:40,146] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9018671e-13 1.3717250e-18 4.3822614e-13 1.0000000e+00 3.2754754e-10], sum to 1.0000
[2019-03-26 21:27:40,156] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2510
[2019-03-26 21:27:40,163] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.78333333333333, 65.5, 1.0, 2.0, 0.8574325370415345, 1.0, 2.0, 0.7493063080350298, 1.0, 1.0, 1.03, 7.005110148850044, 6.9112, 170.5573041426782, 3144496.3550586, 3077224.695416695, 575668.0717538554], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5482200.0000, 
sim time next is 5482800.0000, 
raw observation next is [35.0, 65.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.748159963514141, 6.9112, 170.5573041426782, 3509576.617830936, 2910028.150611166, 548936.5599103254], 
processed observation next is [1.0, 0.4782608695652174, 0.8578199052132701, 0.65, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.08369599635141407, 0.0, 0.8375144448122397, 0.9748823938419267, 0.808341152947546, 0.8193082983736201], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.05586716], dtype=float32), -0.055752344]. 
=============================================
[2019-03-26 21:27:40,722] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8849288e-19 1.0000000e+00 1.0597912e-21 3.5142600e-10 2.6776521e-21], sum to 1.0000
[2019-03-26 21:27:40,730] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5417
[2019-03-26 21:27:40,739] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1964309.830339561 W.
[2019-03-26 21:27:40,747] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.8, 73.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.630387528007676, 6.9112, 168.9093277897452, 1964309.830339561, 1454104.406315272, 311356.5305897943], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5385600.0000, 
sim time next is 5386200.0000, 
raw observation next is [31.98333333333333, 72.16666666666667, 1.0, 2.0, 0.4781107612879184, 1.0, 1.0, 0.4781107612879184, 1.0, 1.0, 0.8303202787122382, 6.9112, 6.9112, 170.5573041426782, 2005471.428910951, 2005471.428910951, 400340.6073540525], 
processed observation next is [1.0, 0.34782608695652173, 0.7148499210110584, 0.7216666666666667, 1.0, 1.0, 0.371217784684239, 1.0, 0.5, 0.371217784684239, 1.0, 0.5, 0.7930735106246807, 0.0, 0.0, 0.8375144448122397, 0.5570753969197085, 0.5570753969197085, 0.5975232945582872], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.80165374], dtype=float32), 1.495392]. 
=============================================
[2019-03-26 21:27:41,169] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1206676: loss 0.8211
[2019-03-26 21:27:41,174] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1206676: learning rate 0.0010
[2019-03-26 21:27:41,268] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8997847e-37 1.0000000e+00 0.0000000e+00 1.0712207e-21 0.0000000e+00], sum to 1.0000
[2019-03-26 21:27:41,277] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2277
[2019-03-26 21:27:41,283] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.46666666666667, 58.33333333333334, 1.0, 2.0, 0.4923990788460354, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 688047.7699068038, 688047.7699068038, 182416.9685964483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5592000.0000, 
sim time next is 5592600.0000, 
raw observation next is [32.2, 60.0, 1.0, 2.0, 0.487147862103459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 680707.6960670656, 680707.6960670656, 181610.6420791815], 
processed observation next is [1.0, 0.7391304347826086, 0.7251184834123224, 0.6, 1.0, 1.0, 0.38210585795597474, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18908547112974045, 0.18908547112974045, 0.27106065981967387], 
reward next is 0.7289, 
noisyNet noise sample is [array([0.96445054], dtype=float32), 0.9754488]. 
=============================================
[2019-03-26 21:27:42,401] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.0337358e-37 0.0000000e+00], sum to 1.0000
[2019-03-26 21:27:42,411] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2472
[2019-03-26 21:27:42,416] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.6, 74.66666666666667, 1.0, 2.0, 0.5730722300147552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 800817.8942086841, 800817.8942086835, 195837.3381750356], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5514000.0000, 
sim time next is 5514600.0000, 
raw observation next is [30.35, 76.33333333333333, 1.0, 2.0, 0.576406859247662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 805479.5113056763, 805479.5113056763, 196433.5117151019], 
processed observation next is [1.0, 0.8260869565217391, 0.637440758293839, 0.7633333333333333, 1.0, 1.0, 0.4896468183706771, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2237443086960212, 0.2237443086960212, 0.29318434584343567], 
reward next is 0.7068, 
noisyNet noise sample is [array([-2.1611848], dtype=float32), -0.32076362]. 
=============================================
[2019-03-26 21:27:44,033] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0068513e-12 9.8254170e-16 1.6185841e-12 1.0000000e+00 4.5683685e-10], sum to 1.0000
[2019-03-26 21:27:44,042] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6909
[2019-03-26 21:27:44,047] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.23333333333333, 69.33333333333333, 1.0, 2.0, 1.002576210934348, 1.0, 2.0, 1.002576210934348, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2804521.72575315, 2804521.725753151, 530554.8964116621], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5478000.0000, 
sim time next is 5478600.0000, 
raw observation next is [33.46666666666667, 68.66666666666667, 1.0, 2.0, 1.004847000295542, 1.0, 2.0, 1.004847000295542, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2810880.986005743, 2810880.986005743, 531932.7359093797], 
processed observation next is [1.0, 0.391304347826087, 0.7851500789889416, 0.6866666666666668, 1.0, 1.0, 1.0058397593922195, 1.0, 1.0, 1.0058397593922195, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7808002738904842, 0.7808002738904842, 0.7939294565811637], 
reward next is 0.2061, 
noisyNet noise sample is [array([-0.2695106], dtype=float32), -0.09507083]. 
=============================================
[2019-03-26 21:27:44,530] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1208177: loss 0.4218
[2019-03-26 21:27:44,532] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1208178: learning rate 0.0010
[2019-03-26 21:27:44,842] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1208311: loss 1.0593
[2019-03-26 21:27:44,848] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1208312: learning rate 0.0010
[2019-03-26 21:27:46,187] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1208911: loss 0.3720
[2019-03-26 21:27:46,189] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1208911: learning rate 0.0010
[2019-03-26 21:27:47,101] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 21:27:47,111] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6219
[2019-03-26 21:27:47,117] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.8, 55.0, 1.0, 2.0, 0.5212053075555958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 728313.59667673, 728313.5966767307, 186985.6740319945], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5745600.0000, 
sim time next is 5746200.0000, 
raw observation next is [33.0, 54.66666666666667, 1.0, 2.0, 0.5363100960623538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 749427.9319116526, 749427.9319116526, 189480.3181243428], 
processed observation next is [0.0, 0.5217391304347826, 0.7630331753554502, 0.5466666666666667, 1.0, 1.0, 0.441337465135366, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2081744255310146, 0.2081744255310146, 0.28280644496170565], 
reward next is 0.7172, 
noisyNet noise sample is [array([1.2781034], dtype=float32), -0.42009905]. 
=============================================
[2019-03-26 21:27:47,241] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1209382: loss 1.7588
[2019-03-26 21:27:47,243] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1209384: learning rate 0.0010
[2019-03-26 21:27:47,811] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1209637: loss 1.6131
[2019-03-26 21:27:47,815] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1209637: learning rate 0.0010
[2019-03-26 21:27:48,440] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1209920: loss 0.8835
[2019-03-26 21:27:48,441] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1209920: learning rate 0.0010
[2019-03-26 21:27:48,595] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.9165215e-30 0.0000000e+00], sum to 1.0000
[2019-03-26 21:27:48,603] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5864
[2019-03-26 21:27:48,613] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.1, 71.33333333333334, 1.0, 2.0, 0.5685703269645005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 794524.5288780818, 794524.5288780824, 195037.5903009192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5512800.0000, 
sim time next is 5513400.0000, 
raw observation next is [30.85, 73.0, 1.0, 2.0, 0.5699094366103854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 796396.5124781496, 796396.5124781496, 195274.9081794913], 
processed observation next is [1.0, 0.8260869565217391, 0.661137440758294, 0.73, 1.0, 1.0, 0.4818185983257655, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22122125346615268, 0.22122125346615268, 0.2914550868350616], 
reward next is 0.7085, 
noisyNet noise sample is [array([-1.3228749], dtype=float32), -0.44524896]. 
=============================================
[2019-03-26 21:27:48,708] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1210034: loss 1.1313
[2019-03-26 21:27:48,710] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1210035: learning rate 0.0010
[2019-03-26 21:27:49,068] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1210195: loss 1.1274
[2019-03-26 21:27:49,070] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1210195: learning rate 0.0010
[2019-03-26 21:27:49,198] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1210255: loss 1.6976
[2019-03-26 21:27:49,200] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1210255: learning rate 0.0010
[2019-03-26 21:27:49,215] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1210262: loss 1.3033
[2019-03-26 21:27:49,217] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1210262: learning rate 0.0010
[2019-03-26 21:27:49,287] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1210293: loss 0.8383
[2019-03-26 21:27:49,290] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1210294: learning rate 0.0010
[2019-03-26 21:27:50,062] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1210645: loss 2.1190
[2019-03-26 21:27:50,068] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1210646: learning rate 0.0010
[2019-03-26 21:27:51,059] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1211091: loss 1.8305
[2019-03-26 21:27:51,062] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1211092: learning rate 0.0010
[2019-03-26 21:27:53,725] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1212285: loss 3.9809
[2019-03-26 21:27:53,728] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1212285: learning rate 0.0010
[2019-03-26 21:27:56,578] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1213561: loss 1.1937
[2019-03-26 21:27:56,583] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1213562: learning rate 0.0010
[2019-03-26 21:27:59,028] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1214656: loss 2.8568
[2019-03-26 21:27:59,031] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1214657: learning rate 0.0010
[2019-03-26 21:27:59,384] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.4991006e-38 1.0000000e+00 0.0000000e+00 8.8296179e-23 0.0000000e+00], sum to 1.0000
[2019-03-26 21:27:59,394] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3311
[2019-03-26 21:27:59,399] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 92.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.057030420481707, 6.9112, 168.9116496823552, 1557282.100177859, 1453825.781208625, 311349.760079369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5802000.0000, 
sim time next is 5802600.0000, 
raw observation next is [26.25, 92.66666666666666, 1.0, 2.0, 1.009234403524848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9128061637083, 1410720.93145806, 1410720.93145806, 301751.5491550232], 
processed observation next is [1.0, 0.13043478260869565, 0.4431279620853081, 0.9266666666666665, 1.0, 1.0, 1.011125787379335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294392068810652, 0.39186692540501666, 0.39186692540501666, 0.4503754465000346], 
reward next is 0.5496, 
noisyNet noise sample is [array([0.32076138], dtype=float32), 0.78622514]. 
=============================================
[2019-03-26 21:28:00,174] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-26 21:28:00,185] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5103
[2019-03-26 21:28:00,189] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.6, 60.0, 1.0, 2.0, 0.5201989665103799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726906.8906554563, 726906.8906554563, 186821.6285277968], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5742000.0000, 
sim time next is 5742600.0000, 
raw observation next is [31.8, 59.16666666666666, 1.0, 2.0, 0.5258469851833755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 734801.9538435276, 734801.9538435276, 187744.7910346609], 
processed observation next is [0.0, 0.4782608695652174, 0.7061611374407584, 0.5916666666666666, 1.0, 1.0, 0.42873130744984994, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20411165384542432, 0.20411165384542432, 0.28021610602188196], 
reward next is 0.7198, 
noisyNet noise sample is [array([1.449952], dtype=float32), -0.6754158]. 
=============================================
[2019-03-26 21:28:02,263] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1216097: loss 3.6616
[2019-03-26 21:28:02,268] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1216097: learning rate 0.0010
[2019-03-26 21:28:02,647] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1216272: loss 3.8627
[2019-03-26 21:28:02,651] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1216273: learning rate 0.0010
[2019-03-26 21:28:04,435] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1217067: loss 0.9314
[2019-03-26 21:28:04,439] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1217069: learning rate 0.0010
[2019-03-26 21:28:05,167] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1217398: loss 5.8069
[2019-03-26 21:28:05,170] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1217398: learning rate 0.0010
[2019-03-26 21:28:05,293] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.3714109e-18 1.3204317e-03 2.0097260e-19 9.9867958e-01 1.2841043e-19], sum to 1.0000
[2019-03-26 21:28:05,300] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0508
[2019-03-26 21:28:05,305] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.03333333333333, 78.5, 1.0, 2.0, 0.7497371346868698, 1.0, 2.0, 0.7497371346868698, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2096641.539723324, 2096641.539723323, 396150.7280159807], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5907000.0000, 
sim time next is 5907600.0000, 
raw observation next is [30.2, 78.0, 1.0, 2.0, 0.77276844958043, 1.0, 2.0, 0.77276844958043, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2161113.632846738, 2161113.632846738, 406839.0646555874], 
processed observation next is [1.0, 0.391304347826087, 0.6303317535545023, 0.78, 1.0, 1.0, 0.7262270476872651, 1.0, 1.0, 0.7262270476872651, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6003093424574273, 0.6003093424574273, 0.6072224845605783], 
reward next is 0.3928, 
noisyNet noise sample is [array([-1.1573068], dtype=float32), -0.40063623]. 
=============================================
[2019-03-26 21:28:05,700] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1217631: loss 10.6419
[2019-03-26 21:28:05,702] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1217632: learning rate 0.0010
[2019-03-26 21:28:06,419] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1217950: loss 1.4552
[2019-03-26 21:28:06,422] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1217950: learning rate 0.0010
[2019-03-26 21:28:06,497] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1217987: loss 4.0571
[2019-03-26 21:28:06,498] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1217988: learning rate 0.0010
[2019-03-26 21:28:06,903] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1218166: loss 15.4320
[2019-03-26 21:28:06,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1218167: learning rate 0.0010
[2019-03-26 21:28:07,209] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1218298: loss 5.1455
[2019-03-26 21:28:07,211] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1218299: learning rate 0.0010
[2019-03-26 21:28:07,272] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1218330: loss 5.5764
[2019-03-26 21:28:07,276] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1218331: learning rate 0.0010
[2019-03-26 21:28:07,295] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1218340: loss 1.1493
[2019-03-26 21:28:07,296] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1218340: learning rate 0.0010
[2019-03-26 21:28:08,094] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1218697: loss 8.2287
[2019-03-26 21:28:08,095] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1218697: learning rate 0.0010
[2019-03-26 21:28:09,045] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1219120: loss 11.4947
[2019-03-26 21:28:09,048] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1219120: learning rate 0.0010
[2019-03-26 21:28:11,736] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1220328: loss 1.8711
[2019-03-26 21:28:11,738] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1220330: learning rate 0.0010
[2019-03-26 21:28:14,840] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1221714: loss 2.0151
[2019-03-26 21:28:14,847] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1221714: learning rate 0.0010
[2019-03-26 21:28:15,328] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 4.782436e-28 0.000000e+00], sum to 1.0000
[2019-03-26 21:28:15,341] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9977
[2019-03-26 21:28:15,347] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.63333333333333, 90.33333333333333, 1.0, 2.0, 0.6734618237490946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 941165.6530311353, 941165.6530311353, 215220.992789946], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6068400.0000, 
sim time next is 6069000.0000, 
raw observation next is [26.76666666666667, 89.66666666666667, 1.0, 2.0, 0.674263405035288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 942286.3631138303, 942286.3631138309, 215387.915329292], 
processed observation next is [1.0, 0.21739130434782608, 0.46761453396524505, 0.8966666666666667, 1.0, 1.0, 0.607546271126853, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.26174621197606396, 0.2617462119760641, 0.32147450049148063], 
reward next is 0.6785, 
noisyNet noise sample is [array([1.4609531], dtype=float32), -0.14095822]. 
=============================================
[2019-03-26 21:28:15,364] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[56.481358]
 [56.372044]
 [56.232037]
 [56.20768 ]
 [56.345753]], R is [[56.65549469]
 [56.76771545]
 [56.87810516]
 [56.98714828]
 [57.08477783]].
[2019-03-26 21:28:16,936] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1222632: loss 3.1756
[2019-03-26 21:28:16,939] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1222632: learning rate 0.0010
[2019-03-26 21:28:17,161] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3675441e-27 1.0000000e+00 1.0268980e-30 7.1838821e-15 1.3225516e-32], sum to 1.0000
[2019-03-26 21:28:17,174] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5391
[2019-03-26 21:28:17,188] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2152371.332426536 W.
[2019-03-26 21:28:17,194] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.7, 66.5, 1.0, 2.0, 0.898095927733748, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.987020017028772, 6.9112, 168.9124417206691, 2152371.332426536, 2098582.16675448, 434225.9549184554], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6103800.0000, 
sim time next is 6104400.0000, 
raw observation next is [30.66666666666666, 66.66666666666667, 1.0, 2.0, 0.7777608289205723, 1.0, 1.0, 0.7777608289205723, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2175089.427699334, 2175089.427699334, 409186.7922301], 
processed observation next is [1.0, 0.6521739130434783, 0.6524486571879934, 0.6666666666666667, 1.0, 1.0, 0.7322419625549064, 1.0, 0.5, 0.7322419625549064, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6041915076942594, 0.6041915076942594, 0.6107265555673135], 
reward next is 0.3893, 
noisyNet noise sample is [array([0.6415629], dtype=float32), 1.1341406]. 
=============================================
[2019-03-26 21:28:20,266] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1224120: loss 2.7589
[2019-03-26 21:28:20,267] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1224120: learning rate 0.0010
[2019-03-26 21:28:20,276] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.4177897e-15 7.3589887e-03 7.3314837e-17 9.9264103e-01 6.9773381e-16], sum to 1.0000
[2019-03-26 21:28:20,284] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6929
[2019-03-26 21:28:20,287] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 8.977804e-23 0.000000e+00], sum to 1.0000
[2019-03-26 21:28:20,288] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.4, 68.33333333333334, 1.0, 2.0, 0.5528960204322407, 1.0, 2.0, 0.5528960204322407, 1.0, 2.0, 0.9564548139828313, 6.9112, 6.9112, 170.5573041426782, 2319486.913933739, 2319486.913933739, 452896.6236746135], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6108000.0000, 
sim time next is 6108600.0000, 
raw observation next is [30.35, 68.66666666666666, 1.0, 2.0, 0.827435686832493, 1.0, 2.0, 0.827435686832493, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2314144.768042214, 2314144.768042214, 433445.1671245024], 
processed observation next is [1.0, 0.6956521739130435, 0.637440758293839, 0.6866666666666665, 1.0, 1.0, 0.7920911889548109, 1.0, 1.0, 0.7920911889548109, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6428179911228373, 0.6428179911228373, 0.6469330852604513], 
reward next is 0.3531, 
noisyNet noise sample is [array([-0.7789157], dtype=float32), 0.765264]. 
=============================================
[2019-03-26 21:28:20,297] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2877
[2019-03-26 21:28:20,303] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.58333333333334, 92.0, 1.0, 2.0, 0.8195761215711496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1145471.112078917, 1145471.112078916, 248772.8191490404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6149400.0000, 
sim time next is 6150000.0000, 
raw observation next is [26.56666666666667, 92.0, 1.0, 2.0, 0.7094215103613662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 991442.9196514131, 991442.9196514137, 222892.1227399357], 
processed observation next is [1.0, 0.17391304347826086, 0.45813586097946307, 0.92, 1.0, 1.0, 0.6499054341703208, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.27540081101428143, 0.2754008110142816, 0.33267481005960553], 
reward next is 0.6673, 
noisyNet noise sample is [array([-0.60065097], dtype=float32), -0.22889224]. 
=============================================
[2019-03-26 21:28:20,321] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[57.180687]
 [58.769833]
 [58.941807]
 [59.13464 ]
 [58.99747 ]], R is [[58.39900589]
 [58.44371414]
 [58.53017044]
 [58.61323929]
 [58.69249344]].
[2019-03-26 21:28:20,684] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1224307: loss 2.5729
[2019-03-26 21:28:20,686] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1224309: learning rate 0.0010
[2019-03-26 21:28:22,147] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1224899: loss 1378.6973
[2019-03-26 21:28:22,151] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1224900: learning rate 0.0010
[2019-03-26 21:28:22,369] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 21:28:22,374] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:28:22,375] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:28:22,376] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:28:22,378] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:28:22,377] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:28:22,379] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:28:22,381] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:28:22,378] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:28:22,382] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:28:22,386] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:28:22,396] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run50
[2019-03-26 21:28:22,416] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run50
[2019-03-26 21:28:22,438] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run50
[2019-03-26 21:28:22,439] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run50
[2019-03-26 21:28:22,485] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run50
[2019-03-26 21:28:30,241] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.49429128]
[2019-03-26 21:28:30,243] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.66666666666667, 74.33333333333334, 1.0, 2.0, 0.4821566031659228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742447.6737088154, 742447.6737088148, 189089.0669748627]
[2019-03-26 21:28:30,244] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:28:30,247] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5478245e-32 0.0000000e+00], sampled 0.8363661329545659
[2019-03-26 21:29:53,854] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.49429128]
[2019-03-26 21:29:53,855] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.3, 71.5, 1.0, 2.0, 0.4871206774760796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 680669.6979250896, 680669.6979250903, 181602.5562100193]
[2019-03-26 21:29:53,856] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:29:53,858] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 6.669276e-36 0.000000e+00], sampled 0.9902444084221942
[2019-03-26 21:30:14,226] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7877.1551 3164638718.8196 1776.0000
[2019-03-26 21:30:14,522] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.9766 3008303976.5521 1766.0000
[2019-03-26 21:30:14,681] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.0740 2927981547.8413 1338.0000
[2019-03-26 21:30:14,710] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.0319 2779830318.5638 932.0000
[2019-03-26 21:30:14,752] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.8629 2843167093.8007 1131.0000
[2019-03-26 21:30:15,768] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1225000, evaluation results [1225000.0, 7877.155125466313, 3164638718.81958, 1776.0, 8254.073971726037, 2927981547.8412614, 1338.0, 8660.03188781958, 2779830318.5637875, 932.0, 7997.976645730424, 3008303976.5521116, 1766.0, 8495.862932155293, 2843167093.8007364, 1131.0]
[2019-03-26 21:30:16,429] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1225302: loss 2.7189
[2019-03-26 21:30:16,431] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1225303: learning rate 0.0010
[2019-03-26 21:30:17,020] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1225572: loss 2.4716
[2019-03-26 21:30:17,021] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1225572: learning rate 0.0010
[2019-03-26 21:30:17,481] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1225778: loss 1357.4297
[2019-03-26 21:30:17,483] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1225778: learning rate 0.0010
[2019-03-26 21:30:17,922] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1225977: loss 2.1651
[2019-03-26 21:30:17,924] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1225978: learning rate 0.0010
[2019-03-26 21:30:18,427] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 5.542223e-28 0.000000e+00], sum to 1.0000
[2019-03-26 21:30:18,434] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5219
[2019-03-26 21:30:18,442] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 88.0, 1.0, 2.0, 0.5367055306939107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 749980.6986402537, 749980.6986402532, 189547.0545906634], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6132600.0000, 
sim time next is 6133200.0000, 
raw observation next is [27.16666666666667, 88.33333333333333, 1.0, 2.0, 0.5388578802352892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 752989.4113689464, 752989.4113689458, 189908.2768996689], 
processed observation next is [1.0, 1.0, 0.4865718799368091, 0.8833333333333333, 1.0, 1.0, 0.4444070846208304, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2091637253802629, 0.20916372538026273, 0.2834451894024909], 
reward next is 0.7166, 
noisyNet noise sample is [array([0.79475176], dtype=float32), 0.6921818]. 
=============================================
[2019-03-26 21:30:18,503] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1226237: loss 1.6545
[2019-03-26 21:30:18,506] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1226237: learning rate 0.0010
[2019-03-26 21:30:18,643] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1226293: loss 2.2170
[2019-03-26 21:30:18,648] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1226294: learning rate 0.0010
[2019-03-26 21:30:18,707] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1226326: loss 1.4390
[2019-03-26 21:30:18,715] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1226327: learning rate 0.0010
[2019-03-26 21:30:18,758] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.5112637e-19 8.4413560e-03 1.8882284e-21 9.9155867e-01 3.7270212e-20], sum to 1.0000
[2019-03-26 21:30:18,769] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2117
[2019-03-26 21:30:18,776] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.71666666666667, 80.66666666666667, 1.0, 2.0, 0.7725472046359921, 1.0, 2.0, 0.7725472046359921, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2160494.278290675, 2160494.278290675, 406727.829580905], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6169800.0000, 
sim time next is 6170400.0000, 
raw observation next is [28.8, 80.0, 1.0, 2.0, 0.780444973129417, 1.0, 2.0, 0.780444973129417, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2182603.56526164, 2182603.56526164, 410463.3842498112], 
processed observation next is [1.0, 0.43478260869565216, 0.5639810426540285, 0.8, 1.0, 1.0, 0.7354758712402614, 1.0, 1.0, 0.7354758712402614, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6062787681282333, 0.6062787681282333, 0.6126319167907629], 
reward next is 0.3874, 
noisyNet noise sample is [array([-1.2678125], dtype=float32), 0.5564328]. 
=============================================
[2019-03-26 21:30:18,866] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1226395: loss 2.0509
[2019-03-26 21:30:18,868] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1226395: learning rate 0.0010
[2019-03-26 21:30:19,783] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1226804: loss 0.8135
[2019-03-26 21:30:19,787] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1226804: learning rate 0.0010
[2019-03-26 21:30:20,698] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1227211: loss 1.7102
[2019-03-26 21:30:20,699] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1227211: learning rate 0.0010
[2019-03-26 21:30:22,880] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1228195: loss 1208.7686
[2019-03-26 21:30:22,882] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1228196: learning rate 0.0010
[2019-03-26 21:30:23,394] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3466125e-30 0.0000000e+00], sum to 1.0000
[2019-03-26 21:30:23,404] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1473
[2019-03-26 21:30:23,408] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.86666666666667, 62.0, 1.0, 2.0, 0.511359269741871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 714550.4691691964, 714550.4691691964, 185395.0851147994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6271800.0000, 
sim time next is 6272400.0000, 
raw observation next is [30.83333333333334, 62.0, 1.0, 2.0, 0.5098208307436327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712400.0027689746, 712400.002768974, 185149.2394375378], 
processed observation next is [0.0, 0.6086956521739131, 0.6603475513428123, 0.62, 1.0, 1.0, 0.40942268764293094, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19788888965804852, 0.19788888965804835, 0.2763421484142355], 
reward next is 0.7237, 
noisyNet noise sample is [array([-0.45441037], dtype=float32), 1.567782]. 
=============================================
[2019-03-26 21:30:26,429] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1229783: loss 1953.7075
[2019-03-26 21:30:26,430] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1229783: learning rate 0.0010
[2019-03-26 21:30:28,395] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1230667: loss 1704.6156
[2019-03-26 21:30:28,397] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1230667: learning rate 0.0010
[2019-03-26 21:30:29,452] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0982952e-27 0.0000000e+00], sum to 1.0000
[2019-03-26 21:30:29,460] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3988
[2019-03-26 21:30:29,468] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.4, 77.0, 1.0, 2.0, 0.5221943287481604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729696.0940914345, 729696.0940914345, 187146.4758004152], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6336000.0000, 
sim time next is 6336600.0000, 
raw observation next is [28.55, 76.33333333333334, 1.0, 2.0, 0.5230728038745603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 730924.0668513494, 730924.06685135, 187290.0561081764], 
processed observation next is [0.0, 0.34782608695652173, 0.552132701421801, 0.7633333333333334, 1.0, 1.0, 0.42538892033079556, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20303446301426373, 0.2030344630142639, 0.27953739717638265], 
reward next is 0.7205, 
noisyNet noise sample is [array([0.78549695], dtype=float32), -0.5733392]. 
=============================================
[2019-03-26 21:30:30,134] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.5498972e-29 0.0000000e+00], sum to 1.0000
[2019-03-26 21:30:30,138] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0910
[2019-03-26 21:30:30,148] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 81.0, 1.0, 2.0, 0.5230324939998808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 730867.7198315278, 730867.7198315272, 187283.4548789769], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6332400.0000, 
sim time next is 6333000.0000, 
raw observation next is [27.9, 80.33333333333333, 1.0, 2.0, 0.522397246669101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 729979.7419275157, 729979.7419275151, 187179.6792625401], 
processed observation next is [0.0, 0.30434782608695654, 0.5213270142180094, 0.8033333333333332, 1.0, 1.0, 0.4245749959868687, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20277215053542103, 0.20277215053542086, 0.2793726556157315], 
reward next is 0.7206, 
noisyNet noise sample is [array([-1.1210904], dtype=float32), -0.6534483]. 
=============================================
[2019-03-26 21:30:30,168] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[72.936  ]
 [72.79266]
 [72.77287]
 [72.75585]
 [72.74538]], R is [[72.93621826]
 [72.92733002]
 [72.91835022]
 [72.90938568]
 [72.90061188]].
[2019-03-26 21:30:31,495] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1232057: loss 909.9354
[2019-03-26 21:30:31,498] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1232057: learning rate 0.0010
[2019-03-26 21:30:32,111] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1232331: loss 881.3734
[2019-03-26 21:30:32,115] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1232332: learning rate 0.0010
[2019-03-26 21:30:33,334] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.6328573e-36 1.0000000e+00 0.0000000e+00 2.0258024e-17 0.0000000e+00], sum to 1.0000
[2019-03-26 21:30:33,342] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6061
[2019-03-26 21:30:33,348] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.91666666666667, 84.66666666666667, 1.0, 2.0, 0.9667340763539486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129514303031, 1351275.613025517, 1351275.613025517, 288952.2227001259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6403800.0000, 
sim time next is 6404400.0000, 
raw observation next is [26.9, 85.0, 1.0, 2.0, 0.958417360410368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565091625, 1339643.390294484, 1339643.390294483, 286510.4543876376], 
processed observation next is [1.0, 0.13043478260869565, 0.4739336492890995, 0.85, 1.0, 1.0, 0.949900434229359, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451460738, 0.37212316397069, 0.37212316397068973, 0.4276275438621457], 
reward next is 0.5724, 
noisyNet noise sample is [array([-0.9790189], dtype=float32), -0.74110883]. 
=============================================
[2019-03-26 21:30:33,882] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1233102: loss 0.1181
[2019-03-26 21:30:33,886] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1233102: learning rate 0.0010
[2019-03-26 21:30:34,264] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1233270: loss 810.5388
[2019-03-26 21:30:34,266] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1233270: learning rate 0.0010
[2019-03-26 21:30:34,810] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1233519: loss 793.0243
[2019-03-26 21:30:34,814] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1233519: learning rate 0.0010
[2019-03-26 21:30:35,749] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1233937: loss 0.0629
[2019-03-26 21:30:35,754] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1233939: learning rate 0.0010
[2019-03-26 21:30:35,759] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1233940: loss 213.6226
[2019-03-26 21:30:35,765] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1233942: learning rate 0.0010
[2019-03-26 21:30:36,288] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1234177: loss 883.1292
[2019-03-26 21:30:36,290] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1234177: learning rate 0.0010
[2019-03-26 21:30:36,360] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1234207: loss 410.8628
[2019-03-26 21:30:36,362] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1234207: learning rate 0.0010
[2019-03-26 21:30:36,515] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1234278: loss 841.4462
[2019-03-26 21:30:36,516] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1234278: learning rate 0.0010
[2019-03-26 21:30:36,713] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1234367: loss 822.3746
[2019-03-26 21:30:36,714] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1234369: learning rate 0.0010
[2019-03-26 21:30:37,446] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5485834e-21 0.0000000e+00], sum to 1.0000
[2019-03-26 21:30:37,454] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4929
[2019-03-26 21:30:37,461] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.85, 75.0, 1.0, 2.0, 0.4895861670088543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 684115.9166385791, 684115.9166385791, 181980.4981491886], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6553800.0000, 
sim time next is 6554400.0000, 
raw observation next is [27.8, 75.66666666666666, 1.0, 2.0, 0.4916107407467386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 686945.8392241794, 686945.83922418, 182292.0809893254], 
processed observation next is [1.0, 0.8695652173913043, 0.5165876777251186, 0.7566666666666666, 1.0, 1.0, 0.3874828201767935, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19081828867338316, 0.19081828867338332, 0.2720777328198886], 
reward next is 0.7279, 
noisyNet noise sample is [array([-1.5520568], dtype=float32), 0.069952436]. 
=============================================
[2019-03-26 21:30:37,479] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1234709: loss 576.7833
[2019-03-26 21:30:37,481] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1234710: learning rate 0.0010
[2019-03-26 21:30:38,644] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1235227: loss 672.6201
[2019-03-26 21:30:38,647] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1235227: learning rate 0.0010
[2019-03-26 21:30:41,006] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1236284: loss 0.0197
[2019-03-26 21:30:41,007] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1236284: learning rate 0.0010
[2019-03-26 21:30:42,312] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7164182e-22 2.0503987e-02 4.8476513e-25 9.7949606e-01 2.1384436e-24], sum to 1.0000
[2019-03-26 21:30:42,322] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7316
[2019-03-26 21:30:42,327] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.13333333333333, 59.0, 1.0, 2.0, 0.7442567214277815, 1.0, 2.0, 0.7442567214277815, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2081300.663492376, 2081300.663492376, 393636.9005196973], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6535200.0000, 
sim time next is 6535800.0000, 
raw observation next is [31.0, 59.5, 1.0, 2.0, 0.7451643877360719, 1.0, 2.0, 0.7451643877360719, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2083841.404973908, 2083841.404973908, 394049.1354006689], 
processed observation next is [1.0, 0.6521739130434783, 0.6682464454976303, 0.595, 1.0, 1.0, 0.6929691418506889, 1.0, 1.0, 0.6929691418506889, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5788448347149745, 0.5788448347149745, 0.5881330379114461], 
reward next is 0.4119, 
noisyNet noise sample is [array([-1.6391414], dtype=float32), 0.28134075]. 
=============================================
[2019-03-26 21:30:44,426] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1237822: loss 0.0046
[2019-03-26 21:30:44,429] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1237823: learning rate 0.0010
[2019-03-26 21:30:46,347] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1238683: loss 0.0190
[2019-03-26 21:30:46,349] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1238684: learning rate 0.0010
[2019-03-26 21:30:49,593] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1240145: loss 0.0076
[2019-03-26 21:30:49,596] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1240146: learning rate 0.0010
[2019-03-26 21:30:50,088] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1240365: loss 0.0108
[2019-03-26 21:30:50,090] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1240366: learning rate 0.0010
[2019-03-26 21:30:51,469] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1240986: loss 3.2615
[2019-03-26 21:30:51,472] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1240987: learning rate 0.0010
[2019-03-26 21:30:52,206] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1241311: loss 0.0417
[2019-03-26 21:30:52,209] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1241312: learning rate 0.0010
[2019-03-26 21:30:52,717] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1241542: loss 0.1528
[2019-03-26 21:30:52,722] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1241544: learning rate 0.0010
[2019-03-26 21:30:53,348] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1241824: loss 21.2292
[2019-03-26 21:30:53,354] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1241825: learning rate 0.0010
[2019-03-26 21:30:53,843] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1242045: loss 0.0267
[2019-03-26 21:30:53,846] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1242045: learning rate 0.0010
[2019-03-26 21:30:54,241] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1242223: loss 0.0043
[2019-03-26 21:30:54,243] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1242224: learning rate 0.0010
[2019-03-26 21:30:54,410] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1242295: loss 0.0118
[2019-03-26 21:30:54,411] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1242296: learning rate 0.0010
[2019-03-26 21:30:54,524] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1242349: loss 0.0063
[2019-03-26 21:30:54,526] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1242349: learning rate 0.0010
[2019-03-26 21:30:54,859] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1242497: loss 0.0271
[2019-03-26 21:30:54,864] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1242498: learning rate 0.0010
[2019-03-26 21:30:55,640] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1242851: loss 0.0122
[2019-03-26 21:30:55,643] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1242852: learning rate 0.0010
[2019-03-26 21:30:56,512] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6395143e-30 0.0000000e+00], sum to 1.0000
[2019-03-26 21:30:56,522] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4749
[2019-03-26 21:30:56,526] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 90.66666666666667, 1.0, 2.0, 0.4149436429970368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 611070.153209249, 611070.153209249, 175341.5404123613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6930600.0000, 
sim time next is 6931200.0000, 
raw observation next is [24.0, 89.33333333333334, 1.0, 2.0, 0.4156428271130365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 611545.8753499115, 611545.8753499115, 175370.8192671171], 
processed observation next is [0.0, 0.21739130434782608, 0.3364928909952607, 0.8933333333333334, 1.0, 1.0, 0.2959552133892006, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1698738542638643, 0.1698738542638643, 0.2617474914434584], 
reward next is 0.7383, 
noisyNet noise sample is [array([-0.45864692], dtype=float32), 0.99858004]. 
=============================================
[2019-03-26 21:30:56,608] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1243282: loss 0.0767
[2019-03-26 21:30:56,610] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1243282: learning rate 0.0010
[2019-03-26 21:30:56,995] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.00000e+00 1.00000e+00 0.00000e+00 7.73478e-22 0.00000e+00], sum to 1.0000
[2019-03-26 21:30:57,004] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5237
[2019-03-26 21:30:57,007] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.13333333333333, 49.66666666666666, 1.0, 2.0, 0.983175641571401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1517779.401463615, 1517779.401463614, 314605.7827455242], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6799200.0000, 
sim time next is 6799800.0000, 
raw observation next is [29.11666666666667, 49.83333333333334, 1.0, 2.0, 0.9959389549247336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1536659.084714192, 1536659.084714191, 318770.0041731353], 
processed observation next is [1.0, 0.6956521739130435, 0.5789889415481835, 0.4983333333333334, 1.0, 1.0, 0.9951071746081128, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.4268497457539422, 0.42684974575394197, 0.47577612563154525], 
reward next is 0.5242, 
noisyNet noise sample is [array([0.30348948], dtype=float32), 0.97575504]. 
=============================================
[2019-03-26 21:30:58,655] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1244191: loss 128.8376
[2019-03-26 21:30:58,657] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1244191: learning rate 0.0010
[2019-03-26 21:31:02,229] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1245796: loss -20.6791
[2019-03-26 21:31:02,232] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1245797: learning rate 0.0010
[2019-03-26 21:31:02,311] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 9.9052623e-26 0.0000000e+00], sum to 1.0000
[2019-03-26 21:31:02,320] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5922
[2019-03-26 21:31:02,326] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.86666666666667, 58.66666666666667, 1.0, 2.0, 0.4558483970616229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 648770.5358751133, 648770.5358751127, 178488.3026248644], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6974400.0000, 
sim time next is 6975000.0000, 
raw observation next is [29.8, 58.5, 1.0, 2.0, 0.4528090363367156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 646873.6021973578, 646873.6021973571, 178353.7599114793], 
processed observation next is [0.0, 0.7391304347826086, 0.6113744075829385, 0.585, 1.0, 1.0, 0.3407337787189345, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17968711172148827, 0.17968711172148807, 0.26619964165892435], 
reward next is 0.7338, 
noisyNet noise sample is [array([0.08059351], dtype=float32), 0.7120269]. 
=============================================
[2019-03-26 21:31:02,341] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[69.22909]
 [69.22768]
 [69.20823]
 [69.11203]
 [69.13991]], R is [[69.30461884]
 [69.34516907]
 [69.38528442]
 [69.42402649]
 [69.46194458]].
[2019-03-26 21:31:04,113] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1246639: loss -107.6946
[2019-03-26 21:31:04,115] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1246639: learning rate 0.0010
[2019-03-26 21:31:07,325] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1248082: loss -28.7232
[2019-03-26 21:31:07,331] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1248083: learning rate 0.0010
[2019-03-26 21:31:07,870] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1248327: loss -193.5912
[2019-03-26 21:31:07,876] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1248327: learning rate 0.0010
[2019-03-26 21:31:09,729] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1249156: loss 0.0340
[2019-03-26 21:31:09,731] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1249156: learning rate 0.0010
[2019-03-26 21:31:09,845] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.8262086e-31 0.0000000e+00], sum to 1.0000
[2019-03-26 21:31:09,853] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9822
[2019-03-26 21:31:09,858] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 78.0, 1.0, 2.0, 0.4482107158004517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 642325.5437809144, 642325.5437809144, 177941.5072398884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6998400.0000, 
sim time next is 6999000.0000, 
raw observation next is [26.26666666666667, 78.33333333333333, 1.0, 2.0, 0.4498600878039608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 644362.2943696409, 644362.2943696403, 178140.1221229633], 
processed observation next is [1.0, 0.0, 0.44391785150079005, 0.7833333333333333, 1.0, 1.0, 0.3371808286794708, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17898952621378914, 0.17898952621378897, 0.26588077928800496], 
reward next is 0.7341, 
noisyNet noise sample is [array([-1.4222201], dtype=float32), 0.50750554]. 
=============================================
[2019-03-26 21:31:09,869] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[76.87622 ]
 [82.597824]
 [82.62132 ]
 [82.65285 ]
 [82.70356 ]], R is [[74.0236969 ]
 [74.01787567]
 [74.01210785]
 [74.00650024]
 [74.00118256]].
[2019-03-26 21:31:10,054] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1249298: loss 154.8522
[2019-03-26 21:31:10,055] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1249299: learning rate 0.0010
[2019-03-26 21:31:10,615] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1249551: loss -141.7709
[2019-03-26 21:31:10,617] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1249552: learning rate 0.0010
[2019-03-26 21:31:11,287] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1249863: loss 0.0365
[2019-03-26 21:31:11,289] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1249863: learning rate 0.0010
[2019-03-26 21:31:11,659] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 21:31:11,660] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:31:11,661] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:31:11,661] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:31:11,662] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:31:11,665] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:31:11,666] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:31:11,667] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:31:11,664] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:31:11,670] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:31:11,672] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:31:11,695] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run51
[2019-03-26 21:31:11,717] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run51
[2019-03-26 21:31:11,739] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run51
[2019-03-26 21:31:11,762] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run51
[2019-03-26 21:31:11,763] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run51
[2019-03-26 21:31:19,013] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56534237]
[2019-03-26 21:31:19,014] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.8, 77.5, 1.0, 2.0, 0.3972677704483104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 653737.6474729812, 653737.6474729812, 179071.1754221473]
[2019-03-26 21:31:19,016] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:31:19,020] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.3603427e-24 0.0000000e+00], sampled 0.8948746930483648
[2019-03-26 21:31:40,524] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56534237]
[2019-03-26 21:31:40,526] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.5, 91.0, 1.0, 2.0, 0.8253365866930183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1153526.5329145, 1153526.532914501, 250222.0657609555]
[2019-03-26 21:31:40,527] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:31:40,529] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.0793284e-21 0.0000000e+00], sampled 0.4675556176979686
[2019-03-26 21:31:43,560] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56534237]
[2019-03-26 21:31:43,560] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.7, 94.0, 1.0, 2.0, 0.3768230200393364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 567989.627089897, 567989.627089897, 171822.8452709726]
[2019-03-26 21:31:43,562] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:31:43,564] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6873226e-24 0.0000000e+00], sampled 0.10575183890848339
[2019-03-26 21:31:45,830] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56534237]
[2019-03-26 21:31:45,832] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.0499483, 56.37746376, 1.0, 2.0, 0.648818463519946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 906711.755212815, 906711.755212815, 210182.0900024825]
[2019-03-26 21:31:45,835] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:31:45,837] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 7.507018e-23 0.000000e+00], sampled 0.7697704886207185
[2019-03-26 21:31:54,612] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56534237]
[2019-03-26 21:31:54,613] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.7, 77.0, 1.0, 2.0, 0.6448287847523375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 901133.8878803306, 901133.8878803306, 209384.7961152852]
[2019-03-26 21:31:54,614] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:31:54,616] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1702923e-22 0.0000000e+00], sampled 0.040863760297272234
[2019-03-26 21:31:57,239] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56534237]
[2019-03-26 21:31:57,241] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.7, 68.0, 1.0, 2.0, 0.7699653272104823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1076098.023661495, 1076098.023661495, 236672.8178538751]
[2019-03-26 21:31:57,242] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:31:57,244] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 3.615208e-21 0.000000e+00], sampled 0.0399128396194105
[2019-03-26 21:32:16,723] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56534237]
[2019-03-26 21:32:16,724] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.58253077, 85.23818496333334, 1.0, 2.0, 0.5351916429672248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 747864.4799696682, 747864.4799696688, 189293.7649797396]
[2019-03-26 21:32:16,725] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:32:16,726] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 8.2888976e-24 0.0000000e+00], sampled 0.5727072167557742
[2019-03-26 21:32:22,136] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56534237]
[2019-03-26 21:32:22,141] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.26715754666667, 83.64705603333333, 1.0, 2.0, 0.4949789167894408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 691653.8481722331, 691653.8481722337, 182812.2544962781]
[2019-03-26 21:32:22,146] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:32:22,149] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 7.221904e-24 0.000000e+00], sampled 0.9464269485024934
[2019-03-26 21:32:44,223] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56534237]
[2019-03-26 21:32:44,224] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.58846088, 85.66045873, 1.0, 2.0, 0.6956713870350888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 972217.8154124003, 972217.8154124003, 219911.6038844326]
[2019-03-26 21:32:44,224] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:32:44,227] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.6082911e-21 0.0000000e+00], sampled 0.19267581373613818
[2019-03-26 21:32:51,756] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.56534237]
[2019-03-26 21:32:51,757] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.5, 64.66666666666667, 1.0, 2.0, 0.4408929778499958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 633161.8353945035, 633161.8353945035, 177054.3946692837]
[2019-03-26 21:32:51,759] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:32:51,762] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.2958759e-24 0.0000000e+00], sampled 0.2885039763488402
[2019-03-26 21:33:05,734] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.8216 2779836413.0450 927.0000
[2019-03-26 21:33:06,271] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7878.1922 3164270909.1007 1771.0000
[2019-03-26 21:33:06,350] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.7216 2843266204.0812 1130.0000
[2019-03-26 21:33:06,382] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.8776 2927980590.1882 1334.0000
[2019-03-26 21:33:06,384] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.6418 3008292636.6174 1767.0000
[2019-03-26 21:33:07,401] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1250000, evaluation results [1250000.0, 7878.19219004646, 3164270909.1007137, 1771.0, 8255.877618126327, 2927980590.1882486, 1334.0, 8660.821567294593, 2779836413.044969, 927.0, 7997.641807735364, 3008292636.61744, 1767.0, 8495.721599672193, 2843266204.081167, 1130.0]
[2019-03-26 21:33:07,522] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1250059: loss -28.3558
[2019-03-26 21:33:07,526] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1250060: learning rate 0.0010
[2019-03-26 21:33:07,703] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1250138: loss -119.0245
[2019-03-26 21:33:07,706] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1250138: learning rate 0.0010
[2019-03-26 21:33:07,943] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1250242: loss -128.2168
[2019-03-26 21:33:07,948] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1250243: learning rate 0.0010
[2019-03-26 21:33:08,033] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1250286: loss -190.5346
[2019-03-26 21:33:08,036] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1250287: learning rate 0.0010
[2019-03-26 21:33:08,408] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1250452: loss -50.0415
[2019-03-26 21:33:08,410] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1250454: learning rate 0.0010
[2019-03-26 21:33:09,175] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1250792: loss -136.1380
[2019-03-26 21:33:09,177] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1250792: learning rate 0.0010
[2019-03-26 21:33:10,033] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1251172: loss -175.7350
[2019-03-26 21:33:10,035] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1251172: learning rate 0.0010
[2019-03-26 21:33:12,240] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1252160: loss 0.0192
[2019-03-26 21:33:12,241] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1252160: learning rate 0.0010
[2019-03-26 21:33:15,912] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1253804: loss 0.2194
[2019-03-26 21:33:15,916] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1253806: learning rate 0.0010
[2019-03-26 21:33:17,790] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1254651: loss 0.1047
[2019-03-26 21:33:17,796] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1254652: learning rate 0.0010
[2019-03-26 21:33:18,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1510711e-24 0.0000000e+00], sum to 1.0000
[2019-03-26 21:33:18,918] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8104
[2019-03-26 21:33:18,924] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 88.66666666666667, 1.0, 2.0, 0.3719014736728388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 565609.8918124081, 565609.8918124087, 171771.207091038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7240200.0000, 
sim time next is 7240800.0000, 
raw observation next is [23.0, 89.33333333333334, 1.0, 2.0, 0.3710377579367017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 564517.6232246225, 564517.6232246218, 171683.0425482135], 
processed observation next is [1.0, 0.8260869565217391, 0.28909952606635075, 0.8933333333333334, 1.0, 1.0, 0.2422141661887972, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15681045089572845, 0.15681045089572826, 0.25624334708688584], 
reward next is 0.7438, 
noisyNet noise sample is [array([0.52714247], dtype=float32), 2.166105]. 
=============================================
[2019-03-26 21:33:20,989] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1256053: loss 0.1870
[2019-03-26 21:33:20,991] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1256054: learning rate 0.0010
[2019-03-26 21:33:21,334] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1256212: loss 0.1922
[2019-03-26 21:33:21,338] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1256213: learning rate 0.0010
[2019-03-26 21:33:23,000] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1256953: loss -169.3615
[2019-03-26 21:33:23,003] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1256955: learning rate 0.0010
[2019-03-26 21:33:23,748] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1257295: loss 0.3546
[2019-03-26 21:33:23,755] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1257296: learning rate 0.0010
[2019-03-26 21:33:24,525] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1257644: loss 0.6274
[2019-03-26 21:33:24,530] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1257648: learning rate 0.0010
[2019-03-26 21:33:24,574] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1257667: loss -68.5080
[2019-03-26 21:33:24,577] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1257667: learning rate 0.0010
[2019-03-26 21:33:25,487] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1258076: loss 0.3961
[2019-03-26 21:33:25,489] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1258076: learning rate 0.0010
[2019-03-26 21:33:25,712] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1258174: loss 0.2035
[2019-03-26 21:33:25,716] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1258176: learning rate 0.0010
[2019-03-26 21:33:25,930] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1258276: loss 0.0983
[2019-03-26 21:33:25,932] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1258276: learning rate 0.0010
[2019-03-26 21:33:26,175] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1258383: loss 0.0676
[2019-03-26 21:33:26,177] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1258383: learning rate 0.0010
[2019-03-26 21:33:26,419] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1258494: loss 0.1169
[2019-03-26 21:33:26,420] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1258494: learning rate 0.0010
[2019-03-26 21:33:27,239] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1258862: loss 0.2328
[2019-03-26 21:33:27,243] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1258863: learning rate 0.0010
[2019-03-26 21:33:28,185] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1259289: loss 0.3404
[2019-03-26 21:33:28,188] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1259290: learning rate 0.0010
[2019-03-26 21:33:29,941] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1260068: loss -256.0401
[2019-03-26 21:33:29,944] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1260068: learning rate 0.0010
[2019-03-26 21:33:33,654] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1261735: loss -34.9715
[2019-03-26 21:33:33,656] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1261735: learning rate 0.0010
[2019-03-26 21:33:35,487] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1262562: loss -9.7425
[2019-03-26 21:33:35,487] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1262562: learning rate 0.0010
[2019-03-26 21:33:38,085] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2234421e-14 0.0000000e+00], sum to 1.0000
[2019-03-26 21:33:38,092] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9124
[2019-03-26 21:33:38,098] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 93.0, 1.0, 2.0, 0.4091832003651533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 602415.1954450014, 602415.1954450014, 174523.8407494047], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7524000.0000, 
sim time next is 7524600.0000, 
raw observation next is [23.46666666666667, 92.83333333333333, 1.0, 2.0, 0.407581719654442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 600886.2128957993, 600886.2128957993, 174406.3971178725], 
processed observation next is [0.0, 0.08695652173913043, 0.31121642969984215, 0.9283333333333332, 1.0, 1.0, 0.2862430357282434, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1669128369154998, 0.1669128369154998, 0.26030805539980967], 
reward next is 0.7397, 
noisyNet noise sample is [array([-0.8802371], dtype=float32), -0.39116466]. 
=============================================
[2019-03-26 21:33:38,799] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1264048: loss -23.1748
[2019-03-26 21:33:38,801] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1264048: learning rate 0.0010
[2019-03-26 21:33:39,017] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1264142: loss -215.4851
[2019-03-26 21:33:39,019] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1264142: learning rate 0.0010
[2019-03-26 21:33:41,417] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1265218: loss 0.8824
[2019-03-26 21:33:41,418] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1265219: learning rate 0.0010
[2019-03-26 21:33:42,111] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1265532: loss 0.1241
[2019-03-26 21:33:42,113] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1265532: learning rate 0.0010
[2019-03-26 21:33:42,279] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:33:42,280] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:33:42,350] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run7
[2019-03-26 21:33:42,852] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1265899: loss 0.1297
[2019-03-26 21:33:42,857] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1265901: learning rate 0.0010
[2019-03-26 21:33:43,053] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1266015: loss 0.1172
[2019-03-26 21:33:43,055] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1266015: learning rate 0.0010
[2019-03-26 21:33:43,227] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1266110: loss 0.0721
[2019-03-26 21:33:43,228] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1266110: learning rate 0.0010
[2019-03-26 21:33:43,344] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1266188: loss 0.3375
[2019-03-26 21:33:43,345] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1266188: learning rate 0.0010
[2019-03-26 21:33:43,491] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1266268: loss 0.0708
[2019-03-26 21:33:43,493] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1266268: learning rate 0.0010
[2019-03-26 21:33:43,576] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:33:43,577] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:33:43,646] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run7
[2019-03-26 21:33:44,101] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.3894896e-20 0.0000000e+00], sum to 1.0000
[2019-03-26 21:33:44,111] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0822
[2019-03-26 21:33:44,115] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.56666666666666, 74.66666666666666, 1.0, 2.0, 0.5007804407418393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 699763.2198669618, 699763.2198669618, 183719.2481085293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7756800.0000, 
sim time next is 7757400.0000, 
raw observation next is [28.38333333333333, 75.83333333333334, 1.0, 2.0, 0.5038040579441986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 703989.6573216347, 703989.6573216347, 184194.8833086832], 
processed observation next is [1.0, 0.782608695652174, 0.5442338072669825, 0.7583333333333334, 1.0, 1.0, 0.402173563788191, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19555268258934297, 0.19555268258934297, 0.2749177362816167], 
reward next is 0.7251, 
noisyNet noise sample is [array([-0.5252218], dtype=float32), 1.0832827]. 
=============================================
[2019-03-26 21:33:44,232] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1266650: loss 0.1350
[2019-03-26 21:33:44,239] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1266653: learning rate 0.0010
[2019-03-26 21:33:44,980] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1267069: loss 0.0569
[2019-03-26 21:33:44,983] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1267069: learning rate 0.0010
[2019-03-26 21:33:47,897] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:33:47,898] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:33:47,962] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run7
[2019-03-26 21:33:50,989] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:33:50,989] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:33:51,066] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run7
[2019-03-26 21:33:52,372] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.2728296e-21 9.9974805e-01 1.3991868e-23 2.5196152e-04 1.0075956e-25], sum to 1.0000
[2019-03-26 21:33:52,382] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6399
[2019-03-26 21:33:52,390] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2410853.795488899 W.
[2019-03-26 21:33:52,397] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 66.5, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.079282848992903, 6.9112, 168.9117866320078, 2410853.795488899, 2291610.863321424, 476105.9314883973], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7831800.0000, 
sim time next is 7832400.0000, 
raw observation next is [31.0, 65.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.392840077976341, 6.9112, 168.910046032034, 2637409.072369143, 2295722.911853347, 475624.7857063041], 
processed observation next is [1.0, 0.6521739130434783, 0.6682464454976303, 0.6533333333333334, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.04816400779763406, 0.0, 0.8294256533709505, 0.7326136312136508, 0.637700808848152, 0.7098877398601553], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.95743924], dtype=float32), 0.09104825]. 
=============================================
[2019-03-26 21:33:52,558] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:33:52,558] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:33:52,628] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run7
[2019-03-26 21:33:55,205] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:33:55,208] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:33:55,285] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run7
[2019-03-26 21:33:55,441] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:33:55,441] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:33:55,509] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run7
[2019-03-26 21:33:57,193] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:33:57,194] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:33:57,281] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run7
[2019-03-26 21:33:57,740] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:33:57,741] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:33:57,788] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run7
[2019-03-26 21:33:58,295] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 1.675594e-13 0.000000e+00], sum to 1.0000
[2019-03-26 21:33:58,301] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7584
[2019-03-26 21:33:58,306] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 62.16666666666667, 1.0, 2.0, 0.9338398950633804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1391413.295148267, 1391413.295148266, 292020.8634988565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 49800.0000, 
sim time next is 50400.0000, 
raw observation next is [28.0, 62.0, 1.0, 2.0, 0.9934345129241986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1477009.605252179, 1477009.60525218, 310327.2248383393], 
processed observation next is [1.0, 0.6086956521739131, 0.5260663507109005, 0.62, 1.0, 1.0, 0.9920897746074682, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.4102804459033831, 0.41028044590338336, 0.46317496244528256], 
reward next is 0.5368, 
noisyNet noise sample is [array([1.1697142], dtype=float32), 0.43051487]. 
=============================================
[2019-03-26 21:33:58,572] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:33:58,574] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:33:58,627] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run7
[2019-03-26 21:33:58,768] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:33:58,770] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:33:58,824] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run7
[2019-03-26 21:33:58,913] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:33:58,914] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:33:58,925] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4179528e-12 0.0000000e+00], sum to 1.0000
[2019-03-26 21:33:58,929] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3310
[2019-03-26 21:33:58,934] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 86.0, 1.0, 2.0, 0.3213215530535128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 512655.718011903, 512655.718011903, 168040.2722682601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 21600.0000, 
sim time next is 22200.0000, 
raw observation next is [21.66666666666667, 85.66666666666667, 1.0, 2.0, 0.3690137845416782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 588413.6889443405, 588413.6889443405, 174182.9217423461], 
processed observation next is [1.0, 0.2608695652173913, 0.22590837282780438, 0.8566666666666667, 1.0, 1.0, 0.23977564402611834, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16344824692898346, 0.16344824692898346, 0.25997451006320316], 
reward next is 0.7400, 
noisyNet noise sample is [array([-0.09853556], dtype=float32), 0.7793431]. 
=============================================
[2019-03-26 21:33:58,970] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run7
[2019-03-26 21:33:59,099] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:33:59,100] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:33:59,144] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run7
[2019-03-26 21:33:59,173] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.000000e+00 9.999995e-01 0.000000e+00 4.982102e-07 0.000000e+00], sum to 1.0000
[2019-03-26 21:33:59,178] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0358
[2019-03-26 21:33:59,182] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 85.0, 1.0, 2.0, 0.2931794131352752, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 473644.8918155906, 473644.89181559, 165207.2081659699], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 10800.0000, 
sim time next is 11400.0000, 
raw observation next is [21.03333333333333, 85.00000000000001, 1.0, 2.0, 0.3447860764646196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 557446.5383482359, 557446.5383482359, 171504.5631084876], 
processed observation next is [1.0, 0.13043478260869565, 0.19589257503949445, 0.8500000000000001, 1.0, 1.0, 0.21058563429472243, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15484626065228774, 0.15484626065228774, 0.25597695986341434], 
reward next is 0.7440, 
noisyNet noise sample is [array([0.23457403], dtype=float32), 0.072611295]. 
=============================================
[2019-03-26 21:33:59,245] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:33:59,245] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:33:59,287] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run7
[2019-03-26 21:33:59,664] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:33:59,665] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:33:59,686] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run7
[2019-03-26 21:34:00,139] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:34:00,139] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:34:00,197] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run7
[2019-03-26 21:34:00,643] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 21:34:00,644] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:34:00,645] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:34:00,646] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:34:00,648] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:34:00,645] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:34:00,648] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:34:00,649] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:34:00,649] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:34:00,648] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:34:00,649] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:34:00,668] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run52
[2019-03-26 21:34:00,684] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run52
[2019-03-26 21:34:00,700] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run52
[2019-03-26 21:34:00,700] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run52
[2019-03-26 21:34:00,729] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run52
[2019-03-26 21:35:54,397] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8001.2777 3008137870.5046 1762.0000
[2019-03-26 21:35:54,792] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.0313 3164530702.2237 1767.0000
[2019-03-26 21:35:54,879] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8259.5342 2927783479.9905 1326.0000
[2019-03-26 21:35:54,896] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.7694 2843141528.0607 1123.0000
[2019-03-26 21:35:55,064] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8662.4458 2779631480.9208 920.0000
[2019-03-26 21:35:56,080] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1275000, evaluation results [1275000.0, 7882.031316481575, 3164530702.223711, 1767.0, 8259.534153343897, 2927783479.9905014, 1326.0, 8662.445823130061, 2779631480.920754, 920.0, 8001.277655921997, 3008137870.504635, 1762.0, 8496.769448760873, 2843141528.0607495, 1123.0]
[2019-03-26 21:36:10,934] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0445169e-11 0.0000000e+00], sum to 1.0000
[2019-03-26 21:36:10,943] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0250
[2019-03-26 21:36:10,952] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.3, 68.5, 1.0, 2.0, 0.4605003215267129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 755739.554287621, 755739.5542876205, 188959.1340844114], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 469800.0000, 
sim time next is 470400.0000, 
raw observation next is [22.43333333333333, 67.66666666666667, 1.0, 2.0, 0.4671205029577186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 766549.5944158662, 766549.5944158655, 190072.9993363132], 
processed observation next is [1.0, 0.43478260869565216, 0.2622432859399683, 0.6766666666666667, 1.0, 1.0, 0.35797650958761285, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21293044289329616, 0.21293044289329596, 0.2836910437855421], 
reward next is 0.7163, 
noisyNet noise sample is [array([-0.05449015], dtype=float32), 1.178726]. 
=============================================
[2019-03-26 21:36:17,164] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.6272523e-15 0.0000000e+00], sum to 1.0000
[2019-03-26 21:36:17,174] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3042
[2019-03-26 21:36:17,178] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.05, 89.5, 1.0, 2.0, 0.2628025625747001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 427839.1772719586, 427839.1772719593, 162122.1209462835], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 364200.0000, 
sim time next is 364800.0000, 
raw observation next is [20.1, 89.0, 1.0, 2.0, 0.2577437023177542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 419668.4362613151, 419668.4362613158, 161610.9908548877], 
processed observation next is [1.0, 0.21739130434782608, 0.15165876777251197, 0.89, 1.0, 1.0, 0.10571530399729417, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11657456562814307, 0.11657456562814326, 0.24121043411177268], 
reward next is 0.7588, 
noisyNet noise sample is [array([0.37283462], dtype=float32), -0.45102882]. 
=============================================
[2019-03-26 21:36:18,681] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4150536e-16 0.0000000e+00], sum to 1.0000
[2019-03-26 21:36:18,691] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6349
[2019-03-26 21:36:18,707] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 66.33333333333334, 1.0, 2.0, 0.2401018453830852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 395993.0779871152, 395993.0779871159, 159918.0543452117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 499200.0000, 
sim time next is 499800.0000, 
raw observation next is [21.95, 67.66666666666666, 1.0, 2.0, 0.2407609549877426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 397262.7553255308, 397262.7553255308, 159973.0869926063], 
processed observation next is [1.0, 0.782608695652174, 0.2393364928909953, 0.6766666666666665, 1.0, 1.0, 0.08525416263583446, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11035076536820299, 0.11035076536820299, 0.23876580148150192], 
reward next is 0.7612, 
noisyNet noise sample is [array([1.471173], dtype=float32), -1.0542854]. 
=============================================
[2019-03-26 21:36:21,697] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 2.526346e-13 0.000000e+00], sum to 1.0000
[2019-03-26 21:36:21,706] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0903
[2019-03-26 21:36:21,710] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 75.66666666666666, 1.0, 2.0, 0.2543079736086176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 418575.0686870357, 418575.0686870363, 161327.9664394889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 718800.0000, 
sim time next is 719400.0000, 
raw observation next is [21.28333333333333, 74.83333333333334, 1.0, 2.0, 0.2638325361547078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 433725.1113663855, 433725.1113663848, 162303.5312655763], 
processed observation next is [1.0, 0.30434782608695654, 0.20774091627172192, 0.7483333333333334, 1.0, 1.0, 0.11305124837916602, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12047919760177374, 0.12047919760177354, 0.24224407651578553], 
reward next is 0.7578, 
noisyNet noise sample is [array([-0.22724642], dtype=float32), 0.05751031]. 
=============================================
[2019-03-26 21:36:25,090] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 2.574671e-13 0.000000e+00], sum to 1.0000
[2019-03-26 21:36:25,102] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3448
[2019-03-26 21:36:25,106] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.75, 53.5, 1.0, 2.0, 0.5747622264378489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 944144.329170262, 944144.329170262, 210297.642093279], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 491400.0000, 
sim time next is 492000.0000, 
raw observation next is [24.7, 53.66666666666667, 1.0, 2.0, 0.5577225204564762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 916337.0853982749, 916337.0853982749, 206833.5854249532], 
processed observation next is [1.0, 0.6956521739130435, 0.3696682464454976, 0.5366666666666667, 1.0, 1.0, 0.46713556681503154, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2545380792772986, 0.2545380792772986, 0.3087068439178406], 
reward next is 0.6913, 
noisyNet noise sample is [array([0.66004753], dtype=float32), 1.4387766]. 
=============================================
[2019-03-26 21:36:25,126] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.15876 ]
 [72.034874]
 [71.90964 ]
 [72.01181 ]
 [71.73149 ]], R is [[72.42744446]
 [72.38929749]
 [72.35293579]
 [72.3166275 ]
 [72.28670502]].
[2019-03-26 21:36:25,958] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.2094332e-14 0.0000000e+00], sum to 1.0000
[2019-03-26 21:36:25,967] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5823
[2019-03-26 21:36:25,975] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 55.33333333333333, 1.0, 2.0, 0.3501702907954479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 573934.1410301038, 573934.1410301044, 172526.7757412604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 564000.0000, 
sim time next is 564600.0000, 
raw observation next is [24.5, 55.66666666666667, 1.0, 2.0, 0.3498141191536414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 573622.1155521977, 573622.1155521977, 172483.1554737045], 
processed observation next is [1.0, 0.5217391304347826, 0.3601895734597157, 0.5566666666666668, 1.0, 1.0, 0.21664351705258, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15933947654227712, 0.15933947654227712, 0.2574375454831411], 
reward next is 0.7426, 
noisyNet noise sample is [array([0.07394158], dtype=float32), -0.6209243]. 
=============================================
[2019-03-26 21:36:34,955] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 8.936214e-17 0.000000e+00], sum to 1.0000
[2019-03-26 21:36:34,962] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1533
[2019-03-26 21:36:34,965] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.26666666666667, 54.5, 1.0, 2.0, 0.4705730174011961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 766204.2374903259, 766204.2374903265, 190516.0469403185], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 735000.0000, 
sim time next is 735600.0000, 
raw observation next is [25.33333333333334, 54.0, 1.0, 2.0, 0.3495018895137921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 569324.169269985, 569324.1692699844, 172337.6181527059], 
processed observation next is [1.0, 0.5217391304347826, 0.3996840442338076, 0.54, 1.0, 1.0, 0.2162673367636049, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15814560257499585, 0.15814560257499566, 0.25722032560105357], 
reward next is 0.7428, 
noisyNet noise sample is [array([-0.37623528], dtype=float32), 1.7547215]. 
=============================================
[2019-03-26 21:36:38,524] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.3446097e-16 0.0000000e+00], sum to 1.0000
[2019-03-26 21:36:38,531] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2198
[2019-03-26 21:36:38,537] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.23333333333333, 70.0, 1.0, 2.0, 0.4933154680641298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 808044.4208022965, 808044.4208022971, 194610.3667792293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 722400.0000, 
sim time next is 723000.0000, 
raw observation next is [22.41666666666667, 69.0, 1.0, 2.0, 0.5024554194723655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 822644.3336216464, 822644.3336216458, 196248.3106412334], 
processed observation next is [1.0, 0.34782608695652173, 0.26145339652448685, 0.69, 1.0, 1.0, 0.40054869815947647, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22851231489490179, 0.22851231489490162, 0.29290792633019913], 
reward next is 0.7071, 
noisyNet noise sample is [array([-1.3279731], dtype=float32), -0.12715039]. 
=============================================
[2019-03-26 21:36:38,555] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[69.30356 ]
 [69.664795]
 [70.64778 ]
 [72.26096 ]
 [72.4062  ]], R is [[69.06280518]
 [69.08171082]
 [69.10282135]
 [69.13974762]
 [69.20504761]].
[2019-03-26 21:36:39,285] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.9346485e-18 0.0000000e+00], sum to 1.0000
[2019-03-26 21:36:39,292] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1432
[2019-03-26 21:36:39,296] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.15, 88.5, 1.0, 2.0, 0.2980085863276811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 476556.6058885139, 476556.6058885139, 165402.6710470118], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1121400.0000, 
sim time next is 1122000.0000, 
raw observation next is [21.1, 88.66666666666666, 1.0, 2.0, 0.2974904764655094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 476011.9620746989, 476011.9620746995, 165366.9566344492], 
processed observation next is [1.0, 1.0, 0.1990521327014219, 0.8866666666666666, 1.0, 1.0, 0.15360298369338482, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13222554502074968, 0.13222554502074987, 0.24681635318574505], 
reward next is 0.7532, 
noisyNet noise sample is [array([0.36418533], dtype=float32), 0.91731477]. 
=============================================
[2019-03-26 21:36:39,309] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[76.512955]
 [76.52378 ]
 [76.54843 ]
 [76.58448 ]
 [76.49646 ]], R is [[76.49562073]
 [76.48379517]
 [76.47202301]
 [76.46026611]
 [76.44850922]].
[2019-03-26 21:36:39,369] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.1223657e-18 0.0000000e+00], sum to 1.0000
[2019-03-26 21:36:39,381] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9410
[2019-03-26 21:36:39,385] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 85.66666666666667, 1.0, 2.0, 0.3034191572796478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 482038.306052571, 482038.306052571, 165749.320943273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 856200.0000, 
sim time next is 856800.0000, 
raw observation next is [21.8, 86.0, 1.0, 2.0, 0.3047671035984224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 484073.4764388891, 484073.4764388897, 165894.3172226585], 
processed observation next is [0.0, 0.9565217391304348, 0.23222748815165886, 0.86, 1.0, 1.0, 0.16237000433544868, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1344648545663581, 0.13446485456635823, 0.24760345854128132], 
reward next is 0.7524, 
noisyNet noise sample is [array([0.01164912], dtype=float32), 0.34914762]. 
=============================================
[2019-03-26 21:36:46,477] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.9128682e-18 0.0000000e+00], sum to 1.0000
[2019-03-26 21:36:46,488] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9169
[2019-03-26 21:36:46,494] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 71.33333333333333, 1.0, 2.0, 0.3014877156297535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 478693.274271819, 478693.2742718183, 165503.9728785646], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 909600.0000, 
sim time next is 910200.0000, 
raw observation next is [24.05, 70.66666666666667, 1.0, 2.0, 0.3027321731922025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 480197.6300833625, 480197.6300833632, 165602.6905125778], 
processed observation next is [0.0, 0.5217391304347826, 0.3388625592417062, 0.7066666666666667, 1.0, 1.0, 0.15991828095446087, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1333882305787118, 0.133388230578712, 0.24716819479489224], 
reward next is 0.7528, 
noisyNet noise sample is [array([0.04485014], dtype=float32), -1.0893244]. 
=============================================
[2019-03-26 21:36:51,853] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 21:36:51,854] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:36:51,855] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:36:51,855] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:36:51,855] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:36:51,856] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:36:51,857] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:36:51,858] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:36:51,858] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:36:51,859] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:36:51,860] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:36:51,883] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run53
[2019-03-26 21:36:51,907] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run53
[2019-03-26 21:36:51,907] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run53
[2019-03-26 21:36:51,908] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run53
[2019-03-26 21:36:51,908] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run53
[2019-03-26 21:37:21,372] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.6396176]
[2019-03-26 21:37:21,373] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.497127425, 95.29532252333334, 1.0, 2.0, 0.5654850278136649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 790211.5044638643, 790211.5044638643, 194493.5522085142]
[2019-03-26 21:37:21,375] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:37:21,377] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 7.964605e-17 0.000000e+00], sampled 0.2247153400163029
[2019-03-26 21:38:09,661] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.6396176]
[2019-03-26 21:38:09,663] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.16666666666667, 78.33333333333334, 1.0, 2.0, 0.562311796246484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 785775.5751789607, 785775.5751789613, 193934.2017467929]
[2019-03-26 21:38:09,664] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:38:09,666] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5550576e-16 0.0000000e+00], sampled 0.7669904825196148
[2019-03-26 21:38:12,805] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.6396176]
[2019-03-26 21:38:12,806] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.80962164, 88.54499237499999, 1.0, 2.0, 0.5447811972893444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 761269.5042510491, 761269.5042510486, 190908.473977865]
[2019-03-26 21:38:12,808] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:38:12,810] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.8006314e-17 0.0000000e+00], sampled 0.6566714261169369
[2019-03-26 21:38:17,592] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.6396176]
[2019-03-26 21:38:17,594] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.99455262666667, 79.23724486333333, 1.0, 2.0, 0.5543060822525215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 774584.2961426751, 774584.2961426751, 192542.0570547158]
[2019-03-26 21:38:17,598] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:38:17,601] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.3315854e-18 0.0000000e+00], sampled 0.038173359840051546
[2019-03-26 21:38:26,639] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.6396176]
[2019-03-26 21:38:26,640] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.17526343666667, 77.58337177, 1.0, 2.0, 0.4801941772010698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 672823.6151070055, 672823.6151070055, 180788.1314883225]
[2019-03-26 21:38:26,643] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:38:26,646] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 2.979768e-17 0.000000e+00], sampled 0.14294066989801324
[2019-03-26 21:38:45,626] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8259.8874 2927913832.0983 1326.0000
[2019-03-26 21:38:46,080] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.5625 2779890177.5499 921.0000
[2019-03-26 21:38:46,238] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.3168 3008746041.1940 1766.0000
[2019-03-26 21:38:46,380] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8492.0035 2843576590.7546 1130.0000
[2019-03-26 21:38:46,522] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7873.5655 3164861001.5350 1775.0000
[2019-03-26 21:38:47,539] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1300000, evaluation results [1300000.0, 7873.565463704328, 3164861001.534994, 1775.0, 8259.88738887422, 2927913832.0983257, 1326.0, 8658.562467665353, 2779890177.5498824, 921.0, 7997.316847757386, 3008746041.194046, 1766.0, 8492.00353360562, 2843576590.754619, 1130.0]
[2019-03-26 21:38:49,514] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.7540682e-18 0.0000000e+00], sum to 1.0000
[2019-03-26 21:38:49,526] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2051
[2019-03-26 21:38:49,530] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 93.0, 1.0, 2.0, 0.3350384879186246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 519354.9549688383, 519354.9549688377, 168252.030569168], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 978000.0000, 
sim time next is 978600.0000, 
raw observation next is [21.9, 93.0, 1.0, 2.0, 0.3329765268366439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 516161.5966468404, 516161.5966468398, 168000.7902355249], 
processed observation next is [1.0, 0.30434782608695654, 0.23696682464454974, 0.93, 1.0, 1.0, 0.19635726124896857, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.143378221290789, 0.14337822129078884, 0.25074744811272376], 
reward next is 0.7493, 
noisyNet noise sample is [array([2.6555288], dtype=float32), -0.7712288]. 
=============================================
[2019-03-26 21:39:02,522] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 9.9999309e-01 0.0000000e+00 6.9381567e-06 0.0000000e+00], sum to 1.0000
[2019-03-26 21:39:02,532] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8655
[2019-03-26 21:39:02,538] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.86666666666667, 66.16666666666667, 1.0, 2.0, 0.3445898396661412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 532736.5550255472, 532736.5550255479, 169280.1545796951], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1191000.0000, 
sim time next is 1191600.0000, 
raw observation next is [25.7, 67.0, 1.0, 2.0, 0.3443976029830777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 532773.1660277712, 532773.1660277712, 169292.8305185069], 
processed observation next is [1.0, 0.8260869565217391, 0.4170616113744076, 0.67, 1.0, 1.0, 0.2101175939555153, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14799254611882534, 0.14799254611882534, 0.2526758664455327], 
reward next is 0.7473, 
noisyNet noise sample is [array([0.8960269], dtype=float32), -0.84168965]. 
=============================================
[2019-03-26 21:39:07,862] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.9579712e-16 0.0000000e+00], sum to 1.0000
[2019-03-26 21:39:07,873] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8812
[2019-03-26 21:39:07,878] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 91.0, 1.0, 2.0, 0.8618038511760767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1204523.687623024, 1204523.687623024, 259643.2187026259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1677600.0000, 
sim time next is 1678200.0000, 
raw observation next is [25.31666666666667, 90.50000000000001, 1.0, 2.0, 0.9560773333030395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1336370.52086463, 1336370.52086463, 285825.2544364419], 
processed observation next is [1.0, 0.43478260869565216, 0.39889415481832563, 0.9050000000000001, 1.0, 1.0, 0.9470811244614933, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3712140335735083, 0.3712140335735083, 0.42660485736782366], 
reward next is 0.5734, 
noisyNet noise sample is [array([-0.305452], dtype=float32), -0.41780967]. 
=============================================
[2019-03-26 21:39:08,010] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 3.821445e-13 0.000000e+00], sum to 1.0000
[2019-03-26 21:39:08,021] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6059
[2019-03-26 21:39:08,025] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 94.0, 1.0, 2.0, 0.4594574191080348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 651614.1455646659, 651614.1455646659, 178726.2787576435], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1297800.0000, 
sim time next is 1298400.0000, 
raw observation next is [24.3, 94.0, 1.0, 2.0, 0.4596510825608306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 651891.214867351, 651891.2148673504, 178755.0599349044], 
processed observation next is [1.0, 0.0, 0.3507109004739337, 0.94, 1.0, 1.0, 0.3489772079046152, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1810808930187086, 0.18108089301870844, 0.26679859691776775], 
reward next is 0.7332, 
noisyNet noise sample is [array([0.6850911], dtype=float32), -0.23709205]. 
=============================================
[2019-03-26 21:39:08,716] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 1.458851e-19 0.000000e+00], sum to 1.0000
[2019-03-26 21:39:08,725] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0039
[2019-03-26 21:39:08,729] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 94.0, 1.0, 2.0, 0.45971656316523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 651988.9023952944, 651988.902395295, 178765.3062099393], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1299600.0000, 
sim time next is 1300200.0000, 
raw observation next is [24.28333333333333, 94.00000000000001, 1.0, 2.0, 0.4590338509617207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 651345.2800327229, 651345.2800327229, 178706.4688538504], 
processed observation next is [1.0, 0.043478260869565216, 0.34992101105845175, 0.9400000000000002, 1.0, 1.0, 0.34823355537556716, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18092924445353412, 0.18092924445353412, 0.26672607291619466], 
reward next is 0.7333, 
noisyNet noise sample is [array([-1.3923157], dtype=float32), 1.1576291]. 
=============================================
[2019-03-26 21:39:10,473] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.9079314e-19 0.0000000e+00], sum to 1.0000
[2019-03-26 21:39:10,481] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9879
[2019-03-26 21:39:10,484] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 93.0, 1.0, 2.0, 0.3300264527944478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 515928.093286766, 515928.0932867654, 168107.1509076998], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1407600.0000, 
sim time next is 1408200.0000, 
raw observation next is [21.68333333333334, 92.5, 1.0, 2.0, 0.3308154636927673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 516777.1966169412, 516777.1966169412, 168163.2932813919], 
processed observation next is [0.0, 0.30434782608695654, 0.22669826224328635, 0.925, 1.0, 1.0, 0.19375357071417748, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14354922128248365, 0.14354922128248365, 0.2509899899722267], 
reward next is 0.7490, 
noisyNet noise sample is [array([-1.4068879], dtype=float32), 0.042039726]. 
=============================================
[2019-03-26 21:39:12,464] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 6.240673e-17 0.000000e+00], sum to 1.0000
[2019-03-26 21:39:12,472] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5460
[2019-03-26 21:39:12,479] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 91.0, 1.0, 2.0, 0.7091606161431733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1130087.578516714, 1130087.578516714, 239288.0164668727], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1353600.0000, 
sim time next is 1354200.0000, 
raw observation next is [20.96666666666667, 91.16666666666667, 1.0, 2.0, 0.6389362483018863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1018434.12291141, 1018434.122911409, 222670.5488732789], 
processed observation next is [1.0, 0.6956521739130435, 0.1927330173775673, 0.9116666666666667, 1.0, 1.0, 0.5649834316890197, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2828983674753917, 0.2828983674753914, 0.3323441027959386], 
reward next is 0.6677, 
noisyNet noise sample is [array([-0.12153134], dtype=float32), -0.4338689]. 
=============================================
[2019-03-26 21:39:18,157] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4104714e-18 0.0000000e+00], sum to 1.0000
[2019-03-26 21:39:18,169] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7458
[2019-03-26 21:39:18,175] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.75, 88.0, 1.0, 2.0, 0.3937778143103614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 587622.5538527947, 587622.5538527947, 173401.3058275043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1452600.0000, 
sim time next is 1453200.0000, 
raw observation next is [23.5, 89.33333333333333, 1.0, 2.0, 0.3907755687023597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 584580.0612230237, 584580.0612230243, 173168.24205628], 
processed observation next is [0.0, 0.8260869565217391, 0.31279620853080575, 0.8933333333333333, 1.0, 1.0, 0.26599466108718034, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1623833503397288, 0.16238335033972898, 0.25846006277056716], 
reward next is 0.7415, 
noisyNet noise sample is [array([0.3536689], dtype=float32), 0.9158268]. 
=============================================
[2019-03-26 21:39:18,980] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.0754201e-19 0.0000000e+00], sum to 1.0000
[2019-03-26 21:39:18,992] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5007
[2019-03-26 21:39:18,998] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 85.0, 1.0, 2.0, 0.8248013986985608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1246279.625636021, 1246279.625636021, 262823.3009326591], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1596600.0000, 
sim time next is 1597200.0000, 
raw observation next is [23.83333333333333, 85.0, 1.0, 2.0, 0.7987309430605135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1205591.685212153, 1205591.685212153, 255609.3047495016], 
processed observation next is [1.0, 0.4782608695652174, 0.32859399684044216, 0.85, 1.0, 1.0, 0.7575071603138717, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.33488657922559806, 0.33488657922559806, 0.38150642499925613], 
reward next is 0.6185, 
noisyNet noise sample is [array([-0.9312642], dtype=float32), -0.6071147]. 
=============================================
[2019-03-26 21:39:27,393] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.5988613e-21 0.0000000e+00], sum to 1.0000
[2019-03-26 21:39:27,401] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7532
[2019-03-26 21:39:27,407] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 95.5, 1.0, 2.0, 0.4116340556942512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 607754.4664720419, 607754.4664720419, 175073.8917299772], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1621800.0000, 
sim time next is 1622400.0000, 
raw observation next is [23.1, 95.33333333333333, 1.0, 2.0, 0.4118243485850188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 608498.4812234347, 608498.4812234347, 175156.9013538017], 
processed observation next is [1.0, 0.782608695652174, 0.2938388625592418, 0.9533333333333333, 1.0, 1.0, 0.29135463684942026, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16902735589539852, 0.16902735589539852, 0.2614282109758234], 
reward next is 0.7386, 
noisyNet noise sample is [array([-1.4083227], dtype=float32), 0.7046456]. 
=============================================
[2019-03-26 21:39:29,824] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6045448e-21 0.0000000e+00], sum to 1.0000
[2019-03-26 21:39:29,837] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5590
[2019-03-26 21:39:29,845] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.65, 98.0, 1.0, 2.0, 0.4341939420624599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 619786.8178648998, 619786.817864899, 175622.3809237987], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1668600.0000, 
sim time next is 1669200.0000, 
raw observation next is [23.66666666666667, 98.0, 1.0, 2.0, 0.4493481692295083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 640961.0280242809, 640961.0280242809, 177726.5250660207], 
processed observation next is [1.0, 0.30434782608695654, 0.3206951026856243, 0.98, 1.0, 1.0, 0.33656405931266065, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1780447300067447, 0.1780447300067447, 0.26526347024779207], 
reward next is 0.7347, 
noisyNet noise sample is [array([-2.2879906], dtype=float32), -0.7565402]. 
=============================================
[2019-03-26 21:39:32,267] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.4089815e-22 0.0000000e+00], sum to 1.0000
[2019-03-26 21:39:32,276] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3597
[2019-03-26 21:39:32,280] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.53333333333333, 81.33333333333334, 1.0, 2.0, 0.5090368748779744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 711304.1724018042, 711304.1724018042, 185024.4410137997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1709400.0000, 
sim time next is 1710000.0000, 
raw observation next is [27.4, 82.0, 1.0, 2.0, 0.5063752165239351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 707583.6575528891, 707583.6575528898, 184601.4270496964], 
processed observation next is [1.0, 0.8260869565217391, 0.4976303317535545, 0.82, 1.0, 1.0, 0.4052713452095604, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19655101598691363, 0.19655101598691382, 0.27552451798462146], 
reward next is 0.7245, 
noisyNet noise sample is [array([1.7569869], dtype=float32), 0.42720354]. 
=============================================
[2019-03-26 21:39:32,290] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[67.63249 ]
 [67.70497 ]
 [67.228294]
 [67.20331 ]
 [67.18379 ]], R is [[67.38738251]
 [67.43735504]
 [67.48653412]
 [67.53553772]
 [67.58470154]].
[2019-03-26 21:39:37,154] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 9.638729e-22 0.000000e+00], sum to 1.0000
[2019-03-26 21:39:37,166] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0742
[2019-03-26 21:39:37,175] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.81666666666667, 84.83333333333334, 1.0, 2.0, 0.5917256669463309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 919469.1522564429, 919469.1522564436, 210267.1149630368], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1775400.0000, 
sim time next is 1776000.0000, 
raw observation next is [22.73333333333333, 84.66666666666667, 1.0, 2.0, 0.681857240381397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1062414.05920471, 1062414.059204711, 230387.9684804505], 
processed observation next is [1.0, 0.5652173913043478, 0.27646129541864134, 0.8466666666666667, 1.0, 1.0, 0.6166954703390325, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2951150164457528, 0.2951150164457531, 0.34386263952306045], 
reward next is 0.6561, 
noisyNet noise sample is [array([-0.92642665], dtype=float32), -0.42316097]. 
=============================================
[2019-03-26 21:39:37,192] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[73.794266]
 [74.09903 ]
 [74.109665]
 [73.75336 ]
 [72.77975 ]], R is [[72.71838379]
 [72.67736816]
 [72.64577484]
 [72.61911774]
 [72.58409119]].
[2019-03-26 21:39:43,070] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 21:39:43,072] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:39:43,072] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:39:43,073] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:39:43,075] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:39:43,075] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:39:43,076] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:39:43,077] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:39:43,079] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:39:43,079] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:39:43,078] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:39:43,118] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run54
[2019-03-26 21:39:43,138] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run54
[2019-03-26 21:39:43,158] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run54
[2019-03-26 21:39:43,183] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run54
[2019-03-26 21:39:43,201] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run54
[2019-03-26 21:39:49,534] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.65107745]
[2019-03-26 21:39:49,535] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [20.7, 72.5, 1.0, 2.0, 0.2802647146316176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 464807.7473827199, 464807.7473827193, 163857.4224244074]
[2019-03-26 21:39:49,539] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:39:49,542] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.07786166e-20
 0.00000000e+00], sampled 0.9419174965300672
[2019-03-26 21:39:51,296] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.65107745]
[2019-03-26 21:39:51,297] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.99102785, 65.48239886, 1.0, 2.0, 0.390969628344003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 631727.0848467097, 631727.0848467092, 177801.9036843827]
[2019-03-26 21:39:51,299] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:39:51,302] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 9.893807e-21 0.000000e+00], sampled 0.7981346302135133
[2019-03-26 21:40:12,339] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.65107745]
[2019-03-26 21:40:12,341] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.1, 91.0, 1.0, 2.0, 0.4368810511432824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 635064.0412796895, 635064.0412796895, 177445.3820241003]
[2019-03-26 21:40:12,343] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:40:12,345] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1541733e-20 0.0000000e+00], sampled 0.8206902440548313
[2019-03-26 21:40:26,842] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.65107745]
[2019-03-26 21:40:26,843] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.01666666666667, 88.0, 1.0, 2.0, 0.5069349408214806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 708366.0493565529, 708366.0493565535, 184689.0562831664]
[2019-03-26 21:40:26,845] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:40:26,847] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.1656028e-20 0.0000000e+00], sampled 0.5824980753398313
[2019-03-26 21:40:36,704] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.65107745]
[2019-03-26 21:40:36,704] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.12637537, 72.48831587000001, 1.0, 2.0, 0.6551297707415286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 915535.4914356638, 915535.4914356638, 211454.9515227001]
[2019-03-26 21:40:36,704] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:40:36,707] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2735543e-19 0.0000000e+00], sampled 0.8322291175011618
[2019-03-26 21:41:14,623] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.65107745]
[2019-03-26 21:41:14,625] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.58373387, 83.13345644, 1.0, 2.0, 0.9048573363983716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1264734.407118836, 1264734.407118836, 271279.2633398755]
[2019-03-26 21:41:14,626] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:41:14,628] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.5890423e-19 0.0000000e+00], sampled 0.09016084357168608
[2019-03-26 21:41:15,464] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.65107745]
[2019-03-26 21:41:15,465] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.83333333333334, 68.66666666666667, 1.0, 2.0, 0.8800193565818685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1229997.833088041, 1229997.833088041, 264504.5417203527]
[2019-03-26 21:41:15,465] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:41:15,469] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7700784e-19 0.0000000e+00], sampled 0.025484212119522787
[2019-03-26 21:41:17,090] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.65107745]
[2019-03-26 21:41:17,092] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.85, 81.5, 1.0, 2.0, 0.7043330272409057, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.98196269140603, 6.9112, 168.9119525258916, 1881192.256147194, 1830991.065787399, 386456.0622412128]
[2019-03-26 21:41:17,095] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:41:17,100] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.6612523e-16 0.0000000e+00], sampled 0.03939080558574293
[2019-03-26 21:41:17,101] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1881192.256147194 W.
[2019-03-26 21:41:32,010] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.65107745]
[2019-03-26 21:41:32,010] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.6, 73.5, 1.0, 2.0, 0.5472840287919637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 764768.1844707952, 764768.1844707945, 191335.7299789043]
[2019-03-26 21:41:32,012] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:41:32,015] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 4.768426e-21 0.000000e+00], sampled 0.8259417949181447
[2019-03-26 21:41:32,221] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.65107745]
[2019-03-26 21:41:32,222] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.5, 80.5, 1.0, 2.0, 0.5497549925830485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 768222.3284771323, 768222.328477133, 191758.3811321502]
[2019-03-26 21:41:32,223] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:41:32,226] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.8100224e-21 0.0000000e+00], sampled 0.03833758549142385
[2019-03-26 21:41:36,950] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8494.2616 2843368869.3792 1131.0000
[2019-03-26 21:41:37,156] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.6078 3008551080.6251 1766.0000
[2019-03-26 21:41:37,193] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.7003 2928231904.9171 1338.0000
[2019-03-26 21:41:37,381] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.1120 2780070553.5627 933.0000
[2019-03-26 21:41:37,441] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7874.2549 3164933419.7733 1778.0000
[2019-03-26 21:41:38,460] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1325000, evaluation results [1325000.0, 7874.254934002473, 3164933419.7732573, 1778.0, 8253.700304448676, 2928231904.9170933, 1338.0, 8658.112016599982, 2780070553.5627275, 933.0, 7997.607833681256, 3008551080.6250534, 1766.0, 8494.261612308823, 2843368869.379151, 1131.0]
[2019-03-26 21:41:39,059] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.0267063e-23 0.0000000e+00], sum to 1.0000
[2019-03-26 21:41:39,068] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4634
[2019-03-26 21:41:39,077] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.95, 97.66666666666667, 1.0, 2.0, 0.4643511869416615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 655091.546806363, 655091.546806363, 179005.5196459925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2004600.0000, 
sim time next is 2005200.0000, 
raw observation next is [23.9, 98.0, 1.0, 2.0, 0.4633728702384586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 653961.8516538395, 653961.8516538395, 178893.4476831057], 
processed observation next is [0.0, 0.21739130434782608, 0.33175355450236965, 0.98, 1.0, 1.0, 0.353461289443926, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1816560699038443, 0.1816560699038443, 0.2670051457956802], 
reward next is 0.7330, 
noisyNet noise sample is [array([0.6423441], dtype=float32), -0.94139475]. 
=============================================
[2019-03-26 21:41:43,391] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.4424263e-19 0.0000000e+00], sum to 1.0000
[2019-03-26 21:41:43,398] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4194
[2019-03-26 21:41:43,402] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 97.0, 1.0, 2.0, 0.460795891596776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 651176.1322495863, 651176.1322495863, 178624.0099571674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2088000.0000, 
sim time next is 2088600.0000, 
raw observation next is [23.96666666666667, 97.16666666666667, 1.0, 2.0, 0.4599709408056562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 650217.9598427864, 650217.9598427871, 178529.635563173], 
processed observation next is [0.0, 0.17391304347826086, 0.33491311216429714, 0.9716666666666667, 1.0, 1.0, 0.34936257928392317, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18061609995632957, 0.18061609995632977, 0.2664621426316015], 
reward next is 0.7335, 
noisyNet noise sample is [array([1.3967222], dtype=float32), -0.32963207]. 
=============================================
[2019-03-26 21:41:45,317] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.17858795e-17
 0.00000000e+00], sum to 1.0000
[2019-03-26 21:41:45,327] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6598
[2019-03-26 21:41:45,332] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.36666666666667, 94.83333333333334, 1.0, 2.0, 0.4649283893598679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 654700.6073903277, 654700.607390327, 178935.8505071668], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1991400.0000, 
sim time next is 1992000.0000, 
raw observation next is [24.43333333333334, 94.66666666666667, 1.0, 2.0, 0.4677261088709502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 657310.2762225271, 657310.2762225271, 179178.3553379314], 
processed observation next is [0.0, 0.043478260869565216, 0.3570300157977887, 0.9466666666666668, 1.0, 1.0, 0.3587061552662051, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18258618783959088, 0.18258618783959088, 0.26743038110139017], 
reward next is 0.7326, 
noisyNet noise sample is [array([1.0856591], dtype=float32), -0.4397987]. 
=============================================
[2019-03-26 21:41:45,348] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[73.89022 ]
 [74.15132 ]
 [74.30622 ]
 [74.513725]
 [74.71558 ]], R is [[73.76070404]
 [73.75602722]
 [73.75163269]
 [73.7472229 ]
 [73.74279785]].
[2019-03-26 21:41:45,902] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 3.003027e-15 0.000000e+00], sum to 1.0000
[2019-03-26 21:41:45,914] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2114
[2019-03-26 21:41:45,921] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.23333333333333, 95.83333333333333, 1.0, 2.0, 0.4650883855131099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 654539.6954840053, 654539.6954840046, 178909.694666516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2001000.0000, 
sim time next is 2001600.0000, 
raw observation next is [24.2, 96.0, 1.0, 2.0, 0.4643381237217728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 653842.1613753759, 653842.1613753765, 178845.3110665021], 
processed observation next is [0.0, 0.17391304347826086, 0.3459715639810427, 0.96, 1.0, 1.0, 0.3546242454479191, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1816228226042711, 0.18162282260427126, 0.26693330009925686], 
reward next is 0.7331, 
noisyNet noise sample is [array([-0.39274707], dtype=float32), 1.2834053]. 
=============================================
[2019-03-26 21:41:47,028] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0597898e-16 0.0000000e+00], sum to 1.0000
[2019-03-26 21:41:47,040] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8137
[2019-03-26 21:41:47,048] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.13333333333333, 84.66666666666667, 1.0, 2.0, 0.5167793546206902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722126.8266303921, 722126.8266303921, 186266.9261211203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2035200.0000, 
sim time next is 2035800.0000, 
raw observation next is [27.25, 84.0, 1.0, 2.0, 0.5168110363721877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722171.1124931996, 722171.1124931996, 186272.0921017974], 
processed observation next is [0.0, 0.5652173913043478, 0.490521327014218, 0.84, 1.0, 1.0, 0.41784462213516593, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20060308680366656, 0.20060308680366656, 0.27801804791313045], 
reward next is 0.7220, 
noisyNet noise sample is [array([0.5063585], dtype=float32), -1.0797632]. 
=============================================
[2019-03-26 21:41:48,591] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 6.903475e-17 0.000000e+00], sum to 1.0000
[2019-03-26 21:41:48,600] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4661
[2019-03-26 21:41:48,603] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 88.33333333333334, 1.0, 2.0, 0.4833796441520721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 675440.5674690019, 675440.5674690013, 181032.8963085709], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2056800.0000, 
sim time next is 2057400.0000, 
raw observation next is [25.6, 88.5, 1.0, 2.0, 0.4819775380918156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 673480.742453085, 673480.7424530843, 180820.3905261952], 
processed observation next is [0.0, 0.8260869565217391, 0.4123222748815167, 0.885, 1.0, 1.0, 0.37587655191785013, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18707798401474585, 0.18707798401474565, 0.26988117988984356], 
reward next is 0.7301, 
noisyNet noise sample is [array([-0.03077981], dtype=float32), -0.3979471]. 
=============================================
[2019-03-26 21:41:53,504] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.8156769e-22 9.9979538e-01 7.2918087e-25 2.0463018e-04 6.1869671e-25], sum to 1.0000
[2019-03-26 21:41:53,515] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3766
[2019-03-26 21:41:53,521] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2618762.901756771 W.
[2019-03-26 21:41:53,525] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.85, 67.5, 1.0, 2.0, 0.6241597517583264, 1.0, 2.0, 0.6241597517583264, 1.0, 2.0, 1.03, 6.971860631923112, 6.9112, 170.5573041426782, 2618762.901756771, 2575309.223593502, 496904.9184445538], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2219400.0000, 
sim time next is 2220000.0000, 
raw observation next is [31.83333333333334, 67.66666666666666, 1.0, 2.0, 0.7688585562358726, 1.0, 2.0, 0.7688585562358726, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2150168.304397942, 2150168.304397942, 405001.2425113079], 
processed observation next is [1.0, 0.6956521739130435, 0.7077409162717223, 0.6766666666666665, 1.0, 1.0, 0.7215163328143044, 1.0, 1.0, 0.7215163328143044, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5972689734438728, 0.5972689734438728, 0.6044794664347879], 
reward next is 0.3955, 
noisyNet noise sample is [array([0.719394], dtype=float32), 0.9293389]. 
=============================================
[2019-03-26 21:41:53,543] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[35.37033 ]
 [35.380104]
 [36.605324]
 [41.528313]
 [39.00562 ]], R is [[40.49794388]
 [40.09296417]
 [39.69203568]
 [39.29511642]
 [39.21186066]].
[2019-03-26 21:41:58,374] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.5158111e-30 1.0000000e+00 4.5506690e-37 1.8613522e-12 3.3324520e-38], sum to 1.0000
[2019-03-26 21:41:58,385] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8375
[2019-03-26 21:41:58,390] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.4, 71.33333333333333, 1.0, 2.0, 0.5878398519148471, 1.0, 1.0, 0.5878398519148471, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1643548.187635473, 1643548.187635473, 329800.8884522849], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2277600.0000, 
sim time next is 2278200.0000, 
raw observation next is [29.6, 70.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.372214334334837, 6.9112, 168.9109048682609, 1781034.392844473, 1453978.929691581, 311349.8092421904], 
processed observation next is [1.0, 0.34782608695652173, 0.6018957345971565, 0.7066666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.04610143343348368, 0.0, 0.8294298706500016, 0.4947317757901314, 0.4038830360254392, 0.46470120782416474], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9739848], dtype=float32), 0.96294177]. 
=============================================
[2019-03-26 21:41:59,344] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 7.715191e-20 0.000000e+00], sum to 1.0000
[2019-03-26 21:41:59,350] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9923
[2019-03-26 21:41:59,355] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666666, 70.66666666666667, 1.0, 2.0, 0.5678245230785808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 793481.9475389589, 793481.9475389589, 194905.5421730983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2313600.0000, 
sim time next is 2314200.0000, 
raw observation next is [31.03333333333333, 71.33333333333333, 1.0, 2.0, 0.5675287176369502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 793068.4326352568, 793068.4326352568, 194853.256522012], 
processed observation next is [1.0, 0.782608695652174, 0.669826224328594, 0.7133333333333333, 1.0, 1.0, 0.47895026221319303, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2202967868431269, 0.2202967868431269, 0.290825756003003], 
reward next is 0.7092, 
noisyNet noise sample is [array([1.808135], dtype=float32), -0.6125775]. 
=============================================
[2019-03-26 21:42:01,404] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.36453610e-21 9.99999881e-01 9.73007270e-25 1.06858344e-07
 2.66434985e-25], sum to 1.0000
[2019-03-26 21:42:01,416] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3630
[2019-03-26 21:42:01,423] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2456966.920044129 W.
[2019-03-26 21:42:01,430] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.98333333333333, 63.16666666666666, 1.0, 2.0, 0.5856349400737132, 1.0, 2.0, 0.5856349400737132, 1.0, 2.0, 1.017054218473869, 6.911199999999999, 6.9112, 170.5573041426782, 2456966.920044129, 2456966.92004413, 479413.4521574602], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2290200.0000, 
sim time next is 2290800.0000, 
raw observation next is [31.96666666666667, 63.33333333333334, 1.0, 2.0, 0.67381664028585, 1.0, 2.0, 0.67381664028585, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1884143.013920815, 1884143.013920815, 363119.9048570822], 
processed observation next is [1.0, 0.5217391304347826, 0.7140600315955767, 0.6333333333333334, 1.0, 1.0, 0.6070080003443975, 1.0, 1.0, 0.6070080003443975, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5233730594224486, 0.5233730594224486, 0.5419700072493764], 
reward next is 0.4580, 
noisyNet noise sample is [array([0.13955383], dtype=float32), -0.046424057]. 
=============================================
[2019-03-26 21:42:13,077] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6164942e-21 0.0000000e+00], sum to 1.0000
[2019-03-26 21:42:13,087] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5645
[2019-03-26 21:42:13,094] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3959674096291794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 590841.7069712145, 590841.7069712151, 173694.8769551762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2668800.0000, 
sim time next is 2669400.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3958583586890215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 590679.0946986069, 590679.0946986069, 173679.9431152444], 
processed observation next is [0.0, 0.9130434782608695, 0.28909952606635075, 0.94, 1.0, 1.0, 0.27211850444460417, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1640775263051686, 0.1640775263051686, 0.25922379569439463], 
reward next is 0.7408, 
noisyNet noise sample is [array([-0.03194517], dtype=float32), -0.44413766]. 
=============================================
[2019-03-26 21:42:15,477] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.9999178e-18 0.0000000e+00], sum to 1.0000
[2019-03-26 21:42:15,478] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5415
[2019-03-26 21:42:15,484] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3377006207281725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 520218.5628121088, 520218.5628121095, 168216.6743281917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2787600.0000, 
sim time next is 2788200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3381475861693375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 520911.9204612995, 520911.9204612989, 168271.9779602908], 
processed observation next is [1.0, 0.2608695652173913, 0.2417061611374408, 0.94, 1.0, 1.0, 0.20258745321606925, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1446977556836943, 0.14469775568369414, 0.2511522059108818], 
reward next is 0.7488, 
noisyNet noise sample is [array([1.4375399], dtype=float32), -1.7357674]. 
=============================================
[2019-03-26 21:42:18,035] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.6873714e-20 0.0000000e+00], sum to 1.0000
[2019-03-26 21:42:18,041] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1238
[2019-03-26 21:42:18,045] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.3170575583172149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 501368.4287978841, 501368.4287978835, 167127.8055310481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2931600.0000, 
sim time next is 2932200.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.3177529425547354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 502467.2599172965, 502467.2599172965, 167210.3012784686], 
processed observation next is [1.0, 0.9565217391304348, 0.19431279620853087, 0.94, 1.0, 1.0, 0.17801559343944023, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1395742388659157, 0.1395742388659157, 0.2495676138484606], 
reward next is 0.7504, 
noisyNet noise sample is [array([0.03862556], dtype=float32), -0.076401725]. 
=============================================
[2019-03-26 21:42:21,233] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 8.713324e-20 0.000000e+00], sum to 1.0000
[2019-03-26 21:42:21,241] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3208
[2019-03-26 21:42:21,246] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4738631162323849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 662292.3425520502, 662292.3425520497, 179621.9109307519], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2621400.0000, 
sim time next is 2622000.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4741184900357455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 662626.665547584, 662626.665547584, 179657.0114156023], 
processed observation next is [0.0, 0.34782608695652173, 0.4312796208530806, 0.84, 1.0, 1.0, 0.36640781932017535, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18406296265210664, 0.18406296265210664, 0.26814479315761536], 
reward next is 0.7319, 
noisyNet noise sample is [array([0.07948502], dtype=float32), -2.1756043]. 
=============================================
[2019-03-26 21:42:21,265] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[74.94159]
 [74.93739]
 [74.82826]
 [74.80838]
 [74.76258]], R is [[74.95858002]
 [74.94090271]
 [74.92350769]
 [74.90654755]
 [74.89001465]].
[2019-03-26 21:42:24,611] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5698373e-18 0.0000000e+00], sum to 1.0000
[2019-03-26 21:42:24,624] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9414
[2019-03-26 21:42:24,633] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.331634081581932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515089.818378539, 515089.818378539, 167947.7659570396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3043800.0000, 
sim time next is 3044400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.3314771753901596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 514847.1167386528, 514847.1167386528, 167928.8227189743], 
processed observation next is [1.0, 0.21739130434782608, 0.19431279620853087, 1.0, 1.0, 1.0, 0.19455081372308383, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14301308798295911, 0.14301308798295911, 0.25064003390891687], 
reward next is 0.7494, 
noisyNet noise sample is [array([-0.46943265], dtype=float32), -0.838521]. 
=============================================
[2019-03-26 21:42:26,383] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 9.5480915e-20 0.0000000e+00], sum to 1.0000
[2019-03-26 21:42:26,393] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4509
[2019-03-26 21:42:26,397] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 83.0, 1.0, 2.0, 0.5879318061340045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 909290.8951521824, 909290.8951521824, 209054.5582509945], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2805600.0000, 
sim time next is 2806200.0000, 
raw observation next is [23.5, 83.0, 1.0, 2.0, 0.6100250177025361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 939134.7442926532, 939134.7442926537, 213163.2371544995], 
processed observation next is [1.0, 0.4782608695652174, 0.31279620853080575, 0.83, 1.0, 1.0, 0.5301506237379954, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.26087076230351475, 0.2608707623035149, 0.31815408530522316], 
reward next is 0.6818, 
noisyNet noise sample is [array([-0.20202333], dtype=float32), 2.9799676]. 
=============================================
[2019-03-26 21:42:26,822] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.8698595e-17 0.0000000e+00], sum to 1.0000
[2019-03-26 21:42:26,831] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4810
[2019-03-26 21:42:26,834] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 86.0, 1.0, 2.0, 0.5656816255115659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 846588.7830245778, 846588.7830245785, 201492.78422965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2809800.0000, 
sim time next is 2810400.0000, 
raw observation next is [24.0, 87.0, 1.0, 2.0, 0.5074931472829456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 756014.4061528356, 756014.4061528356, 190594.5126949097], 
processed observation next is [1.0, 0.5217391304347826, 0.3364928909952607, 0.87, 1.0, 1.0, 0.40661824973848865, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.210004001709121, 0.210004001709121, 0.284469421932701], 
reward next is 0.7155, 
noisyNet noise sample is [array([0.02675342], dtype=float32), -0.06889996]. 
=============================================
[2019-03-26 21:42:28,796] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.4702526e-24 0.0000000e+00], sum to 1.0000
[2019-03-26 21:42:28,807] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3920
[2019-03-26 21:42:28,813] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 95.0, 1.0, 2.0, 0.3911062162407326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 584174.1603886123, 584174.1603886123, 173103.7404002603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2747400.0000, 
sim time next is 2748000.0000, 
raw observation next is [22.66666666666667, 96.0, 1.0, 2.0, 0.3899526964879866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 583306.3079049023, 583306.3079049016, 173051.4434765129], 
processed observation next is [0.0, 0.8260869565217391, 0.27330173775671435, 0.96, 1.0, 1.0, 0.26500324878070675, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16202952997358397, 0.16202952997358377, 0.25828573653210884], 
reward next is 0.7417, 
noisyNet noise sample is [array([0.77745086], dtype=float32), 0.5003902]. 
=============================================
[2019-03-26 21:42:28,828] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[83.86092]
 [83.8327 ]
 [83.68839]
 [83.64963]
 [83.5895 ]], R is [[83.81652069]
 [83.71999359]
 [83.6242981 ]
 [83.52934265]
 [83.43523407]].
[2019-03-26 21:42:31,982] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.6118056e-19 0.0000000e+00], sum to 1.0000
[2019-03-26 21:42:31,989] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7607
[2019-03-26 21:42:31,994] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 93.16666666666667, 1.0, 2.0, 0.3977676784717663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 591824.6310228049, 591824.6310228043, 173734.0849522283], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2839800.0000, 
sim time next is 2840400.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3941880045486493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 587763.2868035784, 587763.2868035778, 173399.7780090811], 
processed observation next is [1.0, 0.9130434782608695, 0.28909952606635075, 0.94, 1.0, 1.0, 0.2701060295766859, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16326757966766067, 0.1632675796676605, 0.25880563881952406], 
reward next is 0.7412, 
noisyNet noise sample is [array([0.34135723], dtype=float32), -1.4182544]. 
=============================================
[2019-03-26 21:42:34,184] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 21:42:34,187] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:42:34,188] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:42:34,188] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:42:34,192] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:42:34,194] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:42:34,191] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:42:34,196] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:42:34,198] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:42:34,195] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:42:34,204] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:42:34,222] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run55
[2019-03-26 21:42:34,244] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run55
[2019-03-26 21:42:34,269] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run55
[2019-03-26 21:42:34,269] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run55
[2019-03-26 21:42:34,270] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run55
[2019-03-26 21:42:38,039] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.69269735]
[2019-03-26 21:42:38,041] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [20.61666666666667, 77.33333333333333, 1.0, 2.0, 0.2483357195435739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 409739.8927695358, 409739.8927695351, 160706.188876242]
[2019-03-26 21:42:38,043] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:42:38,047] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.9842537e-22 0.0000000e+00], sampled 0.3121459996563384
[2019-03-26 21:42:39,870] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.69269735]
[2019-03-26 21:42:39,871] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.8255828, 83.15499528, 1.0, 2.0, 0.2960202604308501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 474229.8131199123, 474229.8131199123, 165246.4037889405]
[2019-03-26 21:42:39,873] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:42:39,875] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 2.675995e-23 0.000000e+00], sampled 0.840675347405337
[2019-03-26 21:42:57,743] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.69269735]
[2019-03-26 21:42:57,746] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.66666666666666, 95.16666666666667, 1.0, 2.0, 0.3453853068329361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 535022.2491416008, 535022.2491416014, 169495.6252996505]
[2019-03-26 21:42:57,746] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:42:57,749] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 7.672472e-24 0.000000e+00], sampled 0.6275319150952798
[2019-03-26 21:43:12,081] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.69269735]
[2019-03-26 21:43:12,081] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.0, 89.0, 1.0, 2.0, 0.6572403156099959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1001733.16975557, 1001733.16975557, 222295.8885578048]
[2019-03-26 21:43:12,083] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:43:12,085] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.0236513e-21 0.0000000e+00], sampled 0.836003000576545
[2019-03-26 21:43:31,031] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.69269735]
[2019-03-26 21:43:31,031] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.66666666666666, 58.66666666666666, 1.0, 2.0, 0.7253674252503876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1013738.564689718, 1013738.564689719, 226421.9447891558]
[2019-03-26 21:43:31,032] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:43:31,035] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.5236243e-22 0.0000000e+00], sampled 0.23479042929948724
[2019-03-26 21:43:32,014] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.69269735]
[2019-03-26 21:43:32,016] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.44109978, 74.22024112, 1.0, 2.0, 0.5750325333966895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 803558.2814774769, 803558.2814774769, 196181.7051300925]
[2019-03-26 21:43:32,018] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:43:32,020] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 6.967509e-22 0.000000e+00], sampled 0.728879496098305
[2019-03-26 21:43:41,188] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.69269735]
[2019-03-26 21:43:41,189] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.1, 88.0, 1.0, 2.0, 1.000995511487371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129194845105, 1399196.911102816, 1399196.911102816, 299231.987813753]
[2019-03-26 21:43:41,190] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:43:41,193] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 6.463921e-18 0.000000e+00], sampled 0.22570327918423616
[2019-03-26 21:43:51,094] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.69269735]
[2019-03-26 21:43:51,095] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.85, 91.0, 1.0, 2.0, 0.6413929851651113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 896330.408269062, 896330.4082690626, 208704.1366917441]
[2019-03-26 21:43:51,096] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:43:51,100] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.8807986e-21 0.0000000e+00], sampled 0.6863412534544844
[2019-03-26 21:43:52,495] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.69269735]
[2019-03-26 21:43:52,496] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.76244041, 88.22671152, 1.0, 2.0, 0.5258529674169915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 734810.3161190164, 734810.3161190164, 187745.701863503]
[2019-03-26 21:43:52,497] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:43:52,502] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 8.919537e-22 0.000000e+00], sampled 0.43605248505632277
[2019-03-26 21:44:01,292] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.69269735]
[2019-03-26 21:44:01,294] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.5, 70.0, 1.0, 2.0, 0.5884518668721577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 822317.8995754375, 822317.8995754375, 198614.0772156733]
[2019-03-26 21:44:01,296] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:44:01,298] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.5927335e-23 0.0000000e+00], sampled 0.26084288758340846
[2019-03-26 21:44:11,226] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7876.6154 3164676497.9081 1778.0000
[2019-03-26 21:44:11,529] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.9766 3008303976.5521 1766.0000
[2019-03-26 21:44:11,603] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.7138 2779867804.7524 933.0000
[2019-03-26 21:44:11,609] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.0740 2927981547.8413 1338.0000
[2019-03-26 21:44:11,630] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.8629 2843167093.8007 1131.0000
[2019-03-26 21:44:12,646] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1350000, evaluation results [1350000.0, 7876.615402862808, 3164676497.9080544, 1778.0, 8254.073971726037, 2927981547.8412614, 1338.0, 8659.713804063274, 2779867804.752359, 933.0, 7997.976645730424, 3008303976.5521116, 1766.0, 8495.862932155293, 2843167093.8007364, 1131.0]
[2019-03-26 21:44:16,292] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.2620458e-20 0.0000000e+00], sum to 1.0000
[2019-03-26 21:44:16,302] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0773
[2019-03-26 21:44:16,308] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3022885073314969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 481377.9521034923, 481377.9521034916, 165720.6348426957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2940600.0000, 
sim time next is 2941200.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3022952447846516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 481388.7555171007, 481388.7555171007, 165721.4112967301], 
processed observation next is [1.0, 0.043478260869565216, 0.1469194312796209, 1.0, 1.0, 1.0, 0.1593918611863272, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1337190987547502, 0.1337190987547502, 0.24734538999511957], 
reward next is 0.7527, 
noisyNet noise sample is [array([-0.3648363], dtype=float32), 0.36832762]. 
=============================================
[2019-03-26 21:44:19,121] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 4.253989e-22 0.000000e+00], sum to 1.0000
[2019-03-26 21:44:19,131] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5096
[2019-03-26 21:44:19,137] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 89.0, 1.0, 2.0, 0.4554664323995708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 644889.3542668258, 644889.3542668258, 178005.615019745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3214200.0000, 
sim time next is 3214800.0000, 
raw observation next is [25.0, 89.0, 1.0, 2.0, 0.4551870254107773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 644494.1438965485, 644494.1438965485, 177965.0173941553], 
processed observation next is [0.0, 0.21739130434782608, 0.38388625592417064, 0.89, 1.0, 1.0, 0.3435988257961173, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1790261510823746, 0.1790261510823746, 0.2656194289465004], 
reward next is 0.7344, 
noisyNet noise sample is [array([-2.929406], dtype=float32), 1.6165692]. 
=============================================
[2019-03-26 21:44:26,939] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.00000e+00 1.00000e+00 0.00000e+00 7.88729e-18 0.00000e+00], sum to 1.0000
[2019-03-26 21:44:26,948] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6380
[2019-03-26 21:44:26,954] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 76.5, 1.0, 2.0, 0.5166572696123977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 721956.1719435282, 721956.1719435282, 186247.4435737031], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3439800.0000, 
sim time next is 3440400.0000, 
raw observation next is [28.33333333333333, 77.33333333333333, 1.0, 2.0, 0.5157695029439897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 720715.2215249649, 720715.2215249649, 186104.0597786985], 
processed observation next is [1.0, 0.8260869565217391, 0.541864139020537, 0.7733333333333333, 1.0, 1.0, 0.4165897625831201, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20019867264582358, 0.20019867264582358, 0.2777672534010425], 
reward next is 0.7222, 
noisyNet noise sample is [array([2.4548738], dtype=float32), 0.8624974]. 
=============================================
[2019-03-26 21:44:33,425] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 9.6941125e-15 0.0000000e+00], sum to 1.0000
[2019-03-26 21:44:33,434] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1070
[2019-03-26 21:44:33,439] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 75.66666666666666, 1.0, 2.0, 0.5040244115696126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 704297.6701225686, 704297.6701225693, 184228.735297169], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3544800.0000, 
sim time next is 3545400.0000, 
raw observation next is [28.0, 74.83333333333334, 1.0, 2.0, 0.4995048238479894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 697980.1569303558, 697980.1569303565, 183518.2135709811], 
processed observation next is [1.0, 0.0, 0.5260663507109005, 0.7483333333333334, 1.0, 1.0, 0.3969937636722764, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19388337692509883, 0.19388337692509902, 0.27390778144922556], 
reward next is 0.7261, 
noisyNet noise sample is [array([-2.8952568], dtype=float32), 0.37904888]. 
=============================================
[2019-03-26 21:44:39,019] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.7024086e-11 0.0000000e+00], sum to 1.0000
[2019-03-26 21:44:39,028] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8546
[2019-03-26 21:44:39,033] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.7715458770249043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1078308.110315211, 1078308.110315211, 237045.5242425282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3384000.0000, 
sim time next is 3384600.0000, 
raw observation next is [26.0, 94.00000000000001, 1.0, 2.0, 0.8375912802156392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1170663.670720548, 1170663.670720547, 253346.4939416901], 
processed observation next is [1.0, 0.17391304347826086, 0.4312796208530806, 0.9400000000000002, 1.0, 1.0, 0.8043268436333002, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.32518435297792997, 0.3251843529779297, 0.3781290954353584], 
reward next is 0.6219, 
noisyNet noise sample is [array([-1.046157], dtype=float32), 0.27334294]. 
=============================================
[2019-03-26 21:44:39,966] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.2438235e-10 0.0000000e+00], sum to 1.0000
[2019-03-26 21:44:39,974] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5785
[2019-03-26 21:44:39,978] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4776390051154442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 667542.1365439373, 667542.1365439373, 180182.5460899989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3288000.0000, 
sim time next is 3288600.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4777145889650721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 667649.3665650703, 667649.3665650703, 180194.0888419972], 
processed observation next is [0.0, 0.043478260869565216, 0.4312796208530806, 0.84, 1.0, 1.0, 0.370740468632617, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1854581573791862, 0.1854581573791862, 0.26894640125671226], 
reward next is 0.7311, 
noisyNet noise sample is [array([-0.01051958], dtype=float32), 0.63634276]. 
=============================================
[2019-03-26 21:44:42,611] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.1939579e-16 4.4170916e-02 1.1426761e-18 9.5582902e-01 9.5310361e-20], sum to 1.0000
[2019-03-26 21:44:42,620] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6533
[2019-03-26 21:44:42,625] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.16666666666667, 70.33333333333334, 1.0, 2.0, 0.9472690795492072, 1.0, 2.0, 0.9472690795492072, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2649646.178029408, 2649646.178029408, 497943.058761155], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3409800.0000, 
sim time next is 3410400.0000, 
raw observation next is [32.33333333333334, 69.66666666666667, 1.0, 2.0, 0.9322558554180246, 1.0, 2.0, 0.9322558554180246, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2607608.234303355, 2607608.234303355, 489402.4039340653], 
processed observation next is [1.0, 0.4782608695652174, 0.7314375987361774, 0.6966666666666668, 1.0, 1.0, 0.9183805486964152, 1.0, 1.0, 0.9183805486964152, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7243356206398209, 0.7243356206398209, 0.7304513491553214], 
reward next is 0.2695, 
noisyNet noise sample is [array([1.5226133], dtype=float32), 0.24724793]. 
=============================================
[2019-03-26 21:44:45,859] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.1886666e-19 0.0000000e+00], sum to 1.0000
[2019-03-26 21:44:45,868] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4986
[2019-03-26 21:44:45,874] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 76.5, 1.0, 2.0, 0.5166572696123977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 721956.1719435282, 721956.1719435282, 186247.4435737031], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3439800.0000, 
sim time next is 3440400.0000, 
raw observation next is [28.33333333333333, 77.33333333333333, 1.0, 2.0, 0.5157695029439897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 720715.2215249649, 720715.2215249649, 186104.0597786985], 
processed observation next is [1.0, 0.8260869565217391, 0.541864139020537, 0.7733333333333333, 1.0, 1.0, 0.4165897625831201, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20019867264582358, 0.20019867264582358, 0.2777672534010425], 
reward next is 0.7222, 
noisyNet noise sample is [array([0.90862507], dtype=float32), -1.1344062]. 
=============================================
[2019-03-26 21:44:53,000] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5770857e-13 6.2681742e-08 1.2846015e-14 9.9999988e-01 2.1361548e-13], sum to 1.0000
[2019-03-26 21:44:53,005] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5377
[2019-03-26 21:44:53,012] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 61.66666666666667, 1.0, 2.0, 0.9586359029243369, 1.0, 2.0, 0.9586359029243369, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2681474.918016909, 2681474.91801691, 504491.9106713546], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3676800.0000, 
sim time next is 3677400.0000, 
raw observation next is [33.0, 61.0, 1.0, 2.0, 0.98419593760955, 1.0, 2.0, 0.98419593760955, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2753049.652610518, 2753049.652610519, 519507.2759320477], 
processed observation next is [1.0, 0.5652173913043478, 0.7630331753554502, 0.61, 1.0, 1.0, 0.9809589609753615, 1.0, 1.0, 0.9809589609753615, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7647360146140327, 0.7647360146140331, 0.7753839939284294], 
reward next is 0.2246, 
noisyNet noise sample is [array([0.09266236], dtype=float32), -0.37185043]. 
=============================================
[2019-03-26 21:44:56,807] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.6208085e-25 1.0000000e+00 1.5957554e-28 6.6189360e-11 2.7432408e-30], sum to 1.0000
[2019-03-26 21:44:56,817] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5108
[2019-03-26 21:44:56,825] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2216484.236871239 W.
[2019-03-26 21:44:56,829] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.5, 72.0, 1.0, 2.0, 0.7925475435686825, 1.0, 1.0, 0.7925475435686825, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2216484.236871239, 2216484.236871239, 416254.8278061872], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3573000.0000, 
sim time next is 3573600.0000, 
raw observation next is [29.66666666666667, 71.33333333333333, 1.0, 2.0, 0.4810220811758265, 1.0, 2.0, 0.4810220811758265, 1.0, 1.0, 0.8259709581907494, 6.9112, 6.9112, 170.5573041426782, 2017694.678239445, 2017694.678239445, 400636.8523954644], 
processed observation next is [1.0, 0.34782608695652173, 0.6050552922590839, 0.7133333333333333, 1.0, 1.0, 0.37472539900701995, 1.0, 1.0, 0.37472539900701995, 1.0, 0.5, 0.7877694612082309, 0.0, 0.0, 0.8375144448122397, 0.5604707439554014, 0.5604707439554014, 0.597965451336514], 
reward next is 0.4020, 
noisyNet noise sample is [array([-1.5356696], dtype=float32), 0.7987683]. 
=============================================
[2019-03-26 21:45:01,358] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.9987412e-18 9.9999976e-01 2.5146832e-20 2.3494815e-07 1.6982888e-22], sum to 1.0000
[2019-03-26 21:45:01,365] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9951
[2019-03-26 21:45:01,375] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2483216.116028639 W.
[2019-03-26 21:45:01,381] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.33333333333334, 65.5, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.181438928259237, 6.9112, 168.9112068834906, 2483216.116028639, 2291501.30524813, 475889.9573229707], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4014600.0000, 
sim time next is 4015200.0000, 
raw observation next is [31.66666666666667, 65.0, 1.0, 2.0, 0.9237217546232055, 1.0, 1.0, 0.9237217546232055, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2583712.861806944, 2583712.861806944, 484596.3423209155], 
processed observation next is [1.0, 0.4782608695652174, 0.6998420221169038, 0.65, 1.0, 1.0, 0.9080984995460307, 1.0, 0.5, 0.9080984995460307, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7176980171685956, 0.7176980171685956, 0.7232781228670381], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.10513403], dtype=float32), 1.1034741]. 
=============================================
[2019-03-26 21:45:03,146] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.1078470e-13 8.2231713e-07 7.6175171e-14 9.9999917e-01 3.0448066e-14], sum to 1.0000
[2019-03-26 21:45:03,153] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6799
[2019-03-26 21:45:03,158] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 60.33333333333333, 1.0, 2.0, 0.9792201655051281, 1.0, 2.0, 0.9792201655051281, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2739115.87715809, 2739115.877158089, 516553.1412626589], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3678000.0000, 
sim time next is 3678600.0000, 
raw observation next is [33.0, 59.66666666666667, 1.0, 2.0, 0.9719763931742758, 1.0, 2.0, 0.9719763931742758, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2718831.24340231, 2718831.24340231, 512278.8367730116], 
processed observation next is [1.0, 0.5652173913043478, 0.7630331753554502, 0.5966666666666667, 1.0, 1.0, 0.9662366182822599, 1.0, 1.0, 0.9662366182822599, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7552309009450862, 0.7552309009450862, 0.764595278765689], 
reward next is 0.2354, 
noisyNet noise sample is [array([0.23010406], dtype=float32), 1.1019801]. 
=============================================
[2019-03-26 21:45:06,132] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5305006e-29 0.0000000e+00], sum to 1.0000
[2019-03-26 21:45:06,139] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2782
[2019-03-26 21:45:06,145] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.4934420051251383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 689505.5630190618, 689505.5630190624, 182574.681723728], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3709200.0000, 
sim time next is 3709800.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.492888272639752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 688731.5604081282, 688731.5604081289, 182489.0766849304], 
processed observation next is [1.0, 0.9565217391304348, 0.5260663507109005, 0.74, 1.0, 1.0, 0.38902201522861685, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19131432233559117, 0.19131432233559137, 0.2723717562461648], 
reward next is 0.7276, 
noisyNet noise sample is [array([0.5848173], dtype=float32), -0.87802625]. 
=============================================
[2019-03-26 21:45:07,678] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.7304553e-27 0.0000000e+00], sum to 1.0000
[2019-03-26 21:45:07,686] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8861
[2019-03-26 21:45:07,691] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.33333333333334, 63.33333333333333, 1.0, 2.0, 0.5572060011874463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 778638.1123257191, 778638.1123257191, 193045.2620676647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3868800.0000, 
sim time next is 3869400.0000, 
raw observation next is [32.16666666666666, 65.16666666666667, 1.0, 2.0, 0.5640217650058872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 788165.9753220618, 788165.9753220612, 194235.5952034292], 
processed observation next is [0.0, 0.782608695652174, 0.7235387045813582, 0.6516666666666667, 1.0, 1.0, 0.4747250180793821, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21893499314501716, 0.218934993145017, 0.28990387343795404], 
reward next is 0.7101, 
noisyNet noise sample is [array([-1.8811976], dtype=float32), -0.13332887]. 
=============================================
[2019-03-26 21:45:08,169] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 21:45:08,173] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:45:08,174] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:45:08,176] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:45:08,178] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:45:08,180] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:45:08,179] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:45:08,176] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:45:08,184] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:45:08,185] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:45:08,183] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:45:08,213] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run56
[2019-03-26 21:45:08,235] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run56
[2019-03-26 21:45:08,254] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run56
[2019-03-26 21:45:08,275] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run56
[2019-03-26 21:45:08,295] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run56
[2019-03-26 21:45:09,500] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.86407155]
[2019-03-26 21:45:09,501] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.4, 73.0, 1.0, 2.0, 0.1944871282499636, 1.0, 2.0, 0.1944871282499636, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 169.0403247858759, 584709.4915126814, 584709.4915126808, 239371.0410011887]
[2019-03-26 21:45:09,502] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:45:09,504] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0928630e-18 4.6046161e-08 4.0682730e-20 1.0000000e+00 9.0753675e-20], sampled 0.3172798370155564
[2019-03-26 21:45:23,334] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.86407155]
[2019-03-26 21:45:23,335] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.77316803166667, 92.77849892333333, 1.0, 2.0, 0.366318675112623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 560546.0718390847, 560546.0718390854, 171435.944747785]
[2019-03-26 21:45:23,336] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:45:23,338] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.1245443e-32 0.0000000e+00], sampled 0.2827230808555822
[2019-03-26 21:45:49,218] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.86407155]
[2019-03-26 21:45:49,220] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.08308541, 99.43946980666666, 1.0, 2.0, 0.4717369725514896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 659166.8732209255, 659166.8732209249, 179286.4975155537]
[2019-03-26 21:45:49,222] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:45:49,228] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.9624363e-30 0.0000000e+00], sampled 0.3394874824187031
[2019-03-26 21:46:17,385] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.86407155]
[2019-03-26 21:46:17,387] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.83333333333333, 70.66666666666667, 1.0, 2.0, 0.9188989514959002, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.985142803000475, 6.9112, 168.9124570709035, 2181490.133343697, 2129032.719086113, 440111.12218496]
[2019-03-26 21:46:17,387] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:46:17,390] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.7270623e-27 1.0000000e+00 5.2448423e-31 3.1406664e-13 5.0968293e-33], sampled 0.41143655361339415
[2019-03-26 21:46:17,392] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2181490.133343697 W.
[2019-03-26 21:47:02,102] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.9210 2842890288.6408 1131.0000
[2019-03-26 21:47:02,169] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.3731 3008038374.3173 1766.0000
[2019-03-26 21:47:02,174] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7879.6451 3164445220.6628 1778.0000
[2019-03-26 21:47:02,326] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7732 2779589745.4232 933.0000
[2019-03-26 21:47:02,352] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.3751 2927779800.6357 1338.0000
[2019-03-26 21:47:03,368] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1375000, evaluation results [1375000.0, 7879.6450561207575, 3164445220.6627817, 1778.0, 8254.375086958147, 2927779800.6357465, 1338.0, 8660.773226357216, 2779589745.4231777, 933.0, 7998.373066976429, 3008038374.3172884, 1766.0, 8496.920990814182, 2842890288.6407876, 1131.0]
[2019-03-26 21:47:11,509] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.7703573e-12 2.1632400e-03 4.1491493e-13 9.9783677e-01 1.4858243e-13], sum to 1.0000
[2019-03-26 21:47:11,516] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8689
[2019-03-26 21:47:11,523] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.33333333333334, 76.33333333333334, 1.0, 2.0, 0.9248698547411895, 1.0, 2.0, 0.9248698547411895, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2586927.50077058, 2586927.500770579, 485250.5349840372], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4098000.0000, 
sim time next is 4098600.0000, 
raw observation next is [31.5, 75.0, 1.0, 2.0, 0.9211697049424139, 1.0, 2.0, 0.9211697049424139, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2576567.244278233, 2576567.244278233, 483181.4729931022], 
processed observation next is [1.0, 0.43478260869565216, 0.6919431279620853, 0.75, 1.0, 1.0, 0.9050237408944746, 1.0, 1.0, 0.9050237408944746, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7157131234106203, 0.7157131234106203, 0.7211663776016451], 
reward next is 0.2788, 
noisyNet noise sample is [array([-0.7081382], dtype=float32), -0.7707089]. 
=============================================
[2019-03-26 21:47:12,038] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.0599421e-25 0.0000000e+00], sum to 1.0000
[2019-03-26 21:47:12,054] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2461
[2019-03-26 21:47:12,061] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 85.66666666666667, 1.0, 2.0, 0.565386746059028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 790074.113987782, 790074.1139877826, 194474.783560228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3912000.0000, 
sim time next is 3912600.0000, 
raw observation next is [28.66666666666667, 84.83333333333333, 1.0, 2.0, 0.5721265898930277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 799495.9482186974, 799495.9482186969, 195668.1644147278], 
processed observation next is [0.0, 0.2608695652173913, 0.5576619273301741, 0.8483333333333333, 1.0, 1.0, 0.4844898673409972, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22208220783852706, 0.22208220783852692, 0.29204203643989224], 
reward next is 0.7080, 
noisyNet noise sample is [array([-1.4178789], dtype=float32), -1.062158]. 
=============================================
[2019-03-26 21:47:14,198] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0056525e-18 1.0000000e+00 1.1754785e-21 2.6085669e-08 9.1940729e-23], sum to 1.0000
[2019-03-26 21:47:14,206] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8329
[2019-03-26 21:47:14,217] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2643769.565043955 W.
[2019-03-26 21:47:14,223] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.0, 60.00000000000001, 1.0, 2.0, 0.9451703653097268, 1.0, 2.0, 0.9451703653097268, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2643769.565043955, 2643769.565043956, 496739.4374307183], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4022400.0000, 
sim time next is 4023000.0000, 
raw observation next is [34.0, 60.0, 1.0, 2.0, 0.9572593193715073, 1.0, 2.0, 0.9572593193715073, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2677620.242962942, 2677620.242962943, 503698.1504701097], 
processed observation next is [1.0, 0.5652173913043478, 0.8104265402843602, 0.6, 1.0, 1.0, 0.948505204062057, 1.0, 1.0, 0.948505204062057, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7437834008230394, 0.7437834008230397, 0.7517882842837459], 
reward next is 0.2482, 
noisyNet noise sample is [array([-1.6166418], dtype=float32), 0.90258324]. 
=============================================
[2019-03-26 21:47:14,243] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[26.34787 ]
 [27.532118]
 [28.621027]
 [28.048838]
 [30.920637]], R is [[29.16184044]
 [28.87022209]
 [28.58152008]
 [28.2957058 ]
 [28.01274872]].
[2019-03-26 21:47:22,053] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.2693449e-18 0.0000000e+00], sum to 1.0000
[2019-03-26 21:47:22,062] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0348
[2019-03-26 21:47:22,068] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 85.66666666666667, 1.0, 2.0, 0.9772308967099878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1365957.233263604, 1365957.233263604, 292071.0438370645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4344000.0000, 
sim time next is 4344600.0000, 
raw observation next is [29.83333333333333, 84.83333333333333, 1.0, 2.0, 0.985891497624193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1378070.735662323, 1378070.735662324, 294662.644026053], 
processed observation next is [1.0, 0.2608695652173913, 0.6129541864139019, 0.8483333333333333, 1.0, 1.0, 0.9830018043664976, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.38279742657286747, 0.38279742657286775, 0.4397949910836612], 
reward next is 0.5602, 
noisyNet noise sample is [array([0.96243054], dtype=float32), -0.6871792]. 
=============================================
[2019-03-26 21:47:28,127] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.1727949e-12 1.4716044e-10 5.7838348e-13 1.0000000e+00 2.9487979e-12], sum to 1.0000
[2019-03-26 21:47:28,138] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3067
[2019-03-26 21:47:28,147] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.66666666666667, 73.66666666666666, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 6.930424796535631, 6.9112, 170.5573041426782, 2923117.311926232, 2909345.808153036, 553542.7858152691], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4178400.0000, 
sim time next is 4179000.0000, 
raw observation next is [32.83333333333333, 72.33333333333334, 1.0, 2.0, 1.009332850704634, 1.0, 2.0, 1.009332850704634, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2823443.53660696, 2823443.53660696, 534662.4834195155], 
processed observation next is [1.0, 0.34782608695652173, 0.7551342812006318, 0.7233333333333334, 1.0, 1.0, 1.011244398439318, 1.0, 1.0, 1.011244398439318, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7842898712797111, 0.7842898712797111, 0.7980037065962918], 
reward next is 0.2020, 
noisyNet noise sample is [array([-0.9205777], dtype=float32), -0.2838782]. 
=============================================
[2019-03-26 21:47:28,166] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[19.057026]
 [19.162567]
 [26.671162]
 [38.4736  ]
 [43.87022 ]], R is [[19.11776543]
 [18.92658806]
 [18.73732185]
 [18.54994965]
 [18.36445045]].
[2019-03-26 21:47:31,273] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 5.299245e-30 0.000000e+00], sum to 1.0000
[2019-03-26 21:47:31,279] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8173
[2019-03-26 21:47:31,284] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 75.0, 1.0, 2.0, 0.6017710636677364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 840937.85878658, 840937.85878658, 201076.3022146555], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4232400.0000, 
sim time next is 4233000.0000, 
raw observation next is [31.0, 75.0, 1.0, 2.0, 0.6008825142831682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 839695.6751250174, 839695.6751250174, 200910.4748922966], 
processed observation next is [1.0, 1.0, 0.6682464454976303, 0.75, 1.0, 1.0, 0.519135559377311, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23324879864583817, 0.23324879864583817, 0.29986638043626357], 
reward next is 0.7001, 
noisyNet noise sample is [array([-2.6711855], dtype=float32), -2.3728185]. 
=============================================
[2019-03-26 21:47:31,301] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[81.552925]
 [81.58532 ]
 [81.61248 ]
 [81.64782 ]
 [81.68777 ]], R is [[81.4009552 ]
 [81.28682709]
 [81.17393494]
 [81.06244659]
 [80.95219421]].
[2019-03-26 21:47:39,280] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4823066e-32 0.0000000e+00], sum to 1.0000
[2019-03-26 21:47:39,288] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0513
[2019-03-26 21:47:39,292] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.5527835446855871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 772455.9368315182, 772455.9368315176, 192278.7896705648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4482600.0000, 
sim time next is 4483200.0000, 
raw observation next is [28.0, 84.0, 1.0, 2.0, 0.5501475598523213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 768771.0967108719, 768771.0967108713, 191825.7660821197], 
processed observation next is [0.0, 0.9130434782608695, 0.5260663507109005, 0.84, 1.0, 1.0, 0.4580091082558088, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2135475268641311, 0.21354752686413092, 0.2863071135554025], 
reward next is 0.7137, 
noisyNet noise sample is [array([-1.3993758], dtype=float32), -0.12888466]. 
=============================================
[2019-03-26 21:47:41,616] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4555514e-31 0.0000000e+00], sum to 1.0000
[2019-03-26 21:47:41,631] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7435
[2019-03-26 21:47:41,640] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5130121937667768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 716860.9702976157, 716860.9702976157, 185659.7436488764], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4519800.0000, 
sim time next is 4520400.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5134090715666738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 717415.7373815287, 717415.7373815293, 185723.4554471353], 
processed observation next is [0.0, 0.30434782608695654, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4137458693574383, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19928214927264687, 0.19928214927264704, 0.2771991872345303], 
reward next is 0.7228, 
noisyNet noise sample is [array([-0.43950045], dtype=float32), -0.6109163]. 
=============================================
[2019-03-26 21:47:42,890] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.7387028e-30 0.0000000e+00], sum to 1.0000
[2019-03-26 21:47:42,896] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4543
[2019-03-26 21:47:42,900] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 83.16666666666666, 1.0, 2.0, 0.5551925732185099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 775823.526184428, 775823.5261844286, 192694.7126408039], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4477800.0000, 
sim time next is 4478400.0000, 
raw observation next is [28.0, 84.0, 1.0, 2.0, 0.5527037252724505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 772344.3571794131, 772344.3571794131, 192265.0418269546], 
processed observation next is [0.0, 0.8695652173913043, 0.5260663507109005, 0.84, 1.0, 1.0, 0.4610888256294584, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21454009921650363, 0.21454009921650363, 0.28696274899545465], 
reward next is 0.7130, 
noisyNet noise sample is [array([0.819247], dtype=float32), -0.8649365]. 
=============================================
[2019-03-26 21:47:46,662] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.00000e+00 1.00000e+00 0.00000e+00 7.22209e-26 0.00000e+00], sum to 1.0000
[2019-03-26 21:47:46,670] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4950
[2019-03-26 21:47:46,676] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.8244836235566202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1152333.747422435, 1152333.747422435, 250005.8600467185], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4761000.0000, 
sim time next is 4761600.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.7835879753519386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1095146.756755355, 1095146.756755355, 239918.6676532144], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.79, 1.0, 1.0, 0.7392626209059501, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.30420743243204307, 0.30420743243204307, 0.358087563661514], 
reward next is 0.6419, 
noisyNet noise sample is [array([-0.25724903], dtype=float32), -0.33440286]. 
=============================================
[2019-03-26 21:47:53,352] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000e+00 1.0000e+00 0.0000e+00 2.2002e-21 0.0000e+00], sum to 1.0000
[2019-03-26 21:47:53,358] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4162
[2019-03-26 21:47:53,362] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 1.001329001628105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1399663.372522734, 1399663.372522734, 299336.5388062986], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4604400.0000, 
sim time next is 4605000.0000, 
raw observation next is [29.16666666666667, 88.16666666666667, 1.0, 2.0, 1.000461134521655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1398449.463905272, 1398449.463905272, 299071.9936719646], 
processed observation next is [1.0, 0.30434782608695654, 0.581358609794629, 0.8816666666666667, 1.0, 1.0, 1.00055558376103, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3884581844181311, 0.3884581844181311, 0.44637610995815613], 
reward next is 0.5536, 
noisyNet noise sample is [array([-0.0755484], dtype=float32), -1.2124535]. 
=============================================
[2019-03-26 21:47:53,384] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[53.19219 ]
 [52.74482 ]
 [52.14148 ]
 [52.374546]
 [52.516273]], R is [[52.85293961]
 [52.87763977]
 [52.91225433]
 [52.94724655]
 [52.97376251]].
[2019-03-26 21:47:56,489] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 9.1423817e-23 0.0000000e+00], sum to 1.0000
[2019-03-26 21:47:56,504] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0809
[2019-03-26 21:47:56,512] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 94.0, 1.0, 2.0, 0.4724233350370068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 664883.6020439009, 664883.6020439015, 180001.7606253187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4658400.0000, 
sim time next is 4659000.0000, 
raw observation next is [24.58333333333334, 94.00000000000001, 1.0, 2.0, 0.4767004995338715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 668384.50316243, 668384.50316243, 180320.1372688563], 
processed observation next is [1.0, 0.9565217391304348, 0.3641390205371251, 0.9400000000000002, 1.0, 1.0, 0.3695186741371945, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1856623619895639, 0.1856623619895639, 0.26913453323709896], 
reward next is 0.7309, 
noisyNet noise sample is [array([-0.05575066], dtype=float32), -0.71674514]. 
=============================================
[2019-03-26 21:47:56,526] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[69.4466 ]
 [69.42568]
 [69.60262]
 [69.86413]
 [69.98485]], R is [[69.40866089]
 [69.44591522]
 [69.48323822]
 [69.52067566]
 [69.55825806]].
[2019-03-26 21:47:59,124] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 21:47:59,125] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:47:59,126] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:47:59,127] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:47:59,128] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:47:59,128] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:47:59,129] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:47:59,130] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:47:59,130] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:47:59,131] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:47:59,131] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:47:59,165] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run57
[2019-03-26 21:47:59,187] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run57
[2019-03-26 21:47:59,188] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run57
[2019-03-26 21:47:59,209] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run57
[2019-03-26 21:47:59,249] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/7/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run57
[2019-03-26 21:48:25,406] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.82225335]
[2019-03-26 21:48:25,409] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.0, 93.66666666666667, 1.0, 2.0, 0.5309232420199458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 840383.3991394218, 840383.3991394218, 199840.6788662375]
[2019-03-26 21:48:25,410] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:48:25,412] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.6325126e-30 0.0000000e+00], sampled 0.8788716959872592
[2019-03-26 21:48:40,981] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.82225335]
[2019-03-26 21:48:40,983] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.1, 54.0, 1.0, 2.0, 0.8653367274783101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1209464.321033755, 1209464.321033754, 260580.1166673866]
[2019-03-26 21:48:40,985] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:48:40,987] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5029098e-28 0.0000000e+00], sampled 0.828798112977296
[2019-03-26 21:48:48,604] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13253538], dtype=float32), -0.82225335]
[2019-03-26 21:48:48,607] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.8, 65.66666666666667, 1.0, 2.0, 0.7761271981519937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1084714.208791067, 1084714.208791068, 238132.9651938812]
[2019-03-26 21:48:48,607] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:48:48,609] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0416946e-28 0.0000000e+00], sampled 0.8913337706074279
