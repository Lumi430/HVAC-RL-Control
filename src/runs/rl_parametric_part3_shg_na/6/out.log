Using TensorFlow backend.
[2019-03-26 19:03:08,870] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='linear', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Shg-Train-v1', eval_act_func='part3_shg_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=5e-06, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[19, 1], model_type='nn', num_threads=16, output='./Part3-NA-Shg-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Shg-Test-v1', 'Part3-NA-Shg-Test-v2', 'Part3-NA-Shg-Test-v3', 'Part3-NA-Shg-Test-v4'], test_mode='Multiple', train_act_func='part3_shg_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=29)
[2019-03-26 19:03:08,871] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-26 19:03:08.904754: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-26 19:03:26,090] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-26 19:03:26,090] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Shg-Train-v1', 'Part3-NA-Shg-Test-v1', 'Part3-NA-Shg-Test-v2', 'Part3-NA-Shg-Test-v3', 'Part3-NA-Shg-Test-v4'] ...
[2019-03-26 19:03:26,100] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation worker starts!
[2019-03-26 19:03:26,105] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation worker starts!
[2019-03-26 19:03:26,110] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation worker starts!
[2019-03-26 19:03:26,115] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation worker starts!
[2019-03-26 19:03:26,118] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation worker starts!
[2019-03-26 19:03:26,118] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:26,118] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-26 19:03:26,172] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:26,173] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run1
[2019-03-26 19:03:27,119] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:27,121] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-26 19:03:27,208] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:27,208] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run1
[2019-03-26 19:03:27,398] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 19:03:27,399] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:03:27,399] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:03:27,400] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:27,400] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:03:27,400] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:27,401] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:03:27,401] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:03:27,401] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:27,402] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:27,401] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:27,405] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run1
[2019-03-26 19:03:27,412] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run1
[2019-03-26 19:03:27,413] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run1
[2019-03-26 19:03:27,431] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run1
[2019-03-26 19:03:27,439] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run1
[2019-03-26 19:03:28,122] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:28,124] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-26 19:03:28,202] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:28,203] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run1
[2019-03-26 19:03:29,125] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:29,131] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-26 19:03:29,188] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:29,189] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run1
[2019-03-26 19:03:30,130] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:30,135] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-26 19:03:30,190] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:30,192] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run1
[2019-03-26 19:03:31,134] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:31,140] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-26 19:03:31,198] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:31,199] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run1
[2019-03-26 19:03:32,140] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:32,146] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-26 19:03:32,207] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:32,208] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run1
[2019-03-26 19:03:32,847] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:03:32,850] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.043454935, 76.345169215, 1.0, 2.0, 0.1932606799572578, 1.0, 2.0, 0.1932606799572578, 0.0, 1.0, 0.0, 6.9112, 6.9112, 171.5212843490159, 576492.608630164, 576492.608630164, 238976.7888216684]
[2019-03-26 19:03:32,852] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:03:32,854] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.3493895  0.05616868 0.26718083 0.12049624 0.20676482], sampled 0.6730808118273379
[2019-03-26 19:03:33,143] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:33,147] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-26 19:03:33,204] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:33,205] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run1
[2019-03-26 19:03:34,147] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:34,150] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-26 19:03:34,205] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:34,206] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run1
[2019-03-26 19:03:35,151] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:35,152] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-26 19:03:35,242] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:35,242] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run1
[2019-03-26 19:03:35,605] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:03:35,606] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.18842945666667, 72.87171755666667, 1.0, 1.0, 0.17, 1.0, 1.0, 0.17, 1.0, 2.0, 0.18, 6.911200000000001, 6.9112, 184.5923449428631, 423878.3050479115, 423878.3050479108, 219184.2707636857]
[2019-03-26 19:03:35,607] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:03:35,611] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.18934318 0.04818379 0.4538049  0.12988633 0.17878188], sampled 0.11506482711735855
[2019-03-26 19:03:36,153] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:36,157] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-26 19:03:36,213] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:36,215] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run1
[2019-03-26 19:03:37,158] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:37,161] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-26 19:03:37,263] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:37,264] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run1
[2019-03-26 19:03:38,163] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:38,169] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-26 19:03:38,256] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:38,258] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run1
[2019-03-26 19:03:39,168] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:39,172] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-26 19:03:39,228] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:39,229] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run1
[2019-03-26 19:03:40,172] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:40,175] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-26 19:03:40,235] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:40,236] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run1
[2019-03-26 19:03:41,175] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:41,179] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-26 19:03:41,238] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:41,239] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run1
[2019-03-26 19:03:42,422] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.13617662 0.17334475 0.19868997 0.23414966 0.25763896], sum to 1.0000
[2019-03-26 19:03:42,423] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9858
[2019-03-26 19:03:42,498] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.3, 89.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2061999732655149, 6.911200000000001, 6.9112, 170.5573041426782, 535887.6784477276, 535887.6784477269, 235515.6743966998], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 0.0000, 
sim time next is 600.0000, 
raw observation next is [21.95, 88.16666666666667, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2014978073796613, 6.9112, 6.9112, 170.5573041426782, 525509.9952246582, 525509.9952246582, 233898.4183255517], 
processed observation next is [1.0, 0.0, 0.2393364928909953, 0.8816666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.026216838267879645, 0.0, 0.0, 0.8375144448122397, 0.14597499867351615, 0.14597499867351615, 0.3491021169038085], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.10971364], dtype=float32), 0.004678865]. 
=============================================
[2019-03-26 19:04:11,034] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:04:11,035] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.66666666666667, 96.0, 1.0, 2.0, 0.17, 1.0, 1.0, 0.17, 1.0, 2.0, 0.2279225535585934, 6.911200000000001, 6.9112, 170.5573041426782, 584257.5596722799, 584257.5596722792, 242792.7472378796]
[2019-03-26 19:04:11,037] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:04:11,039] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.31099546 0.02637459 0.28145462 0.20106639 0.18010902], sampled 0.10136506430039727
[2019-03-26 19:04:18,463] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:04:18,463] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.4, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.01735537771074, 6.911200000000001, 6.9112, 168.912841376484, 819155.3815513499, 819155.3815513493, 251508.5559178342]
[2019-03-26 19:04:18,464] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:04:18,465] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.26275766 0.03296933 0.29318637 0.13345562 0.277631  ], sampled 0.7962377880533587
[2019-03-26 19:04:28,240] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:04:28,241] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [35.0, 56.0, 1.0, 2.0, 0.3022282267638391, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5248704814868965, 6.9112, 6.9112, 168.912956510431, 844692.0173203994, 844692.0173203994, 222682.0185678745]
[2019-03-26 19:04:28,242] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:04:28,244] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.30441177 0.03144247 0.31150758 0.16829415 0.18434408], sampled 0.10985532052538627
[2019-03-26 19:04:39,141] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:04:39,142] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.421581615, 85.547961115, 1.0, 2.0, 0.2345268315418887, 1.0, 2.0, 0.2345268315418887, 0.0, 1.0, 0.0, 6.9112, 6.9112, 172.86236624, 657925.5152850494, 657925.5152850494, 239353.7732999047]
[2019-03-26 19:04:39,143] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:04:39,146] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.37574178 0.03117302 0.24985543 0.11585367 0.2273761 ], sampled 0.4383466787972349
[2019-03-26 19:04:43,780] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:04:43,783] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.66666666666667, 65.33333333333334, 1.0, 2.0, 0.17, 1.0, 1.0, 0.17, 1.0, 2.0, 0.2838351168043002, 6.9112, 6.9112, 170.5573041426782, 696870.954764058, 696870.954764058, 259617.7451051596]
[2019-03-26 19:04:43,785] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:04:43,788] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.36205158 0.03655883 0.2992262  0.0561734  0.24599   ], sampled 0.2868754064692809
[2019-03-26 19:05:07,518] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:05:07,519] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.41666666666666, 60.5, 1.0, 2.0, 0.5657232185117502, 1.0, 1.0, 0.5657232185117502, 1.0, 2.0, 0.9705462912869911, 6.9112, 6.9112, 170.5573041426782, 2373350.153508206, 2373350.153508206, 461086.0098507075]
[2019-03-26 19:05:07,519] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:05:07,522] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.54091877 0.00880077 0.2266839  0.09519111 0.12840548], sampled 0.7057681341831169
[2019-03-26 19:05:12,636] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:05:12,637] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.8, 94.66666666666666, 1.0, 2.0, 0.2650075586924859, 1.0, 2.0, 0.2650075586924859, 0.0, 1.0, 0.0, 6.9112, 6.9112, 172.86236624, 740622.5015235187, 740622.5015235187, 243957.5134153714]
[2019-03-26 19:05:12,638] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:05:12,640] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.2151837  0.01651797 0.2370728  0.3256554  0.20557012], sampled 0.5423594415998014
[2019-03-26 19:05:26,100] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 3713.7671 3305900940.3303 1019.0000
[2019-03-26 19:05:26,287] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 3685.6271 3179370089.8050 752.0000
[2019-03-26 19:05:26,307] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 3605.9546 3361035482.9674 1381.0000
[2019-03-26 19:05:26,312] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 3597.2711 3509105056.6804 1469.0000
[2019-03-26 19:05:26,415] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 3667.6344 3212437603.7918 883.0000
[2019-03-26 19:05:27,430] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 3597.271076560201, 3509105056.6804333, 1469.0, 3713.767103582124, 3305900940.3302994, 1019.0, 3685.6270645076092, 3179370089.8049545, 752.0, 3605.9545705277974, 3361035482.9673758, 1381.0, 3667.634380807916, 3212437603.7917557, 883.0]
[2019-03-26 19:05:27,498] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.20238549 0.13663988 0.2562452  0.22353724 0.18119219], sum to 1.0000
[2019-03-26 19:05:27,501] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3899
[2019-03-26 19:05:27,608] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.25, 86.5, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 1.0, 0.1873378713061431, 6.911200000000001, 6.9112, 170.5573041426782, 492964.2798343205, 492964.2798343198, 228862.5650552935], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1800.0000, 
sim time next is 2400.0000, 
raw observation next is [20.9, 85.66666666666667, 1.0, 2.0, 0.17, 0.0, 1.0, 0.0, 1.0, 2.0, 0.2689366614452952, 6.9112, 6.9112, 168.912956510431, 474714.5483896466, 474714.5483896466, 187049.8907572855], 
processed observation next is [1.0, 0.0, 0.1895734597156398, 0.8566666666666667, 1.0, 1.0, 0.0, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.10845934322596977, 0.0, 0.0, 0.8294399451523027, 0.13186515233045737, 0.13186515233045737, 0.2791789414287843], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.12385303], dtype=float32), -0.18089195]. 
=============================================
[2019-03-26 19:05:30,803] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.36461216 0.00840882 0.40737176 0.0956273  0.12397999], sum to 1.0000
[2019-03-26 19:05:30,812] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9545
[2019-03-26 19:05:30,913] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.86666666666667, 84.66666666666667, 1.0, 2.0, 0.1797626411524613, 0.0, 1.0, 0.0, 1.0, 2.0, 0.3250123264908784, 6.9112, 6.9112, 168.912956510431, 569967.856636187, 569967.856636187, 197868.1470504054], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 24000.0000, 
sim time next is 24600.0000, 
raw observation next is [21.93333333333334, 84.33333333333333, 1.0, 2.0, 0.17, 1.0, 1.0, 0.17, 1.0, 2.0, 0.2154305864928921, 6.911199999999999, 6.9112, 170.5573041426782, 565415.7288318975, 565415.7288318981, 239030.1772545824], 
processed observation next is [1.0, 0.2608695652173913, 0.23854660347551382, 0.8433333333333333, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.043208032308404996, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.15705992467552707, 0.15705992467552723, 0.35676145858892894], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6560114], dtype=float32), 2.2457104]. 
=============================================
[2019-03-26 19:05:31,273] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.27634725 0.0356736  0.37411374 0.12154908 0.19231626], sum to 1.0000
[2019-03-26 19:05:31,281] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5070
[2019-03-26 19:05:31,286] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.51666666666667, 83.0, 1.0, 1.0, 0.1788987962172246, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3220198529766282, 6.9112, 6.9112, 168.912956510431, 562941.8508880638, 562941.8508880638, 197367.6821839887], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 29400.0000, 
sim time next is 30000.0000, 
raw observation next is [22.73333333333333, 82.0, 1.0, 2.0, 0.2721449769944146, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4890267430144132, 6.911199999999999, 6.9112, 168.912956510431, 854020.5062737424, 854020.5062737431, 221649.061016318], 
processed observation next is [1.0, 0.34782608695652173, 0.27646129541864134, 0.82, 1.0, 1.0, 0.12306623734266817, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3768618817248941, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2372279184093729, 0.2372279184093731, 0.33081949405420596], 
reward next is 0.6692, 
noisyNet noise sample is [array([-0.7550399], dtype=float32), 0.5863071]. 
=============================================
[2019-03-26 19:05:31,304] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-1.7841644]
 [-2.7233658]
 [-2.010471 ]
 [-2.467718 ]
 [-2.1519742]], R is [[-1.55273998]
 [-1.53721261]
 [-0.76845491]
 [-0.05311036]
 [-0.05257926]].
[2019-03-26 19:05:46,752] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 7922: loss -3.0075
[2019-03-26 19:05:46,812] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 7922: learning rate 0.0000
[2019-03-26 19:05:46,832] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7936: loss 10.1072
[2019-03-26 19:05:46,838] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 7939: learning rate 0.0000
[2019-03-26 19:05:46,838] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 7939: loss 7.4644
[2019-03-26 19:05:46,842] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 7940: learning rate 0.0000
[2019-03-26 19:05:46,855] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7948: loss 1.1754
[2019-03-26 19:05:46,858] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7949: learning rate 0.0000
[2019-03-26 19:05:46,865] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7952: loss 7.6062
[2019-03-26 19:05:46,869] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 7955: learning rate 0.0000
[2019-03-26 19:05:46,897] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 7965: loss 2.6963
[2019-03-26 19:05:46,900] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 7967: learning rate 0.0000
[2019-03-26 19:05:46,925] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7977: loss 6.2902
[2019-03-26 19:05:46,928] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 7979: learning rate 0.0000
[2019-03-26 19:05:46,940] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 7982: loss 1.9891
[2019-03-26 19:05:46,942] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 7982: learning rate 0.0000
[2019-03-26 19:05:46,957] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 7993: loss 1.6006
[2019-03-26 19:05:46,962] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 7995: loss 0.4579
[2019-03-26 19:05:46,963] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 7994: learning rate 0.0000
[2019-03-26 19:05:46,967] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 7998: learning rate 0.0000
[2019-03-26 19:05:46,974] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7999: loss 0.9157
[2019-03-26 19:05:46,977] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 7999: learning rate 0.0000
[2019-03-26 19:05:46,993] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 8008: loss 8.6509
[2019-03-26 19:05:46,993] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 8008: loss -3.4138
[2019-03-26 19:05:46,994] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 8008: learning rate 0.0000
[2019-03-26 19:05:46,995] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 8008: learning rate 0.0000
[2019-03-26 19:05:47,019] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 8020: loss 2.8534
[2019-03-26 19:05:47,022] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 8021: learning rate 0.0000
[2019-03-26 19:05:47,058] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 8036: loss 0.1554
[2019-03-26 19:05:47,061] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 8037: learning rate 0.0000
[2019-03-26 19:05:47,265] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 8132: loss 7.2285
[2019-03-26 19:05:47,270] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 8133: learning rate 0.0000
[2019-03-26 19:05:49,961] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.3014036  0.14557053 0.18615232 0.22027385 0.14659968], sum to 1.0000
[2019-03-26 19:05:49,969] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0222
[2019-03-26 19:05:50,075] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.3, 87.0, 1.0, 2.0, 0.17, 0.0, 1.0, 0.0, 1.0, 2.0, 0.238842313435484, 6.911200000000001, 6.9112, 168.912956510431, 423558.7193722062, 423558.7193722056, 180361.0129768866], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 352800.0000, 
sim time next is 353400.0000, 
raw observation next is [20.28333333333333, 87.16666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5177220430356722, 6.9112, 6.9112, 168.912956510431, 459653.3068350803, 459653.3068350803, 154187.6223620376], 
processed observation next is [1.0, 0.08695652173913043, 0.16034755134281198, 0.8716666666666667, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4118561500435026, 0.0, 0.0, 0.8294399451523027, 0.12768147412085565, 0.12768147412085565, 0.23013077964483222], 
reward next is 0.7699, 
noisyNet noise sample is [array([1.2245314], dtype=float32), 0.005785821]. 
=============================================
[2019-03-26 19:05:53,617] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.15178114 0.1962167  0.45697945 0.11825611 0.07676662], sum to 1.0000
[2019-03-26 19:05:53,621] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8563
[2019-03-26 19:05:53,624] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.66666666666667, 80.33333333333333, 1.0, 2.0, 0.2564390091728924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 420498.6523125551, 420498.6523125558, 161550.8064610493], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 416400.0000, 
sim time next is 417000.0000, 
raw observation next is [20.58333333333334, 80.16666666666667, 1.0, 2.0, 0.17, 1.0, 1.0, 0.17, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 417852.2964674792, 417852.2964674792, 216769.6198578114], 
processed observation next is [1.0, 0.8260869565217391, 0.17456556082148533, 0.8016666666666667, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.11607008235207755, 0.11607008235207755, 0.3235367460564349], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8422306], dtype=float32), 0.13424735]. 
=============================================
[2019-03-26 19:05:53,637] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[1.5962468]
 [2.149513 ]
 [1.8963089]
 [1.86449  ]
 [2.0396433]], R is [[1.48939121]
 [2.23337674]
 [2.21104288]
 [2.96598554]
 [2.93632579]].
[2019-03-26 19:05:54,215] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.26353258 0.33089897 0.23620656 0.07328696 0.09607496], sum to 1.0000
[2019-03-26 19:05:54,220] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7857
[2019-03-26 19:05:54,300] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.75, 85.66666666666667, 1.0, 2.0, 0.2470864188695453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 406555.8672708419, 406555.8672708425, 160617.3790305967], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 427800.0000, 
sim time next is 428400.0000, 
raw observation next is [19.7, 86.0, 1.0, 2.0, 0.17, 0.0, 2.0, 0.0, 1.0, 1.0, 0.2270616203915882, 6.911200000000001, 6.9112, 168.912956510431, 405354.9084954147, 405354.9084954141, 177573.3819189367], 
processed observation next is [1.0, 1.0, 0.1327014218009479, 0.86, 1.0, 1.0, 0.0, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.057392219989741707, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11259858569317076, 0.11259858569317059, 0.2650348983864727], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.21147627], dtype=float32), -1.2631955]. 
=============================================
[2019-03-26 19:05:55,232] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.24683176 0.2137696  0.38980523 0.06401867 0.08557469], sum to 1.0000
[2019-03-26 19:05:55,239] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2024
[2019-03-26 19:05:55,348] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.73333333333333, 82.00000000000001, 1.0, 2.0, 0.17, 0.0, 2.0, 0.0, 1.0, 1.0, 0.2178075504685653, 6.911200000000001, 6.9112, 168.912956510431, 390202.8409977127, 390202.8409977121, 175433.7511983159], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 450600.0000, 
sim time next is 451200.0000, 
raw observation next is [19.76666666666667, 82.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4220891698670383, 6.9112, 6.9112, 168.912956510431, 378149.2841175299, 378149.2841175299, 142857.7724204221], 
processed observation next is [1.0, 0.21739130434782608, 0.13586097946287537, 0.82, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.2952306949598028, 0.0, 0.0, 0.8294399451523027, 0.10504146781042498, 0.10504146781042498, 0.21322055585137625], 
reward next is 0.7868, 
noisyNet noise sample is [array([0.6476533], dtype=float32), -0.03393223]. 
=============================================
[2019-03-26 19:06:00,292] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.11289306 0.49842492 0.30404717 0.03980233 0.04483248], sum to 1.0000
[2019-03-26 19:06:00,302] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0374
[2019-03-26 19:06:00,308] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.75, 90.5, 1.0, 2.0, 0.17, 1.0, 1.0, 0.17, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 352910.2482507726, 352910.2482507726, 203408.1019079837], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 534600.0000, 
sim time next is 535200.0000, 
raw observation next is [17.7, 90.66666666666667, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3890927499516679, 6.9112, 6.9112, 168.912956510431, 350731.3372910572, 350731.3372910572, 139427.5285326798], 
processed observation next is [1.0, 0.17391304347826086, 0.03791469194312799, 0.9066666666666667, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.2549911584776438, 0.0, 0.0, 0.8294399451523027, 0.09742537146973812, 0.09742537146973812, 0.20810078885474598], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4923708], dtype=float32), -0.11117475]. 
=============================================
[2019-03-26 19:06:04,021] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 15914: loss -0.8935
[2019-03-26 19:06:04,024] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 15914: learning rate 0.0000
[2019-03-26 19:06:04,026] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 15915: loss 9.0709
[2019-03-26 19:06:04,028] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 15915: learning rate 0.0000
[2019-03-26 19:06:04,068] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 15932: loss 2.9494
[2019-03-26 19:06:04,071] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 15933: learning rate 0.0000
[2019-03-26 19:06:04,091] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 15944: loss 3.2799
[2019-03-26 19:06:04,093] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 15944: loss -2.7356
[2019-03-26 19:06:04,094] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 15944: learning rate 0.0000
[2019-03-26 19:06:04,096] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 15944: learning rate 0.0000
[2019-03-26 19:06:04,142] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 15963: loss 12.6027
[2019-03-26 19:06:04,143] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 15963: learning rate 0.0000
[2019-03-26 19:06:04,157] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 15971: loss 7.9824
[2019-03-26 19:06:04,159] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 15972: learning rate 0.0000
[2019-03-26 19:06:04,162] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 15974: loss 8.0760
[2019-03-26 19:06:04,165] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 15974: learning rate 0.0000
[2019-03-26 19:06:04,181] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 15984: loss 10.5225
[2019-03-26 19:06:04,182] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 15984: learning rate 0.0000
[2019-03-26 19:06:04,222] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 16000: loss 9.4778
[2019-03-26 19:06:04,223] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 16000: learning rate 0.0000
[2019-03-26 19:06:04,244] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 16007: loss 8.6871
[2019-03-26 19:06:04,248] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 16008: learning rate 0.0000
[2019-03-26 19:06:04,266] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 16015: loss 6.3854
[2019-03-26 19:06:04,270] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 16016: learning rate 0.0000
[2019-03-26 19:06:04,280] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 16022: loss 0.8023
[2019-03-26 19:06:04,283] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 16024: learning rate 0.0000
[2019-03-26 19:06:04,305] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 16036: loss -0.0445
[2019-03-26 19:06:04,307] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 16036: learning rate 0.0000
[2019-03-26 19:06:04,325] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 16045: loss 6.9061
[2019-03-26 19:06:04,328] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 16046: learning rate 0.0000
[2019-03-26 19:06:04,534] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 16134: loss 6.3108
[2019-03-26 19:06:04,536] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 16135: learning rate 0.0000
[2019-03-26 19:06:13,537] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.00141725 0.9903706  0.00540673 0.00164555 0.0011599 ], sum to 1.0000
[2019-03-26 19:06:13,550] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4100
[2019-03-26 19:06:13,652] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 63.5, 1.0, 2.0, 0.2440252528498042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 402372.2842304306, 402372.28423043, 160297.3331151968], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 757800.0000, 
sim time next is 758400.0000, 
raw observation next is [22.5, 65.0, 1.0, 2.0, 0.2450190389611186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 403835.3042693184, 403835.3042693177, 160399.4502776505], 
processed observation next is [1.0, 0.782608695652174, 0.2654028436018958, 0.65, 1.0, 1.0, 0.09038438429050433, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.112176473408144, 0.11217647340814381, 0.23940216459350822], 
reward next is 0.7606, 
noisyNet noise sample is [array([0.24773146], dtype=float32), 0.7161588]. 
=============================================
[2019-03-26 19:06:14,695] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.00129686 0.9899603  0.00584477 0.00158128 0.00131675], sum to 1.0000
[2019-03-26 19:06:14,706] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5424
[2019-03-26 19:06:14,713] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.56666666666667, 88.33333333333334, 1.0, 2.0, 0.2552014212143335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 419218.9642377191, 419218.9642377191, 161427.2336434695], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 775200.0000, 
sim time next is 775800.0000, 
raw observation next is [19.55, 88.5, 1.0, 2.0, 0.2543699431186543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 417835.6658879847, 417835.6658879847, 161344.0834414767], 
processed observation next is [1.0, 1.0, 0.12559241706161148, 0.885, 1.0, 1.0, 0.10165053387789673, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1160654627466624, 0.1160654627466624, 0.24081206483802492], 
reward next is 0.7592, 
noisyNet noise sample is [array([1.6631523], dtype=float32), 0.3307605]. 
=============================================
[2019-03-26 19:06:18,082] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.00143128 0.9881094  0.00570488 0.00220247 0.00255199], sum to 1.0000
[2019-03-26 19:06:18,091] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5987
[2019-03-26 19:06:18,191] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.43333333333333, 66.33333333333333, 1.0, 2.0, 0.2938091098117316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 469094.101236043, 469094.101236043, 164868.587597187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 831000.0000, 
sim time next is 831600.0000, 
raw observation next is [24.4, 67.0, 1.0, 2.0, 0.2960799492552072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 472020.0737030072, 472020.0737030066, 165063.6170354874], 
processed observation next is [0.0, 0.6521739130434783, 0.3554502369668246, 0.67, 1.0, 1.0, 0.15190355331952674, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13111668713972421, 0.13111668713972405, 0.24636360751565284], 
reward next is 0.7536, 
noisyNet noise sample is [array([-0.9151177], dtype=float32), -0.39356807]. 
=============================================
[2019-03-26 19:06:21,770] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.00113004 0.98760635 0.00641536 0.00283572 0.00201254], sum to 1.0000
[2019-03-26 19:06:21,781] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2747
[2019-03-26 19:06:21,893] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.4, 79.33333333333334, 1.0, 2.0, 0.2910488064414534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 465268.5318146853, 465268.5318146859, 164610.1486551551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 892200.0000, 
sim time next is 892800.0000, 
raw observation next is [22.5, 79.0, 1.0, 2.0, 0.2922412664094219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 466670.2044195034, 466670.204419504, 164700.6656892739], 
processed observation next is [0.0, 0.34782608695652173, 0.2654028436018958, 0.79, 1.0, 1.0, 0.14727863422821913, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12963061233875095, 0.12963061233875112, 0.24582188908846853], 
reward next is 0.7542, 
noisyNet noise sample is [array([1.5152217], dtype=float32), -0.6467264]. 
=============================================
[2019-03-26 19:06:21,934] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 23836: loss 0.2153
[2019-03-26 19:06:21,936] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 23836: learning rate 0.0000
[2019-03-26 19:06:22,017] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 23870: loss 3.5341
[2019-03-26 19:06:22,022] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 23870: learning rate 0.0000
[2019-03-26 19:06:22,120] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 23920: loss 0.2046
[2019-03-26 19:06:22,124] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 23920: learning rate 0.0000
[2019-03-26 19:06:22,143] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 23928: loss 5.9310
[2019-03-26 19:06:22,146] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 23928: learning rate 0.0000
[2019-03-26 19:06:22,153] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 23934: loss 5.9232
[2019-03-26 19:06:22,155] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 23934: learning rate 0.0000
[2019-03-26 19:06:22,240] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 23971: loss 9.1741
[2019-03-26 19:06:22,242] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 23971: learning rate 0.0000
[2019-03-26 19:06:22,252] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 23976: loss 5.8195
[2019-03-26 19:06:22,256] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 23977: learning rate 0.0000
[2019-03-26 19:06:22,270] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 23987: loss 6.1621
[2019-03-26 19:06:22,273] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 23987: learning rate 0.0000
[2019-03-26 19:06:22,273] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23987: loss 5.9149
[2019-03-26 19:06:22,280] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 23988: learning rate 0.0000
[2019-03-26 19:06:22,286] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23992: loss 5.9728
[2019-03-26 19:06:22,288] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 23993: learning rate 0.0000
[2019-03-26 19:06:22,329] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 24010: loss 4.9527
[2019-03-26 19:06:22,330] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 24010: learning rate 0.0000
[2019-03-26 19:06:22,354] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 24019: loss 6.3600
[2019-03-26 19:06:22,355] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 24019: loss 5.8900
[2019-03-26 19:06:22,356] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 24019: learning rate 0.0000
[2019-03-26 19:06:22,359] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 24020: learning rate 0.0000
[2019-03-26 19:06:22,475] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 24072: loss 5.8725
[2019-03-26 19:06:22,477] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 24072: learning rate 0.0000
[2019-03-26 19:06:22,506] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 24088: loss 5.8356
[2019-03-26 19:06:22,508] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 24088: learning rate 0.0000
[2019-03-26 19:06:22,769] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 24200: loss 2.6441
[2019-03-26 19:06:22,774] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 24203: learning rate 0.0000
[2019-03-26 19:06:24,153] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7805057e-04 9.9768329e-01 1.3446833e-03 4.6381491e-04 3.3011060e-04], sum to 1.0000
[2019-03-26 19:06:24,165] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0980
[2019-03-26 19:06:24,171] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.18333333333334, 81.33333333333334, 1.0, 2.0, 0.3290145769842875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 513310.819311581, 513310.8193115816, 167875.7974355611], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 931800.0000, 
sim time next is 932400.0000, 
raw observation next is [23.1, 82.0, 1.0, 2.0, 0.3290152649457214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 513191.5550425368, 513191.5550425375, 167863.1858485076], 
processed observation next is [0.0, 0.8260869565217391, 0.2938388625592418, 0.82, 1.0, 1.0, 0.19158465656111015, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.142553209734038, 0.1425532097340382, 0.25054206843060833], 
reward next is 0.7495, 
noisyNet noise sample is [array([-0.15781215], dtype=float32), -1.1876116]. 
=============================================
[2019-03-26 19:06:24,535] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 19:06:24,539] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:06:24,541] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:06:24,542] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:06:24,543] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:06:24,544] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:06:24,545] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:06:24,545] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:06:24,548] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:06:24,546] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:06:24,549] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:06:24,565] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run2
[2019-03-26 19:06:24,566] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run2
[2019-03-26 19:06:24,566] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run2
[2019-03-26 19:06:24,597] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run2
[2019-03-26 19:06:24,629] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run2
[2019-03-26 19:06:40,882] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00740112], dtype=float32), 0.016795382]
[2019-03-26 19:06:40,885] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.78333333333333, 84.16666666666667, 1.0, 2.0, 0.3021437113078593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 482478.6210010134, 482478.6210010134, 165817.2531501559]
[2019-03-26 19:06:40,887] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:06:40,891] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.8213046e-04 9.9736661e-01 1.3175053e-03 8.0450095e-04 3.2928432e-04], sampled 0.7717537152852257
[2019-03-26 19:06:51,837] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00740112], dtype=float32), 0.016795382]
[2019-03-26 19:06:51,839] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.46666666666667, 88.0, 1.0, 2.0, 0.7475995732008608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1044824.428437385, 1044824.428437384, 231451.1021800936]
[2019-03-26 19:06:51,841] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:06:51,845] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.04001585e-04 9.98566687e-01 7.08469364e-04 4.35887720e-04
 1.84981822e-04], sampled 0.6669410751707118
[2019-03-26 19:07:28,827] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00740112], dtype=float32), 0.016795382]
[2019-03-26 19:07:28,828] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [36.3, 51.0, 1.0, 2.0, 0.5829407764474777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104262, 814613.6056249735, 814613.6056249735, 197612.605346075]
[2019-03-26 19:07:28,829] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:07:28,834] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.1511690e-04 9.9763978e-01 8.9959422e-04 8.3079102e-04 2.1468793e-04], sampled 0.17277805574396743
[2019-03-26 19:07:34,200] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00740112], dtype=float32), 0.016795382]
[2019-03-26 19:07:34,202] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.18333333333334, 65.83333333333334, 1.0, 2.0, 0.9355408642771195, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.992653187881313, 6.9112, 168.91240622783, 2204783.039182538, 2146997.532550705, 444605.6886470554]
[2019-03-26 19:07:34,204] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:07:34,208] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.8693865e-04 9.9831176e-01 4.9332523e-04 6.1886077e-04 2.8924292e-04], sampled 0.4962996642521853
[2019-03-26 19:07:34,209] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2204783.039182538 W.
[2019-03-26 19:07:58,179] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00740112], dtype=float32), 0.016795382]
[2019-03-26 19:07:58,180] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.6, 89.0, 1.0, 2.0, 0.5239633614847792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 732168.9305094335, 732168.9305094341, 187435.6785391268]
[2019-03-26 19:07:58,182] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:07:58,186] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.5474816e-04 9.9577928e-01 2.1915962e-03 1.1241118e-03 5.5022916e-04], sampled 0.05405894394637367
[2019-03-26 19:08:20,120] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7845.3565 3165277058.1310 1778.0000
[2019-03-26 19:08:20,351] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8613.8101 2780900037.9315 934.0000
[2019-03-26 19:08:20,409] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8219.3020 2928638013.1037 1339.0000
[2019-03-26 19:08:20,426] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7969.2459 3008997731.0004 1766.0000
[2019-03-26 19:08:20,496] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8465.3408 2843558243.3889 1130.0000
[2019-03-26 19:08:21,511] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 25000, evaluation results [25000.0, 7845.356539077429, 3165277058.131015, 1778.0, 8219.301960020453, 2928638013.1036763, 1339.0, 8613.810081958865, 2780900037.9314685, 934.0, 7969.245858049016, 3008997731.0004463, 1766.0, 8465.340803819327, 2843558243.388918, 1130.0]
[2019-03-26 19:08:22,750] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.6032981e-04 9.9492574e-01 3.6757160e-03 8.2464778e-04 3.1355055e-04], sum to 1.0000
[2019-03-26 19:08:22,755] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0754
[2019-03-26 19:08:22,855] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 92.66666666666667, 1.0, 2.0, 0.3313461095703727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 514104.4202601747, 514104.4202601747, 167854.2908459639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 966000.0000, 
sim time next is 966600.0000, 
raw observation next is [21.9, 92.5, 1.0, 2.0, 0.3266065538592764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 507045.1089431385, 507045.1089431385, 167315.7245968776], 
processed observation next is [1.0, 0.17391304347826086, 0.23696682464454974, 0.925, 1.0, 1.0, 0.18868259501117637, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14084586359531626, 0.14084586359531626, 0.24972496208489195], 
reward next is 0.7503, 
noisyNet noise sample is [array([1.4470477], dtype=float32), -0.7911643]. 
=============================================
[2019-03-26 19:08:30,328] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8432173e-06 9.9992239e-01 4.0954859e-05 2.6476609e-05 8.3807299e-06], sum to 1.0000
[2019-03-26 19:08:30,336] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3978
[2019-03-26 19:08:30,343] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 89.5, 1.0, 2.0, 0.2928451233047513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 469547.5094624624, 469547.5094624631, 164921.6273135842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1125000.0000, 
sim time next is 1125600.0000, 
raw observation next is [20.86666666666667, 89.66666666666667, 1.0, 2.0, 0.292297394789205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 468788.9812294227, 468788.9812294221, 164869.7039335522], 
processed observation next is [1.0, 0.0, 0.18799368088467638, 0.8966666666666667, 1.0, 1.0, 0.14734625878217472, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13021916145261742, 0.13021916145261725, 0.24607418497545105], 
reward next is 0.7539, 
noisyNet noise sample is [array([0.4067587], dtype=float32), -0.9143302]. 
=============================================
[2019-03-26 19:08:31,856] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2476008e-06 9.9993849e-01 3.8355742e-05 1.7107564e-05 3.6419488e-06], sum to 1.0000
[2019-03-26 19:08:31,866] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8157
[2019-03-26 19:08:31,874] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.95, 75.5, 1.0, 2.0, 0.6276188675638236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 981068.4198427381, 981068.4198427381, 218421.2473973475], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1157400.0000, 
sim time next is 1158000.0000, 
raw observation next is [24.13333333333333, 74.66666666666667, 1.0, 2.0, 0.6905006168336422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1077805.185289239, 1077805.185289239, 232630.4473362391], 
processed observation next is [1.0, 0.391304347826087, 0.3428120063191152, 0.7466666666666667, 1.0, 1.0, 0.6271091769080026, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.29939032924701087, 0.29939032924701087, 0.3472096228899091], 
reward next is 0.6528, 
noisyNet noise sample is [array([-2.0621781], dtype=float32), 1.8269966]. 
=============================================
[2019-03-26 19:08:31,883] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[20.30212 ]
 [20.227592]
 [20.126377]
 [20.00479 ]
 [19.899727]], R is [[20.87117195]
 [21.33645821]
 [21.80268097]
 [22.25635147]
 [22.68859291]].
[2019-03-26 19:08:33,507] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31808: loss 2.5735
[2019-03-26 19:08:33,511] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 31808: learning rate 0.0000
[2019-03-26 19:08:33,569] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 31841: loss 2.5324
[2019-03-26 19:08:33,570] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 31841: learning rate 0.0000
[2019-03-26 19:08:33,651] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 31880: loss 2.6929
[2019-03-26 19:08:33,652] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 31880: learning rate 0.0000
[2019-03-26 19:08:33,681] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 31900: loss 2.5212
[2019-03-26 19:08:33,683] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 31900: learning rate 0.0000
[2019-03-26 19:08:33,755] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 31937: loss 2.6226
[2019-03-26 19:08:33,760] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 31937: learning rate 0.0000
[2019-03-26 19:08:33,767] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 31942: loss 2.6269
[2019-03-26 19:08:33,770] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 31943: learning rate 0.0000
[2019-03-26 19:08:33,777] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 31947: loss 2.5837
[2019-03-26 19:08:33,779] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 31947: learning rate 0.0000
[2019-03-26 19:08:33,811] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 31966: loss 2.6512
[2019-03-26 19:08:33,813] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 31968: learning rate 0.0000
[2019-03-26 19:08:33,832] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 31980: loss 2.5556
[2019-03-26 19:08:33,834] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 31981: learning rate 0.0000
[2019-03-26 19:08:33,851] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 31995: loss 2.5969
[2019-03-26 19:08:33,852] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 31995: learning rate 0.0000
[2019-03-26 19:08:33,875] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 32005: loss 2.5890
[2019-03-26 19:08:33,876] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 32006: learning rate 0.0000
[2019-03-26 19:08:33,897] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 32017: loss 2.6136
[2019-03-26 19:08:33,899] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 32019: learning rate 0.0000
[2019-03-26 19:08:34,008] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 32081: loss 2.6087
[2019-03-26 19:08:34,010] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 32081: learning rate 0.0000
[2019-03-26 19:08:34,020] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1150008e-07 9.9997330e-01 1.8250157e-05 6.8886370e-06 1.3269821e-06], sum to 1.0000
[2019-03-26 19:08:34,027] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2182
[2019-03-26 19:08:34,032] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 87.0, 1.0, 2.0, 0.3565731776975517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 549146.8796949072, 549146.8796949066, 170571.0982558838], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1206000.0000, 
sim time next is 1206600.0000, 
raw observation next is [22.85, 87.16666666666667, 1.0, 2.0, 0.3557153872458308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 548072.2460944823, 548072.2460944816, 170488.2475067229], 
processed observation next is [1.0, 1.0, 0.28199052132701435, 0.8716666666666667, 1.0, 1.0, 0.22375347860943468, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15224229058180064, 0.15224229058180044, 0.25446007090555656], 
reward next is 0.7455, 
noisyNet noise sample is [array([0.657558], dtype=float32), -0.07758926]. 
=============================================
[2019-03-26 19:08:34,052] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 32102: loss 2.5218
[2019-03-26 19:08:34,053] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 32102: learning rate 0.0000
[2019-03-26 19:08:34,141] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 32149: loss 2.5470
[2019-03-26 19:08:34,143] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 32149: learning rate 0.0000
[2019-03-26 19:08:34,310] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 32257: loss 2.4523
[2019-03-26 19:08:34,314] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 32260: learning rate 0.0000
[2019-03-26 19:08:35,060] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4565509e-06 9.9985743e-01 1.1146855e-04 2.1652859e-05 7.9913434e-06], sum to 1.0000
[2019-03-26 19:08:35,068] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1286
[2019-03-26 19:08:35,072] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 94.0, 1.0, 2.0, 0.3523946565407417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 547468.391229226, 547468.3912292254, 170556.3222392198], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1225800.0000, 
sim time next is 1226400.0000, 
raw observation next is [21.66666666666667, 94.33333333333333, 1.0, 2.0, 0.3556166477422023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 552366.4180396085, 552366.4180396092, 170960.6782596908], 
processed observation next is [1.0, 0.17391304347826086, 0.22590837282780438, 0.9433333333333332, 1.0, 1.0, 0.22363451535205098, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15343511612211347, 0.15343511612211366, 0.2551651914323743], 
reward next is 0.7448, 
noisyNet noise sample is [array([1.2342368], dtype=float32), -0.68451846]. 
=============================================
[2019-03-26 19:08:40,142] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8933396e-07 9.9998009e-01 1.3982917e-05 5.1928741e-06 5.2624381e-07], sum to 1.0000
[2019-03-26 19:08:40,151] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9471
[2019-03-26 19:08:40,254] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.53333333333333, 91.66666666666667, 1.0, 2.0, 0.5137428404186826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730800.3274593552, 730800.3274593552, 187428.4019170274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1311600.0000, 
sim time next is 1312200.0000, 
raw observation next is [24.55, 91.5, 1.0, 2.0, 0.5153362958853872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733246.0981006918, 733246.0981006911, 187712.6272447009], 
processed observation next is [1.0, 0.17391304347826086, 0.3625592417061612, 0.915, 1.0, 1.0, 0.4160678263679364, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2036794716946366, 0.2036794716946364, 0.2801681003652252], 
reward next is 0.7198, 
noisyNet noise sample is [array([0.05181984], dtype=float32), 0.4107741]. 
=============================================
[2019-03-26 19:08:40,481] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.2417091e-07 9.9998546e-01 8.0940936e-06 5.0037520e-06 1.0443658e-06], sum to 1.0000
[2019-03-26 19:08:40,492] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3900
[2019-03-26 19:08:40,499] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 91.0, 1.0, 2.0, 0.4899368075859202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 697606.7093396898, 697606.7093396892, 183697.8037423817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1314000.0000, 
sim time next is 1314600.0000, 
raw observation next is [24.51666666666667, 91.33333333333334, 1.0, 2.0, 0.4829092636687409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 688431.9385824759, 688431.9385824759, 182708.3712056043], 
processed observation next is [1.0, 0.21739130434782608, 0.36097946287519767, 0.9133333333333334, 1.0, 1.0, 0.37699911285390464, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19123109405068775, 0.19123109405068775, 0.2726990615009019], 
reward next is 0.7273, 
noisyNet noise sample is [array([0.27884427], dtype=float32), 1.178482]. 
=============================================
[2019-03-26 19:08:42,801] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.92528553e-08 9.99997616e-01 1.53153110e-06 7.08139964e-07
 1.14736515e-07], sum to 1.0000
[2019-03-26 19:08:42,809] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5626
[2019-03-26 19:08:42,820] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 91.0, 1.0, 2.0, 0.7091606161431733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1130087.578516714, 1130087.578516714, 239288.0164668727], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1353600.0000, 
sim time next is 1354200.0000, 
raw observation next is [20.96666666666667, 91.16666666666667, 1.0, 2.0, 0.6389362483018863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1018434.12291141, 1018434.122911409, 222670.5488732789], 
processed observation next is [1.0, 0.6956521739130435, 0.1927330173775673, 0.9116666666666667, 1.0, 1.0, 0.5649834316890197, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2828983674753917, 0.2828983674753914, 0.3323441027959386], 
reward next is 0.6677, 
noisyNet noise sample is [array([1.0233693], dtype=float32), 0.7451691]. 
=============================================
[2019-03-26 19:08:44,737] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.1893270e-08 9.9999404e-01 2.5111233e-06 2.8735583e-06 5.1555253e-07], sum to 1.0000
[2019-03-26 19:08:44,749] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3441
[2019-03-26 19:08:44,756] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 97.5, 1.0, 2.0, 0.3068023820804128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 488327.5231009396, 488327.5231009396, 166219.2769416711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1387800.0000, 
sim time next is 1388400.0000, 
raw observation next is [20.26666666666667, 97.66666666666666, 1.0, 2.0, 0.3058459772450906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 486958.926968225, 486958.9269682244, 166122.0727794527], 
processed observation next is [0.0, 0.043478260869565216, 0.15955766192733034, 0.9766666666666666, 1.0, 1.0, 0.1636698521025188, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13526636860228472, 0.13526636860228455, 0.24794339220813835], 
reward next is 0.7521, 
noisyNet noise sample is [array([0.70989907], dtype=float32), 1.3559415]. 
=============================================
[2019-03-26 19:08:45,202] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.6540375e-08 9.9998713e-01 7.3450701e-06 4.8547577e-06 5.8223679e-07], sum to 1.0000
[2019-03-26 19:08:45,211] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5959
[2019-03-26 19:08:45,217] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 98.0, 1.0, 2.0, 0.3077453330171429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 488643.4134052232, 488643.4134052238, 166223.5209646378], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1394400.0000, 
sim time next is 1395000.0000, 
raw observation next is [20.4, 98.0, 1.0, 2.0, 0.3099197336711298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 491720.4763980514, 491720.4763980507, 166442.265502585], 
processed observation next is [0.0, 0.13043478260869565, 0.16587677725118483, 0.98, 1.0, 1.0, 0.16857799237485516, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13658902122168096, 0.13658902122168076, 0.248421291794903], 
reward next is 0.7516, 
noisyNet noise sample is [array([-1.2343343], dtype=float32), 0.63542604]. 
=============================================
[2019-03-26 19:08:45,232] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[25.1558  ]
 [25.454561]
 [25.577265]
 [25.802446]
 [26.034842]], R is [[25.58180809]
 [26.07789612]
 [26.56918335]
 [27.05568314]
 [27.53734589]].
[2019-03-26 19:08:48,275] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3410916e-08 9.9999726e-01 1.0817951e-06 1.3004229e-06 3.4558943e-07], sum to 1.0000
[2019-03-26 19:08:48,289] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8179
[2019-03-26 19:08:48,294] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.35, 74.83333333333333, 1.0, 2.0, 0.4201252165336955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 612031.5313201292, 612031.5313201298, 175240.9820735452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1446600.0000, 
sim time next is 1447200.0000, 
raw observation next is [26.1, 76.0, 1.0, 2.0, 0.4176003942456843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 609794.8782963161, 609794.8782963167, 175070.5709150185], 
processed observation next is [0.0, 0.782608695652174, 0.4360189573459717, 0.76, 1.0, 1.0, 0.2983137280068485, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16938746619342115, 0.16938746619342132, 0.2612993595746545], 
reward next is 0.7387, 
noisyNet noise sample is [array([-1.636092], dtype=float32), 1.2319255]. 
=============================================
[2019-03-26 19:08:51,065] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 39794: loss 3.5272
[2019-03-26 19:08:51,068] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 39795: learning rate 0.0000
[2019-03-26 19:08:51,080] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 39799: loss 3.6126
[2019-03-26 19:08:51,081] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 39800: learning rate 0.0000
[2019-03-26 19:08:51,294] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39894: loss 3.5664
[2019-03-26 19:08:51,297] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 39894: learning rate 0.0000
[2019-03-26 19:08:51,323] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 39904: loss 3.5902
[2019-03-26 19:08:51,326] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 39904: learning rate 0.0000
[2019-03-26 19:08:51,353] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 39917: loss 3.5446
[2019-03-26 19:08:51,357] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 39919: learning rate 0.0000
[2019-03-26 19:08:51,415] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 39948: loss 3.5424
[2019-03-26 19:08:51,419] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 39948: learning rate 0.0000
[2019-03-26 19:08:51,442] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39959: loss 3.5458
[2019-03-26 19:08:51,446] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 39960: learning rate 0.0000
[2019-03-26 19:08:51,456] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 39967: loss 3.5497
[2019-03-26 19:08:51,456] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 39967: loss 3.5576
[2019-03-26 19:08:51,457] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 39967: learning rate 0.0000
[2019-03-26 19:08:51,458] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 39967: learning rate 0.0000
[2019-03-26 19:08:51,542] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 40000: loss 3.6004
[2019-03-26 19:08:51,544] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 40000: learning rate 0.0000
[2019-03-26 19:08:51,561] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 40008: loss 3.5517
[2019-03-26 19:08:51,566] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 40012: learning rate 0.0000
[2019-03-26 19:08:51,578] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 40019: loss 3.5997
[2019-03-26 19:08:51,580] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 40019: learning rate 0.0000
[2019-03-26 19:08:51,723] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 40081: loss 3.5525
[2019-03-26 19:08:51,725] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 40081: learning rate 0.0000
[2019-03-26 19:08:51,799] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 40117: loss 3.5297
[2019-03-26 19:08:51,801] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 40117: learning rate 0.0000
[2019-03-26 19:08:51,855] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 40139: loss 3.5028
[2019-03-26 19:08:51,857] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 40140: learning rate 0.0000
[2019-03-26 19:08:52,127] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 40260: loss 3.6193
[2019-03-26 19:08:52,130] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 40261: learning rate 0.0000
[2019-03-26 19:09:02,226] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.7993644e-11 1.0000000e+00 5.4484300e-08 2.6352867e-08 2.2727678e-09], sum to 1.0000
[2019-03-26 19:09:02,240] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4573
[2019-03-26 19:09:02,246] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.43333333333333, 90.0, 1.0, 2.0, 0.9086910339732761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1270096.036179465, 1270096.036179465, 272336.1166628831], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1678800.0000, 
sim time next is 1679400.0000, 
raw observation next is [25.55, 89.5, 1.0, 2.0, 0.9582083846393582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1339351.106769004, 1339351.106769004, 286447.7388908998], 
processed observation next is [1.0, 0.43478260869565216, 0.40995260663507116, 0.895, 1.0, 1.0, 0.9496486561919978, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.37204197410250106, 0.37204197410250106, 0.42753393864313405], 
reward next is 0.5725, 
noisyNet noise sample is [array([1.4319698], dtype=float32), 1.8376054]. 
=============================================
[2019-03-26 19:09:06,582] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.5627058e-11 1.0000000e+00 8.2024609e-09 1.5128928e-09 4.1621578e-10], sum to 1.0000
[2019-03-26 19:09:06,589] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0137
[2019-03-26 19:09:06,598] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.15, 89.33333333333333, 1.0, 2.0, 0.4664865109814356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 654881.2491352783, 654881.2491352777, 178906.5591946662], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1756200.0000, 
sim time next is 1756800.0000, 
raw observation next is [25.2, 89.0, 1.0, 2.0, 0.5579299271410525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 783100.424087762, 783100.424087762, 193610.5593701128], 
processed observation next is [1.0, 0.34782608695652173, 0.3933649289099526, 0.89, 1.0, 1.0, 0.46738545438681023, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2175278955799339, 0.2175278955799339, 0.28897098413449673], 
reward next is 0.7110, 
noisyNet noise sample is [array([1.484673], dtype=float32), 0.6885005]. 
=============================================
[2019-03-26 19:09:07,184] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4565112e-10 1.0000000e+00 4.5454794e-08 2.1340632e-08 9.8708663e-10], sum to 1.0000
[2019-03-26 19:09:07,192] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7817
[2019-03-26 19:09:07,300] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 89.66666666666666, 1.0, 2.0, 0.4630044367811743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 650127.7876267509, 650127.7876267516, 178412.4582639883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1755600.0000, 
sim time next is 1756200.0000, 
raw observation next is [25.15, 89.33333333333333, 1.0, 2.0, 0.4664865109814356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 654881.2491352783, 654881.2491352777, 178906.5591946662], 
processed observation next is [1.0, 0.30434782608695654, 0.3909952606635071, 0.8933333333333333, 1.0, 1.0, 0.357212663833055, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18191145809313286, 0.1819114580931327, 0.2670247152159197], 
reward next is 0.7330, 
noisyNet noise sample is [array([-0.24690257], dtype=float32), -0.34955016]. 
=============================================
[2019-03-26 19:09:08,873] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.5388164e-12 1.0000000e+00 7.3940414e-09 2.1268169e-09 1.4562028e-10], sum to 1.0000
[2019-03-26 19:09:08,886] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7266
[2019-03-26 19:09:08,891] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.85, 88.0, 1.0, 2.0, 0.3195953847722333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 504038.244491728, 504038.2444917274, 167301.682872369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1794600.0000, 
sim time next is 1795200.0000, 
raw observation next is [21.8, 88.33333333333333, 1.0, 2.0, 0.3178032969868665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 501301.812656998, 501301.8126569974, 167097.3435697311], 
processed observation next is [1.0, 0.782608695652174, 0.23222748815165886, 0.8833333333333333, 1.0, 1.0, 0.1780762614299596, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13925050351583276, 0.13925050351583262, 0.24939902025333002], 
reward next is 0.7506, 
noisyNet noise sample is [array([0.03101814], dtype=float32), 0.6684523]. 
=============================================
[2019-03-26 19:09:08,942] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 47792: loss 1.1268
[2019-03-26 19:09:08,946] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 47792: learning rate 0.0000
[2019-03-26 19:09:08,973] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 47806: loss 1.1108
[2019-03-26 19:09:08,977] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 47806: learning rate 0.0000
[2019-03-26 19:09:09,160] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 47890: loss 1.1683
[2019-03-26 19:09:09,161] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 47890: learning rate 0.0000
[2019-03-26 19:09:09,174] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 47894: loss 1.1102
[2019-03-26 19:09:09,178] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 47894: learning rate 0.0000
[2019-03-26 19:09:09,193] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 47904: loss 1.1357
[2019-03-26 19:09:09,194] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 47904: learning rate 0.0000
[2019-03-26 19:09:09,239] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 47923: loss 1.1589
[2019-03-26 19:09:09,243] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 47924: loss 1.1780
[2019-03-26 19:09:09,245] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 47925: learning rate 0.0000
[2019-03-26 19:09:09,245] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 47925: learning rate 0.0000
[2019-03-26 19:09:09,288] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 47945: loss 1.1384
[2019-03-26 19:09:09,296] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 47946: learning rate 0.0000
[2019-03-26 19:09:09,319] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 47957: loss 1.0690
[2019-03-26 19:09:09,321] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 47957: learning rate 0.0000
[2019-03-26 19:09:09,445] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 48015: loss 1.1911
[2019-03-26 19:09:09,449] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 48016: learning rate 0.0000
[2019-03-26 19:09:09,485] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.4010850e-11 1.0000000e+00 1.5660293e-08 1.0516270e-08 1.0233616e-10], sum to 1.0000
[2019-03-26 19:09:09,498] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4826
[2019-03-26 19:09:09,502] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 48042: loss 1.0130
[2019-03-26 19:09:09,504] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.43333333333333, 94.66666666666667, 1.0, 2.0, 0.3361926734803173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 525136.4967936483, 525136.4967936483, 168819.4305102034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1808400.0000, 
sim time next is 1809000.0000, 
raw observation next is [21.45, 95.0, 1.0, 2.0, 0.3386862032060498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 528242.5919976203, 528242.5919976203, 169046.6448126051], 
processed observation next is [1.0, 0.9565217391304348, 0.2156398104265403, 0.95, 1.0, 1.0, 0.2032363894048793, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1467340533326723, 0.1467340533326723, 0.2523084250934405], 
reward next is 0.7477, 
noisyNet noise sample is [array([-0.8468711], dtype=float32), -0.70662904]. 
=============================================
[2019-03-26 19:09:09,505] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 48042: learning rate 0.0000
[2019-03-26 19:09:09,522] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[41.574627]
 [41.519688]
 [41.46462 ]
 [41.445934]
 [41.51115 ]], R is [[41.95997238]
 [42.28840637]
 [42.6139183 ]
 [42.93632889]
 [43.25536346]].
[2019-03-26 19:09:09,585] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 48072: loss 1.0882
[2019-03-26 19:09:09,587] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 48073: learning rate 0.0000
[2019-03-26 19:09:09,612] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 48084: loss 1.0315
[2019-03-26 19:09:09,614] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 48086: learning rate 0.0000
[2019-03-26 19:09:09,737] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 48140: loss 1.0871
[2019-03-26 19:09:09,742] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 48141: learning rate 0.0000
[2019-03-26 19:09:09,856] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 48198: loss 1.1182
[2019-03-26 19:09:09,857] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 48199: learning rate 0.0000
[2019-03-26 19:09:09,884] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 48210: loss 1.0709
[2019-03-26 19:09:09,886] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 48211: learning rate 0.0000
[2019-03-26 19:09:12,418] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.5040846e-12 1.0000000e+00 1.8476308e-09 1.0861351e-09 1.2796810e-11], sum to 1.0000
[2019-03-26 19:09:12,430] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5478
[2019-03-26 19:09:12,439] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.25, 91.0, 1.0, 2.0, 0.8637238646207229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1248636.462475907, 1248636.462475906, 266115.14753887], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1848600.0000, 
sim time next is 1849200.0000, 
raw observation next is [24.36666666666667, 90.66666666666667, 1.0, 2.0, 0.8773852283162079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1264676.635659685, 1264676.635659684, 269362.8476898289], 
processed observation next is [1.0, 0.391304347826087, 0.3538704581358612, 0.9066666666666667, 1.0, 1.0, 0.852271359417118, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3512990654610236, 0.3512990654610233, 0.40203410102959536], 
reward next is 0.5980, 
noisyNet noise sample is [array([-0.04021373], dtype=float32), -1.0556904]. 
=============================================
[2019-03-26 19:09:12,542] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1701872e-11 1.0000000e+00 1.3296804e-08 2.0257296e-09 3.8326172e-11], sum to 1.0000
[2019-03-26 19:09:12,551] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6312
[2019-03-26 19:09:12,556] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.36666666666667, 90.66666666666667, 1.0, 2.0, 0.8773852283162079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1264676.635659685, 1264676.635659684, 269362.8476898289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1849200.0000, 
sim time next is 1849800.0000, 
raw observation next is [24.48333333333333, 90.33333333333333, 1.0, 2.0, 0.8876414164202816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1275697.956631741, 1275697.956631741, 271685.1948351348], 
processed observation next is [1.0, 0.391304347826087, 0.3593996840442337, 0.9033333333333333, 1.0, 1.0, 0.8646282125545561, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.35436054350881696, 0.35436054350881696, 0.40550029079870864], 
reward next is 0.5945, 
noisyNet noise sample is [array([0.9127766], dtype=float32), -0.08622866]. 
=============================================
[2019-03-26 19:09:13,884] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 19:09:13,887] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:09:13,888] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:09:13,889] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:09:13,889] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:09:13,890] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:09:13,891] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:09:13,891] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:09:13,893] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:09:13,894] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:09:13,895] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:09:13,909] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run3
[2019-03-26 19:09:13,926] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run3
[2019-03-26 19:09:13,944] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run3
[2019-03-26 19:09:13,945] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run3
[2019-03-26 19:09:13,980] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run3
[2019-03-26 19:09:23,253] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03055709], dtype=float32), 0.039423596]
[2019-03-26 19:09:23,254] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.03333333333333, 69.5, 1.0, 2.0, 0.253045115210523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 415820.7852035931, 415820.7852035924, 161210.9314993903]
[2019-03-26 19:09:23,256] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:09:23,260] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.8287128e-11 1.0000000e+00 9.2631565e-09 8.1038847e-09 4.5868609e-10], sampled 0.6284861864743193
[2019-03-26 19:09:34,837] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03055709], dtype=float32), 0.039423596]
[2019-03-26 19:09:34,838] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [17.56577737, 100.0, 1.0, 2.0, 0.2535471588811318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 418937.268631948, 418937.2686319486, 161192.0512370615]
[2019-03-26 19:09:34,841] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:09:34,845] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.7551528e-10 1.0000000e+00 4.4384137e-08 4.1140009e-08 1.9259614e-09], sampled 0.8620335810842847
[2019-03-26 19:10:19,492] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03055709], dtype=float32), 0.039423596]
[2019-03-26 19:10:19,494] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.23782091, 83.19318412, 1.0, 2.0, 0.5490734609019385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 767269.618707834, 767269.618707834, 191639.4508816759]
[2019-03-26 19:10:19,496] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:10:19,499] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.2484080e-11 1.0000000e+00 1.4247822e-08 1.3019514e-08 7.1494538e-10], sampled 0.6689278507839538
[2019-03-26 19:11:01,225] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03055709], dtype=float32), 0.039423596]
[2019-03-26 19:11:01,226] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.66666666666667, 87.0, 1.0, 2.0, 0.2817976931909142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 456471.5194258331, 456471.5194258331, 164021.1520503433]
[2019-03-26 19:11:01,227] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:11:01,230] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.8819942e-11 1.0000000e+00 6.3624013e-09 5.1384248e-09 2.7282043e-10], sampled 0.05065066771279958
[2019-03-26 19:11:08,171] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.0653 2927317329.7462 1338.0000
[2019-03-26 19:11:08,331] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8335 2842452168.1498 1131.0000
[2019-03-26 19:11:08,481] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.8889 2779256332.3854 933.0000
[2019-03-26 19:11:08,482] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7995.3168 3007810081.4350 1766.0000
[2019-03-26 19:11:08,534] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.9141 3164158593.5985 1778.0000
[2019-03-26 19:11:09,548] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 50000, evaluation results [50000.0, 7881.914089779894, 3164158593.5985365, 1778.0, 8255.065342017213, 2927317329.746172, 1338.0, 8659.888853383243, 2779256332.3854055, 933.0, 7995.316824600767, 3007810081.435039, 1766.0, 8496.833495916873, 2842452168.149761, 1131.0]
[2019-03-26 19:11:11,209] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.3290095e-13 1.0000000e+00 1.7760690e-10 2.3174691e-10 9.5975016e-12], sum to 1.0000
[2019-03-26 19:11:11,219] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2167
[2019-03-26 19:11:11,222] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 95.0, 1.0, 2.0, 0.4625432617026303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 652647.5764196299, 652647.5764196299, 178752.9072299544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1904400.0000, 
sim time next is 1905000.0000, 
raw observation next is [24.28333333333333, 95.16666666666667, 1.0, 2.0, 0.463167910437884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 653043.0560201956, 653043.0560201956, 178782.3635346329], 
processed observation next is [1.0, 0.043478260869565216, 0.34992101105845175, 0.9516666666666667, 1.0, 1.0, 0.3532143499251615, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18140084889449878, 0.18140084889449878, 0.2668393485591536], 
reward next is 0.7332, 
noisyNet noise sample is [array([0.55186695], dtype=float32), -0.8516756]. 
=============================================
[2019-03-26 19:11:11,229] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[45.233574]
 [45.358173]
 [45.514557]
 [45.72231 ]
 [45.89965 ]], R is [[45.29293442]
 [45.57320786]
 [45.85083008]
 [46.12592316]
 [46.39864731]].
[2019-03-26 19:11:11,906] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.4733522e-12 1.0000000e+00 5.0767008e-09 1.5237119e-09 5.3608423e-11], sum to 1.0000
[2019-03-26 19:11:11,915] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4351
[2019-03-26 19:11:12,036] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.68333333333333, 87.5, 1.0, 2.0, 0.4242001502744097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 614077.919594889, 614077.9195948885, 175322.9939811042], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1925400.0000, 
sim time next is 1926000.0000, 
raw observation next is [24.8, 87.0, 1.0, 2.0, 0.4274254435734332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 617571.7663213384, 617571.7663213384, 175626.4153832308], 
processed observation next is [1.0, 0.30434782608695654, 0.3744075829383887, 0.87, 1.0, 1.0, 0.31015113683546175, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17154771286703843, 0.17154771286703843, 0.26212897818392655], 
reward next is 0.7379, 
noisyNet noise sample is [array([-1.257782], dtype=float32), 0.97636074]. 
=============================================
[2019-03-26 19:11:12,049] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[43.31497 ]
 [43.320732]
 [43.32249 ]
 [43.309456]
 [43.310898]], R is [[43.55079269]
 [43.85360718]
 [44.15371323]
 [44.45090485]
 [44.74451065]].
[2019-03-26 19:11:13,315] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1825264e-13 1.0000000e+00 6.6603223e-11 2.8640951e-10 1.2464017e-11], sum to 1.0000
[2019-03-26 19:11:13,321] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2778
[2019-03-26 19:11:13,330] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1761181.771013905 W.
[2019-03-26 19:11:13,337] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.73333333333333, 77.33333333333334, 1.0, 2.0, 0.6298737005094822, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.932776970644581, 6.9112, 168.9128066346003, 1761181.771013905, 1745874.338998861, 371737.5165412119], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1943400.0000, 
sim time next is 1944000.0000, 
raw observation next is [26.8, 77.0, 1.0, 2.0, 0.6332061098174978, 1.0, 1.0, 0.6332061098174978, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1770493.010228548, 1770493.010228548, 346827.0876358328], 
processed observation next is [1.0, 0.5217391304347826, 0.4691943127962086, 0.77, 1.0, 1.0, 0.5580796503825275, 1.0, 0.5, 0.5580796503825275, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.49180361395237443, 0.49180361395237443, 0.5176523696057206], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2726012], dtype=float32), -0.34002793]. 
=============================================
[2019-03-26 19:11:13,353] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[47.503654]
 [47.4247  ]
 [47.353397]
 [47.75909 ]
 [47.66959 ]], R is [[47.15209198]
 [46.68057251]
 [46.21376801]
 [45.75162888]
 [45.29411316]].
[2019-03-26 19:11:21,599] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 55726: loss 1.6212
[2019-03-26 19:11:21,608] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 55727: learning rate 0.0000
[2019-03-26 19:11:21,625] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 55735: loss 1.5508
[2019-03-26 19:11:21,627] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 55735: learning rate 0.0000
[2019-03-26 19:11:21,846] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 55834: loss 1.6689
[2019-03-26 19:11:21,848] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 55834: learning rate 0.0000
[2019-03-26 19:11:21,963] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 55888: loss 1.7072
[2019-03-26 19:11:21,966] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 55889: learning rate 0.0000
[2019-03-26 19:11:22,039] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 55920: loss 1.6470
[2019-03-26 19:11:22,042] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 55921: learning rate 0.0000
[2019-03-26 19:11:22,050] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 55924: loss 1.6890
[2019-03-26 19:11:22,054] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 55924: learning rate 0.0000
[2019-03-26 19:11:22,087] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 55940: loss 1.6739
[2019-03-26 19:11:22,088] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 55940: learning rate 0.0000
[2019-03-26 19:11:22,090] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 55940: loss 1.6596
[2019-03-26 19:11:22,095] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 55940: learning rate 0.0000
[2019-03-26 19:11:22,174] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 55982: loss 1.6639
[2019-03-26 19:11:22,176] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 55982: learning rate 0.0000
[2019-03-26 19:11:22,257] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 56012: loss 1.5700
[2019-03-26 19:11:22,260] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 56015: learning rate 0.0000
[2019-03-26 19:11:22,382] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 56070: loss 1.6349
[2019-03-26 19:11:22,385] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 56071: learning rate 0.0000
[2019-03-26 19:11:22,413] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 56084: loss 1.5481
[2019-03-26 19:11:22,416] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 56085: learning rate 0.0000
[2019-03-26 19:11:22,482] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 56112: loss 1.5886
[2019-03-26 19:11:22,486] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 56113: learning rate 0.0000
[2019-03-26 19:11:22,542] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 56141: loss 1.5161
[2019-03-26 19:11:22,543] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 56141: learning rate 0.0000
[2019-03-26 19:11:22,735] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 56229: loss 1.6409
[2019-03-26 19:11:22,737] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 56229: learning rate 0.0000
[2019-03-26 19:11:22,763] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 56238: loss 1.5381
[2019-03-26 19:11:22,772] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 56239: learning rate 0.0000
[2019-03-26 19:11:28,957] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1684597e-13 1.0000000e+00 3.0539973e-11 1.1560563e-10 3.2549123e-13], sum to 1.0000
[2019-03-26 19:11:28,962] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5810
[2019-03-26 19:11:28,972] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2396024.631874281 W.
[2019-03-26 19:11:28,976] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.95, 66.5, 1.0, 2.0, 0.5711228402370171, 1.0, 1.0, 0.5711228402370171, 1.0, 2.0, 0.9918515002822804, 6.9112, 6.9112, 170.5573041426782, 2396024.631874281, 2396024.631874281, 467812.8072981542], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2215800.0000, 
sim time next is 2216400.0000, 
raw observation next is [31.93333333333333, 66.66666666666667, 1.0, 2.0, 0.5790467927138014, 1.0, 2.0, 0.5790467927138014, 1.0, 2.0, 1.005612785243327, 6.9112, 6.9112, 170.5573041426782, 2429300.205697396, 2429300.205697396, 474111.4863450146], 
processed observation next is [1.0, 0.6521739130434783, 0.7124802527646128, 0.6666666666666667, 1.0, 1.0, 0.4928274611009656, 1.0, 1.0, 0.4928274611009656, 1.0, 1.0, 1.0068448600528377, 0.0, 0.0, 0.8375144448122397, 0.6748056126937211, 0.6748056126937211, 0.7076290840970367], 
reward next is 0.2924, 
noisyNet noise sample is [array([0.98815185], dtype=float32), 1.3416663]. 
=============================================
[2019-03-26 19:11:30,245] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.6438256e-14 1.0000000e+00 3.6966766e-11 6.2443202e-12 2.0352720e-13], sum to 1.0000
[2019-03-26 19:11:30,252] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0661
[2019-03-26 19:11:30,259] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 82.33333333333334, 1.0, 2.0, 0.5445081688488133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 760887.8415388272, 760887.8415388279, 190863.5972684024], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2236200.0000, 
sim time next is 2236800.0000, 
raw observation next is [28.2, 82.66666666666667, 1.0, 2.0, 0.5433030048505412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 759203.1609540338, 759203.1609540345, 190659.0467544961], 
processed observation next is [1.0, 0.9130434782608695, 0.5355450236966824, 0.8266666666666667, 1.0, 1.0, 0.4497626564464351, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21088976693167608, 0.21088976693167627, 0.28456574142462104], 
reward next is 0.7154, 
noisyNet noise sample is [array([0.54126215], dtype=float32), 1.192624]. 
=============================================
[2019-03-26 19:11:36,289] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3714112e-14 1.0000000e+00 1.4992951e-11 1.9494167e-11 6.6645562e-14], sum to 1.0000
[2019-03-26 19:11:36,297] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0597
[2019-03-26 19:11:36,303] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.1, 81.0, 1.0, 2.0, 0.5344076175475718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 746768.5157886085, 746768.5157886085, 189162.5425645207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2336400.0000, 
sim time next is 2337000.0000, 
raw observation next is [28.05, 81.0, 1.0, 2.0, 0.5323853369376412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 743941.6393067535, 743941.6393067541, 188825.6811382481], 
processed observation next is [1.0, 0.043478260869565216, 0.528436018957346, 0.81, 1.0, 1.0, 0.43660883968390507, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2066504553629871, 0.20665045536298726, 0.28182937483320614], 
reward next is 0.7182, 
noisyNet noise sample is [array([0.47535133], dtype=float32), -2.3643458]. 
=============================================
[2019-03-26 19:11:36,320] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[56.606304]
 [56.79956 ]
 [57.01548 ]
 [57.28782 ]
 [57.507477]], R is [[56.46939468]
 [56.62236786]
 [56.77349091]
 [56.92274094]
 [57.07010269]].
[2019-03-26 19:11:39,397] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 63716: loss 2.2832
[2019-03-26 19:11:39,398] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 63717: learning rate 0.0000
[2019-03-26 19:11:39,439] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 63736: loss 2.5906
[2019-03-26 19:11:39,440] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 63737: learning rate 0.0000
[2019-03-26 19:11:39,640] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 63822: loss 2.4102
[2019-03-26 19:11:39,641] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 63823: learning rate 0.0000
[2019-03-26 19:11:39,792] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 63889: loss 2.1074
[2019-03-26 19:11:39,794] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 63891: learning rate 0.0000
[2019-03-26 19:11:39,833] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 63907: loss 1.8187
[2019-03-26 19:11:39,835] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 63907: learning rate 0.0000
[2019-03-26 19:11:39,870] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 63923: loss 0.9182
[2019-03-26 19:11:39,872] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 63924: learning rate 0.0000
[2019-03-26 19:11:39,902] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 63939: loss 1.4725
[2019-03-26 19:11:39,905] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 63940: learning rate 0.0000
[2019-03-26 19:11:39,952] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 63959: loss 1.3215
[2019-03-26 19:11:39,954] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 63959: learning rate 0.0000
[2019-03-26 19:11:39,981] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 63972: loss 2.1238
[2019-03-26 19:11:39,982] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 63972: learning rate 0.0000
[2019-03-26 19:11:40,014] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 63984: loss 0.7484
[2019-03-26 19:11:40,018] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 63985: learning rate 0.0000
[2019-03-26 19:11:40,225] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 64082: loss 0.6501
[2019-03-26 19:11:40,226] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 64082: learning rate 0.0000
[2019-03-26 19:11:40,247] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 64089: loss 1.5752
[2019-03-26 19:11:40,253] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 64090: learning rate 0.0000
[2019-03-26 19:11:40,383] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 64152: loss 1.5021
[2019-03-26 19:11:40,386] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 64152: learning rate 0.0000
[2019-03-26 19:11:40,421] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 64166: loss 0.4082
[2019-03-26 19:11:40,423] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 64166: learning rate 0.0000
[2019-03-26 19:11:40,694] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 64291: loss 1.1496
[2019-03-26 19:11:40,700] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 64291: learning rate 0.0000
[2019-03-26 19:11:40,764] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 64324: loss 1.8430
[2019-03-26 19:11:40,767] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 64324: learning rate 0.0000
[2019-03-26 19:11:41,061] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.9781521e-15 1.0000000e+00 1.2866487e-11 1.0215007e-11 1.5103987e-13], sum to 1.0000
[2019-03-26 19:11:41,072] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5848
[2019-03-26 19:11:41,075] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 77.33333333333334, 1.0, 2.0, 0.5780193806038082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 807733.7294120664, 807733.729412067, 196722.4401446359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2410800.0000, 
sim time next is 2411400.0000, 
raw observation next is [29.9, 77.66666666666666, 1.0, 2.0, 0.5762160637791944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 805212.7898215837, 805212.7898215842, 196398.7064164983], 
processed observation next is [1.0, 0.9130434782608695, 0.6161137440758293, 0.7766666666666666, 1.0, 1.0, 0.48941694431228244, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22367021939488435, 0.22367021939488452, 0.2931323976365646], 
reward next is 0.7069, 
noisyNet noise sample is [array([-0.54684377], dtype=float32), -1.1404568]. 
=============================================
[2019-03-26 19:11:41,701] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9391395e-16 1.0000000e+00 1.6633513e-12 2.5763228e-12 2.3326888e-14], sum to 1.0000
[2019-03-26 19:11:41,711] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7595
[2019-03-26 19:11:41,716] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.9, 80.0, 1.0, 2.0, 0.5547100137790519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 775148.9538129104, 775148.9538129104, 192611.8932705215], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2421600.0000, 
sim time next is 2422200.0000, 
raw observation next is [28.85, 80.0, 1.0, 2.0, 0.5530945427769307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 772890.6815433354, 772890.681543336, 192332.9599338659], 
processed observation next is [1.0, 0.0, 0.5663507109004741, 0.8, 1.0, 1.0, 0.4615596900926876, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21469185598425986, 0.21469185598426, 0.28706411930427744], 
reward next is 0.7129, 
noisyNet noise sample is [array([1.4361565], dtype=float32), -0.12470704]. 
=============================================
[2019-03-26 19:11:42,170] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.2634848e-15 1.0000000e+00 1.3059655e-12 1.8242157e-12 2.3306476e-14], sum to 1.0000
[2019-03-26 19:11:42,174] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0541
[2019-03-26 19:11:42,279] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.76666666666667, 80.0, 1.0, 2.0, 0.5502540305683199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 768919.9317527176, 768919.9317527176, 191844.3924685367], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2423400.0000, 
sim time next is 2424000.0000, 
raw observation next is [28.73333333333333, 80.0, 1.0, 2.0, 0.5487826762094897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 766863.1324832169, 766863.1324832164, 191592.2849676814], 
processed observation next is [1.0, 0.043478260869565216, 0.560821484992101, 0.8, 1.0, 1.0, 0.4563646701319153, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21301753680089358, 0.21301753680089344, 0.28595863428012147], 
reward next is 0.7140, 
noisyNet noise sample is [array([0.62126845], dtype=float32), 0.49092412]. 
=============================================
[2019-03-26 19:11:42,308] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[55.332336]
 [55.598362]
 [55.768047]
 [55.97591 ]
 [56.22657 ]], R is [[55.29698563]
 [55.45767975]
 [55.61641312]
 [55.77318573]
 [55.9279747 ]].
[2019-03-26 19:11:47,726] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.9835258e-15 1.0000000e+00 7.3040726e-11 6.1686767e-12 2.8727842e-13], sum to 1.0000
[2019-03-26 19:11:47,735] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7131
[2019-03-26 19:11:47,741] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 95.33333333333333, 1.0, 2.0, 0.7050951351341217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 985393.8444012653, 985393.8444012653, 221949.5710385862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2528400.0000, 
sim time next is 2529000.0000, 
raw observation next is [26.35, 95.0, 1.0, 2.0, 0.7298930664276032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1020066.420432293, 1020066.420432294, 227430.54580256], 
processed observation next is [1.0, 0.2608695652173913, 0.4478672985781992, 0.95, 1.0, 1.0, 0.6745699595513291, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2833517834534147, 0.283351783453415, 0.33944857582471644], 
reward next is 0.6606, 
noisyNet noise sample is [array([0.23932584], dtype=float32), -0.24327609]. 
=============================================
[2019-03-26 19:11:47,758] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[54.73582 ]
 [54.524864]
 [54.44263 ]
 [54.40882 ]
 [54.54895 ]], R is [[54.84028625]
 [54.96061707]
 [55.07760239]
 [55.20399857]
 [55.3086853 ]].
[2019-03-26 19:11:47,789] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.0133529e-14 1.0000000e+00 1.9509939e-11 8.0765594e-12 2.0029616e-13], sum to 1.0000
[2019-03-26 19:11:47,799] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0146
[2019-03-26 19:11:47,805] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.36666666666667, 94.66666666666666, 1.0, 2.0, 0.6889343645853419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 962798.393559916, 962798.393559916, 218475.4372980976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2529600.0000, 
sim time next is 2530200.0000, 
raw observation next is [26.38333333333333, 94.33333333333334, 1.0, 2.0, 0.6745944939554251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 942749.2668443718, 942749.2668443718, 215457.5680809156], 
processed observation next is [1.0, 0.2608695652173913, 0.44944707740916257, 0.9433333333333335, 1.0, 1.0, 0.6079451734402712, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.26187479634565886, 0.26187479634565886, 0.3215784598222621], 
reward next is 0.6784, 
noisyNet noise sample is [array([-0.95008415], dtype=float32), -0.3338085]. 
=============================================
[2019-03-26 19:11:53,145] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.4155849e-13 1.0000000e+00 2.3483404e-10 6.5956629e-10 1.7692146e-11], sum to 1.0000
[2019-03-26 19:11:53,153] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0967
[2019-03-26 19:11:53,157] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 86.5, 1.0, 2.0, 0.4660689571230514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 655977.7309307858, 655977.7309307863, 179061.9022285829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2619000.0000, 
sim time next is 2619600.0000, 
raw observation next is [25.66666666666666, 85.66666666666667, 1.0, 2.0, 0.4682794274503636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 657664.9178185721, 657664.9178185728, 179205.7604229623], 
processed observation next is [0.0, 0.30434782608695654, 0.4154818325434437, 0.8566666666666667, 1.0, 1.0, 0.35937280415706463, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18268469939404783, 0.18268469939404802, 0.26747128421337657], 
reward next is 0.7325, 
noisyNet noise sample is [array([-0.8717306], dtype=float32), 0.18629448]. 
=============================================
[2019-03-26 19:11:56,646] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.7007436e-13 1.0000000e+00 1.4162083e-10 1.8529306e-10 5.2955552e-12], sum to 1.0000
[2019-03-26 19:11:56,657] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7835
[2019-03-26 19:11:56,662] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 98.0, 1.0, 2.0, 0.4309244411845149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 623563.9284298284, 623563.9284298284, 176236.7602489321], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2683200.0000, 
sim time next is 2683800.0000, 
raw observation next is [23.5, 97.0, 1.0, 2.0, 0.4332689551429648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 625832.8628156359, 625832.8628156359, 176427.988253219], 
processed observation next is [0.0, 0.043478260869565216, 0.31279620853080575, 0.97, 1.0, 1.0, 0.3171915122204395, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1738424618932322, 0.1738424618932322, 0.2633253556018194], 
reward next is 0.7367, 
noisyNet noise sample is [array([0.23396145], dtype=float32), -0.95733327]. 
=============================================
[2019-03-26 19:11:57,331] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 71703: loss 1.5328
[2019-03-26 19:11:57,335] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 71705: learning rate 0.0000
[2019-03-26 19:11:57,354] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 71715: loss 1.4035
[2019-03-26 19:11:57,359] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 71716: learning rate 0.0000
[2019-03-26 19:11:57,540] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 71799: loss 1.4598
[2019-03-26 19:11:57,541] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 71800: learning rate 0.0000
[2019-03-26 19:11:57,599] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71822: loss 1.3866
[2019-03-26 19:11:57,601] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 71822: learning rate 0.0000
[2019-03-26 19:11:57,637] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 71838: loss 1.3878
[2019-03-26 19:11:57,638] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 71838: learning rate 0.0000
[2019-03-26 19:11:57,751] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 71892: loss 1.5013
[2019-03-26 19:11:57,753] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 71892: learning rate 0.0000
[2019-03-26 19:11:57,913] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 71967: loss 1.4345
[2019-03-26 19:11:57,917] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 71967: learning rate 0.0000
[2019-03-26 19:11:57,930] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 71975: loss 1.3927
[2019-03-26 19:11:57,932] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 71976: learning rate 0.0000
[2019-03-26 19:11:57,977] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 71992: loss 1.3798
[2019-03-26 19:11:57,981] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 71992: learning rate 0.0000
[2019-03-26 19:11:58,138] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 72067: loss 1.4670
[2019-03-26 19:11:58,140] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 72067: learning rate 0.0000
[2019-03-26 19:11:58,164] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 72076: loss 1.4017
[2019-03-26 19:11:58,166] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 72076: learning rate 0.0000
[2019-03-26 19:11:58,249] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 72116: loss 1.4001
[2019-03-26 19:11:58,250] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 72118: learning rate 0.0000
[2019-03-26 19:11:58,266] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 72126: loss 1.4242
[2019-03-26 19:11:58,268] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 72126: learning rate 0.0000
[2019-03-26 19:11:58,348] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 72157: loss 1.4773
[2019-03-26 19:11:58,349] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 72157: learning rate 0.0000
[2019-03-26 19:11:58,499] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 72228: loss 1.4012
[2019-03-26 19:11:58,505] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 72229: learning rate 0.0000
[2019-03-26 19:11:58,717] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 72325: loss 1.4020
[2019-03-26 19:11:58,721] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 72325: learning rate 0.0000
[2019-03-26 19:12:01,058] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1014492e-14 1.0000000e+00 3.7764743e-11 5.7117595e-11 7.4717158e-13], sum to 1.0000
[2019-03-26 19:12:01,069] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0732
[2019-03-26 19:12:01,077] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 95.0, 1.0, 2.0, 0.3911062162407326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 584174.1603886123, 584174.1603886123, 173103.7404002603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2747400.0000, 
sim time next is 2748000.0000, 
raw observation next is [22.66666666666667, 96.0, 1.0, 2.0, 0.3899526964879866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 583306.3079049023, 583306.3079049016, 173051.4434765129], 
processed observation next is [0.0, 0.8260869565217391, 0.27330173775671435, 0.96, 1.0, 1.0, 0.26500324878070675, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16202952997358397, 0.16202952997358377, 0.25828573653210884], 
reward next is 0.7417, 
noisyNet noise sample is [array([1.1143516], dtype=float32), -0.42511392]. 
=============================================
[2019-03-26 19:12:01,092] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[51.85147 ]
 [51.8022  ]
 [51.759758]
 [51.718555]
 [51.666943]], R is [[52.11964798]
 [52.34008789]
 [52.55818939]
 [52.77389526]
 [52.98734283]].
[2019-03-26 19:12:04,653] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 19:12:04,654] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:12:04,655] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:12:04,655] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:12:04,655] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:12:04,656] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:12:04,656] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:12:04,656] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:12:04,658] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:12:04,661] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:12:04,660] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:12:04,681] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run4
[2019-03-26 19:12:04,699] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run4
[2019-03-26 19:12:04,720] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run4
[2019-03-26 19:12:04,720] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run4
[2019-03-26 19:12:04,752] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run4
[2019-03-26 19:12:08,244] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04227491], dtype=float32), 0.050825693]
[2019-03-26 19:12:08,245] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [20.95, 76.5, 1.0, 2.0, 0.256774358388316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 422565.9762311082, 422565.9762311075, 161576.9304545495]
[2019-03-26 19:12:08,247] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:12:08,251] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.0732827e-12 1.0000000e+00 8.3351392e-10 6.3163541e-10 1.9377357e-11], sampled 0.7212156221774515
[2019-03-26 19:12:12,922] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04227491], dtype=float32), 0.050825693]
[2019-03-26 19:12:12,923] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.05, 74.0, 1.0, 2.0, 0.3075215585899375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 492330.2077422648, 492330.2077422641, 166540.1115642805]
[2019-03-26 19:12:12,925] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:12:12,928] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.17935430e-14 1.00000000e+00 1.04783925e-11 1.48365764e-11
 2.33108427e-13], sampled 0.5279303203213633
[2019-03-26 19:12:24,091] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04227491], dtype=float32), 0.050825693]
[2019-03-26 19:12:24,094] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.98514422, 77.19883146, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.325589305357572, 6.9112, 168.9105925456277, 1747934.196027124, 1453956.274954546, 311353.5751280135]
[2019-03-26 19:12:24,094] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:12:24,097] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.4131978e-16 1.0000000e+00 3.7933702e-13 9.9988138e-13 9.0335276e-15], sampled 0.199529924457596
[2019-03-26 19:12:24,099] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1747934.196027124 W.
[2019-03-26 19:13:18,898] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04227491], dtype=float32), 0.050825693]
[2019-03-26 19:13:18,899] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.01666666666667, 62.5, 1.0, 2.0, 0.6759777585446368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 944683.2459729238, 944683.2459729232, 215751.9224778498]
[2019-03-26 19:13:18,900] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:13:18,903] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.5967037e-15 1.0000000e+00 1.7212625e-12 3.1488854e-12 4.7064932e-14], sampled 0.46409513477371744
[2019-03-26 19:13:59,085] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.1321 2842492854.9742 1131.0000
[2019-03-26 19:13:59,149] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 19:13:59,586] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6673 3164091574.6358 1778.0000
[2019-03-26 19:13:59,626] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2605 3007618784.0356 1766.0000
[2019-03-26 19:13:59,642] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4308 2779149198.4617 933.0000
[2019-03-26 19:14:00,658] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 75000, evaluation results [75000.0, 7882.667340288573, 3164091574.635788, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8661.430759135581, 2779149198.4616733, 933.0, 7998.26053894139, 3007618784.0355844, 1766.0, 8496.132107770307, 2842492854.9741545, 1131.0]
[2019-03-26 19:14:01,625] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.9032876e-17 1.0000000e+00 5.8449182e-13 1.6169355e-13 6.4597125e-16], sum to 1.0000
[2019-03-26 19:14:01,635] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2358
[2019-03-26 19:14:01,638] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.4059744611742992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 598168.7936836937, 598168.793683693, 174143.7409613761], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2828400.0000, 
sim time next is 2829000.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.4040913762003742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 595394.5450848016, 595394.545084801, 173887.1380199762], 
processed observation next is [1.0, 0.7391304347826086, 0.3364928909952607, 0.89, 1.0, 1.0, 0.28203780265105327, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16538737363466713, 0.16538737363466696, 0.25953304182086], 
reward next is 0.7405, 
noisyNet noise sample is [array([-1.6436402], dtype=float32), 0.54103625]. 
=============================================
[2019-03-26 19:14:01,652] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[63.49984]
 [63.38213]
 [63.50554]
 [63.53166]
 [63.5199 ]], R is [[63.56882858]
 [63.6732254 ]
 [63.7769928 ]
 [63.87956619]
 [63.96368027]].
[2019-03-26 19:14:03,802] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9318272e-15 1.0000000e+00 1.5755054e-12 5.7173918e-12 1.5876184e-14], sum to 1.0000
[2019-03-26 19:14:03,810] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8011
[2019-03-26 19:14:03,822] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.463536188504447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 714057.5529147636, 714057.552914763, 186056.7008064638], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2859000.0000, 
sim time next is 2859600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3977644377628135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 612691.2463478635, 612691.2463478629, 176141.2239813128], 
processed observation next is [1.0, 0.08695652173913043, 0.2417061611374408, 0.94, 1.0, 1.0, 0.2744149852564018, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17019201287440652, 0.17019201287440636, 0.26289734922584], 
reward next is 0.7371, 
noisyNet noise sample is [array([-1.4504198], dtype=float32), -1.4809229]. 
=============================================
[2019-03-26 19:14:10,342] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 79690: loss 0.1002
[2019-03-26 19:14:10,345] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 79691: learning rate 0.0000
[2019-03-26 19:14:10,462] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 79709: loss 0.0819
[2019-03-26 19:14:10,466] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 79711: learning rate 0.0000
[2019-03-26 19:14:10,741] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 79809: loss 0.1002
[2019-03-26 19:14:10,745] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 79809: learning rate 0.0000
[2019-03-26 19:14:10,961] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 79880: loss 0.0913
[2019-03-26 19:14:10,965] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 79880: learning rate 0.0000
[2019-03-26 19:14:11,061] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 79891: loss 0.0992
[2019-03-26 19:14:11,065] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 79891: learning rate 0.0000
[2019-03-26 19:14:11,159] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 79906: loss 0.0705
[2019-03-26 19:14:11,160] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 79906: learning rate 0.0000
[2019-03-26 19:14:11,281] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 79938: loss 0.1008
[2019-03-26 19:14:11,288] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 79940: learning rate 0.0000
[2019-03-26 19:14:11,374] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 79950: loss 0.0730
[2019-03-26 19:14:11,377] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 79950: learning rate 0.0000
[2019-03-26 19:14:11,380] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 79952: loss 0.0989
[2019-03-26 19:14:11,457] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 79955: learning rate 0.0000
[2019-03-26 19:14:11,586] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 79983: loss 0.1051
[2019-03-26 19:14:11,588] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 79984: learning rate 0.0000
[2019-03-26 19:14:11,765] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 80044: loss 0.0849
[2019-03-26 19:14:11,766] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 80044: learning rate 0.0000
[2019-03-26 19:14:11,932] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 80084: loss 0.0853
[2019-03-26 19:14:11,935] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 80086: learning rate 0.0000
[2019-03-26 19:14:12,137] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 80147: loss 0.1079
[2019-03-26 19:14:12,139] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 80148: learning rate 0.0000
[2019-03-26 19:14:12,283] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 80187: loss 0.0835
[2019-03-26 19:14:12,286] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 80188: learning rate 0.0000
[2019-03-26 19:14:12,379] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 80199: loss 0.0924
[2019-03-26 19:14:12,380] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 80199: learning rate 0.0000
[2019-03-26 19:14:12,728] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 80334: loss 0.0827
[2019-03-26 19:14:12,730] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 80334: learning rate 0.0000
[2019-03-26 19:14:13,900] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.0635146e-17 1.0000000e+00 1.7755582e-13 9.0430139e-14 6.9171596e-16], sum to 1.0000
[2019-03-26 19:14:13,907] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3514
[2019-03-26 19:14:13,912] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3015956000108688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 480274.6810608006, 480274.6810608006, 165641.5433232328], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3027600.0000, 
sim time next is 3028200.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3019530957307914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 480844.2237597334, 480844.2237597327, 165682.3570734033], 
processed observation next is [1.0, 0.043478260869565216, 0.1469194312796209, 1.0, 1.0, 1.0, 0.15897963341059201, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13356783993325927, 0.13356783993325907, 0.24728710010955718], 
reward next is 0.7527, 
noisyNet noise sample is [array([-2.314031], dtype=float32), 0.55304587]. 
=============================================
[2019-03-26 19:14:19,866] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.5788475e-16 1.0000000e+00 1.0742744e-12 1.9273476e-12 2.4536573e-14], sum to 1.0000
[2019-03-26 19:14:19,875] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3573
[2019-03-26 19:14:19,879] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2212550e-16 1.0000000e+00 8.6318765e-12 8.8574612e-13 6.1967250e-14], sum to 1.0000
[2019-03-26 19:14:19,881] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.361786056609901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 556647.5646419071, 556647.5646419071, 171187.8250084225], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3124800.0000, 
sim time next is 3125400.0000, 
raw observation next is [21.83333333333334, 95.0, 1.0, 2.0, 0.3824516615590052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 589629.2817722468, 589629.2817722461, 174084.2236438014], 
processed observation next is [1.0, 0.17391304347826086, 0.23380726698262277, 0.95, 1.0, 1.0, 0.2559658573000062, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1637859116034019, 0.1637859116034017, 0.2598271994683603], 
reward next is 0.7402, 
noisyNet noise sample is [array([-0.7734629], dtype=float32), 0.39774498]. 
=============================================
[2019-03-26 19:14:19,889] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1740
[2019-03-26 19:14:19,895] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.361786056609901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 556647.5646419071, 556647.5646419071, 171187.8250084225], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3124800.0000, 
sim time next is 3125400.0000, 
raw observation next is [21.83333333333334, 95.0, 1.0, 2.0, 0.3824516615590052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 589629.2817722468, 589629.2817722461, 174084.2236438014], 
processed observation next is [1.0, 0.17391304347826086, 0.23380726698262277, 0.95, 1.0, 1.0, 0.2559658573000062, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1637859116034019, 0.1637859116034017, 0.2598271994683603], 
reward next is 0.7402, 
noisyNet noise sample is [array([0.02310084], dtype=float32), -0.14209804]. 
=============================================
[2019-03-26 19:14:23,200] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2011759e-19 1.0000000e+00 5.7896267e-14 1.2499685e-14 4.5153384e-16], sum to 1.0000
[2019-03-26 19:14:23,208] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0623
[2019-03-26 19:14:23,215] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 90.66666666666667, 1.0, 2.0, 0.4947539045591702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 691339.3272651251, 691339.3272651251, 182778.2510657697], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3180000.0000, 
sim time next is 3180600.0000, 
raw observation next is [25.5, 91.5, 1.0, 2.0, 0.4924721973161032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 688149.9741911981, 688149.9741911988, 182425.0814064551], 
processed observation next is [1.0, 0.8260869565217391, 0.40758293838862564, 0.915, 1.0, 1.0, 0.3885207196579557, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19115277060866614, 0.19115277060866634, 0.2722762409051569], 
reward next is 0.7277, 
noisyNet noise sample is [array([-0.21705016], dtype=float32), 0.8189175]. 
=============================================
[2019-03-26 19:14:24,755] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.4734694e-15 1.0000000e+00 5.3297137e-12 5.1007349e-12 4.8215243e-14], sum to 1.0000
[2019-03-26 19:14:24,765] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0251
[2019-03-26 19:14:24,771] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 78.16666666666667, 1.0, 2.0, 0.4784003462120729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 668480.6591032878, 668480.6591032878, 180281.2126089916], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3226200.0000, 
sim time next is 3226800.0000, 
raw observation next is [27.33333333333334, 77.33333333333334, 1.0, 2.0, 0.4801970682299169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 670992.0562059153, 670992.0562059153, 180551.6786721637], 
processed observation next is [0.0, 0.34782608695652173, 0.4944707740916275, 0.7733333333333334, 1.0, 1.0, 0.373731407505924, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1863866822794209, 0.1863866822794209, 0.2694801174211398], 
reward next is 0.7305, 
noisyNet noise sample is [array([-0.25590512], dtype=float32), 1.0358304]. 
=============================================
[2019-03-26 19:14:26,522] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1393423e-15 1.0000000e+00 4.7920166e-12 3.4639921e-12 3.1064320e-14], sum to 1.0000
[2019-03-26 19:14:26,532] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5140
[2019-03-26 19:14:26,537] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.66666666666667, 63.0, 1.0, 2.0, 0.5639949699404903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 788128.5179131179, 788128.5179131179, 194231.0397517385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3246000.0000, 
sim time next is 3246600.0000, 
raw observation next is [32.83333333333333, 63.0, 1.0, 2.0, 0.5693407449678668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 795601.5200955024, 795601.5200955024, 195174.2476920109], 
processed observation next is [0.0, 0.5652173913043478, 0.7551342812006318, 0.63, 1.0, 1.0, 0.48113342767212863, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22100042224875066, 0.22100042224875066, 0.2913048473015088], 
reward next is 0.7087, 
noisyNet noise sample is [array([-0.8442966], dtype=float32), 2.4710932]. 
=============================================
[2019-03-26 19:14:26,935] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0691900e-16 1.0000000e+00 1.2338947e-13 4.0185117e-14 4.6079821e-15], sum to 1.0000
[2019-03-26 19:14:26,944] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3037
[2019-03-26 19:14:26,949] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.0, 63.0, 1.0, 2.0, 0.5819015969336226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813160.8786120126, 813160.8786120126, 197423.2344444387], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3247800.0000, 
sim time next is 3248400.0000, 
raw observation next is [33.0, 63.00000000000001, 1.0, 2.0, 0.5794404456166239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 809720.305816154, 809720.305816154, 196978.9719834855], 
processed observation next is [0.0, 0.6086956521739131, 0.7630331753554502, 0.6300000000000001, 1.0, 1.0, 0.49330174170677576, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22492230717115388, 0.22492230717115388, 0.2939984656469933], 
reward next is 0.7060, 
noisyNet noise sample is [array([-0.69041896], dtype=float32), -0.6455156]. 
=============================================
[2019-03-26 19:14:29,121] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 87654: loss 0.1108
[2019-03-26 19:14:29,124] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 87654: learning rate 0.0000
[2019-03-26 19:14:29,140] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 87659: loss 0.1693
[2019-03-26 19:14:29,144] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 87659: learning rate 0.0000
[2019-03-26 19:14:29,491] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 87819: loss 0.1235
[2019-03-26 19:14:29,497] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 87821: learning rate 0.0000
[2019-03-26 19:14:29,664] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 87893: loss 0.1589
[2019-03-26 19:14:29,666] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 87893: learning rate 0.0000
[2019-03-26 19:14:29,726] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 87919: loss 0.1151
[2019-03-26 19:14:29,728] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 87919: learning rate 0.0000
[2019-03-26 19:14:29,744] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 87930: loss 0.1785
[2019-03-26 19:14:29,746] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 87930: learning rate 0.0000
[2019-03-26 19:14:29,767] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 87940: loss 0.1305
[2019-03-26 19:14:29,769] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 87940: learning rate 0.0000
[2019-03-26 19:14:29,791] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 87952: loss 0.1532
[2019-03-26 19:14:29,793] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 87952: learning rate 0.0000
[2019-03-26 19:14:29,798] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 87953: loss 0.0993
[2019-03-26 19:14:29,802] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 87954: learning rate 0.0000
[2019-03-26 19:14:30,026] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 88056: loss 0.1735
[2019-03-26 19:14:30,029] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 88056: learning rate 0.0000
[2019-03-26 19:14:30,048] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 88063: loss 0.1109
[2019-03-26 19:14:30,059] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 88064: learning rate 0.0000
[2019-03-26 19:14:30,112] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 88095: loss 0.1905
[2019-03-26 19:14:30,114] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 88095: learning rate 0.0000
[2019-03-26 19:14:30,189] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 88129: loss 0.1182
[2019-03-26 19:14:30,191] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 88129: learning rate 0.0000
[2019-03-26 19:14:30,336] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 88193: loss 0.1587
[2019-03-26 19:14:30,338] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 88194: learning rate 0.0000
[2019-03-26 19:14:30,354] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 88202: loss 0.0874
[2019-03-26 19:14:30,356] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 88202: learning rate 0.0000
[2019-03-26 19:14:30,629] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.5767279e-15 1.0000000e+00 6.0297344e-12 9.2203961e-12 6.4626310e-13], sum to 1.0000
[2019-03-26 19:14:30,639] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4747
[2019-03-26 19:14:30,647] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 72.66666666666667, 1.0, 2.0, 0.4904327901074785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 685299.3143714768, 685299.3143714775, 182110.7996345521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3313200.0000, 
sim time next is 3313800.0000, 
raw observation next is [28.5, 72.0, 1.0, 2.0, 0.4921111322998788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 687645.2811283108, 687645.2811283114, 182369.4389374428], 
processed observation next is [0.0, 0.34782608695652173, 0.5497630331753555, 0.72, 1.0, 1.0, 0.388085701566119, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19101257809119745, 0.19101257809119762, 0.2721931924439445], 
reward next is 0.7278, 
noisyNet noise sample is [array([-1.3000842], dtype=float32), -0.5196116]. 
=============================================
[2019-03-26 19:14:30,666] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 88338: loss 0.1017
[2019-03-26 19:14:30,667] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 88338: learning rate 0.0000
[2019-03-26 19:14:34,987] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0707075e-18 1.0000000e+00 1.2775385e-13 4.3067790e-14 5.6111608e-16], sum to 1.0000
[2019-03-26 19:14:34,994] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8936
[2019-03-26 19:14:35,092] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 92.33333333333334, 1.0, 2.0, 0.8219963233802569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1148855.509134595, 1148855.509134595, 249381.2279087122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3388800.0000, 
sim time next is 3389400.0000, 
raw observation next is [26.5, 91.5, 1.0, 2.0, 0.8171736454974532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1142111.5132643, 1142111.5132643, 248169.615476196], 
processed observation next is [1.0, 0.21739130434782608, 0.4549763033175356, 0.915, 1.0, 1.0, 0.7797272837318713, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.31725319812897224, 0.31725319812897224, 0.3704024111585015], 
reward next is 0.6296, 
noisyNet noise sample is [array([-1.9652206], dtype=float32), -1.2420442]. 
=============================================
[2019-03-26 19:14:37,618] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0879220e-17 1.0000000e+00 8.5795561e-14 4.1996127e-14 6.7711925e-16], sum to 1.0000
[2019-03-26 19:14:37,625] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7283
[2019-03-26 19:14:37,632] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2476449.548809365 W.
[2019-03-26 19:14:37,728] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 66.5, 1.0, 2.0, 0.5902741612727836, 1.0, 2.0, 0.5902741612727836, 1.0, 1.0, 1.02511101148276, 6.9112, 6.9112, 170.5573041426782, 2476449.548809365, 2476449.548809365, 483183.9534743266], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3429000.0000, 
sim time next is 3429600.0000, 
raw observation next is [31.66666666666666, 67.66666666666667, 1.0, 2.0, 0.5848687322188065, 1.0, 2.0, 0.5848687322188065, 1.0, 2.0, 1.015723568818706, 6.9112, 6.9112, 170.5573041426782, 2453749.223159217, 2453749.223159217, 478794.2774818378], 
processed observation next is [1.0, 0.6956521739130435, 0.6998420221169034, 0.6766666666666667, 1.0, 1.0, 0.49984184604675486, 1.0, 1.0, 0.49984184604675486, 1.0, 1.0, 1.0191750839252514, 0.0, 0.0, 0.8375144448122397, 0.6815970064331158, 0.6815970064331158, 0.7146183245997578], 
reward next is 0.2854, 
noisyNet noise sample is [array([-0.34029925], dtype=float32), -1.1161087]. 
=============================================
[2019-03-26 19:14:42,172] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7193903e-16 1.0000000e+00 1.6342209e-13 3.3809166e-12 6.6636760e-15], sum to 1.0000
[2019-03-26 19:14:42,178] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5811
[2019-03-26 19:14:42,179] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2106806.201918879 W.
[2019-03-26 19:14:42,183] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.5, 65.0, 1.0, 2.0, 0.7533683409787825, 1.0, 1.0, 0.7533683409787825, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2106806.201918879, 2106806.20191888, 397815.2172754777], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3501000.0000, 
sim time next is 3501600.0000, 
raw observation next is [32.66666666666667, 64.33333333333334, 1.0, 2.0, 0.7803813883056274, 1.0, 2.0, 0.7803813883056274, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2182425.561878879, 2182425.561878878, 410440.0099967236], 
processed observation next is [1.0, 0.5217391304347826, 0.7472353870458138, 0.6433333333333334, 1.0, 1.0, 0.7353992630188282, 1.0, 1.0, 0.7353992630188282, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6062293227441331, 0.6062293227441328, 0.6125970298458562], 
reward next is 0.3874, 
noisyNet noise sample is [array([0.9032931], dtype=float32), 1.8103135]. 
=============================================
[2019-03-26 19:14:47,285] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 95710: loss -112.3743
[2019-03-26 19:14:47,290] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 95710: learning rate 0.0000
[2019-03-26 19:14:47,349] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 95737: loss -96.4638
[2019-03-26 19:14:47,350] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 95738: learning rate 0.0000
[2019-03-26 19:14:47,616] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 95855: loss -176.7233
[2019-03-26 19:14:47,618] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 95855: learning rate 0.0000
[2019-03-26 19:14:47,744] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 95912: loss -126.9196
[2019-03-26 19:14:47,747] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 95912: learning rate 0.0000
[2019-03-26 19:14:47,785] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 95933: loss -120.6778
[2019-03-26 19:14:47,788] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 95933: learning rate 0.0000
[2019-03-26 19:14:47,818] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 95945: loss -71.2824
[2019-03-26 19:14:47,819] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 95946: loss -195.8051
[2019-03-26 19:14:47,820] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 95947: learning rate 0.0000
[2019-03-26 19:14:47,822] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 95947: learning rate 0.0000
[2019-03-26 19:14:47,880] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 95970: loss -80.1960
[2019-03-26 19:14:47,882] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 95970: loss -151.9980
[2019-03-26 19:14:47,884] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 95970: learning rate 0.0000
[2019-03-26 19:14:47,887] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 95970: learning rate 0.0000
[2019-03-26 19:14:48,026] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 96035: loss -229.3071
[2019-03-26 19:14:48,031] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 96036: learning rate 0.0000
[2019-03-26 19:14:48,039] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 96043: loss -242.8874
[2019-03-26 19:14:48,041] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 96043: learning rate 0.0000
[2019-03-26 19:14:48,135] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 96085: loss -157.1530
[2019-03-26 19:14:48,138] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 96087: learning rate 0.0000
[2019-03-26 19:14:48,141] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 96087: loss -155.7293
[2019-03-26 19:14:48,143] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 96088: learning rate 0.0000
[2019-03-26 19:14:48,318] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 96166: loss -157.9733
[2019-03-26 19:14:48,319] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 96166: learning rate 0.0000
[2019-03-26 19:14:48,547] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 96267: loss -166.1686
[2019-03-26 19:14:48,549] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 96267: learning rate 0.0000
[2019-03-26 19:14:48,638] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 96307: loss -119.0342
[2019-03-26 19:14:48,640] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 96307: learning rate 0.0000
[2019-03-26 19:14:56,703] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7877313e-16 1.0000000e+00 1.5584479e-13 2.2144677e-14 1.8758791e-16], sum to 1.0000
[2019-03-26 19:14:56,708] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2312
[2019-03-26 19:14:56,719] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2062983.959265002 W.
[2019-03-26 19:14:56,724] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 70.0, 1.0, 2.0, 0.4918087420556662, 1.0, 2.0, 0.4918087420556662, 1.0, 1.0, 0.8370957068639571, 6.9112, 6.9112, 170.5573041426782, 2062983.959265002, 2062983.959265002, 406473.3558160912], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3746400.0000, 
sim time next is 3747000.0000, 
raw observation next is [29.0, 70.0, 1.0, 2.0, 0.8454169978441758, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.972791119782486, 6.9112, 168.9125894608698, 2078638.158959193, 2034943.393732124, 420494.9932672253], 
processed observation next is [1.0, 0.34782608695652173, 0.5734597156398105, 0.7, 1.0, 1.0, 0.8137554190893684, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.006159111978248611, 0.0, 0.8294381427709212, 0.5773994885997759, 0.5652620538144789, 0.6276044675630228], 
reward next is 0.0644, 
noisyNet noise sample is [array([0.15927756], dtype=float32), -0.54407924]. 
=============================================
[2019-03-26 19:14:56,749] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[66.18069 ]
 [66.42349 ]
 [66.538445]
 [66.220436]
 [65.96243 ]], R is [[65.31555176]
 [65.0557251 ]
 [64.75084686]
 [64.10334015]
 [64.040802  ]].
[2019-03-26 19:14:56,865] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 19:14:56,866] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:14:56,867] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:14:56,867] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:14:56,868] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:14:56,868] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:14:56,870] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:14:56,870] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:14:56,870] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:14:56,871] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:14:56,874] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:14:56,894] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run5
[2019-03-26 19:14:56,894] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run5
[2019-03-26 19:14:56,894] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run5
[2019-03-26 19:14:56,947] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run5
[2019-03-26 19:14:56,967] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run5
[2019-03-26 19:15:17,733] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04623463], dtype=float32), 0.054562334]
[2019-03-26 19:15:17,734] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.63333333333333, 55.33333333333334, 1.0, 2.0, 0.2780890495636003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 455558.539575731, 455558.5395757304, 163806.5424939839]
[2019-03-26 19:15:17,736] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:15:17,739] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.9575638e-15 1.0000000e+00 3.0908795e-12 3.7745492e-12 6.9597540e-14], sampled 0.3395424667807948
[2019-03-26 19:15:35,939] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04623463], dtype=float32), 0.054562334]
[2019-03-26 19:15:35,942] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.55, 94.0, 1.0, 2.0, 0.4884136833719727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 684781.0828366879, 684781.0828366879, 182096.8427798822]
[2019-03-26 19:15:35,945] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:15:35,947] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.0394969e-16 1.0000000e+00 3.3205789e-13 5.1249364e-13 6.0183847e-15], sampled 0.07236746241533665
[2019-03-26 19:15:48,490] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04623463], dtype=float32), 0.054562334]
[2019-03-26 19:15:48,493] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.05, 84.0, 1.0, 2.0, 0.522595952874793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730257.5025111719, 730257.5025111719, 187211.4015552242]
[2019-03-26 19:15:48,494] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:15:48,498] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.3186599e-17 1.0000000e+00 8.9650970e-14 2.0078614e-13 1.1624966e-15], sampled 0.35895976205488755
[2019-03-26 19:16:08,668] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04623463], dtype=float32), 0.054562334]
[2019-03-26 19:16:08,669] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.57884538333333, 78.33823529, 1.0, 2.0, 0.6218242191781677, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.92921199217451, 6.9112, 168.9128428016408, 1738656.281904349, 1725877.963332936, 369942.4884948288]
[2019-03-26 19:16:08,670] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:16:08,672] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.4485321e-15 1.0000000e+00 1.8286364e-12 2.9500356e-12 5.1897380e-14], sampled 0.010027633141285408
[2019-03-26 19:16:08,674] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1738656.281904349 W.
[2019-03-26 19:16:10,123] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04623463], dtype=float32), 0.054562334]
[2019-03-26 19:16:10,124] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.88571024666667, 84.09582312666667, 1.0, 2.0, 0.448982013929365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 649817.0278310522, 649817.0278310529, 178856.9160423405]
[2019-03-26 19:16:10,125] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:16:10,128] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.1896312e-17 1.0000000e+00 9.6568017e-14 1.6700359e-13 1.6949039e-15], sampled 0.9842074912631023
[2019-03-26 19:16:24,744] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04623463], dtype=float32), 0.054562334]
[2019-03-26 19:16:24,746] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.03333333333333, 94.33333333333334, 1.0, 2.0, 0.5335523139768186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 745572.9154383411, 745572.9154383418, 189019.6070186341]
[2019-03-26 19:16:24,749] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:16:24,752] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.7531040e-17 1.0000000e+00 1.4923009e-13 1.6288590e-13 2.0921286e-15], sampled 0.6198868308441684
[2019-03-26 19:16:51,065] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8724 2842497929.8887 1131.0000
[2019-03-26 19:16:51,762] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4188 3164139523.4469 1778.0000
[2019-03-26 19:16:51,775] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.9085 2927359888.4909 1338.0000
[2019-03-26 19:16:51,784] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7281 2779199535.5119 933.0000
[2019-03-26 19:16:51,825] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2767 3007680316.3481 1766.0000
[2019-03-26 19:16:52,839] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 100000, evaluation results [100000.0, 7883.41881391125, 3164139523.4469013, 1778.0, 8252.908535966402, 2927359888.490912, 1338.0, 8660.728066421085, 2779199535.5119066, 933.0, 7998.276703650782, 3007680316.348062, 1766.0, 8496.87235025343, 2842497929.888741, 1131.0]
[2019-03-26 19:16:57,943] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.30625308e-16 1.00000000e+00 2.68719481e-13 3.73191766e-13
 1.01900435e-14], sum to 1.0000
[2019-03-26 19:16:57,948] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0566
[2019-03-26 19:16:57,953] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.0, 63.0, 1.0, 2.0, 0.616474343870628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861493.1167962622, 861493.1167962622, 203856.0112491574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3844200.0000, 
sim time next is 3844800.0000, 
raw observation next is [34.0, 63.0, 1.0, 2.0, 0.6167753717940899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861913.9594688974, 861913.9594688974, 203913.5549506455], 
processed observation next is [0.0, 0.5217391304347826, 0.8104265402843602, 0.63, 1.0, 1.0, 0.5382835804748071, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23942054429691595, 0.23942054429691595, 0.3043485894785754], 
reward next is 0.6957, 
noisyNet noise sample is [array([-0.34889734], dtype=float32), -0.0058359]. 
=============================================
[2019-03-26 19:17:00,275] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 103641: loss 0.2669
[2019-03-26 19:17:00,277] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 103642: learning rate 0.0000
[2019-03-26 19:17:00,442] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 103718: loss 0.2849
[2019-03-26 19:17:00,444] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 103718: learning rate 0.0000
[2019-03-26 19:17:00,689] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 103824: loss 0.2946
[2019-03-26 19:17:00,696] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 103828: learning rate 0.0000
[2019-03-26 19:17:00,748] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 103854: loss 0.2191
[2019-03-26 19:17:00,750] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 103855: learning rate 0.0000
[2019-03-26 19:17:00,858] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 103900: loss 0.2646
[2019-03-26 19:17:00,860] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 103901: learning rate 0.0000
[2019-03-26 19:17:00,881] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 103910: loss 0.2079
[2019-03-26 19:17:00,882] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 103911: learning rate 0.0000
[2019-03-26 19:17:00,937] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 103938: loss 0.3067
[2019-03-26 19:17:00,940] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 103938: learning rate 0.0000
[2019-03-26 19:17:00,993] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 103961: loss 0.2523
[2019-03-26 19:17:00,996] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 103962: learning rate 0.0000
[2019-03-26 19:17:01,019] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 103972: loss 0.2689
[2019-03-26 19:17:01,021] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 103972: learning rate 0.0000
[2019-03-26 19:17:01,101] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 104008: loss 0.2636
[2019-03-26 19:17:01,105] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 104011: learning rate 0.0000
[2019-03-26 19:17:01,116] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 104018: loss 0.2237
[2019-03-26 19:17:01,118] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 104018: learning rate 0.0000
[2019-03-26 19:17:01,197] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 104052: loss 0.3617
[2019-03-26 19:17:01,202] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 104053: learning rate 0.0000
[2019-03-26 19:17:01,332] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 104113: loss 0.2273
[2019-03-26 19:17:01,334] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 104113: learning rate 0.0000
[2019-03-26 19:17:01,442] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 104161: loss 0.3351
[2019-03-26 19:17:01,446] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 104163: learning rate 0.0000
[2019-03-26 19:17:01,871] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 104353: loss 0.2722
[2019-03-26 19:17:01,872] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 104353: learning rate 0.0000
[2019-03-26 19:17:01,921] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 104372: loss 0.2917
[2019-03-26 19:17:01,926] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 104373: learning rate 0.0000
[2019-03-26 19:17:04,692] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.8038739e-17 1.0000000e+00 4.3892942e-14 4.9326098e-13 9.0893877e-15], sum to 1.0000
[2019-03-26 19:17:04,699] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5906
[2019-03-26 19:17:04,708] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333334, 73.66666666666667, 1.0, 2.0, 0.6046563939403528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 844971.5333202941, 844971.5333202948, 201616.6447879491], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3964800.0000, 
sim time next is 3965400.0000, 
raw observation next is [31.5, 73.0, 1.0, 2.0, 0.6041539172788504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 844269.0728390906, 844269.0728390906, 201522.530803418], 
processed observation next is [0.0, 0.9130434782608695, 0.6919431279620853, 0.73, 1.0, 1.0, 0.5230770087696992, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23451918689974738, 0.23451918689974738, 0.3007798967215194], 
reward next is 0.6992, 
noisyNet noise sample is [array([1.8721497], dtype=float32), 0.6424938]. 
=============================================
[2019-03-26 19:17:09,127] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.8619967e-16 1.0000000e+00 1.3366264e-13 3.9849129e-14 9.0535328e-16], sum to 1.0000
[2019-03-26 19:17:09,134] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2016
[2019-03-26 19:17:09,141] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2124896.498553457 W.
[2019-03-26 19:17:09,150] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.5, 61.5, 1.0, 2.0, 0.7598308019405092, 1.0, 2.0, 0.7598308019405092, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2124896.498553457, 2124896.498553457, 400798.1268826625], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4019400.0000, 
sim time next is 4020000.0000, 
raw observation next is [33.66666666666666, 61.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.423973578900526, 6.9112, 168.9105357534865, 2647787.283036864, 2284013.271321117, 474974.4001908873], 
processed observation next is [1.0, 0.5217391304347826, 0.7946287519747232, 0.61, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.05127735789005259, 0.0, 0.8294280581274779, 0.73549646751024, 0.6344481309225325, 0.7089170152102795], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.27170926], dtype=float32), -0.61140573]. 
=============================================
[2019-03-26 19:17:09,167] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[63.48995 ]
 [64.37244 ]
 [63.38777 ]
 [63.570744]
 [63.98113 ]], R is [[63.37678528]
 [63.14481354]
 [62.8429184 ]
 [62.21448898]
 [61.59234619]].
[2019-03-26 19:17:16,291] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.2289747e-18 1.0000000e+00 5.0301793e-15 6.6507279e-14 3.2787470e-16], sum to 1.0000
[2019-03-26 19:17:16,298] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7376
[2019-03-26 19:17:16,303] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1923309.877128724 W.
[2019-03-26 19:17:16,306] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.6878111287525216, 1.0, 1.0, 0.6878111287525216, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1923309.877128724, 1923309.877128724, 368957.5828904677], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4155600.0000, 
sim time next is 4156200.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.5330950167705134, 1.0, 2.0, 0.5330950167705134, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1490380.050495132, 1490380.050495132, 310863.3212973434], 
processed observation next is [1.0, 0.08695652173913043, 0.5734597156398105, 0.84, 1.0, 1.0, 0.4374638756271246, 1.0, 1.0, 0.4374638756271246, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.41399445847087, 0.41399445847087, 0.4639751064139454], 
reward next is 0.5360, 
noisyNet noise sample is [array([-0.8086007], dtype=float32), 1.0297892]. 
=============================================
[2019-03-26 19:17:18,282] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 111639: loss -164.1275
[2019-03-26 19:17:18,285] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 111641: learning rate 0.0000
[2019-03-26 19:17:18,611] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 111787: loss -243.3610
[2019-03-26 19:17:18,615] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 111788: learning rate 0.0000
[2019-03-26 19:17:18,725] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 111836: loss -133.8401
[2019-03-26 19:17:18,727] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 111836: learning rate 0.0000
[2019-03-26 19:17:18,825] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 111878: loss -137.5553
[2019-03-26 19:17:18,829] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 111880: learning rate 0.0000
[2019-03-26 19:17:18,950] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 111936: loss -145.5616
[2019-03-26 19:17:18,952] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 111936: learning rate 0.0000
[2019-03-26 19:17:18,975] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 111947: loss -141.7310
[2019-03-26 19:17:18,976] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 111947: learning rate 0.0000
[2019-03-26 19:17:18,980] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 111949: loss -216.5026
[2019-03-26 19:17:18,982] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 111950: learning rate 0.0000
[2019-03-26 19:17:19,044] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 111974: loss -165.7156
[2019-03-26 19:17:19,046] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 111974: learning rate 0.0000
[2019-03-26 19:17:19,057] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 111980: loss -111.7663
[2019-03-26 19:17:19,059] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 111980: learning rate 0.0000
[2019-03-26 19:17:19,100] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 112000: loss -156.5109
[2019-03-26 19:17:19,103] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 112000: learning rate 0.0000
[2019-03-26 19:17:19,132] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 112013: loss -170.8295
[2019-03-26 19:17:19,137] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 112014: learning rate 0.0000
[2019-03-26 19:17:19,189] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 112037: loss -167.7600
[2019-03-26 19:17:19,191] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 112038: learning rate 0.0000
[2019-03-26 19:17:19,401] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 112129: loss -193.8288
[2019-03-26 19:17:19,402] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 112130: learning rate 0.0000
[2019-03-26 19:17:19,478] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 112166: loss -121.8132
[2019-03-26 19:17:19,480] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 112166: learning rate 0.0000
[2019-03-26 19:17:19,742] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 112281: loss -165.5312
[2019-03-26 19:17:19,746] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 112282: learning rate 0.0000
[2019-03-26 19:17:19,861] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 112335: loss -153.2684
[2019-03-26 19:17:19,867] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 112335: learning rate 0.0000
[2019-03-26 19:17:21,048] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2231604e-19 1.0000000e+00 4.0233239e-16 1.6111125e-15 8.8609192e-18], sum to 1.0000
[2019-03-26 19:17:21,056] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2763
[2019-03-26 19:17:21,067] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 75.0, 1.0, 2.0, 0.601006346581114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 839868.7914228167, 839868.7914228167, 200933.5713125359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4234200.0000, 
sim time next is 4234800.0000, 
raw observation next is [31.0, 75.0, 1.0, 2.0, 0.6011041619487852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 840005.536335655, 840005.5363356543, 200951.8184427393], 
processed observation next is [1.0, 0.0, 0.6682464454976303, 0.75, 1.0, 1.0, 0.5194026047575726, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23333487120434862, 0.23333487120434843, 0.2999280872279691], 
reward next is 0.7001, 
noisyNet noise sample is [array([0.8043951], dtype=float32), 0.29185122]. 
=============================================
[2019-03-26 19:17:24,459] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.9440701e-17 1.0000000e+00 9.6623979e-15 2.5250264e-13 5.3809070e-16], sum to 1.0000
[2019-03-26 19:17:24,467] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4298
[2019-03-26 19:17:24,475] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3265291.590979741 W.
[2019-03-26 19:17:24,483] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [38.0, 47.0, 1.0, 2.0, 0.914926293732134, 1.0, 2.0, 0.7780531863803296, 1.0, 1.0, 1.03, 7.005114685017497, 6.9112, 170.5573041426782, 3265291.590979741, 3198016.681896571, 597814.0549506356], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4290000.0000, 
sim time next is 4290600.0000, 
raw observation next is [38.0, 46.0, 1.0, 2.0, 0.8445867256523988, 1.0, 2.0, 0.7428834023404619, 1.0, 2.0, 1.03, 7.005109135455475, 6.9112, 170.5573041426782, 3117508.711562159, 3050237.777856007, 570886.9021970299], 
processed observation next is [1.0, 0.6521739130434783, 1.0, 0.46, 1.0, 1.0, 0.8127550911474684, 1.0, 1.0, 0.6902209666752553, 1.0, 1.0, 1.0365853658536586, 0.00939091354554753, 0.0, 0.8375144448122397, 0.8659746421005997, 0.8472882716266686, 0.8520700032791492], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7278043], dtype=float32), -0.19327027]. 
=============================================
[2019-03-26 19:17:26,521] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7105756e-17 1.0000000e+00 1.4871288e-14 1.0438924e-13 9.9815487e-17], sum to 1.0000
[2019-03-26 19:17:26,529] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7657
[2019-03-26 19:17:26,536] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 0.5071179505396199, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8806961736183713, 6.911200000000001, 6.9112, 168.9129564187469, 1417716.757122501, 1417716.7571225, 312064.3302363054], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4336800.0000, 
sim time next is 4337400.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 0.9733432481370654, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104081, 1360519.660109657, 1360519.660109658, 290914.5343847317], 
processed observation next is [1.0, 0.17391304347826086, 0.5734597156398105, 0.89, 1.0, 1.0, 0.9678834314904402, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451521902, 0.3779221278082381, 0.37792212780823836, 0.4342007975891518], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5960288], dtype=float32), -2.5281415]. 
=============================================
[2019-03-26 19:17:29,917] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.70678431e-16 1.00000000e+00 3.83912296e-14 6.22853223e-13
 1.01252955e-14], sum to 1.0000
[2019-03-26 19:17:29,926] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6819
[2019-03-26 19:17:29,935] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2789310.671279005 W.
[2019-03-26 19:17:29,940] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.0, 63.0, 1.0, 2.0, 0.6883459764416906, 1.0, 2.0, 0.664763027735108, 1.0, 1.0, 1.03, 7.005096813265062, 6.9112, 170.5573041426782, 2789310.671279005, 2722048.56445908, 517673.3088671597], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4381200.0000, 
sim time next is 4381800.0000, 
raw observation next is [32.83333333333334, 63.66666666666666, 1.0, 2.0, 0.2756033532785964, 1.0, 2.0, 0.2756033532785964, 1.0, 2.0, 0.4786318812232396, 6.911200000000001, 6.9112, 170.5573041426782, 1155580.981666428, 1155580.981666427, 294725.0785110372], 
processed observation next is [1.0, 0.7391304347826086, 0.7551342812006324, 0.6366666666666666, 1.0, 1.0, 0.12723295575734508, 1.0, 1.0, 0.12723295575734508, 1.0, 1.0, 0.3641852210039507, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.32099471712956335, 0.32099471712956307, 0.4398881768821451], 
reward next is 0.5601, 
noisyNet noise sample is [array([-1.203163], dtype=float32), -1.5562963]. 
=============================================
[2019-03-26 19:17:36,162] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 119607: loss 0.5232
[2019-03-26 19:17:36,166] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 119608: learning rate 0.0000
[2019-03-26 19:17:36,337] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 119687: loss 0.4196
[2019-03-26 19:17:36,343] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 119690: learning rate 0.0000
[2019-03-26 19:17:36,588] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 119800: loss 0.5189
[2019-03-26 19:17:36,593] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 119802: learning rate 0.0000
[2019-03-26 19:17:36,614] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 119810: loss 0.3949
[2019-03-26 19:17:36,618] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 119811: learning rate 0.0000
[2019-03-26 19:17:36,842] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 119914: loss 0.4510
[2019-03-26 19:17:36,843] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 119914: learning rate 0.0000
[2019-03-26 19:17:36,864] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 119922: loss 0.5530
[2019-03-26 19:17:36,867] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 119922: learning rate 0.0000
[2019-03-26 19:17:36,928] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 119949: loss 0.4939
[2019-03-26 19:17:36,930] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 119949: learning rate 0.0000
[2019-03-26 19:17:36,951] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 119958: loss 0.3827
[2019-03-26 19:17:36,953] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 119959: learning rate 0.0000
[2019-03-26 19:17:37,015] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 119986: loss 0.3451
[2019-03-26 19:17:37,019] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 119986: learning rate 0.0000
[2019-03-26 19:17:37,021] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 119988: loss 0.4662
[2019-03-26 19:17:37,025] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 119989: learning rate 0.0000
[2019-03-26 19:17:37,041] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 119999: loss 0.3905
[2019-03-26 19:17:37,043] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 119999: learning rate 0.0000
[2019-03-26 19:17:37,273] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 120100: loss 0.4076
[2019-03-26 19:17:37,275] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 120101: learning rate 0.0000
[2019-03-26 19:17:37,322] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 120124: loss 0.5464
[2019-03-26 19:17:37,324] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 120124: learning rate 0.0000
[2019-03-26 19:17:37,481] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 120192: loss 0.3605
[2019-03-26 19:17:37,483] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 120192: learning rate 0.0000
[2019-03-26 19:17:37,887] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 120374: loss 0.3716
[2019-03-26 19:17:37,889] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 120375: learning rate 0.0000
[2019-03-26 19:17:37,916] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 120390: loss 0.4855
[2019-03-26 19:17:37,919] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 120391: learning rate 0.0000
[2019-03-26 19:17:45,029] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4748998e-16 1.0000000e+00 3.3547052e-14 1.9683200e-13 5.0391894e-14], sum to 1.0000
[2019-03-26 19:17:45,036] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7452
[2019-03-26 19:17:45,043] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2787067.1634074 W.
[2019-03-26 19:17:45,047] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.0, 63.5, 1.0, 2.0, 0.6872777990793262, 1.0, 2.0, 0.6642289390539258, 1.0, 2.0, 1.03, 7.00509672904372, 6.9112, 170.5573041426782, 2787067.1634074, 2719805.116918648, 517341.8285553029], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4635000.0000, 
sim time next is 4635600.0000, 
raw observation next is [33.66666666666667, 64.66666666666667, 1.0, 2.0, 0.9659955597231925, 1.0, 2.0, 0.9659955597231925, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2702083.447851221, 2702083.447851222, 508784.4978078904], 
processed observation next is [1.0, 0.6521739130434783, 0.7946287519747238, 0.6466666666666667, 1.0, 1.0, 0.9590307948472199, 1.0, 1.0, 0.9590307948472199, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.750578735514228, 0.7505787355142284, 0.7593798474744633], 
reward next is 0.2406, 
noisyNet noise sample is [array([-0.6399709], dtype=float32), -0.84195596]. 
=============================================
[2019-03-26 19:17:45,286] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.20687781e-17 1.00000000e+00 7.65707281e-14 1.00843636e-13
 1.57803530e-15], sum to 1.0000
[2019-03-26 19:17:45,295] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9904
[2019-03-26 19:17:45,304] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2597576.447200915 W.
[2019-03-26 19:17:45,309] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.66666666666666, 69.0, 1.0, 2.0, 0.6191153851566878, 1.0, 2.0, 0.6191153851566878, 1.0, 1.0, 1.03, 6.962011789905626, 6.9112, 170.5573041426782, 2597576.447200915, 2561177.89520005, 495013.8736025171], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4639200.0000, 
sim time next is 4639800.0000, 
raw observation next is [31.33333333333334, 69.5, 1.0, 2.0, 0.6173539896821628, 1.0, 2.0, 0.6173539896821628, 1.0, 2.0, 1.03, 6.95857280362926, 6.9112, 170.5573041426782, 2590178.630736399, 2556243.564494313, 494356.6700243732], 
processed observation next is [1.0, 0.6956521739130435, 0.6840442338072673, 0.695, 1.0, 1.0, 0.5389807104604372, 1.0, 1.0, 0.5389807104604372, 1.0, 1.0, 1.0365853658536586, 0.004737280362926022, 0.0, 0.8375144448122397, 0.7194940640934442, 0.7100676568039759, 0.737845776155781], 
reward next is 0.0253, 
noisyNet noise sample is [array([0.14253552], dtype=float32), -1.9578289]. 
=============================================
[2019-03-26 19:17:48,202] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 19:17:48,205] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:17:48,206] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:17:48,207] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:17:48,209] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:17:48,209] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:17:48,210] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:17:48,211] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:17:48,211] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:17:48,212] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:17:48,213] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:17:48,229] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run6
[2019-03-26 19:17:48,230] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run6
[2019-03-26 19:17:48,266] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run6
[2019-03-26 19:17:48,267] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run6
[2019-03-26 19:17:48,300] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run6
[2019-03-26 19:18:07,218] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:18:07,220] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.55, 87.33333333333334, 1.0, 2.0, 0.4150440338059782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 626248.9733533538, 626248.9733533538, 177151.9139097347]
[2019-03-26 19:18:07,220] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:18:07,225] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.4654860e-15 1.0000000e+00 1.5331843e-12 7.7670140e-13 2.4286911e-14], sampled 0.7546745069314356
[2019-03-26 19:18:10,747] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:18:10,747] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.78127594333333, 88.28734331333334, 1.0, 2.0, 0.3794947305961779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 580563.339004929, 580563.339004929, 173174.5800897474]
[2019-03-26 19:18:10,748] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:18:10,750] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5852799e-17 1.0000000e+00 2.9343142e-14 3.0189481e-14 5.5598539e-16], sampled 0.35057972193367826
[2019-03-26 19:18:14,999] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:18:15,000] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.05, 86.5, 1.0, 2.0, 0.708797764454538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1016242.482101053, 1016242.482101053, 226194.6978298636]
[2019-03-26 19:18:15,000] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:18:15,004] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.8363502e-16 1.0000000e+00 3.4683801e-13 2.1622095e-13 5.3278250e-15], sampled 0.7434299341365955
[2019-03-26 19:18:23,843] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:18:23,844] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 67.0, 1.0, 2.0, 0.9299918984992019, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.993074082248562, 6.9112, 168.9124036783209, 2197016.843341964, 2138932.741609407, 442996.4726729438]
[2019-03-26 19:18:23,846] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:18:23,850] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.1582669e-17 1.0000000e+00 2.6605867e-14 5.2321381e-14 1.3615974e-15], sampled 0.06698686820096866
[2019-03-26 19:18:23,851] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2197016.843341964 W.
[2019-03-26 19:18:30,701] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:18:30,702] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.9, 86.33333333333334, 1.0, 2.0, 0.5614103787475387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 784515.467470032, 784515.467470032, 193776.4623206108]
[2019-03-26 19:18:30,703] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:18:30,706] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.6375071e-16 1.0000000e+00 1.6399412e-13 5.4814558e-14 1.1182478e-15], sampled 0.7097461436455178
[2019-03-26 19:18:39,339] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:18:39,340] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [33.17996338, 68.70456304, 1.0, 2.0, 0.9523543838281067, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005990810240634, 6.9112, 168.9123142148168, 2228315.125761221, 2161067.518240239, 449005.7962843012]
[2019-03-26 19:18:39,341] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:18:39,343] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0813521e-16 1.0000000e+00 4.1627129e-14 8.0820374e-14 1.6761037e-15], sampled 0.2748726252869437
[2019-03-26 19:18:39,345] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2228315.125761221 W.
[2019-03-26 19:18:46,835] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:18:46,836] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [36.34047633666667, 55.27472302666666, 1.0, 2.0, 0.6530348483005204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 912606.6062336339, 912606.6062336345, 211042.5208615054]
[2019-03-26 19:18:46,837] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:18:46,839] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.6344108e-18 1.0000000e+00 1.5204392e-14 1.7958669e-14 4.0460564e-16], sampled 0.47270754163947726
[2019-03-26 19:18:48,467] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:18:48,468] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.74960774, 85.02726514, 1.0, 2.0, 0.5815958999952543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 812733.5281868078, 812733.5281868078, 197367.0863609062]
[2019-03-26 19:18:48,470] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:18:48,474] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.6931694e-18 1.0000000e+00 4.0310688e-15 5.0766564e-15 7.9433354e-17], sampled 0.931516481541117
[2019-03-26 19:18:57,793] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:18:57,795] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.22053080666667, 67.45841237833334, 1.0, 2.0, 0.615099440573715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 859570.9783672922, 859570.9783672922, 203584.1174217544]
[2019-03-26 19:18:57,796] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:18:57,799] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.6279644e-17 1.0000000e+00 2.4968121e-14 2.1750766e-14 5.4421761e-16], sampled 0.5592193322210922
[2019-03-26 19:19:01,699] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:19:01,700] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.61050685833333, 74.33731686166666, 1.0, 2.0, 0.5023687150549787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 701983.3209104481, 701983.3209104481, 183966.5231569328]
[2019-03-26 19:19:01,704] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:19:01,707] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.1584543e-18 1.0000000e+00 1.4800488e-14 1.5427928e-14 2.3102771e-16], sampled 0.8655810218509723
[2019-03-26 19:19:20,472] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:19:20,474] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.1, 85.66666666666667, 1.0, 2.0, 0.5237910485583507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731928.0632159087, 731928.0632159094, 187407.5278585231]
[2019-03-26 19:19:20,475] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:19:20,477] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.5583539e-16 1.0000000e+00 4.2806402e-13 2.7634359e-13 7.8904626e-15], sampled 0.7526436697199741
[2019-03-26 19:19:26,497] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:19:26,500] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.13557419666667, 57.49463220333334, 1.0, 2.0, 0.7511769498146428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1111512.864986999, 1111512.864986998, 240533.4150105368]
[2019-03-26 19:19:26,502] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:19:26,507] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.9263455e-17 1.0000000e+00 6.0813916e-14 4.8234098e-14 1.2437465e-15], sampled 0.49570658975349813
[2019-03-26 19:19:36,243] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:19:36,245] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.21666666666667, 94.83333333333333, 1.0, 2.0, 0.3224974911412962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 506079.5579301456, 506079.5579301456, 167398.0400135795]
[2019-03-26 19:19:36,246] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:19:36,251] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.0922556e-15 1.0000000e+00 5.6746084e-12 2.8783143e-12 1.0104368e-13], sampled 0.12792377837240565
[2019-03-26 19:19:42,226] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 19:19:42,597] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.5678 2842630539.9971 1131.0000
[2019-03-26 19:19:42,750] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7281 2779199535.5119 933.0000
[2019-03-26 19:19:42,758] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5735 3007608940.6579 1766.0000
[2019-03-26 19:19:42,809] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6584 3164060843.9104 1778.0000
[2019-03-26 19:19:43,823] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 125000, evaluation results [125000.0, 7882.658396093389, 3164060843.9103956, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8660.728066421085, 2779199535.5119066, 933.0, 7997.573463137595, 3007608940.657916, 1766.0, 8496.567753251295, 2842630539.997116, 1131.0]
[2019-03-26 19:19:46,121] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.15318981e-17 1.00000000e+00 1.04836394e-13 4.39704493e-14
 8.33614728e-16], sum to 1.0000
[2019-03-26 19:19:46,130] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4645
[2019-03-26 19:19:46,135] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.5173717296712005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 722954.869546444, 722954.8695464433, 186363.1535348479], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4734000.0000, 
sim time next is 4734600.0000, 
raw observation next is [28.83333333333334, 74.83333333333334, 1.0, 2.0, 0.5163743409950602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 721560.684549907, 721560.6845499076, 186201.8923903371], 
processed observation next is [1.0, 0.8260869565217391, 0.5655608214849924, 0.7483333333333334, 1.0, 1.0, 0.4173184831265785, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20043352348608529, 0.20043352348608542, 0.2779132722243837], 
reward next is 0.7221, 
noisyNet noise sample is [array([0.5915043], dtype=float32), 0.25187916]. 
=============================================
[2019-03-26 19:19:47,635] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.1208720e-18 1.0000000e+00 1.6010715e-14 2.2573474e-14 1.8674897e-16], sum to 1.0000
[2019-03-26 19:19:47,644] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5233
[2019-03-26 19:19:47,650] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5176297980677346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723315.606932321, 723315.606932321, 186404.4491686033], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4739400.0000, 
sim time next is 4740000.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5172384432464104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 722768.5569846696, 722768.5569846702, 186341.1345189717], 
processed observation next is [1.0, 0.8695652173913043, 0.5260663507109005, 0.79, 1.0, 1.0, 0.4183595701763981, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2007690436068527, 0.20076904360685285, 0.2781210962969727], 
reward next is 0.7219, 
noisyNet noise sample is [array([1.4471401], dtype=float32), 0.030792275]. 
=============================================
[2019-03-26 19:19:47,664] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[68.44923 ]
 [68.262375]
 [67.60139 ]
 [67.62548 ]
 [67.0087  ]], R is [[67.85813141]
 [67.90133667]
 [67.94419861]
 [67.98694611]
 [68.02938843]].
[2019-03-26 19:19:49,043] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.03773474e-16 1.00000000e+00 1.21135917e-13 8.12306900e-14
 1.11132883e-15], sum to 1.0000
[2019-03-26 19:19:49,051] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5024
[2019-03-26 19:19:49,058] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666667, 81.0, 1.0, 2.0, 0.8259522448463741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1154387.471438376, 1154387.471438376, 250382.1220618755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4778400.0000, 
sim time next is 4779000.0000, 
raw observation next is [29.0, 79.5, 1.0, 2.0, 0.8609422907561163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1203318.821810219, 1203318.821810219, 259421.2778980691], 
processed observation next is [1.0, 0.30434782608695654, 0.5734597156398105, 0.795, 1.0, 1.0, 0.8324605912724292, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3342552282806164, 0.3342552282806164, 0.38719593716129713], 
reward next is 0.6128, 
noisyNet noise sample is [array([-0.8766872], dtype=float32), -0.24584395]. 
=============================================
[2019-03-26 19:19:49,071] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[66.57118 ]
 [66.47088 ]
 [66.433266]
 [66.549644]
 [66.46586 ]], R is [[66.62809753]
 [66.58811188]
 [66.56907654]
 [66.5991745 ]
 [66.63043213]].
[2019-03-26 19:19:49,421] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 127634: loss -87.5876
[2019-03-26 19:19:49,423] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 127634: learning rate 0.0000
[2019-03-26 19:19:49,668] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 127788: loss -156.5206
[2019-03-26 19:19:49,670] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 127789: loss -128.4874
[2019-03-26 19:19:49,671] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 127789: learning rate 0.0000
[2019-03-26 19:19:49,673] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 127789: learning rate 0.0000
[2019-03-26 19:19:49,724] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 127822: loss -54.5109
[2019-03-26 19:19:49,727] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 127823: learning rate 0.0000
[2019-03-26 19:19:49,921] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 127945: loss -128.4667
[2019-03-26 19:19:49,922] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 127945: learning rate 0.0000
[2019-03-26 19:19:49,931] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 127950: loss -112.2324
[2019-03-26 19:19:49,932] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 127950: learning rate 0.0000
[2019-03-26 19:19:49,955] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 127966: loss -35.2863
[2019-03-26 19:19:49,958] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 127966: learning rate 0.0000
[2019-03-26 19:19:49,971] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 127977: loss -84.8801
[2019-03-26 19:19:49,973] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 127977: learning rate 0.0000
[2019-03-26 19:19:49,980] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 127981: loss -111.8173
[2019-03-26 19:19:49,981] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 127982: learning rate 0.0000
[2019-03-26 19:19:49,981] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 127982: loss -92.6337
[2019-03-26 19:19:49,982] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 127982: learning rate 0.0000
[2019-03-26 19:19:50,024] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 128014: loss -118.3807
[2019-03-26 19:19:50,026] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 128014: learning rate 0.0000
[2019-03-26 19:19:50,090] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 128059: loss -67.5607
[2019-03-26 19:19:50,092] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 128059: learning rate 0.0000
[2019-03-26 19:19:50,179] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 128123: loss -40.2970
[2019-03-26 19:19:50,180] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 128124: learning rate 0.0000
[2019-03-26 19:19:50,218] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 128146: loss -111.5125
[2019-03-26 19:19:50,221] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 128147: learning rate 0.0000
[2019-03-26 19:19:50,551] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 128311: loss -38.0599
[2019-03-26 19:19:50,553] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 128311: learning rate 0.0000
[2019-03-26 19:19:50,604] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 128329: loss -181.4739
[2019-03-26 19:19:50,605] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 128329: learning rate 0.0000
[2019-03-26 19:19:52,731] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0143527e-17 1.0000000e+00 2.7132704e-13 2.0401449e-14 1.9557840e-16], sum to 1.0000
[2019-03-26 19:19:52,735] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9597
[2019-03-26 19:19:52,748] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.4848186778890622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 677452.0127284338, 677452.0127284338, 181251.4184775893], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4845600.0000, 
sim time next is 4846200.0000, 
raw observation next is [27.0, 79.00000000000001, 1.0, 2.0, 0.9806421946334349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1370728.567619118, 1370728.567619118, 293079.7629098151], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.7900000000000001, 1.0, 1.0, 0.9766773429318493, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.38075793544975495, 0.38075793544975495, 0.43743248195494794], 
reward next is 0.5626, 
noisyNet noise sample is [array([1.0799448], dtype=float32), -0.13428578]. 
=============================================
[2019-03-26 19:20:00,267] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.7739750e-15 1.0000000e+00 2.5556057e-12 7.3073292e-12 3.5660640e-13], sum to 1.0000
[2019-03-26 19:20:00,280] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1849
[2019-03-26 19:20:00,290] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2223135.614649753 W.
[2019-03-26 19:20:00,293] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.8, 63.0, 1.0, 2.0, 0.5299491740930115, 1.0, 2.0, 0.5299491740930115, 1.0, 2.0, 0.9086141068093557, 6.911199999999999, 6.9112, 170.5573041426782, 2223135.614649753, 2223135.614649754, 434199.9807300368], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4978800.0000, 
sim time next is 4979400.0000, 
raw observation next is [30.83333333333334, 63.0, 1.0, 2.0, 0.4947342357720285, 1.0, 2.0, 0.4947342357720285, 1.0, 2.0, 0.8482164622806077, 6.9112, 6.9112, 170.5573041426782, 2075267.377542447, 2075267.377542447, 409553.470439431], 
processed observation next is [1.0, 0.6521739130434783, 0.6603475513428123, 0.63, 1.0, 1.0, 0.3912460671952151, 1.0, 1.0, 0.3912460671952151, 1.0, 1.0, 0.8148981247324484, 0.0, 0.0, 0.8375144448122397, 0.5764631604284575, 0.5764631604284575, 0.6112738364767627], 
reward next is 0.3887, 
noisyNet noise sample is [array([2.0738661], dtype=float32), -1.5538118]. 
=============================================
[2019-03-26 19:20:00,834] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2202563e-15 1.0000000e+00 7.2743124e-13 3.4148162e-13 2.8271551e-14], sum to 1.0000
[2019-03-26 19:20:00,844] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6948
[2019-03-26 19:20:00,851] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 67.66666666666667, 1.0, 2.0, 0.5005539020913188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 699446.5629206613, 699446.5629206606, 183685.0184415001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4988400.0000, 
sim time next is 4989000.0000, 
raw observation next is [30.16666666666666, 68.83333333333333, 1.0, 2.0, 0.506324710356891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 707513.0592325422, 707513.0592325422, 184594.8456621898], 
processed observation next is [1.0, 0.7391304347826086, 0.6287519747235385, 0.6883333333333332, 1.0, 1.0, 0.4052104944058927, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19653140534237282, 0.19653140534237282, 0.2755146950181937], 
reward next is 0.7245, 
noisyNet noise sample is [array([1.6718009], dtype=float32), 1.2088906]. 
=============================================
[2019-03-26 19:20:00,861] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[56.563534]
 [56.369644]
 [55.83533 ]
 [54.504745]
 [55.093002]], R is [[57.00456238]
 [57.16035843]
 [57.31647873]
 [57.47004318]
 [57.50284195]].
[2019-03-26 19:20:03,138] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.3243666e-19 1.0000000e+00 5.4637056e-16 2.0067672e-16 4.9648026e-18], sum to 1.0000
[2019-03-26 19:20:03,150] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8696
[2019-03-26 19:20:03,155] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5091015903215216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 711394.6329976249, 711394.6329976243, 185034.4587508654], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5005800.0000, 
sim time next is 5006400.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5104633257084197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 713298.0968898302, 713298.0968898295, 185251.679123224], 
processed observation next is [1.0, 0.9565217391304348, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4101967779619514, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19813836024717504, 0.19813836024717485, 0.2764950434674985], 
reward next is 0.7235, 
noisyNet noise sample is [array([2.0671895], dtype=float32), -0.53118515]. 
=============================================
[2019-03-26 19:20:05,007] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.54804691e-17 1.00000000e+00 1.02954076e-13 3.48214106e-13
 6.74127392e-15], sum to 1.0000
[2019-03-26 19:20:05,015] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3947
[2019-03-26 19:20:05,022] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 63.0, 1.0, 2.0, 0.5438862664541704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 760018.4932231669, 760018.4932231669, 190758.7568232735], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5058000.0000, 
sim time next is 5058600.0000, 
raw observation next is [31.83333333333334, 63.0, 1.0, 2.0, 0.5419154270068041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 757263.4901138083, 757263.4901138083, 190424.636971973], 
processed observation next is [0.0, 0.5652173913043478, 0.7077409162717223, 0.63, 1.0, 1.0, 0.44809087591181207, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21035096947605786, 0.21035096947605786, 0.28421587607757165], 
reward next is 0.7158, 
noisyNet noise sample is [array([0.49980453], dtype=float32), -0.9552149]. 
=============================================
[2019-03-26 19:20:05,273] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.8778221e-16 1.0000000e+00 1.3369221e-13 2.5479229e-14 1.0900625e-15], sum to 1.0000
[2019-03-26 19:20:05,284] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2686
[2019-03-26 19:20:05,290] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333333, 63.0, 1.0, 2.0, 0.5393228908244629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 753639.438542164, 753639.438542164, 189987.4066432035], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5057400.0000, 
sim time next is 5058000.0000, 
raw observation next is [32.0, 63.0, 1.0, 2.0, 0.5438862664541704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 760018.4932231669, 760018.4932231669, 190758.7568232735], 
processed observation next is [0.0, 0.5652173913043478, 0.7156398104265403, 0.63, 1.0, 1.0, 0.4504653812700848, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21111624811754637, 0.21111624811754637, 0.28471456242279625], 
reward next is 0.7153, 
noisyNet noise sample is [array([0.25746447], dtype=float32), -0.5489431]. 
=============================================
[2019-03-26 19:20:05,306] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[61.172123]
 [61.12789 ]
 [61.07698 ]
 [61.024597]
 [60.971878]], R is [[61.32734299]
 [61.43050766]
 [61.53380966]
 [61.63725281]
 [61.74081039]].
[2019-03-26 19:20:06,896] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 135546: loss 0.4110
[2019-03-26 19:20:06,899] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 135546: learning rate 0.0000
[2019-03-26 19:20:07,182] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5155264e-17 1.0000000e+00 4.2703220e-14 9.5732490e-14 2.0379037e-15], sum to 1.0000
[2019-03-26 19:20:07,190] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7555
[2019-03-26 19:20:07,197] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 70.0, 1.0, 2.0, 0.5561092231212424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777104.9170712325, 777104.9170712325, 192852.4636751746], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5073000.0000, 
sim time next is 5073600.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.5314308110443645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 742607.3430174363, 742607.3430174369, 188667.4421233954], 
processed observation next is [0.0, 0.7391304347826086, 0.6208530805687204, 0.7, 1.0, 1.0, 0.43545880848718616, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20627981750484342, 0.2062798175048436, 0.2815931971990976], 
reward next is 0.7184, 
noisyNet noise sample is [array([0.14068015], dtype=float32), 0.024932094]. 
=============================================
[2019-03-26 19:20:07,275] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 135713: loss 0.3979
[2019-03-26 19:20:07,277] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 135714: learning rate 0.0000
[2019-03-26 19:20:07,416] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 135775: loss 0.3590
[2019-03-26 19:20:07,418] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 135775: learning rate 0.0000
[2019-03-26 19:20:07,516] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 135823: loss 0.3462
[2019-03-26 19:20:07,521] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 135823: learning rate 0.0000
[2019-03-26 19:20:07,759] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 135930: loss 0.4851
[2019-03-26 19:20:07,762] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 135930: learning rate 0.0000
[2019-03-26 19:20:07,831] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 135963: loss 0.4069
[2019-03-26 19:20:07,834] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 135964: learning rate 0.0000
[2019-03-26 19:20:07,846] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 135970: loss 0.4042
[2019-03-26 19:20:07,848] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 135970: learning rate 0.0000
[2019-03-26 19:20:07,860] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 135976: loss 0.3883
[2019-03-26 19:20:07,863] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 135976: learning rate 0.0000
[2019-03-26 19:20:07,877] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 135983: loss 0.4529
[2019-03-26 19:20:07,881] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 135983: learning rate 0.0000
[2019-03-26 19:20:07,882] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 135984: loss 0.4518
[2019-03-26 19:20:07,886] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 135986: learning rate 0.0000
[2019-03-26 19:20:07,901] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 135993: loss 0.4528
[2019-03-26 19:20:07,904] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 135993: learning rate 0.0000
[2019-03-26 19:20:07,913] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 135996: loss 0.4154
[2019-03-26 19:20:07,915] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 135997: learning rate 0.0000
[2019-03-26 19:20:08,267] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 136155: loss 0.5217
[2019-03-26 19:20:08,268] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 136156: learning rate 0.0000
[2019-03-26 19:20:08,346] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 136191: loss 0.3692
[2019-03-26 19:20:08,349] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 136191: learning rate 0.0000
[2019-03-26 19:20:08,793] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 136389: loss 0.4458
[2019-03-26 19:20:08,794] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 136389: learning rate 0.0000
[2019-03-26 19:20:08,836] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 136408: loss 0.3752
[2019-03-26 19:20:08,838] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 136408: learning rate 0.0000
[2019-03-26 19:20:12,701] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1475847e-18 1.0000000e+00 1.5743652e-14 6.0930218e-15 4.2056284e-16], sum to 1.0000
[2019-03-26 19:20:12,713] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9856
[2019-03-26 19:20:12,717] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 79.0, 1.0, 2.0, 0.5060471560311154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 707125.0894830591, 707125.0894830597, 184548.2607312716], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5179200.0000, 
sim time next is 5179800.0000, 
raw observation next is [27.16666666666666, 79.0, 1.0, 2.0, 0.5006537658082684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 699586.1529506514, 699586.1529506508, 183697.824478063], 
processed observation next is [0.0, 0.9565217391304348, 0.4865718799368086, 0.79, 1.0, 1.0, 0.3983780310942992, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19432948693073648, 0.19432948693073632, 0.27417585742994477], 
reward next is 0.7258, 
noisyNet noise sample is [array([0.7156667], dtype=float32), 1.5818435]. 
=============================================
[2019-03-26 19:20:16,184] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4797805e-18 1.0000000e+00 3.6376711e-15 1.4649710e-16 3.1389651e-17], sum to 1.0000
[2019-03-26 19:20:16,191] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0203
[2019-03-26 19:20:16,195] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.81666666666667, 78.83333333333334, 1.0, 2.0, 0.5452327300927857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 761900.6960647892, 761900.6960647892, 190986.6117764753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5255400.0000, 
sim time next is 5256000.0000, 
raw observation next is [28.8, 79.0, 1.0, 2.0, 0.5473916124312921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 764918.5746976368, 764918.5746976368, 191354.3720096959], 
processed observation next is [1.0, 0.8695652173913043, 0.5639810426540285, 0.79, 1.0, 1.0, 0.4546886896762555, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21247738186045464, 0.21247738186045464, 0.2856035403129789], 
reward next is 0.7144, 
noisyNet noise sample is [array([-0.66054523], dtype=float32), 0.47949088]. 
=============================================
[2019-03-26 19:20:16,213] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[68.64604]
 [68.67059]
 [67.84742]
 [67.78492]
 [67.14378]], R is [[68.48296356]
 [68.51307678]
 [68.54364014]
 [68.57365417]
 [68.60301208]].
[2019-03-26 19:20:24,344] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 143540: loss -193.1009
[2019-03-26 19:20:24,346] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 143540: learning rate 0.0000
[2019-03-26 19:20:24,865] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 143776: loss -207.4253
[2019-03-26 19:20:24,867] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 143776: learning rate 0.0000
[2019-03-26 19:20:25,014] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 143841: loss -212.3938
[2019-03-26 19:20:25,016] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 143842: learning rate 0.0000
[2019-03-26 19:20:25,098] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 143874: loss -110.6663
[2019-03-26 19:20:25,099] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 143874: learning rate 0.0000
[2019-03-26 19:20:25,157] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 143899: loss -165.5884
[2019-03-26 19:20:25,159] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 143900: learning rate 0.0000
[2019-03-26 19:20:25,225] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 143932: loss -229.1542
[2019-03-26 19:20:25,230] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 143932: learning rate 0.0000
[2019-03-26 19:20:25,251] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 143943: loss -224.8542
[2019-03-26 19:20:25,254] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 143943: learning rate 0.0000
[2019-03-26 19:20:25,266] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 143948: loss -247.0998
[2019-03-26 19:20:25,267] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 143948: learning rate 0.0000
[2019-03-26 19:20:25,304] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 143962: loss -192.0078
[2019-03-26 19:20:25,305] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 143962: learning rate 0.0000
[2019-03-26 19:20:25,396] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 144005: loss -259.3297
[2019-03-26 19:20:25,398] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 144008: learning rate 0.0000
[2019-03-26 19:20:25,466] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 144036: loss -214.3296
[2019-03-26 19:20:25,469] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 144036: learning rate 0.0000
[2019-03-26 19:20:25,504] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 144051: loss -266.0377
[2019-03-26 19:20:25,507] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 144051: learning rate 0.0000
[2019-03-26 19:20:25,719] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 144149: loss -219.5474
[2019-03-26 19:20:25,726] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 144151: learning rate 0.0000
[2019-03-26 19:20:25,776] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 144175: loss -194.0105
[2019-03-26 19:20:25,777] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 144175: learning rate 0.0000
[2019-03-26 19:20:26,097] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 144319: loss -176.4348
[2019-03-26 19:20:26,099] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 144319: learning rate 0.0000
[2019-03-26 19:20:26,197] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 144364: loss -214.2070
[2019-03-26 19:20:26,198] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 144364: learning rate 0.0000
[2019-03-26 19:20:26,483] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.0413333e-17 1.0000000e+00 1.4620861e-14 3.6704997e-14 1.1203442e-15], sum to 1.0000
[2019-03-26 19:20:26,491] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0108
[2019-03-26 19:20:26,496] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.88333333333333, 75.66666666666667, 1.0, 2.0, 0.5821301382215632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813480.3690571458, 813480.3690571458, 197465.3251334452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5422200.0000, 
sim time next is 5422800.0000, 
raw observation next is [30.86666666666667, 76.33333333333334, 1.0, 2.0, 0.5872359064941861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 820618.0285986264, 820618.0285986264, 198393.2900724918], 
processed observation next is [1.0, 0.782608695652174, 0.6619273301737759, 0.7633333333333334, 1.0, 1.0, 0.5026938632460073, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22794945238850733, 0.22794945238850733, 0.2961093881678982], 
reward next is 0.7039, 
noisyNet noise sample is [array([-0.10892162], dtype=float32), 0.8132768]. 
=============================================
[2019-03-26 19:20:28,389] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7081303e-17 1.0000000e+00 1.7534261e-14 8.8436391e-16 1.8320750e-16], sum to 1.0000
[2019-03-26 19:20:28,398] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6206
[2019-03-26 19:20:28,407] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.41666666666666, 89.66666666666667, 1.0, 2.0, 0.5883698627198274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 822203.2604925588, 822203.2604925588, 198599.4757223906], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5447400.0000, 
sim time next is 5448000.0000, 
raw observation next is [28.33333333333334, 90.33333333333334, 1.0, 2.0, 0.5889300058987476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 822986.3223094663, 822986.3223094663, 198701.9466961817], 
processed observation next is [1.0, 0.043478260869565216, 0.5418641390205374, 0.9033333333333334, 1.0, 1.0, 0.5047349468659609, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22860731175262952, 0.22860731175262952, 0.2965700696957936], 
reward next is 0.7034, 
noisyNet noise sample is [array([-0.5506013], dtype=float32), -1.2979577]. 
=============================================
[2019-03-26 19:20:28,423] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[69.85287]
 [70.21046]
 [70.47623]
 [70.78178]
 [71.1357 ]], R is [[69.59914398]
 [69.60673523]
 [69.61435699]
 [69.62181854]
 [69.6289444 ]].
[2019-03-26 19:20:34,711] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.9683454e-18 1.0000000e+00 2.9028387e-15 3.9809757e-15 2.7340148e-16], sum to 1.0000
[2019-03-26 19:20:34,723] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5283
[2019-03-26 19:20:34,731] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 95.0, 1.0, 2.0, 0.5086861770946968, 1.0, 1.0, 0.5086861770946968, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1422094.699434403, 1422094.699434403, 302973.4183357868], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5538600.0000, 
sim time next is 5539200.0000, 
raw observation next is [26.16666666666666, 95.0, 1.0, 2.0, 0.9593438232230637, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565085993, 1340939.186540829, 1340939.18654083, 286783.1953809508], 
processed observation next is [1.0, 0.08695652173913043, 0.4391785150078987, 0.95, 1.0, 1.0, 0.9510166544856189, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451433082, 0.3724831073724525, 0.37248310737245277, 0.4280346199715684], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2693074], dtype=float32), -0.58797485]. 
=============================================
[2019-03-26 19:20:35,411] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3072880e-17 1.0000000e+00 1.8763355e-14 6.3444470e-15 1.1986428e-16], sum to 1.0000
[2019-03-26 19:20:35,418] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1883
[2019-03-26 19:20:35,424] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 86.0, 1.0, 2.0, 0.8365889707277824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1169262.016483936, 1169262.016483935, 253091.0094335143], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5554800.0000, 
sim time next is 5555400.0000, 
raw observation next is [27.88333333333333, 85.33333333333334, 1.0, 2.0, 0.8302677065363072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1160422.247817472, 1160422.247817473, 251477.0291355819], 
processed observation next is [1.0, 0.30434782608695654, 0.5205371248025275, 0.8533333333333334, 1.0, 1.0, 0.7955032608871171, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.32233951328263116, 0.3223395132826314, 0.37533884945609236], 
reward next is 0.6247, 
noisyNet noise sample is [array([-0.80632854], dtype=float32), 1.5333353]. 
=============================================
[2019-03-26 19:20:38,823] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 19:20:38,826] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:20:38,828] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:20:38,828] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:20:38,829] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:20:38,830] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:20:38,832] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:20:38,833] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:20:38,835] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:20:38,831] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:20:38,839] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:20:38,849] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run7
[2019-03-26 19:20:38,866] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run7
[2019-03-26 19:20:38,866] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run7
[2019-03-26 19:20:38,907] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run7
[2019-03-26 19:20:38,907] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run7
[2019-03-26 19:21:48,000] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04674687], dtype=float32), 0.054028183]
[2019-03-26 19:21:48,002] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.1, 53.0, 1.0, 2.0, 0.5196122190562255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 726086.711139293, 726086.7111392937, 186726.1127470609]
[2019-03-26 19:21:48,004] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:21:48,006] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.7775843e-17 1.0000000e+00 1.5312452e-14 1.5397031e-14 6.2404379e-16], sampled 0.6057493074309931
[2019-03-26 19:22:04,543] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04674687], dtype=float32), 0.054028183]
[2019-03-26 19:22:04,543] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.13722007666667, 80.95624624999999, 1.0, 2.0, 0.5644907401186957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 788821.5661204283, 788821.5661204283, 194317.4268193821]
[2019-03-26 19:22:04,544] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:22:04,547] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.04375685e-17 1.00000000e+00 9.04725378e-15 8.59243944e-15
 3.08103788e-16], sampled 0.6818493705247003
[2019-03-26 19:22:33,335] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.9596 2842607972.5311 1131.0000
[2019-03-26 19:22:33,588] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9878 2779190307.3385 933.0000
[2019-03-26 19:22:33,665] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 19:22:33,688] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6679 2927328479.9021 1338.0000
[2019-03-26 19:22:33,710] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4154 3164089036.9102 1778.0000
[2019-03-26 19:22:34,723] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 150000, evaluation results [150000.0, 7883.415428030625, 3164089036.9102125, 1778.0, 8253.667895353341, 2927328479.9020863, 1338.0, 8659.987755389953, 2779190307.3384666, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8495.959645458452, 2842607972.531135, 1131.0]
[2019-03-26 19:22:37,892] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 151492: loss 0.1127
[2019-03-26 19:22:37,894] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 151492: learning rate 0.0000
[2019-03-26 19:22:38,364] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 151715: loss 0.1076
[2019-03-26 19:22:38,364] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 151715: learning rate 0.0000
[2019-03-26 19:22:38,499] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 151781: loss 0.1232
[2019-03-26 19:22:38,503] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 151783: learning rate 0.0000
[2019-03-26 19:22:38,570] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 151814: loss 0.1830
[2019-03-26 19:22:38,572] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 151814: learning rate 0.0000
[2019-03-26 19:22:38,759] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 151902: loss 0.1274
[2019-03-26 19:22:38,761] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 151903: learning rate 0.0000
[2019-03-26 19:22:38,769] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 151906: loss 0.1380
[2019-03-26 19:22:38,773] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 151907: learning rate 0.0000
[2019-03-26 19:22:38,805] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 151925: loss 0.1468
[2019-03-26 19:22:38,806] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 151925: learning rate 0.0000
[2019-03-26 19:22:38,830] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 151936: loss 0.1205
[2019-03-26 19:22:38,834] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 151936: learning rate 0.0000
[2019-03-26 19:22:38,868] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 151948: loss 0.1007
[2019-03-26 19:22:38,873] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 151950: learning rate 0.0000
[2019-03-26 19:22:38,907] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 151972: loss 0.0887
[2019-03-26 19:22:38,911] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 151973: learning rate 0.0000
[2019-03-26 19:22:38,990] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 152007: loss 0.1613
[2019-03-26 19:22:38,991] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 152008: learning rate 0.0000
[2019-03-26 19:22:39,165] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 152088: loss 0.1389
[2019-03-26 19:22:39,169] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 152089: learning rate 0.0000
[2019-03-26 19:22:39,357] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 152176: loss 0.1484
[2019-03-26 19:22:39,360] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 152176: learning rate 0.0000
[2019-03-26 19:22:39,454] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 152221: loss 0.1683
[2019-03-26 19:22:39,461] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 152224: learning rate 0.0000
[2019-03-26 19:22:39,857] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 152433: loss 0.1699
[2019-03-26 19:22:39,859] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 152433: learning rate 0.0000
[2019-03-26 19:22:39,900] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 152461: loss 0.1232
[2019-03-26 19:22:39,901] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 152461: learning rate 0.0000
[2019-03-26 19:22:42,964] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1352454e-18 1.0000000e+00 2.8752851e-16 2.8767896e-15 1.6818150e-17], sum to 1.0000
[2019-03-26 19:22:42,972] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4153
[2019-03-26 19:22:42,977] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.35, 86.5, 1.0, 2.0, 0.5406072735995959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 755434.8485502941, 755434.8485502935, 190202.6357142658], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5783400.0000, 
sim time next is 5784000.0000, 
raw observation next is [27.3, 86.66666666666667, 1.0, 2.0, 0.5397328615130403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 754212.5270855926, 754212.527085592, 190055.2146745392], 
processed observation next is [0.0, 0.9565217391304348, 0.4928909952606636, 0.8666666666666667, 1.0, 1.0, 0.4454612789313739, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20950347974599795, 0.20950347974599778, 0.2836644995142376], 
reward next is 0.7163, 
noisyNet noise sample is [array([1.114702], dtype=float32), 0.46235162]. 
=============================================
[2019-03-26 19:22:42,996] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[67.74059]
 [67.69379]
 [67.64533]
 [67.58859]
 [67.54686]], R is [[67.83040619]
 [67.86821747]
 [67.90541077]
 [67.9417572 ]
 [67.97751617]].
[2019-03-26 19:22:44,598] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.8701862e-18 1.0000000e+00 6.5700576e-15 6.0861608e-14 5.7452995e-16], sum to 1.0000
[2019-03-26 19:22:44,608] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4706
[2019-03-26 19:22:44,608] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1988716.893981853 W.
[2019-03-26 19:22:44,619] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.7, 89.66666666666667, 1.0, 2.0, 0.4741201308803493, 1.0, 1.0, 0.4741201308803493, 1.0, 1.0, 0.8177374655927996, 6.9112, 6.9112, 170.5573041426782, 1988716.893981853, 1988716.893981853, 396748.3683917068], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5797200.0000, 
sim time next is 5797800.0000, 
raw observation next is [26.65, 90.0, 1.0, 2.0, 0.5930139548157445, 0.0, 1.0, 0.0, 1.0, 2.0, 1.012322847895439, 6.9112, 6.9112, 168.9129562504637, 1658038.198419172, 1658038.198419172, 359363.0155227557], 
processed observation next is [1.0, 0.08695652173913043, 0.462085308056872, 0.9, 1.0, 1.0, 0.5096553672478848, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0150278632871206, 0.0, 0.0, 0.8294399438757443, 0.4605661662275478, 0.4605661662275478, 0.5363627097354562], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.88073486], dtype=float32), -0.026877841]. 
=============================================
[2019-03-26 19:22:49,574] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.60250681e-18 1.00000000e+00 1.39285028e-15 7.17418377e-16
 1.10274665e-17], sum to 1.0000
[2019-03-26 19:22:49,585] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3490
[2019-03-26 19:22:49,595] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 95.0, 1.0, 2.0, 0.8228677927758413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1150074.169842294, 1150074.169842294, 249600.277331638], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5889000.0000, 
sim time next is 5889600.0000, 
raw observation next is [25.7, 95.0, 1.0, 2.0, 0.8046205679501416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1124557.586466148, 1124557.586466147, 245046.9223346355], 
processed observation next is [1.0, 0.17391304347826086, 0.4170616113744076, 0.95, 1.0, 1.0, 0.7646030939158333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31237710735170776, 0.31237710735170754, 0.36574167512632166], 
reward next is 0.6343, 
noisyNet noise sample is [array([-0.44801146], dtype=float32), -1.4428802]. 
=============================================
[2019-03-26 19:22:49,716] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.5454019e-19 1.0000000e+00 2.5582195e-16 1.6316644e-16 1.1514616e-17], sum to 1.0000
[2019-03-26 19:22:49,723] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0908
[2019-03-26 19:22:49,732] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 95.33333333333334, 1.0, 2.0, 0.6529595923711611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 912501.3919981535, 912501.3919981542, 211018.2105547009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5890800.0000, 
sim time next is 5891400.0000, 
raw observation next is [25.65, 95.5, 1.0, 2.0, 0.6471841503213586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 904426.8603967883, 904426.8603967878, 209857.000412857], 
processed observation next is [1.0, 0.17391304347826086, 0.41469194312796204, 0.955, 1.0, 1.0, 0.5749206630377813, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25122968344355234, 0.2512296834435522, 0.31321940360127914], 
reward next is 0.6868, 
noisyNet noise sample is [array([0.02956136], dtype=float32), 0.79262066]. 
=============================================
[2019-03-26 19:22:55,427] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 159545: loss -204.1113
[2019-03-26 19:22:55,428] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 159545: learning rate 0.0000
[2019-03-26 19:22:55,965] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 159787: loss -222.0436
[2019-03-26 19:22:55,966] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 159788: learning rate 0.0000
[2019-03-26 19:22:56,000] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 159802: loss -206.0895
[2019-03-26 19:22:56,002] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 159802: learning rate 0.0000
[2019-03-26 19:22:56,081] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 159836: loss -240.8036
[2019-03-26 19:22:56,082] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 159836: learning rate 0.0000
[2019-03-26 19:22:56,244] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 159909: loss -254.2818
[2019-03-26 19:22:56,244] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 159909: learning rate 0.0000
[2019-03-26 19:22:56,270] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 159919: loss -237.6724
[2019-03-26 19:22:56,273] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 159920: learning rate 0.0000
[2019-03-26 19:22:56,280] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 159925: loss -303.1270
[2019-03-26 19:22:56,286] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 159925: learning rate 0.0000
[2019-03-26 19:22:56,316] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.8755265e-16 1.0000000e+00 1.3604637e-14 5.4020688e-13 9.1869930e-15], sum to 1.0000
[2019-03-26 19:22:56,324] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5005
[2019-03-26 19:22:56,332] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2414651.174187958 W.
[2019-03-26 19:22:56,335] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.1, 73.0, 1.0, 2.0, 0.5755584271937971, 1.0, 1.0, 0.5755584271937971, 1.0, 2.0, 0.9995546479551857, 6.9112, 6.9112, 170.5573041426782, 2414651.174187958, 2414651.174187958, 471328.3707642488], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5999400.0000, 
sim time next is 6000000.0000, 
raw observation next is [31.26666666666667, 72.33333333333333, 1.0, 2.0, 0.5613470064087528, 1.0, 2.0, 0.5613470064087528, 1.0, 2.0, 0.9748741098402341, 6.9112, 6.9112, 170.5573041426782, 2354973.551983547, 2354973.551983547, 460161.4562521687], 
processed observation next is [1.0, 0.43478260869565216, 0.6808846761453398, 0.7233333333333333, 1.0, 1.0, 0.4715024173599431, 1.0, 1.0, 0.4715024173599431, 1.0, 1.0, 0.9693586705368707, 0.0, 0.0, 0.8375144448122397, 0.6541593199954298, 0.6541593199954298, 0.6868081436599532], 
reward next is 0.3132, 
noisyNet noise sample is [array([-0.3948023], dtype=float32), 0.105433054]. 
=============================================
[2019-03-26 19:22:56,335] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 159943: loss -230.3793
[2019-03-26 19:22:56,336] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 159943: learning rate 0.0000
[2019-03-26 19:22:56,349] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[61.032074]
 [61.390846]
 [61.54297 ]
 [61.950912]
 [62.571674]], R is [[60.12247086]
 [59.52124786]
 [58.92603683]
 [58.33677673]
 [57.75341034]].
[2019-03-26 19:22:56,351] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 159948: loss -242.8687
[2019-03-26 19:22:56,358] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 159948: learning rate 0.0000
[2019-03-26 19:22:56,414] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 159976: loss -197.7371
[2019-03-26 19:22:56,416] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 159977: learning rate 0.0000
[2019-03-26 19:22:56,426] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 159981: loss -141.1521
[2019-03-26 19:22:56,428] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 159982: learning rate 0.0000
[2019-03-26 19:22:56,694] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 160100: loss -201.8283
[2019-03-26 19:22:56,696] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 160100: learning rate 0.0000
[2019-03-26 19:22:56,736] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 160117: loss -200.4339
[2019-03-26 19:22:56,740] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 160117: learning rate 0.0000
[2019-03-26 19:22:56,848] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 160167: loss -221.0185
[2019-03-26 19:22:56,852] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 160167: learning rate 0.0000
[2019-03-26 19:22:57,329] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 160376: loss -269.4548
[2019-03-26 19:22:57,333] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 160376: learning rate 0.0000
[2019-03-26 19:22:57,345] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 160383: loss -193.3294
[2019-03-26 19:22:57,346] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 160383: learning rate 0.0000
[2019-03-26 19:22:57,943] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.8303424e-16 1.0000000e+00 5.7259204e-14 7.3006352e-14 7.0091701e-16], sum to 1.0000
[2019-03-26 19:22:57,951] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6534
[2019-03-26 19:22:57,957] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 72.0, 1.0, 2.0, 0.5288687236323367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 739025.9044827132, 739025.9044827132, 188244.2116368087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6026400.0000, 
sim time next is 6027000.0000, 
raw observation next is [29.81666666666667, 73.0, 1.0, 2.0, 0.5333841168605511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 745337.7984546522, 745337.7984546529, 188993.0165104999], 
processed observation next is [1.0, 0.782608695652174, 0.6121642969984205, 0.73, 1.0, 1.0, 0.43781218898861574, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2070382773485145, 0.20703827734851468, 0.2820791291201491], 
reward next is 0.7179, 
noisyNet noise sample is [array([-0.6200555], dtype=float32), -1.6711618]. 
=============================================
[2019-03-26 19:22:57,971] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[60.05606 ]
 [59.199585]
 [58.126926]
 [57.71768 ]
 [57.18463 ]], R is [[61.00454712]
 [61.11354065]
 [61.22400284]
 [61.3359642 ]
 [61.44933319]].
[2019-03-26 19:23:02,703] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.6483146e-15 1.0000000e+00 1.0648028e-12 4.5431622e-13 9.9814066e-15], sum to 1.0000
[2019-03-26 19:23:02,715] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7947
[2019-03-26 19:23:02,723] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2259704.62036299 W.
[2019-03-26 19:23:02,728] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.1, 65.0, 1.0, 2.0, 0.8079878832361204, 1.0, 1.0, 0.8079878832361204, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2259704.62036299, 2259704.62036299, 423775.9715050642], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6096600.0000, 
sim time next is 6097200.0000, 
raw observation next is [31.1, 65.0, 1.0, 2.0, 0.7889009206072692, 1.0, 2.0, 0.7889009206072692, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2206275.943725944, 2206275.943725944, 414501.4921406985], 
processed observation next is [1.0, 0.5652173913043478, 0.6729857819905214, 0.65, 1.0, 1.0, 0.7456637597677942, 1.0, 1.0, 0.7456637597677942, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6128544288127622, 0.6128544288127622, 0.6186589434935799], 
reward next is 0.3813, 
noisyNet noise sample is [array([1.1997757], dtype=float32), 1.2131162]. 
=============================================
[2019-03-26 19:23:08,606] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.2930718e-18 1.0000000e+00 1.0757202e-15 2.3758618e-15 5.3855251e-17], sum to 1.0000
[2019-03-26 19:23:08,617] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4635
[2019-03-26 19:23:08,621] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.58333333333334, 84.5, 1.0, 2.0, 0.530354557545269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 741102.8902399419, 741102.8902399419, 188488.9550259797], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6205800.0000, 
sim time next is 6206400.0000, 
raw observation next is [27.5, 85.0, 1.0, 2.0, 0.5310323353892278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742050.3291968158, 742050.3291968158, 188601.2464162806], 
processed observation next is [1.0, 0.8695652173913043, 0.5023696682464456, 0.85, 1.0, 1.0, 0.43497871733641896, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20612509144355995, 0.20612509144355995, 0.2814943976362397], 
reward next is 0.7185, 
noisyNet noise sample is [array([0.76583487], dtype=float32), 0.029035555]. 
=============================================
[2019-03-26 19:23:13,124] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 167427: loss 0.2953
[2019-03-26 19:23:13,127] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 167427: learning rate 0.0000
[2019-03-26 19:23:13,760] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 167708: loss 0.2818
[2019-03-26 19:23:13,766] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 167709: learning rate 0.0000
[2019-03-26 19:23:13,927] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 167783: loss 0.3165
[2019-03-26 19:23:13,930] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 167783: learning rate 0.0000
[2019-03-26 19:23:14,123] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 167871: loss 0.2578
[2019-03-26 19:23:14,126] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 167872: learning rate 0.0000
[2019-03-26 19:23:14,144] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 167882: loss 0.2966
[2019-03-26 19:23:14,150] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 167882: learning rate 0.0000
[2019-03-26 19:23:14,160] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 167888: loss 0.2380
[2019-03-26 19:23:14,164] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 167889: loss 0.2992
[2019-03-26 19:23:14,165] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 167889: learning rate 0.0000
[2019-03-26 19:23:14,166] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 167889: learning rate 0.0000
[2019-03-26 19:23:14,230] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 167922: loss 0.2915
[2019-03-26 19:23:14,236] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 167923: learning rate 0.0000
[2019-03-26 19:23:14,279] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 167940: loss 0.3177
[2019-03-26 19:23:14,284] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 167942: learning rate 0.0000
[2019-03-26 19:23:14,373] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 167983: loss 0.2583
[2019-03-26 19:23:14,376] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 167983: learning rate 0.0000
[2019-03-26 19:23:14,427] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 168007: loss 0.3110
[2019-03-26 19:23:14,432] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 168007: learning rate 0.0000
[2019-03-26 19:23:14,615] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 168093: loss 0.2574
[2019-03-26 19:23:14,616] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 168093: learning rate 0.0000
[2019-03-26 19:23:14,795] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 168178: loss 0.2268
[2019-03-26 19:23:14,798] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 168178: learning rate 0.0000
[2019-03-26 19:23:14,927] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 168238: loss 0.2082
[2019-03-26 19:23:14,934] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 168238: learning rate 0.0000
[2019-03-26 19:23:15,446] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 168471: loss 0.2586
[2019-03-26 19:23:15,449] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 168471: learning rate 0.0000
[2019-03-26 19:23:15,503] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 168496: loss 0.2443
[2019-03-26 19:23:15,507] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 168497: learning rate 0.0000
[2019-03-26 19:23:18,096] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2627911e-18 1.0000000e+00 2.5162448e-15 5.6291298e-15 5.4489068e-16], sum to 1.0000
[2019-03-26 19:23:18,106] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2545
[2019-03-26 19:23:18,112] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.25, 70.5, 1.0, 2.0, 0.5158433814178596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 720818.4913110913, 720818.4913110913, 186115.4075364385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6367800.0000, 
sim time next is 6368400.0000, 
raw observation next is [28.9, 72.0, 1.0, 2.0, 0.5143807941019103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 718774.0400198154, 718774.0400198147, 185879.6017012107], 
processed observation next is [0.0, 0.7391304347826086, 0.5687203791469194, 0.72, 1.0, 1.0, 0.4149166193998919, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19965945556105985, 0.19965945556105966, 0.2774322413450906], 
reward next is 0.7226, 
noisyNet noise sample is [array([0.12151614], dtype=float32), -0.9556761]. 
=============================================
[2019-03-26 19:23:18,501] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9714822e-18 1.0000000e+00 1.1957617e-15 1.8226792e-15 4.8404800e-17], sum to 1.0000
[2019-03-26 19:23:18,510] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8690
[2019-03-26 19:23:18,513] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1020443e-17 1.0000000e+00 1.7439436e-14 8.5928985e-15 6.6301520e-16], sum to 1.0000
[2019-03-26 19:23:18,519] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.23333333333333, 82.0, 1.0, 2.0, 0.5136162823872085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 717705.3826788549, 717705.3826788554, 185756.5918737479], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6389400.0000, 
sim time next is 6390000.0000, 
raw observation next is [27.2, 82.0, 1.0, 2.0, 0.5123752175565013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 715970.587428095, 715970.5874280944, 185557.364716329], 
processed observation next is [0.0, 1.0, 0.4881516587677725, 0.82, 1.0, 1.0, 0.41250026211626656, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1988807187300264, 0.19888071873002622, 0.27695129062138657], 
reward next is 0.7230, 
noisyNet noise sample is [array([1.0464257], dtype=float32), 0.56431305]. 
=============================================
[2019-03-26 19:23:18,525] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5648
[2019-03-26 19:23:18,528] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 65.0, 1.0, 2.0, 0.5368629694898716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 750200.7778971322, 750200.7778971328, 189573.3209990672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6362400.0000, 
sim time next is 6363000.0000, 
raw observation next is [31.0, 64.5, 1.0, 2.0, 0.5319731121381953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 743365.4053665273, 743365.4053665273, 188757.3890295669], 
processed observation next is [0.0, 0.6521739130434783, 0.6682464454976303, 0.645, 1.0, 1.0, 0.43611218329903045, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2064903903795909, 0.2064903903795909, 0.2817274463127864], 
reward next is 0.7183, 
noisyNet noise sample is [array([-2.2071865], dtype=float32), -0.3688103]. 
=============================================
[2019-03-26 19:23:18,531] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[69.61453]
 [69.55832]
 [69.49181]
 [69.42858]
 [69.36179]], R is [[69.6950531 ]
 [69.72084808]
 [69.74610901]
 [69.77084351]
 [69.7950592 ]].
[2019-03-26 19:23:18,540] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[65.414665]
 [65.35568 ]
 [65.27524 ]
 [65.21213 ]
 [65.162796]], R is [[65.52645874]
 [65.58824921]
 [65.6445694 ]
 [65.70529938]
 [65.76651001]].
[2019-03-26 19:23:21,633] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.4781301e-19 1.0000000e+00 3.3497593e-16 8.6240580e-16 5.5566281e-17], sum to 1.0000
[2019-03-26 19:23:21,641] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5213
[2019-03-26 19:23:21,646] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.03333333333333, 83.0, 1.0, 2.0, 0.5110430279115776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 714108.4185074257, 714108.4185074263, 185344.0614224369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6399600.0000, 
sim time next is 6400200.0000, 
raw observation next is [27.01666666666667, 83.0, 1.0, 2.0, 0.510108049918798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712801.4841913255, 712801.4841913255, 185194.6590759626], 
processed observation next is [1.0, 0.043478260869565216, 0.4794628751974725, 0.83, 1.0, 1.0, 0.4097687348419253, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1980004122753682, 0.1980004122753682, 0.2764099389193472], 
reward next is 0.7236, 
noisyNet noise sample is [array([1.0511503], dtype=float32), -1.4269997]. 
=============================================
[2019-03-26 19:23:23,400] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0867327e-15 1.0000000e+00 2.1638350e-13 2.3320316e-13 1.4380739e-14], sum to 1.0000
[2019-03-26 19:23:23,411] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9379
[2019-03-26 19:23:23,418] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2311143.795650394 W.
[2019-03-26 19:23:23,422] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.95, 68.5, 1.0, 2.0, 1.011532380130795, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.983721374431889, 6.9112, 168.9125249978266, 2311143.795650394, 2259694.76806966, 467678.4066929878], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6442200.0000, 
sim time next is 6442800.0000, 
raw observation next is [29.96666666666667, 68.33333333333333, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.984564558242527, 6.9112, 168.9122820262267, 2353628.804816809, 2301581.670015926, 476746.9266698058], 
processed observation next is [1.0, 0.5652173913043478, 0.6192733017377569, 0.6833333333333332, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007336455824252663, 0.0, 0.8294366331260794, 0.6537857791157803, 0.6393282416710906, 0.7115625771191131], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5999426], dtype=float32), 1.7963725]. 
=============================================
[2019-03-26 19:23:24,828] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7649936e-20 1.0000000e+00 3.0499307e-17 3.2512946e-17 1.1359945e-18], sum to 1.0000
[2019-03-26 19:23:24,835] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0421
[2019-03-26 19:23:24,840] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 87.0, 1.0, 2.0, 0.5307494053681528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 741654.8323595145, 741654.8323595152, 188554.3217904331], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6476400.0000, 
sim time next is 6477000.0000, 
raw observation next is [27.15, 87.16666666666667, 1.0, 2.0, 0.5316882047698023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 742967.1439800152, 742967.1439800158, 188709.9675605736], 
processed observation next is [1.0, 1.0, 0.485781990521327, 0.8716666666666667, 1.0, 1.0, 0.4357689214094003, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2063797622166709, 0.20637976221667104, 0.2816566680008561], 
reward next is 0.7183, 
noisyNet noise sample is [array([-0.41152093], dtype=float32), -0.71667546]. 
=============================================
[2019-03-26 19:23:24,853] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[73.2764 ]
 [73.1873 ]
 [73.1013 ]
 [73.00292]
 [72.90278]], R is [[73.36042023]
 [73.34539032]
 [73.33086395]
 [73.31678772]
 [73.30311584]].
[2019-03-26 19:23:26,248] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8462574e-20 1.0000000e+00 7.0284173e-17 3.9329262e-17 9.4806251e-19], sum to 1.0000
[2019-03-26 19:23:26,258] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5229
[2019-03-26 19:23:26,262] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.25, 86.33333333333333, 1.0, 2.0, 0.5293408073653753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 739685.8103626199, 739685.8103626193, 188321.0480314826], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6475800.0000, 
sim time next is 6476400.0000, 
raw observation next is [27.2, 87.0, 1.0, 2.0, 0.5307494053681528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 741654.8323595145, 741654.8323595152, 188554.3217904331], 
processed observation next is [1.0, 1.0, 0.4881516587677725, 0.87, 1.0, 1.0, 0.43463783779295523, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20601523121097626, 0.20601523121097645, 0.28142436088124345], 
reward next is 0.7186, 
noisyNet noise sample is [array([-0.87686884], dtype=float32), 0.7479927]. 
=============================================
[2019-03-26 19:23:27,597] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.7959677e-18 1.0000000e+00 2.8066242e-15 6.9826732e-15 7.0756331e-16], sum to 1.0000
[2019-03-26 19:23:27,605] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2018
[2019-03-26 19:23:27,615] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1959576.516676495 W.
[2019-03-26 19:23:27,619] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.8, 66.0, 1.0, 2.0, 0.7603452491832494, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.973901029848824, 6.9112, 168.9125829936063, 1959576.516676495, 1915094.346462374, 399377.5619806084], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6516000.0000, 
sim time next is 6516600.0000, 
raw observation next is [30.01666666666667, 64.5, 1.0, 2.0, 0.7479589698833264, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.970150449466946, 6.9112, 168.912554217544, 1942242.49023792, 1900421.112072637, 396591.7797274195], 
processed observation next is [1.0, 0.43478260869565216, 0.6216429699842023, 0.645, 1.0, 1.0, 0.6963361082931644, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.005895044946694572, 0.0, 0.829437969710057, 0.5395118028438667, 0.5278947533535103, 0.5919280294439097], 
reward next is 0.1133, 
noisyNet noise sample is [array([-0.69794863], dtype=float32), -0.40293184]. 
=============================================
[2019-03-26 19:23:30,180] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 19:23:30,181] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:23:30,181] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:23:30,182] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:23:30,182] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:23:30,182] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:23:30,183] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:23:30,185] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:23:30,185] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:23:30,188] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:23:30,188] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:23:30,207] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run8
[2019-03-26 19:23:30,230] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run8
[2019-03-26 19:23:30,231] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run8
[2019-03-26 19:23:30,231] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run8
[2019-03-26 19:23:30,231] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run8
[2019-03-26 19:23:53,154] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04954733], dtype=float32), 0.056216944]
[2019-03-26 19:23:53,156] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.0, 51.0, 1.0, 2.0, 0.3428707597271431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527662.0149253301, 527662.0149253301, 168795.5129784984]
[2019-03-26 19:23:53,157] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:23:53,163] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.3002661e-16 1.0000000e+00 5.7000296e-14 4.5251285e-14 2.5119099e-15], sampled 0.27989636842963916
[2019-03-26 19:24:36,654] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04954733], dtype=float32), 0.056216944]
[2019-03-26 19:24:36,655] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.8, 70.0, 1.0, 2.0, 0.5740280698154621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 802154.1003865645, 802154.1003865645, 196006.2369027617]
[2019-03-26 19:24:36,656] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:24:36,659] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0697156e-18 1.0000000e+00 8.2811251e-16 1.0448295e-15 3.9005788e-17], sampled 0.24334539067517436
[2019-03-26 19:24:42,439] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04954733], dtype=float32), 0.056216944]
[2019-03-26 19:24:42,440] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.4312627, 65.86458985499999, 1.0, 2.0, 1.039941638767091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1453673.29157496, 1453673.29157496, 311328.8320673749]
[2019-03-26 19:24:42,440] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:24:42,445] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.4650105e-19 1.0000000e+00 3.0819664e-16 2.8961676e-16 9.7458593e-18], sampled 0.3760648932704004
[2019-03-26 19:24:55,424] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04954733], dtype=float32), 0.056216944]
[2019-03-26 19:24:55,425] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.81666666666667, 89.0, 1.0, 2.0, 0.5347091481231504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 747190.0156496192, 747190.0156496197, 189212.6271551946]
[2019-03-26 19:24:55,426] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:24:55,430] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.58969420e-18 1.00000000e+00 2.90599619e-15 2.88182017e-15
 1.03299916e-16], sampled 0.3362157855880433
[2019-03-26 19:25:13,189] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04954733], dtype=float32), 0.056216944]
[2019-03-26 19:25:13,190] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.05402274, 86.79436673, 1.0, 2.0, 0.4781697612748312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 668158.3557279297, 668158.3557279297, 180246.9755190967]
[2019-03-26 19:25:13,191] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:25:13,193] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0657118e-18 1.0000000e+00 8.9110291e-16 1.0322355e-15 3.1785480e-17], sampled 0.6463828362362957
[2019-03-26 19:25:20,244] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04954733], dtype=float32), 0.056216944]
[2019-03-26 19:25:20,245] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.16666666666667, 62.0, 1.0, 2.0, 0.4445139563660606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 633156.6034245412, 633156.6034245412, 176913.5538732694]
[2019-03-26 19:25:20,246] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:25:20,248] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.5299319e-17 1.0000000e+00 8.3209332e-15 8.3334489e-15 3.6916152e-16], sampled 0.800596673280162
[2019-03-26 19:25:24,781] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.8607 3007711637.9330 1766.0000
[2019-03-26 19:25:25,297] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 19:25:25,326] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5752 2842451949.6408 1131.0000
[2019-03-26 19:25:25,346] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1685 3164067279.4129 1778.0000
[2019-03-26 19:25:25,374] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.0653 2927317329.7462 1338.0000
[2019-03-26 19:25:26,385] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 175000, evaluation results [175000.0, 7884.168455680242, 3164067279.4128904, 1778.0, 8255.065342017213, 2927317329.746172, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7998.86073322157, 3007711637.9330444, 1766.0, 8497.575228127671, 2842451949.640752, 1131.0]
[2019-03-26 19:25:27,255] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 175414: loss -294.3286
[2019-03-26 19:25:27,257] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 175414: learning rate 0.0000
[2019-03-26 19:25:27,906] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 175709: loss -304.3748
[2019-03-26 19:25:27,909] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 175710: learning rate 0.0000
[2019-03-26 19:25:27,970] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 175739: loss -269.2860
[2019-03-26 19:25:27,974] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 175740: learning rate 0.0000
[2019-03-26 19:25:28,188] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 175841: loss -276.7523
[2019-03-26 19:25:28,192] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 175842: learning rate 0.0000
[2019-03-26 19:25:28,279] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 175889: loss -347.3416
[2019-03-26 19:25:28,281] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 175890: loss -363.8428
[2019-03-26 19:25:28,282] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 175889: learning rate 0.0000
[2019-03-26 19:25:28,284] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 175892: learning rate 0.0000
[2019-03-26 19:25:28,345] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 175915: loss -317.7029
[2019-03-26 19:25:28,347] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 175915: learning rate 0.0000
[2019-03-26 19:25:28,359] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 175923: loss -341.3283
[2019-03-26 19:25:28,360] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 175923: learning rate 0.0000
[2019-03-26 19:25:28,447] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 175963: loss -292.3640
[2019-03-26 19:25:28,449] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 175964: learning rate 0.0000
[2019-03-26 19:25:28,463] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 175970: loss -299.8959
[2019-03-26 19:25:28,464] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 175970: learning rate 0.0000
[2019-03-26 19:25:28,470] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 175970: loss -225.1577
[2019-03-26 19:25:28,473] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 175972: learning rate 0.0000
[2019-03-26 19:25:28,619] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 176038: loss -339.4980
[2019-03-26 19:25:28,622] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 176038: learning rate 0.0000
[2019-03-26 19:25:28,643] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.25219594e-16 1.00000000e+00 1.01099007e-13 3.04226045e-14
 2.07144152e-15], sum to 1.0000
[2019-03-26 19:25:28,650] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7657
[2019-03-26 19:25:28,657] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2393629.777879627 W.
[2019-03-26 19:25:28,663] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.051826120713041, 6.9112, 168.9120753330483, 2393629.777879627, 2293865.28831779, 476272.0247427998], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6609600.0000, 
sim time next is 6610200.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.8011374567282207, 1.0, 1.0, 0.8011374567282207, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2240528.817544354, 2240528.817544354, 420423.2589658666], 
processed observation next is [1.0, 0.5217391304347826, 0.6682464454976303, 0.66, 1.0, 1.0, 0.7604065743713502, 1.0, 0.5, 0.7604065743713502, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6223691159845428, 0.6223691159845428, 0.6274974014415919], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.6102808], dtype=float32), 1.2450813]. 
=============================================
[2019-03-26 19:25:28,919] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 176174: loss -221.9672
[2019-03-26 19:25:28,921] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 176175: learning rate 0.0000
[2019-03-26 19:25:29,004] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 176216: loss -261.8513
[2019-03-26 19:25:29,007] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 176217: learning rate 0.0000
[2019-03-26 19:25:29,461] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 176424: loss -299.8067
[2019-03-26 19:25:29,463] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 176424: learning rate 0.0000
[2019-03-26 19:25:29,526] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 176455: loss -336.2723
[2019-03-26 19:25:29,529] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 176455: learning rate 0.0000
[2019-03-26 19:25:34,488] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.0727707e-15 1.0000000e+00 4.9164823e-13 4.2304384e-13 2.2898187e-14], sum to 1.0000
[2019-03-26 19:25:34,496] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6817
[2019-03-26 19:25:34,503] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2026344.679728324 W.
[2019-03-26 19:25:34,509] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.86666666666667, 64.33333333333333, 1.0, 2.0, 0.4830823088089595, 1.0, 2.0, 0.4830823088089595, 1.0, 2.0, 0.8204228829160012, 6.911200000000001, 6.9112, 170.5573041426782, 2026344.679728324, 2026344.679728324, 400376.5523226307], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6709200.0000, 
sim time next is 6709800.0000, 
raw observation next is [29.83333333333334, 64.66666666666667, 1.0, 2.0, 0.7260836682427653, 1.0, 2.0, 0.7260836682427653, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2030431.882055632, 2030431.882055632, 385480.9137132887], 
processed observation next is [1.0, 0.6521739130434783, 0.6129541864139023, 0.6466666666666667, 1.0, 1.0, 0.6699803231840545, 1.0, 1.0, 0.6699803231840545, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5640088561265645, 0.5640088561265645, 0.5753446473332667], 
reward next is 0.4247, 
noisyNet noise sample is [array([-0.1350037], dtype=float32), -0.3833214]. 
=============================================
[2019-03-26 19:25:40,086] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.2872956e-19 1.0000000e+00 5.4269566e-17 1.6931260e-16 1.1046160e-17], sum to 1.0000
[2019-03-26 19:25:40,099] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8786
[2019-03-26 19:25:40,105] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.95, 50.33333333333334, 1.0, 2.0, 0.4634626496994402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 715458.3699750584, 715458.369975059, 186202.897116919], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6801000.0000, 
sim time next is 6801600.0000, 
raw observation next is [28.8, 50.66666666666667, 1.0, 2.0, 0.3253137773952314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 503269.5484397367, 503269.5484397367, 166966.0851520679], 
processed observation next is [1.0, 0.7391304347826086, 0.5639810426540285, 0.5066666666666667, 1.0, 1.0, 0.18712503300630284, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13979709678881574, 0.13979709678881574, 0.24920311216726554], 
reward next is 0.7508, 
noisyNet noise sample is [array([-0.5170728], dtype=float32), 1.9608456]. 
=============================================
[2019-03-26 19:25:43,292] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1187507e-16 1.0000000e+00 2.0297700e-14 1.6268308e-14 1.4865324e-15], sum to 1.0000
[2019-03-26 19:25:43,299] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7496
[2019-03-26 19:25:43,304] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.01666666666667, 60.5, 1.0, 2.0, 0.3552286247109708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 546793.3043005125, 546793.3043005131, 170366.6043472594], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6861000.0000, 
sim time next is 6861600.0000, 
raw observation next is [27.2, 59.0, 1.0, 2.0, 0.3515686018820105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 542502.2869446904, 542502.286944691, 170049.3311366432], 
processed observation next is [0.0, 0.43478260869565216, 0.4881516587677725, 0.59, 1.0, 1.0, 0.2187573516650729, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15069507970685844, 0.1506950797068586, 0.2538049718457361], 
reward next is 0.7462, 
noisyNet noise sample is [array([0.6795303], dtype=float32), -1.2127482]. 
=============================================
[2019-03-26 19:25:44,564] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 183374: loss 0.9002
[2019-03-26 19:25:44,567] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 183374: learning rate 0.0000
[2019-03-26 19:25:45,299] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 183702: loss 0.7385
[2019-03-26 19:25:45,302] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 183702: learning rate 0.0000
[2019-03-26 19:25:45,419] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 183755: loss 0.8462
[2019-03-26 19:25:45,421] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 183757: learning rate 0.0000
[2019-03-26 19:25:45,548] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 183813: loss 0.8692
[2019-03-26 19:25:45,551] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 183814: learning rate 0.0000
[2019-03-26 19:25:45,737] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 183892: loss 0.7662
[2019-03-26 19:25:45,740] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 183893: learning rate 0.0000
[2019-03-26 19:25:45,752] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.99524004e-17 1.00000000e+00 1.14742946e-14 2.46327955e-14
 3.75796940e-16], sum to 1.0000
[2019-03-26 19:25:45,758] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1826
[2019-03-26 19:25:45,762] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.46666666666667, 59.83333333333334, 1.0, 2.0, 0.3651673809196034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 557958.4867546587, 557958.4867546587, 171189.7000053049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6894600.0000, 
sim time next is 6895200.0000, 
raw observation next is [27.33333333333334, 60.66666666666667, 1.0, 2.0, 0.3659445231085839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 558768.4986753551, 558768.4986753558, 171247.8002511893], 
processed observation next is [0.0, 0.8260869565217391, 0.4944707740916275, 0.6066666666666667, 1.0, 1.0, 0.2360777386850408, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15521347185426532, 0.1552134718542655, 0.255593731718193], 
reward next is 0.7444, 
noisyNet noise sample is [array([-0.5418932], dtype=float32), 1.7007117]. 
=============================================
[2019-03-26 19:25:45,818] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 183932: loss 0.8357
[2019-03-26 19:25:45,820] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 183934: learning rate 0.0000
[2019-03-26 19:25:45,851] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 183947: loss 0.7952
[2019-03-26 19:25:45,854] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 183949: learning rate 0.0000
[2019-03-26 19:25:45,861] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 183951: loss 0.7348
[2019-03-26 19:25:45,865] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 183952: learning rate 0.0000
[2019-03-26 19:25:45,907] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 183969: loss 0.7909
[2019-03-26 19:25:45,909] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 183969: learning rate 0.0000
[2019-03-26 19:25:45,943] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 183986: loss 0.7273
[2019-03-26 19:25:45,947] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 183988: learning rate 0.0000
[2019-03-26 19:25:45,948] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 183989: loss 0.8553
[2019-03-26 19:25:45,953] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 183990: learning rate 0.0000
[2019-03-26 19:25:46,060] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 184036: loss 0.7213
[2019-03-26 19:25:46,062] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 184036: learning rate 0.0000
[2019-03-26 19:25:46,396] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 184186: loss 0.7230
[2019-03-26 19:25:46,399] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 184187: learning rate 0.0000
[2019-03-26 19:25:46,590] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 184278: loss 0.8132
[2019-03-26 19:25:46,595] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 184280: learning rate 0.0000
[2019-03-26 19:25:47,063] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 184491: loss 0.8804
[2019-03-26 19:25:47,067] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 184493: learning rate 0.0000
[2019-03-26 19:25:47,072] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 184496: loss 0.7172
[2019-03-26 19:25:47,078] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 184498: learning rate 0.0000
[2019-03-26 19:25:48,940] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8064324e-16 1.0000000e+00 2.6659152e-14 1.1274317e-14 1.2712222e-15], sum to 1.0000
[2019-03-26 19:25:48,946] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4590
[2019-03-26 19:25:48,950] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666666, 52.66666666666667, 1.0, 2.0, 0.4683991813756679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 655373.9722792763, 655373.972279277, 178905.9571989406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6957600.0000, 
sim time next is 6958200.0000, 
raw observation next is [31.83333333333333, 52.33333333333334, 1.0, 2.0, 0.471694100601146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 659106.9488606076, 659106.9488606076, 179279.9763761303], 
processed observation next is [0.0, 0.5217391304347826, 0.7077409162717218, 0.5233333333333334, 1.0, 1.0, 0.3634868681941518, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.183085263572391, 0.183085263572391, 0.2675820542927318], 
reward next is 0.7324, 
noisyNet noise sample is [array([1.1178935], dtype=float32), 1.6415899]. 
=============================================
[2019-03-26 19:25:49,379] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0546513e-17 1.0000000e+00 3.5628107e-15 3.0590341e-15 2.0270790e-16], sum to 1.0000
[2019-03-26 19:25:49,386] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2610
[2019-03-26 19:25:49,394] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.81666666666667, 52.0, 1.0, 2.0, 0.4655127809537518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 652273.3864311778, 652273.3864311778, 178603.0257078125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6965400.0000, 
sim time next is 6966000.0000, 
raw observation next is [32.0, 52.0, 1.0, 2.0, 0.4712522346341112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 658489.3299567733, 658489.329956774, 179214.6750887377], 
processed observation next is [0.0, 0.6521739130434783, 0.7156398104265403, 0.52, 1.0, 1.0, 0.36295449955917014, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18291370276577038, 0.18291370276577057, 0.26748458968468314], 
reward next is 0.7325, 
noisyNet noise sample is [array([0.9704349], dtype=float32), -1.3172712]. 
=============================================
[2019-03-26 19:25:49,418] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[63.965134]
 [63.900482]
 [63.828037]
 [63.764885]
 [63.704414]], R is [[64.13385773]
 [64.22594452]
 [64.31786346]
 [64.40973663]
 [64.5020752 ]].
[2019-03-26 19:25:57,060] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3865912e-20 1.0000000e+00 2.6559688e-17 4.8853161e-17 8.1663548e-20], sum to 1.0000
[2019-03-26 19:25:57,069] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6133
[2019-03-26 19:25:57,075] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.23333333333333, 88.83333333333334, 1.0, 2.0, 0.4723686625885019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 662500.8905011335, 662500.8905011329, 179696.5471681743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7084200.0000, 
sim time next is 7084800.0000, 
raw observation next is [25.2, 89.0, 1.0, 2.0, 0.4718344121776715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 662063.976337504, 662063.9763375047, 179657.2734908038], 
processed observation next is [1.0, 0.0, 0.3933649289099526, 0.89, 1.0, 1.0, 0.3636559182863512, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18390666009375112, 0.1839066600937513, 0.2681451843146326], 
reward next is 0.7319, 
noisyNet noise sample is [array([0.4288015], dtype=float32), -1.5802672]. 
=============================================
[2019-03-26 19:26:02,294] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 191303: loss 0.0867
[2019-03-26 19:26:02,301] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 191306: learning rate 0.0000
[2019-03-26 19:26:03,267] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 191732: loss 0.1174
[2019-03-26 19:26:03,270] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 191733: learning rate 0.0000
[2019-03-26 19:26:03,332] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 191764: loss 0.0937
[2019-03-26 19:26:03,335] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 191766: learning rate 0.0000
[2019-03-26 19:26:03,376] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 191783: loss 0.0823
[2019-03-26 19:26:03,377] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 191783: learning rate 0.0000
[2019-03-26 19:26:03,562] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 191865: loss 0.0844
[2019-03-26 19:26:03,566] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 191866: learning rate 0.0000
[2019-03-26 19:26:03,700] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 191923: loss 0.0727
[2019-03-26 19:26:03,702] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 191923: learning rate 0.0000
[2019-03-26 19:26:03,716] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 191931: loss 0.0771
[2019-03-26 19:26:03,719] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 191931: learning rate 0.0000
[2019-03-26 19:26:03,755] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 191953: loss 0.1080
[2019-03-26 19:26:03,758] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 191954: learning rate 0.0000
[2019-03-26 19:26:03,769] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 191959: loss 0.0934
[2019-03-26 19:26:03,771] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 191959: learning rate 0.0000
[2019-03-26 19:26:03,802] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 191971: loss 0.1184
[2019-03-26 19:26:03,804] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 191972: learning rate 0.0000
[2019-03-26 19:26:03,912] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 192021: loss 0.0874
[2019-03-26 19:26:03,919] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 192021: learning rate 0.0000
[2019-03-26 19:26:03,980] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 192051: loss 0.0889
[2019-03-26 19:26:03,982] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 192052: learning rate 0.0000
[2019-03-26 19:26:04,157] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 192128: loss 0.1160
[2019-03-26 19:26:04,163] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 192131: learning rate 0.0000
[2019-03-26 19:26:04,385] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 192228: loss 0.1227
[2019-03-26 19:26:04,390] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 192229: learning rate 0.0000
[2019-03-26 19:26:04,796] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 192411: loss 0.1072
[2019-03-26 19:26:04,797] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 192411: learning rate 0.0000
[2019-03-26 19:26:04,949] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 192468: loss 0.1050
[2019-03-26 19:26:04,951] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 192468: learning rate 0.0000
[2019-03-26 19:26:06,777] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.4221373e-20 1.0000000e+00 3.2317465e-16 3.9034534e-16 1.2789834e-18], sum to 1.0000
[2019-03-26 19:26:06,789] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3185
[2019-03-26 19:26:06,793] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.38333333333333, 91.00000000000001, 1.0, 2.0, 0.3549431300573214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 546522.4374547639, 546522.4374547639, 170348.9265087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7251000.0000, 
sim time next is 7251600.0000, 
raw observation next is [22.36666666666667, 91.0, 1.0, 2.0, 0.3542422841174849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 545710.5119515782, 545710.5119515775, 170289.0408707763], 
processed observation next is [1.0, 0.9565217391304348, 0.2590837282780413, 0.91, 1.0, 1.0, 0.2219786555632348, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15158625331988285, 0.15158625331988265, 0.25416274756832286], 
reward next is 0.7458, 
noisyNet noise sample is [array([-1.8372929], dtype=float32), 0.9780942]. 
=============================================
[2019-03-26 19:26:08,784] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8115164e-18 1.0000000e+00 7.9395829e-16 4.4568465e-16 1.1773753e-16], sum to 1.0000
[2019-03-26 19:26:08,796] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5972
[2019-03-26 19:26:08,804] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.95, 88.5, 1.0, 2.0, 0.3271061895200982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 513743.2461474621, 513743.2461474627, 167996.220911652], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7263000.0000, 
sim time next is 7263600.0000, 
raw observation next is [21.93333333333333, 88.33333333333334, 1.0, 2.0, 0.3261194198805615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 512668.71813455, 512668.71813455, 167924.1603654595], 
processed observation next is [1.0, 0.043478260869565216, 0.23854660347551332, 0.8833333333333334, 1.0, 1.0, 0.18809568660308612, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14240797725959722, 0.14240797725959722, 0.25063307517232764], 
reward next is 0.7494, 
noisyNet noise sample is [array([-0.3667988], dtype=float32), 0.30245396]. 
=============================================
[2019-03-26 19:26:08,971] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3832240e-17 1.0000000e+00 1.5375747e-15 3.6337324e-15 1.7454261e-16], sum to 1.0000
[2019-03-26 19:26:08,980] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2777
[2019-03-26 19:26:08,989] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.05, 86.66666666666667, 1.0, 2.0, 0.3440939055081151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 542383.9099507106, 542383.9099507106, 170296.9382657273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7283400.0000, 
sim time next is 7284000.0000, 
raw observation next is [22.1, 86.33333333333334, 1.0, 2.0, 0.3213458952932802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 506439.1921281008, 506439.1921281014, 167475.9403250956], 
processed observation next is [1.0, 0.30434782608695654, 0.24644549763033188, 0.8633333333333334, 1.0, 1.0, 0.18234445216057857, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14067755336891688, 0.14067755336891707, 0.24996409003745612], 
reward next is 0.7500, 
noisyNet noise sample is [array([-0.58762336], dtype=float32), 0.29740506]. 
=============================================
[2019-03-26 19:26:09,004] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[62.645916]
 [62.574757]
 [62.560516]
 [62.51705 ]
 [62.44458 ]], R is [[62.82576752]
 [62.94333649]
 [63.06378555]
 [63.18272018]
 [63.3004303 ]].
[2019-03-26 19:26:09,095] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.2736947e-18 1.0000000e+00 5.0416794e-14 1.1564288e-14 1.6065761e-16], sum to 1.0000
[2019-03-26 19:26:09,107] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3053
[2019-03-26 19:26:09,112] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.7, 78.0, 1.0, 2.0, 0.6158571413611812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 960038.4330644807, 960038.4330644801, 215619.9456759862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7290000.0000, 
sim time next is 7290600.0000, 
raw observation next is [23.91666666666666, 77.0, 1.0, 2.0, 0.6188979037045651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 963114.0137039186, 963114.0137039186, 216104.6805326202], 
processed observation next is [1.0, 0.391304347826087, 0.3325434439178513, 0.77, 1.0, 1.0, 0.5408408478368254, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2675316704733107, 0.2675316704733107, 0.32254429930241824], 
reward next is 0.6775, 
noisyNet noise sample is [array([0.19004996], dtype=float32), -0.8118576]. 
=============================================
[2019-03-26 19:26:16,355] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.0533620e-19 1.0000000e+00 1.1758627e-16 5.6411865e-16 2.7520411e-18], sum to 1.0000
[2019-03-26 19:26:16,364] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1830
[2019-03-26 19:26:16,369] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 92.0, 1.0, 2.0, 0.3159488283097837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 498901.1413231689, 498901.1413231689, 166928.5734579208], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7434000.0000, 
sim time next is 7434600.0000, 
raw observation next is [21.31666666666667, 91.83333333333334, 1.0, 2.0, 0.315471054679055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 498204.7504799939, 498204.7504799945, 166877.7633131374], 
processed observation next is [0.0, 0.043478260869565216, 0.20932069510268583, 0.9183333333333334, 1.0, 1.0, 0.17526633093862048, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13839020846666497, 0.13839020846666514, 0.24907128852707075], 
reward next is 0.7509, 
noisyNet noise sample is [array([-2.0623848], dtype=float32), 0.5054575]. 
=============================================
[2019-03-26 19:26:19,387] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.0084667e-17 1.0000000e+00 1.2695921e-14 4.2497080e-14 6.6952936e-16], sum to 1.0000
[2019-03-26 19:26:19,394] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9832
[2019-03-26 19:26:19,402] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 94.0, 1.0, 2.0, 0.343530330741215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 531024.3913743892, 531024.3913743892, 169139.5427582343], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7461000.0000, 
sim time next is 7461600.0000, 
raw observation next is [22.0, 93.66666666666667, 1.0, 2.0, 0.3452236390077541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 532743.9537262849, 532743.9537262843, 169251.9696557469], 
processed observation next is [0.0, 0.34782608695652173, 0.2417061611374408, 0.9366666666666668, 1.0, 1.0, 0.21111281808163143, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1479844315906347, 0.14798443159063454, 0.2526148800832044], 
reward next is 0.7474, 
noisyNet noise sample is [array([-0.28897288], dtype=float32), 1.0105543]. 
=============================================
[2019-03-26 19:26:20,224] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 199327: loss 0.2167
[2019-03-26 19:26:20,229] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 199329: learning rate 0.0000
[2019-03-26 19:26:21,179] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 199747: loss 0.2073
[2019-03-26 19:26:21,181] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 199748: learning rate 0.0000
[2019-03-26 19:26:21,289] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 199800: loss 0.2173
[2019-03-26 19:26:21,291] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 199800: learning rate 0.0000
[2019-03-26 19:26:21,387] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 199840: loss 0.1447
[2019-03-26 19:26:21,389] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 199840: learning rate 0.0000
[2019-03-26 19:26:21,435] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 199862: loss 0.2214
[2019-03-26 19:26:21,438] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 199862: learning rate 0.0000
[2019-03-26 19:26:21,458] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 199872: loss 0.1518
[2019-03-26 19:26:21,461] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 199872: learning rate 0.0000
[2019-03-26 19:26:21,581] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 199927: loss 0.1335
[2019-03-26 19:26:21,583] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 199927: learning rate 0.0000
[2019-03-26 19:26:21,621] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 199943: loss 0.1740
[2019-03-26 19:26:21,622] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 199943: learning rate 0.0000
[2019-03-26 19:26:21,665] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 199963: loss 0.2095
[2019-03-26 19:26:21,670] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 199963: learning rate 0.0000
[2019-03-26 19:26:21,730] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 199991: loss 0.1639
[2019-03-26 19:26:21,734] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 199992: learning rate 0.0000
[2019-03-26 19:26:21,747] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 19:26:21,749] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:26:21,750] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:26:21,751] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:26:21,751] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:26:21,752] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:26:21,755] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:26:21,757] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:26:21,759] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:26:21,756] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:26:21,764] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:26:21,782] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run9
[2019-03-26 19:26:21,801] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run9
[2019-03-26 19:26:21,801] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run9
[2019-03-26 19:26:21,819] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run9
[2019-03-26 19:26:21,851] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run9
[2019-03-26 19:26:29,680] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05307939], dtype=float32), 0.059570003]
[2019-03-26 19:26:29,681] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.13218529666667, 79.06254298000002, 1.0, 2.0, 0.211592399899161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 353125.0865723865, 353125.0865723865, 156642.8732592074]
[2019-03-26 19:26:29,682] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:26:29,687] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1775774e-16 1.0000000e+00 5.5424107e-14 2.9156192e-14 1.5283410e-15], sampled 0.5477575297190316
[2019-03-26 19:27:11,230] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05307939], dtype=float32), 0.059570003]
[2019-03-26 19:27:11,231] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.78333333333333, 70.5, 1.0, 2.0, 0.5390074614433792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 753198.5073163166, 753198.5073163166, 189932.8096527205]
[2019-03-26 19:27:11,232] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:27:11,234] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.9637708e-18 1.0000000e+00 1.9015288e-15 1.5121035e-15 7.0620115e-17], sampled 0.06529947298156813
[2019-03-26 19:27:36,529] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05307939], dtype=float32), 0.059570003]
[2019-03-26 19:27:36,530] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.33333333333333, 82.66666666666667, 1.0, 2.0, 0.5952599714634166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 831835.4469585558, 831835.4469585558, 199865.5597759124]
[2019-03-26 19:27:36,532] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:27:36,533] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.527451e-19 1.000000e+00 7.010935e-16 5.562718e-16 2.110515e-17], sampled 0.23401842292656994
[2019-03-26 19:28:08,976] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05307939], dtype=float32), 0.059570003]
[2019-03-26 19:28:08,977] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.51000905166667, 91.11139842, 1.0, 2.0, 0.2875836810369267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 463860.7490254548, 463860.7490254548, 164536.1406860835]
[2019-03-26 19:28:08,977] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:28:08,980] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.1732051e-17 1.0000000e+00 1.7622573e-14 1.0253133e-14 5.0199598e-16], sampled 0.13228922097231266
[2019-03-26 19:28:16,679] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3694 2779190338.1949 933.0000
[2019-03-26 19:28:16,885] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0947 2842476605.5833 1131.0000
[2019-03-26 19:28:17,140] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4118 3164064553.2451 1778.0000
[2019-03-26 19:28:17,145] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.3823 2927278091.4500 1338.0000
[2019-03-26 19:28:17,163] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5735 3007648438.5815 1766.0000
[2019-03-26 19:28:18,178] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 200000, evaluation results [200000.0, 7883.411789251931, 3164064553.2451096, 1778.0, 8254.382294801491, 2927278091.449961, 1338.0, 8661.369356548688, 2779190338.194891, 933.0, 7997.573465804901, 3007648438.5815053, 1766.0, 8496.094724748822, 2842476605.583347, 1131.0]
[2019-03-26 19:28:18,251] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 200039: loss 0.2366
[2019-03-26 19:28:18,255] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 200040: learning rate 0.0000
[2019-03-26 19:28:18,274] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5730487e-20 1.0000000e+00 2.9138969e-17 4.1427761e-18 3.0575478e-18], sum to 1.0000
[2019-03-26 19:28:18,281] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2981
[2019-03-26 19:28:18,286] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.45, 85.33333333333334, 1.0, 2.0, 0.402064948367434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 593435.8710656009, 593435.8710656002, 173736.6906591997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7503000.0000, 
sim time next is 7503600.0000, 
raw observation next is [24.4, 85.66666666666667, 1.0, 2.0, 0.4026875036412299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 594441.6762665659, 594441.6762665653, 173833.0508850024], 
processed observation next is [0.0, 0.8695652173913043, 0.3554502369668246, 0.8566666666666667, 1.0, 1.0, 0.28034638992919264, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16512268785182388, 0.1651226878518237, 0.2594523147537349], 
reward next is 0.7405, 
noisyNet noise sample is [array([0.15244478], dtype=float32), -1.0985347]. 
=============================================
[2019-03-26 19:28:18,311] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 200070: loss 0.1614
[2019-03-26 19:28:18,314] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 200070: learning rate 0.0000
[2019-03-26 19:28:18,493] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 200154: loss 0.1674
[2019-03-26 19:28:18,495] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 200155: learning rate 0.0000
[2019-03-26 19:28:18,821] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 200304: loss 0.1836
[2019-03-26 19:28:18,824] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 200304: learning rate 0.0000
[2019-03-26 19:28:19,171] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 200470: loss 0.1385
[2019-03-26 19:28:19,174] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 200470: learning rate 0.0000
[2019-03-26 19:28:19,306] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 200529: loss 0.1436
[2019-03-26 19:28:19,308] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 200529: learning rate 0.0000
[2019-03-26 19:28:19,366] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1124136e-17 1.0000000e+00 1.8216504e-15 2.9592566e-15 7.2604084e-17], sum to 1.0000
[2019-03-26 19:28:19,378] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3266
[2019-03-26 19:28:19,383] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 93.0, 1.0, 2.0, 0.4052288579085293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 596593.7991905018, 596593.7991905018, 173983.2925343863], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7521600.0000, 
sim time next is 7522200.0000, 
raw observation next is [23.5, 93.0, 1.0, 2.0, 0.4059162739980898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 597606.4208987879, 597606.4208987873, 174076.9876780622], 
processed observation next is [0.0, 0.043478260869565216, 0.31279620853080575, 0.93, 1.0, 1.0, 0.28423647469649377, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16600178358299664, 0.16600178358299647, 0.2598163995194958], 
reward next is 0.7402, 
noisyNet noise sample is [array([0.6087782], dtype=float32), 0.1117729]. 
=============================================
[2019-03-26 19:28:19,698] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.10545906e-17 1.00000000e+00 1.30245664e-14 7.26853541e-15
 7.32445007e-16], sum to 1.0000
[2019-03-26 19:28:19,709] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0624
[2019-03-26 19:28:19,717] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.13333333333333, 90.66666666666667, 1.0, 2.0, 0.3780343696340843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 569319.488506724, 569319.4885067233, 171924.0297224739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7532400.0000, 
sim time next is 7533000.0000, 
raw observation next is [23.1, 90.5, 1.0, 2.0, 0.3755939519671112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 566659.9541613702, 566659.9541613702, 171722.8529146654], 
processed observation next is [0.0, 0.17391304347826086, 0.2938388625592418, 0.905, 1.0, 1.0, 0.24770355658688098, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15740554282260283, 0.15740554282260283, 0.2563027655442767], 
reward next is 0.7437, 
noisyNet noise sample is [array([-0.21593644], dtype=float32), 1.0409336]. 
=============================================
[2019-03-26 19:28:19,734] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[65.41427]
 [65.63761]
 [65.92196]
 [66.12191]
 [66.41378]], R is [[65.29187012]
 [65.38235474]
 [65.47162628]
 [65.55976868]
 [65.6468811 ]].
[2019-03-26 19:28:22,082] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2890096e-18 1.0000000e+00 1.9755874e-16 8.8068424e-16 2.0548882e-17], sum to 1.0000
[2019-03-26 19:28:22,089] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5996
[2019-03-26 19:28:22,093] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.83333333333333, 62.0, 1.0, 2.0, 0.4674771543322592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 653212.7197094756, 653212.7197094751, 178657.5924909291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7571400.0000, 
sim time next is 7572000.0000, 
raw observation next is [29.66666666666667, 62.0, 1.0, 2.0, 0.4643887633404882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 648895.9474373192, 648895.9474373192, 178204.6994065632], 
processed observation next is [0.0, 0.6521739130434783, 0.6050552922590839, 0.62, 1.0, 1.0, 0.3546852570367327, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18024887428814423, 0.18024887428814423, 0.2659771632933779], 
reward next is 0.7340, 
noisyNet noise sample is [array([-0.0194503], dtype=float32), 0.53775495]. 
=============================================
[2019-03-26 19:28:22,103] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[69.58095 ]
 [69.51572 ]
 [69.45244 ]
 [69.40279 ]
 [69.346115]], R is [[69.6727066 ]
 [69.7093277 ]
 [69.74567413]
 [69.78326416]
 [69.82167816]].
[2019-03-26 19:28:24,493] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.8606702e-20 1.0000000e+00 2.4568381e-17 1.8547308e-17 2.3953682e-19], sum to 1.0000
[2019-03-26 19:28:24,501] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8882
[2019-03-26 19:28:24,508] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.45, 93.5, 1.0, 2.0, 0.4621301086147338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 652642.8195107767, 652642.8195107767, 178766.3776916693], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7605000.0000, 
sim time next is 7605600.0000, 
raw observation next is [24.4, 93.66666666666667, 1.0, 2.0, 0.460480244997354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 651126.4823016808, 651126.4823016814, 178628.5229309812], 
processed observation next is [1.0, 0.0, 0.3554502369668246, 0.9366666666666668, 1.0, 1.0, 0.3499761987919928, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18086846730602246, 0.18086846730602263, 0.26660973571788243], 
reward next is 0.7334, 
noisyNet noise sample is [array([-0.36612678], dtype=float32), 0.42628852]. 
=============================================
[2019-03-26 19:28:26,954] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.0768759e-20 1.0000000e+00 7.9382465e-17 2.7627503e-17 1.3298308e-18], sum to 1.0000
[2019-03-26 19:28:26,961] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2442
[2019-03-26 19:28:26,969] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.06666666666667, 66.66666666666667, 1.0, 2.0, 1.0035792529014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104249, 1402810.864809447, 1402810.864809446, 300014.8380955955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7641600.0000, 
sim time next is 7642200.0000, 
raw observation next is [29.33333333333334, 65.33333333333333, 1.0, 2.0, 1.014968762684523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1418741.848497398, 1418741.848497398, 303516.4204953069], 
processed observation next is [1.0, 0.43478260869565216, 0.5892575039494474, 0.6533333333333333, 1.0, 1.0, 1.0180346538367746, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3940949579159439, 0.3940949579159439, 0.45300958282881626], 
reward next is 0.5470, 
noisyNet noise sample is [array([-0.15722664], dtype=float32), -0.42084974]. 
=============================================
[2019-03-26 19:28:27,915] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0632180e-19 1.0000000e+00 7.9438166e-18 1.2484655e-17 6.3539527e-19], sum to 1.0000
[2019-03-26 19:28:27,922] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3155
[2019-03-26 19:28:27,932] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 88.00000000000001, 1.0, 2.0, 0.4874057564364518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 681068.175803685, 681068.1758036857, 181645.9529602509], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7683000.0000, 
sim time next is 7683600.0000, 
raw observation next is [25.63333333333334, 88.0, 1.0, 2.0, 0.4854030803664347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 678268.8769390162, 678268.8769390162, 181340.2800587422], 
processed observation next is [1.0, 0.9565217391304348, 0.4139020537124806, 0.88, 1.0, 1.0, 0.3800037112848611, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18840802137194892, 0.18840802137194892, 0.2706571344160332], 
reward next is 0.7293, 
noisyNet noise sample is [array([0.4016756], dtype=float32), -1.3932072]. 
=============================================
[2019-03-26 19:28:28,451] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1165437e-21 1.0000000e+00 5.4696015e-18 4.0259914e-18 1.3932141e-19], sum to 1.0000
[2019-03-26 19:28:28,460] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5135
[2019-03-26 19:28:28,466] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 88.0, 1.0, 2.0, 0.4907757578077594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 685778.7101230004, 685778.7101230004, 182163.2575080206], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7680000.0000, 
sim time next is 7680600.0000, 
raw observation next is [25.8, 88.0, 1.0, 2.0, 0.4890337036597263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 683343.6919329992, 683343.6919329999, 181895.5481705506], 
processed observation next is [1.0, 0.9130434782608695, 0.42180094786729866, 0.88, 1.0, 1.0, 0.3843779562165377, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1898176922036109, 0.18981769220361108, 0.2714858927918666], 
reward next is 0.7285, 
noisyNet noise sample is [array([-1.0430392], dtype=float32), 2.391764]. 
=============================================
[2019-03-26 19:28:31,184] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3439324e-19 1.0000000e+00 6.0176699e-16 2.6532460e-16 2.0523344e-17], sum to 1.0000
[2019-03-26 19:28:31,195] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1697
[2019-03-26 19:28:31,201] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2013634.191144428 W.
[2019-03-26 19:28:31,205] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.1, 70.0, 1.0, 2.0, 0.4800549625741918, 1.0, 1.0, 0.4800549625741918, 1.0, 2.0, 0.8285346063372513, 6.9112, 6.9112, 170.5573041426782, 2013634.191144428, 2013634.191144428, 400736.7490785991], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7726200.0000, 
sim time next is 7726800.0000, 
raw observation next is [30.3, 69.0, 1.0, 2.0, 0.7118785799921034, 1.0, 2.0, 0.7118785799921034, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1990671.641578456, 1990671.641578456, 379249.9213498148], 
processed observation next is [1.0, 0.43478260869565216, 0.6350710900473934, 0.69, 1.0, 1.0, 0.6528657590266306, 1.0, 1.0, 0.6528657590266306, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5529643448829045, 0.5529643448829045, 0.5660446587310669], 
reward next is 0.4340, 
noisyNet noise sample is [array([0.00849294], dtype=float32), 0.346206]. 
=============================================
[2019-03-26 19:28:34,165] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 207434: loss 0.0768
[2019-03-26 19:28:34,172] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 207434: learning rate 0.0000
[2019-03-26 19:28:34,863] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 207745: loss 0.0714
[2019-03-26 19:28:34,868] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 207748: learning rate 0.0000
[2019-03-26 19:28:34,892] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 207759: loss 0.0551
[2019-03-26 19:28:34,896] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 207760: learning rate 0.0000
[2019-03-26 19:28:34,999] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 207805: loss 0.0542
[2019-03-26 19:28:35,002] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 207805: learning rate 0.0000
[2019-03-26 19:28:35,099] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 207849: loss 0.0700
[2019-03-26 19:28:35,102] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 207849: learning rate 0.0000
[2019-03-26 19:28:35,108] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 207853: loss 0.0774
[2019-03-26 19:28:35,110] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 207855: learning rate 0.0000
[2019-03-26 19:28:35,352] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 207962: loss 0.0965
[2019-03-26 19:28:35,355] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 207962: learning rate 0.0000
[2019-03-26 19:28:35,364] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 207966: loss 0.0772
[2019-03-26 19:28:35,367] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 207966: learning rate 0.0000
[2019-03-26 19:28:35,393] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 207983: loss 0.0455
[2019-03-26 19:28:35,394] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 207983: learning rate 0.0000
[2019-03-26 19:28:35,426] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 207999: loss 0.0967
[2019-03-26 19:28:35,431] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 207999: learning rate 0.0000
[2019-03-26 19:28:35,490] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 208023: loss 0.0562
[2019-03-26 19:28:35,492] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 208024: learning rate 0.0000
[2019-03-26 19:28:35,589] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 208068: loss 0.0818
[2019-03-26 19:28:35,591] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 208068: learning rate 0.0000
[2019-03-26 19:28:35,615] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 208078: loss 0.0889
[2019-03-26 19:28:35,616] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 208078: learning rate 0.0000
[2019-03-26 19:28:35,966] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 208232: loss 0.0826
[2019-03-26 19:28:35,968] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 208232: learning rate 0.0000
[2019-03-26 19:28:36,325] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 208393: loss 0.0673
[2019-03-26 19:28:36,327] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 208393: learning rate 0.0000
[2019-03-26 19:28:36,385] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 208418: loss 0.1345
[2019-03-26 19:28:36,387] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 208418: learning rate 0.0000
[2019-03-26 19:28:40,840] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.43231141e-18 1.00000000e+00 1.06452284e-15 1.07590026e-16
 6.93757951e-18], sum to 1.0000
[2019-03-26 19:28:40,848] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7614
[2019-03-26 19:28:40,854] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.06666666666667, 91.66666666666667, 1.0, 2.0, 0.7750309242955185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1083181.276651891, 1083181.276651891, 237872.7383336706], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7872000.0000, 
sim time next is 7872600.0000, 
raw observation next is [26.08333333333334, 91.33333333333334, 1.0, 2.0, 0.7600381123005231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1062216.880056028, 1062216.880056028, 234336.6552992772], 
processed observation next is [1.0, 0.08695652173913043, 0.43522906793049004, 0.9133333333333334, 1.0, 1.0, 0.710889291928341, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2950602444600078, 0.2950602444600078, 0.3497562019392197], 
reward next is 0.6502, 
noisyNet noise sample is [array([-0.40009615], dtype=float32), -0.060533736]. 
=============================================
[2019-03-26 19:28:44,033] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:44,034] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:44,067] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run2
[2019-03-26 19:28:44,882] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:44,882] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:44,884] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run2
[2019-03-26 19:28:44,899] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:44,900] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:44,903] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run2
[2019-03-26 19:28:44,923] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:44,923] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:44,924] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run2
[2019-03-26 19:28:44,936] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:44,936] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:44,941] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run2
[2019-03-26 19:28:45,045] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:45,045] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:45,046] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run2
[2019-03-26 19:28:45,167] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:45,168] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:45,169] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run2
[2019-03-26 19:28:45,185] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:45,186] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:45,189] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:45,189] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:45,191] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run2
[2019-03-26 19:28:45,204] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:45,206] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:45,205] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run2
[2019-03-26 19:28:45,207] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run2
[2019-03-26 19:28:45,222] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:45,236] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:45,236] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:45,237] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:45,237] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:45,240] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:45,241] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run2
[2019-03-26 19:28:45,258] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run2
[2019-03-26 19:28:45,275] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run2
[2019-03-26 19:28:45,296] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:45,297] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:45,298] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run2
[2019-03-26 19:28:45,335] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:45,335] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:45,336] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run2
[2019-03-26 19:28:45,364] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:45,365] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:45,366] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run2
[2019-03-26 19:28:48,373] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0729493e-16 1.0000000e+00 5.1927456e-15 1.0796139e-14 8.5663142e-17], sum to 1.0000
[2019-03-26 19:28:48,381] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5427
[2019-03-26 19:28:48,389] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.53333333333333, 86.0, 1.0, 2.0, 0.3225577815003167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515338.6165904351, 515338.6165904351, 168248.5764558202], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 20400.0000, 
sim time next is 21000.0000, 
raw observation next is [21.56666666666667, 86.0, 1.0, 2.0, 0.3214659440292797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 513241.6594918593, 513241.6594918599, 168087.156031407], 
processed observation next is [1.0, 0.21739130434782608, 0.22116903633491333, 0.86, 1.0, 1.0, 0.18248908919190324, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1425671276366276, 0.14256712763662774, 0.2508763522856821], 
reward next is 0.7491, 
noisyNet noise sample is [array([1.0411466], dtype=float32), -1.0640507]. 
=============================================
[2019-03-26 19:28:48,401] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[62.310875]
 [62.176743]
 [62.112503]
 [61.934612]
 [61.572346]], R is [[62.52991486]
 [62.6534996 ]
 [62.77540588]
 [62.89616394]
 [63.01001358]].
[2019-03-26 19:28:58,390] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3364223e-17 1.0000000e+00 3.5550180e-15 1.7871186e-15 2.9711643e-17], sum to 1.0000
[2019-03-26 19:28:58,397] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2131
[2019-03-26 19:28:58,403] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.06666666666667, 89.33333333333334, 1.0, 2.0, 0.2549050236881701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 415034.4809460548, 415034.4809460548, 161326.1703894624], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 361200.0000, 
sim time next is 361800.0000, 
raw observation next is [20.05, 89.5, 1.0, 2.0, 0.2566018689352981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 417774.758054382, 417774.758054382, 161494.9195042748], 
processed observation next is [1.0, 0.17391304347826086, 0.14928909952606645, 0.895, 1.0, 1.0, 0.1043396011268652, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.116048543903995, 0.116048543903995, 0.24103719328996237], 
reward next is 0.7590, 
noisyNet noise sample is [array([0.2899802], dtype=float32), 1.3177508]. 
=============================================
[2019-03-26 19:28:58,976] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3367588e-17 1.0000000e+00 2.2728877e-14 6.9042193e-15 2.8255833e-16], sum to 1.0000
[2019-03-26 19:28:58,986] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8138
[2019-03-26 19:28:58,992] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.6, 93.0, 1.0, 2.0, 0.2955235204301194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 472817.2235251571, 472817.2235251571, 165141.3872876969], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 207000.0000, 
sim time next is 207600.0000, 
raw observation next is [20.63333333333333, 93.0, 1.0, 2.0, 0.2963497847265903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 473810.7724524142, 473810.7724524142, 165207.7891244677], 
processed observation next is [0.0, 0.391304347826087, 0.17693522906793036, 0.93, 1.0, 1.0, 0.15222865629709673, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13161410345900396, 0.13161410345900396, 0.2465787897380115], 
reward next is 0.7534, 
noisyNet noise sample is [array([0.11751735], dtype=float32), 0.08119059]. 
=============================================
[2019-03-26 19:28:59,266] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.7876909e-18 1.0000000e+00 7.0499874e-15 9.7225862e-16 8.1310240e-17], sum to 1.0000
[2019-03-26 19:28:59,273] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6966
[2019-03-26 19:28:59,278] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.63333333333333, 88.33333333333334, 1.0, 2.0, 0.311616766952448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 493580.8106055849, 493580.8106055849, 166564.0478682458], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 219000.0000, 
sim time next is 219600.0000, 
raw observation next is [21.7, 88.0, 1.0, 2.0, 0.3124876121438484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 494685.9445756486, 494685.9445756486, 166640.4764981013], 
processed observation next is [0.0, 0.5652173913043478, 0.2274881516587678, 0.88, 1.0, 1.0, 0.1716718218600583, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1374127623821246, 0.1374127623821246, 0.24871712910164376], 
reward next is 0.7513, 
noisyNet noise sample is [array([1.4042517], dtype=float32), -0.91634136]. 
=============================================
[2019-03-26 19:29:03,985] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7445199e-17 1.0000000e+00 4.4592808e-15 5.5525021e-15 1.1011834e-16], sum to 1.0000
[2019-03-26 19:29:03,995] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2137
[2019-03-26 19:29:03,998] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.85, 88.66666666666667, 1.0, 2.0, 0.2812510604852813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 452555.221064153, 452555.221064153, 163769.1885237974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 283800.0000, 
sim time next is 284400.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.282696241791992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 454294.7908719257, 454294.7908719263, 163883.2565483385], 
processed observation next is [0.0, 0.30434782608695654, 0.19431279620853087, 0.88, 1.0, 1.0, 0.13577860456866503, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1261929974644238, 0.12619299746442397, 0.24460187544528136], 
reward next is 0.7554, 
noisyNet noise sample is [array([0.16191323], dtype=float32), 0.56755567]. 
=============================================
[2019-03-26 19:29:14,870] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 19:29:14,873] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:29:14,874] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:29:14,875] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:29:14,876] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:29:14,876] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:29:14,877] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:29:14,878] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:29:14,877] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:29:14,878] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:29:14,879] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:29:14,885] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run10
[2019-03-26 19:29:14,886] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run10
[2019-03-26 19:29:14,921] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run10
[2019-03-26 19:29:14,937] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run10
[2019-03-26 19:29:14,938] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run10
[2019-03-26 19:29:17,936] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05726479], dtype=float32), 0.06340234]
[2019-03-26 19:29:17,938] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.48333333333333, 40.0, 1.0, 2.0, 0.4798731107733391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 796445.66643605, 796445.66643605, 191981.1588952663]
[2019-03-26 19:29:17,939] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:29:17,942] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.3862417e-19 1.0000000e+00 2.7580870e-16 2.2590766e-16 8.5781806e-18], sampled 0.03272165347112799
[2019-03-26 19:29:27,712] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05726479], dtype=float32), 0.06340234]
[2019-03-26 19:29:27,713] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.96213517, 79.86188213666668, 1.0, 2.0, 0.3472204156974226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 540641.579594688, 540641.5795946887, 170023.616895482]
[2019-03-26 19:29:27,714] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:29:27,717] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.69730464e-18 1.00000000e+00 4.07758993e-15 2.50174484e-15
 1.01170614e-16], sampled 0.6486065283194574
[2019-03-26 19:29:35,772] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05726479], dtype=float32), 0.06340234]
[2019-03-26 19:29:35,774] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.6, 42.33333333333334, 1.0, 2.0, 0.4466701697424912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 737751.163800436, 737751.1638004367, 186627.9216569559]
[2019-03-26 19:29:35,776] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:29:35,781] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.1290961e-19 1.0000000e+00 4.3813269e-16 3.3966098e-16 1.4185118e-17], sampled 0.5439830229141387
[2019-03-26 19:29:46,007] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05726479], dtype=float32), 0.06340234]
[2019-03-26 19:29:46,008] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.93333333333333, 91.66666666666667, 1.0, 2.0, 0.485059253392507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 677796.4941473521, 677796.4941473521, 181288.5286096499]
[2019-03-26 19:29:46,009] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:29:46,011] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.1903400e-19 1.0000000e+00 2.9417645e-16 2.1233721e-16 7.3180189e-18], sampled 0.5306209938810684
[2019-03-26 19:29:48,971] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05726479], dtype=float32), 0.06340234]
[2019-03-26 19:29:48,972] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.76666666666667, 70.16666666666667, 1.0, 2.0, 0.552833413583755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 815482.3917800939, 815482.3917800939, 197674.9927552994]
[2019-03-26 19:29:48,972] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:29:48,975] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.3723044e-20 1.0000000e+00 1.6705167e-17 1.4875919e-17 4.3291038e-19], sampled 0.5361608931863789
[2019-03-26 19:29:49,222] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05726479], dtype=float32), 0.06340234]
[2019-03-26 19:29:49,223] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.52987165333333, 74.91943655666667, 1.0, 2.0, 0.6528506830155845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 912349.12740861, 912349.12740861, 210995.8242733318]
[2019-03-26 19:29:49,225] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:29:49,229] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.0184401e-20 1.0000000e+00 7.2820997e-17 5.6483969e-17 1.9306677e-18], sampled 0.7941467924268653
[2019-03-26 19:30:08,230] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05726479], dtype=float32), 0.06340234]
[2019-03-26 19:30:08,231] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.1, 73.0, 1.0, 2.0, 0.5627061563112516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 786326.8586652633, 786326.8586652633, 194003.3580579093]
[2019-03-26 19:30:08,233] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:30:08,238] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.3641648e-21 1.0000000e+00 3.5244421e-18 4.3829943e-18 1.1410885e-19], sampled 0.8010770136169149
[2019-03-26 19:30:20,115] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05726479], dtype=float32), 0.06340234]
[2019-03-26 19:30:20,116] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [37.46666666666667, 46.66666666666667, 1.0, 2.0, 0.8518375372006398, 1.0, 2.0, 0.8518375372006398, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 169.0403247858759, 2382476.492443391, 2382476.49244339, 445618.1057812326]
[2019-03-26 19:30:20,117] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:30:20,120] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0775092e-18 1.0000000e+00 2.4424394e-16 2.9684016e-16 1.6461680e-17], sampled 0.5591665890933013
[2019-03-26 19:30:20,121] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2382476.492443391 W.
[2019-03-26 19:30:28,011] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05726479], dtype=float32), 0.06340234]
[2019-03-26 19:30:28,013] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.00011803666667, 76.15922095333333, 1.0, 2.0, 0.5115604397116678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 714831.6696304646, 714831.6696304646, 185426.5997002371]
[2019-03-26 19:30:28,016] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:30:28,019] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.7493001e-20 1.0000000e+00 3.9068329e-17 1.8575773e-17 9.8217679e-19], sampled 0.40299966251858943
[2019-03-26 19:31:02,672] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05726479], dtype=float32), 0.06340234]
[2019-03-26 19:31:02,673] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.2, 59.0, 1.0, 2.0, 0.4378727727129335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 636493.3193609954, 636493.3193609954, 177586.7658467099]
[2019-03-26 19:31:02,675] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:31:02,679] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.7606486e-20 1.0000000e+00 7.4030428e-17 7.6667361e-17 2.5850962e-18], sampled 0.554107006531885
[2019-03-26 19:31:04,275] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05726479], dtype=float32), 0.06340234]
[2019-03-26 19:31:04,277] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.20811737666666, 63.11931239333333, 1.0, 2.0, 0.3484078956830046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 540276.3655134988, 540276.3655134988, 169939.1314423248]
[2019-03-26 19:31:04,277] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:31:04,279] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6799410e-19 1.0000000e+00 1.5941711e-16 1.4748340e-16 5.3496897e-18], sampled 0.43442127570433053
[2019-03-26 19:31:09,190] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.9283 2927337382.1572 1338.0000
[2019-03-26 19:31:09,650] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5144 2842492707.2201 1131.0000
[2019-03-26 19:31:09,721] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2953 3007596012.4260 1766.0000
[2019-03-26 19:31:09,722] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9878 2779156505.7300 933.0000
[2019-03-26 19:31:09,844] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.1591 3164159331.6151 1778.0000
[2019-03-26 19:31:10,861] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 225000, evaluation results [225000.0, 7881.159086882945, 3164159331.61508, 1778.0, 8252.928345183711, 2927337382.157177, 1338.0, 8659.98778398064, 2779156505.7300115, 933.0, 7998.295259250187, 3007596012.4259605, 1766.0, 8497.514395919725, 2842492707.2200756, 1131.0]
[2019-03-26 19:31:14,814] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.5866469e-21 1.0000000e+00 9.8846925e-18 2.7303745e-18 3.8578827e-19], sum to 1.0000
[2019-03-26 19:31:14,825] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7467
[2019-03-26 19:31:14,829] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.51666666666667, 63.66666666666666, 1.0, 2.0, 0.6213822625029956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1013779.672211657, 1013779.672211657, 220151.5694562062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 579000.0000, 
sim time next is 579600.0000, 
raw observation next is [23.5, 64.0, 1.0, 2.0, 0.6167703106639623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1005722.353483141, 1005722.353483141, 219114.3159739852], 
processed observation next is [1.0, 0.7391304347826086, 0.31279620853080575, 0.64, 1.0, 1.0, 0.5382774827276654, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.27936732041198364, 0.27936732041198364, 0.32703629249848537], 
reward next is 0.6730, 
noisyNet noise sample is [array([0.5084616], dtype=float32), 0.5124934]. 
=============================================
[2019-03-26 19:31:17,554] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.5517923e-21 1.0000000e+00 2.3899045e-16 3.9783000e-17 1.3548391e-18], sum to 1.0000
[2019-03-26 19:31:17,562] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7239
[2019-03-26 19:31:17,569] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.15, 72.5, 1.0, 2.0, 0.24277941807949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 400902.2784614968, 400902.2784614962, 160151.2920609879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 589800.0000, 
sim time next is 590400.0000, 
raw observation next is [21.0, 73.0, 1.0, 2.0, 0.2414860320580799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 399087.1499936656, 399087.1499936663, 160008.93160913], 
processed observation next is [1.0, 0.8695652173913043, 0.19431279620853087, 0.73, 1.0, 1.0, 0.08612774946756613, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1108575416649071, 0.1108575416649073, 0.23881930090914924], 
reward next is 0.7612, 
noisyNet noise sample is [array([-0.91351813], dtype=float32), -0.32840994]. 
=============================================
[2019-03-26 19:31:23,834] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0427359e-18 1.0000000e+00 5.3500830e-16 3.4013553e-16 4.0875997e-17], sum to 1.0000
[2019-03-26 19:31:23,845] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0999
[2019-03-26 19:31:23,852] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.6, 92.16666666666667, 1.0, 2.0, 0.2156493060691995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 359411.5057573406, 359411.5057573401, 157168.2631591955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 705000.0000, 
sim time next is 705600.0000, 
raw observation next is [17.6, 92.0, 1.0, 2.0, 0.2149129967709744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 358225.1785073982, 358225.1785073988, 157091.67273694], 
processed observation next is [1.0, 0.17391304347826086, 0.0331753554502371, 0.92, 1.0, 1.0, 0.05411204430237877, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.09950699402983283, 0.099506994029833, 0.2344651831894627], 
reward next is 0.7655, 
noisyNet noise sample is [array([-0.16942893], dtype=float32), -0.596907]. 
=============================================
[2019-03-26 19:31:33,265] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3487866e-19 1.0000000e+00 1.1337625e-15 5.8143539e-16 3.5783072e-17], sum to 1.0000
[2019-03-26 19:31:33,280] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7384
[2019-03-26 19:31:33,285] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.95, 88.5, 1.0, 2.0, 0.2873202962730949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 461280.7366350644, 461280.7366350638, 164354.9904660491], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 876600.0000, 
sim time next is 877200.0000, 
raw observation next is [20.93333333333333, 88.33333333333334, 1.0, 2.0, 0.2867807129147474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 460748.844830786, 460748.844830786, 164320.6354003196], 
processed observation next is [0.0, 0.13043478260869565, 0.19115323854660338, 0.8833333333333334, 1.0, 1.0, 0.14069965411415347, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1279857902307739, 0.1279857902307739, 0.24525467970196954], 
reward next is 0.7547, 
noisyNet noise sample is [array([-0.05481883], dtype=float32), 0.2557316]. 
=============================================
[2019-03-26 19:31:34,628] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0330099e-18 1.0000000e+00 7.0215341e-16 6.7240112e-16 2.3823576e-17], sum to 1.0000
[2019-03-26 19:31:34,635] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1311
[2019-03-26 19:31:34,641] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 81.0, 1.0, 2.0, 0.2831950774689267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 454999.5074738975, 454999.5074738968, 163930.182327815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 889200.0000, 
sim time next is 889800.0000, 
raw observation next is [22.0, 80.66666666666667, 1.0, 2.0, 0.2841501866107968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 456166.4625647859, 456166.4625647865, 164006.5777040067], 
processed observation next is [0.0, 0.30434782608695654, 0.2417061611374408, 0.8066666666666668, 1.0, 1.0, 0.13753034531421296, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12671290626799608, 0.12671290626799625, 0.2447859368716518], 
reward next is 0.7552, 
noisyNet noise sample is [array([0.5674117], dtype=float32), -0.60158616]. 
=============================================
[2019-03-26 19:31:36,269] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9362036e-21 1.0000000e+00 5.4362575e-18 1.3165508e-18 6.0116004e-20], sum to 1.0000
[2019-03-26 19:31:36,280] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2334
[2019-03-26 19:31:36,286] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 91.0, 1.0, 2.0, 0.339550640762631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 525660.1717307077, 525660.1717307077, 168732.1414536615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 942000.0000, 
sim time next is 942600.0000, 
raw observation next is [22.15, 91.5, 1.0, 2.0, 0.3404024194911415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 526792.0208482681, 526792.0208482675, 168817.1136385364], 
processed observation next is [0.0, 0.9130434782608695, 0.24881516587677724, 0.915, 1.0, 1.0, 0.20530411986884514, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1463311169022967, 0.14633111690229653, 0.25196584125154686], 
reward next is 0.7480, 
noisyNet noise sample is [array([-0.7987525], dtype=float32), 1.0649877]. 
=============================================
[2019-03-26 19:31:40,060] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2621307e-19 1.0000000e+00 1.8264855e-16 1.0561616e-16 1.5871671e-18], sum to 1.0000
[2019-03-26 19:31:40,070] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9322
[2019-03-26 19:31:40,077] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.75, 95.16666666666667, 1.0, 2.0, 0.2720137407407139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 440269.0698627054, 440269.0698627054, 162954.1796970875], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1141800.0000, 
sim time next is 1142400.0000, 
raw observation next is [19.9, 94.33333333333333, 1.0, 2.0, 0.2725155493758764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 440664.0383251179, 440664.0383251173, 162982.4112130433], 
processed observation next is [1.0, 0.21739130434782608, 0.14218009478672985, 0.9433333333333332, 1.0, 1.0, 0.12351271009141736, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12240667731253276, 0.12240667731253259, 0.24325733016872134], 
reward next is 0.7567, 
noisyNet noise sample is [array([-1.3382695], dtype=float32), -1.7171097]. 
=============================================
[2019-03-26 19:31:40,769] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.0080115e-21 1.0000000e+00 2.4472025e-18 8.7766163e-18 9.4590539e-20], sum to 1.0000
[2019-03-26 19:31:40,773] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3120
[2019-03-26 19:31:40,780] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.654795584693358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1008446.270262785, 1008446.270262785, 222905.818017141], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 987000.0000, 
sim time next is 987600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.584112130816609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 899525.1845637473, 899525.1845637478, 207878.2152914389], 
processed observation next is [1.0, 0.43478260869565216, 0.2417061611374408, 0.94, 1.0, 1.0, 0.4989302780922999, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24986810682326313, 0.2498681068232633, 0.31026599297229684], 
reward next is 0.6897, 
noisyNet noise sample is [array([-0.7871728], dtype=float32), -0.29447854]. 
=============================================
[2019-03-26 19:31:41,087] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.0595503e-22 1.0000000e+00 1.0828707e-17 2.2228282e-19 4.2712948e-20], sum to 1.0000
[2019-03-26 19:31:41,098] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4474
[2019-03-26 19:31:41,104] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.76666666666667, 95.0, 1.0, 2.0, 0.4490403868515986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 693652.4545397687, 693652.4545397687, 183952.0066599745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 996000.0000, 
sim time next is 996600.0000, 
raw observation next is [21.73333333333333, 95.0, 1.0, 2.0, 0.4628382711410866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 715629.8000872062, 715629.8000872068, 186219.443187303], 
processed observation next is [1.0, 0.5217391304347826, 0.22906793048973137, 0.95, 1.0, 1.0, 0.3528171941458875, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1987860555797795, 0.19878605557977966, 0.2779394674437358], 
reward next is 0.7221, 
noisyNet noise sample is [array([0.84134674], dtype=float32), 0.77999574]. 
=============================================
[2019-03-26 19:31:55,339] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.4314637e-20 1.0000000e+00 4.4686102e-16 7.2660888e-17 1.0231394e-17], sum to 1.0000
[2019-03-26 19:31:55,347] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2009
[2019-03-26 19:31:55,350] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.73333333333333, 93.66666666666667, 1.0, 2.0, 0.3438181241893709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 534239.1184354243, 534239.1184354249, 169476.7890487272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1225200.0000, 
sim time next is 1225800.0000, 
raw observation next is [21.7, 94.0, 1.0, 2.0, 0.3523946565407417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 547468.391229226, 547468.3912292254, 170556.3222392198], 
processed observation next is [1.0, 0.17391304347826086, 0.2274881516587678, 0.94, 1.0, 1.0, 0.21975259824185747, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15207455311922946, 0.1520745531192293, 0.25456167498391014], 
reward next is 0.7454, 
noisyNet noise sample is [array([-0.30267206], dtype=float32), 0.35790727]. 
=============================================
[2019-03-26 19:31:56,782] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5678885e-20 1.0000000e+00 1.3476029e-17 3.2116267e-17 2.8358915e-19], sum to 1.0000
[2019-03-26 19:31:56,791] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5369
[2019-03-26 19:31:56,796] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.36666666666667, 72.83333333333333, 1.0, 2.0, 0.9314206446789248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1301885.15650952, 1301885.156509519, 278724.1967324288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1255800.0000, 
sim time next is 1256400.0000, 
raw observation next is [28.4, 73.0, 1.0, 2.0, 1.032628219743363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1443443.342415169, 1443443.34241517, 309022.4345519682], 
processed observation next is [1.0, 0.5652173913043478, 0.5450236966824644, 0.73, 1.0, 1.0, 1.0393111081245336, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.40095648400421363, 0.4009564840042139, 0.4612275142566689], 
reward next is 0.5388, 
noisyNet noise sample is [array([-0.20689884], dtype=float32), -1.7429713]. 
=============================================
[2019-03-26 19:31:58,402] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.8705477e-18 1.0000000e+00 8.5782870e-16 7.9927321e-16 1.2059668e-17], sum to 1.0000
[2019-03-26 19:31:58,414] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6589
[2019-03-26 19:31:58,419] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.65, 76.66666666666667, 1.0, 2.0, 0.4406091687475463, 1.0, 1.0, 0.4406091687475463, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1231667.726072203, 1231667.726072203, 282832.689917264], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1271400.0000, 
sim time next is 1272000.0000, 
raw observation next is [27.5, 77.33333333333334, 1.0, 2.0, 0.4753981256483927, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129560933668, 664284.2702658746, 664284.2702658746, 179831.9851621796], 
processed observation next is [1.0, 0.7391304347826086, 0.5023696682464456, 0.7733333333333334, 1.0, 1.0, 0.36794954897396703, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399431043266, 0.18452340840718737, 0.18452340840718737, 0.2684059480032531], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.30691373], dtype=float32), 0.5996945]. 
=============================================
[2019-03-26 19:31:58,432] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[70.269745]
 [70.24614 ]
 [70.17483 ]
 [70.03086 ]
 [69.551056]], R is [[70.06885529]
 [69.94602203]
 [69.24655914]
 [68.55409241]
 [68.36761475]].
[2019-03-26 19:31:59,828] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.061884e-20 1.000000e+00 4.468593e-16 3.625119e-16 1.034844e-18], sum to 1.0000
[2019-03-26 19:31:59,836] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6678
[2019-03-26 19:31:59,840] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.26666666666667, 92.33333333333334, 1.0, 2.0, 0.4391945585639844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 629226.1205875443, 629226.1205875437, 176621.3329282753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1316400.0000, 
sim time next is 1317000.0000, 
raw observation next is [24.18333333333334, 92.66666666666666, 1.0, 2.0, 0.4364102202341828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 626270.748492715, 626270.748492715, 176357.1436132321], 
processed observation next is [1.0, 0.21739130434782608, 0.3451816745655612, 0.9266666666666665, 1.0, 1.0, 0.3209761689568468, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17396409680353192, 0.17396409680353192, 0.2632196173331822], 
reward next is 0.7368, 
noisyNet noise sample is [array([-0.31390193], dtype=float32), -0.37652412]. 
=============================================
[2019-03-26 19:31:59,859] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[78.62996 ]
 [78.44763 ]
 [78.476265]
 [78.38813 ]
 [78.238205]], R is [[78.57343292]
 [78.524086  ]
 [78.47463989]
 [78.42553711]
 [78.36858368]].
[2019-03-26 19:32:00,846] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.3269810e-21 1.0000000e+00 2.6068241e-17 1.3658611e-18 1.5615644e-19], sum to 1.0000
[2019-03-26 19:32:00,854] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4851
[2019-03-26 19:32:00,864] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.98333333333333, 95.0, 1.0, 2.0, 0.8096201733490408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1202973.091506808, 1202973.091506808, 256087.5527103175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1332600.0000, 
sim time next is 1333200.0000, 
raw observation next is [22.96666666666667, 95.0, 1.0, 2.0, 0.8086954594068322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1202305.55719818, 1202305.55719818, 255934.45372449], 
processed observation next is [1.0, 0.43478260869565216, 0.2875197472353872, 0.95, 1.0, 1.0, 0.7695126016949785, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3339737658883833, 0.3339737658883833, 0.3819917219768508], 
reward next is 0.6180, 
noisyNet noise sample is [array([1.2818943], dtype=float32), 0.7203994]. 
=============================================
[2019-03-26 19:32:02,119] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.2322146e-21 1.0000000e+00 1.0120375e-17 2.8268742e-18 6.4457920e-20], sum to 1.0000
[2019-03-26 19:32:02,127] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5179
[2019-03-26 19:32:02,128] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2785863e-21 1.0000000e+00 1.6556263e-18 3.1047242e-19 4.7303075e-21], sum to 1.0000
[2019-03-26 19:32:02,133] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.36666666666667, 88.66666666666666, 1.0, 2.0, 0.5136073376258888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 817199.162105594, 817199.162105594, 196986.9948725727], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1348800.0000, 
sim time next is 1349400.0000, 
raw observation next is [21.33333333333333, 88.83333333333334, 1.0, 2.0, 0.4991752223904971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 794473.4551694791, 794473.4551694791, 194404.6104285996], 
processed observation next is [1.0, 0.6086956521739131, 0.21011058451816728, 0.8883333333333334, 1.0, 1.0, 0.39659665348252665, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22068707088041087, 0.22068707088041087, 0.29015613496805914], 
reward next is 0.7098, 
noisyNet noise sample is [array([0.4914479], dtype=float32), -1.733854]. 
=============================================
[2019-03-26 19:32:02,138] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8666
[2019-03-26 19:32:02,143] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 90.0, 1.0, 2.0, 0.6095514060263363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 954581.580616492, 954581.5806164913, 214705.5538799792], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1344000.0000, 
sim time next is 1344600.0000, 
raw observation next is [21.75, 89.5, 1.0, 2.0, 0.6325786714045516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 994203.1120139954, 994203.1120139954, 220021.807208456], 
processed observation next is [1.0, 0.5652173913043478, 0.2298578199052133, 0.895, 1.0, 1.0, 0.5573237004874115, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2761675311149987, 0.2761675311149987, 0.3283907570275463], 
reward next is 0.6716, 
noisyNet noise sample is [array([0.57302785], dtype=float32), -2.0380974]. 
=============================================
[2019-03-26 19:32:04,953] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.1691113e-19 1.0000000e+00 3.8384529e-16 3.3662325e-16 1.1850025e-18], sum to 1.0000
[2019-03-26 19:32:04,963] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5417
[2019-03-26 19:32:04,967] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 98.0, 1.0, 2.0, 0.3048391428512721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 485239.5302921806, 485239.53029218, 165995.854233575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1391400.0000, 
sim time next is 1392000.0000, 
raw observation next is [20.26666666666667, 98.0, 1.0, 2.0, 0.3050233257361261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 485352.8525933396, 485352.8525933389, 166001.3273036943], 
processed observation next is [0.0, 0.08695652173913043, 0.15955766192733034, 0.98, 1.0, 1.0, 0.16267870570617604, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13482023683148323, 0.13482023683148303, 0.24776317508014076], 
reward next is 0.7522, 
noisyNet noise sample is [array([0.13817362], dtype=float32), 0.5306325]. 
=============================================
[2019-03-26 19:32:04,979] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[72.044395]
 [72.52961 ]
 [72.84446 ]
 [73.114525]
 [73.44574 ]], R is [[71.56639099]
 [71.60297394]
 [71.63920593]
 [71.67510223]
 [71.71063232]].
[2019-03-26 19:32:06,122] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 19:32:06,124] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:32:06,125] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:32:06,126] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:32:06,126] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:32:06,127] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:32:06,129] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:32:06,128] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:32:06,129] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:32:06,136] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:32:06,138] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:32:06,147] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run11
[2019-03-26 19:32:06,165] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run11
[2019-03-26 19:32:06,181] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run11
[2019-03-26 19:32:06,207] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run11
[2019-03-26 19:32:06,207] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run11
[2019-03-26 19:32:44,355] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05821769], dtype=float32), 0.064525664]
[2019-03-26 19:32:44,356] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.5, 57.33333333333334, 1.0, 2.0, 0.5943041523887254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 830499.2324149717, 830499.2324149717, 199682.9583617348]
[2019-03-26 19:32:44,358] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:32:44,360] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.0438371e-21 1.0000000e+00 8.9397561e-18 8.5367223e-18 2.5326975e-19], sampled 0.8243976773831153
[2019-03-26 19:33:55,919] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05821769], dtype=float32), 0.064525664]
[2019-03-26 19:33:55,920] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.0, 65.5, 1.0, 2.0, 0.4654160733662236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 650501.3002128416, 650501.3002128416, 178376.8866243147]
[2019-03-26 19:33:55,921] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:33:55,926] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.3108407e-20 1.0000000e+00 7.3524683e-17 6.7300129e-17 2.1769607e-18], sampled 0.3171093499069306
[2019-03-26 19:33:59,246] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05821769], dtype=float32), 0.064525664]
[2019-03-26 19:33:59,249] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.33333333333334, 84.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.993677876991796, 6.9112, 168.912365175871, 1512307.438410374, 1453794.998645425, 311352.042452415]
[2019-03-26 19:33:59,250] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:33:59,253] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.1045624e-20 1.0000000e+00 2.0364561e-17 5.8881396e-18 2.0754079e-19], sampled 0.9421611779762993
[2019-03-26 19:34:00,345] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05821769], dtype=float32), 0.064525664]
[2019-03-26 19:34:00,346] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.056659265, 81.76690608999999, 1.0, 2.0, 0.4339676225198464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 616402.9106068049, 616402.9106068056, 175198.3106287947]
[2019-03-26 19:34:00,347] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:34:00,349] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.0170378e-20 1.0000000e+00 4.7240774e-17 2.7766971e-17 5.6455263e-19], sampled 0.9522604614045115
[2019-03-26 19:34:01,163] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7281 2779199535.5119 933.0000
[2019-03-26 19:34:01,221] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6842 2927326903.3807 1338.0000
[2019-03-26 19:34:01,295] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1685 3164067279.4129 1778.0000
[2019-03-26 19:34:01,548] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 19:34:01,574] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2722 3007609378.0304 1766.0000
[2019-03-26 19:34:02,589] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 250000, evaluation results [250000.0, 7884.168455680242, 3164067279.4128904, 1778.0, 8253.684241790532, 2927326903.3806534, 1338.0, 8660.728066421085, 2779199535.5119066, 933.0, 7998.272155887525, 3007609378.0303907, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 19:34:24,020] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0958503e-21 1.0000000e+00 6.2890161e-18 5.1139650e-19 5.4285841e-20], sum to 1.0000
[2019-03-26 19:34:24,024] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5716
[2019-03-26 19:34:24,030] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 92.33333333333334, 1.0, 2.0, 0.611183759918883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 970856.4212880665, 970856.4212880665, 216282.768564925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1782600.0000, 
sim time next is 1783200.0000, 
raw observation next is [21.0, 92.66666666666667, 1.0, 2.0, 0.5659994561674413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 898306.8904581534, 898306.8904581541, 206835.93483588], 
processed observation next is [1.0, 0.6521739130434783, 0.19431279620853087, 0.9266666666666667, 1.0, 1.0, 0.4771077785149895, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2495296917939315, 0.2495296917939317, 0.30871035050131346], 
reward next is 0.6913, 
noisyNet noise sample is [array([1.2387744], dtype=float32), -1.5983953]. 
=============================================
[2019-03-26 19:34:26,794] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5657202e-21 1.0000000e+00 5.2565312e-19 6.0787782e-19 1.6659904e-19], sum to 1.0000
[2019-03-26 19:34:26,802] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1238
[2019-03-26 19:34:26,807] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 85.0, 1.0, 2.0, 0.7470040219412213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1043991.693378904, 1043991.693378904, 231315.5883646931], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1861200.0000, 
sim time next is 1861800.0000, 
raw observation next is [26.6, 84.66666666666667, 1.0, 2.0, 0.6201111546737215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 866577.4575470068, 866577.4575470068, 204544.0130438161], 
processed observation next is [1.0, 0.5652173913043478, 0.4597156398104266, 0.8466666666666667, 1.0, 1.0, 0.5423025959924355, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2407159604297241, 0.2407159604297241, 0.30528957170718823], 
reward next is 0.6947, 
noisyNet noise sample is [array([0.9471784], dtype=float32), -0.9606523]. 
=============================================
[2019-03-26 19:34:27,625] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.3741679e-20 1.0000000e+00 3.7688781e-17 4.2151989e-17 1.3003038e-19], sum to 1.0000
[2019-03-26 19:34:27,639] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5893
[2019-03-26 19:34:27,646] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 90.33333333333333, 1.0, 2.0, 0.5678133717221682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 834684.7240467081, 834684.7240467088, 200096.5005454881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1843800.0000, 
sim time next is 1844400.0000, 
raw observation next is [23.9, 90.66666666666667, 1.0, 2.0, 0.7640117855382538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1121185.983993121, 1121185.983993122, 242503.4252908333], 
processed observation next is [1.0, 0.34782608695652173, 0.33175355450236965, 0.9066666666666667, 1.0, 1.0, 0.7156768500460888, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31144055110920027, 0.31144055110920055, 0.36194541088184073], 
reward next is 0.6381, 
noisyNet noise sample is [array([-0.06101565], dtype=float32), 1.8971374]. 
=============================================
[2019-03-26 19:34:27,797] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.4420346e-21 1.0000000e+00 2.9870974e-17 3.1876550e-17 1.1283840e-19], sum to 1.0000
[2019-03-26 19:34:27,813] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6062
[2019-03-26 19:34:27,822] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 90.0, 1.0, 2.0, 0.8642812292572144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1238442.543499014, 1238442.543499014, 264706.07610416], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1850400.0000, 
sim time next is 1851000.0000, 
raw observation next is [24.71666666666667, 89.66666666666667, 1.0, 2.0, 0.8951863576699861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1278924.57930032, 1278924.57930032, 272699.238558078], 
processed observation next is [1.0, 0.43478260869565216, 0.3704581358609796, 0.8966666666666667, 1.0, 1.0, 0.8737185032168507, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.35525682758342225, 0.35525682758342225, 0.40701378889265377], 
reward next is 0.5930, 
noisyNet noise sample is [array([2.1923866], dtype=float32), 0.8849386]. 
=============================================
[2019-03-26 19:34:27,834] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[77.23597 ]
 [76.9134  ]
 [76.56139 ]
 [76.17368 ]
 [75.790565]], R is [[77.46572876]
 [77.29598999]
 [77.11753082]
 [76.94432831]
 [76.77770233]].
[2019-03-26 19:34:34,277] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.50333515e-18 1.00000000e+00 1.10178912e-15 7.08754607e-16
 1.14101575e-17], sum to 1.0000
[2019-03-26 19:34:34,285] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0765
[2019-03-26 19:34:34,296] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1662821.938215124 W.
[2019-03-26 19:34:34,301] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.1, 76.0, 1.0, 2.0, 0.3964853707772497, 1.0, 2.0, 0.3964853707772497, 1.0, 2.0, 0.6661361602172641, 6.911200000000001, 6.9112, 170.5573041426782, 1662821.938215124, 1662821.938215123, 347760.9731873994], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1953000.0000, 
sim time next is 1953600.0000, 
raw observation next is [26.93333333333334, 76.66666666666667, 1.0, 2.0, 0.5923556269725265, 1.0, 2.0, 0.5923556269725265, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1656183.651015681, 1656183.651015681, 331432.6097315156], 
processed observation next is [1.0, 0.6086956521739131, 0.4755134281200636, 0.7666666666666667, 1.0, 1.0, 0.5088622011717187, 1.0, 1.0, 0.5088622011717187, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4600510141710225, 0.4600510141710225, 0.4946755369127098], 
reward next is 0.5053, 
noisyNet noise sample is [array([0.24482568], dtype=float32), 0.2697847]. 
=============================================
[2019-03-26 19:34:40,263] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4150176e-21 1.0000000e+00 2.5541505e-18 8.0590693e-18 8.3398514e-20], sum to 1.0000
[2019-03-26 19:34:40,273] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1468
[2019-03-26 19:34:40,282] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.95, 84.66666666666667, 1.0, 2.0, 0.5084988919999548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 710552.1690202173, 710552.1690202173, 184938.6034889804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2044200.0000, 
sim time next is 2044800.0000, 
raw observation next is [26.9, 85.0, 1.0, 2.0, 0.5087270310955853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 710871.0664116039, 710871.0664116046, 184974.9145333862], 
processed observation next is [0.0, 0.6956521739130435, 0.4739336492890995, 0.85, 1.0, 1.0, 0.40810485674166896, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19746418511433442, 0.1974641851143346, 0.2760819619901287], 
reward next is 0.7239, 
noisyNet noise sample is [array([-0.68225527], dtype=float32), -0.26687625]. 
=============================================
[2019-03-26 19:34:41,173] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.5076123e-22 1.0000000e+00 3.9618357e-18 1.3971593e-17 2.7292886e-20], sum to 1.0000
[2019-03-26 19:34:41,180] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4431
[2019-03-26 19:34:41,186] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.35, 89.33333333333334, 1.0, 2.0, 0.4770284952411142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 666563.1363382066, 666563.1363382066, 180075.0003259419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2059800.0000, 
sim time next is 2060400.0000, 
raw observation next is [25.3, 89.66666666666667, 1.0, 2.0, 0.4766639897089207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 666053.644511222, 666053.6445112227, 180020.40054449], 
processed observation next is [0.0, 0.8695652173913043, 0.39810426540284366, 0.8966666666666667, 1.0, 1.0, 0.36947468639629005, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18501490125311723, 0.18501490125311743, 0.26868716499177614], 
reward next is 0.7313, 
noisyNet noise sample is [array([-0.82921803], dtype=float32), 0.49531347]. 
=============================================
[2019-03-26 19:34:52,960] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.4608855e-20 1.0000000e+00 2.7131834e-16 2.7779154e-17 1.0490614e-18], sum to 1.0000
[2019-03-26 19:34:52,965] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6284
[2019-03-26 19:34:52,973] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.03333333333333, 86.33333333333334, 1.0, 2.0, 0.5980096843371455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 835679.4958897944, 835679.4958897944, 200367.9193378125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2265600.0000, 
sim time next is 2266200.0000, 
raw observation next is [26.2, 85.5, 1.0, 2.0, 0.5981101342203867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 835819.9232756051, 835819.9232756051, 200386.6752005977], 
processed observation next is [1.0, 0.21739130434782608, 0.44075829383886256, 0.855, 1.0, 1.0, 0.5157953424342009, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2321722009098903, 0.2321722009098903, 0.2990845898516384], 
reward next is 0.7009, 
noisyNet noise sample is [array([-1.1501998], dtype=float32), 0.4494852]. 
=============================================
[2019-03-26 19:34:54,746] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1056247e-15 1.0000000e+00 8.0773983e-14 1.8049680e-13 2.1348659e-15], sum to 1.0000
[2019-03-26 19:34:54,753] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3379
[2019-03-26 19:34:54,757] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2381646.453860939 W.
[2019-03-26 19:34:54,762] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 65.0, 1.0, 2.0, 0.5676988821021404, 1.0, 2.0, 0.5676988821021404, 1.0, 2.0, 0.9859052173222578, 6.9112, 6.9112, 170.5573041426782, 2381646.453860939, 2381646.453860939, 465117.5525601819], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2300400.0000, 
sim time next is 2301000.0000, 
raw observation next is [32.03333333333333, 64.83333333333334, 1.0, 2.0, 0.8606082591048019, 1.0, 2.0, 0.8606082591048019, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2407010.070928698, 2407010.070928699, 450457.6015973101], 
processed observation next is [1.0, 0.6521739130434783, 0.7172195892575038, 0.6483333333333334, 1.0, 1.0, 0.8320581434997613, 1.0, 1.0, 0.8320581434997613, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.668613908591305, 0.6686139085913052, 0.672324778503448], 
reward next is 0.3277, 
noisyNet noise sample is [array([-1.0314589], dtype=float32), 0.3376352]. 
=============================================
[2019-03-26 19:34:54,777] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[61.398853]
 [62.19104 ]
 [62.540577]
 [63.09732 ]
 [63.631775]], R is [[61.23053741]
 [60.92402649]
 [60.63120651]
 [60.02489471]
 [59.42464447]].
[2019-03-26 19:34:57,843] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 19:34:57,847] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:34:57,849] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:34:57,849] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:34:57,851] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:34:57,851] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:34:57,852] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:34:57,854] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:34:57,855] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:34:57,855] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:34:57,858] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:34:57,875] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run12
[2019-03-26 19:34:57,894] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run12
[2019-03-26 19:34:57,915] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run12
[2019-03-26 19:34:57,930] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run12
[2019-03-26 19:34:57,931] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run12
[2019-03-26 19:35:00,030] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05565601], dtype=float32), 0.061977856]
[2019-03-26 19:35:00,031] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.8, 82.0, 1.0, 2.0, 0.4163172136686517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 616608.3979270809, 616608.3979270816, 175962.1403774745]
[2019-03-26 19:35:00,033] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:35:00,036] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.1823234e-20 1.0000000e+00 3.8596972e-17 5.0272583e-17 1.7317752e-18], sampled 0.059980721712797
[2019-03-26 19:35:01,341] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05565601], dtype=float32), 0.061977856]
[2019-03-26 19:35:01,343] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [19.96666666666667, 96.0, 1.0, 2.0, 0.2910544883419042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 468160.597263258, 468160.5972632574, 164832.3844922244]
[2019-03-26 19:35:01,345] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:35:01,347] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.6547113e-18 1.0000000e+00 1.7731029e-15 1.6565133e-15 5.2077174e-17], sampled 0.4060135383449226
[2019-03-26 19:35:07,080] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05565601], dtype=float32), 0.061977856]
[2019-03-26 19:35:07,083] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.0, 56.5, 1.0, 2.0, 0.357109564917917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 580831.5348488641, 580831.5348488634, 173322.6289214375]
[2019-03-26 19:35:07,084] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:35:07,085] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.4485270e-18 1.0000000e+00 2.9383001e-15 2.0762912e-15 9.6074778e-17], sampled 0.3799731165423508
[2019-03-26 19:35:09,936] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05565601], dtype=float32), 0.061977856]
[2019-03-26 19:35:09,937] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.24178641, 53.21195722333334, 1.0, 2.0, 0.3741693323109748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 618906.8797173386, 618906.8797173379, 175714.0275936339]
[2019-03-26 19:35:09,939] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:35:09,941] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6202131e-18 1.0000000e+00 1.0225162e-15 7.7307622e-16 3.3821787e-17], sampled 0.4118326433601297
[2019-03-26 19:35:54,881] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05565601], dtype=float32), 0.061977856]
[2019-03-26 19:35:54,882] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.33333333333334, 85.66666666666666, 1.0, 2.0, 0.5282946385323052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 738223.4157592438, 738223.4157592432, 188148.2279317458]
[2019-03-26 19:35:54,883] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:35:54,885] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.9756521e-19 1.0000000e+00 1.7417014e-16 1.8646992e-16 5.5604847e-18], sampled 0.04937760168495264
[2019-03-26 19:36:44,313] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05565601], dtype=float32), 0.061977856]
[2019-03-26 19:36:44,314] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.65, 81.83333333333334, 1.0, 2.0, 0.6037929218037543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 843764.4028106617, 843764.4028106623, 201453.9809418314]
[2019-03-26 19:36:44,316] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:36:44,318] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.3974059e-21 1.0000000e+00 7.8766768e-18 8.6957345e-18 2.0048360e-19], sampled 0.3394205432443518
[2019-03-26 19:36:51,919] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05565601], dtype=float32), 0.061977856]
[2019-03-26 19:36:51,919] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.91666666666666, 67.0, 1.0, 2.0, 0.3268105292460267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 514972.8561502189, 514972.8561502189, 168127.5863236523]
[2019-03-26 19:36:51,920] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:36:51,925] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.1019238e-19 1.0000000e+00 1.6235433e-16 1.7661084e-16 5.8258264e-18], sampled 0.11475686025984289
[2019-03-26 19:36:52,938] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 19:36:52,972] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.7746 2842563444.1824 1131.0000
[2019-03-26 19:36:53,015] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 19:36:53,046] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 19:36:53,050] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 19:36:54,063] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 275000, evaluation results [275000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8496.774567725599, 2842563444.1823883, 1131.0]
[2019-03-26 19:36:54,199] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.3601601e-20 1.0000000e+00 1.5895915e-17 3.0282846e-18 1.2769262e-18], sum to 1.0000
[2019-03-26 19:36:54,206] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1921
[2019-03-26 19:36:54,211] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.13333333333333, 82.0, 1.0, 2.0, 0.6682611215593884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 933894.4548958407, 933894.4548958407, 214141.528037051], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2350200.0000, 
sim time next is 2350800.0000, 
raw observation next is [27.1, 82.0, 1.0, 2.0, 0.6234163866440692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 871198.2649760069, 871198.2649760064, 205181.0847337015], 
processed observation next is [1.0, 0.21739130434782608, 0.4834123222748816, 0.82, 1.0, 1.0, 0.5462848031856254, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2419995180488908, 0.24199951804889067, 0.3062404249756739], 
reward next is 0.6938, 
noisyNet noise sample is [array([1.2029525], dtype=float32), -0.98295987]. 
=============================================
[2019-03-26 19:36:54,641] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.3270681e-21 1.0000000e+00 5.3956217e-17 7.6841233e-18 1.6676308e-19], sum to 1.0000
[2019-03-26 19:36:54,650] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3224
[2019-03-26 19:36:54,658] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.03333333333333, 78.33333333333334, 1.0, 2.0, 0.7347836663053045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1026904.612226668, 1026904.612226668, 228531.0034874748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2355000.0000, 
sim time next is 2355600.0000, 
raw observation next is [28.16666666666667, 77.66666666666667, 1.0, 2.0, 0.7111225497767187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 993821.2977888229, 993821.2977888235, 223263.03256951], 
processed observation next is [1.0, 0.2608695652173913, 0.5339652448657191, 0.7766666666666667, 1.0, 1.0, 0.6519548792490587, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.27606147160800637, 0.27606147160800654, 0.33322840682016414], 
reward next is 0.6668, 
noisyNet noise sample is [array([0.03453844], dtype=float32), -1.108984]. 
=============================================
[2019-03-26 19:37:13,482] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2703039e-19 1.0000000e+00 1.1980434e-17 4.0467337e-17 3.5261786e-17], sum to 1.0000
[2019-03-26 19:37:13,488] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2558
[2019-03-26 19:37:13,493] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 96.0, 1.0, 2.0, 0.4352432743349033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 627590.2333733159, 627590.2333733152, 176570.8904051139], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2684400.0000, 
sim time next is 2685000.0000, 
raw observation next is [23.83333333333333, 95.0, 1.0, 2.0, 0.4375903340815071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 629907.8198955805, 629907.8198955805, 176771.0168835794], 
processed observation next is [0.0, 0.043478260869565216, 0.32859399684044216, 0.95, 1.0, 1.0, 0.3223979928692857, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17497439441543902, 0.17497439441543902, 0.26383733863220804], 
reward next is 0.7362, 
noisyNet noise sample is [array([-1.1322559], dtype=float32), -0.48777217]. 
=============================================
[2019-03-26 19:37:13,515] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[69.20823 ]
 [69.48181 ]
 [69.712456]
 [69.97972 ]
 [70.33451 ]], R is [[68.99178314]
 [69.03832245]
 [69.08460999]
 [69.13072968]
 [69.17677307]].
[2019-03-26 19:37:18,652] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3569176e-19 1.0000000e+00 1.3614469e-15 1.4854434e-16 2.1023589e-17], sum to 1.0000
[2019-03-26 19:37:18,664] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4109
[2019-03-26 19:37:18,672] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.337116271885331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 520451.6342583667, 520451.6342583673, 168272.3744305947], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2776800.0000, 
sim time next is 2777400.0000, 
raw observation next is [21.5, 97.0, 1.0, 2.0, 0.3334609077491934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515505.4628424659, 515505.4628424659, 167904.5039443714], 
processed observation next is [1.0, 0.13043478260869565, 0.21800947867298584, 0.97, 1.0, 1.0, 0.19694085270987158, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14319596190068498, 0.14319596190068498, 0.2506037372304051], 
reward next is 0.7494, 
noisyNet noise sample is [array([-2.3153107], dtype=float32), 0.6305576]. 
=============================================
[2019-03-26 19:37:20,992] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.0096852e-21 1.0000000e+00 6.3695878e-17 6.0238217e-17 1.2988172e-18], sum to 1.0000
[2019-03-26 19:37:21,000] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4762
[2019-03-26 19:37:21,010] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 83.0, 1.0, 2.0, 0.699917861205047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1067141.025263553, 1067141.025263553, 232137.4131958989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2807400.0000, 
sim time next is 2808000.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.6020702654444282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 913311.9876172242, 913311.9876172242, 210017.3544686618], 
processed observation next is [1.0, 0.5217391304347826, 0.3364928909952607, 0.83, 1.0, 1.0, 0.520566584872805, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.25369777433811785, 0.25369777433811785, 0.31345873801292806], 
reward next is 0.6865, 
noisyNet noise sample is [array([0.16441992], dtype=float32), 0.4460625]. 
=============================================
[2019-03-26 19:37:21,025] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[75.8404 ]
 [75.53222]
 [75.25926]
 [75.02702]
 [74.77564]], R is [[75.96512604]
 [75.85900116]
 [75.76337433]
 [75.68759155]
 [75.61869812]].
[2019-03-26 19:37:26,624] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.3802461e-21 1.0000000e+00 1.0570070e-18 1.3077462e-18 1.4329610e-19], sum to 1.0000
[2019-03-26 19:37:26,626] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8761
[2019-03-26 19:37:26,631] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 99.0, 1.0, 2.0, 0.3441424890590314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 533493.0394974338, 533493.0394974338, 169382.653889772], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2915400.0000, 
sim time next is 2916000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.3444608833846927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 534749.1700828595, 534749.1700828589, 169505.0779180692], 
processed observation next is [1.0, 0.782608695652174, 0.19431279620853087, 1.0, 1.0, 1.0, 0.21019383540324424, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14854143613412762, 0.14854143613412746, 0.25299265360905854], 
reward next is 0.7470, 
noisyNet noise sample is [array([-0.9671485], dtype=float32), -0.6702006]. 
=============================================
[2019-03-26 19:37:26,656] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[79.13316 ]
 [79.23313 ]
 [79.23019 ]
 [79.34591 ]
 [79.383896]], R is [[79.02643585]
 [78.98336792]
 [78.94070435]
 [78.89836884]
 [78.85572815]].
[2019-03-26 19:37:26,933] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1740567e-22 1.0000000e+00 2.8807371e-19 1.1706295e-18 4.3866337e-21], sum to 1.0000
[2019-03-26 19:37:26,941] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7960
[2019-03-26 19:37:26,944] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.8386034150715587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1216916.286248577, 1216916.286248577, 259959.349771019], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3078000.0000, 
sim time next is 3078600.0000, 
raw observation next is [23.16666666666667, 99.00000000000001, 1.0, 2.0, 0.7888085287301458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1143192.121185025, 1143192.121185024, 246814.0474492084], 
processed observation next is [1.0, 0.6521739130434783, 0.2969984202211693, 0.9900000000000001, 1.0, 1.0, 0.7455524442531878, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31755336699584025, 0.31755336699584, 0.36837917529732594], 
reward next is 0.6316, 
noisyNet noise sample is [array([-0.5366179], dtype=float32), -0.6612233]. 
=============================================
[2019-03-26 19:37:31,258] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1155587e-19 1.0000000e+00 2.9464349e-17 2.0590233e-17 2.5645569e-19], sum to 1.0000
[2019-03-26 19:37:31,271] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4542
[2019-03-26 19:37:31,280] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3046781921487323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 485182.2398720158, 485182.2398720158, 165994.6212026615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3012600.0000, 
sim time next is 3013200.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3047168758067159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 485243.725406528, 485243.7254065274, 165999.0642198544], 
processed observation next is [1.0, 0.9130434782608695, 0.1469194312796209, 1.0, 1.0, 1.0, 0.1623094889237541, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13478992372403556, 0.1347899237240354, 0.24775979734306625], 
reward next is 0.7522, 
noisyNet noise sample is [array([0.21753184], dtype=float32), 1.323396]. 
=============================================
[2019-03-26 19:37:36,112] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.2527393e-21 1.0000000e+00 1.1230645e-17 1.7094397e-18 6.1361815e-20], sum to 1.0000
[2019-03-26 19:37:36,121] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7250
[2019-03-26 19:37:36,126] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.8214801701034867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1180295.802366947, 1180295.802366947, 253793.5278438263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3081600.0000, 
sim time next is 3082200.0000, 
raw observation next is [23.83333333333333, 95.0, 1.0, 2.0, 0.8370665503745157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1203420.733259079, 1203420.73325908, 257979.0417563959], 
processed observation next is [1.0, 0.6956521739130435, 0.32859399684044216, 0.95, 1.0, 1.0, 0.8036946390054406, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33428353701641084, 0.3342835370164111, 0.3850433459050685], 
reward next is 0.6150, 
noisyNet noise sample is [array([0.5313991], dtype=float32), -1.3131673]. 
=============================================
[2019-03-26 19:37:36,862] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.4140565e-23 1.0000000e+00 1.3332588e-19 2.0368038e-19 3.1231791e-22], sum to 1.0000
[2019-03-26 19:37:36,876] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5958
[2019-03-26 19:37:36,882] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.4221929928478546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 612799.3362681925, 612799.3362681925, 175248.3666270096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3087000.0000, 
sim time next is 3087600.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.4274092874770286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 620381.1581846853, 620381.158184686, 175980.4027678079], 
processed observation next is [1.0, 0.7391304347826086, 0.28909952606635075, 1.0, 1.0, 1.0, 0.31013167165907063, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1723280994957459, 0.1723280994957461, 0.2626573175638924], 
reward next is 0.7373, 
noisyNet noise sample is [array([-0.1100225], dtype=float32), 0.16533302]. 
=============================================
[2019-03-26 19:37:41,741] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.2524473e-22 1.0000000e+00 2.8180025e-18 1.3384777e-18 2.8984716e-20], sum to 1.0000
[2019-03-26 19:37:41,748] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6139
[2019-03-26 19:37:41,751] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1920434.13011275 W.
[2019-03-26 19:37:41,756] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.568582472989275, 6.9112, 168.909338348425, 1920434.13011275, 1454074.368183976, 311348.7219669761], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3169800.0000, 
sim time next is 3170400.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.6083343895578213, 1.0, 1.0, 0.6083343895578213, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1700894.574175727, 1700894.574175727, 337345.1371460482], 
processed observation next is [1.0, 0.6956521739130435, 0.4786729857819906, 0.84, 1.0, 1.0, 0.5281137223588208, 1.0, 0.5, 0.5281137223588208, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4724707150488131, 0.4724707150488131, 0.5035002046955943], 
reward next is 0.4965, 
noisyNet noise sample is [array([-0.04194869], dtype=float32), 0.4392926]. 
=============================================
[2019-03-26 19:37:42,525] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5748380e-20 1.0000000e+00 2.8991506e-17 5.7751778e-18 6.6330765e-19], sum to 1.0000
[2019-03-26 19:37:42,529] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6050
[2019-03-26 19:37:42,537] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1700050.750541642 W.
[2019-03-26 19:37:42,540] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.16666666666667, 84.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.25813918599143, 6.9112, 168.9106585972182, 1700050.750541642, 1453923.499665862, 311346.7066446837], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3165000.0000, 
sim time next is 3165600.0000, 
raw observation next is [26.33333333333334, 84.0, 1.0, 2.0, 0.5498827592089649, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9200576805495063, 6.911199999999999, 6.9112, 168.9126739768374, 1537358.136168443, 1537358.136168444, 329271.8069460293], 
processed observation next is [1.0, 0.6521739130434783, 0.44707740916271754, 0.84, 1.0, 1.0, 0.4576900713361023, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.9025093665237881, -8.881784197001253e-17, 0.0, 0.8294385577830137, 0.42704392671345637, 0.4270439267134567, 0.49145045812840193], 
reward next is 0.5085, 
noisyNet noise sample is [array([-0.32030421], dtype=float32), 1.2456933]. 
=============================================
[2019-03-26 19:37:46,445] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1658517e-19 1.0000000e+00 1.3632026e-16 2.1971610e-16 9.1376624e-18], sum to 1.0000
[2019-03-26 19:37:46,458] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8620
[2019-03-26 19:37:46,462] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 87.33333333333334, 1.0, 2.0, 0.4599948506132508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 648857.8977596752, 648857.8977596757, 178354.138512402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3219600.0000, 
sim time next is 3220200.0000, 
raw observation next is [25.5, 86.5, 1.0, 2.0, 0.4623547181189223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 650751.4531206937, 650751.4531206937, 178515.4787447156], 
processed observation next is [0.0, 0.2608695652173913, 0.40758293838862564, 0.865, 1.0, 1.0, 0.35223460014327995, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18076429253352602, 0.18076429253352602, 0.26644101305181433], 
reward next is 0.7336, 
noisyNet noise sample is [array([-1.7745023], dtype=float32), 1.6533628]. 
=============================================
[2019-03-26 19:37:46,489] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.03374374e-20 1.00000000e+00 1.05124515e-17 2.24702571e-17
 2.69179957e-18], sum to 1.0000
[2019-03-26 19:37:46,500] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2375
[2019-03-26 19:37:46,504] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.0, 63.0, 1.0, 2.0, 0.5753130607095253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 803950.4425160888, 803950.4425160888, 196237.9633904234], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3247200.0000, 
sim time next is 3247800.0000, 
raw observation next is [33.0, 63.0, 1.0, 2.0, 0.5819015969336226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813160.8786120126, 813160.8786120126, 197423.2344444387], 
processed observation next is [0.0, 0.6086956521739131, 0.7630331753554502, 0.63, 1.0, 1.0, 0.49626698425737664, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22587802183667016, 0.22587802183667016, 0.29466154394692345], 
reward next is 0.7053, 
noisyNet noise sample is [array([0.72461444], dtype=float32), 0.71049917]. 
=============================================
[2019-03-26 19:37:49,464] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 19:37:49,466] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:37:49,466] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:37:49,467] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:37:49,467] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:37:49,468] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:37:49,469] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:37:49,470] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:37:49,470] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:37:49,472] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:37:49,474] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:37:49,494] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run13
[2019-03-26 19:37:49,511] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run13
[2019-03-26 19:37:49,530] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run13
[2019-03-26 19:37:49,558] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run13
[2019-03-26 19:37:49,559] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run13
[2019-03-26 19:38:04,748] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05677506], dtype=float32), 0.062971726]
[2019-03-26 19:38:04,750] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.9, 93.0, 1.0, 2.0, 0.3329765268366439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 516161.5966468404, 516161.5966468398, 168000.7902355249]
[2019-03-26 19:38:04,751] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:38:04,753] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.8177672e-18 1.0000000e+00 1.2138789e-15 7.6824025e-16 3.1609546e-17], sampled 0.7210521776488957
[2019-03-26 19:38:20,104] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05677506], dtype=float32), 0.062971726]
[2019-03-26 19:38:20,104] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.30953026333334, 94.16526289666668, 1.0, 2.0, 0.4200472211254917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 620295.5546930638, 620295.5546930633, 176265.0073790366]
[2019-03-26 19:38:20,105] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:38:20,108] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.2230401e-19 1.0000000e+00 1.8442055e-16 1.5241135e-16 5.5729710e-18], sampled 0.3234980312082827
[2019-03-26 19:38:45,226] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05677506], dtype=float32), 0.062971726]
[2019-03-26 19:38:45,229] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.1, 54.0, 1.0, 2.0, 0.8642471573981884, 1.0, 1.0, 0.8642471573981884, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 169.0403247858759, 2417218.423423579, 2417218.423423578, 452079.6584607888]
[2019-03-26 19:38:45,230] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:38:45,232] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.2546587e-20 1.0000000e+00 1.6171575e-17 3.4480048e-17 1.2405887e-18], sampled 0.8091302020540331
[2019-03-26 19:38:45,234] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2417218.423423579 W.
[2019-03-26 19:38:45,783] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05677506], dtype=float32), 0.062971726]
[2019-03-26 19:38:45,787] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [34.17233667333333, 56.94751432666666, 1.0, 2.0, 0.9851741966273223, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9129564413349, 1377067.448142527, 1377067.448142527, 294444.8618396401]
[2019-03-26 19:38:45,787] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:38:45,791] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.4116484e-22 1.0000000e+00 7.8963483e-19 1.0075033e-18 3.3896133e-20], sampled 0.8530482192462642
[2019-03-26 19:38:46,178] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05677506], dtype=float32), 0.062971726]
[2019-03-26 19:38:46,179] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.094697485, 84.43570449, 1.0, 2.0, 0.5797585627165631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 810165.017804742, 810165.017804742, 197033.4505731201]
[2019-03-26 19:38:46,180] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:38:46,182] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.1158874e-21 1.0000000e+00 2.8629912e-18 3.7700986e-18 9.1223287e-20], sampled 0.24194647942990855
[2019-03-26 19:38:55,780] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05677506], dtype=float32), 0.062971726]
[2019-03-26 19:38:55,782] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [34.65165876, 66.8011921, 1.0, 2.0, 0.6810496568129507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 951774.4323940699, 951774.4323940706, 216818.2293686434]
[2019-03-26 19:38:55,782] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:38:55,784] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.040786e-21 1.000000e+00 7.474348e-18 8.996031e-18 2.951021e-19], sampled 0.3445474078480665
[2019-03-26 19:38:57,540] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05677506], dtype=float32), 0.062971726]
[2019-03-26 19:38:57,542] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.78333333333333, 68.5, 1.0, 2.0, 0.6343859703447748, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.964389546319739, 6.9112, 168.9125780837924, 1773809.01730184, 1736074.607038747, 372083.6007143952]
[2019-03-26 19:38:57,543] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:38:57,545] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.0935807e-19 1.0000000e+00 2.2873720e-16 4.1052913e-16 1.7214945e-17], sampled 0.24966808415804154
[2019-03-26 19:38:57,546] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1773809.01730184 W.
[2019-03-26 19:39:00,220] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05677506], dtype=float32), 0.062971726]
[2019-03-26 19:39:00,221] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 79.0, 1.0, 2.0, 0.4846202610063223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 677174.6703606546, 677174.670360654, 181221.2402177604]
[2019-03-26 19:39:00,222] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:39:00,224] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.6521031e-20 1.0000000e+00 6.4764874e-17 7.0088456e-17 2.2612126e-18], sampled 0.6682391806943317
[2019-03-26 19:39:21,669] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05677506], dtype=float32), 0.062971726]
[2019-03-26 19:39:21,670] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.5, 87.66666666666667, 1.0, 2.0, 0.5917484141111213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 826926.3734350005, 826926.3734350012, 199218.1585199925]
[2019-03-26 19:39:21,671] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:39:21,674] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.8171503e-20 1.0000000e+00 2.8587799e-17 3.4088484e-17 9.5451835e-19], sampled 0.7505008964037392
[2019-03-26 19:39:44,408] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.3130 3007656030.3370 1766.0000
[2019-03-26 19:39:44,709] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 19:39:44,789] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0954 2842517464.9746 1131.0000
[2019-03-26 19:39:44,806] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4188 3164139523.4469 1778.0000
[2019-03-26 19:39:44,875] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 19:39:45,889] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 300000, evaluation results [300000.0, 7883.41881391125, 3164139523.4469013, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7998.312951428424, 3007656030.3370423, 1766.0, 8496.095384209508, 2842517464.974608, 1131.0]
[2019-03-26 19:39:54,425] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.0269941e-17 1.0000000e+00 2.0713151e-15 2.1653190e-15 2.3970813e-16], sum to 1.0000
[2019-03-26 19:39:54,433] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0149
[2019-03-26 19:39:54,439] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.5, 65.0, 1.0, 2.0, 0.5474955680421482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 765063.8933554917, 765063.8933554917, 191375.1170108264], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3605400.0000, 
sim time next is 3606000.0000, 
raw observation next is [32.33333333333334, 65.66666666666667, 1.0, 2.0, 0.5568726483659189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 778172.1153874714, 778172.1153874714, 192988.5860635341], 
processed observation next is [1.0, 0.7391304347826086, 0.7314375987361774, 0.6566666666666667, 1.0, 1.0, 0.46611162453725163, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21615892094096428, 0.21615892094096428, 0.2880426657664688], 
reward next is 0.7120, 
noisyNet noise sample is [array([0.7817407], dtype=float32), 0.00749091]. 
=============================================
[2019-03-26 19:39:54,456] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[64.25863 ]
 [64.67958 ]
 [62.579853]
 [62.24084 ]
 [61.789604]], R is [[66.74385834]
 [66.79078674]
 [66.83627319]
 [66.75748444]
 [66.34304047]].
[2019-03-26 19:39:56,787] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.7004780e-19 1.0000000e+00 1.3688089e-17 9.0897944e-17 2.3692694e-18], sum to 1.0000
[2019-03-26 19:39:56,798] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5198
[2019-03-26 19:39:56,806] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1970296.43106178 W.
[2019-03-26 19:39:56,813] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.33333333333334, 68.66666666666667, 1.0, 2.0, 0.704598951313661, 1.0, 2.0, 0.704598951313661, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1970296.43106178, 1970296.43106178, 376091.6380241393], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3487200.0000, 
sim time next is 3487800.0000, 
raw observation next is [29.66666666666666, 67.33333333333333, 1.0, 2.0, 0.714342793359177, 1.0, 2.0, 0.714342793359177, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1997568.903432091, 1997568.90343209, 380317.5903818132], 
processed observation next is [1.0, 0.34782608695652173, 0.6050552922590835, 0.6733333333333333, 1.0, 1.0, 0.6558346907941892, 1.0, 1.0, 0.6558346907941892, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5548802509533586, 0.5548802509533584, 0.5676381945997212], 
reward next is 0.4324, 
noisyNet noise sample is [array([0.9737801], dtype=float32), -0.259037]. 
=============================================
[2019-03-26 19:40:03,991] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0440601e-17 1.0000000e+00 3.7321275e-15 4.9304788e-15 1.6301029e-16], sum to 1.0000
[2019-03-26 19:40:03,999] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8042
[2019-03-26 19:40:04,006] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333334, 66.83333333333334, 1.0, 2.0, 0.5675168131537903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 793051.7910204724, 793051.791020473, 194851.0513613692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3607800.0000, 
sim time next is 3608400.0000, 
raw observation next is [31.66666666666667, 66.66666666666667, 1.0, 2.0, 0.5594867318126384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 781826.3718749982, 781826.3718749982, 193441.8728858562], 
processed observation next is [1.0, 0.782608695652174, 0.6998420221169038, 0.6666666666666667, 1.0, 1.0, 0.46926112266582937, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2171739921874995, 0.2171739921874995, 0.2887192132624719], 
reward next is 0.7113, 
noisyNet noise sample is [array([0.20898713], dtype=float32), 1.9243644]. 
=============================================
[2019-03-26 19:40:06,467] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3144524e-19 1.0000000e+00 8.7596336e-16 1.4949594e-16 1.1368095e-18], sum to 1.0000
[2019-03-26 19:40:06,475] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8742
[2019-03-26 19:40:06,479] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.7243636465149337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1012335.063248648, 1012335.063248648, 226188.5617082594], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3642000.0000, 
sim time next is 3642600.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.7028789668046981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 982295.2432512394, 982295.24325124, 221464.4733701137], 
processed observation next is [1.0, 0.13043478260869565, 0.4786729857819906, 0.79, 1.0, 1.0, 0.6420228515719254, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.272859789792011, 0.2728597897920111, 0.3305439901046473], 
reward next is 0.6695, 
noisyNet noise sample is [array([-0.61972743], dtype=float32), 1.4581832]. 
=============================================
[2019-03-26 19:40:10,974] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.6877513e-20 1.0000000e+00 2.5325854e-16 1.8367213e-16 2.9715481e-18], sum to 1.0000
[2019-03-26 19:40:10,985] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9582
[2019-03-26 19:40:10,995] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.83333333333334, 1.0, 2.0, 0.4655929563119225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 660767.0441381582, 660767.0441381582, 179691.3630170218], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3718200.0000, 
sim time next is 3718800.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.4579791345538589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 653507.9042580575, 653507.9042580575, 179018.0397899096], 
processed observation next is [1.0, 0.043478260869565216, 0.4786729857819906, 0.74, 1.0, 1.0, 0.3469628127154927, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18152997340501598, 0.18152997340501598, 0.2671911041640442], 
reward next is 0.7328, 
noisyNet noise sample is [array([-0.9167766], dtype=float32), -0.40593034]. 
=============================================
[2019-03-26 19:40:13,843] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.3592749e-16 1.0000000e+00 6.5130410e-14 6.8715758e-14 2.9816472e-15], sum to 1.0000
[2019-03-26 19:40:13,852] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5430
[2019-03-26 19:40:13,863] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2668754.120072258 W.
[2019-03-26 19:40:13,868] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.16666666666667, 60.0, 1.0, 2.0, 0.9540930288506443, 1.0, 2.0, 0.9540930288506443, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2668754.120072258, 2668754.120072259, 501868.3568129042], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3768600.0000, 
sim time next is 3769200.0000, 
raw observation next is [34.0, 60.0, 1.0, 2.0, 0.9060309752979046, 1.0, 2.0, 0.9060309752979046, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2534180.362660288, 2534180.362660288, 474798.8446431714], 
processed observation next is [1.0, 0.6521739130434783, 0.8104265402843602, 0.6, 1.0, 1.0, 0.8867843075878368, 1.0, 1.0, 0.8867843075878368, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7039389896278577, 0.7039389896278577, 0.7086549920047335], 
reward next is 0.2913, 
noisyNet noise sample is [array([1.9714502], dtype=float32), -1.665355]. 
=============================================
[2019-03-26 19:40:28,636] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9156378e-16 1.0000000e+00 9.5474962e-15 1.0974188e-14 4.3866807e-15], sum to 1.0000
[2019-03-26 19:40:28,645] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3956
[2019-03-26 19:40:28,656] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2469600.841162183 W.
[2019-03-26 19:40:28,660] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.5886433490521819, 1.0, 2.0, 0.5886433490521819, 1.0, 1.0, 1.020514599017459, 6.9112, 6.9112, 170.5573041426782, 2469600.841162183, 2469600.841162183, 481473.9577230118], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4014000.0000, 
sim time next is 4014600.0000, 
raw observation next is [31.33333333333334, 65.5, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.189474743851661, 6.9112, 168.911156231198, 2487897.63909574, 2290482.062413257, 475820.6315103745], 
processed observation next is [1.0, 0.4782608695652174, 0.6840442338072673, 0.655, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.027827474385166084, 0.0, 0.8294311049570973, 0.6910826775265945, 0.6362450173370159, 0.7101800470304097], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.01953975], dtype=float32), 0.056496065]. 
=============================================
[2019-03-26 19:40:31,268] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1958505e-19 1.0000000e+00 4.4026549e-16 1.3006430e-16 2.1332343e-18], sum to 1.0000
[2019-03-26 19:40:31,280] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3656
[2019-03-26 19:40:31,284] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666666, 76.33333333333333, 1.0, 2.0, 0.6317607026905631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 882863.9433764647, 882863.9433764641, 206812.6283973069], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4221600.0000, 
sim time next is 4222200.0000, 
raw observation next is [31.33333333333334, 77.66666666666667, 1.0, 2.0, 0.6299860219547007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 880382.8599504848, 880382.8599504848, 206465.6320131386], 
processed observation next is [1.0, 0.8695652173913043, 0.6840442338072673, 0.7766666666666667, 1.0, 1.0, 0.5542000264514465, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24455079443069022, 0.24455079443069022, 0.3081576597211024], 
reward next is 0.6918, 
noisyNet noise sample is [array([-0.95440656], dtype=float32), 0.4743574]. 
=============================================
[2019-03-26 19:40:32,619] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5554282e-20 1.0000000e+00 5.0784138e-17 2.6431036e-16 1.3557232e-18], sum to 1.0000
[2019-03-26 19:40:32,629] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1113
[2019-03-26 19:40:32,633] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.7025231281703276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 981797.7178059865, 981797.7178059865, 221390.9508297546], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4081800.0000, 
sim time next is 4082400.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.6571349986278583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 918338.9833539705, 918338.9833539705, 211865.1391908308], 
processed observation next is [1.0, 0.2608695652173913, 0.4786729857819906, 0.89, 1.0, 1.0, 0.586909636901034, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2550941620427696, 0.2550941620427696, 0.31621662565795644], 
reward next is 0.6838, 
noisyNet noise sample is [array([0.5138942], dtype=float32), -1.1223524]. 
=============================================
[2019-03-26 19:40:38,281] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.4766793e-20 1.0000000e+00 2.0222045e-17 6.6762641e-17 1.3362592e-17], sum to 1.0000
[2019-03-26 19:40:38,292] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1083
[2019-03-26 19:40:38,301] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2929153.919404369 W.
[2019-03-26 19:40:38,305] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.66666666666667, 73.66666666666666, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 6.938842000438483, 6.9112, 170.5573041426782, 2929153.919404369, 2909352.830085596, 553500.6711901841], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4178400.0000, 
sim time next is 4179000.0000, 
raw observation next is [32.83333333333333, 72.33333333333334, 1.0, 2.0, 1.009805134932769, 1.0, 2.0, 1.009805134932769, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2824766.168203464, 2824766.168203464, 534950.5262125253], 
processed observation next is [1.0, 0.34782608695652173, 0.7551342812006318, 0.7233333333333334, 1.0, 1.0, 1.0118134155816494, 1.0, 1.0, 1.0118134155816494, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7846572689454065, 0.7846572689454065, 0.7984336212127243], 
reward next is 0.2016, 
noisyNet noise sample is [array([-0.6563466], dtype=float32), 2.1504238]. 
=============================================
[2019-03-26 19:40:38,324] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[67.73652 ]
 [68.370026]
 [70.12559 ]
 [71.863   ]
 [72.56757 ]], R is [[66.6005249 ]
 [65.97018433]
 [65.31048584]
 [64.65737915]
 [64.4334259 ]].
[2019-03-26 19:40:38,478] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0435087e-15 1.0000000e+00 6.8482207e-14 1.5973784e-13 4.2079435e-14], sum to 1.0000
[2019-03-26 19:40:38,485] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3622
[2019-03-26 19:40:38,493] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2593522.208585792 W.
[2019-03-26 19:40:38,496] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.33333333333334, 55.0, 1.0, 2.0, 0.6181500857297006, 1.0, 2.0, 0.6181500857297006, 1.0, 1.0, 1.03, 6.960127116095882, 6.9112, 170.5573041426782, 2593522.208585792, 2558473.725098476, 494654.2978803412], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4188000.0000, 
sim time next is 4188600.0000, 
raw observation next is [35.5, 54.5, 1.0, 2.0, 0.9317025613867884, 1.0, 2.0, 0.9317025613867884, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2606059.004275845, 2606059.004275845, 489089.5801814198], 
processed observation next is [1.0, 0.4782608695652174, 0.8815165876777251, 0.545, 1.0, 1.0, 0.9177139293816728, 1.0, 1.0, 0.9177139293816728, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7239052789655125, 0.7239052789655125, 0.7299844480319698], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0093365], dtype=float32), -0.016266515]. 
=============================================
[2019-03-26 19:40:40,997] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 19:40:40,999] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:40:41,002] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:40:41,004] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:40:41,005] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:40:41,006] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:40:41,007] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:40:41,007] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:40:41,008] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:40:41,010] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:40:41,011] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:40:41,032] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run14
[2019-03-26 19:40:41,032] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run14
[2019-03-26 19:40:41,050] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run14
[2019-03-26 19:40:41,050] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run14
[2019-03-26 19:40:41,102] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run14
[2019-03-26 19:40:50,444] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05296812], dtype=float32), 0.058477927]
[2019-03-26 19:40:50,445] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.33772216333333, 67.97927718666666, 1.0, 2.0, 0.289527848048624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 479911.3591907573, 479911.3591907579, 164909.0922686436]
[2019-03-26 19:40:50,448] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:40:50,450] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.7862578e-17 1.0000000e+00 5.8516272e-15 4.8455286e-15 2.2156357e-16], sampled 0.08599247914596442
[2019-03-26 19:41:06,846] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05296812], dtype=float32), 0.058477927]
[2019-03-26 19:41:06,846] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.55, 76.0, 1.0, 2.0, 0.4792057180084694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104275, 669606.3797527608, 669606.37975276, 180404.6233446581]
[2019-03-26 19:41:06,847] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:41:06,850] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.5973550e-17 1.0000000e+00 4.2631177e-15 1.0137701e-14 3.7089490e-16], sampled 0.9393460153584768
[2019-03-26 19:41:10,857] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05296812], dtype=float32), 0.058477927]
[2019-03-26 19:41:10,858] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.96666666666667, 95.0, 1.0, 2.0, 0.5070163310171788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 708479.8179550462, 708479.8179550468, 184701.7266617256]
[2019-03-26 19:41:10,859] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:41:10,863] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.9265743e-20 1.0000000e+00 3.2325709e-17 3.6308186e-17 1.0689078e-18], sampled 0.04721672965595691
[2019-03-26 19:41:31,477] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05296812], dtype=float32), 0.058477927]
[2019-03-26 19:41:31,482] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.41445593, 89.04328233, 1.0, 2.0, 0.533508299852628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 745511.3895977411, 745511.3895977405, 189011.3613265754]
[2019-03-26 19:41:31,483] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:41:31,488] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.5497186e-20 1.0000000e+00 1.8180178e-17 2.6036440e-17 7.2675504e-19], sampled 0.7223264828753647
[2019-03-26 19:42:14,168] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05296812], dtype=float32), 0.058477927]
[2019-03-26 19:42:14,169] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.93333333333333, 84.33333333333334, 1.0, 2.0, 0.5223941021454377, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8822173837785204, 6.911199999999999, 6.9112, 168.912712370336, 1460452.682526844, 1460452.682526844, 315690.476064947]
[2019-03-26 19:42:14,170] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:42:14,174] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.1126024e-18 1.0000000e+00 1.7306486e-15 3.0635651e-15 1.0544748e-16], sampled 0.4298158472081445
[2019-03-26 19:42:19,311] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05296812], dtype=float32), 0.058477927]
[2019-03-26 19:42:19,312] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.1, 90.0, 1.0, 2.0, 0.4973505556749084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 696810.393198897, 696810.3931988977, 183417.9902960376]
[2019-03-26 19:42:19,315] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:42:19,317] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.0247252e-18 1.0000000e+00 1.9405724e-15 1.2880874e-15 5.3899850e-17], sampled 0.6891071093017368
[2019-03-26 19:42:35,841] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6673 3164154095.2556 1778.0000
[2019-03-26 19:42:35,941] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5749 3007726976.5989 1766.0000
[2019-03-26 19:42:36,024] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.4067 2927264152.9822 1338.0000
[2019-03-26 19:42:36,194] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 19:42:36,257] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 19:42:37,272] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 325000, evaluation results [325000.0, 7882.667338675547, 3164154095.2555733, 1778.0, 8254.406660643592, 2927264152.9821725, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7997.574940102971, 3007726976.5988917, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 19:42:38,245] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.4307239e-18 1.0000000e+00 1.5947070e-15 1.5649838e-16 4.7262225e-17], sum to 1.0000
[2019-03-26 19:42:38,253] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5720
[2019-03-26 19:42:38,258] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 79.0, 1.0, 2.0, 0.8630526313377184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1206270.070790945, 1206270.070790946, 259977.8209068921], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4254000.0000, 
sim time next is 4254600.0000, 
raw observation next is [29.0, 79.0, 1.0, 2.0, 0.8641396242585072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1207790.201490409, 1207790.201490408, 260265.107691575], 
processed observation next is [1.0, 0.21739130434782608, 0.5734597156398105, 0.79, 1.0, 1.0, 0.8363128003114545, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33549727819178027, 0.33549727819178, 0.388455384614291], 
reward next is 0.6115, 
noisyNet noise sample is [array([-0.51335824], dtype=float32), -0.011062168]. 
=============================================
[2019-03-26 19:42:38,341] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3453935e-18 1.0000000e+00 6.8446615e-16 1.3325641e-16 3.0784635e-17], sum to 1.0000
[2019-03-26 19:42:38,355] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6125
[2019-03-26 19:42:38,358] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 79.0, 1.0, 2.0, 0.9187025758693804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1284097.835336189, 1284097.835336189, 275136.2849042831], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4256400.0000, 
sim time next is 4257000.0000, 
raw observation next is [29.5, 79.0, 1.0, 2.0, 0.9834529039382823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1374659.88324726, 1374659.883247259, 293927.35968535], 
processed observation next is [1.0, 0.2608695652173913, 0.5971563981042655, 0.79, 1.0, 1.0, 0.9800637396846775, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.38184996756868334, 0.38184996756868306, 0.4386975517691791], 
reward next is 0.5613, 
noisyNet noise sample is [array([-0.51335824], dtype=float32), -0.011062168]. 
=============================================
[2019-03-26 19:42:38,372] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[68.76318]
 [68.36515]
 [67.77888]
 [67.43662]
 [67.03794]], R is [[68.63433075]
 [68.53733826]
 [68.40435791]
 [68.3368988 ]
 [68.26507568]].
[2019-03-26 19:42:38,824] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9973962e-16 1.0000000e+00 8.7952852e-14 3.2508467e-14 7.2240315e-15], sum to 1.0000
[2019-03-26 19:42:38,831] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0183
[2019-03-26 19:42:38,839] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2489802.377639234 W.
[2019-03-26 19:42:38,845] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.66666666666666, 76.5, 1.0, 2.0, 0.8901805607784536, 1.0, 2.0, 0.8901805607784536, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2489802.377639234, 2489802.377639234, 466181.8677456414], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4265400.0000, 
sim time next is 4266000.0000, 
raw observation next is [33.0, 75.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 10.39583552277784, 6.9112, 168.8926852242995, 4757784.527329366, 2285960.835355663, 466441.8714244304], 
processed observation next is [1.0, 0.391304347826087, 0.7630331753554502, 0.75, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.348463552277784, 0.0, 0.829340403857162, 1.321606813147046, 0.6349891209321287, 0.6961818976484035], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.00857912], dtype=float32), -2.3245585]. 
=============================================
[2019-03-26 19:42:38,855] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[58.927174]
 [59.440395]
 [60.34884 ]
 [61.079056]
 [62.523106]], R is [[57.60799789]
 [57.03191757]
 [56.46159744]
 [56.0947113 ]
 [55.71247101]].
[2019-03-26 19:42:59,490] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0784114e-15 1.0000000e+00 3.4418008e-14 1.8893150e-13 2.0853650e-14], sum to 1.0000
[2019-03-26 19:42:59,498] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6462
[2019-03-26 19:42:59,503] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.5241637676044307, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 732449.0678878941, 732449.0678878941, 187471.9760826372], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4641600.0000, 
sim time next is 4642200.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.5179499162533343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 723763.0799391958, 723763.0799391952, 186460.0130775358], 
processed observation next is [1.0, 0.7391304347826086, 0.6682464454976303, 0.7, 1.0, 1.0, 0.4192167665702823, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20104529998310994, 0.20104529998310977, 0.27829852698139673], 
reward next is 0.7217, 
noisyNet noise sample is [array([-0.8937153], dtype=float32), 1.2514234]. 
=============================================
[2019-03-26 19:43:01,811] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.4891852e-19 1.0000000e+00 7.4266647e-16 1.0017099e-16 7.0522631e-18], sum to 1.0000
[2019-03-26 19:43:01,822] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5868
[2019-03-26 19:43:01,829] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 74.0, 1.0, 2.0, 0.4745648029814758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 669080.7530330656, 669080.753033065, 180474.7162654271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4651800.0000, 
sim time next is 4652400.0000, 
raw observation next is [26.66666666666667, 78.0, 1.0, 2.0, 0.4718766926789524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 665992.9614055092, 665992.9614055092, 180161.2066178872], 
processed observation next is [1.0, 0.8695652173913043, 0.4628751974723541, 0.78, 1.0, 1.0, 0.3637068586493402, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18499804483486365, 0.18499804483486365, 0.2688973233102794], 
reward next is 0.7311, 
noisyNet noise sample is [array([-0.33310634], dtype=float32), -0.7326628]. 
=============================================
[2019-03-26 19:43:04,620] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.5539116e-20 1.0000000e+00 5.1168582e-17 1.1719616e-17 2.5634821e-18], sum to 1.0000
[2019-03-26 19:43:04,628] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7774
[2019-03-26 19:43:04,632] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666666, 85.66666666666667, 1.0, 2.0, 0.830988013210304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1161429.53381116, 1161429.53381116, 251659.916831695], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4689600.0000, 
sim time next is 4690200.0000, 
raw observation next is [27.83333333333334, 84.83333333333333, 1.0, 2.0, 0.7939864652292251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1109687.335726188, 1109687.335726188, 242440.7364978558], 
processed observation next is [1.0, 0.2608695652173913, 0.5181674565560824, 0.8483333333333333, 1.0, 1.0, 0.7517909219629219, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.30824648214616335, 0.30824648214616335, 0.36185184551918775], 
reward next is 0.6381, 
noisyNet noise sample is [array([-1.1613365], dtype=float32), 0.6078402]. 
=============================================
[2019-03-26 19:43:08,472] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5467648e-19 1.0000000e+00 3.6762691e-16 1.3000082e-16 6.5818124e-18], sum to 1.0000
[2019-03-26 19:43:08,482] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1776
[2019-03-26 19:43:08,486] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 83.16666666666666, 1.0, 2.0, 0.5046798576487501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 705213.8606261248, 705213.8606261241, 184332.621123565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4917000.0000, 
sim time next is 4917600.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5069177657347922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 708342.0417301061, 708342.0417301061, 184687.246725973], 
processed observation next is [1.0, 0.9565217391304348, 0.4786729857819906, 0.84, 1.0, 1.0, 0.40592501895758093, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1967616782583628, 0.1967616782583628, 0.27565260705369105], 
reward next is 0.7243, 
noisyNet noise sample is [array([-0.03573929], dtype=float32), 0.73009694]. 
=============================================
[2019-03-26 19:43:10,677] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.4474447e-14 1.0000000e+00 1.7616308e-12 1.8196078e-12 4.7002316e-14], sum to 1.0000
[2019-03-26 19:43:10,685] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8128
[2019-03-26 19:43:10,693] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2631120.966697341 W.
[2019-03-26 19:43:10,701] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.83333333333334, 63.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.393893572548272, 6.9112, 168.9106565411589, 2631120.966697341, 2288686.196058571, 475278.2102427921], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4800000.0000, 
sim time next is 4800600.0000, 
raw observation next is [31.75, 64.0, 1.0, 2.0, 0.9194610789759076, 1.0, 1.0, 0.9194610789759076, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2571783.195808665, 2571783.195808665, 482217.2438343287], 
processed observation next is [1.0, 0.5652173913043478, 0.7037914691943128, 0.64, 1.0, 1.0, 0.9029651553926598, 1.0, 0.5, 0.9029651553926598, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7143842210579625, 0.7143842210579625, 0.7197272296034757], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.68679655], dtype=float32), 1.0220206]. 
=============================================
[2019-03-26 19:43:12,110] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.8227996e-20 1.0000000e+00 5.3264175e-17 3.9168461e-17 3.1294210e-19], sum to 1.0000
[2019-03-26 19:43:12,118] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5004
[2019-03-26 19:43:12,123] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 77.0, 1.0, 2.0, 0.4933954913837593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 689440.5464808679, 689440.5464808679, 182567.4639977381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4834800.0000, 
sim time next is 4835400.0000, 
raw observation next is [27.41666666666667, 77.33333333333334, 1.0, 2.0, 0.4927984996387762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 688606.0765155231, 688606.0765155231, 182475.1169427546], 
processed observation next is [1.0, 1.0, 0.4984202211690366, 0.7733333333333334, 1.0, 1.0, 0.3889138549864773, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19127946569875642, 0.19127946569875642, 0.2723509208100815], 
reward next is 0.7276, 
noisyNet noise sample is [array([0.21865311], dtype=float32), -0.5462186]. 
=============================================
[2019-03-26 19:43:14,633] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.7214612e-15 1.0000000e+00 1.0741570e-13 2.0529689e-13 7.2711705e-15], sum to 1.0000
[2019-03-26 19:43:14,644] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8516
[2019-03-26 19:43:14,656] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2121844.163933615 W.
[2019-03-26 19:43:14,664] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.33333333333334, 66.0, 1.0, 2.0, 0.7587404132496529, 1.0, 2.0, 0.7587404132496529, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2121844.163933615, 2121844.163933615, 400278.9596105331], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4898400.0000, 
sim time next is 4899000.0000, 
raw observation next is [30.16666666666666, 66.0, 1.0, 2.0, 0.8883254560520302, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.97901440710323, 6.9112, 168.9125525434709, 2138695.497806663, 2090585.738473943, 431787.596118502], 
processed observation next is [1.0, 0.6956521739130435, 0.6287519747235385, 0.66, 1.0, 1.0, 0.865452356689193, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.006781440710322962, 0.0, 0.8294379614895917, 0.5940820827240731, 0.5807182606872063, 0.6444590986843314], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7380303], dtype=float32), -1.8917187]. 
=============================================
[2019-03-26 19:43:14,680] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[51.70642 ]
 [50.985916]
 [51.27365 ]
 [50.672253]
 [49.97812 ]], R is [[51.12129593]
 [51.01265335]
 [50.50252914]
 [49.99750519]
 [49.92007828]].
[2019-03-26 19:43:16,213] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.02594325e-14 1.00000000e+00 1.23168500e-12 2.21150680e-12
 3.72961942e-13], sum to 1.0000
[2019-03-26 19:43:16,222] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6517
[2019-03-26 19:43:16,229] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2264256.917773158 W.
[2019-03-26 19:43:16,234] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.5397427636077559, 1.0, 2.0, 0.5397427636077559, 1.0, 2.0, 0.9355470525564837, 6.911199999999999, 6.9112, 170.5573041426782, 2264256.917773158, 2264256.917773159, 443362.0937871474], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4882200.0000, 
sim time next is 4882800.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.7189621116555488, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.993098915122884, 6.9112, 168.9124678838482, 1901663.832509764, 1843562.091454017, 389299.5325798089], 
processed observation next is [1.0, 0.5217391304347826, 0.6682464454976303, 0.66, 1.0, 1.0, 0.6614001345247575, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008189891512288393, 0.0, 0.8294375457720868, 0.5282399534749345, 0.5121005809594492, 0.5810440784773268], 
reward next is 0.0095, 
noisyNet noise sample is [array([-0.35370484], dtype=float32), 0.39745578]. 
=============================================
[2019-03-26 19:43:18,303] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9999167e-19 1.0000000e+00 8.8420830e-17 1.5499702e-16 2.0678303e-18], sum to 1.0000
[2019-03-26 19:43:18,312] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5696
[2019-03-26 19:43:18,318] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 83.16666666666666, 1.0, 2.0, 0.5046798576487501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 705213.8606261248, 705213.8606261241, 184332.621123565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4917000.0000, 
sim time next is 4917600.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5069177657347922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 708342.0417301061, 708342.0417301061, 184687.246725973], 
processed observation next is [1.0, 0.9565217391304348, 0.4786729857819906, 0.84, 1.0, 1.0, 0.40592501895758093, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1967616782583628, 0.1967616782583628, 0.27565260705369105], 
reward next is 0.7243, 
noisyNet noise sample is [array([-1.8889177], dtype=float32), -0.18938804]. 
=============================================
[2019-03-26 19:43:18,346] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3843629e-17 1.0000000e+00 1.9468972e-15 1.8315029e-15 7.8780888e-18], sum to 1.0000
[2019-03-26 19:43:18,357] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4096
[2019-03-26 19:43:18,362] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333333, 72.66666666666666, 1.0, 2.0, 0.493160040738451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 689111.4355003275, 689111.4355003275, 182531.3177667337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4909200.0000, 
sim time next is 4909800.0000, 
raw observation next is [28.16666666666667, 73.33333333333334, 1.0, 2.0, 0.491514018420261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 686810.6418548356, 686810.6418548356, 182277.1349528615], 
processed observation next is [1.0, 0.8260869565217391, 0.5339652448657191, 0.7333333333333334, 1.0, 1.0, 0.38736628725332645, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19078073384856542, 0.19078073384856542, 0.2720554253027784], 
reward next is 0.7279, 
noisyNet noise sample is [array([-0.09904627], dtype=float32), 0.035801552]. 
=============================================
[2019-03-26 19:43:21,455] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2539559e-15 1.0000000e+00 3.6734833e-14 4.0746009e-13 3.5122157e-14], sum to 1.0000
[2019-03-26 19:43:21,464] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2303
[2019-03-26 19:43:21,472] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1937157.043919639 W.
[2019-03-26 19:43:21,476] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 66.66666666666666, 1.0, 2.0, 0.7443250523690309, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.977998522901091, 6.9112, 168.912558603634, 1937157.043919639, 1889767.984380139, 395536.4316458591], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4963800.0000, 
sim time next is 4964400.0000, 
raw observation next is [30.0, 66.0, 1.0, 2.0, 0.6823166599555295, 1.0, 1.0, 0.6823166599555295, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1907932.144857525, 1907932.144857525, 366639.9261944883], 
processed observation next is [1.0, 0.4782608695652174, 0.6208530805687204, 0.66, 1.0, 1.0, 0.6172489878982282, 1.0, 0.5, 0.6172489878982282, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5299811513493125, 0.5299811513493125, 0.5472237704395347], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.90573263], dtype=float32), 0.3675214]. 
=============================================
[2019-03-26 19:43:22,005] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.7057122e-14 1.0000000e+00 1.9183620e-12 8.2308145e-12 4.0194413e-13], sum to 1.0000
[2019-03-26 19:43:22,012] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6086
[2019-03-26 19:43:22,022] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2154942.380835171 W.
[2019-03-26 19:43:22,028] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 63.0, 1.0, 2.0, 0.7705639580925725, 1.0, 2.0, 0.7705639580925725, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2154942.380835171, 2154942.380835171, 405789.8729411034], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4982400.0000, 
sim time next is 4983000.0000, 
raw observation next is [31.0, 63.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.026373329329161, 6.9112, 168.912318858162, 2382150.755391345, 2300443.140055411, 476615.6045046633], 
processed observation next is [1.0, 0.6956521739130435, 0.6682464454976303, 0.63, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.01151733293291608, 0.0, 0.8294368139877434, 0.6617085431642624, 0.6390119833487253, 0.7113665738875572], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4936316], dtype=float32), 1.0863042]. 
=============================================
[2019-03-26 19:43:22,041] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[50.01803 ]
 [49.298023]
 [49.644985]
 [49.792053]
 [50.00976 ]], R is [[50.19977951]
 [50.09212494]
 [49.5912056 ]
 [49.09529495]
 [49.01625443]].
[2019-03-26 19:43:23,145] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1771136e-18 1.0000000e+00 8.0833353e-17 9.4512777e-17 2.0505960e-18], sum to 1.0000
[2019-03-26 19:43:23,154] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8008
[2019-03-26 19:43:23,157] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 79.0, 1.0, 2.0, 0.5055472138692355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 706426.262918072, 706426.2629180714, 184469.471636405], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4998600.0000, 
sim time next is 4999200.0000, 
raw observation next is [27.33333333333334, 79.0, 1.0, 2.0, 0.5008635856409079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 699879.4402785505, 699879.4402785498, 183731.1038394858], 
processed observation next is [1.0, 0.8695652173913043, 0.4944707740916275, 0.79, 1.0, 1.0, 0.398630826073383, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1944109556329307, 0.1944109556329305, 0.2742255281186355], 
reward next is 0.7258, 
noisyNet noise sample is [array([-0.31428334], dtype=float32), -0.22784586]. 
=============================================
[2019-03-26 19:43:28,327] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.1140192e-18 1.0000000e+00 1.2686450e-15 5.6225168e-16 1.0399336e-17], sum to 1.0000
[2019-03-26 19:43:28,337] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2896
[2019-03-26 19:43:28,343] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4814624873965489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 672885.4902672878, 672885.4902672871, 180758.0926966805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5113800.0000, 
sim time next is 5114400.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4805817283252084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 671654.9019920448, 671654.9019920448, 180625.1653267668], 
processed observation next is [0.0, 0.17391304347826086, 0.4312796208530806, 0.84, 1.0, 1.0, 0.3741948534038655, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1865708061089013, 0.1865708061089013, 0.2695897989951743], 
reward next is 0.7304, 
noisyNet noise sample is [array([0.15287596], dtype=float32), -0.16687141]. 
=============================================
[2019-03-26 19:43:28,866] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3746622e-20 1.0000000e+00 3.4099409e-17 8.4192618e-18 4.0519022e-20], sum to 1.0000
[2019-03-26 19:43:28,873] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5200
[2019-03-26 19:43:28,878] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 81.33333333333333, 1.0, 2.0, 0.5497328995329734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 768191.4446982018, 768191.4446982018, 191754.9222320282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5263800.0000, 
sim time next is 5264400.0000, 
raw observation next is [28.5, 81.66666666666667, 1.0, 2.0, 0.5508259599999857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 769719.4302636089, 769719.4302636089, 191942.5302566618], 
processed observation next is [1.0, 0.9565217391304348, 0.5497630331753555, 0.8166666666666668, 1.0, 1.0, 0.4588264578313081, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2138109528510025, 0.2138109528510025, 0.2864813884427788], 
reward next is 0.7135, 
noisyNet noise sample is [array([0.72638094], dtype=float32), -0.59520704]. 
=============================================
[2019-03-26 19:43:30,517] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5461369e-17 1.0000000e+00 2.3271627e-16 1.1430214e-14 1.6424611e-17], sum to 1.0000
[2019-03-26 19:43:30,526] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6439
[2019-03-26 19:43:30,530] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666666, 65.66666666666667, 1.0, 2.0, 0.5497628870783279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 768233.3641580797, 768233.3641580797, 191761.1359522969], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5139600.0000, 
sim time next is 5140200.0000, 
raw observation next is [31.83333333333333, 66.33333333333333, 1.0, 2.0, 0.5587821854353346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 780841.4773765682, 780841.4773765688, 193319.4404316455], 
processed observation next is [0.0, 0.4782608695652174, 0.7077409162717218, 0.6633333333333333, 1.0, 1.0, 0.4684122716088369, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21690041038238006, 0.21690041038238023, 0.2885364782561873], 
reward next is 0.7115, 
noisyNet noise sample is [array([-0.6115732], dtype=float32), -1.0206851]. 
=============================================
[2019-03-26 19:43:32,616] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 19:43:32,618] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:43:32,619] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:43:32,621] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:43:32,622] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:43:32,622] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:43:32,623] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:43:32,623] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:43:32,624] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:43:32,631] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:43:32,632] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:43:32,641] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run15
[2019-03-26 19:43:32,642] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run15
[2019-03-26 19:43:32,679] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run15
[2019-03-26 19:43:32,679] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run15
[2019-03-26 19:43:32,680] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run15
[2019-03-26 19:43:52,639] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05564673], dtype=float32), 0.06013382]
[2019-03-26 19:43:52,640] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.6, 61.0, 1.0, 2.0, 0.2138469448450036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 356711.8742454565, 356711.8742454559, 156906.8123916593]
[2019-03-26 19:43:52,642] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:43:52,645] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.1337471e-18 1.0000000e+00 7.3444829e-16 1.2828748e-15 2.6932183e-17], sampled 0.7428927719777261
[2019-03-26 19:44:15,395] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05564673], dtype=float32), 0.06013382]
[2019-03-26 19:44:15,396] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.66746608333333, 87.49665469333334, 1.0, 2.0, 0.3252960847292656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515805.6435442958, 515805.6435442958, 168246.7099716463]
[2019-03-26 19:44:15,400] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:44:15,403] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.8279754e-20 1.0000000e+00 1.6050010e-17 2.8767208e-17 4.3815711e-19], sampled 0.1926096308371149
[2019-03-26 19:44:53,186] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05564673], dtype=float32), 0.06013382]
[2019-03-26 19:44:53,186] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [34.83333333333334, 50.66666666666666, 1.0, 2.0, 0.9739266691691698, 1.0, 2.0, 0.9739266691691698, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2724292.541434822, 2724292.541434822, 513424.8680944377]
[2019-03-26 19:44:53,188] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:44:53,191] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9867997e-18 1.0000000e+00 8.9296077e-16 4.1923836e-15 1.0046106e-16], sampled 0.7890927167288683
[2019-03-26 19:44:53,194] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2724292.541434822 W.
[2019-03-26 19:44:53,740] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05564673], dtype=float32), 0.06013382]
[2019-03-26 19:44:53,742] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.6, 80.0, 1.0, 2.0, 0.5882373266902848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 822017.9795488719, 822017.9795488719, 198574.4301363589]
[2019-03-26 19:44:53,745] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:44:53,748] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.877364e-20 1.000000e+00 1.227779e-17 2.568848e-17 4.172066e-19], sampled 0.5772824499463848
[2019-03-26 19:45:23,684] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05564673], dtype=float32), 0.06013382]
[2019-03-26 19:45:23,685] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.76906323, 92.34299742666666, 1.0, 2.0, 0.4285675626270312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 627385.3517349544, 627385.3517349544, 176806.2468638065]
[2019-03-26 19:45:23,686] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:45:23,689] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.2867246e-19 1.0000000e+00 4.5435516e-17 9.0136918e-17 1.4910566e-18], sampled 0.21869069104769712
[2019-03-26 19:45:27,484] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.5883 2927390983.0870 1338.0000
[2019-03-26 19:45:27,683] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164071917.9177 1778.0000
[2019-03-26 19:45:27,842] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9767 2779231803.5959 933.0000
[2019-03-26 19:45:27,970] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2178 3007719775.7786 1766.0000
[2019-03-26 19:45:27,971] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5144 2842492707.2201 1131.0000
[2019-03-26 19:45:28,990] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 350000, evaluation results [350000.0, 7884.168443086554, 3164071917.9176674, 1778.0, 8253.588268818321, 2927390983.087013, 1338.0, 8659.976680226611, 2779231803.5959473, 933.0, 7998.217808978373, 3007719775.7785764, 1766.0, 8497.514395919725, 2842492707.2200756, 1131.0]
[2019-03-26 19:45:29,089] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.5882004e-21 1.0000000e+00 3.6239812e-18 1.6017532e-17 1.5667793e-19], sum to 1.0000
[2019-03-26 19:45:29,100] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5549
[2019-03-26 19:45:29,103] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333333, 65.0, 1.0, 2.0, 0.5454243160662059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 762168.5117103031, 762168.5117103037, 191019.3302135518], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5157600.0000, 
sim time next is 5158200.0000, 
raw observation next is [31.16666666666667, 65.5, 1.0, 2.0, 0.5437880349774372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 759881.1769350927, 759881.1769350927, 190741.2701560888], 
processed observation next is [0.0, 0.6956521739130435, 0.6761453396524489, 0.655, 1.0, 1.0, 0.45034703009329785, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21107810470419242, 0.21107810470419242, 0.28468846291953553], 
reward next is 0.7153, 
noisyNet noise sample is [array([1.3733265], dtype=float32), -0.13471727]. 
=============================================
[2019-03-26 19:45:29,775] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.7351380e-21 1.0000000e+00 4.9037073e-17 6.4424060e-18 5.4253572e-19], sum to 1.0000
[2019-03-26 19:45:29,784] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4126
[2019-03-26 19:45:29,790] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5228320007704005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 730587.4611039674, 730587.4611039667, 187250.3871592841], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5173200.0000, 
sim time next is 5173800.0000, 
raw observation next is [28.0, 79.00000000000001, 1.0, 2.0, 0.5234912123965862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731508.9379428031, 731508.9379428037, 187358.1546805001], 
processed observation next is [0.0, 0.9130434782608695, 0.5260663507109005, 0.7900000000000001, 1.0, 1.0, 0.42589302698383885, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2031969272063342, 0.20319692720633437, 0.2796390368365673], 
reward next is 0.7204, 
noisyNet noise sample is [array([0.9373598], dtype=float32), -0.4376378]. 
=============================================
[2019-03-26 19:45:33,965] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1384054e-20 1.0000000e+00 4.2231822e-17 3.2107446e-17 1.4503778e-19], sum to 1.0000
[2019-03-26 19:45:33,972] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3916
[2019-03-26 19:45:33,977] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 88.0, 1.0, 2.0, 0.8229685654645147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1150215.090218088, 1150215.090218088, 249630.8066591812], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5291400.0000, 
sim time next is 5292000.0000, 
raw observation next is [28.6, 88.0, 1.0, 2.0, 0.9495685690163033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1327267.117137036, 1327267.117137035, 283940.5516541216], 
processed observation next is [1.0, 0.2608695652173913, 0.5545023696682465, 0.88, 1.0, 1.0, 0.9392392397786786, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.36868531031584334, 0.368685310315843, 0.42379186814048003], 
reward next is 0.5762, 
noisyNet noise sample is [array([0.7820945], dtype=float32), 0.30401194]. 
=============================================
[2019-03-26 19:45:33,990] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[72.40549 ]
 [72.37161 ]
 [71.32143 ]
 [71.206245]
 [70.887985]], R is [[72.7261734 ]
 [72.62632751]
 [72.52643585]
 [72.42599487]
 [72.32875824]].
[2019-03-26 19:45:43,069] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6175616e-13 1.0000000e+00 1.8743308e-12 2.3153372e-12 3.4824864e-13], sum to 1.0000
[2019-03-26 19:45:43,077] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8458
[2019-03-26 19:45:43,083] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 3090059.437883598 W.
[2019-03-26 19:45:43,086] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [37.08333333333334, 54.0, 1.0, 2.0, 0.831520898793349, 1.0, 2.0, 0.736350488910937, 1.0, 2.0, 1.03, 7.005108104748982, 6.9112, 170.5573041426782, 3090059.437883598, 3022789.242514433, 566089.6732177786], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5407800.0000, 
sim time next is 5408400.0000, 
raw observation next is [37.26666666666667, 54.00000000000001, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 6.933629152856978, 6.9112, 170.5573041426782, 2925415.39588875, 2909348.481337691, 553529.2515987892], 
processed observation next is [1.0, 0.6086956521739131, 0.9652448657187996, 0.54, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.0022429152856977552, 0.0, 0.8375144448122397, 0.812615387746875, 0.8081523559271364, 0.8261630620877451], 
reward next is 0.0617, 
noisyNet noise sample is [array([1.0934097], dtype=float32), -0.5270402]. 
=============================================
[2019-03-26 19:45:46,264] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2088305e-19 1.0000000e+00 2.2940304e-16 2.5260918e-16 2.6457843e-18], sum to 1.0000
[2019-03-26 19:45:46,272] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3030
[2019-03-26 19:45:46,282] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 92.66666666666667, 1.0, 2.0, 0.5148374441949914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 719412.359690964, 719412.3596909647, 185953.2053432669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5622000.0000, 
sim time next is 5622600.0000, 
raw observation next is [25.75, 92.83333333333333, 1.0, 2.0, 0.513362587680311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 717350.7608672512, 717350.7608672512, 185715.9903424979], 
processed observation next is [0.0, 0.043478260869565216, 0.41943127962085314, 0.9283333333333332, 1.0, 1.0, 0.4136898646750734, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1992641002409031, 0.1992641002409031, 0.27718804528731034], 
reward next is 0.7228, 
noisyNet noise sample is [array([-1.364653], dtype=float32), -2.2020736]. 
=============================================
[2019-03-26 19:45:47,416] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9246609e-17 1.0000000e+00 2.4094760e-16 1.5497878e-15 1.3125604e-16], sum to 1.0000
[2019-03-26 19:45:47,426] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7930
[2019-03-26 19:45:47,432] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2790366.101185709 W.
[2019-03-26 19:45:47,439] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.23333333333333, 69.33333333333333, 1.0, 2.0, 0.9975214240039615, 1.0, 2.0, 0.9975214240039615, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2790366.101185709, 2790366.101185709, 527500.3130354084], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5478000.0000, 
sim time next is 5478600.0000, 
raw observation next is [33.46666666666667, 68.66666666666667, 1.0, 2.0, 0.723032004088866, 1.0, 2.0, 0.6821060415586957, 1.0, 1.0, 1.03, 7.005099548278348, 6.9112, 170.5573041426782, 2862164.410644935, 2794900.344623739, 528703.9564017417], 
processed observation next is [1.0, 0.391304347826087, 0.7851500789889416, 0.6866666666666668, 1.0, 1.0, 0.6663036193841759, 1.0, 1.0, 0.6169952307936093, 1.0, 0.5, 1.0365853658536586, 0.009389954827834756, 0.0, 0.8375144448122397, 0.795045669623593, 0.7763612068399275, 0.7891103826891668], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.43136278], dtype=float32), -1.2409884]. 
=============================================
[2019-03-26 19:46:18,586] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3869423e-17 1.0000000e+00 6.0692409e-16 1.5165689e-15 5.4319277e-17], sum to 1.0000
[2019-03-26 19:46:18,592] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0917
[2019-03-26 19:46:18,603] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2009565.3128503 W.
[2019-03-26 19:46:18,606] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.53333333333333, 79.83333333333334, 1.0, 2.0, 0.7186287625451112, 1.0, 2.0, 0.7186287625451112, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2009565.3128503, 2009565.3128503, 382207.3359840713], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5993400.0000, 
sim time next is 5994000.0000, 
raw observation next is [29.7, 79.0, 1.0, 2.0, 0.8292189130183596, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.005983309842643, 6.9112, 168.9123931883171, 2055967.201461748, 1988724.883522459, 415172.0304382888], 
processed observation next is [1.0, 0.391304347826087, 0.6066350710900474, 0.79, 1.0, 1.0, 0.7942396542389875, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.009478330984264271, 0.0, 0.8294371789828335, 0.5711020004060411, 0.5524235787562386, 0.6196597469228191], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.9964186], dtype=float32), -1.9157926]. 
=============================================
[2019-03-26 19:46:18,619] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[68.09162 ]
 [69.29627 ]
 [71.39424 ]
 [72.65381 ]
 [72.477905]], R is [[66.16539001]
 [65.93328094]
 [65.67879486]
 [65.0220108 ]
 [64.37178802]].
[2019-03-26 19:46:24,220] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 19:46:24,223] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:46:24,227] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:46:24,227] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:46:24,228] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:46:24,228] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:46:24,230] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:46:24,233] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:46:24,234] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:46:24,234] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:46:24,234] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:46:24,257] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run16
[2019-03-26 19:46:24,258] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run16
[2019-03-26 19:46:24,289] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run16
[2019-03-26 19:46:24,290] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run16
[2019-03-26 19:46:24,322] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run16
[2019-03-26 19:46:40,522] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05519924], dtype=float32), 0.058578614]
[2019-03-26 19:46:40,523] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.999055045, 95.75021419, 1.0, 2.0, 0.3587496140662904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 547448.8494004188, 547448.8494004188, 170277.3770509686]
[2019-03-26 19:46:40,525] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:46:40,528] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.8365647e-18 1.0000000e+00 9.4707717e-16 2.2295669e-15 1.8663493e-17], sampled 0.7642876371049957
[2019-03-26 19:47:39,375] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05519924], dtype=float32), 0.058578614]
[2019-03-26 19:47:39,377] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.03333333333333, 73.33333333333334, 1.0, 2.0, 0.6071775903924442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 848496.1634830114, 848496.1634830114, 202089.6746038916]
[2019-03-26 19:47:39,379] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:47:39,382] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.0859265e-19 1.0000000e+00 6.2386974e-17 1.5630806e-16 1.4580284e-18], sampled 0.27613846437001366
[2019-03-26 19:47:50,724] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05519924], dtype=float32), 0.058578614]
[2019-03-26 19:47:50,726] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.016911825, 86.53358144, 1.0, 2.0, 0.6326602883205923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 884121.6067298009, 884121.6067298015, 206986.1483559282]
[2019-03-26 19:47:50,728] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:47:50,730] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.5154898e-20 1.0000000e+00 6.0290606e-18 2.9635350e-17 9.5687659e-20], sampled 0.6105401622891975
[2019-03-26 19:47:53,565] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05519924], dtype=float32), 0.058578614]
[2019-03-26 19:47:53,566] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.73333333333333, 90.0, 1.0, 2.0, 0.6436713855520295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 899515.7632904821, 899515.7632904828, 209156.4573357524]
[2019-03-26 19:47:53,569] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:47:53,571] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.24939777e-19 1.00000000e+00 1.01736426e-16 2.04275164e-16
 2.02801277e-18], sampled 0.06221881142751462
[2019-03-26 19:48:16,911] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05519924], dtype=float32), 0.058578614]
[2019-03-26 19:48:16,912] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.85, 63.0, 1.0, 2.0, 0.3392041555904872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 531451.666160379, 531451.6661603784, 169358.752545204]
[2019-03-26 19:48:16,913] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:48:16,919] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.3817044e-19 1.0000000e+00 8.4097329e-17 2.4935686e-16 2.2532046e-18], sampled 0.5812717375844187
[2019-03-26 19:48:18,413] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 19:48:19,098] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164027848.4855 1778.0000
[2019-03-26 19:48:19,194] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.1049 2927540863.5018 1338.0000
[2019-03-26 19:48:19,248] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5144 2842492707.2201 1131.0000
[2019-03-26 19:48:19,409] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 19:48:20,423] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 375000, evaluation results [375000.0, 7884.16835844559, 3164027848.485504, 1778.0, 8252.10492501701, 2927540863.501752, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8497.514395919725, 2842492707.2200756, 1131.0]
[2019-03-26 19:48:26,844] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6911354e-20 1.0000000e+00 3.7994213e-18 2.6726265e-17 6.4799371e-20], sum to 1.0000
[2019-03-26 19:48:26,853] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6864
[2019-03-26 19:48:26,860] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.25, 86.16666666666667, 1.0, 2.0, 0.5296273506821226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740086.3573434277, 740086.3573434271, 188368.3708849643], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6210600.0000, 
sim time next is 6211200.0000, 
raw observation next is [27.2, 86.33333333333334, 1.0, 2.0, 0.528573020536152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738612.5538424747, 738612.5538424747, 188194.0872299482], 
processed observation next is [1.0, 0.9130434782608695, 0.4881516587677725, 0.8633333333333334, 1.0, 1.0, 0.43201568739295415, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20517015384513188, 0.20517015384513188, 0.28088669735813165], 
reward next is 0.7191, 
noisyNet noise sample is [array([-1.9670889], dtype=float32), 0.81371105]. 
=============================================
[2019-03-26 19:48:34,619] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0350297e-19 1.0000000e+00 2.3235877e-16 1.6643603e-16 2.3032087e-18], sum to 1.0000
[2019-03-26 19:48:34,626] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3773
[2019-03-26 19:48:34,634] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.4, 68.66666666666667, 1.0, 2.0, 0.5390066517151064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 753197.3754166679, 753197.3754166673, 189933.3915772869], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6344400.0000, 
sim time next is 6345000.0000, 
raw observation next is [30.55, 68.0, 1.0, 2.0, 0.5387501720062388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 752838.8486701441, 752838.8486701441, 189890.3342784654], 
processed observation next is [0.0, 0.43478260869565216, 0.6469194312796209, 0.68, 1.0, 1.0, 0.44427731567016715, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20912190240837336, 0.20912190240837336, 0.2834184093708439], 
reward next is 0.7166, 
noisyNet noise sample is [array([-0.34130827], dtype=float32), -0.02633147]. 
=============================================
[2019-03-26 19:48:34,678] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[69.99794]
 [69.93581]
 [69.86797]
 [69.80746]
 [69.75668]], R is [[70.07138062]
 [70.08718109]
 [70.1031723 ]
 [70.11960602]
 [70.13633728]].
[2019-03-26 19:48:38,206] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4122836e-21 1.0000000e+00 3.6378026e-19 7.6097390e-18 8.0312832e-21], sum to 1.0000
[2019-03-26 19:48:38,213] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1773
[2019-03-26 19:48:38,218] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.1, 83.0, 1.0, 2.0, 0.5124905265649867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 716131.769476908, 716131.769476908, 185575.9632581578], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6394800.0000, 
sim time next is 6395400.0000, 
raw observation next is [27.1, 83.0, 1.0, 2.0, 0.5123525211006227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 715938.8617114736, 715938.8617114729, 185553.8411422499], 
processed observation next is [1.0, 0.0, 0.4834123222748816, 0.83, 1.0, 1.0, 0.412472916988702, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19887190603096488, 0.1988719060309647, 0.2769460315555969], 
reward next is 0.7231, 
noisyNet noise sample is [array([-1.1604565], dtype=float32), -0.1493118]. 
=============================================
[2019-03-26 19:48:40,252] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.9473559e-13 1.0000000e+00 1.9598656e-12 3.4306100e-12 1.6304444e-13], sum to 1.0000
[2019-03-26 19:48:40,260] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0070
[2019-03-26 19:48:40,270] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1667533.072976858 W.
[2019-03-26 19:48:40,275] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.9, 69.0, 1.0, 2.0, 0.3976078264270595, 1.0, 2.0, 0.3976078264270595, 1.0, 1.0, 0.6819561752372282, 6.9112, 6.9112, 170.5573041426782, 1667533.072976858, 1667533.072976858, 350374.5714163264], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6439200.0000, 
sim time next is 6439800.0000, 
raw observation next is [29.9, 69.0, 1.0, 2.0, 0.5741325721626768, 1.0, 2.0, 0.5741325721626768, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1605195.145474094, 1605195.145474094, 324891.4988676415], 
processed observation next is [1.0, 0.5217391304347826, 0.6161137440758293, 0.69, 1.0, 1.0, 0.48690671344900815, 1.0, 1.0, 0.48690671344900815, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.44588754040947054, 0.44588754040947054, 0.48491268487707684], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0055792], dtype=float32), 1.5572702]. 
=============================================
[2019-03-26 19:48:48,616] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6463987e-19 1.0000000e+00 7.4941088e-17 4.2478723e-16 6.9886282e-19], sum to 1.0000
[2019-03-26 19:48:48,623] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6628
[2019-03-26 19:48:48,628] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.91666666666666, 91.83333333333333, 1.0, 2.0, 0.6900972663872862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 964424.3080547536, 964424.3080547536, 218720.6287760917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6580200.0000, 
sim time next is 6580800.0000, 
raw observation next is [25.9, 92.0, 1.0, 2.0, 0.6567178005377173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 917755.7016708504, 917755.7016708504, 211778.6193700534], 
processed observation next is [1.0, 0.17391304347826086, 0.42654028436018954, 0.92, 1.0, 1.0, 0.5864069885996595, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.254932139353014, 0.254932139353014, 0.31608749159709465], 
reward next is 0.6839, 
noisyNet noise sample is [array([-0.18459073], dtype=float32), 0.9622695]. 
=============================================
[2019-03-26 19:48:50,770] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.1093023e-16 1.0000000e+00 2.2526936e-14 6.9732272e-14 2.7632063e-15], sum to 1.0000
[2019-03-26 19:48:50,780] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7839
[2019-03-26 19:48:50,789] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2128787.582506141 W.
[2019-03-26 19:48:50,799] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.5, 80.5, 1.0, 2.0, 0.8812468307965657, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.99036914745939, 6.9112, 168.912420995886, 2128787.582506141, 2072622.442570848, 429491.5815498587], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6623400.0000, 
sim time next is 6624000.0000, 
raw observation next is [28.0, 84.0, 1.0, 2.0, 0.8338394477633783, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.991181730604744, 6.9112, 168.9124160842159, 2062434.086559327, 2005692.475651342, 416926.3796088968], 
processed observation next is [1.0, 0.6956521739130435, 0.5260663507109005, 0.84, 1.0, 1.0, 0.7998065635703352, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.00799817306047439, 0.0, 0.8294372914121783, 0.5728983573775909, 0.5571367987920395, 0.6222781785207415], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.572288], dtype=float32), -0.39241916]. 
=============================================
[2019-03-26 19:48:50,810] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[54.620483]
 [54.5911  ]
 [54.791214]
 [54.241943]
 [54.959072]], R is [[53.96572495]
 [53.42606735]
 [52.89180756]
 [52.36288834]
 [51.8392601 ]].
[2019-03-26 19:48:53,694] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.0290810e-19 1.0000000e+00 8.8559902e-17 6.4518043e-17 1.4664344e-18], sum to 1.0000
[2019-03-26 19:48:53,706] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4867
[2019-03-26 19:48:53,713] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.85, 95.0, 1.0, 2.0, 0.6174718364561248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 862887.6307443506, 862887.6307443506, 204037.042439798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6665400.0000, 
sim time next is 6666000.0000, 
raw observation next is [24.83333333333333, 95.0, 1.0, 2.0, 0.5671261544422777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 792505.6782678583, 792505.6782678589, 194775.735778482], 
processed observation next is [1.0, 0.13043478260869565, 0.3759873617693521, 0.95, 1.0, 1.0, 0.47846524631599713, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2201404661855162, 0.22014046618551636, 0.29071005340071937], 
reward next is 0.7093, 
noisyNet noise sample is [array([-2.143614], dtype=float32), -0.42633125]. 
=============================================
[2019-03-26 19:48:53,728] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.45843 ]
 [68.549904]
 [68.64959 ]
 [68.66852 ]
 [68.734406]], R is [[68.51200867]
 [68.52235413]
 [68.53611755]
 [68.54722595]
 [68.56468964]].
[2019-03-26 19:48:56,370] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5283418e-13 1.0000000e+00 7.5724357e-12 9.6957173e-12 3.1321237e-13], sum to 1.0000
[2019-03-26 19:48:56,380] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7847
[2019-03-26 19:48:56,391] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2056190.423498849 W.
[2019-03-26 19:48:56,395] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.06666666666667, 62.0, 1.0, 2.0, 0.4901907377908207, 1.0, 1.0, 0.4901907377908207, 1.0, 2.0, 0.8290755036650568, 6.9112, 6.9112, 170.5573041426782, 2056190.423498849, 2056190.423498849, 404429.4595725613], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6705600.0000, 
sim time next is 6706200.0000, 
raw observation next is [30.03333333333333, 62.5, 1.0, 2.0, 0.4885131945097581, 1.0, 2.0, 0.4885131945097581, 1.0, 2.0, 0.8278296625931516, 6.911200000000001, 6.9112, 170.5573041426782, 2049146.945972024, 2049146.945972024, 403615.169271498], 
processed observation next is [1.0, 0.6086956521739131, 0.622432859399684, 0.625, 1.0, 1.0, 0.3837508367587448, 1.0, 1.0, 0.3837508367587448, 1.0, 1.0, 0.7900361738940873, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5692074849922288, 0.5692074849922288, 0.6024107004052208], 
reward next is 0.3976, 
noisyNet noise sample is [array([0.9982049], dtype=float32), 0.37755936]. 
=============================================
[2019-03-26 19:49:09,154] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3884822e-18 1.0000000e+00 7.5691241e-17 2.4331397e-16 4.3453840e-19], sum to 1.0000
[2019-03-26 19:49:09,163] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7856
[2019-03-26 19:49:09,168] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.96666666666667, 89.66666666666666, 1.0, 2.0, 0.4177167231459037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 613994.5689308227, 613994.5689308232, 175586.1054938332], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6925800.0000, 
sim time next is 6926400.0000, 
raw observation next is [23.9, 90.0, 1.0, 2.0, 0.4165771048668537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 612831.3522172116, 612831.3522172116, 175490.061568499], 
processed observation next is [0.0, 0.17391304347826086, 0.33175355450236965, 0.9, 1.0, 1.0, 0.2970808492371731, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17023093117144766, 0.17023093117144766, 0.26192546502761044], 
reward next is 0.7381, 
noisyNet noise sample is [array([0.39613867], dtype=float32), -0.9154595]. 
=============================================
[2019-03-26 19:49:12,880] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.9513786e-21 1.0000000e+00 5.6182231e-18 1.2151842e-17 7.3270618e-20], sum to 1.0000
[2019-03-26 19:49:12,889] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7194
[2019-03-26 19:49:12,896] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.53333333333333, 66.66666666666667, 1.0, 2.0, 0.4144269176033511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 608711.9609456295, 608711.9609456295, 175072.9004370057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6990000.0000, 
sim time next is 6990600.0000, 
raw observation next is [27.41666666666666, 67.83333333333333, 1.0, 2.0, 0.4183159584869597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 612532.4056348385, 612532.4056348385, 175380.4542522756], 
processed observation next is [0.0, 0.9130434782608695, 0.4984202211690361, 0.6783333333333332, 1.0, 1.0, 0.2991758535987466, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17014789045412182, 0.17014789045412182, 0.2617618720183218], 
reward next is 0.7382, 
noisyNet noise sample is [array([0.97277164], dtype=float32), 1.3964994]. 
=============================================
[2019-03-26 19:49:15,051] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1839797e-20 1.0000000e+00 6.0865314e-18 3.0406475e-18 5.9210635e-20], sum to 1.0000
[2019-03-26 19:49:15,061] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0659
[2019-03-26 19:49:15,065] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 79.0, 1.0, 2.0, 0.5855903575358012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 837296.2155166777, 837296.215516677, 200529.5002674691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7021200.0000, 
sim time next is 7021800.0000, 
raw observation next is [26.35, 78.0, 1.0, 2.0, 0.5977991114801654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 854855.0022633283, 854855.0022633277, 202843.5922504146], 
processed observation next is [1.0, 0.2608695652173913, 0.4478672985781992, 0.78, 1.0, 1.0, 0.5154206162411631, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23745972285092454, 0.23745972285092437, 0.3027516302244994], 
reward next is 0.6972, 
noisyNet noise sample is [array([0.3189848], dtype=float32), 0.8453561]. 
=============================================
[2019-03-26 19:49:15,536] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-26 19:49:15,537] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:49:15,538] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:49:15,539] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:49:15,540] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:49:15,540] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:49:15,541] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:49:15,544] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:49:15,545] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:49:15,546] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:49:15,544] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:49:15,566] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run17
[2019-03-26 19:49:15,583] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run17
[2019-03-26 19:49:15,609] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run17
[2019-03-26 19:49:15,609] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run17
[2019-03-26 19:49:15,625] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run17
[2019-03-26 19:49:43,322] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05921049], dtype=float32), 0.061885834]
[2019-03-26 19:49:43,325] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.16666666666667, 89.66666666666666, 1.0, 2.0, 0.3817332303297106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 576854.1256120398, 576854.1256120398, 172650.8097071538]
[2019-03-26 19:49:43,325] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:49:43,330] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.3551159e-19 1.0000000e+00 1.0836811e-16 3.1690576e-16 1.8161176e-18], sampled 0.6992387991905706
[2019-03-26 19:49:51,900] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05921049], dtype=float32), 0.061885834]
[2019-03-26 19:49:51,906] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.3, 80.0, 1.0, 2.0, 0.5726442381513778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 800219.5880377964, 800219.5880377964, 195759.9957346452]
[2019-03-26 19:49:51,907] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:49:51,910] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.2644088e-21 1.0000000e+00 3.0231815e-19 1.9081748e-18 6.3846089e-21], sampled 0.35192945311550117
[2019-03-26 19:50:05,316] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05921049], dtype=float32), 0.061885834]
[2019-03-26 19:50:05,319] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.0, 72.0, 1.0, 2.0, 0.5350461803463259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 747661.1423160979, 747661.1423160972, 189270.173455255]
[2019-03-26 19:50:05,320] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:50:05,323] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1691696e-19 1.0000000e+00 1.8801981e-17 7.1309335e-17 4.1212899e-19], sampled 0.007373717358497678
[2019-03-26 19:50:06,940] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05921049], dtype=float32), 0.061885834]
[2019-03-26 19:50:06,941] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.56788245166667, 78.63359188666666, 1.0, 2.0, 0.5352262408849944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 747912.8433238264, 747912.8433238271, 189299.4480417905]
[2019-03-26 19:50:06,942] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:50:06,946] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.6601538e-21 1.0000000e+00 7.8580059e-19 4.5327814e-18 1.7343585e-20], sampled 0.37577112858491457
[2019-03-26 19:50:07,465] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05921049], dtype=float32), 0.061885834]
[2019-03-26 19:50:07,469] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.45, 84.0, 1.0, 2.0, 0.6277783149459266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 877296.3944237874, 877296.3944237867, 206025.7130306941]
[2019-03-26 19:50:07,470] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:50:07,472] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.4554945e-20 1.0000000e+00 1.5485925e-17 4.9726899e-17 2.7354398e-19], sampled 0.22260262212652193
[2019-03-26 19:50:14,965] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05921049], dtype=float32), 0.061885834]
[2019-03-26 19:50:14,967] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.66666666666667, 65.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 8.500124651128505, 6.9112, 168.9036748247824, 3418025.364243168, 2290849.47134295, 472384.8356354238]
[2019-03-26 19:50:14,968] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:50:14,971] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.5940815e-17 1.0000000e+00 2.0766791e-15 9.2995781e-15 1.4574016e-16], sampled 0.7528668729455467
[2019-03-26 19:50:14,972] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 3418025.364243168 W.
[2019-03-26 19:50:24,513] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05921049], dtype=float32), 0.061885834]
[2019-03-26 19:50:24,514] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.5, 46.0, 1.0, 2.0, 0.5171509128484197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722646.20386177, 722646.20386177, 186326.462411284]
[2019-03-26 19:50:24,516] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:50:24,521] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.0318971e-21 1.0000000e+00 4.4616370e-19 3.0501038e-18 1.2767543e-20], sampled 0.7914954316017878
[2019-03-26 19:50:58,287] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05921049], dtype=float32), 0.061885834]
[2019-03-26 19:50:58,291] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.02022825166667, 79.61062333333334, 1.0, 2.0, 0.365388044031228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 562945.4494296713, 562945.449429672, 171743.9764166109]
[2019-03-26 19:50:58,293] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:50:58,295] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.5757085e-20 1.0000000e+00 1.0939146e-17 2.9775068e-17 1.9241451e-19], sampled 0.9439939616487488
[2019-03-26 19:51:08,225] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05921049], dtype=float32), 0.061885834]
[2019-03-26 19:51:08,226] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.27689129, 68.46143072, 1.0, 2.0, 0.9453610688729287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.91295651043, 1379453.681034031, 1379453.681034031, 291406.9556104089]
[2019-03-26 19:51:08,226] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:51:08,228] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.4355399e-22 1.0000000e+00 1.3403981e-19 6.3506326e-19 2.4536580e-21], sampled 0.49175649172109936
[2019-03-26 19:51:09,928] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 19:51:10,036] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7281 2779199535.5119 933.0000
[2019-03-26 19:51:10,301] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.0766 3007691463.1510 1766.0000
[2019-03-26 19:51:10,365] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 19:51:10,396] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6466 2927350664.6004 1338.0000
[2019-03-26 19:51:11,411] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 400000, evaluation results [400000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8253.646569330924, 2927350664.600389, 1338.0, 8660.728066421085, 2779199535.5119066, 933.0, 7996.076579686626, 3007691463.1509957, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 19:51:15,200] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.8282110e-19 1.0000000e+00 2.4375315e-18 1.5498342e-16 2.7677476e-19], sum to 1.0000
[2019-03-26 19:51:15,207] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9348
[2019-03-26 19:51:15,215] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 72.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.050295756754078, 6.9112, 168.9119923231301, 1574211.495455671, 1475532.741588167, 314828.173526949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7117200.0000, 
sim time next is 7117800.0000, 
raw observation next is [27.6, 71.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.865800084982329, 6.9112, 168.9075676307972, 2151868.761937186, 1474664.212596213, 314626.0437618887], 
processed observation next is [1.0, 0.391304347826087, 0.5071090047393366, 0.7166666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.09546000849823288, 0.0, 0.8294134832862609, 0.5977413227603294, 0.4096289479433925, 0.4695911100923712], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.46500054], dtype=float32), -0.8459873]. 
=============================================
[2019-03-26 19:51:20,399] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6485993e-18 1.0000000e+00 3.4585319e-16 1.8978186e-15 8.5268606e-18], sum to 1.0000
[2019-03-26 19:51:20,408] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6113
[2019-03-26 19:51:20,419] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2048237.739469575 W.
[2019-03-26 19:51:20,424] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 83.16666666666667, 1.0, 2.0, 0.4882966482206731, 1.0, 1.0, 0.4882966482206731, 1.0, 2.0, 0.8480097957901503, 6.9112, 6.9112, 170.5573041426782, 2048237.739469575, 2048237.739469575, 407147.4158852476], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7204200.0000, 
sim time next is 7204800.0000, 
raw observation next is [29.0, 82.33333333333334, 1.0, 2.0, 0.6923012553699236, 1.0, 2.0, 0.6923012553699236, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1935876.854578043, 1935876.854578043, 370851.5704089983], 
processed observation next is [1.0, 0.391304347826087, 0.5734597156398105, 0.8233333333333335, 1.0, 1.0, 0.6292786209276188, 1.0, 1.0, 0.6292786209276188, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5377435707161231, 0.5377435707161231, 0.5535098065805945], 
reward next is 0.4465, 
noisyNet noise sample is [array([-0.8638154], dtype=float32), 0.80068624]. 
=============================================
[2019-03-26 19:51:22,590] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.0042436e-20 1.0000000e+00 5.4749873e-18 1.6053195e-17 1.5501866e-19], sum to 1.0000
[2019-03-26 19:51:22,598] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9103
[2019-03-26 19:51:22,604] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 83.5, 1.0, 2.0, 0.871551739259961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1303050.687787422, 1303050.687787421, 274202.9493284149], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7230600.0000, 
sim time next is 7231200.0000, 
raw observation next is [24.33333333333334, 82.66666666666667, 1.0, 2.0, 0.8681887734308278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1301619.070462619, 1301619.070462619, 273715.6453515906], 
processed observation next is [1.0, 0.6956521739130435, 0.35229067930489766, 0.8266666666666667, 1.0, 1.0, 0.841191293290154, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.36156085290628304, 0.36156085290628304, 0.4085308139575979], 
reward next is 0.5915, 
noisyNet noise sample is [array([-0.17995039], dtype=float32), 0.17388897]. 
=============================================
[2019-03-26 19:51:23,329] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.4702241e-18 1.0000000e+00 5.3808869e-16 1.2252863e-15 2.1115849e-18], sum to 1.0000
[2019-03-26 19:51:23,337] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2894
[2019-03-26 19:51:23,343] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.85, 88.0, 1.0, 2.0, 0.3243149078412004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 511550.5761409131, 511550.5761409138, 167874.7034761465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7281000.0000, 
sim time next is 7281600.0000, 
raw observation next is [21.9, 87.66666666666667, 1.0, 2.0, 0.32384633556991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 510724.8929599915, 510724.8929599921, 167809.770943136], 
processed observation next is [1.0, 0.2608695652173913, 0.23696682464454974, 0.8766666666666667, 1.0, 1.0, 0.18535703080712046, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14186802582221986, 0.14186802582222002, 0.2504623446912478], 
reward next is 0.7495, 
noisyNet noise sample is [array([1.1855236], dtype=float32), -0.21460553]. 
=============================================
[2019-03-26 19:51:24,957] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.6053576e-18 1.0000000e+00 3.2916550e-16 1.9792543e-15 3.0353744e-18], sum to 1.0000
[2019-03-26 19:51:24,966] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0032
[2019-03-26 19:51:24,973] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.63333333333333, 89.66666666666667, 1.0, 2.0, 0.3310579444283711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 522246.5324323068, 522246.5324323062, 168702.9998408542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7270800.0000, 
sim time next is 7271400.0000, 
raw observation next is [21.61666666666667, 89.83333333333333, 1.0, 2.0, 0.3282927001426869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 517834.9143904585, 517834.9143904591, 168359.0085167426], 
processed observation next is [1.0, 0.13043478260869565, 0.22353870458135885, 0.8983333333333333, 1.0, 1.0, 0.1907140965574541, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14384303177512736, 0.14384303177512753, 0.2512821022637949], 
reward next is 0.7487, 
noisyNet noise sample is [array([-0.74322695], dtype=float32), 2.3602133]. 
=============================================
[2019-03-26 19:51:25,979] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6655462e-20 1.0000000e+00 2.6274074e-19 8.1112859e-18 1.7495355e-20], sum to 1.0000
[2019-03-26 19:51:25,988] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5797
[2019-03-26 19:51:25,993] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.86666666666667, 59.0, 1.0, 2.0, 0.5469681215190736, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9581572722657448, 6.9112, 6.9112, 168.9127464997505, 1648931.145085765, 1648931.145085765, 345106.5565319973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7310400.0000, 
sim time next is 7311000.0000, 
raw observation next is [27.83333333333334, 59.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.15293579318967, 6.9112, 168.9114645934991, 1744184.825315209, 1572690.648451388, 329547.3156867361], 
processed observation next is [1.0, 0.6086956521739131, 0.5181674565560824, 0.595, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.024173579318966975, 0.0, 0.8294326191571645, 0.4844957848097803, 0.4368585134587189, 0.4918616652040837], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5968661], dtype=float32), 0.7710906]. 
=============================================
[2019-03-26 19:51:26,015] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[77.51412 ]
 [79.117256]
 [78.86098 ]
 [78.63438 ]
 [78.342384]], R is [[76.66648102]
 [76.38473511]
 [75.62088776]
 [75.1025238 ]
 [74.87677765]].
[2019-03-26 19:51:32,381] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8888641e-21 1.0000000e+00 4.5031015e-19 1.6675934e-18 3.3100068e-20], sum to 1.0000
[2019-03-26 19:51:32,395] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2922
[2019-03-26 19:51:32,400] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.76666666666667, 91.33333333333334, 1.0, 2.0, 0.5568043743383154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 890735.134253962, 890735.1342539614, 205559.217615906], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7396800.0000, 
sim time next is 7397400.0000, 
raw observation next is [20.73333333333333, 91.16666666666667, 1.0, 2.0, 0.5776088857498417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 924981.165246668, 924981.165246668, 209820.0580557807], 
processed observation next is [1.0, 0.6086956521739131, 0.18167456556082143, 0.9116666666666667, 1.0, 1.0, 0.4910950430720984, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2569392125685189, 0.2569392125685189, 0.3131642657548966], 
reward next is 0.6868, 
noisyNet noise sample is [array([-2.4423778], dtype=float32), 0.81518155]. 
=============================================
[2019-03-26 19:51:38,484] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0112521e-21 1.0000000e+00 8.3271083e-19 1.6973599e-18 6.0471814e-20], sum to 1.0000
[2019-03-26 19:51:38,494] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0414
[2019-03-26 19:51:38,498] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.43333333333333, 80.0, 1.0, 2.0, 0.4123104407429036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 603519.7908392458, 603519.7908392464, 174521.6613810738], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7497600.0000, 
sim time next is 7498200.0000, 
raw observation next is [25.31666666666667, 80.5, 1.0, 2.0, 0.4102745150565296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 601467.1663904247, 601467.1663904247, 174357.7980464165], 
processed observation next is [0.0, 0.782608695652174, 0.39889415481832563, 0.805, 1.0, 1.0, 0.2894873675379875, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1670742128862291, 0.1670742128862291, 0.2602355194722634], 
reward next is 0.7398, 
noisyNet noise sample is [array([0.6747626], dtype=float32), -0.25849488]. 
=============================================
[2019-03-26 19:51:39,914] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.3754888e-20 1.0000000e+00 4.4664924e-18 4.3559771e-17 1.8545380e-19], sum to 1.0000
[2019-03-26 19:51:39,922] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4144
[2019-03-26 19:51:39,926] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 93.0, 1.0, 2.0, 0.4055862931466801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 597113.5328769247, 597113.5328769247, 174031.1522881732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7521000.0000, 
sim time next is 7521600.0000, 
raw observation next is [23.5, 93.0, 1.0, 2.0, 0.4052288579085293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 596593.7991905018, 596593.7991905018, 173983.2925343863], 
processed observation next is [0.0, 0.043478260869565216, 0.31279620853080575, 0.93, 1.0, 1.0, 0.28340826254039675, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1657204997751394, 0.1657204997751394, 0.2596765560214721], 
reward next is 0.7403, 
noisyNet noise sample is [array([0.15004037], dtype=float32), 0.24195799]. 
=============================================
[2019-03-26 19:51:42,898] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9706372e-20 1.0000000e+00 7.4744048e-18 1.9718433e-18 2.6144685e-20], sum to 1.0000
[2019-03-26 19:51:42,909] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0683
[2019-03-26 19:51:42,914] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 95.0, 1.0, 2.0, 0.5300940610091275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 763228.287883301, 763228.2878833016, 191303.9255806483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7612200.0000, 
sim time next is 7612800.0000, 
raw observation next is [23.76666666666667, 95.0, 1.0, 2.0, 0.5236451941342106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 755012.724271016, 755012.724271016, 190340.6590097879], 
processed observation next is [1.0, 0.08695652173913043, 0.32543443917851517, 0.95, 1.0, 1.0, 0.4260785471496513, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20972575674194888, 0.20972575674194888, 0.2840905358355043], 
reward next is 0.7159, 
noisyNet noise sample is [array([0.22489421], dtype=float32), 1.3161705]. 
=============================================
[2019-03-26 19:51:44,037] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.08825035e-21 1.00000000e+00 1.11554911e-18 1.06664775e-17
 3.41832324e-20], sum to 1.0000
[2019-03-26 19:51:44,048] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5010
[2019-03-26 19:51:44,054] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.86666666666667, 87.66666666666667, 1.0, 2.0, 0.4889998492040688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 683296.3707179198, 683296.3707179191, 181890.3967815603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7591800.0000, 
sim time next is 7592400.0000, 
raw observation next is [25.8, 88.0, 1.0, 2.0, 0.4895780379250799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 684104.5539272211, 684104.5539272205, 181979.0735598011], 
processed observation next is [0.0, 0.9130434782608695, 0.42180094786729866, 0.88, 1.0, 1.0, 0.3850337806326264, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1900290427575614, 0.19002904275756125, 0.2716105575519419], 
reward next is 0.7284, 
noisyNet noise sample is [array([0.9337822], dtype=float32), -0.22026187]. 
=============================================
[2019-03-26 19:51:48,080] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9055181e-16 1.0000000e+00 3.5447670e-15 4.9001337e-14 4.3827811e-16], sum to 1.0000
[2019-03-26 19:51:48,088] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2624
[2019-03-26 19:51:48,097] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1769927.922432672 W.
[2019-03-26 19:51:48,104] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.7, 75.0, 1.0, 2.0, 0.6330041763594831, 1.0, 2.0, 0.6330041763594831, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1769927.922432672, 1769927.922432672, 346758.1678247926], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7664400.0000, 
sim time next is 7665000.0000, 
raw observation next is [28.55, 75.66666666666667, 1.0, 2.0, 0.2137140057038233, 1.0, 2.0, 0.2137140057038233, 1.0, 1.0, 0.3645497942321031, 6.911200000000001, 6.9112, 170.5573041426782, 895975.8952359201, 895975.8952359195, 273372.4198518081], 
processed observation next is [1.0, 0.7391304347826086, 0.552132701421801, 0.7566666666666667, 1.0, 1.0, 0.05266747675159431, 1.0, 1.0, 0.05266747675159431, 1.0, 0.5, 0.22506072467329646, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.24888219312108892, 0.24888219312108875, 0.4080185370922509], 
reward next is 0.5920, 
noisyNet noise sample is [array([0.45733565], dtype=float32), 0.8257063]. 
=============================================
[2019-03-26 19:51:48,115] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[58.458942]
 [57.470848]
 [57.705948]
 [58.460274]
 [58.264893]], R is [[58.05401611]
 [57.95592499]
 [57.85358047]
 [57.27504349]
 [56.7022934 ]].
[2019-03-26 19:51:56,481] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:51:56,483] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:51:56,532] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run3
[2019-03-26 19:52:02,832] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:02,832] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:02,859] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run3
[2019-03-26 19:52:03,637] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:03,638] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:03,659] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run3
[2019-03-26 19:52:04,417] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:04,417] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:04,423] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run3
[2019-03-26 19:52:04,777] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:04,778] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:04,792] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run3
[2019-03-26 19:52:04,840] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:04,841] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:04,857] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run3
[2019-03-26 19:52:05,011] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:05,011] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:05,025] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run3
[2019-03-26 19:52:05,075] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:05,075] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:05,088] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run3
[2019-03-26 19:52:05,151] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:05,152] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:05,162] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run3
[2019-03-26 19:52:05,163] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:05,178] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:05,185] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:05,186] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:05,194] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:05,194] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:05,203] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run3
[2019-03-26 19:52:05,205] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:05,206] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run3
[2019-03-26 19:52:05,206] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:05,246] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:05,247] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:05,250] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:05,248] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:05,246] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run3
[2019-03-26 19:52:05,277] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run3
[2019-03-26 19:52:05,293] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run3
[2019-03-26 19:52:05,295] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:05,296] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:05,321] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run3
[2019-03-26 19:52:05,356] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run3
[2019-03-26 19:52:06,302] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 19:52:06,304] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:52:06,305] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:06,306] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run18
[2019-03-26 19:52:06,348] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:52:06,349] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:06,350] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run18
[2019-03-26 19:52:06,391] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:52:06,392] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:06,393] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run18
[2019-03-26 19:52:06,473] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:52:06,473] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:06,475] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run18
[2019-03-26 19:52:06,526] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:52:06,526] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:06,528] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run18
[2019-03-26 19:52:12,655] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06111745], dtype=float32), 0.06350275]
[2019-03-26 19:52:12,656] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.5, 67.5, 1.0, 2.0, 0.2389830045320122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 396234.6210847562, 396234.6210847569, 159659.9616555557]
[2019-03-26 19:52:12,657] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:52:12,660] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.48977589e-18 1.00000000e+00 6.51283580e-16 1.94931970e-15
 1.35109795e-17], sampled 0.5995541598541746
[2019-03-26 19:52:42,363] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06111745], dtype=float32), 0.06350275]
[2019-03-26 19:52:42,365] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.9, 67.33333333333334, 1.0, 2.0, 0.4933085302763801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 735219.0766219446, 735219.0766219452, 188251.3169994063]
[2019-03-26 19:52:42,368] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:52:42,370] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.8782955e-20 1.0000000e+00 3.4637965e-18 1.5014225e-17 6.8682661e-20], sampled 0.03457080012524094
[2019-03-26 19:52:44,087] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06111745], dtype=float32), 0.06350275]
[2019-03-26 19:52:44,088] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.27251383, 79.33985786, 1.0, 2.0, 0.6904564421865076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 964926.4912333217, 964926.4912333217, 218801.0484692432]
[2019-03-26 19:52:44,090] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:52:44,092] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.5941026e-21 1.0000000e+00 1.0464793e-18 4.4093231e-18 1.7381535e-20], sampled 0.009758172847089797
[2019-03-26 19:52:49,399] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06111745], dtype=float32), 0.06350275]
[2019-03-26 19:52:49,400] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.41666666666666, 79.66666666666667, 1.0, 2.0, 0.5962280057221058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 833188.7397804743, 833188.7397804743, 200038.5179753048]
[2019-03-26 19:52:49,402] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:52:49,406] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.0000852e-20 1.0000000e+00 7.7767782e-18 2.3329656e-17 1.2919923e-19], sampled 0.2479922896247495
[2019-03-26 19:53:23,128] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06111745], dtype=float32), 0.06350275]
[2019-03-26 19:53:23,130] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.51331567833333, 75.18405805666667, 1.0, 2.0, 0.6882076395287314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 961782.3220983496, 961782.322098349, 218316.8536132956]
[2019-03-26 19:53:23,130] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:53:23,135] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.3232578e-21 1.0000000e+00 1.5515659e-18 5.0609673e-18 3.4436224e-20], sampled 0.8316997404254081
[2019-03-26 19:53:47,272] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06111745], dtype=float32), 0.06350275]
[2019-03-26 19:53:47,275] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.8, 84.66666666666667, 1.0, 2.0, 0.4240072970887338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 619883.8812531757, 619883.8812531751, 176057.0589635421]
[2019-03-26 19:53:47,276] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:53:47,279] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.3113849e-20 1.0000000e+00 8.4139323e-18 3.8221154e-17 1.8719874e-19], sampled 0.5991358469925003
[2019-03-26 19:54:00,807] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.5921 2779214994.0068 933.0000
[2019-03-26 19:54:00,948] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.0653 2927317329.7462 1338.0000
[2019-03-26 19:54:01,133] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.4166 2842558242.3972 1131.0000
[2019-03-26 19:54:01,242] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164071917.9177 1778.0000
[2019-03-26 19:54:01,252] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.3130 3007656030.3370 1766.0000
[2019-03-26 19:54:02,267] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 425000, evaluation results [425000.0, 7884.168443086554, 3164071917.9176674, 1778.0, 8255.065342017213, 2927317329.746172, 1338.0, 8660.592086161303, 2779214994.0067887, 933.0, 7998.312951428424, 3007656030.3370423, 1766.0, 8497.416582222564, 2842558242.397172, 1131.0]
[2019-03-26 19:54:06,822] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.6520017e-20 1.0000000e+00 3.2964016e-18 1.6768119e-17 3.7802474e-20], sum to 1.0000
[2019-03-26 19:54:06,836] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8839
[2019-03-26 19:54:06,838] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.28333333333333, 88.66666666666667, 1.0, 2.0, 0.3438367295255514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 535122.9142332589, 535122.9142332589, 169570.2271388917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 82200.0000, 
sim time next is 82800.0000, 
raw observation next is [22.2, 89.0, 1.0, 2.0, 0.3420326641599545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 532885.1997642361, 532885.1997642361, 169404.0686306888], 
processed observation next is [1.0, 1.0, 0.2511848341232228, 0.89, 1.0, 1.0, 0.2072682700722343, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1480236666011767, 0.1480236666011767, 0.25284189347864], 
reward next is 0.7472, 
noisyNet noise sample is [array([1.9817569], dtype=float32), -0.2886709]. 
=============================================
[2019-03-26 19:54:13,714] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.3186573e-19 1.0000000e+00 4.6899437e-17 4.2145881e-17 8.9752198e-19], sum to 1.0000
[2019-03-26 19:54:13,726] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3588
[2019-03-26 19:54:13,731] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 93.0, 1.0, 2.0, 0.2927604075809669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 469301.1687311629, 469301.1687311629, 164903.6486414795], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 205200.0000, 
sim time next is 205800.0000, 
raw observation next is [20.53333333333333, 93.0, 1.0, 2.0, 0.2935388023309903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 470281.9536565233, 470281.9536565239, 164969.8636236899], 
processed observation next is [0.0, 0.391304347826087, 0.17219589257503945, 0.93, 1.0, 1.0, 0.1488419305192654, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13063387601570092, 0.1306338760157011, 0.24622367705028342], 
reward next is 0.7538, 
noisyNet noise sample is [array([-0.26260087], dtype=float32), 1.0051402]. 
=============================================
[2019-03-26 19:54:17,249] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.8363591e-19 1.0000000e+00 8.9487681e-17 7.2051719e-17 1.0448718e-18], sum to 1.0000
[2019-03-26 19:54:17,259] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5839
[2019-03-26 19:54:17,266] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 92.66666666666667, 1.0, 2.0, 0.2846646876911634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 457752.9761656316, 457752.9761656316, 164118.6441627186], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 267600.0000, 
sim time next is 268200.0000, 
raw observation next is [20.3, 93.0, 1.0, 2.0, 0.2839837324739529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 456896.6056773736, 456896.6056773742, 164061.5322567067], 
processed observation next is [0.0, 0.08695652173913043, 0.16113744075829392, 0.93, 1.0, 1.0, 0.13732979816138904, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12691572379927044, 0.1269157237992706, 0.24486795859209956], 
reward next is 0.7551, 
noisyNet noise sample is [array([-0.9364947], dtype=float32), -0.36944553]. 
=============================================
[2019-03-26 19:54:17,843] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2708905e-18 1.0000000e+00 2.1637161e-16 5.1831248e-16 2.5866744e-18], sum to 1.0000
[2019-03-26 19:54:17,853] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3238
[2019-03-26 19:54:17,863] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.85, 94.5, 1.0, 2.0, 0.2754767701685673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 445380.6546891804, 445380.6546891811, 163291.4703041285], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 271800.0000, 
sim time next is 272400.0000, 
raw observation next is [19.76666666666667, 94.66666666666666, 1.0, 2.0, 0.2734517028126561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 442613.6084806612, 442613.6084806618, 163106.7859766746], 
processed observation next is [0.0, 0.13043478260869565, 0.13586097946287537, 0.9466666666666665, 1.0, 1.0, 0.12464060579838081, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12294822457796144, 0.12294822457796162, 0.24344296414429045], 
reward next is 0.7566, 
noisyNet noise sample is [array([-1.4464068], dtype=float32), -0.47595698]. 
=============================================
[2019-03-26 19:54:23,416] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8392147e-19 1.0000000e+00 1.4624750e-16 3.1613645e-17 1.3682340e-18], sum to 1.0000
[2019-03-26 19:54:23,426] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8930
[2019-03-26 19:54:23,432] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 86.5, 1.0, 2.0, 0.2609633783394137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 425208.3495388778, 425208.3495388784, 161948.2201520966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 367800.0000, 
sim time next is 368400.0000, 
raw observation next is [20.43333333333333, 86.0, 1.0, 2.0, 0.258034591050252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 420407.3492760002, 420407.3492760009, 161650.391173464], 
processed observation next is [1.0, 0.2608695652173913, 0.1674565560821484, 0.86, 1.0, 1.0, 0.1060657723497012, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1167798192433334, 0.1167798192433336, 0.24126924055740898], 
reward next is 0.7587, 
noisyNet noise sample is [array([0.3542886], dtype=float32), -1.5004483]. 
=============================================
[2019-03-26 19:54:32,168] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.9027997e-21 1.0000000e+00 4.5469998e-18 8.8559520e-18 2.7165128e-20], sum to 1.0000
[2019-03-26 19:54:32,182] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6819
[2019-03-26 19:54:32,187] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.15, 85.5, 1.0, 2.0, 0.2350162099216474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 389299.1388566919, 389299.1388566919, 159325.0359620243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 513000.0000, 
sim time next is 513600.0000, 
raw observation next is [19.06666666666666, 86.0, 1.0, 2.0, 0.2341557513240907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 387957.2324333502, 387957.2324333495, 159236.4573550978], 
processed observation next is [1.0, 0.9565217391304348, 0.10268562401263795, 0.86, 1.0, 1.0, 0.07729608593263938, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10776589789815283, 0.10776589789815263, 0.23766635426134], 
reward next is 0.7623, 
noisyNet noise sample is [array([-0.10613801], dtype=float32), -0.894553]. 
=============================================
[2019-03-26 19:54:41,440] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.2311213e-21 1.0000000e+00 6.2701604e-19 2.6938334e-18 1.0592218e-20], sum to 1.0000
[2019-03-26 19:54:41,449] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4248
[2019-03-26 19:54:41,455] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.96666666666667, 62.66666666666667, 1.0, 2.0, 0.2497542569032178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 411159.580403137, 411159.5804031377, 160874.469992949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 670800.0000, 
sim time next is 671400.0000, 
raw observation next is [22.75, 64.0, 1.0, 2.0, 0.2477770852107169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 407900.3416524674, 407900.341652468, 160680.6588433189], 
processed observation next is [1.0, 0.782608695652174, 0.27725118483412325, 0.64, 1.0, 1.0, 0.09370733157917698, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11330565045901872, 0.1133056504590189, 0.23982187887062523], 
reward next is 0.7602, 
noisyNet noise sample is [array([0.9537367], dtype=float32), -0.03282666]. 
=============================================
[2019-03-26 19:54:57,300] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 19:54:57,303] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:54:57,304] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:54:57,304] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:54:57,305] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:54:57,306] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:54:57,304] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:54:57,306] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:54:57,311] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:54:57,309] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:54:57,311] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:54:57,326] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run19
[2019-03-26 19:54:57,343] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run19
[2019-03-26 19:54:57,365] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run19
[2019-03-26 19:54:57,366] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run19
[2019-03-26 19:54:57,401] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run19
[2019-03-26 19:55:05,953] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06728558], dtype=float32), 0.06944348]
[2019-03-26 19:55:05,956] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.4, 75.0, 1.0, 2.0, 0.2877483491362977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 464776.1418924236, 464776.1418924242, 164595.6741045941]
[2019-03-26 19:55:05,958] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:55:05,961] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.2270095e-22 1.0000000e+00 1.7137480e-19 8.5675475e-19 2.2506326e-21], sampled 0.2910294475113331
[2019-03-26 19:55:11,977] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06728558], dtype=float32), 0.06944348]
[2019-03-26 19:55:11,979] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.26666666666667, 83.16666666666667, 1.0, 2.0, 0.3528521330088455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 545528.8790141412, 545528.8790141412, 170328.3782700332]
[2019-03-26 19:55:11,981] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:55:11,984] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.8910427e-22 1.0000000e+00 1.3107421e-19 7.0221663e-19 1.7090133e-21], sampled 0.5556514950228093
[2019-03-26 19:55:50,397] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06728558], dtype=float32), 0.06944348]
[2019-03-26 19:55:50,398] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.04237875, 76.55597132666668, 1.0, 2.0, 0.7812632521670521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1091896.040711273, 1091896.040711273, 239366.6320025753]
[2019-03-26 19:55:50,399] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:55:50,401] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.9881575e-22 1.0000000e+00 2.9306487e-19 1.0083915e-18 2.7745738e-21], sampled 0.06270183923524364
[2019-03-26 19:55:58,934] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06728558], dtype=float32), 0.06944348]
[2019-03-26 19:55:58,935] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.83333333333334, 84.83333333333333, 1.0, 2.0, 0.5806682511980742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 811436.7183846717, 811436.7183846717, 197199.6546098688]
[2019-03-26 19:55:58,937] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:55:58,940] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.0871790e-24 1.0000000e+00 2.1352014e-21 1.8219794e-20 2.9465832e-23], sampled 0.5383081958649533
[2019-03-26 19:56:06,544] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06728558], dtype=float32), 0.06944348]
[2019-03-26 19:56:06,546] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.23333333333333, 59.66666666666667, 1.0, 2.0, 0.5782666207506277, 0.0, 2.0, 0.0, 1.0, 2.0, 0.989869502266446, 6.911199999999999, 6.9112, 168.912930643303, 1616773.963280848, 1616773.963280849, 350790.2468031103]
[2019-03-26 19:56:06,548] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:56:06,551] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.7947431e-21 1.0000000e+00 1.1755161e-18 9.5688485e-18 3.8223573e-20], sampled 0.48506894035377324
[2019-03-26 19:56:14,417] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06728558], dtype=float32), 0.06944348]
[2019-03-26 19:56:14,418] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.57122835, 64.59482235666667, 1.0, 2.0, 0.9574800222568087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1338332.384873556, 1338332.384873556, 286239.5444864454]
[2019-03-26 19:56:14,419] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:56:14,427] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.5955129e-24 1.0000000e+00 1.1484764e-21 7.3059581e-21 1.3095600e-23], sampled 0.5203962656821803
[2019-03-26 19:56:24,323] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06728558], dtype=float32), 0.06944348]
[2019-03-26 19:56:24,325] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.36215347, 74.68111176, 1.0, 2.0, 0.5596482119719388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104262, 782052.1072080545, 782052.1072080551, 193470.4491103898]
[2019-03-26 19:56:24,328] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:56:24,331] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.2115920e-20 1.0000000e+00 3.4927217e-18 1.7367246e-17 7.3393422e-20], sampled 0.005393800214342326
[2019-03-26 19:56:52,417] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 19:56:52,429] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8724 2842497929.8887 1131.0000
[2019-03-26 19:56:52,487] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.2362 2779138868.9993 933.0000
[2019-03-26 19:56:52,488] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4187 3164052187.7637 1778.0000
[2019-03-26 19:56:52,558] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.0653 2927317329.7462 1338.0000
[2019-03-26 19:56:53,573] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 450000, evaluation results [450000.0, 7883.418744751638, 3164052187.7636957, 1778.0, 8255.065342017213, 2927317329.746172, 1338.0, 8659.23621041285, 2779138868.999297, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8496.87235025343, 2842497929.888741, 1131.0]
[2019-03-26 19:56:54,342] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6617067e-19 1.0000000e+00 1.0570438e-17 1.3222445e-16 8.8193687e-19], sum to 1.0000
[2019-03-26 19:56:54,354] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9244
[2019-03-26 19:56:54,361] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.05, 79.33333333333334, 1.0, 2.0, 0.4675282410209698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 653284.125842108, 653284.1258421086, 178665.6062579418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1273800.0000, 
sim time next is 1274400.0000, 
raw observation next is [26.9, 80.0, 1.0, 2.0, 0.4722703246041702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 659912.3674762726, 659912.3674762732, 179365.9376944303], 
processed observation next is [1.0, 0.782608695652174, 0.4739336492890995, 0.8, 1.0, 1.0, 0.3641811139809279, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18330899096563127, 0.18330899096563144, 0.2677103547678064], 
reward next is 0.7323, 
noisyNet noise sample is [array([-2.433145], dtype=float32), -0.0014274601]. 
=============================================
[2019-03-26 19:56:57,004] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2176504e-21 1.0000000e+00 3.9341077e-19 4.2906324e-19 5.7146371e-22], sum to 1.0000
[2019-03-26 19:56:57,010] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0549
[2019-03-26 19:56:57,037] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 95.0, 1.0, 2.0, 0.4102773023912795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 634948.3089447392, 634948.3089447386, 178232.2694986775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 997200.0000, 
sim time next is 997800.0000, 
raw observation next is [21.68333333333333, 95.16666666666667, 1.0, 2.0, 0.3863456947753357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 598072.0404958345, 598072.0404958345, 174882.9244018733], 
processed observation next is [1.0, 0.5652173913043478, 0.22669826224328585, 0.9516666666666667, 1.0, 1.0, 0.2606574635847418, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16613112235995403, 0.16613112235995403, 0.26101929015204967], 
reward next is 0.7390, 
noisyNet noise sample is [array([0.42582256], dtype=float32), 0.7846402]. 
=============================================
[2019-03-26 19:57:03,124] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.8731936e-20 1.0000000e+00 1.7205154e-18 3.5281681e-18 5.6083246e-20], sum to 1.0000
[2019-03-26 19:57:03,135] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7845
[2019-03-26 19:57:03,141] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 93.0, 1.0, 2.0, 0.5285086589159383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 753666.2896072889, 753666.2896072895, 190117.0290542869], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1306800.0000, 
sim time next is 1307400.0000, 
raw observation next is [24.33333333333333, 92.83333333333333, 1.0, 2.0, 0.5427297502722095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 773743.6861823428, 773743.6861823434, 192522.4575212592], 
processed observation next is [1.0, 0.13043478260869565, 0.35229067930489716, 0.9283333333333332, 1.0, 1.0, 0.44907198827977046, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21492880171731746, 0.21492880171731762, 0.2873469515242675], 
reward next is 0.7127, 
noisyNet noise sample is [array([0.9695765], dtype=float32), -1.0164219]. 
=============================================
[2019-03-26 19:57:05,258] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.9859644e-22 1.0000000e+00 1.8701103e-19 3.5896787e-19 1.1328771e-21], sum to 1.0000
[2019-03-26 19:57:05,274] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2353
[2019-03-26 19:57:05,278] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 91.0, 1.0, 2.0, 0.562827691920754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 875034.8951867357, 875034.8951867357, 204526.2362519844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1342800.0000, 
sim time next is 1343400.0000, 
raw observation next is [21.91666666666667, 90.50000000000001, 1.0, 2.0, 0.5491828657643029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 856840.7394381252, 856840.7394381252, 202185.1770847914], 
processed observation next is [1.0, 0.5652173913043478, 0.23775671406003188, 0.9050000000000001, 1.0, 1.0, 0.45684682622205164, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23801131651059032, 0.23801131651059032, 0.3017689210220767], 
reward next is 0.6982, 
noisyNet noise sample is [array([0.14566137], dtype=float32), -1.6694459]. 
=============================================
[2019-03-26 19:57:08,578] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.1173095e-22 1.0000000e+00 1.1727884e-18 6.8822258e-18 2.8377933e-21], sum to 1.0000
[2019-03-26 19:57:08,590] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0130
[2019-03-26 19:57:08,595] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 85.33333333333334, 1.0, 2.0, 0.3554413071659422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 547751.2515474142, 547751.2515474149, 170464.3484644801], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1204800.0000, 
sim time next is 1205400.0000, 
raw observation next is [23.0, 86.16666666666666, 1.0, 2.0, 0.3560965178943104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 548579.436239281, 548579.436239281, 170528.3612299317], 
processed observation next is [1.0, 0.9565217391304348, 0.28909952606635075, 0.8616666666666666, 1.0, 1.0, 0.22421267216181975, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1523831767331336, 0.1523831767331336, 0.2545199421342264], 
reward next is 0.7455, 
noisyNet noise sample is [array([0.21568042], dtype=float32), 0.31534064]. 
=============================================
[2019-03-26 19:57:10,984] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.5404303e-21 1.0000000e+00 2.4424460e-18 4.7332541e-19 3.5216815e-21], sum to 1.0000
[2019-03-26 19:57:10,992] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6046
[2019-03-26 19:57:11,002] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.23333333333334, 73.66666666666667, 1.0, 2.0, 0.586624993963457, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9821851794979696, 6.911200000000001, 6.9112, 168.9126160012299, 1654672.817811926, 1654672.817811925, 352071.2666277591], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1246800.0000, 
sim time next is 1247400.0000, 
raw observation next is [27.45, 73.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 8.427819295231911, 6.9112, 168.9043175481157, 2544361.943899262, 1468475.046325171, 312858.0191178528], 
processed observation next is [1.0, 0.43478260869565216, 0.5, 0.73, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.15166192952319113, 0.0, 0.8293975238924005, 0.706767206638684, 0.40790973509032524, 0.4669522673400788], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7507211], dtype=float32), 0.93416727]. 
=============================================
[2019-03-26 19:57:19,688] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.7580442e-20 1.0000000e+00 1.4626082e-17 7.4648921e-17 2.0361977e-19], sum to 1.0000
[2019-03-26 19:57:19,694] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6191
[2019-03-26 19:57:19,698] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.26666666666667, 98.0, 1.0, 2.0, 0.3050233257361261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 485352.8525933396, 485352.8525933389, 166001.3273036943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1392000.0000, 
sim time next is 1392600.0000, 
raw observation next is [20.28333333333333, 98.0, 1.0, 2.0, 0.3052578858737106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 485545.4604064184, 485545.460406419, 166012.4568929832], 
processed observation next is [0.0, 0.08695652173913043, 0.16034755134281198, 0.98, 1.0, 1.0, 0.16296130828157904, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1348737390017829, 0.13487373900178307, 0.2477797864074376], 
reward next is 0.7522, 
noisyNet noise sample is [array([-0.16091628], dtype=float32), 1.1882353]. 
=============================================
[2019-03-26 19:57:27,043] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.3056234e-20 1.0000000e+00 3.5999258e-17 1.3726476e-16 3.9584196e-19], sum to 1.0000
[2019-03-26 19:57:27,049] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8019
[2019-03-26 19:57:27,054] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.1, 51.0, 1.0, 2.0, 0.3480171406727051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 534257.5264887547, 534257.5264887554, 169288.3780549595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1512000.0000, 
sim time next is 1512600.0000, 
raw observation next is [29.16666666666667, 51.0, 1.0, 2.0, 0.3501266927854602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 536672.4447150303, 536672.4447150296, 169459.796027057], 
processed observation next is [0.0, 0.5217391304347826, 0.581358609794629, 0.51, 1.0, 1.0, 0.2170201117897111, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1490756790875084, 0.1490756790875082, 0.25292506869709996], 
reward next is 0.7471, 
noisyNet noise sample is [array([0.25235927], dtype=float32), -0.3023281]. 
=============================================
[2019-03-26 19:57:30,488] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.1236478e-20 1.0000000e+00 4.1197850e-17 9.3210556e-17 1.1666657e-19], sum to 1.0000
[2019-03-26 19:57:30,497] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3853
[2019-03-26 19:57:30,507] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 88.66666666666667, 1.0, 2.0, 0.312807323646386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 493251.869358558, 493251.869358558, 166492.7018573178], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1574400.0000, 
sim time next is 1575000.0000, 
raw observation next is [21.9, 88.5, 1.0, 2.0, 0.3139729591363515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 494165.2074130095, 494165.2074130089, 166538.1748206596], 
processed observation next is [1.0, 0.21739130434782608, 0.23696682464454974, 0.885, 1.0, 1.0, 0.17346139654982107, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13726811317028043, 0.13726811317028026, 0.24856444003083522], 
reward next is 0.7514, 
noisyNet noise sample is [array([0.19402282], dtype=float32), 0.03845071]. 
=============================================
[2019-03-26 19:57:30,523] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[73.14405 ]
 [73.099594]
 [73.01228 ]
 [72.97137 ]
 [72.97257 ]], R is [[73.17154694]
 [73.19133759]
 [73.20704651]
 [73.2274704 ]
 [73.24758148]].
[2019-03-26 19:57:33,116] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5275807e-20 1.0000000e+00 1.6410823e-18 1.9660449e-18 1.4308683e-20], sum to 1.0000
[2019-03-26 19:57:33,128] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0053
[2019-03-26 19:57:33,136] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.65, 86.5, 1.0, 2.0, 0.5082943590738291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 710266.2688861516, 710266.2688861516, 184905.9869181053], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1714200.0000, 
sim time next is 1714800.0000, 
raw observation next is [26.6, 87.0, 1.0, 2.0, 0.5097277816118588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712269.9366325306, 712269.9366325306, 185134.3652466727], 
processed observation next is [1.0, 0.8695652173913043, 0.4597156398104266, 0.87, 1.0, 1.0, 0.4093105802552516, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19785276017570297, 0.19785276017570297, 0.2763199481293622], 
reward next is 0.7237, 
noisyNet noise sample is [array([-0.37278548], dtype=float32), 1.3886857]. 
=============================================
[2019-03-26 19:57:42,372] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0455599e-21 1.0000000e+00 3.3838899e-20 2.7275728e-19 5.6523270e-22], sum to 1.0000
[2019-03-26 19:57:42,381] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4269
[2019-03-26 19:57:42,388] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 85.66666666666667, 1.0, 2.0, 0.6935849271315306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1064085.705241788, 1064085.705241787, 231391.2392456986], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1772400.0000, 
sim time next is 1773000.0000, 
raw observation next is [23.1, 85.5, 1.0, 2.0, 0.6861817415830092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1055454.805219974, 1055454.805219974, 229954.8168320121], 
processed observation next is [1.0, 0.5217391304347826, 0.2938388625592418, 0.855, 1.0, 1.0, 0.6219057127506135, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.29318189033888165, 0.29318189033888165, 0.3432161445253912], 
reward next is 0.6568, 
noisyNet noise sample is [array([-0.05810556], dtype=float32), 0.044565145]. 
=============================================
[2019-03-26 19:57:42,403] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[81.94388]
 [81.82996]
 [81.64748]
 [81.43601]
 [81.19887]], R is [[81.82976532]
 [81.66610718]
 [81.48033905]
 [81.28297424]
 [81.10296631]].
[2019-03-26 19:57:47,860] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5010831e-19 1.0000000e+00 4.3049331e-17 8.8019343e-17 2.6720325e-19], sum to 1.0000
[2019-03-26 19:57:47,868] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8487
[2019-03-26 19:57:47,876] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1700658.699447867 W.
[2019-03-26 19:57:47,881] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 85.0, 1.0, 2.0, 0.4055000630266437, 1.0, 2.0, 0.4055000630266437, 1.0, 1.0, 0.6923941493429925, 6.9112, 6.9112, 170.5573041426782, 1700658.699447867, 1700658.699447867, 354258.0431163031], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1868400.0000, 
sim time next is 1869000.0000, 
raw observation next is [27.0, 85.16666666666667, 1.0, 2.0, 0.7059492461448087, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.979031525207995, 6.9112, 168.9125530051116, 1883453.927850718, 1835332.024242843, 386895.8790384034], 
processed observation next is [1.0, 0.6521739130434783, 0.4786729857819906, 0.8516666666666667, 1.0, 1.0, 0.6457219833069984, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.006783152520799529, 0.0, 0.8294379637564588, 0.5231816466251994, 0.5098144511785675, 0.577456535878214], 
reward next is 0.0834, 
noisyNet noise sample is [array([1.7445846], dtype=float32), 0.1889078]. 
=============================================
[2019-03-26 19:57:47,891] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[72.54582 ]
 [75.11616 ]
 [76.135925]
 [77.422646]
 [77.39901 ]], R is [[70.71311951]
 [70.00598907]
 [69.30593109]
 [68.82355499]
 [68.13532257]].
[2019-03-26 19:57:48,481] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 19:57:48,483] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:57:48,484] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:57:48,485] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:57:48,486] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:57:48,486] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:57:48,487] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:57:48,488] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:57:48,488] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:57:48,493] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:57:48,495] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:57:48,512] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run20
[2019-03-26 19:57:48,530] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run20
[2019-03-26 19:57:48,548] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run20
[2019-03-26 19:57:48,570] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run20
[2019-03-26 19:57:48,571] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run20
[2019-03-26 19:57:53,677] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06363729], dtype=float32), 0.065985516]
[2019-03-26 19:57:53,679] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.03155166, 96.78515807, 1.0, 2.0, 0.2593864843163288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 424017.0022345468, 424017.0022345468, 161829.3948232712]
[2019-03-26 19:57:53,680] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:57:53,684] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.1101037e-19 1.0000000e+00 1.0342175e-16 2.2595162e-16 1.3434139e-18], sampled 0.4070760306897071
[2019-03-26 19:58:25,772] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06363729], dtype=float32), 0.065985516]
[2019-03-26 19:58:25,774] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.131631515, 85.727532315, 1.0, 2.0, 0.5649156647033784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 789415.5780497944, 789415.578049795, 194391.3958831663]
[2019-03-26 19:58:25,776] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:58:25,778] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.8028698e-23 1.0000000e+00 1.5237035e-20 8.3134560e-20 2.3505041e-22], sampled 0.5434441835293274
[2019-03-26 19:58:27,623] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06363729], dtype=float32), 0.065985516]
[2019-03-26 19:58:27,624] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.23333333333333, 92.0, 1.0, 2.0, 0.4449993894872299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 639556.9271264095, 639556.9271264095, 177708.6451254884]
[2019-03-26 19:58:27,625] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:58:27,626] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1436853e-20 1.0000000e+00 2.5812924e-18 1.2774043e-17 4.3716515e-20], sampled 0.5346700230602262
[2019-03-26 19:59:29,474] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06363729], dtype=float32), 0.065985516]
[2019-03-26 19:59:29,475] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.85, 90.33333333333333, 1.0, 2.0, 0.416518356706541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 613002.4067127772, 613002.4067127772, 175513.5447305596]
[2019-03-26 19:59:29,477] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:59:29,480] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.1547375e-20 1.0000000e+00 1.4498870e-17 4.1566137e-17 1.8435557e-19], sampled 0.477167194945074
[2019-03-26 19:59:32,878] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06363729], dtype=float32), 0.065985516]
[2019-03-26 19:59:32,879] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.5, 81.0, 1.0, 2.0, 0.5890346358179845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 823132.5915734464, 823132.5915734464, 198720.4108676804]
[2019-03-26 19:59:32,880] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:59:32,883] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.6134901e-21 1.0000000e+00 5.8864969e-19 2.7050268e-18 4.3121067e-21], sampled 0.9783667221032952
[2019-03-26 19:59:37,281] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06363729], dtype=float32), 0.065985516]
[2019-03-26 19:59:37,283] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.15, 72.0, 1.0, 2.0, 0.4487509930980948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 645985.8495900566, 645985.8495900566, 178384.6913701158]
[2019-03-26 19:59:37,285] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:59:37,289] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.3406768e-20 1.0000000e+00 9.2789399e-18 4.2872827e-17 1.7187565e-19], sampled 0.17396397068655178
[2019-03-26 19:59:43,252] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 19:59:43,560] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 19:59:43,579] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0954 2842522369.8966 1131.0000
[2019-03-26 19:59:43,589] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4188 3164134907.6624 1778.0000
[2019-03-26 19:59:43,618] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.3130 3007656030.3370 1766.0000
[2019-03-26 19:59:44,631] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 475000, evaluation results [475000.0, 7883.418813853433, 3164134907.662386, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7998.312951428424, 3007656030.3370423, 1766.0, 8496.095385747887, 2842522369.896584, 1131.0]
[2019-03-26 19:59:46,782] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.4007735e-22 1.0000000e+00 5.1528331e-20 4.4840572e-19 1.0087786e-21], sum to 1.0000
[2019-03-26 19:59:46,792] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0035
[2019-03-26 19:59:46,801] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1686719.542674613 W.
[2019-03-26 19:59:46,810] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.3, 79.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.20485821959964, 6.9112, 168.9109806922303, 1686719.542674613, 1478390.731658793, 315270.6679004913], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1939200.0000, 
sim time next is 1939800.0000, 
raw observation next is [26.35, 79.16666666666667, 1.0, 2.0, 0.5459845359732179, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9149025619274422, 6.9112, 6.9112, 168.9127173680542, 1541786.975338964, 1541786.975338964, 328455.847558539], 
processed observation next is [1.0, 0.43478260869565216, 0.4478672985781992, 0.7916666666666667, 1.0, 1.0, 0.45299341683520233, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.8962226364968808, 0.0, 0.0, 0.8294387708537527, 0.4282741598163789, 0.4282741598163789, 0.49023260829632687], 
reward next is 0.5098, 
noisyNet noise sample is [array([0.05842074], dtype=float32), 0.32724893]. 
=============================================
[2019-03-26 19:59:51,569] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3121340e-19 1.0000000e+00 3.8372942e-17 1.9223505e-16 4.3126044e-19], sum to 1.0000
[2019-03-26 19:59:51,581] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9049
[2019-03-26 19:59:51,588] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 96.0, 1.0, 2.0, 0.4763922924712487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 665673.8767111677, 665673.8767111677, 179979.8213440143], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2008800.0000, 
sim time next is 2009400.0000, 
raw observation next is [24.58333333333334, 95.83333333333333, 1.0, 2.0, 0.478267751760229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 668295.3233105448, 668295.3233105455, 180261.1107287601], 
processed observation next is [0.0, 0.2608695652173913, 0.3641390205371251, 0.9583333333333333, 1.0, 1.0, 0.37140692983160123, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1856375898084847, 0.18563758980848488, 0.26904643392352257], 
reward next is 0.7310, 
noisyNet noise sample is [array([-0.07590588], dtype=float32), -0.49073142]. 
=============================================
[2019-03-26 19:59:52,727] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.8627889e-22 1.0000000e+00 2.0525368e-18 9.7088637e-18 1.8648377e-20], sum to 1.0000
[2019-03-26 19:59:52,735] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1810
[2019-03-26 19:59:52,742] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.56666666666667, 94.0, 1.0, 2.0, 0.505891989172379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 706908.1948985324, 706908.194898533, 184524.5759677409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2020800.0000, 
sim time next is 2021400.0000, 
raw observation next is [25.55, 94.0, 1.0, 2.0, 0.5061863276668502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 707319.625740364, 707319.6257403634, 184571.1629275885], 
processed observation next is [0.0, 0.391304347826087, 0.40995260663507116, 0.94, 1.0, 1.0, 0.4050437682733135, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19647767381676776, 0.19647767381676762, 0.27547934765311716], 
reward next is 0.7245, 
noisyNet noise sample is [array([0.22798164], dtype=float32), -2.6903937]. 
=============================================
[2019-03-26 19:59:57,647] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8496691e-20 1.0000000e+00 1.8793151e-18 1.0020228e-17 3.9800545e-20], sum to 1.0000
[2019-03-26 19:59:57,660] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0555
[2019-03-26 19:59:57,664] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.15, 81.5, 1.0, 2.0, 0.5281077366108463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 737962.1537803897, 737962.1537803903, 188117.8881391904], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2107800.0000, 
sim time next is 2108400.0000, 
raw observation next is [28.36666666666667, 80.66666666666667, 1.0, 2.0, 0.5318864316745767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 743244.2379628149, 743244.2379628143, 188743.5019594662], 
processed observation next is [0.0, 0.391304347826087, 0.543443917851501, 0.8066666666666668, 1.0, 1.0, 0.4360077490055141, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20645673276744858, 0.20645673276744841, 0.28170671934248687], 
reward next is 0.7183, 
noisyNet noise sample is [array([-0.4162641], dtype=float32), -0.9934521]. 
=============================================
[2019-03-26 20:00:23,613] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.3628383e-16 1.0000000e+00 5.7325862e-14 3.1112428e-13 8.1551993e-15], sum to 1.0000
[2019-03-26 20:00:23,622] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8086
[2019-03-26 20:00:23,630] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2006885.467406774 W.
[2019-03-26 20:00:23,635] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 82.66666666666667, 1.0, 2.0, 0.7176713356475061, 1.0, 2.0, 0.7176713356475061, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2006885.467406774, 2006885.467406774, 381779.7596064435], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2542800.0000, 
sim time next is 2543400.0000, 
raw observation next is [28.1, 82.0, 1.0, 2.0, 0.722942014291491, 1.0, 2.0, 0.722942014291491, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2021638.221660466, 2021638.221660466, 384098.9403695185], 
processed observation next is [1.0, 0.43478260869565216, 0.5308056872037916, 0.82, 1.0, 1.0, 0.6661951979415554, 1.0, 1.0, 0.6661951979415554, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5615661726834628, 0.5615661726834628, 0.5732820005515201], 
reward next is 0.4267, 
noisyNet noise sample is [array([1.0883607], dtype=float32), -0.57750344]. 
=============================================
[2019-03-26 20:00:30,320] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.8852672e-20 1.0000000e+00 1.0640990e-18 7.2524326e-18 8.1517577e-20], sum to 1.0000
[2019-03-26 20:00:30,333] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2487
[2019-03-26 20:00:30,337] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 98.0, 1.0, 2.0, 0.4309244411845149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 623563.9284298284, 623563.9284298284, 176236.7602489321], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2683200.0000, 
sim time next is 2683800.0000, 
raw observation next is [23.5, 97.0, 1.0, 2.0, 0.4332689551429648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 625832.8628156359, 625832.8628156359, 176427.988253219], 
processed observation next is [0.0, 0.043478260869565216, 0.31279620853080575, 0.97, 1.0, 1.0, 0.3171915122204395, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1738424618932322, 0.1738424618932322, 0.2633253556018194], 
reward next is 0.7367, 
noisyNet noise sample is [array([-0.32159454], dtype=float32), 1.0110785]. 
=============================================
[2019-03-26 20:00:32,356] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2479567e-19 1.0000000e+00 3.9341287e-16 1.4997125e-15 1.5085817e-17], sum to 1.0000
[2019-03-26 20:00:32,368] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1379
[2019-03-26 20:00:32,374] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.4412583521901511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 633801.0473858996, 633801.047385899, 177121.2809928687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2688000.0000, 
sim time next is 2688600.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.4404975202183125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 632708.5283133048, 632708.5283133048, 177012.2143808495], 
processed observation next is [0.0, 0.08695652173913043, 0.3364928909952607, 0.94, 1.0, 1.0, 0.32590062676905124, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17575236897591798, 0.17575236897591798, 0.2641973348967903], 
reward next is 0.7358, 
noisyNet noise sample is [array([0.59778583], dtype=float32), -0.7877382]. 
=============================================
[2019-03-26 20:00:39,789] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 20:00:39,790] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:00:39,792] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:00:39,797] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:00:39,797] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run21
[2019-03-26 20:00:39,797] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:00:39,797] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:00:39,814] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:00:39,815] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:00:39,816] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:00:39,817] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:00:39,817] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:00:39,824] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run21
[2019-03-26 20:00:39,840] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run21
[2019-03-26 20:00:39,858] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run21
[2019-03-26 20:00:39,876] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run21
[2019-03-26 20:00:52,868] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06254766], dtype=float32), 0.064320944]
[2019-03-26 20:00:52,870] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.51877271, 87.41917794, 1.0, 2.0, 0.2807809287120449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 450464.1666915458, 450464.1666915452, 163620.3170610011]
[2019-03-26 20:00:52,871] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:00:52,874] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6375866e-18 1.0000000e+00 1.9685534e-16 6.4359279e-16 3.0393833e-18], sampled 0.5860714108827834
[2019-03-26 20:00:54,740] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06254766], dtype=float32), 0.064320944]
[2019-03-26 20:00:54,741] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.55135225, 70.75108699, 1.0, 2.0, 0.3336597313225179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 522330.6860132111, 522330.6860132111, 168625.8757702336]
[2019-03-26 20:00:54,742] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:00:54,744] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.6877902e-20 1.0000000e+00 6.3185457e-18 4.0273604e-17 1.3637415e-19], sampled 0.8130200499117076
[2019-03-26 20:00:56,456] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06254766], dtype=float32), 0.064320944]
[2019-03-26 20:00:56,458] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.77183080333333, 98.68818472666666, 1.0, 2.0, 0.3615678229497324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 553687.8066590249, 553687.8066590242, 170863.3193081645]
[2019-03-26 20:00:56,459] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:00:56,464] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.3710965e-19 1.0000000e+00 1.7198733e-17 9.9291035e-17 3.8082126e-19], sampled 0.8351573086645544
[2019-03-26 20:01:27,305] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06254766], dtype=float32), 0.064320944]
[2019-03-26 20:01:27,308] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [36.25, 51.16666666666666, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.354094903133099, 6.9112, 168.9108928272122, 1768171.173643763, 1453970.124873062, 311355.8235681532]
[2019-03-26 20:01:27,308] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:01:27,312] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.5622717e-20 1.0000000e+00 2.6035332e-18 2.7620232e-17 1.2042738e-19], sampled 0.3311429970653227
[2019-03-26 20:01:27,314] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1768171.173643763 W.
[2019-03-26 20:01:41,390] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06254766], dtype=float32), 0.064320944]
[2019-03-26 20:01:41,391] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.2, 60.0, 1.0, 2.0, 0.5626333366689277, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9771080401062405, 6.911199999999999, 6.9112, 168.9129564911561, 1573032.519558855, 1573032.519558856, 344212.1178963138]
[2019-03-26 20:01:41,392] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:01:41,398] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.3073079e-17 1.0000000e+00 3.1466755e-16 2.5184920e-15 4.1857159e-17], sampled 0.6540909801521106
[2019-03-26 20:01:48,281] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06254766], dtype=float32), 0.064320944]
[2019-03-26 20:01:48,284] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.74813474333333, 83.55211527666668, 1.0, 2.0, 0.7094008300679965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 991414.0046824624, 991414.0046824631, 222885.0414376433]
[2019-03-26 20:01:48,285] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:01:48,287] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.8736216e-21 1.0000000e+00 3.2068122e-19 1.8951028e-18 4.9900288e-21], sampled 0.68060934906171
[2019-03-26 20:01:54,146] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06254766], dtype=float32), 0.064320944]
[2019-03-26 20:01:54,147] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.82523647666667, 67.38149264, 1.0, 2.0, 0.8869445770480832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1239682.823461318, 1239682.823461319, 266374.9848668071]
[2019-03-26 20:01:54,149] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:01:54,153] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0455361e-21 1.0000000e+00 1.3800379e-19 1.1189373e-18 2.4070077e-21], sampled 0.7233422740896487
[2019-03-26 20:02:34,949] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164071917.9177 1778.0000
[2019-03-26 20:02:35,063] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8356 2842522561.2823 1131.0000
[2019-03-26 20:02:35,326] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 20:02:35,348] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.3273 2927391892.5307 1338.0000
[2019-03-26 20:02:35,481] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9767 2779207024.4606 933.0000
[2019-03-26 20:02:36,494] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 500000, evaluation results [500000.0, 7884.168443086554, 3164071917.9176674, 1778.0, 8254.327253941756, 2927391892.530706, 1338.0, 8659.976662972434, 2779207024.4606214, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8496.835586979434, 2842522561.2823186, 1131.0]
[2019-03-26 20:02:37,722] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.8531055e-22 1.0000000e+00 2.3580694e-19 4.5989662e-18 1.3442020e-20], sum to 1.0000
[2019-03-26 20:02:37,736] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6186
[2019-03-26 20:02:37,745] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.4094262076607182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 603250.7644546658, 603250.7644546658, 174616.0758322382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2833800.0000, 
sim time next is 2834400.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.4091672451503332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 602870.9496955557, 602870.9496955563, 174580.6887437804], 
processed observation next is [1.0, 0.8260869565217391, 0.3364928909952607, 0.89, 1.0, 1.0, 0.28815330741004, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1674641526932099, 0.16746415269321008, 0.2605681921548961], 
reward next is 0.7394, 
noisyNet noise sample is [array([1.830136], dtype=float32), -0.18794633]. 
=============================================
[2019-03-26 20:02:51,722] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1368880e-21 1.0000000e+00 8.2883135e-20 1.5041613e-19 1.9613441e-22], sum to 1.0000
[2019-03-26 20:02:51,729] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0900
[2019-03-26 20:02:51,738] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 98.0, 1.0, 2.0, 0.792185365789055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1146047.146729372, 1146047.146729373, 247390.1156672415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3079200.0000, 
sim time next is 3079800.0000, 
raw observation next is [23.5, 97.0, 1.0, 2.0, 0.8129721434911567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1174031.285721376, 1174031.285721376, 252419.0025796037], 
processed observation next is [1.0, 0.6521739130434783, 0.31279620853080575, 0.97, 1.0, 1.0, 0.7746652331218755, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3261198015892711, 0.3261198015892711, 0.37674477996955774], 
reward next is 0.6233, 
noisyNet noise sample is [array([0.85431737], dtype=float32), 0.85443]. 
=============================================
[2019-03-26 20:02:52,475] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.0548817e-21 1.0000000e+00 3.4534377e-19 2.3703723e-18 1.0176450e-21], sum to 1.0000
[2019-03-26 20:02:52,485] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4279
[2019-03-26 20:02:52,490] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 99.00000000000001, 1.0, 2.0, 0.4264394184050594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 621010.880074416, 621010.8800744154, 176098.6453409253], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3093000.0000, 
sim time next is 3093600.0000, 
raw observation next is [23.0, 98.0, 1.0, 2.0, 0.4229290631167505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 618778.816211871, 618778.816211871, 175963.6500937533], 
processed observation next is [1.0, 0.8260869565217391, 0.28909952606635075, 0.98, 1.0, 1.0, 0.3047338109840367, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1718830045032975, 0.1718830045032975, 0.2626323135727661], 
reward next is 0.7374, 
noisyNet noise sample is [array([0.86493576], dtype=float32), -0.8246787]. 
=============================================
[2019-03-26 20:02:57,757] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8497820e-20 1.0000000e+00 6.2975386e-18 5.5510114e-18 9.4637055e-21], sum to 1.0000
[2019-03-26 20:02:57,766] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7064
[2019-03-26 20:02:57,771] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333333, 92.33333333333334, 1.0, 2.0, 0.4914239763024455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 686684.7820207494, 686684.7820207487, 182263.2816266926], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3181200.0000, 
sim time next is 3181800.0000, 
raw observation next is [25.16666666666667, 93.16666666666667, 1.0, 2.0, 0.4920327516193084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 687535.7214298253, 687535.7214298247, 182357.0076422961], 
processed observation next is [1.0, 0.8260869565217391, 0.39178515007898923, 0.9316666666666668, 1.0, 1.0, 0.3879912670112149, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19098214484161813, 0.19098214484161796, 0.27217463827208377], 
reward next is 0.7278, 
noisyNet noise sample is [array([-2.4468236], dtype=float32), 1.0072206]. 
=============================================
[2019-03-26 20:02:59,184] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.7179640e-20 1.0000000e+00 1.0149217e-17 3.7695107e-17 1.5225661e-18], sum to 1.0000
[2019-03-26 20:02:59,197] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0090
[2019-03-26 20:02:59,200] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 90.33333333333333, 1.0, 2.0, 0.4682276596196061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 657270.9418419404, 657270.9418419404, 179156.5997873862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3207000.0000, 
sim time next is 3207600.0000, 
raw observation next is [25.0, 90.0, 1.0, 2.0, 0.4657045598329232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 655042.1432493017, 655042.1432493011, 178953.5943287883], 
processed observation next is [0.0, 0.13043478260869565, 0.38388625592417064, 0.9, 1.0, 1.0, 0.3562705540155702, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1819561509025838, 0.18195615090258366, 0.2670949169086393], 
reward next is 0.7329, 
noisyNet noise sample is [array([0.18290746], dtype=float32), 0.75012815]. 
=============================================
[2019-03-26 20:03:03,075] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.8118207e-22 1.0000000e+00 9.3672731e-20 1.7700590e-18 1.4049436e-21], sum to 1.0000
[2019-03-26 20:03:03,085] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5123
[2019-03-26 20:03:03,091] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5199735503351353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 726591.7946593971, 726591.7946593978, 186784.5782920096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3273600.0000, 
sim time next is 3274200.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5187093207022149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 724824.6042412353, 724824.604241236, 186579.3330116044], 
processed observation next is [0.0, 0.9130434782608695, 0.5260663507109005, 0.79, 1.0, 1.0, 0.4201317116894155, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2013401678447876, 0.20134016784478778, 0.2784766164352305], 
reward next is 0.7215, 
noisyNet noise sample is [array([-1.0132524], dtype=float32), 0.25514087]. 
=============================================
[2019-03-26 20:03:18,986] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8772372e-20 1.0000000e+00 1.3280210e-18 5.7073318e-17 2.2622025e-20], sum to 1.0000
[2019-03-26 20:03:18,996] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4709
[2019-03-26 20:03:19,001] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5192605690757257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 725595.1607614532, 725595.1607614526, 186668.7689581645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3536400.0000, 
sim time next is 3537000.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5183974007267487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 724388.5905567933, 724388.590556794, 186528.7661862407], 
processed observation next is [1.0, 0.9565217391304348, 0.5260663507109005, 0.79, 1.0, 1.0, 0.4197559044900586, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20121905293244258, 0.20121905293244277, 0.2784011435615533], 
reward next is 0.7216, 
noisyNet noise sample is [array([0.34664685], dtype=float32), 0.05251203]. 
=============================================
[2019-03-26 20:03:19,014] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[77.203835]
 [77.19744 ]
 [77.01343 ]
 [76.82687 ]
 [76.80594 ]], R is [[77.15372467]
 [77.10357666]
 [77.05362701]
 [77.00352478]
 [76.95243073]].
[2019-03-26 20:03:23,102] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.6812927e-15 1.0000000e+00 4.8406076e-14 4.1790475e-13 6.5778784e-16], sum to 1.0000
[2019-03-26 20:03:23,110] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9604
[2019-03-26 20:03:23,113] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.5612244348728901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 784255.5333745743, 784255.5333745749, 193746.0851466803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3607200.0000, 
sim time next is 3607800.0000, 
raw observation next is [31.83333333333334, 66.83333333333334, 1.0, 2.0, 0.5675168131537903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 793051.7910204724, 793051.791020473, 194851.0513613695], 
processed observation next is [1.0, 0.782608695652174, 0.7077409162717223, 0.6683333333333334, 1.0, 1.0, 0.47893591946239794, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22029216417235345, 0.22029216417235362, 0.2908224647184619], 
reward next is 0.7092, 
noisyNet noise sample is [array([-2.7305787], dtype=float32), -0.20390463]. 
=============================================
[2019-03-26 20:03:23,831] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0405317e-19 1.0000000e+00 7.9122168e-17 5.1220363e-16 1.9512502e-19], sum to 1.0000
[2019-03-26 20:03:23,842] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9873
[2019-03-26 20:03:23,846] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.5271852845638958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 736672.6995608315, 736672.6995608315, 187964.9008016786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3617400.0000, 
sim time next is 3618000.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.52709078992367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 736540.6098425238, 736540.6098425244, 187949.3416142548], 
processed observation next is [1.0, 0.9130434782608695, 0.5734597156398105, 0.74, 1.0, 1.0, 0.43022986737791563, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20459461384514552, 0.20459461384514566, 0.2805214053944102], 
reward next is 0.7195, 
noisyNet noise sample is [array([-0.5627615], dtype=float32), -0.57583654]. 
=============================================
[2019-03-26 20:03:23,858] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[74.12827 ]
 [73.823555]
 [73.555016]
 [72.9921  ]
 [72.316284]], R is [[74.71614075]
 [74.68843079]
 [74.66117096]
 [74.63465118]
 [74.60868835]].
[2019-03-26 20:03:27,934] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0927062e-15 1.0000000e+00 1.9128503e-14 2.9082227e-13 1.1861304e-15], sum to 1.0000
[2019-03-26 20:03:27,948] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0279
[2019-03-26 20:03:27,955] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2507403.010056572 W.
[2019-03-26 20:03:27,960] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 70.0, 1.0, 2.0, 0.896467018101429, 1.0, 2.0, 0.896467018101429, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2507403.010056572, 2507403.010056571, 469561.4511383821], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4012200.0000, 
sim time next is 4012800.0000, 
raw observation next is [30.33333333333333, 68.66666666666667, 1.0, 2.0, 0.6053428862770062, 1.0, 2.0, 0.6053428862770062, 1.0, 1.0, 1.03, 6.930485905498368, 6.9112, 170.5573041426782, 2539733.467777269, 2525918.18916831, 490117.6272911948], 
processed observation next is [1.0, 0.43478260869565216, 0.6366508688783569, 0.6866666666666668, 1.0, 1.0, 0.5245095015385616, 1.0, 1.0, 0.5245095015385616, 1.0, 0.5, 1.0365853658536586, 0.001928590549836784, 0.0, 0.8375144448122397, 0.7054815188270191, 0.7016439414356416, 0.7315188467032758], 
reward next is 0.1721, 
noisyNet noise sample is [array([1.5319337], dtype=float32), -1.0571455]. 
=============================================
[2019-03-26 20:03:31,665] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 20:03:31,667] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:03:31,668] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:03:31,668] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:03:31,669] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:03:31,670] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:03:31,670] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:03:31,671] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:03:31,670] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:03:31,674] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:03:31,675] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:03:31,693] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run22
[2019-03-26 20:03:31,711] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run22
[2019-03-26 20:03:31,739] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run22
[2019-03-26 20:03:31,740] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run22
[2019-03-26 20:03:31,783] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run22
[2019-03-26 20:03:42,804] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06099479], dtype=float32), 0.062472243]
[2019-03-26 20:03:42,805] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.33333333333334, 78.33333333333333, 1.0, 2.0, 0.2456158105228543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 405761.9823307951, 405761.9823307945, 160415.6371487835]
[2019-03-26 20:03:42,806] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:03:42,808] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.4144410e-19 1.0000000e+00 5.1309706e-17 3.1698313e-16 8.1312635e-19], sampled 0.7367246971662377
[2019-03-26 20:04:02,113] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06099479], dtype=float32), 0.062472243]
[2019-03-26 20:04:02,114] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.46666666666667, 95.0, 1.0, 2.0, 0.3814813294063354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 577232.7169003858, 577232.7169003865, 172706.7820029893]
[2019-03-26 20:04:02,115] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:04:02,117] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2968270e-18 1.0000000e+00 1.2578692e-16 6.4085136e-16 1.6927174e-18], sampled 0.04367319190105767
[2019-03-26 20:04:03,807] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06099479], dtype=float32), 0.062472243]
[2019-03-26 20:04:03,809] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.38855372333334, 82.12890383999999, 1.0, 2.0, 0.5123552407480795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 715942.6633078043, 715942.6633078043, 185554.622128656]
[2019-03-26 20:04:03,810] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:04:03,813] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.0555348e-21 1.0000000e+00 8.1445506e-19 1.1141038e-17 1.5732649e-20], sampled 0.35835022520037263
[2019-03-26 20:04:15,783] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06099479], dtype=float32), 0.062472243]
[2019-03-26 20:04:15,784] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.4, 72.33333333333334, 1.0, 2.0, 0.5028782659800126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 702695.5757724827, 702695.5757724821, 184047.7235745593]
[2019-03-26 20:04:15,786] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:04:15,790] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.1446626e-20 1.0000000e+00 9.3877803e-18 9.2252628e-17 2.0932660e-19], sampled 0.35433412000262654
[2019-03-26 20:04:27,766] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06099479], dtype=float32), 0.062472243]
[2019-03-26 20:04:27,772] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.25, 79.0, 1.0, 2.0, 0.5703259144975626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 796978.7207220218, 796978.7207220218, 195347.283774873]
[2019-03-26 20:04:27,773] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:04:27,775] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.5542432e-21 1.0000000e+00 6.2077341e-19 8.3122917e-18 1.1645042e-20], sampled 0.3175307588889664
[2019-03-26 20:04:35,683] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06099479], dtype=float32), 0.062472243]
[2019-03-26 20:04:35,684] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [36.43022303333333, 66.58049874833334, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.36027864882101, 6.9112, 171.5212843490159, 3233196.897959994, 2909685.402158093, 551462.2009372489]
[2019-03-26 20:04:35,685] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:04:35,688] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1724720e-16 1.0000000e+00 1.7038954e-15 2.6082357e-14 2.1644757e-16], sampled 0.7694277816143111
[2019-03-26 20:04:35,689] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 3233196.897959994 W.
[2019-03-26 20:04:45,793] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06099479], dtype=float32), 0.062472243]
[2019-03-26 20:04:45,794] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.80713717666666, 77.17547555, 1.0, 2.0, 0.5951266143471479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 831649.016472477, 831649.016472477, 199839.8131191835]
[2019-03-26 20:04:45,796] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:04:45,798] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.2531984e-20 1.0000000e+00 7.7124327e-18 6.2321323e-17 1.1913747e-19], sampled 0.11760678695673343
[2019-03-26 20:05:05,714] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06099479], dtype=float32), 0.062472243]
[2019-03-26 20:05:05,715] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.61666666666667, 86.83333333333333, 1.0, 2.0, 0.8100175178758163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1132104.518057822, 1132104.518057821, 246382.8546300093]
[2019-03-26 20:05:05,716] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:05:05,720] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.5114949e-19 1.0000000e+00 1.1441845e-17 6.7450742e-17 2.0284451e-19], sampled 0.09511631271803767
[2019-03-26 20:05:26,470] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 20:05:26,543] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06099479], dtype=float32), 0.062472243]
[2019-03-26 20:05:26,545] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.2, 82.66666666666667, 1.0, 2.0, 0.6842778206632252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 956287.858239193, 956287.8582391937, 217486.5422263585]
[2019-03-26 20:05:26,546] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:05:26,548] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.711886e-20 1.000000e+00 5.227459e-18 3.479943e-17 6.907626e-20], sampled 0.7539556661658942
[2019-03-26 20:05:26,607] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9878 2779131868.1217 933.0000
[2019-03-26 20:05:26,792] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5374 3007679688.9915 1766.0000
[2019-03-26 20:05:26,923] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4154 3164065956.6075 1778.0000
[2019-03-26 20:05:26,926] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0344 2842563115.2351 1131.0000
[2019-03-26 20:05:27,941] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 525000, evaluation results [525000.0, 7883.415429619458, 3164065956.607484, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8659.98775396918, 2779131868.121704, 933.0, 7997.53741177424, 3007679688.9914675, 1766.0, 8496.034363079138, 2842563115.235065, 1131.0]
[2019-03-26 20:05:35,868] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.1461553e-20 1.0000000e+00 2.7998403e-18 3.8049494e-17 4.3421509e-20], sum to 1.0000
[2019-03-26 20:05:35,879] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2933
[2019-03-26 20:05:35,882] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 86.5, 1.0, 2.0, 0.5815642600583141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 812689.2970028928, 812689.2970028921, 197361.2961121615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3889800.0000, 
sim time next is 3890400.0000, 
raw observation next is [28.33333333333333, 87.33333333333333, 1.0, 2.0, 0.5798409008873147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 810280.1225297259, 810280.1225297266, 197050.0828706015], 
processed observation next is [0.0, 0.0, 0.541864139020537, 0.8733333333333333, 1.0, 1.0, 0.49378421793652366, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22507781181381276, 0.22507781181381295, 0.29410460129940524], 
reward next is 0.7059, 
noisyNet noise sample is [array([-0.06163444], dtype=float32), 0.0038978378]. 
=============================================
[2019-03-26 20:05:43,176] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3600397e-12 1.0000000e+00 1.3393143e-12 8.6578342e-11 2.8643421e-13], sum to 1.0000
[2019-03-26 20:05:43,183] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4294
[2019-03-26 20:05:43,188] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2599585.59850934 W.
[2019-03-26 20:05:43,193] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.33333333333334, 64.0, 1.0, 2.0, 0.9293906333915453, 1.0, 2.0, 0.9293906333915453, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2599585.59850934, 2599585.598509341, 487780.2560557653], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4016400.0000, 
sim time next is 4017000.0000, 
raw observation next is [32.66666666666666, 63.5, 1.0, 2.0, 0.9458899858078658, 1.0, 2.0, 0.9458899858078658, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2645784.572398904, 2645784.572398904, 497147.5688820257], 
processed observation next is [1.0, 0.4782608695652174, 0.7472353870458132, 0.635, 1.0, 1.0, 0.9348072118167058, 1.0, 1.0, 0.9348072118167058, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7349401589996954, 0.7349401589996954, 0.7420112968388444], 
reward next is 0.2580, 
noisyNet noise sample is [array([-0.12314231], dtype=float32), 1.1648729]. 
=============================================
[2019-03-26 20:05:43,215] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[43.43711 ]
 [43.660748]
 [43.684334]
 [44.376896]
 [44.37462 ]], R is [[44.35858154]
 [44.18696594]
 [44.02859879]
 [43.58831406]
 [43.15243149]].
[2019-03-26 20:05:43,582] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.2906741e-12 1.0000000e+00 1.8479321e-11 1.9781234e-10 4.9124446e-12], sum to 1.0000
[2019-03-26 20:05:43,593] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3790
[2019-03-26 20:05:43,608] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 3030474.860359993 W.
[2019-03-26 20:05:43,612] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.0, 60.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.080119858922294, 6.9112, 170.5573041426782, 3030474.860359993, 2909470.694193412, 552768.1524028128], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4024800.0000, 
sim time next is 4025400.0000, 
raw observation next is [34.0, 60.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.580282098197825, 6.9112, 170.5573041426782, 3389178.765665298, 2909888.042206557, 549955.3752569812], 
processed observation next is [1.0, 0.6086956521739131, 0.8104265402843602, 0.6, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.2195121951219512, 0.06690820981978254, 0.0, 0.8375144448122397, 0.9414385460181383, 0.8083022339462659, 0.8208289182940018], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.15200341], dtype=float32), -0.5871043]. 
=============================================
[2019-03-26 20:05:46,153] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7451161e-17 1.0000000e+00 7.1585740e-16 3.0720279e-14 3.0752944e-17], sum to 1.0000
[2019-03-26 20:05:46,163] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6094
[2019-03-26 20:05:46,169] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 86.5, 1.0, 2.0, 0.981870285484318, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9129563853388, 1372446.286244371, 1372446.286244372, 293451.0719904648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4069800.0000, 
sim time next is 4070400.0000, 
raw observation next is [27.46666666666667, 86.66666666666667, 1.0, 2.0, 0.8849166075513234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565103997, 1236846.678605359, 1236846.67860536, 265822.6957625303], 
processed observation next is [1.0, 0.08695652173913043, 0.500789889415482, 0.8666666666666667, 1.0, 1.0, 0.8613453103027993, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.829439945152149, 0.34356852183482195, 0.3435685218348222, 0.39675029218288105], 
reward next is 0.6032, 
noisyNet noise sample is [array([0.07127967], dtype=float32), 0.24374896]. 
=============================================
[2019-03-26 20:06:02,836] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4113677e-14 1.0000000e+00 2.2641745e-13 2.5678160e-12 4.4837583e-15], sum to 1.0000
[2019-03-26 20:06:02,843] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1228
[2019-03-26 20:06:02,847] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 87.33333333333334, 1.0, 2.0, 0.9635828688030784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510413, 1346868.143392806, 1346868.143392806, 288032.0336900885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4342800.0000, 
sim time next is 4343400.0000, 
raw observation next is [29.5, 86.5, 1.0, 2.0, 0.9740883625639153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1361561.833994603, 1361561.833994603, 291136.0962298395], 
processed observation next is [1.0, 0.2608695652173913, 0.5971563981042655, 0.865, 1.0, 1.0, 0.9687811597155606, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3782116205540564, 0.3782116205540564, 0.4345314869102082], 
reward next is 0.5655, 
noisyNet noise sample is [array([1.5623565], dtype=float32), -0.46983367]. 
=============================================
[2019-03-26 20:06:03,918] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1008323e-09 9.9999988e-01 1.4666199e-09 7.2729570e-08 3.6654624e-10], sum to 1.0000
[2019-03-26 20:06:03,930] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0743
[2019-03-26 20:06:03,939] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3386455.323147359 W.
[2019-03-26 20:06:03,945] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.83333333333334, 55.0, 1.0, 2.0, 0.9725898533281696, 1.0, 2.0, 0.8068849661783476, 1.0, 2.0, 1.03, 7.005119235463171, 6.9112, 170.5573041426782, 3386455.323147359, 3319177.154394852, 621268.2722152502], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4362600.0000, 
sim time next is 4363200.0000, 
raw observation next is [37.0, 54.0, 1.0, 2.0, 0.9717108592642465, 1.0, 2.0, 0.806445469146386, 1.0, 2.0, 1.03, 7.00511916609186, 6.9112, 170.5573041426782, 3384608.27640494, 3317330.157345924, 620901.3489319627], 
processed observation next is [1.0, 0.5217391304347826, 0.95260663507109, 0.54, 1.0, 1.0, 0.9659166979087307, 1.0, 1.0, 0.7668017700558868, 1.0, 1.0, 1.0365853658536586, 0.00939191660918599, 0.0, 0.8375144448122397, 0.9401689656680389, 0.9214805992627567, 0.9267184312417355], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.16079777], dtype=float32), -0.29032555]. 
=============================================
[2019-03-26 20:06:06,357] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3167617e-18 1.0000000e+00 3.9368760e-16 8.7215896e-16 9.5124373e-18], sum to 1.0000
[2019-03-26 20:06:06,363] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7551
[2019-03-26 20:06:06,369] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.5053018078412719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 706083.230902521, 706083.2309025218, 184430.5922021657], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4512600.0000, 
sim time next is 4513200.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5056966229924541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 706635.1091571717, 706635.1091571723, 184493.0712654031], 
processed observation next is [0.0, 0.21739130434782608, 0.4312796208530806, 0.89, 1.0, 1.0, 0.40445376264151095, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1962875303214366, 0.19628753032143675, 0.27536279293343746], 
reward next is 0.7246, 
noisyNet noise sample is [array([0.39275354], dtype=float32), -0.6449489]. 
=============================================
[2019-03-26 20:06:15,772] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3545806e-20 1.0000000e+00 1.9752170e-17 1.1991917e-16 2.0109406e-19], sum to 1.0000
[2019-03-26 20:06:15,778] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9834
[2019-03-26 20:06:15,782] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 80.66666666666667, 1.0, 2.0, 0.5285315391338506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 738554.5687871398, 738554.5687871391, 188187.0811544497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4569600.0000, 
sim time next is 4570200.0000, 
raw observation next is [28.0, 81.5, 1.0, 2.0, 0.5315886663888735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742828.0030241485, 742828.0030241485, 188693.4436522572], 
processed observation next is [0.0, 0.9130434782608695, 0.5260663507109005, 0.815, 1.0, 1.0, 0.43564899564924514, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20634111195115237, 0.20634111195115237, 0.28163200545113015], 
reward next is 0.7184, 
noisyNet noise sample is [array([-1.6084656], dtype=float32), 0.42853507]. 
=============================================
[2019-03-26 20:06:22,162] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1934358e-18 1.0000000e+00 2.7281791e-17 7.6449822e-16 2.2287037e-19], sum to 1.0000
[2019-03-26 20:06:22,170] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8769
[2019-03-26 20:06:22,176] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 90.66666666666667, 1.0, 2.0, 0.5004445329501753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 699293.6861796705, 699293.6861796705, 183665.4725159302], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4666800.0000, 
sim time next is 4667400.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5023556926498313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 701965.1180817671, 701965.1180817671, 183965.8295202671], 
processed observation next is [1.0, 0.0, 0.4312796208530806, 0.89, 1.0, 1.0, 0.40042854536124245, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19499031057826866, 0.19499031057826866, 0.2745758649556226], 
reward next is 0.7254, 
noisyNet noise sample is [array([0.6251195], dtype=float32), -1.2226177]. 
=============================================
[2019-03-26 20:06:23,172] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3857473e-19 1.0000000e+00 2.2913006e-17 2.1405322e-16 2.5814487e-19], sum to 1.0000
[2019-03-26 20:06:23,181] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4443
[2019-03-26 20:06:23,185] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.7433204213897285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1038841.079339711, 1038841.079339712, 230473.8937004936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4683600.0000, 
sim time next is 4684200.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.6741954722451413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 942191.3845995613, 942191.3845995606, 215374.1392244629], 
processed observation next is [1.0, 0.21739130434782608, 0.4786729857819906, 0.89, 1.0, 1.0, 0.6074644243917365, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.26171982905543373, 0.2617198290554335, 0.3214539391409894], 
reward next is 0.6785, 
noisyNet noise sample is [array([-1.2420728], dtype=float32), 0.6315327]. 
=============================================
[2019-03-26 20:06:23,296] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 20:06:23,299] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:06:23,301] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:06:23,301] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:06:23,302] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:06:23,303] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:06:23,304] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:06:23,302] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:06:23,305] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:06:23,305] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:06:23,306] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:06:23,331] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run23
[2019-03-26 20:06:23,332] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run23
[2019-03-26 20:06:23,373] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run23
[2019-03-26 20:06:23,390] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run23
[2019-03-26 20:06:23,391] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run23
[2019-03-26 20:07:53,545] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06017824], dtype=float32), 0.060150836]
[2019-03-26 20:07:53,546] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.40313472666666, 97.42619406333333, 1.0, 2.0, 0.6327322838225168, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.981144323082724, 6.9112, 168.9124455795614, 1769181.284924045, 1719560.524925544, 371083.9771619783]
[2019-03-26 20:07:53,548] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:07:53,557] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.4143220e-14 1.0000000e+00 5.0502381e-13 9.9598368e-12 4.1301767e-14], sampled 0.24348016535252903
[2019-03-26 20:07:53,558] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1769181.284924045 W.
[2019-03-26 20:08:00,367] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06017824], dtype=float32), 0.060150836]
[2019-03-26 20:08:00,369] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.5, 87.0, 1.0, 2.0, 0.5072361923811978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 708787.1439663708, 708787.1439663714, 184737.6452244647]
[2019-03-26 20:08:00,370] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:08:00,373] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1397921e-19 1.0000000e+00 9.6427943e-18 2.6922543e-16 9.1502105e-20], sampled 0.3204028115794755
[2019-03-26 20:08:18,214] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.4067 2927264152.9822 1338.0000
[2019-03-26 20:08:18,427] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 20:08:18,522] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.6275 2779190785.3580 933.0000
[2019-03-26 20:08:18,529] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6674 3164196406.5138 1778.0000
[2019-03-26 20:08:18,576] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.1321 2842451957.6633 1131.0000
[2019-03-26 20:08:19,592] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 550000, evaluation results [550000.0, 7882.667391253915, 3164196406.5138016, 1778.0, 8254.406660643592, 2927264152.9821725, 1338.0, 8660.627510841134, 2779190785.357956, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8496.132105234119, 2842451957.6632614, 1131.0]
[2019-03-26 20:08:19,826] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0021910e-17 1.0000000e+00 3.0029684e-16 3.2795744e-15 9.1353930e-19], sum to 1.0000
[2019-03-26 20:08:19,833] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3978
[2019-03-26 20:08:19,839] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.7674757770387476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1072616.888923591, 1072616.888923591, 236084.0565103992], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4682400.0000, 
sim time next is 4683000.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.7580254610233658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1059402.628320965, 1059402.628320965, 233868.611976253], 
processed observation next is [1.0, 0.17391304347826086, 0.4786729857819906, 0.89, 1.0, 1.0, 0.708464410871525, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2942785078669347, 0.2942785078669347, 0.349057629815303], 
reward next is 0.6509, 
noisyNet noise sample is [array([-0.41288865], dtype=float32), 0.30005804]. 
=============================================
[2019-03-26 20:08:19,849] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[68.531395]
 [68.25198 ]
 [68.066864]
 [67.74963 ]
 [67.478874]], R is [[68.64374542]
 [68.60494232]
 [68.56214905]
 [68.51739502]
 [68.45489502]].
[2019-03-26 20:08:28,459] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2742116e-17 1.0000000e+00 4.2535152e-16 3.7086768e-14 5.9102832e-18], sum to 1.0000
[2019-03-26 20:08:28,470] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2897
[2019-03-26 20:08:28,474] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.83333333333334, 1.0, 2.0, 0.6573587196675788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 918651.7662806674, 918651.7662806674, 211907.3129420844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4849800.0000, 
sim time next is 4850400.0000, 
raw observation next is [27.0, 80.66666666666667, 1.0, 2.0, 0.6177226191331104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 863238.2300704888, 863238.2300704888, 204085.358952211], 
processed observation next is [1.0, 0.13043478260869565, 0.4786729857819906, 0.8066666666666668, 1.0, 1.0, 0.5394248423290487, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23978839724180243, 0.23978839724180243, 0.30460501336150897], 
reward next is 0.6954, 
noisyNet noise sample is [array([-0.51146525], dtype=float32), -0.6888645]. 
=============================================
[2019-03-26 20:08:33,851] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.9249410e-18 1.0000000e+00 3.7971359e-16 2.5181076e-15 1.2344471e-18], sum to 1.0000
[2019-03-26 20:08:33,862] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4601
[2019-03-26 20:08:33,870] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.7044352568551113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 984471.2151669071, 984471.2151669076, 221803.1410403291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4938000.0000, 
sim time next is 4938600.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.6908605370632511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 965491.4784959515, 965491.4784959509, 218882.5216439698], 
processed observation next is [1.0, 0.13043478260869565, 0.4312796208530806, 0.89, 1.0, 1.0, 0.6275428157388567, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2681920773599865, 0.26819207735998635, 0.32669033081189525], 
reward next is 0.6733, 
noisyNet noise sample is [array([-0.356874], dtype=float32), -0.010334531]. 
=============================================
[2019-03-26 20:08:46,351] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.0425240e-20 1.0000000e+00 3.4113574e-18 3.5926294e-16 1.4770163e-19], sum to 1.0000
[2019-03-26 20:08:46,361] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3208
[2019-03-26 20:08:46,369] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 63.66666666666666, 1.0, 2.0, 0.557372386554527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 778870.7040187203, 778870.7040187209, 193073.4920540554], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5143800.0000, 
sim time next is 5144400.0000, 
raw observation next is [32.0, 63.0, 1.0, 2.0, 0.553675118974134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 773702.2703814851, 773702.2703814845, 192433.2994364631], 
processed observation next is [0.0, 0.5652173913043478, 0.7156398104265403, 0.63, 1.0, 1.0, 0.4622591794869084, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21491729732819032, 0.21491729732819015, 0.28721387975591506], 
reward next is 0.7128, 
noisyNet noise sample is [array([0.9717966], dtype=float32), -0.34114853]. 
=============================================
[2019-03-26 20:08:50,591] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.5990483e-14 1.0000000e+00 1.2434899e-12 8.5172196e-11 2.4207470e-13], sum to 1.0000
[2019-03-26 20:08:50,597] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0312
[2019-03-26 20:08:50,606] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2493798.584060474 W.
[2019-03-26 20:08:50,611] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 68.0, 1.0, 2.0, 0.5944052683676839, 1.0, 1.0, 0.5944052683676839, 1.0, 2.0, 1.03, 6.913769087138583, 6.9112, 170.5573041426782, 2493798.584060474, 2491958.242439325, 485957.7661089038], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5221800.0000, 
sim time next is 5222400.0000, 
raw observation next is [31.0, 68.66666666666667, 1.0, 2.0, 0.861550631605336, 1.0, 2.0, 0.861550631605336, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2409648.306250701, 2409648.306250702, 450948.3550177966], 
processed observation next is [1.0, 0.43478260869565216, 0.6682464454976303, 0.6866666666666668, 1.0, 1.0, 0.8331935320546217, 1.0, 1.0, 0.8331935320546217, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6693467517363059, 0.6693467517363062, 0.6730572462952188], 
reward next is 0.3269, 
noisyNet noise sample is [array([0.584231], dtype=float32), -0.9675605]. 
=============================================
[2019-03-26 20:08:51,710] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1514297e-19 1.0000000e+00 2.4909623e-17 2.0177221e-15 2.3480788e-19], sum to 1.0000
[2019-03-26 20:08:51,722] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4193
[2019-03-26 20:08:51,728] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.36666666666667, 87.33333333333333, 1.0, 2.0, 0.8011567345204668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1119713.894792561, 1119713.894792561, 244195.3564651177], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5553600.0000, 
sim time next is 5554200.0000, 
raw observation next is [27.53333333333333, 86.66666666666667, 1.0, 2.0, 0.808371934136521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1129803.377829184, 1129803.377829185, 245976.7765173571], 
processed observation next is [1.0, 0.2608695652173913, 0.5039494470774091, 0.8666666666666667, 1.0, 1.0, 0.7691228122126759, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3138342716192178, 0.31383427161921806, 0.36712951719008524], 
reward next is 0.6329, 
noisyNet noise sample is [array([-1.1662263], dtype=float32), -0.91041255]. 
=============================================
[2019-03-26 20:08:53,051] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.7469243e-19 1.0000000e+00 1.1302123e-16 3.6484674e-16 2.5032383e-19], sum to 1.0000
[2019-03-26 20:08:53,059] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8229
[2019-03-26 20:08:53,067] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.7, 79.5, 1.0, 2.0, 0.5479810284523111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 765742.5145672448, 765742.5145672441, 191454.9592761847], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5257800.0000, 
sim time next is 5258400.0000, 
raw observation next is [28.66666666666667, 79.66666666666666, 1.0, 2.0, 0.5469552025755323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 764308.521315797, 764308.5213157964, 191279.8565869479], 
processed observation next is [1.0, 0.8695652173913043, 0.5576619273301741, 0.7966666666666665, 1.0, 1.0, 0.45416289466931603, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21230792258772138, 0.21230792258772122, 0.28549232326410134], 
reward next is 0.7145, 
noisyNet noise sample is [array([1.2964685], dtype=float32), 0.07980985]. 
=============================================
[2019-03-26 20:08:57,351] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.1280511e-11 1.0000000e+00 2.6966615e-10 1.5628604e-08 2.9703802e-11], sum to 1.0000
[2019-03-26 20:08:57,358] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0264
[2019-03-26 20:08:57,365] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3193637.673315919 W.
[2019-03-26 20:08:57,374] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.03333333333333, 53.0, 1.0, 2.0, 0.8808225327557211, 1.0, 2.0, 0.7610013058921233, 1.0, 2.0, 1.03, 7.005111994178296, 6.9112, 170.5573041426782, 3193637.673315919, 3126364.691790323, 584527.6566708083], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5326800.0000, 
sim time next is 5327400.0000, 
raw observation next is [36.01666666666667, 53.0, 1.0, 2.0, 0.8723186418154435, 1.0, 2.0, 0.7567493604219845, 1.0, 2.0, 1.03, 7.005111323256286, 6.9112, 170.5573041426782, 3175771.161114664, 3108498.660197797, 581282.3676185374], 
processed observation next is [1.0, 0.6521739130434783, 0.9060031595576622, 0.53, 1.0, 1.0, 0.8461670383318596, 1.0, 1.0, 0.7069269402674512, 1.0, 1.0, 1.0365853658536586, 0.009391132325628604, 0.0, 0.8375144448122397, 0.8821586558651844, 0.8634718500549436, 0.8675856233112499], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.00488964], dtype=float32), 1.5195434]. 
=============================================
[2019-03-26 20:08:58,356] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.0898574e-20 1.0000000e+00 2.1755421e-17 9.9807544e-16 5.5498197e-20], sum to 1.0000
[2019-03-26 20:08:58,366] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4667
[2019-03-26 20:08:58,371] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.8, 79.66666666666667, 1.0, 2.0, 0.6217062605328083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 868807.4579748324, 868807.457974833, 204859.7899359629], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5347200.0000, 
sim time next is 5347800.0000, 
raw observation next is [30.7, 80.0, 1.0, 2.0, 0.6197149989281698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 866023.6220010631, 866023.6220010631, 204476.6192047563], 
processed observation next is [1.0, 0.9130434782608695, 0.6540284360189573, 0.8, 1.0, 1.0, 0.5418252999134576, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24056211722251752, 0.24056211722251752, 0.305188983887696], 
reward next is 0.6948, 
noisyNet noise sample is [array([-0.32081187], dtype=float32), -0.53710663]. 
=============================================
[2019-03-26 20:08:58,821] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.1467216e-19 1.0000000e+00 5.2911197e-17 5.3357956e-16 1.3905115e-19], sum to 1.0000
[2019-03-26 20:08:58,828] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4048
[2019-03-26 20:08:58,836] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.06666666666666, 83.0, 1.0, 2.0, 0.6145502430742251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 858803.1918004336, 858803.191800433, 203488.1768498952], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5352000.0000, 
sim time next is 5352600.0000, 
raw observation next is [29.98333333333333, 83.5, 1.0, 2.0, 0.6136009548963426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 857476.0736089996, 857476.0736089996, 203307.4196781815], 
processed observation next is [1.0, 0.9565217391304348, 0.6200631911532385, 0.835, 1.0, 1.0, 0.5344589818028224, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2381877982247221, 0.2381877982247221, 0.3034439099674351], 
reward next is 0.6966, 
noisyNet noise sample is [array([-0.74446], dtype=float32), 1.5628046]. 
=============================================
[2019-03-26 20:08:59,672] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0726499e-16 1.0000000e+00 1.0350514e-14 6.1118493e-13 1.6431073e-16], sum to 1.0000
[2019-03-26 20:08:59,681] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0587
[2019-03-26 20:08:59,688] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.1, 88.0, 1.0, 2.0, 0.392875012384643, 1.0, 2.0, 0.392875012384643, 1.0, 1.0, 0.6822939707601474, 6.911199999999999, 6.9112, 170.5573041426782, 1647668.798498359, 1647668.79849836, 348980.6828116485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5366400.0000, 
sim time next is 5367000.0000, 
raw observation next is [29.05, 88.5, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.573792740115747, 6.9112, 168.9092278978081, 1924132.619249037, 1454076.901045732, 311355.8990120316], 
processed observation next is [1.0, 0.08695652173913043, 0.575829383886256, 0.885, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.06625927401157475, 0.0, 0.8294216359573581, 0.5344812831247325, 0.4039102502904811, 0.464710297032883], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.027443], dtype=float32), -0.89892185]. 
=============================================
[2019-03-26 20:08:59,703] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[61.75839 ]
 [64.635376]
 [66.20158 ]
 [69.82811 ]
 [70.012535]], R is [[61.31115723]
 [60.69804764]
 [60.09106827]
 [59.49015808]
 [58.89525604]].
[2019-03-26 20:09:01,452] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9416421e-19 1.0000000e+00 5.0464916e-17 8.0926264e-16 9.1425346e-20], sum to 1.0000
[2019-03-26 20:09:01,458] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6134
[2019-03-26 20:09:01,466] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333333, 82.00000000000001, 1.0, 2.0, 0.6182834709956576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 864022.3128965896, 864022.3128965896, 204201.8626631692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5433000.0000, 
sim time next is 5433600.0000, 
raw observation next is [30.26666666666667, 82.0, 1.0, 2.0, 0.6158046336834332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 860556.8500148747, 860556.8500148754, 203727.530860143], 
processed observation next is [1.0, 0.9130434782608695, 0.6334913112164299, 0.82, 1.0, 1.0, 0.537114016486064, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2390435694485763, 0.2390435694485765, 0.30407094158230297], 
reward next is 0.6959, 
noisyNet noise sample is [array([0.0511503], dtype=float32), -0.7280457]. 
=============================================
[2019-03-26 20:09:02,455] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.8445133e-09 9.9999976e-01 2.7369560e-09 2.5438499e-07 5.6712807e-10], sum to 1.0000
[2019-03-26 20:09:02,465] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3352
[2019-03-26 20:09:02,472] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3335595.504709763 W.
[2019-03-26 20:09:02,481] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.93333333333333, 56.0, 1.0, 2.0, 0.9483856169712718, 1.0, 2.0, 0.7947828479998986, 1.0, 2.0, 1.03, 7.005117325309504, 6.9112, 170.5573041426782, 3335595.504709763, 3268318.704278028, 611272.6995241009], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5406000.0000, 
sim time next is 5406600.0000, 
raw observation next is [36.91666666666666, 55.0, 1.0, 2.0, 0.9157275387585274, 1.0, 2.0, 0.7784538088935263, 1.0, 2.0, 1.03, 7.005114748240672, 6.9112, 170.5573041426782, 3266975.101225567, 3199700.146853064, 598132.4161562971], 
processed observation next is [1.0, 0.5652173913043478, 0.9486571879936805, 0.55, 1.0, 1.0, 0.8984669141669005, 1.0, 1.0, 0.7330768781849715, 1.0, 1.0, 1.0365853658536586, 0.009391474824067192, 0.0, 0.8375144448122397, 0.9074930836737686, 0.8888055963480734, 0.8927349494870106], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9353967], dtype=float32), 0.27896032]. 
=============================================
[2019-03-26 20:09:14,972] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 20:09:14,974] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:09:14,975] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:09:14,976] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:09:14,977] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:09:14,978] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:09:14,977] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:09:14,980] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:09:14,980] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:09:14,983] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:09:14,985] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:09:15,000] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run24
[2019-03-26 20:09:15,021] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run24
[2019-03-26 20:09:15,022] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run24
[2019-03-26 20:09:15,022] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run24
[2019-03-26 20:09:15,023] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run24
[2019-03-26 20:09:45,269] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06244335], dtype=float32), 0.060314335]
[2019-03-26 20:09:45,270] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.31666666666666, 89.33333333333333, 1.0, 2.0, 0.5098641702574394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712460.5837063199, 712460.5837063199, 185156.2316180599]
[2019-03-26 20:09:45,271] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:09:45,276] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.9086838e-19 1.0000000e+00 4.9358559e-17 2.2395403e-15 2.1614936e-19], sampled 0.12929960845281363
[2019-03-26 20:10:14,685] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06244335], dtype=float32), 0.060314335]
[2019-03-26 20:10:14,688] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.6, 60.0, 1.0, 2.0, 0.9569951609427456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1337654.235570436, 1337654.235570435, 286095.7807622626]
[2019-03-26 20:10:14,689] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:10:14,693] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.6024260e-19 1.0000000e+00 4.1397925e-17 1.9570014e-15 1.3171529e-19], sampled 0.7420776972526409
[2019-03-26 20:10:16,555] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06244335], dtype=float32), 0.060314335]
[2019-03-26 20:10:16,557] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.0, 89.0, 1.0, 2.0, 0.7854270605475355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1097718.400631324, 1097718.400631323, 240367.9100953076]
[2019-03-26 20:10:16,561] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:10:16,563] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.7332159e-18 1.0000000e+00 8.0866977e-17 3.4690118e-15 4.4550381e-19], sampled 0.08669866215989241
[2019-03-26 20:10:19,330] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06244335], dtype=float32), 0.060314335]
[2019-03-26 20:10:19,334] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.2, 59.66666666666667, 1.0, 2.0, 0.5434930867981185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 759468.8734655033, 759468.8734655033, 190690.908137785]
[2019-03-26 20:10:19,335] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:10:19,337] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.8895132e-19 1.0000000e+00 5.0657600e-17 3.1150397e-15 3.7146779e-19], sampled 0.012704523681996371
[2019-03-26 20:10:21,570] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06244335], dtype=float32), 0.060314335]
[2019-03-26 20:10:21,570] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.58333333333334, 54.5, 1.0, 2.0, 0.6208461471579345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 867604.9960122979, 867604.9960122986, 204691.1645420538]
[2019-03-26 20:10:21,570] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:10:21,574] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.5810832e-20 1.0000000e+00 2.0616238e-18 2.1716710e-16 1.2725435e-20], sampled 0.45028777354052496
[2019-03-26 20:10:32,112] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06244335], dtype=float32), 0.060314335]
[2019-03-26 20:10:32,112] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.2, 61.0, 1.0, 2.0, 0.892653030782841, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005987315677585, 6.9112, 168.9123159668307, 2144752.831495714, 2077507.702431118, 432031.2669668394]
[2019-03-26 20:10:32,113] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:10:32,120] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.8163698e-15 1.0000000e+00 2.1179501e-14 1.9202363e-12 1.5501425e-15], sampled 0.45513980868737247
[2019-03-26 20:10:32,120] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2144752.831495714 W.
[2019-03-26 20:10:40,824] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06244335], dtype=float32), 0.060314335]
[2019-03-26 20:10:40,825] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.64260755, 67.52887272, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.212076045745453, 6.9112, 168.9109621534419, 1667350.418019215, 1453901.116040908, 311348.4356018196]
[2019-03-26 20:10:40,827] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:10:40,830] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.7069396e-19 1.0000000e+00 2.1056417e-17 4.0129490e-15 2.5545390e-19], sampled 0.1451266266074962
[2019-03-26 20:10:40,831] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1667350.418019215 W.
[2019-03-26 20:10:45,565] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06244335], dtype=float32), 0.060314335]
[2019-03-26 20:10:45,566] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.40000000000001, 54.66666666666667, 1.0, 2.0, 0.9358997974116459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1308149.710658237, 1308149.710658237, 280004.2559988697]
[2019-03-26 20:10:45,566] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:10:45,570] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.2539642e-19 1.0000000e+00 2.1245945e-17 3.0238797e-15 2.8798252e-19], sampled 0.5505561871399199
[2019-03-26 20:10:46,324] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06244335], dtype=float32), 0.060314335]
[2019-03-26 20:10:46,324] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.91346258, 84.019137885, 1.0, 2.0, 0.5433905842366326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 759325.5867675231, 759325.5867675231, 190673.6889802349]
[2019-03-26 20:10:46,326] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:10:46,329] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.0747993e-18 1.0000000e+00 1.5677563e-16 4.6087207e-15 5.8363450e-19], sampled 0.6477415391333561
[2019-03-26 20:10:49,420] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06244335], dtype=float32), 0.060314335]
[2019-03-26 20:10:49,421] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.12770873, 66.6999072, 1.0, 2.0, 0.8189222690124941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1144556.770065525, 1144556.770065525, 248609.7542255623]
[2019-03-26 20:10:49,423] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:10:49,425] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.4868107e-19 1.0000000e+00 1.6657695e-17 9.8677115e-16 8.1627107e-20], sampled 0.32531622007048255
[2019-03-26 20:11:09,874] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164071917.9177 1778.0000
[2019-03-26 20:11:10,112] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2767 3007680316.3481 1766.0000
[2019-03-26 20:11:10,190] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.5681 2927329776.9375 1338.0000
[2019-03-26 20:11:10,247] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9503 2779156117.6396 933.0000
[2019-03-26 20:11:10,310] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5385 2842476554.9448 1131.0000
[2019-03-26 20:11:11,325] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 575000, evaluation results [575000.0, 7884.168443086554, 3164071917.9176674, 1778.0, 8253.568068259077, 2927329776.937506, 1338.0, 8659.950256865504, 2779156117.6396384, 933.0, 7998.276703650782, 3007680316.348062, 1766.0, 8497.538503793214, 2842476554.944838, 1131.0]
[2019-03-26 20:11:12,112] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0232269e-10 1.0000000e+00 5.1697130e-10 1.2392494e-08 7.6525730e-11], sum to 1.0000
[2019-03-26 20:11:12,121] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6241
[2019-03-26 20:11:12,131] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2003740.204729647 W.
[2019-03-26 20:11:12,136] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.53333333333333, 63.33333333333333, 1.0, 2.0, 0.477698417558381, 1.0, 2.0, 0.477698417558381, 1.0, 1.0, 0.8296041740181869, 6.9112, 6.9112, 170.5573041426782, 2003740.204729647, 2003740.204729647, 400066.8009101085], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5835000.0000, 
sim time next is 5835600.0000, 
raw observation next is [32.6, 63.0, 1.0, 2.0, 0.7809049764986088, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.005980292312801, 6.9112, 168.9123932062552, 1988349.534301391, 1921109.357087348, 403163.75063905], 
processed observation next is [1.0, 0.5652173913043478, 0.7440758293838864, 0.63, 1.0, 1.0, 0.7360300921669986, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.009478029231280072, 0.0, 0.8294371790709176, 0.5523193150837198, 0.5336414880798188, 0.6017369412523134], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13938668], dtype=float32), 1.3480135]. 
=============================================
[2019-03-26 20:11:19,043] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2530563e-20 1.0000000e+00 1.5572108e-18 5.5681532e-16 9.1512232e-20], sum to 1.0000
[2019-03-26 20:11:19,046] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2927
[2019-03-26 20:11:19,053] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.53333333333334, 89.5, 1.0, 2.0, 0.5570404966408042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 778406.7519905453, 778406.7519905453, 193015.6653702966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5955000.0000, 
sim time next is 5955600.0000, 
raw observation next is [27.46666666666667, 90.0, 1.0, 2.0, 0.5575782937230792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779158.5436857993, 779158.5436857993, 193109.0351841725], 
processed observation next is [1.0, 0.9565217391304348, 0.500789889415482, 0.9, 1.0, 1.0, 0.4669617996663605, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21643292880161094, 0.21643292880161094, 0.2882224405733918], 
reward next is 0.7118, 
noisyNet noise sample is [array([-1.3129013], dtype=float32), -0.85389626]. 
=============================================
[2019-03-26 20:11:26,753] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.2057968e-19 1.0000000e+00 1.3150564e-16 7.5552237e-16 1.3619063e-19], sum to 1.0000
[2019-03-26 20:11:26,760] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4259
[2019-03-26 20:11:26,764] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 90.16666666666667, 1.0, 2.0, 0.6862671686628288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 959069.2553212187, 959069.2553212187, 217909.5682786445], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5897400.0000, 
sim time next is 5898000.0000, 
raw observation next is [27.2, 89.33333333333334, 1.0, 2.0, 0.7328978633174595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1024267.817487945, 1024267.817487945, 228107.2523535618], 
processed observation next is [1.0, 0.2608695652173913, 0.4881516587677725, 0.8933333333333334, 1.0, 1.0, 0.6781901967680235, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2845188381910958, 0.2845188381910958, 0.34045858560233105], 
reward next is 0.6595, 
noisyNet noise sample is [array([-0.19153848], dtype=float32), -0.9862089]. 
=============================================
[2019-03-26 20:11:26,782] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[72.13903 ]
 [72.06741 ]
 [72.026665]
 [71.91456 ]
 [71.63398 ]], R is [[72.1448288 ]
 [72.0981369 ]
 [72.05387115]
 [72.00395966]
 [71.95728302]].
[2019-03-26 20:11:29,436] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.7361713e-11 1.0000000e+00 5.1358451e-10 2.5223805e-08 2.5724645e-11], sum to 1.0000
[2019-03-26 20:11:29,445] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6251
[2019-03-26 20:11:29,454] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2479679.323958042 W.
[2019-03-26 20:11:29,460] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.05, 77.0, 1.0, 2.0, 0.8865648468982897, 1.0, 1.0, 0.8865648468982897, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2479679.323958042, 2479679.323958042, 464217.2104673041], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5931000.0000, 
sim time next is 5931600.0000, 
raw observation next is [30.1, 77.33333333333334, 1.0, 2.0, 0.81500052378915, 1.0, 2.0, 0.81500052378915, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2279334.799607124, 2279334.799607124, 427245.0721098267], 
processed observation next is [1.0, 0.6521739130434783, 0.6255924170616115, 0.7733333333333334, 1.0, 1.0, 0.7771090648062048, 1.0, 1.0, 0.7771090648062048, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6331485554464233, 0.6331485554464233, 0.637679212104219], 
reward next is 0.3623, 
noisyNet noise sample is [array([1.0306038], dtype=float32), 0.43998274]. 
=============================================
[2019-03-26 20:11:29,734] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.8603205e-11 1.0000000e+00 2.6754260e-10 2.1605949e-08 1.7678520e-11], sum to 1.0000
[2019-03-26 20:11:29,750] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4873
[2019-03-26 20:11:29,760] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2353069.278584643 W.
[2019-03-26 20:11:29,766] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.4, 79.0, 1.0, 2.0, 0.5608935182103151, 1.0, 1.0, 0.5608935182103151, 1.0, 2.0, 0.974086550810387, 6.911199999999999, 6.9112, 170.5573041426782, 2353069.278584643, 2353069.278584644, 459810.022093982], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5936400.0000, 
sim time next is 5937000.0000, 
raw observation next is [30.3, 79.16666666666667, 1.0, 2.0, 0.3989318209810866, 1.0, 2.0, 0.3989318209810866, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1115103.336142019, 1115103.336142019, 271871.5588717372], 
processed observation next is [1.0, 0.7391304347826086, 0.6350710900473934, 0.7916666666666667, 1.0, 1.0, 0.27582147106155014, 1.0, 1.0, 0.27582147106155014, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.30975092670611637, 0.30975092670611637, 0.40577844607721975], 
reward next is 0.5942, 
noisyNet noise sample is [array([-1.0905402], dtype=float32), 1.0583745]. 
=============================================
[2019-03-26 20:11:29,781] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[41.043   ]
 [42.3436  ]
 [41.635044]
 [41.247574]
 [40.817017]], R is [[41.89152145]
 [41.78632355]
 [41.36846161]
 [40.95477676]
 [40.89967346]].
[2019-03-26 20:11:30,577] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0202364e-19 1.0000000e+00 6.2355806e-17 2.3920583e-15 2.2955577e-20], sum to 1.0000
[2019-03-26 20:11:30,587] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6146
[2019-03-26 20:11:30,594] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 91.33333333333334, 1.0, 2.0, 0.5486649305677026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 766698.5365819472, 766698.5365819478, 191572.0490867477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5960400.0000, 
sim time next is 5961000.0000, 
raw observation next is [26.95, 91.16666666666667, 1.0, 2.0, 0.5459869711336645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 762955.0406100419, 762955.0406100419, 191114.8963855663], 
processed observation next is [1.0, 1.0, 0.476303317535545, 0.9116666666666667, 1.0, 1.0, 0.4529963507634511, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21193195572501164, 0.21193195572501164, 0.2852461140083079], 
reward next is 0.7148, 
noisyNet noise sample is [array([-0.27492154], dtype=float32), 0.26359856]. 
=============================================
[2019-03-26 20:11:30,608] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[73.773056]
 [73.74751 ]
 [73.723724]
 [73.69253 ]
 [73.65142 ]], R is [[73.77190399]
 [73.7482605 ]
 [73.72415161]
 [73.69962311]
 [73.67474365]].
[2019-03-26 20:11:42,580] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6742890e-17 1.0000000e+00 4.0855287e-16 3.4373986e-14 2.6879004e-18], sum to 1.0000
[2019-03-26 20:11:42,587] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0872
[2019-03-26 20:11:42,593] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.28333333333333, 91.16666666666667, 1.0, 2.0, 0.8330963961850133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1164377.92881062, 1164377.928810619, 252195.8502293417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6491400.0000, 
sim time next is 6492000.0000, 
raw observation next is [26.26666666666667, 91.33333333333334, 1.0, 2.0, 0.7212835638125493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1008028.447919334, 1008028.447919334, 225505.3897366343], 
processed observation next is [1.0, 0.13043478260869565, 0.44391785150079005, 0.9133333333333334, 1.0, 1.0, 0.6641970648343968, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.28000790219981503, 0.28000790219981503, 0.33657520856214074], 
reward next is 0.6634, 
noisyNet noise sample is [array([-0.07149874], dtype=float32), -0.39108923]. 
=============================================
[2019-03-26 20:11:42,621] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[68.739624]
 [68.539696]
 [68.42865 ]
 [68.36093 ]
 [68.49635 ]], R is [[68.81526184]
 [68.7507019 ]
 [68.73891449]
 [68.72216034]
 [68.69636536]].
[2019-03-26 20:11:43,648] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8443524e-12 1.0000000e+00 4.2439149e-11 1.6346108e-09 2.3928561e-12], sum to 1.0000
[2019-03-26 20:11:43,660] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9522
[2019-03-26 20:11:43,670] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2060943.713189248 W.
[2019-03-26 20:11:43,675] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.63333333333333, 75.0, 1.0, 2.0, 0.8327745908975518, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.994815612057216, 6.9112, 168.9123887651723, 2060943.713189248, 2001624.119552534, 416520.8907345228], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6176400.0000, 
sim time next is 6177000.0000, 
raw observation next is [29.71666666666667, 74.5, 1.0, 2.0, 0.7257715651096982, 1.0, 1.0, 0.7257715651096982, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2029558.285170601, 2029558.285170601, 385353.5717273353], 
processed observation next is [1.0, 0.4782608695652174, 0.6074249605055293, 0.745, 1.0, 1.0, 0.6696042953128893, 1.0, 0.5, 0.6696042953128893, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.563766190325167, 0.563766190325167, 0.5751545846676646], 
reward next is 0.4248, 
noisyNet noise sample is [array([-0.69448453], dtype=float32), -0.01788928]. 
=============================================
[2019-03-26 20:11:43,687] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[44.35409 ]
 [44.407776]
 [44.630936]
 [46.682785]
 [46.759674]], R is [[44.26078033]
 [43.81817245]
 [43.37998962]
 [42.94618988]
 [42.51672745]].
[2019-03-26 20:11:43,797] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.7886200e-12 1.0000000e+00 6.9313486e-11 2.9115810e-09 7.5456620e-12], sum to 1.0000
[2019-03-26 20:11:43,810] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2130
[2019-03-26 20:11:43,820] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1710476.678265951 W.
[2019-03-26 20:11:43,825] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.21666666666667, 71.5, 1.0, 2.0, 0.6117539995786992, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.938419982632098, 6.9112, 168.9127462850561, 1710476.678265951, 1691165.909781031, 367129.0224828239], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6180600.0000, 
sim time next is 6181200.0000, 
raw observation next is [30.3, 71.0, 1.0, 2.0, 0.4315830289685867, 1.0, 1.0, 0.4315830289685867, 1.0, 2.0, 0.7479929145064781, 6.911199999999999, 6.9112, 170.5573041426782, 1810142.502957566, 1810142.502957566, 370828.4578590983], 
processed observation next is [1.0, 0.5652173913043478, 0.6350710900473934, 0.71, 1.0, 1.0, 0.31516027586576706, 1.0, 0.5, 0.31516027586576706, 1.0, 1.0, 0.6926742859835099, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5028173619326572, 0.5028173619326572, 0.5534753102374601], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1707044], dtype=float32), 0.18326122]. 
=============================================
[2019-03-26 20:11:44,902] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.3629874e-12 1.0000000e+00 3.0889910e-10 1.4007138e-09 2.1321141e-12], sum to 1.0000
[2019-03-26 20:11:44,909] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4194
[2019-03-26 20:11:44,916] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.75, 77.5, 1.0, 2.0, 0.4875684746969029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104273, 681295.6203202899, 681295.6203202892, 181674.4259616278], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6197400.0000, 
sim time next is 6198000.0000, 
raw observation next is [28.66666666666667, 78.0, 1.0, 2.0, 0.5008950371047298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 699923.4033164144, 699923.4033164139, 183738.8669801877], 
processed observation next is [1.0, 0.7391304347826086, 0.5576619273301741, 0.78, 1.0, 1.0, 0.3986687194032889, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1944231675878929, 0.19442316758789274, 0.27423711489580255], 
reward next is 0.7258, 
noisyNet noise sample is [array([-1.1846392], dtype=float32), 0.21719557]. 
=============================================
[2019-03-26 20:11:44,939] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[44.289204]
 [42.33163 ]
 [40.11151 ]
 [40.29471 ]
 [39.898697]], R is [[46.63495636]
 [46.89744949]
 [46.42847443]
 [45.96419144]
 [45.50455093]].
[2019-03-26 20:11:53,801] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.3473633e-20 1.0000000e+00 1.2718612e-17 1.2285205e-15 3.2540565e-20], sum to 1.0000
[2019-03-26 20:11:53,814] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1753
[2019-03-26 20:11:53,820] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.41666666666666, 82.0, 1.0, 2.0, 0.5203567118000646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 727127.3935614872, 727127.3935614872, 186846.5989268792], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6385800.0000, 
sim time next is 6386400.0000, 
raw observation next is [27.4, 82.0, 1.0, 2.0, 0.5193917096283556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 725778.4742334208, 725778.4742334208, 186689.7429614227], 
processed observation next is [0.0, 0.9565217391304348, 0.4976303317535545, 0.82, 1.0, 1.0, 0.4209538670221151, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20160513173150577, 0.20160513173150577, 0.2786414074051085], 
reward next is 0.7214, 
noisyNet noise sample is [array([-1.9199332], dtype=float32), -0.12138846]. 
=============================================
[2019-03-26 20:11:59,594] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4698175e-10 1.0000000e+00 1.1661289e-09 2.4304549e-08 5.6878967e-11], sum to 1.0000
[2019-03-26 20:11:59,606] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9369
[2019-03-26 20:11:59,614] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2020833.100945427 W.
[2019-03-26 20:11:59,618] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.9, 69.0, 1.0, 2.0, 0.4817695818351497, 1.0, 2.0, 0.4817695818351497, 1.0, 1.0, 0.8278135276129462, 6.9112, 6.9112, 170.5573041426782, 2020833.100945427, 2020833.100945427, 401227.1301765035], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6438000.0000, 
sim time next is 6438600.0000, 
raw observation next is [29.9, 69.0, 1.0, 2.0, 0.6883357170663913, 1.0, 2.0, 0.6883357170663913, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1924778.088590406, 1924778.088590406, 369167.5137877924], 
processed observation next is [1.0, 0.5217391304347826, 0.6161137440758293, 0.69, 1.0, 1.0, 0.6245008639354112, 1.0, 1.0, 0.6245008639354112, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5346605801640018, 0.5346605801640018, 0.550996289235511], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.1963084], dtype=float32), -1.1089855]. 
=============================================
[2019-03-26 20:12:01,793] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3170172e-19 1.0000000e+00 4.8787026e-18 1.4509619e-15 3.1384334e-20], sum to 1.0000
[2019-03-26 20:12:01,798] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9033
[2019-03-26 20:12:01,803] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.86666666666667, 88.33333333333334, 1.0, 2.0, 0.52873246730019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738835.4375962825, 738835.4375962825, 188220.286648948], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6480600.0000, 
sim time next is 6481200.0000, 
raw observation next is [26.83333333333333, 88.66666666666667, 1.0, 2.0, 0.5291646017967019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 739439.5000042234, 739439.5000042241, 188291.7101906741], 
processed observation next is [1.0, 0.0, 0.470774091627172, 0.8866666666666667, 1.0, 1.0, 0.4327284358996408, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20539986111228428, 0.20539986111228448, 0.28103240326966283], 
reward next is 0.7190, 
noisyNet noise sample is [array([-1.1138383], dtype=float32), 0.16539451]. 
=============================================
[2019-03-26 20:12:03,763] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2876742e-16 1.0000000e+00 4.8164479e-15 9.8024833e-13 1.1864782e-16], sum to 1.0000
[2019-03-26 20:12:03,774] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8551
[2019-03-26 20:12:03,780] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1739937.705748593 W.
[2019-03-26 20:12:03,786] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.71666666666667, 74.33333333333334, 1.0, 2.0, 0.414858036644404, 1.0, 2.0, 0.414858036644404, 1.0, 1.0, 0.7091951048548273, 6.911199999999999, 6.9112, 170.5573041426782, 1739937.705748593, 1739937.705748594, 359606.6979878964], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6513000.0000, 
sim time next is 6513600.0000, 
raw observation next is [28.93333333333334, 72.66666666666667, 1.0, 2.0, 0.4187187703878794, 1.0, 2.0, 0.4187187703878794, 1.0, 2.0, 0.7155163311830108, 6.911200000000001, 6.9112, 170.5573041426782, 1756143.106324155, 1756143.106324154, 361757.5465389492], 
processed observation next is [1.0, 0.391304347826087, 0.5703001579778835, 0.7266666666666667, 1.0, 1.0, 0.2996611691420234, 1.0, 1.0, 0.2996611691420234, 1.0, 1.0, 0.6530686965646474, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4878175295344875, 0.4878175295344872, 0.5399366366252973], 
reward next is 0.4601, 
noisyNet noise sample is [array([-0.79547924], dtype=float32), 1.5279053]. 
=============================================
[2019-03-26 20:12:04,244] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.8489757e-11 1.0000000e+00 2.0113257e-10 9.9000967e-09 4.5764221e-12], sum to 1.0000
[2019-03-26 20:12:04,252] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5274
[2019-03-26 20:12:04,260] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2229596.727199761 W.
[2019-03-26 20:12:04,266] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.1, 55.0, 1.0, 2.0, 0.953270072721905, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.973370474585385, 6.9112, 168.9125868754285, 2229596.727199761, 2185490.949303901, 450369.5271016133], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6530400.0000, 
sim time next is 6531000.0000, 
raw observation next is [31.98333333333333, 55.5, 1.0, 2.0, 0.8010044528183244, 1.0, 1.0, 0.8010044528183244, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2240156.514184684, 2240156.514184684, 420351.0116031492], 
processed observation next is [1.0, 0.6086956521739131, 0.7148499210110584, 0.555, 1.0, 1.0, 0.7602463286967764, 1.0, 0.5, 0.7602463286967764, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6222656983846344, 0.6222656983846344, 0.627389569556939], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2532861], dtype=float32), 0.69281995]. 
=============================================
[2019-03-26 20:12:04,280] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[42.212234]
 [41.862553]
 [41.63496 ]
 [41.27103 ]
 [42.384216]], R is [[41.57134628]
 [41.15563202]
 [40.74407578]
 [40.33663559]
 [39.9332695 ]].
[2019-03-26 20:12:04,812] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9207638e-19 1.0000000e+00 7.0177855e-16 2.7842200e-15 2.2459352e-19], sum to 1.0000
[2019-03-26 20:12:04,820] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0635
[2019-03-26 20:12:04,826] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.56666666666667, 88.66666666666667, 1.0, 2.0, 0.5192630779451771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 725598.6677585011, 725598.6677585011, 186669.2128722406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6569400.0000, 
sim time next is 6570000.0000, 
raw observation next is [26.5, 89.0, 1.0, 2.0, 0.5195887127387313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 726053.8530634192, 726053.8530634185, 186722.0346897692], 
processed observation next is [1.0, 0.043478260869565216, 0.4549763033175356, 0.89, 1.0, 1.0, 0.4211912201671461, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20168162585094979, 0.2016816258509496, 0.2786896040145809], 
reward next is 0.7213, 
noisyNet noise sample is [array([1.4354129], dtype=float32), 0.6926384]. 
=============================================
[2019-03-26 20:12:04,843] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[69.53443 ]
 [69.904785]
 [70.35848 ]
 [70.80402 ]
 [71.15054 ]], R is [[69.26029968]
 [69.28908539]
 [69.31764984]
 [69.34593201]
 [69.37388611]].
[2019-03-26 20:12:06,563] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 20:12:06,565] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:12:06,567] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:12:06,567] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:12:06,569] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:12:06,569] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:12:06,570] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:12:06,570] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:12:06,572] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:12:06,571] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:12:06,574] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:12:06,596] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run25
[2019-03-26 20:12:06,614] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run25
[2019-03-26 20:12:06,616] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run25
[2019-03-26 20:12:06,658] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run25
[2019-03-26 20:12:06,676] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run25
[2019-03-26 20:12:39,419] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06580801], dtype=float32), 0.06224388]
[2019-03-26 20:12:39,420] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.94894008, 96.7303224, 1.0, 2.0, 0.5243829160066478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 741169.9461522271, 741169.9461522277, 188582.0579835171]
[2019-03-26 20:12:39,421] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:12:39,424] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.23276236e-18 1.00000000e+00 1.05253776e-16 8.63120475e-15
 2.42325275e-19], sampled 0.912392590909323
[2019-03-26 20:12:43,153] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06580801], dtype=float32), 0.06224388]
[2019-03-26 20:12:43,155] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.23046481, 90.2995831, 1.0, 2.0, 0.4582391813403777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 640300.4736769453, 640300.4736769447, 177312.3303521039]
[2019-03-26 20:12:43,155] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:12:43,157] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.7339312e-16 1.0000000e+00 1.0569688e-14 2.9649658e-13 3.1904528e-17], sampled 0.46100293542597603
[2019-03-26 20:12:43,564] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06580801], dtype=float32), 0.06224388]
[2019-03-26 20:12:43,565] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.38333333333334, 80.5, 1.0, 2.0, 0.525801279665876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 769215.1648607214, 769215.1648607214, 192076.3679853522]
[2019-03-26 20:12:43,568] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:12:43,573] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.3186623e-18 1.0000000e+00 1.8531123e-16 9.1749457e-15 4.0077699e-19], sampled 0.28121813713518296
[2019-03-26 20:12:58,769] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06580801], dtype=float32), 0.06224388]
[2019-03-26 20:12:58,770] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.08333333333333, 57.16666666666667, 1.0, 2.0, 0.5627003985333133, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9543330804285128, 6.911200000000001, 6.9112, 168.9125475912408, 1573220.155546166, 1573220.155546165, 339439.7682615445]
[2019-03-26 20:12:58,771] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:12:58,773] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.5802178e-17 1.0000000e+00 1.4468938e-15 1.7141030e-13 1.8388867e-17], sampled 0.6860574336262031
[2019-03-26 20:13:52,167] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06580801], dtype=float32), 0.06224388]
[2019-03-26 20:13:52,167] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.42643458, 93.18370697, 1.0, 2.0, 0.3767436632137366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 575310.9173908726, 575310.9173908726, 172684.4668431602]
[2019-03-26 20:13:52,168] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:13:52,170] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.6196446e-18 1.0000000e+00 1.2315463e-16 8.6456382e-15 3.3109809e-19], sampled 0.6217899223628002
[2019-03-26 20:14:01,231] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6842 2927317744.9770 1338.0000
[2019-03-26 20:14:01,596] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8724 2842497929.8887 1131.0000
[2019-03-26 20:14:01,648] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 20:14:01,665] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.9141 3164157795.0059 1778.0000
[2019-03-26 20:14:01,670] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5495 3007743997.8566 1766.0000
[2019-03-26 20:14:02,686] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 600000, evaluation results [600000.0, 7881.914089799695, 3164157795.0059204, 1778.0, 8253.684239900658, 2927317744.977035, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7997.5495352406515, 3007743997.8566456, 1766.0, 8496.87235025343, 2842497929.888741, 1131.0]
[2019-03-26 20:14:04,293] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0748366e-18 1.0000000e+00 7.0827349e-16 1.0674838e-14 1.0101895e-18], sum to 1.0000
[2019-03-26 20:14:04,302] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0342
[2019-03-26 20:14:04,306] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.9, 91.5, 1.0, 2.0, 0.754033857688654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1053821.267887807, 1053821.267887807, 232938.8551451454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6586200.0000, 
sim time next is 6586800.0000, 
raw observation next is [25.96666666666667, 91.0, 1.0, 2.0, 0.7025669105951161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 981858.9333790259, 981858.9333790265, 221398.4840133816], 
processed observation next is [1.0, 0.21739130434782608, 0.42969984202211703, 0.91, 1.0, 1.0, 0.6416468802350797, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.272738592605285, 0.27273859260528516, 0.3304454985274352], 
reward next is 0.6696, 
noisyNet noise sample is [array([1.2947495], dtype=float32), -0.8170495]. 
=============================================
[2019-03-26 20:14:19,710] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7978652e-18 1.0000000e+00 1.9953628e-16 2.6386032e-14 1.6496175e-19], sum to 1.0000
[2019-03-26 20:14:19,720] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7711
[2019-03-26 20:14:19,723] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333334, 62.0, 1.0, 2.0, 0.3590494259817629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 551357.4794983586, 551357.4794983593, 170710.9904451374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6860400.0000, 
sim time next is 6861000.0000, 
raw observation next is [27.01666666666667, 60.5, 1.0, 2.0, 0.3552286247109708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 546793.3043005125, 546793.3043005131, 170366.6043472594], 
processed observation next is [0.0, 0.391304347826087, 0.4794628751974725, 0.605, 1.0, 1.0, 0.22316701772406117, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15188702897236458, 0.15188702897236475, 0.25427851395113343], 
reward next is 0.7457, 
noisyNet noise sample is [array([-0.24590859], dtype=float32), -0.27854696]. 
=============================================
[2019-03-26 20:14:19,738] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[72.901794]
 [72.86923 ]
 [72.83323 ]
 [72.786224]
 [72.727104]], R is [[72.94468689]
 [72.96044922]
 [72.97550964]
 [72.98996735]
 [73.00397491]].
[2019-03-26 20:14:29,526] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.7872978e-19 1.0000000e+00 1.2693413e-16 2.4785196e-15 1.0259367e-19], sum to 1.0000
[2019-03-26 20:14:29,539] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1375
[2019-03-26 20:14:29,549] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.65, 76.0, 1.0, 2.0, 0.5917320944556285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 846554.1892061256, 846554.1892061256, 201742.0874032477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7023000.0000, 
sim time next is 7023600.0000, 
raw observation next is [26.8, 75.0, 1.0, 2.0, 0.6364402611088918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 910828.0310405577, 910828.031040557, 210518.0316832197], 
processed observation next is [1.0, 0.30434782608695654, 0.4691943127962086, 0.75, 1.0, 1.0, 0.5619762182034841, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2530077864001549, 0.2530077864001547, 0.31420601743764137], 
reward next is 0.6858, 
noisyNet noise sample is [array([0.9090937], dtype=float32), 1.3957665]. 
=============================================
[2019-03-26 20:14:33,875] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1290778e-18 1.0000000e+00 5.8672675e-17 2.6042028e-15 1.3378950e-19], sum to 1.0000
[2019-03-26 20:14:33,887] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6466
[2019-03-26 20:14:33,891] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 91.0, 1.0, 2.0, 0.4736726639397326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 662746.8627646222, 662746.8627646222, 179686.7581658885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7088400.0000, 
sim time next is 7089000.0000, 
raw observation next is [24.96666666666667, 91.16666666666667, 1.0, 2.0, 0.4740211407467417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 663354.1910249898, 663354.1910249904, 179754.1539608379], 
processed observation next is [1.0, 0.043478260869565216, 0.3823064770932071, 0.9116666666666667, 1.0, 1.0, 0.36629053102017073, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18426505306249719, 0.18426505306249732, 0.2682897820311013], 
reward next is 0.7317, 
noisyNet noise sample is [array([2.6497235], dtype=float32), 0.14228979]. 
=============================================
[2019-03-26 20:14:33,907] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[72.97906 ]
 [73.33361 ]
 [73.765755]
 [74.2861  ]
 [74.803505]], R is [[72.55709839]
 [72.56333923]
 [72.56951904]
 [72.57554626]
 [72.58135223]].
[2019-03-26 20:14:37,336] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5653950e-17 1.0000000e+00 1.5274726e-15 2.0904385e-14 1.5560351e-18], sum to 1.0000
[2019-03-26 20:14:37,344] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1324
[2019-03-26 20:14:37,349] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 75.33333333333333, 1.0, 2.0, 0.4143900331792998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 636312.9102827344, 636312.9102827339, 178298.6179107785], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7353600.0000, 
sim time next is 7354200.0000, 
raw observation next is [24.58333333333334, 76.16666666666667, 1.0, 2.0, 0.4114681303065342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 631072.2264921246, 631072.2264921246, 177794.5795916351], 
processed observation next is [1.0, 0.08695652173913043, 0.3641390205371251, 0.7616666666666667, 1.0, 1.0, 0.2909254582006436, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17529784069225685, 0.17529784069225685, 0.26536504416661955], 
reward next is 0.7346, 
noisyNet noise sample is [array([-1.4727404], dtype=float32), 2.7026975]. 
=============================================
[2019-03-26 20:14:40,890] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.0522799e-13 1.0000000e+00 6.0218731e-12 3.6117409e-10 1.4930952e-13], sum to 1.0000
[2019-03-26 20:14:40,900] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3958
[2019-03-26 20:14:40,910] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1882300.778230643 W.
[2019-03-26 20:14:40,914] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.16666666666667, 77.0, 1.0, 2.0, 0.4487722593087126, 1.0, 1.0, 0.4487722593087126, 1.0, 2.0, 0.776978697993377, 6.9112, 6.9112, 170.5573041426782, 1882300.778230643, 1882300.778230643, 381148.342494908], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7208400.0000, 
sim time next is 7209000.0000, 
raw observation next is [29.25, 76.0, 1.0, 2.0, 0.4348347774656657, 1.0, 2.0, 0.4348347774656657, 1.0, 2.0, 0.7525940783317998, 6.9112, 6.9112, 170.5573041426782, 1823792.570607855, 1823792.570607855, 372614.5055673344], 
processed observation next is [1.0, 0.43478260869565216, 0.5853080568720379, 0.76, 1.0, 1.0, 0.3190780451393562, 1.0, 1.0, 0.3190780451393562, 1.0, 1.0, 0.6982854613802436, 0.0, 0.0, 0.8375144448122397, 0.5066090473910708, 0.5066090473910708, 0.5561410530855737], 
reward next is 0.4439, 
noisyNet noise sample is [array([0.40587184], dtype=float32), 0.7626037]. 
=============================================
[2019-03-26 20:14:40,928] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[49.75273 ]
 [51.46638 ]
 [52.123642]
 [53.292828]
 [54.25434 ]], R is [[48.16830444]
 [48.11774445]
 [47.64454269]
 [47.16809845]
 [46.69641876]].
[2019-03-26 20:14:43,147] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6520177e-18 1.0000000e+00 2.5611780e-16 1.6034400e-14 4.0827024e-19], sum to 1.0000
[2019-03-26 20:14:43,157] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4683
[2019-03-26 20:14:43,162] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.06666666666667, 89.33333333333333, 1.0, 2.0, 0.3354019002724136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 523749.3957909404, 523749.3957909399, 168705.8100013182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7260000.0000, 
sim time next is 7260600.0000, 
raw observation next is [22.03333333333333, 89.16666666666667, 1.0, 2.0, 0.3330708145564837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 520838.4301610519, 520838.4301610525, 168494.8166367773], 
processed observation next is [1.0, 0.0, 0.2432859399684044, 0.8916666666666667, 1.0, 1.0, 0.19647086091142613, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1446773417114033, 0.14467734171140348, 0.25148480095041387], 
reward next is 0.7485, 
noisyNet noise sample is [array([-0.16869467], dtype=float32), -0.3791894]. 
=============================================
[2019-03-26 20:14:46,273] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.9689864e-20 1.0000000e+00 5.2028300e-18 7.0242134e-16 1.4705958e-19], sum to 1.0000
[2019-03-26 20:14:46,283] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0963
[2019-03-26 20:14:46,294] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.73333333333333, 64.33333333333334, 1.0, 2.0, 0.7743874539833375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1179373.118487598, 1179373.118487598, 250502.7218039786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7299600.0000, 
sim time next is 7300200.0000, 
raw observation next is [26.81666666666667, 63.66666666666666, 1.0, 2.0, 0.7866281003577029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1199196.73302138, 1199196.733021379, 253857.3074249674], 
processed observation next is [1.0, 0.4782608695652174, 0.46998420221169057, 0.6366666666666666, 1.0, 1.0, 0.7429254221177144, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33311020361704996, 0.33311020361704974, 0.37889150361935436], 
reward next is 0.6211, 
noisyNet noise sample is [array([-0.2920563], dtype=float32), 0.3678796]. 
=============================================
[2019-03-26 20:14:52,269] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.5154607e-20 1.0000000e+00 4.3402034e-17 2.1914367e-15 3.6263010e-20], sum to 1.0000
[2019-03-26 20:14:52,280] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5191
[2019-03-26 20:14:52,288] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.63333333333333, 82.33333333333334, 1.0, 2.0, 0.2874782655347496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 462706.1998459483, 462706.1998459483, 164457.4963176636], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7415400.0000, 
sim time next is 7416000.0000, 
raw observation next is [21.7, 82.0, 1.0, 2.0, 0.2876649825195954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 462816.0945530452, 462816.0945530459, 164464.6261958088], 
processed observation next is [1.0, 0.8695652173913043, 0.2274881516587678, 0.82, 1.0, 1.0, 0.1417650391802354, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12856002626473478, 0.12856002626473498, 0.2454695913370281], 
reward next is 0.7545, 
noisyNet noise sample is [array([0.45457712], dtype=float32), -0.0007008654]. 
=============================================
[2019-03-26 20:14:52,311] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[75.30899 ]
 [75.400925]
 [75.56678 ]
 [75.67185 ]
 [75.807816]], R is [[75.18486786]
 [75.18756104]
 [75.19021606]
 [75.19284821]
 [75.19549561]].
[2019-03-26 20:14:57,841] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 20:14:57,847] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:14:57,847] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:14:57,848] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:14:57,849] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:14:57,849] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:14:57,850] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:14:57,850] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:14:57,851] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:14:57,850] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:14:57,852] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:14:57,876] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run26
[2019-03-26 20:14:57,895] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run26
[2019-03-26 20:14:57,897] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run26
[2019-03-26 20:14:57,945] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run26
[2019-03-26 20:14:57,946] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run26
[2019-03-26 20:14:59,675] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07052112], dtype=float32), 0.06639808]
[2019-03-26 20:14:59,679] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.9, 61.5, 1.0, 2.0, 0.80055427292565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1118871.43788565, 1118871.43788565, 244043.0491753223]
[2019-03-26 20:14:59,680] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:14:59,683] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.4916035e-21 1.0000000e+00 2.6776038e-19 4.7742056e-17 3.7990948e-22], sampled 0.7470857785693698
[2019-03-26 20:15:04,457] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07052112], dtype=float32), 0.06639808]
[2019-03-26 20:15:04,458] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.11292766, 86.22857749, 1.0, 2.0, 0.48421606102819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 702285.1770190044, 702285.177019005, 184414.5637921969]
[2019-03-26 20:15:04,458] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:15:04,460] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0271629e-18 1.0000000e+00 7.8425616e-17 4.4125940e-15 1.2763313e-19], sampled 0.21359243648884652
[2019-03-26 20:15:06,551] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07052112], dtype=float32), 0.06639808]
[2019-03-26 20:15:06,552] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.25041376666667, 82.12600259999999, 1.0, 2.0, 0.2523990583419493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 415082.5212365488, 415082.5212365495, 161143.4005270808]
[2019-03-26 20:15:06,553] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:15:06,556] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.7338304e-18 1.0000000e+00 3.1846422e-16 1.2082987e-14 4.5832196e-19], sampled 0.22572224484655645
[2019-03-26 20:15:41,976] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07052112], dtype=float32), 0.06639808]
[2019-03-26 20:15:41,976] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.7, 71.5, 1.0, 2.0, 0.5075049163980327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709162.7711583419, 709162.7711583412, 184779.8045073638]
[2019-03-26 20:15:41,977] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:15:41,981] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2396745e-20 1.0000000e+00 9.4285458e-19 2.0354010e-16 2.3644443e-21], sampled 0.5911993101551655
[2019-03-26 20:15:59,187] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07052112], dtype=float32), 0.06639808]
[2019-03-26 20:15:59,187] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.0, 89.0, 1.0, 2.0, 0.8130366652437334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1136326.4258456, 1136326.4258456, 247138.7285865187]
[2019-03-26 20:15:59,188] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:15:59,192] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.9963791e-20 1.0000000e+00 2.1178692e-18 1.7661084e-16 2.9756954e-21], sampled 0.9530677783041036
[2019-03-26 20:16:05,866] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07052112], dtype=float32), 0.06639808]
[2019-03-26 20:16:05,867] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.56960681666667, 85.75651472333334, 1.0, 2.0, 0.8251087923455618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1153207.984675918, 1153207.984675918, 250165.2120784855]
[2019-03-26 20:16:05,869] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:16:05,871] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.4230306e-19 1.0000000e+00 9.5331068e-18 1.2483382e-15 1.4466639e-20], sampled 0.9732364086074051
[2019-03-26 20:16:08,839] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07052112], dtype=float32), 0.06639808]
[2019-03-26 20:16:08,841] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.60704414, 69.47950730666666, 1.0, 2.0, 0.590251714393029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 824834.0297807849, 824834.0297807849, 198943.6028778046]
[2019-03-26 20:16:08,843] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:16:08,846] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.3006478e-22 1.0000000e+00 4.8161418e-20 1.3007665e-17 6.3890122e-23], sampled 0.5973952660908797
[2019-03-26 20:16:13,983] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07052112], dtype=float32), 0.06639808]
[2019-03-26 20:16:13,985] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.3, 63.33333333333333, 1.0, 2.0, 0.5796892209760965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 810068.0814616492, 810068.0814616486, 197022.2440292638]
[2019-03-26 20:16:13,987] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:16:13,988] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.2677833e-21 1.0000000e+00 9.1525891e-19 1.3717892e-16 1.3245433e-21], sampled 0.7367435005385925
[2019-03-26 20:16:33,865] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07052112], dtype=float32), 0.06639808]
[2019-03-26 20:16:33,867] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.88271619333334, 66.00135939333333, 1.0, 2.0, 0.590648496876272, 0.0, 1.0, 0.0, 1.0, 1.0, 1.025761108631343, 6.911200000000001, 6.9112, 168.9128195762093, 1651419.348498884, 1651419.348498883, 361745.7598698962]
[2019-03-26 20:16:33,868] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:16:33,870] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.0235469e-21 1.0000000e+00 8.3526232e-19 2.1323417e-16 2.6533405e-21], sampled 0.31204329336937076
[2019-03-26 20:16:39,087] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07052112], dtype=float32), 0.06639808]
[2019-03-26 20:16:39,089] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.75, 93.50000000000001, 1.0, 2.0, 0.493893140219897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 690136.1562771677, 690136.1562771677, 182643.6412361407]
[2019-03-26 20:16:39,090] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:16:39,094] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.9333038e-20 1.0000000e+00 8.8470044e-18 7.5179923e-16 1.1151651e-20], sampled 0.24626999756969392
[2019-03-26 20:16:52,292] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4308 2779149198.4617 933.0000
[2019-03-26 20:16:52,348] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 20:16:52,479] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 20:16:52,675] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.3850 2927277645.1185 1338.0000
[2019-03-26 20:16:52,826] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 20:16:53,841] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 625000, evaluation results [625000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8254.384998904972, 2927277645.1184874, 1338.0, 8661.430759135581, 2779149198.4616733, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 20:16:57,346] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0373334e-19 1.0000000e+00 2.3245440e-17 9.8121578e-16 8.3562839e-20], sum to 1.0000
[2019-03-26 20:16:57,354] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2457
[2019-03-26 20:16:57,361] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 76.5, 1.0, 2.0, 0.4702476916781942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 657085.2296747924, 657085.2296747918, 179066.041318213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7554600.0000, 
sim time next is 7555200.0000, 
raw observation next is [27.53333333333333, 75.66666666666666, 1.0, 2.0, 0.4717161429883107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 659137.7586540052, 659137.7586540047, 179283.6296646017], 
processed observation next is [0.0, 0.43478260869565216, 0.5039494470774091, 0.7566666666666666, 1.0, 1.0, 0.3635134252871214, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18309382184833478, 0.18309382184833461, 0.2675875069620921], 
reward next is 0.7324, 
noisyNet noise sample is [array([-1.4797963], dtype=float32), 0.03594456]. 
=============================================
[2019-03-26 20:17:01,475] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.7929331e-18 1.0000000e+00 1.5309494e-15 4.9636951e-14 1.1610550e-17], sum to 1.0000
[2019-03-26 20:17:01,484] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2615
[2019-03-26 20:17:01,493] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1743131.546584188 W.
[2019-03-26 20:17:01,496] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.76666666666667, 63.33333333333334, 1.0, 2.0, 0.6234234681813311, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.927581408687901, 6.9112, 168.9128376486929, 1743131.546584188, 1731510.019634331, 370354.8572809302], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7644000.0000, 
sim time next is 7644600.0000, 
raw observation next is [29.85, 63.0, 1.0, 2.0, 0.6344963252518899, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.949688206172116, 6.9112, 168.9127071285998, 1774117.837874399, 1746813.020066764, 372485.0526567554], 
processed observation next is [1.0, 0.4782608695652174, 0.613744075829384, 0.63, 1.0, 1.0, 0.5596341268095059, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.00384882061721159, 0.0, 0.829438720573344, 0.4928105105206664, 0.4852258389074344, 0.5559478397862021], 
reward next is 0.2516, 
noisyNet noise sample is [array([-1.3869427], dtype=float32), 1.0014875]. 
=============================================
[2019-03-26 20:17:01,831] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:01,831] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:01,864] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run4
[2019-03-26 20:17:06,888] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2948065e-11 1.0000000e+00 9.4351506e-11 3.5565482e-09 3.5545896e-12], sum to 1.0000
[2019-03-26 20:17:06,894] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4921
[2019-03-26 20:17:06,899] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.7, 61.66666666666667, 1.0, 2.0, 0.52923817421294, 1.0, 2.0, 0.52923817421294, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1479589.987743812, 1479589.987743812, 309586.2775081244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7735200.0000, 
sim time next is 7735800.0000, 
raw observation next is [31.75, 61.33333333333334, 1.0, 2.0, 0.997817137505666, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1394751.244082569, 1394751.244082569, 298261.6793300555], 
processed observation next is [1.0, 0.5217391304347826, 0.7037914691943128, 0.6133333333333334, 1.0, 1.0, 0.9973700451875495, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.38743090113404693, 0.38743090113404693, 0.445166685567247], 
reward next is 0.5548, 
noisyNet noise sample is [array([-0.89293796], dtype=float32), -0.6649407]. 
=============================================
[2019-03-26 20:17:08,222] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1633809e-16 1.0000000e+00 1.0518364e-14 2.7380894e-13 6.8827771e-18], sum to 1.0000
[2019-03-26 20:17:08,233] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8980
[2019-03-26 20:17:08,242] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.38333333333333, 75.83333333333334, 1.0, 2.0, 0.5038040579441986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 703989.6573216347, 703989.6573216347, 184194.8833086832], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7757400.0000, 
sim time next is 7758000.0000, 
raw observation next is [28.2, 77.0, 1.0, 2.0, 0.5068590382560402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 708259.9514718591, 708259.9514718591, 184678.1952016931], 
processed observation next is [1.0, 0.8260869565217391, 0.5355450236966824, 0.77, 1.0, 1.0, 0.4058542629590845, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19673887540884977, 0.19673887540884977, 0.27563909731595987], 
reward next is 0.7244, 
noisyNet noise sample is [array([0.04522613], dtype=float32), 1.0213277]. 
=============================================
[2019-03-26 20:17:08,254] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[65.647835]
 [64.404015]
 [62.339306]
 [60.671738]
 [59.29328 ]], R is [[67.07920837]
 [67.13349915]
 [67.18795776]
 [67.24259186]
 [67.2972641 ]].
[2019-03-26 20:17:08,965] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:08,965] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:09,003] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run4
[2019-03-26 20:17:12,722] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:12,723] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:12,756] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run4
[2019-03-26 20:17:17,507] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:17,508] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:17,550] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run4
[2019-03-26 20:17:17,682] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9553375e-18 1.0000000e+00 1.2080302e-16 2.4676340e-14 1.8879512e-19], sum to 1.0000
[2019-03-26 20:17:17,692] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0978
[2019-03-26 20:17:17,696] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 81.66666666666667, 1.0, 2.0, 0.5235415690042754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 731579.3287968005, 731579.3287968005, 187367.2348529376], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7935000.0000, 
sim time next is 7935600.0000, 
raw observation next is [27.8, 82.33333333333334, 1.0, 2.0, 0.5236551086158481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 731738.0398667025, 731738.0398667025, 187385.8173370538], 
processed observation next is [1.0, 0.8695652173913043, 0.5165876777251186, 0.8233333333333335, 1.0, 1.0, 0.4260904923082507, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2032605666296396, 0.2032605666296396, 0.27968032438366236], 
reward next is 0.7203, 
noisyNet noise sample is [array([-0.79277825], dtype=float32), -1.0438173]. 
=============================================
[2019-03-26 20:17:18,618] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.8856315e-19 1.0000000e+00 6.8326806e-18 6.3386138e-16 1.1307065e-19], sum to 1.0000
[2019-03-26 20:17:18,619] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9651
[2019-03-26 20:17:18,624] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 78.83333333333334, 1.0, 2.0, 0.3013051075397071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 479424.4883262644, 479424.4883262644, 165574.4798935821], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 319800.0000, 
sim time next is 320400.0000, 
raw observation next is [22.6, 79.0, 1.0, 2.0, 0.2993775856819734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 476788.9494197393, 476788.9494197399, 165393.446471702], 
processed observation next is [0.0, 0.7391304347826086, 0.27014218009478685, 0.79, 1.0, 1.0, 0.15587660925538965, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13244137483881646, 0.13244137483881663, 0.2468558902562716], 
reward next is 0.7531, 
noisyNet noise sample is [array([-1.1350186], dtype=float32), 0.6589391]. 
=============================================
[2019-03-26 20:17:18,698] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:18,699] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:18,717] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run4
[2019-03-26 20:17:19,265] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:19,265] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:19,280] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run4
[2019-03-26 20:17:19,300] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:19,303] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:19,331] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run4
[2019-03-26 20:17:19,399] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:19,400] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:19,418] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run4
[2019-03-26 20:17:19,435] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:19,436] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:19,440] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:19,440] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:19,454] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run4
[2019-03-26 20:17:19,476] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:19,476] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:19,477] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:19,479] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:19,482] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run4
[2019-03-26 20:17:19,520] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run4
[2019-03-26 20:17:19,543] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:19,543] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:19,546] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:19,545] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:19,543] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:19,544] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:19,549] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:19,544] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run4
[2019-03-26 20:17:19,549] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:19,570] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run4
[2019-03-26 20:17:19,596] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run4
[2019-03-26 20:17:19,658] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run4
[2019-03-26 20:17:19,692] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run4
[2019-03-26 20:17:23,391] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.4412235e-20 1.0000000e+00 3.7100630e-18 5.4078024e-16 4.0341485e-21], sum to 1.0000
[2019-03-26 20:17:23,400] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9324
[2019-03-26 20:17:23,405] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 66.33333333333334, 1.0, 2.0, 0.9701979298382953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1477756.259014511, 1477756.259014512, 307748.2391642974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 40800.0000, 
sim time next is 41400.0000, 
raw observation next is [26.5, 66.0, 1.0, 2.0, 1.011568122795368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1538833.650648151, 1538833.650648151, 321166.3498221408], 
processed observation next is [1.0, 0.4782608695652174, 0.4549763033175356, 0.66, 1.0, 1.0, 1.0139374973438167, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.4274537918467086, 0.4274537918467086, 0.4793527609285684], 
reward next is 0.5206, 
noisyNet noise sample is [array([0.3138298], dtype=float32), -0.10596244]. 
=============================================
[2019-03-26 20:17:23,461] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2525899e-20 1.0000000e+00 1.1289142e-18 8.8961859e-16 1.6310628e-21], sum to 1.0000
[2019-03-26 20:17:23,471] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9903
[2019-03-26 20:17:23,476] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 65.0, 1.0, 2.0, 0.9816847687986171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1487998.301291125, 1487998.301291124, 310516.4289071359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 43200.0000, 
sim time next is 43800.0000, 
raw observation next is [26.9, 64.66666666666667, 1.0, 2.0, 0.8976294841334724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1359017.294545552, 1359017.294545552, 284035.0235331982], 
processed observation next is [1.0, 0.5217391304347826, 0.4739336492890995, 0.6466666666666667, 1.0, 1.0, 0.8766620290764728, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.37750480404043113, 0.37750480404043113, 0.423932870945072], 
reward next is 0.5761, 
noisyNet noise sample is [array([1.5704489], dtype=float32), 1.1294398]. 
=============================================
[2019-03-26 20:17:28,356] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.9023565e-19 1.0000000e+00 1.3209230e-17 3.1589689e-15 3.3672019e-20], sum to 1.0000
[2019-03-26 20:17:28,367] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6635
[2019-03-26 20:17:28,372] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.85, 94.5, 1.0, 2.0, 0.7611937522887287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1138973.070034778, 1138973.070034778, 244615.5935863852], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 124200.0000, 
sim time next is 124800.0000, 
raw observation next is [22.83333333333333, 94.66666666666666, 1.0, 2.0, 0.6972964845658064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1043212.04975452, 1043212.049754521, 229158.2087723514], 
processed observation next is [1.0, 0.43478260869565216, 0.2812006319115322, 0.9466666666666665, 1.0, 1.0, 0.6352969693563932, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2897811249318111, 0.2897811249318114, 0.3420271772721663], 
reward next is 0.6580, 
noisyNet noise sample is [array([0.5646158], dtype=float32), -1.7455513]. 
=============================================
[2019-03-26 20:17:31,002] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.9041140e-19 1.0000000e+00 5.3875388e-17 2.0193005e-15 1.9488984e-20], sum to 1.0000
[2019-03-26 20:17:31,013] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4736
[2019-03-26 20:17:31,016] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 96.0, 1.0, 2.0, 0.3031448632281573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 483559.4951141838, 483559.4951141845, 165888.6869817479], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 173400.0000, 
sim time next is 174000.0000, 
raw observation next is [20.33333333333334, 96.0, 1.0, 2.0, 0.3022975971265512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 482554.179306344, 482554.179306344, 165820.6858335079], 
processed observation next is [0.0, 0.0, 0.16271721958925783, 0.96, 1.0, 1.0, 0.1593946953331942, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13404282758509556, 0.13404282758509556, 0.24749356094553415], 
reward next is 0.7525, 
noisyNet noise sample is [array([-0.32173446], dtype=float32), 0.05558072]. 
=============================================
[2019-03-26 20:17:31,029] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[75.86554]
 [76.40234]
 [76.68946]
 [76.71491]
 [76.73954]], R is [[75.50925446]
 [75.50656891]
 [75.50374603]
 [75.50061035]
 [75.49686432]].
[2019-03-26 20:17:40,032] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.5352812e-20 1.0000000e+00 3.9147679e-18 7.2798257e-16 6.9012228e-21], sum to 1.0000
[2019-03-26 20:17:40,043] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5158
[2019-03-26 20:17:40,049] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 77.0, 1.0, 2.0, 0.3150392842453921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 496097.0192038848, 496097.0192038848, 166688.1536447444], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 313200.0000, 
sim time next is 313800.0000, 
raw observation next is [23.33333333333333, 77.16666666666667, 1.0, 2.0, 0.3136728975625669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 494428.568492173, 494428.5684921724, 166575.4995984131], 
processed observation next is [0.0, 0.6521739130434783, 0.30489731437598716, 0.7716666666666667, 1.0, 1.0, 0.17309987658140588, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13734126902560362, 0.13734126902560345, 0.2486201486543479], 
reward next is 0.7514, 
noisyNet noise sample is [array([0.292053], dtype=float32), -0.38238794]. 
=============================================
[2019-03-26 20:17:46,258] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.8372772e-20 1.0000000e+00 1.7066582e-17 1.8795465e-16 1.9196573e-20], sum to 1.0000
[2019-03-26 20:17:46,266] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8583
[2019-03-26 20:17:46,271] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.03333333333333, 83.66666666666666, 1.0, 2.0, 0.2483630317335039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 408540.0226770592, 408540.0226770592, 160744.0411312169], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 424200.0000, 
sim time next is 424800.0000, 
raw observation next is [20.0, 84.0, 1.0, 2.0, 0.2484011189761096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 408560.1641764822, 408560.1641764816, 160748.413382857], 
processed observation next is [1.0, 0.9565217391304348, 0.1469194312796209, 0.84, 1.0, 1.0, 0.09445917948928864, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11348893449346727, 0.11348893449346711, 0.2399230050490403], 
reward next is 0.7601, 
noisyNet noise sample is [array([-1.0698035], dtype=float32), 0.102575384]. 
=============================================
[2019-03-26 20:17:48,018] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 20:17:48,019] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:17:48,020] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:48,022] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:17:48,023] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:17:48,023] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:48,024] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:48,024] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:17:48,024] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:17:48,026] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:48,026] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:48,052] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run27
[2019-03-26 20:17:48,072] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run27
[2019-03-26 20:17:48,092] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run27
[2019-03-26 20:17:48,111] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run27
[2019-03-26 20:17:48,112] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run27
[2019-03-26 20:17:49,695] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:17:49,695] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.42603517, 71.553314995, 1.0, 2.0, 0.5082230782416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 798660.763632607, 798660.763632607, 195152.6417288291]
[2019-03-26 20:17:49,697] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:17:49,701] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.7489757e-20 1.0000000e+00 5.8072327e-18 6.2940625e-16 7.2622774e-21], sampled 0.8099657392646143
[2019-03-26 20:18:04,727] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:18:04,728] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.37555129166667, 94.64252674333333, 1.0, 2.0, 0.3608155063136064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 547184.7890347684, 547184.7890347678, 170142.9085143887]
[2019-03-26 20:18:04,729] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:18:04,731] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.4506391e-19 1.0000000e+00 2.3707804e-17 1.6060684e-15 2.4407205e-20], sampled 0.27546586261145767
[2019-03-26 20:18:11,420] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:18:11,421] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.1, 86.0, 1.0, 2.0, 0.3561579235170261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 547306.5807380031, 547306.5807380031, 170382.9207291479]
[2019-03-26 20:18:11,425] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:18:11,426] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.34015715e-20 1.00000000e+00 1.25651072e-18 2.36121445e-16
 1.77148826e-21], sampled 0.5348355006957277
[2019-03-26 20:18:25,631] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:18:25,632] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.131631515, 85.727532315, 1.0, 2.0, 0.5649156647033784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 789415.5780497944, 789415.578049795, 194391.3958831663]
[2019-03-26 20:18:25,634] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:18:25,637] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.4009816e-22 1.0000000e+00 2.7881347e-20 8.5117489e-18 3.0258751e-23], sampled 0.009157537262654447
[2019-03-26 20:18:30,117] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:18:30,119] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.66337572, 94.667666405, 1.0, 2.0, 0.2772561794392837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 449425.8213312295, 449425.8213312295, 163547.8873084354]
[2019-03-26 20:18:30,120] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:18:30,127] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.4573528e-19 1.0000000e+00 3.0934728e-17 2.0424489e-15 3.3998047e-20], sampled 0.35136965969281597
[2019-03-26 20:18:47,040] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:18:47,042] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [37.0, 45.83333333333334, 1.0, 2.0, 0.6278979410012889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 877463.6363571997, 877463.6363572004, 206055.7261495886]
[2019-03-26 20:18:47,043] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:18:47,047] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.7246073e-22 1.0000000e+00 7.9485065e-20 2.7436044e-17 1.2893414e-22], sampled 0.6440429730262315
[2019-03-26 20:19:10,246] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:19:10,246] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.827658375, 73.53191422500001, 1.0, 2.0, 0.5730481838406154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 800784.2791345918, 800784.2791345918, 195833.1208620231]
[2019-03-26 20:19:10,249] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:19:10,252] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.5224211e-22 1.0000000e+00 1.0780925e-19 3.0664618e-17 1.3779895e-22], sampled 0.8746839475186486
[2019-03-26 20:19:16,904] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:19:16,906] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.65, 91.5, 1.0, 2.0, 0.5785051141166306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 808412.7596693789, 808412.7596693783, 196806.6259450491]
[2019-03-26 20:19:16,907] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:19:16,910] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2125661e-20 1.0000000e+00 1.3492842e-18 1.4929022e-16 1.1871091e-21], sampled 0.10324505735216172
[2019-03-26 20:19:20,106] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:19:20,109] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.73333333333333, 80.0, 1.0, 2.0, 0.5563239753437872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777405.1208294409, 777405.1208294409, 192890.7876320588]
[2019-03-26 20:19:20,111] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:19:20,113] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1956806e-21 1.0000000e+00 1.2691941e-19 3.7303159e-17 1.5954011e-22], sampled 0.7566704398940585
[2019-03-26 20:19:39,107] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:19:39,107] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.96666666666667, 64.66666666666667, 1.0, 2.0, 0.7150197493143149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 999270.3475010657, 999270.3475010657, 224123.0801190432]
[2019-03-26 20:19:39,108] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:19:39,111] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1111618e-18 1.0000000e+00 7.1038642e-17 4.7261012e-15 6.5157547e-20], sampled 0.3527446698744964
[2019-03-26 20:19:40,017] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:19:40,017] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.51666666666667, 94.16666666666667, 1.0, 2.0, 0.5476631611930595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 767961.4259707705, 767961.4259707705, 191739.8831565204]
[2019-03-26 20:19:40,019] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:19:40,023] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.9267928e-20 1.0000000e+00 3.4679481e-18 3.4674358e-16 3.1140204e-21], sampled 0.0726899358903692
[2019-03-26 20:19:42,235] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:19:42,238] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.76666666666667, 67.66666666666666, 1.0, 2.0, 0.3253391312090933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 513155.9957480194, 513155.9957480188, 167997.6534938914]
[2019-03-26 20:19:42,241] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:19:42,243] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0008185e-19 1.0000000e+00 6.9957535e-18 1.0078546e-15 1.4916866e-20], sampled 0.5673495549182103
[2019-03-26 20:19:43,213] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:19:43,215] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.1, 65.0, 1.0, 2.0, 0.3394130226934388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 536513.4856379686, 536513.485637968, 169846.4697669005]
[2019-03-26 20:19:43,217] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:19:43,218] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.4043386e-20 1.0000000e+00 2.2344082e-18 3.3866217e-16 3.3958628e-21], sampled 0.5322488525697674
[2019-03-26 20:19:43,367] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 20:19:43,381] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 20:19:43,440] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6842 2927317744.9770 1338.0000
[2019-03-26 20:19:43,442] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1685 3164067279.4129 1778.0000
[2019-03-26 20:19:43,504] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5752 2842451949.6408 1131.0000
[2019-03-26 20:19:44,521] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 650000, evaluation results [650000.0, 7884.168455680242, 3164067279.4128904, 1778.0, 8253.684239900658, 2927317744.977035, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8497.575228127671, 2842451949.640752, 1131.0]
[2019-03-26 20:19:56,242] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0918760e-20 1.0000000e+00 4.7996948e-18 1.1061936e-16 7.5189482e-21], sum to 1.0000
[2019-03-26 20:19:56,252] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3488
[2019-03-26 20:19:56,258] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.96666666666667, 62.66666666666667, 1.0, 2.0, 0.2497542569032178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 411159.580403137, 411159.5804031377, 160874.469992949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 670800.0000, 
sim time next is 671400.0000, 
raw observation next is [22.75, 64.0, 1.0, 2.0, 0.2477770852107169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 407900.3416524674, 407900.341652468, 160680.6588433189], 
processed observation next is [1.0, 0.782608695652174, 0.27725118483412325, 0.64, 1.0, 1.0, 0.09370733157917698, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11330565045901872, 0.1133056504590189, 0.23982187887062523], 
reward next is 0.7602, 
noisyNet noise sample is [array([-0.98197263], dtype=float32), 0.8294206]. 
=============================================
[2019-03-26 20:19:58,366] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7411744e-19 1.0000000e+00 2.1754508e-17 1.0198010e-15 2.8436356e-20], sum to 1.0000
[2019-03-26 20:19:58,373] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1933
[2019-03-26 20:19:58,379] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.26666666666667, 83.66666666666667, 1.0, 2.0, 0.2273105243081364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 377038.4691451734, 377038.4691451727, 158558.7234487081], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 714000.0000, 
sim time next is 714600.0000, 
raw observation next is [19.5, 82.5, 1.0, 2.0, 0.2281350297106171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 378105.1292275349, 378105.1292275355, 158669.3260739864], 
processed observation next is [1.0, 0.2608695652173913, 0.12322274881516594, 0.825, 1.0, 1.0, 0.07004220447062301, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10502920256320415, 0.1050292025632043, 0.23681988966266626], 
reward next is 0.7632, 
noisyNet noise sample is [array([-0.07748201], dtype=float32), 0.3442041]. 
=============================================
[2019-03-26 20:20:14,253] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5070226e-19 1.0000000e+00 3.2954727e-17 1.8180059e-15 6.2743207e-20], sum to 1.0000
[2019-03-26 20:20:14,263] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8170
[2019-03-26 20:20:14,272] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 93.0, 1.0, 2.0, 0.3292132708040946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 510337.8854934814, 510337.8854934814, 167546.445712559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 972600.0000, 
sim time next is 973200.0000, 
raw observation next is [21.9, 93.0, 1.0, 2.0, 0.3282851924684677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 508893.8120397911, 508893.8120397917, 167434.2684789953], 
processed observation next is [1.0, 0.2608695652173913, 0.23696682464454974, 0.93, 1.0, 1.0, 0.19070505116682857, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1413593922332753, 0.14135939223327548, 0.2499018932522318], 
reward next is 0.7501, 
noisyNet noise sample is [array([-0.02413815], dtype=float32), 0.5536521]. 
=============================================
[2019-03-26 20:20:18,588] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.9394270e-20 1.0000000e+00 8.8018914e-19 3.9889677e-17 2.6022769e-22], sum to 1.0000
[2019-03-26 20:20:18,590] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8443
[2019-03-26 20:20:18,598] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666666, 97.16666666666667, 1.0, 2.0, 0.3735297665692196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 565849.4265649362, 565849.4265649356, 171724.4730006552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1036200.0000, 
sim time next is 1036800.0000, 
raw observation next is [22.2, 97.0, 1.0, 2.0, 0.3745609537191627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 567166.5495109085, 567166.5495109091, 171831.886341989], 
processed observation next is [1.0, 0.0, 0.2511848341232228, 0.97, 1.0, 1.0, 0.24645898038453337, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15754626375303016, 0.15754626375303032, 0.2564655020029687], 
reward next is 0.7435, 
noisyNet noise sample is [array([0.5430142], dtype=float32), -0.1781289]. 
=============================================
[2019-03-26 20:20:26,612] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.8569214e-22 1.0000000e+00 9.2799222e-20 6.1568476e-17 3.5243140e-22], sum to 1.0000
[2019-03-26 20:20:26,621] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8043
[2019-03-26 20:20:26,624] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 57.5, 1.0, 2.0, 0.8694337795922499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1338358.83683975, 1338358.836839749, 278471.2090432497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1182600.0000, 
sim time next is 1183200.0000, 
raw observation next is [27.6, 57.33333333333334, 1.0, 2.0, 0.8756463434796307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1349039.152794541, 1349039.152794542, 280439.4418665444], 
processed observation next is [1.0, 0.6956521739130435, 0.5071090047393366, 0.5733333333333335, 1.0, 1.0, 0.8501763174453382, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.37473309799848364, 0.3747330979984839, 0.41856633114409614], 
reward next is 0.5814, 
noisyNet noise sample is [array([0.4341277], dtype=float32), -0.22970654]. 
=============================================
[2019-03-26 20:20:26,765] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7966888e-22 1.0000000e+00 3.4648635e-20 9.8078441e-18 1.1588795e-22], sum to 1.0000
[2019-03-26 20:20:26,775] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1322
[2019-03-26 20:20:26,780] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 57.16666666666666, 1.0, 2.0, 0.8749218469490505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1349022.648056325, 1349022.648056325, 280355.8618688554], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1183800.0000, 
sim time next is 1184400.0000, 
raw observation next is [27.6, 57.0, 1.0, 2.0, 0.8641109400539346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1333435.593337787, 1333435.593337787, 277297.3716745664], 
processed observation next is [1.0, 0.7391304347826086, 0.5071090047393366, 0.57, 1.0, 1.0, 0.8362782410288369, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3703987759271631, 0.3703987759271631, 0.4138766741411439], 
reward next is 0.5861, 
noisyNet noise sample is [array([0.9465154], dtype=float32), 0.702228]. 
=============================================
[2019-03-26 20:20:39,169] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 20:20:39,172] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:20:39,174] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:20:39,178] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:20:39,179] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:20:39,181] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:20:39,183] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:20:39,183] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:20:39,183] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:20:39,185] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:20:39,188] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:20:39,201] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run28
[2019-03-26 20:20:39,221] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run28
[2019-03-26 20:20:39,240] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run28
[2019-03-26 20:20:39,259] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run28
[2019-03-26 20:20:39,260] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run28
[2019-03-26 20:20:44,287] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07195614], dtype=float32), 0.067729115]
[2019-03-26 20:20:44,289] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [20.7, 80.0, 1.0, 2.0, 0.2603187166191264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 427142.9310148385, 427142.9310148379, 161945.1865026677]
[2019-03-26 20:20:44,291] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:20:44,294] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.7520686e-18 1.0000000e+00 1.4148431e-16 8.1209267e-15 2.2168412e-19], sampled 0.48899079902276066
[2019-03-26 20:20:58,856] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07195614], dtype=float32), 0.067729115]
[2019-03-26 20:20:58,857] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.55, 35.5, 1.0, 2.0, 0.3503617765224989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 581611.5942867066, 581611.5942867066, 172337.7319400003]
[2019-03-26 20:20:58,858] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:20:58,860] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.4697394e-19 1.0000000e+00 4.0429227e-17 3.8955121e-15 9.7282799e-20], sampled 0.15063038698433906
[2019-03-26 20:22:10,411] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07195614], dtype=float32), 0.067729115]
[2019-03-26 20:22:10,412] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.50837848, 63.42974886666667, 1.0, 2.0, 0.5812164266060625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 812203.0418758553, 812203.0418758553, 197298.3995771476]
[2019-03-26 20:22:10,414] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:22:10,416] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.7658257e-21 1.0000000e+00 3.9050708e-19 9.7899446e-17 7.0800935e-22], sampled 0.3302080731037086
[2019-03-26 20:22:33,426] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.9845 2842525325.0091 1131.0000
[2019-03-26 20:22:33,428] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 20:22:33,776] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9775 2779206587.5399 933.0000
[2019-03-26 20:22:33,831] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4154 3164065956.6075 1778.0000
[2019-03-26 20:22:33,864] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.8487 2927414887.4755 1338.0000
[2019-03-26 20:22:34,877] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 675000, evaluation results [675000.0, 7883.415429619458, 3164065956.607484, 1778.0, 8252.84871800047, 2927414887.475508, 1338.0, 8659.977453803283, 2779206587.539943, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8495.984537277802, 2842525325.009142, 1131.0]
[2019-03-26 20:22:35,189] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.2852233e-19 1.0000000e+00 1.7613776e-17 3.5876462e-15 9.6375944e-21], sum to 1.0000
[2019-03-26 20:22:35,197] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2467
[2019-03-26 20:22:35,204] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.56666666666667, 98.0, 1.0, 2.0, 0.3146155162227376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 497157.3719752533, 497157.3719752527, 166806.0286991008], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1399200.0000, 
sim time next is 1399800.0000, 
raw observation next is [20.58333333333334, 98.0, 1.0, 2.0, 0.3146256245799867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 496975.2427550306, 496975.2427550299, 166788.3153678298], 
processed observation next is [0.0, 0.17391304347826086, 0.17456556082148533, 0.98, 1.0, 1.0, 0.17424774045781533, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13804867854306405, 0.13804867854306385, 0.24893778413108927], 
reward next is 0.7511, 
noisyNet noise sample is [array([0.7453191], dtype=float32), 1.874499]. 
=============================================
[2019-03-26 20:22:35,764] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3905927e-20 1.0000000e+00 4.9770523e-18 1.0193188e-15 1.1109186e-21], sum to 1.0000
[2019-03-26 20:22:35,774] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4637
[2019-03-26 20:22:35,780] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.46666666666667, 88.33333333333334, 1.0, 2.0, 0.3838733222462882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 576914.3328353864, 576914.3328353864, 172560.3639169473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1420800.0000, 
sim time next is 1421400.0000, 
raw observation next is [23.33333333333333, 88.16666666666667, 1.0, 2.0, 0.3777673281179953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 570617.3028294251, 570617.3028294244, 172091.4384280974], 
processed observation next is [0.0, 0.43478260869565216, 0.30489731437598716, 0.8816666666666667, 1.0, 1.0, 0.25032208206987383, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15850480634150696, 0.15850480634150677, 0.2568528931762648], 
reward next is 0.7431, 
noisyNet noise sample is [array([0.030476], dtype=float32), -1.1855526]. 
=============================================
[2019-03-26 20:22:40,616] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.9226983e-20 1.0000000e+00 1.4287378e-17 6.2615894e-16 1.5989967e-21], sum to 1.0000
[2019-03-26 20:22:40,628] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0170
[2019-03-26 20:22:40,632] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.85, 97.0, 1.0, 2.0, 0.317154963496824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 499638.4752906411, 499638.4752906417, 166958.1857657255], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1488600.0000, 
sim time next is 1489200.0000, 
raw observation next is [21.06666666666667, 96.33333333333334, 1.0, 2.0, 0.3211144020052021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 504130.2420193978, 504130.2420193972, 167255.4211590555], 
processed observation next is [0.0, 0.21739130434782608, 0.19747235387045833, 0.9633333333333334, 1.0, 1.0, 0.18206554458458082, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14003617833872162, 0.14003617833872145, 0.24963495695381416], 
reward next is 0.7504, 
noisyNet noise sample is [array([0.07952274], dtype=float32), 0.091851585]. 
=============================================
[2019-03-26 20:22:41,352] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0011168e-18 1.0000000e+00 1.3498873e-17 1.8699002e-15 4.4643073e-20], sum to 1.0000
[2019-03-26 20:22:41,360] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8005
[2019-03-26 20:22:41,365] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 51.0, 1.0, 2.0, 0.3428707597271431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527662.0149253301, 527662.0149253301, 168795.5129784984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1510800.0000, 
sim time next is 1511400.0000, 
raw observation next is [29.05, 51.0, 1.0, 2.0, 0.3449039851276267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 530137.3790334774, 530137.3790334767, 168974.470872795], 
processed observation next is [0.0, 0.4782608695652174, 0.575829383886256, 0.51, 1.0, 1.0, 0.21072769292485147, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14726038306485484, 0.14726038306485464, 0.25220070279521645], 
reward next is 0.7478, 
noisyNet noise sample is [array([1.0525995], dtype=float32), 0.56776625]. 
=============================================
[2019-03-26 20:22:49,903] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.1682051e-20 1.0000000e+00 5.4564725e-18 1.6585682e-15 1.2083733e-20], sum to 1.0000
[2019-03-26 20:22:49,913] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0134
[2019-03-26 20:22:49,917] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 89.33333333333334, 1.0, 2.0, 0.457008147605568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 650229.9721294543, 650229.9721294548, 178634.0645105311], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1892400.0000, 
sim time next is 1893000.0000, 
raw observation next is [24.76666666666667, 89.66666666666666, 1.0, 2.0, 0.4555482627739102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 648744.9343583201, 648744.9343583207, 178495.5949080214], 
processed observation next is [1.0, 0.9130434782608695, 0.3728278041074251, 0.8966666666666666, 1.0, 1.0, 0.3440340515348316, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18020692621064446, 0.18020692621064463, 0.266411335683614], 
reward next is 0.7336, 
noisyNet noise sample is [array([-1.3719623], dtype=float32), 0.016357591]. 
=============================================
[2019-03-26 20:22:49,935] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[78.01075 ]
 [77.80507 ]
 [77.581375]
 [77.23268 ]
 [76.74812 ]], R is [[78.12641144]
 [78.07852936]
 [78.03111267]
 [77.98397064]
 [77.93676758]].
[2019-03-26 20:22:58,851] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.9833544e-20 1.0000000e+00 1.7051291e-17 1.5504559e-15 6.6134637e-21], sum to 1.0000
[2019-03-26 20:22:58,860] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5297
[2019-03-26 20:22:58,873] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.8, 74.83333333333334, 1.0, 2.0, 0.5460826286472423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 763088.7591808831, 763088.7591808836, 191132.0399709794], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2112600.0000, 
sim time next is 2113200.0000, 
raw observation next is [30.0, 74.0, 1.0, 2.0, 0.5477626437469091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 765437.2362863581, 765437.2362863588, 191418.6536162527], 
processed observation next is [0.0, 0.4782608695652174, 0.6208530805687204, 0.74, 1.0, 1.0, 0.45513571535772174, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21262145452398837, 0.21262145452398856, 0.2856994830093324], 
reward next is 0.7143, 
noisyNet noise sample is [array([0.410632], dtype=float32), 0.55254024]. 
=============================================
[2019-03-26 20:22:59,368] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6666777e-18 1.0000000e+00 1.7830591e-16 5.4696517e-15 4.7453129e-19], sum to 1.0000
[2019-03-26 20:22:59,381] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6417
[2019-03-26 20:22:59,386] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 94.0, 1.0, 2.0, 0.3456426327659531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 535458.5648562041, 535458.5648562048, 169532.0914627482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1818000.0000, 
sim time next is 1818600.0000, 
raw observation next is [21.83333333333334, 93.83333333333334, 1.0, 2.0, 0.3459735753827479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 535856.5860672527, 535856.5860672527, 169561.2748346665], 
processed observation next is [1.0, 0.043478260869565216, 0.23380726698262277, 0.9383333333333335, 1.0, 1.0, 0.21201635588282883, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14884905168534796, 0.14884905168534796, 0.25307652960397986], 
reward next is 0.7469, 
noisyNet noise sample is [array([1.0756241], dtype=float32), -0.40025446]. 
=============================================
[2019-03-26 20:23:00,466] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9433898e-20 1.0000000e+00 2.3671465e-18 3.3045254e-16 2.3064055e-21], sum to 1.0000
[2019-03-26 20:23:00,472] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1707
[2019-03-26 20:23:00,478] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.2, 79.5, 1.0, 2.0, 0.5599434419713749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 782464.8134040869, 782464.8134040869, 193520.9843603424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2140200.0000, 
sim time next is 2140800.0000, 
raw observation next is [29.03333333333333, 80.33333333333333, 1.0, 2.0, 0.5604960811354082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 783237.3559466929, 783237.3559466923, 193617.3095072526], 
processed observation next is [0.0, 0.782608695652174, 0.5750394944707741, 0.8033333333333332, 1.0, 1.0, 0.4704772061872387, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2175659322074147, 0.21756593220741452, 0.28898105896604864], 
reward next is 0.7110, 
noisyNet noise sample is [array([0.34867355], dtype=float32), -0.18458553]. 
=============================================
[2019-03-26 20:23:03,798] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.3021637e-20 1.0000000e+00 4.8640404e-18 2.3469004e-16 3.1776702e-20], sum to 1.0000
[2019-03-26 20:23:03,806] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8243
[2019-03-26 20:23:03,810] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.03333333333333, 88.33333333333334, 1.0, 2.0, 0.4619212663082412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 655440.5529497884, 655440.5529497884, 179131.7906215914], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1890600.0000, 
sim time next is 1891200.0000, 
raw observation next is [24.96666666666667, 88.66666666666667, 1.0, 2.0, 0.4590128919104424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 651900.7031326913, 651900.703132692, 178778.1598062251], 
processed observation next is [1.0, 0.9130434782608695, 0.3823064770932071, 0.8866666666666667, 1.0, 1.0, 0.3482083035065572, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1810835286479698, 0.18108352864797, 0.2668330743376494], 
reward next is 0.7332, 
noisyNet noise sample is [array([0.35430974], dtype=float32), 1.0687618]. 
=============================================
[2019-03-26 20:23:05,050] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1185155e-20 1.0000000e+00 1.1786149e-17 2.5683887e-16 1.1795306e-20], sum to 1.0000
[2019-03-26 20:23:05,060] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4385
[2019-03-26 20:23:05,067] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 94.0, 1.0, 2.0, 0.5033578552556454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 703365.9504080118, 703365.9504080118, 184124.0527852743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2025600.0000, 
sim time next is 2026200.0000, 
raw observation next is [25.5, 94.0, 1.0, 2.0, 0.5029984965547285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 702863.6352198946, 702863.6352198952, 184067.4316723697], 
processed observation next is [0.0, 0.43478260869565216, 0.40758293838862564, 0.94, 1.0, 1.0, 0.4012030078972632, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19523989867219294, 0.1952398986721931, 0.2747275099587608], 
reward next is 0.7253, 
noisyNet noise sample is [array([0.00287518], dtype=float32), -1.1802461]. 
=============================================
[2019-03-26 20:23:06,456] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.3088362e-18 1.0000000e+00 7.7041445e-17 1.7103596e-14 7.6541581e-20], sum to 1.0000
[2019-03-26 20:23:06,468] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8765
[2019-03-26 20:23:06,473] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 82.33333333333334, 1.0, 2.0, 0.944622855265667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1351154.575088492, 1351154.575088492, 287167.0202374759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1932000.0000, 
sim time next is 1932600.0000, 
raw observation next is [25.75, 82.16666666666667, 1.0, 2.0, 0.9591499955711602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1370467.644170956, 1370467.644170956, 291273.3067042731], 
processed observation next is [1.0, 0.34782608695652173, 0.41943127962085314, 0.8216666666666668, 1.0, 1.0, 0.9507831271941689, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.38068545671415444, 0.38068545671415444, 0.43473627866309417], 
reward next is 0.5653, 
noisyNet noise sample is [array([0.61084217], dtype=float32), 0.4642914]. 
=============================================
[2019-03-26 20:23:07,387] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7829776e-15 1.0000000e+00 8.7952513e-14 3.7777186e-12 1.1750875e-15], sum to 1.0000
[2019-03-26 20:23:07,396] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0301
[2019-03-26 20:23:07,403] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 88.0, 1.0, 2.0, 0.5436671798572236, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9226020525646972, 6.911199999999999, 6.9112, 168.9126598470645, 1563383.838635537, 1563383.838635537, 331620.9279000681], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1962000.0000, 
sim time next is 1962600.0000, 
raw observation next is [24.5, 88.33333333333334, 1.0, 2.0, 0.541128356334343, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9129564363528, 782400.6616864445, 782400.6616864452, 193620.2572637955], 
processed observation next is [1.0, 0.7391304347826086, 0.3601895734597157, 0.8833333333333334, 1.0, 1.0, 0.4471425979931843, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399447885448, 0.21733351713512347, 0.21733351713512367, 0.2889854586026799], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7749622], dtype=float32), -1.4737036]. 
=============================================
[2019-03-26 20:23:11,826] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.39257084e-19 1.00000000e+00 1.33089721e-17 1.81294316e-15
 1.21107295e-20], sum to 1.0000
[2019-03-26 20:23:11,836] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4314
[2019-03-26 20:23:11,842] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 85.33333333333334, 1.0, 2.0, 0.7423467209443687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1037479.601694007, 1037479.601694007, 230251.8085865166], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2445600.0000, 
sim time next is 2446200.0000, 
raw observation next is [27.7, 85.5, 1.0, 2.0, 0.7473744893047615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1044509.702720558, 1044509.702720558, 231403.9013687684], 
processed observation next is [1.0, 0.30434782608695654, 0.5118483412322274, 0.855, 1.0, 1.0, 0.6956319148250139, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2901415840890439, 0.2901415840890439, 0.3453789572668185], 
reward next is 0.6546, 
noisyNet noise sample is [array([0.13300699], dtype=float32), 1.0920615]. 
=============================================
[2019-03-26 20:23:15,280] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.477268e-13 1.000000e+00 3.054963e-12 4.972110e-10 5.847146e-14], sum to 1.0000
[2019-03-26 20:23:15,292] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7414
[2019-03-26 20:23:15,301] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2095324.672608743 W.
[2019-03-26 20:23:15,304] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.4, 72.0, 1.0, 2.0, 0.857339056637522, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.001758704607475, 6.9112, 168.9124175138631, 2095324.672608743, 2031079.415775619, 422653.8384390911], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2200800.0000, 
sim time next is 2201400.0000, 
raw observation next is [30.5, 71.5, 1.0, 2.0, 0.7054687864135881, 1.0, 1.0, 0.7054687864135881, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1972731.02294334, 1972731.02294334, 376477.7497993315], 
processed observation next is [1.0, 0.4782608695652174, 0.6445497630331753, 0.715, 1.0, 1.0, 0.6451431161609495, 1.0, 0.5, 0.6451431161609495, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5479808397064834, 0.5479808397064834, 0.5619070892527336], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.53695285], dtype=float32), 0.880138]. 
=============================================
[2019-03-26 20:23:20,875] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1437823e-18 1.0000000e+00 3.5223471e-17 9.5822322e-15 4.0773795e-19], sum to 1.0000
[2019-03-26 20:23:20,884] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1457
[2019-03-26 20:23:20,895] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2058183.014306735 W.
[2019-03-26 20:23:20,904] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.7, 80.0, 1.0, 2.0, 0.8308020888640424, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.992143855976874, 6.9112, 168.9115868268401, 2058183.014306735, 2000759.1226476, 416112.479292169], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2191200.0000, 
sim time next is 2191800.0000, 
raw observation next is [28.8, 79.5, 1.0, 2.0, 0.4613205023119524, 1.0, 1.0, 0.4613205023119524, 1.0, 2.0, 0.7969343309027064, 6.9112, 6.9112, 170.5573041426782, 1934979.828179007, 1934979.828179007, 388732.8074586079], 
processed observation next is [1.0, 0.34782608695652173, 0.5639810426540285, 0.795, 1.0, 1.0, 0.3509885570023523, 1.0, 0.5, 0.3509885570023523, 1.0, 1.0, 0.7523589401252517, 0.0, 0.0, 0.8375144448122397, 0.5374943967163908, 0.5374943967163908, 0.5801982200874745], 
reward next is 0.4198, 
noisyNet noise sample is [array([0.26903498], dtype=float32), 0.170839]. 
=============================================
[2019-03-26 20:23:23,182] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1568187e-16 1.0000000e+00 5.7614338e-15 5.1738583e-13 2.1156023e-16], sum to 1.0000
[2019-03-26 20:23:23,191] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6671
[2019-03-26 20:23:23,197] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.05, 75.33333333333333, 1.0, 2.0, 0.5553783215004101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 776083.1847961639, 776083.1847961632, 192728.4417279382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2227800.0000, 
sim time next is 2228400.0000, 
raw observation next is [29.9, 76.0, 1.0, 2.0, 0.5557608008668448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 776617.8551437154, 776617.8551437147, 192794.5471801717], 
processed observation next is [1.0, 0.8260869565217391, 0.6161137440758293, 0.76, 1.0, 1.0, 0.4647720492371623, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21572718198436538, 0.2157271819843652, 0.2877530554927936], 
reward next is 0.7122, 
noisyNet noise sample is [array([-0.88002706], dtype=float32), 0.79500324]. 
=============================================
[2019-03-26 20:23:23,403] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2730755e-12 1.0000000e+00 1.6854938e-11 1.4877937e-09 1.8159386e-13], sum to 1.0000
[2019-03-26 20:23:23,411] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7411
[2019-03-26 20:23:23,418] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.13333333333333, 70.66666666666667, 1.0, 2.0, 0.5390484969802792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 753255.869906509, 753255.869906509, 189943.1877000899], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2223600.0000, 
sim time next is 2224200.0000, 
raw observation next is [30.96666666666667, 71.33333333333333, 1.0, 2.0, 0.548377951945325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 766297.3710551489, 766297.3710551496, 191525.0280133157], 
processed observation next is [1.0, 0.7391304347826086, 0.6666666666666667, 0.7133333333333333, 1.0, 1.0, 0.45587705053653615, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21286038084865247, 0.21286038084865266, 0.2858582507661428], 
reward next is 0.7141, 
noisyNet noise sample is [array([1.3736261], dtype=float32), -1.5131361]. 
=============================================
[2019-03-26 20:23:29,567] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1073784e-19 1.0000000e+00 3.3699312e-17 1.6831902e-15 2.5765873e-20], sum to 1.0000
[2019-03-26 20:23:29,576] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8924
[2019-03-26 20:23:29,584] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3927254813660197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 586005.8747645393, 586005.87476454, 173252.3685203411], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2742600.0000, 
sim time next is 2743200.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3900876994207442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 582070.2072966028, 582070.2072966034, 172894.7167615541], 
processed observation next is [0.0, 0.782608695652174, 0.28909952606635075, 0.94, 1.0, 1.0, 0.2651659029165593, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16168616869350078, 0.16168616869350094, 0.25805181606202104], 
reward next is 0.7419, 
noisyNet noise sample is [array([-0.13289417], dtype=float32), 0.9987277]. 
=============================================
[2019-03-26 20:23:30,162] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 20:23:30,167] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:23:30,168] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:23:30,169] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:23:30,170] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:23:30,171] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:23:30,174] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:23:30,174] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:23:30,175] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:23:30,175] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:23:30,177] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:23:30,186] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run29
[2019-03-26 20:23:30,205] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run29
[2019-03-26 20:23:30,225] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run29
[2019-03-26 20:23:30,225] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run29
[2019-03-26 20:23:30,261] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run29
[2019-03-26 20:23:31,787] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06860191], dtype=float32), 0.064220235]
[2019-03-26 20:23:31,789] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.4, 57.5, 1.0, 2.0, 0.7799282521055937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1099686.960818262, 1099686.960818262, 240389.2996133573]
[2019-03-26 20:23:31,790] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:23:31,793] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.0213503e-19 1.0000000e+00 1.9432223e-17 2.7615099e-15 3.9685172e-20], sampled 0.3385428521787355
[2019-03-26 20:23:37,402] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06860191], dtype=float32), 0.064220235]
[2019-03-26 20:23:37,404] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [19.6, 85.0, 1.0, 2.0, 0.2386394219171848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 393702.6486954252, 393702.6486954258, 159774.2805548117]
[2019-03-26 20:23:37,407] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:23:37,414] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0956519e-17 1.0000000e+00 4.4185378e-16 3.8675070e-14 1.1942510e-18], sampled 0.3690487953400763
[2019-03-26 20:24:19,324] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06860191], dtype=float32), 0.064220235]
[2019-03-26 20:24:19,325] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.0, 84.0, 1.0, 2.0, 0.480380665497935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 671375.1440546975, 671375.1440546975, 180595.003021988]
[2019-03-26 20:24:19,326] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:24:19,328] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0951249e-18 1.0000000e+00 5.5718257e-17 8.8290479e-15 1.4164988e-19], sampled 0.9769729965679012
[2019-03-26 20:24:28,842] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06860191], dtype=float32), 0.064220235]
[2019-03-26 20:24:28,844] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [37.4, 45.16666666666666, 1.0, 2.0, 0.5999824695197342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 838437.4225132655, 838437.4225132655, 200742.1465859236]
[2019-03-26 20:24:28,845] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:24:28,847] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.3657888e-20 1.0000000e+00 3.2025472e-18 8.4975478e-16 8.7538319e-21], sampled 0.16705815553281023
[2019-03-26 20:24:31,189] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06860191], dtype=float32), 0.064220235]
[2019-03-26 20:24:31,191] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.174585855, 89.05717415000001, 1.0, 2.0, 0.5601533157468664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 782758.1990237217, 782758.1990237217, 193556.0707636568]
[2019-03-26 20:24:31,192] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:24:31,195] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.0431855e-20 1.0000000e+00 1.6933309e-18 4.8611888e-16 3.2809531e-21], sampled 0.20130818228238234
[2019-03-26 20:24:33,515] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06860191], dtype=float32), 0.064220235]
[2019-03-26 20:24:33,517] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.8, 62.0, 1.0, 2.0, 0.9248693100168514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1292722.510134276, 1292722.510134276, 276873.2374894047]
[2019-03-26 20:24:33,519] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:24:33,521] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.6101379e-20 1.0000000e+00 3.4717999e-18 6.7345107e-16 5.1238794e-21], sampled 0.2585339684772603
[2019-03-26 20:24:42,259] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06860191], dtype=float32), 0.064220235]
[2019-03-26 20:24:42,260] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.61135814, 72.69956687999999, 1.0, 2.0, 0.4865130600233059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 682627.5147455498, 682627.5147455498, 181870.9397436483]
[2019-03-26 20:24:42,261] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:24:42,264] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.593868e-20 1.000000e+00 3.563988e-18 9.150753e-16 8.140597e-21], sampled 0.4001000038328857
[2019-03-26 20:25:15,865] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06860191], dtype=float32), 0.064220235]
[2019-03-26 20:25:15,866] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.1, 75.5, 1.0, 2.0, 0.576615634214039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 805771.3672075102, 805771.3672075102, 196469.9242248872]
[2019-03-26 20:25:15,868] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:25:15,871] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.3306510e-20 1.0000000e+00 3.5913924e-18 1.0211596e-15 6.7736298e-21], sampled 0.4598552804849435
[2019-03-26 20:25:25,412] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 20:25:25,463] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4154 3163997799.2143 1778.0000
[2019-03-26 20:25:25,501] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.3130 3007656030.3370 1766.0000
[2019-03-26 20:25:25,688] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.1994 2779305917.2640 933.0000
[2019-03-26 20:25:25,691] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8494.5529 2842640641.5065 1131.0000
[2019-03-26 20:25:26,706] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 700000, evaluation results [700000.0, 7883.415429661524, 3163997799.214286, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8659.199368136167, 2779305917.264039, 933.0, 7998.312951428424, 3007656030.3370423, 1766.0, 8494.552924859718, 2842640641.5064535, 1131.0]
[2019-03-26 20:25:44,593] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.2189750e-19 1.0000000e+00 3.2959756e-17 6.7285820e-15 2.7917640e-20], sum to 1.0000
[2019-03-26 20:25:44,604] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9956
[2019-03-26 20:25:44,609] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 98.0, 1.0, 2.0, 0.3705931676615564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 561826.8458285144, 561826.8458285144, 171388.3369283464], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2758800.0000, 
sim time next is 2759400.0000, 
raw observation next is [22.0, 97.0, 1.0, 2.0, 0.3664723963152283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 557692.7297589987, 557692.7297589987, 171098.6210555367], 
processed observation next is [0.0, 0.9565217391304348, 0.2417061611374408, 0.97, 1.0, 1.0, 0.23671373050027508, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15491464715527742, 0.15491464715527742, 0.2553710762022936], 
reward next is 0.7446, 
noisyNet noise sample is [array([1.5279794], dtype=float32), 0.5820807]. 
=============================================
[2019-03-26 20:25:46,686] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.3143592e-18 1.0000000e+00 1.1904498e-16 7.2412515e-14 2.1303220e-19], sum to 1.0000
[2019-03-26 20:25:46,698] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2352
[2019-03-26 20:25:46,702] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3799617438694608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 585306.2526241723, 585306.2526241723, 173689.40024381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2793000.0000, 
sim time next is 2793600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3661254196985073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 563989.4557530059, 563989.4557530066, 171830.7491793997], 
processed observation next is [1.0, 0.34782608695652173, 0.2417061611374408, 0.94, 1.0, 1.0, 0.23629568638374374, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1566637377091683, 0.1566637377091685, 0.25646380474537267], 
reward next is 0.7435, 
noisyNet noise sample is [array([-0.9823428], dtype=float32), -0.91999]. 
=============================================
[2019-03-26 20:25:46,704] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2731080e-18 1.0000000e+00 7.6393480e-18 3.7912758e-15 1.4292597e-19], sum to 1.0000
[2019-03-26 20:25:46,713] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1705
[2019-03-26 20:25:46,720] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.4404975202183125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 632708.5283133048, 632708.5283133048, 177012.2143808495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2688600.0000, 
sim time next is 2689200.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.4399813768221698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 631967.518960236, 631967.5189602353, 176938.3436916701], 
processed observation next is [0.0, 0.13043478260869565, 0.3364928909952607, 0.94, 1.0, 1.0, 0.3252787672556263, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17554653304450998, 0.1755465330445098, 0.26408708013682103], 
reward next is 0.7359, 
noisyNet noise sample is [array([-1.1764823], dtype=float32), 1.0969821]. 
=============================================
[2019-03-26 20:25:50,333] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.2589583e-19 1.0000000e+00 5.7843086e-17 2.5077738e-15 3.8778586e-20], sum to 1.0000
[2019-03-26 20:25:50,341] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7713
[2019-03-26 20:25:50,348] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.5355604728846093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 841524.837482649, 841524.837482649, 200166.0786956559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2977200.0000, 
sim time next is 2977800.0000, 
raw observation next is [22.0, 88.00000000000001, 1.0, 2.0, 0.532402841094277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 836546.0507181135, 836546.0507181135, 199571.6985395206], 
processed observation next is [1.0, 0.4782608695652174, 0.2417061611374408, 0.8800000000000001, 1.0, 1.0, 0.4366299290292494, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23237390297725377, 0.23237390297725377, 0.2978682067754039], 
reward next is 0.7021, 
noisyNet noise sample is [array([-0.03881132], dtype=float32), -0.66461545]. 
=============================================
[2019-03-26 20:25:51,065] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6670901e-19 1.0000000e+00 2.7152736e-17 2.0331129e-15 2.1828043e-20], sum to 1.0000
[2019-03-26 20:25:51,072] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8540
[2019-03-26 20:25:51,077] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3466114755863642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 533945.5494993416, 533945.5494993416, 169321.0441365112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2763000.0000, 
sim time next is 2763600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.34953729368586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 538453.7168682074, 538453.7168682081, 169689.5798246755], 
processed observation next is [0.0, 1.0, 0.2417061611374408, 0.94, 1.0, 1.0, 0.2163099923926024, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1495704769078354, 0.1495704769078356, 0.2532680295890679], 
reward next is 0.7467, 
noisyNet noise sample is [array([1.6306918], dtype=float32), -0.8496112]. 
=============================================
[2019-03-26 20:25:59,328] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4215166e-18 1.0000000e+00 4.4000837e-17 3.5595641e-15 2.4495643e-19], sum to 1.0000
[2019-03-26 20:25:59,339] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3438
[2019-03-26 20:25:59,346] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.85, 89.5, 1.0, 2.0, 0.7060682241505758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1078598.675680693, 1078598.675680693, 233837.28362028], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2892600.0000, 
sim time next is 2893200.0000, 
raw observation next is [22.9, 89.33333333333333, 1.0, 2.0, 0.7267118807483757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1109168.379321267, 1109168.379321268, 238730.1906129474], 
processed observation next is [1.0, 0.4782608695652174, 0.2843601895734597, 0.8933333333333333, 1.0, 1.0, 0.6707372057209345, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.30810232758924083, 0.3081023275892411, 0.3563137173327573], 
reward next is 0.6437, 
noisyNet noise sample is [array([-0.93066853], dtype=float32), -0.73168826]. 
=============================================
[2019-03-26 20:26:00,728] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.5225853e-19 1.0000000e+00 1.2788377e-17 2.5191260e-15 2.3323302e-20], sum to 1.0000
[2019-03-26 20:26:00,736] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0271
[2019-03-26 20:26:00,739] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333334, 99.5, 1.0, 2.0, 0.3084631333891708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 490992.1554524192, 490992.1554524192, 166413.9369656206], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2923800.0000, 
sim time next is 2924400.0000, 
raw observation next is [20.16666666666667, 99.0, 1.0, 2.0, 0.308800462644727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 491248.2889387395, 491248.2889387395, 166428.6719962212], 
processed observation next is [1.0, 0.8695652173913043, 0.15481832543443946, 0.99, 1.0, 1.0, 0.16722947306593614, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13645785803853874, 0.13645785803853874, 0.24840100297943463], 
reward next is 0.7516, 
noisyNet noise sample is [array([-0.2425077], dtype=float32), -0.11085665]. 
=============================================
[2019-03-26 20:26:00,919] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8984053e-20 1.0000000e+00 8.6882122e-17 4.1834513e-16 1.9419078e-20], sum to 1.0000
[2019-03-26 20:26:00,931] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3613
[2019-03-26 20:26:00,935] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 97.0, 1.0, 2.0, 0.3315803871043239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 519262.2577181674, 519262.2577181674, 168389.7613645521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2917800.0000, 
sim time next is 2918400.0000, 
raw observation next is [21.0, 96.0, 1.0, 2.0, 0.327929369601104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515079.3029153354, 515079.3029153354, 168100.4300197184], 
processed observation next is [1.0, 0.782608695652174, 0.19431279620853087, 0.96, 1.0, 1.0, 0.1902763489169928, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14307758414314872, 0.14307758414314872, 0.2508961642085349], 
reward next is 0.7491, 
noisyNet noise sample is [array([0.7064229], dtype=float32), -1.3375759]. 
=============================================
[2019-03-26 20:26:02,934] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.3447125e-18 1.0000000e+00 1.5140537e-16 5.3120164e-15 2.1815568e-19], sum to 1.0000
[2019-03-26 20:26:02,944] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2925
[2019-03-26 20:26:02,952] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 96.0, 1.0, 2.0, 0.3134351607399103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 493290.6173517926, 493290.6173517926, 166472.5207403959], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2960400.0000, 
sim time next is 2961000.0000, 
raw observation next is [21.0, 97.0, 1.0, 2.0, 0.3152768574074239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 494738.7411713288, 494738.7411713288, 166542.4331262729], 
processed observation next is [1.0, 0.2608695652173913, 0.19431279620853087, 0.97, 1.0, 1.0, 0.17503235832219746, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1374274281031469, 0.1374274281031469, 0.24857079571085508], 
reward next is 0.7514, 
noisyNet noise sample is [array([2.6509068], dtype=float32), -0.3943558]. 
=============================================
[2019-03-26 20:26:02,966] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[69.43087 ]
 [69.396545]
 [69.351814]
 [69.33098 ]
 [69.320435]], R is [[69.51496124]
 [69.57134247]
 [69.6247406 ]
 [69.6807785 ]
 [69.73620605]].
[2019-03-26 20:26:06,976] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3481991e-17 1.0000000e+00 7.4761235e-16 1.6187006e-13 1.2866908e-18], sum to 1.0000
[2019-03-26 20:26:06,983] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8181
[2019-03-26 20:26:06,992] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3011493778918823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 479564.4341337842, 479564.4341337842, 165590.718614072], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3030600.0000, 
sim time next is 3031200.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3013590549690915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 479898.5322266188, 479898.5322266183, 165614.6233730871], 
processed observation next is [1.0, 0.08695652173913043, 0.1469194312796209, 1.0, 1.0, 1.0, 0.1582639216495078, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13330514784072744, 0.1333051478407273, 0.24718600503445834], 
reward next is 0.7528, 
noisyNet noise sample is [array([-0.08152001], dtype=float32), -2.3829494]. 
=============================================
[2019-03-26 20:26:07,604] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.3387991e-17 1.0000000e+00 6.0124611e-16 4.1514223e-14 7.7573375e-19], sum to 1.0000
[2019-03-26 20:26:07,614] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5272
[2019-03-26 20:26:07,619] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3136293636407088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 499421.3290167285, 499421.3290167285, 167037.5342275142], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3033000.0000, 
sim time next is 3033600.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3152831036555155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 502062.4358846961, 502062.4358846961, 167234.1481452631], 
processed observation next is [1.0, 0.08695652173913043, 0.1469194312796209, 1.0, 1.0, 1.0, 0.1750398839223078, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1394617877457489, 0.1394617877457489, 0.24960320618695986], 
reward next is 0.7504, 
noisyNet noise sample is [array([0.6852011], dtype=float32), -0.7510789]. 
=============================================
[2019-03-26 20:26:08,222] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.1725935e-18 1.0000000e+00 6.9159161e-17 4.9767370e-15 1.8521696e-19], sum to 1.0000
[2019-03-26 20:26:08,230] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7141
[2019-03-26 20:26:08,233] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.3408426909329262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 526683.8322111608, 526683.8322111614, 168784.6009892069], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3051600.0000, 
sim time next is 3052200.0000, 
raw observation next is [21.83333333333334, 95.0, 1.0, 2.0, 0.3557463601685748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 548977.406688696, 548977.4066886967, 170587.4430615893], 
processed observation next is [1.0, 0.30434782608695654, 0.23380726698262277, 0.95, 1.0, 1.0, 0.22379079538382507, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15249372408019332, 0.15249372408019352, 0.2546081239725213], 
reward next is 0.7454, 
noisyNet noise sample is [array([0.62117344], dtype=float32), 0.69859904]. 
=============================================
[2019-03-26 20:26:10,239] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.4451790e-19 1.0000000e+00 3.4544164e-17 4.4152352e-16 2.2613989e-21], sum to 1.0000
[2019-03-26 20:26:10,247] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8477
[2019-03-26 20:26:10,260] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 95.0, 1.0, 2.0, 0.5296480638879271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 787887.8744350799, 787887.8744350792, 194310.1199839892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3071400.0000, 
sim time next is 3072000.0000, 
raw observation next is [23.0, 96.0, 1.0, 2.0, 0.7583974758994021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1123210.192958733, 1123210.192958733, 242446.031017916], 
processed observation next is [1.0, 0.5652173913043478, 0.28909952606635075, 0.96, 1.0, 1.0, 0.7089126215655447, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31200283137742585, 0.31200283137742585, 0.3618597477879343], 
reward next is 0.6381, 
noisyNet noise sample is [array([0.09744447], dtype=float32), 0.26920715]. 
=============================================
[2019-03-26 20:26:10,285] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[76.10924 ]
 [76.0722  ]
 [76.043846]
 [75.99599 ]
 [75.92286 ]], R is [[76.07180023]
 [76.02106476]
 [75.98817444]
 [75.93483734]
 [75.88526154]].
[2019-03-26 20:26:12,043] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6480639e-19 1.0000000e+00 4.2747200e-19 1.4559686e-15 5.0162522e-21], sum to 1.0000
[2019-03-26 20:26:12,053] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0399
[2019-03-26 20:26:12,058] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 77.66666666666667, 1.0, 2.0, 0.5886233678286997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 822557.652259809, 822557.652259809, 198645.9138852008], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3343200.0000, 
sim time next is 3343800.0000, 
raw observation next is [30.16666666666666, 78.33333333333334, 1.0, 2.0, 0.5871957103560523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 820561.8358201879, 820561.8358201872, 198385.0043462438], 
processed observation next is [0.0, 0.6956521739130435, 0.6287519747235385, 0.7833333333333334, 1.0, 1.0, 0.5026454341639185, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22793384328338553, 0.22793384328338534, 0.2960970214123042], 
reward next is 0.7039, 
noisyNet noise sample is [array([0.36745527], dtype=float32), -0.7483659]. 
=============================================
[2019-03-26 20:26:16,022] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.2319643e-11 1.0000000e+00 1.1502387e-10 2.0181602e-08 5.3891969e-12], sum to 1.0000
[2019-03-26 20:26:16,031] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1031
[2019-03-26 20:26:16,040] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1876174.280225525 W.
[2019-03-26 20:26:16,044] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.4473128765836142, 1.0, 2.0, 0.4473128765836142, 1.0, 2.0, 0.7768345379969697, 6.9112, 6.9112, 170.5573041426782, 1876174.280225525, 1876174.280225525, 380625.2220435548], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3589200.0000, 
sim time next is 3589800.0000, 
raw observation next is [32.16666666666667, 66.33333333333334, 1.0, 2.0, 0.7506623875287941, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.005978403660233, 6.9112, 168.9123932092714, 1946025.776119699, 1878786.938775121, 396010.8894177899], 
processed observation next is [1.0, 0.5652173913043478, 0.7235387045813588, 0.6633333333333334, 1.0, 1.0, 0.6995932379864989, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.009477840366023305, 0.0, 0.8294371790857287, 0.5405627155888053, 0.5218852607708669, 0.5910610289817759], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3254756], dtype=float32), -0.74191]. 
=============================================
[2019-03-26 20:26:17,900] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7020122e-14 1.0000000e+00 2.5530855e-13 1.4017260e-10 2.0924001e-15], sum to 1.0000
[2019-03-26 20:26:17,908] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8156
[2019-03-26 20:26:17,916] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666667, 70.66666666666667, 1.0, 2.0, 0.5429697960851061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 758737.373915605, 758737.373915605, 190603.7892000405], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3435000.0000, 
sim time next is 3435600.0000, 
raw observation next is [30.33333333333334, 71.33333333333334, 1.0, 2.0, 0.5430648807823452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 758870.2912250569, 758870.2912250574, 190619.353949639], 
processed observation next is [1.0, 0.782608695652174, 0.6366508688783573, 0.7133333333333334, 1.0, 1.0, 0.4494757599787291, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21079730311807135, 0.21079730311807152, 0.284506498432297], 
reward next is 0.7155, 
noisyNet noise sample is [array([0.78341335], dtype=float32), 0.09501623]. 
=============================================
[2019-03-26 20:26:21,998] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 20:26:22,002] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:26:22,003] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:26:22,005] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:26:22,006] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:26:22,008] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:26:22,009] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:26:22,010] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:26:22,011] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:26:22,012] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:26:22,012] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:26:22,033] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run30
[2019-03-26 20:26:22,057] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run30
[2019-03-26 20:26:22,058] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run30
[2019-03-26 20:26:22,058] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run30
[2019-03-26 20:26:22,111] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run30
[2019-03-26 20:26:56,705] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07051379], dtype=float32), 0.06578362]
[2019-03-26 20:26:56,706] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.69305425, 69.67835767, 1.0, 2.0, 0.6782824107484248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 947905.4495306101, 947905.4495306101, 216229.0163539361]
[2019-03-26 20:26:56,707] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:26:56,709] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.9734403e-20 1.0000000e+00 1.6851985e-18 3.1686587e-16 2.5392732e-21], sampled 0.9200012568239189
[2019-03-26 20:26:58,895] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07051379], dtype=float32), 0.06578362]
[2019-03-26 20:26:58,896] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.63333333333333, 79.0, 1.0, 2.0, 0.637691972844985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 931838.3036698964, 931838.3036698964, 213215.6281650336]
[2019-03-26 20:26:58,896] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:26:58,899] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.9753225e-19 1.0000000e+00 1.8427910e-17 1.9796924e-15 2.2789886e-20], sampled 0.8164875630929845
[2019-03-26 20:27:00,414] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07051379], dtype=float32), 0.06578362]
[2019-03-26 20:27:00,416] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.1, 82.0, 1.0, 2.0, 0.8433519886899967, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.987767024817693, 6.9112, 168.9124386241294, 2075747.931680686, 2021428.815584054, 419505.3415509235]
[2019-03-26 20:27:00,417] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:27:00,419] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.1983527e-15 1.0000000e+00 2.3822520e-14 5.7139358e-12 5.3345743e-16], sampled 0.2650629312735697
[2019-03-26 20:27:00,420] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2075747.931680686 W.
[2019-03-26 20:27:34,460] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07051379], dtype=float32), 0.06578362]
[2019-03-26 20:27:34,461] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [37.2, 42.66666666666667, 1.0, 2.0, 1.009586306850093, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.000401068615696, 6.9112, 168.9123537440784, 2308419.881973157, 2245137.799656427, 466480.2283242022]
[2019-03-26 20:27:34,462] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:27:34,467] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.0475910e-13 1.0000000e+00 1.9534131e-12 1.6436390e-10 3.6513253e-14], sampled 0.08205236817114303
[2019-03-26 20:27:34,469] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2308419.881973157 W.
[2019-03-26 20:27:39,754] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07051379], dtype=float32), 0.06578362]
[2019-03-26 20:27:39,756] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.16666666666667, 69.5, 1.0, 2.0, 0.8944623320804566, 1.0, 2.0, 0.8944623320804566, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2501790.324053546, 2501790.324053545, 468480.1379034643]
[2019-03-26 20:27:39,758] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:27:39,760] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.4302056e-12 1.0000000e+00 3.8835293e-12 1.5854981e-09 2.4233987e-13], sampled 0.5227294804163694
[2019-03-26 20:27:39,761] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2501790.324053546 W.
[2019-03-26 20:28:09,588] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07051379], dtype=float32), 0.06578362]
[2019-03-26 20:28:09,589] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.94944702666667, 94.80241878, 1.0, 2.0, 0.3456252917432709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 551576.4898623539, 551576.4898623539, 171098.3832453467]
[2019-03-26 20:28:09,591] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:28:09,596] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.3361347e-18 1.0000000e+00 1.1584896e-16 7.8406545e-15 1.4202431e-19], sampled 0.20300548964559295
[2019-03-26 20:28:12,393] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07051379], dtype=float32), 0.06578362]
[2019-03-26 20:28:12,395] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.298544325, 72.76596982333334, 1.0, 2.0, 0.45453284065036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 648289.3485723737, 648289.3485723737, 178473.2462400253]
[2019-03-26 20:28:12,396] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:28:12,397] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.3656364e-19 1.0000000e+00 5.9557517e-18 1.1243688e-15 1.1341272e-20], sampled 0.004603624518687122
[2019-03-26 20:28:17,118] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.8169 3007629189.2715 1766.0000
[2019-03-26 20:28:17,402] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6703 2927361465.7317 1338.0000
[2019-03-26 20:28:17,444] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8356 2842522561.2823 1131.0000
[2019-03-26 20:28:17,578] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 20:28:17,585] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.2711 2779256177.9474 933.0000
[2019-03-26 20:28:18,600] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 725000, evaluation results [725000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8253.670307618522, 2927361465.731651, 1338.0, 8661.271088261434, 2779256177.947352, 933.0, 7996.81694110405, 3007629189.271529, 1766.0, 8496.835586979434, 2842522561.2823186, 1131.0]
[2019-03-26 20:28:22,953] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6112722e-15 1.0000000e+00 2.8039664e-14 1.2624890e-12 1.5463449e-15], sum to 1.0000
[2019-03-26 20:28:22,963] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4128
[2019-03-26 20:28:22,972] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2181538.103874469 W.
[2019-03-26 20:28:22,979] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.33333333333334, 68.66666666666667, 1.0, 2.0, 0.520042918733616, 1.0, 1.0, 0.520042918733616, 1.0, 2.0, 0.8976620619147561, 6.911200000000001, 6.9112, 170.5573041426782, 2181538.103874469, 2181538.103874468, 428248.2381265859], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3576000.0000, 
sim time next is 3576600.0000, 
raw observation next is [30.5, 68.0, 1.0, 2.0, 0.7755444742638068, 1.0, 2.0, 0.7755444742638068, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2168884.88508394, 2168884.885083939, 408138.5668309193], 
processed observation next is [1.0, 0.391304347826087, 0.6445497630331753, 0.68, 1.0, 1.0, 0.7295716557395262, 1.0, 1.0, 0.7295716557395262, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6024680236344278, 0.6024680236344275, 0.6091620400461482], 
reward next is 0.3908, 
noisyNet noise sample is [array([1.0173818], dtype=float32), -1.8006095]. 
=============================================
[2019-03-26 20:28:27,611] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.59126817e-17 1.00000000e+00 3.85005274e-16 1.06214645e-14
 9.38415932e-19], sum to 1.0000
[2019-03-26 20:28:27,620] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1223
[2019-03-26 20:28:27,623] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.7511585591953072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1073596.744355148, 1073596.744355148, 235529.3833489165], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3723600.0000, 
sim time next is 3724200.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.7120148643517216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1017636.38555769, 1017636.385557691, 226492.0396493571], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.74, 1.0, 1.0, 0.6530299570502669, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.282676773766025, 0.2826767737660253, 0.33804782037217473], 
reward next is 0.6620, 
noisyNet noise sample is [array([-1.337992], dtype=float32), 0.3795308]. 
=============================================
[2019-03-26 20:28:38,124] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9313347e-07 9.9998796e-01 3.6949726e-07 1.1440402e-05 4.0797804e-08], sum to 1.0000
[2019-03-26 20:28:38,134] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4475
[2019-03-26 20:28:38,141] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2995765.788038054 W.
[2019-03-26 20:28:38,146] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.0, 60.0, 1.0, 2.0, 0.7866350280206407, 1.0, 2.0, 0.713907553524583, 1.0, 2.0, 1.03, 7.005104564241957, 6.9112, 170.5573041426782, 2995765.788038054, 2928498.128878089, 550088.7375066765], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4030800.0000, 
sim time next is 4031400.0000, 
raw observation next is [34.0, 60.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.121743801388431, 6.9112, 170.5573041426782, 3060326.510999545, 2909505.421690744, 552549.0375043012], 
processed observation next is [1.0, 0.6521739130434783, 0.8104265402843602, 0.6, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.021054380138843067, 0.0, 0.8375144448122397, 0.8500906974998736, 0.8081959504696511, 0.8247000559765689], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05721994], dtype=float32), -0.3504978]. 
=============================================
[2019-03-26 20:28:43,502] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3248057e-07 9.9994397e-01 5.3816825e-07 5.5176923e-05 7.5134878e-08], sum to 1.0000
[2019-03-26 20:28:43,508] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4856
[2019-03-26 20:28:43,513] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3394976.818134333 W.
[2019-03-26 20:28:43,522] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.16666666666666, 66.5, 1.0, 2.0, 0.9766451445331129, 1.0, 2.0, 0.8089126117808191, 1.0, 2.0, 1.03, 7.005119555514479, 6.9112, 170.5573041426782, 3394976.818134333, 3327698.420116054, 622965.4380759565], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4117800.0000, 
sim time next is 4118400.0000, 
raw observation next is [35.0, 67.0, 1.0, 2.0, 0.9677778073302755, 1.0, 2.0, 0.8044789431794002, 1.0, 2.0, 1.03, 7.005118855692995, 6.9112, 170.5573041426782, 3376343.713939696, 3309065.817232014, 619264.420551235], 
processed observation next is [1.0, 0.6956521739130435, 0.8578199052132701, 0.67, 1.0, 1.0, 0.9611780811208139, 1.0, 1.0, 0.7644324616619279, 1.0, 1.0, 1.0365853658536586, 0.009391885569299508, 0.0, 0.8375144448122397, 0.9378732538721378, 0.919184949231115, 0.9242752545540821], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3864328], dtype=float32), -0.032998506]. 
=============================================
[2019-03-26 20:28:46,317] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.97158564e-20 1.00000000e+00 5.03348967e-19 1.06871325e-16
 2.61696176e-21], sum to 1.0000
[2019-03-26 20:28:46,326] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7412
[2019-03-26 20:28:46,333] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.0, 57.33333333333333, 1.0, 2.0, 0.6093395870336394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 851518.6419786054, 851518.6419786054, 202499.3785488599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3854400.0000, 
sim time next is 3855000.0000, 
raw observation next is [35.0, 56.66666666666667, 1.0, 2.0, 0.6045622374870508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 844839.9029176588, 844839.9029176594, 201599.4660853402], 
processed observation next is [0.0, 0.6086956521739131, 0.8578199052132701, 0.5666666666666668, 1.0, 1.0, 0.523568960827772, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23467775081046077, 0.23467775081046094, 0.3008947255005077], 
reward next is 0.6991, 
noisyNet noise sample is [array([0.7410016], dtype=float32), 0.059025142]. 
=============================================
[2019-03-26 20:28:46,345] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[76.24351 ]
 [76.215485]
 [76.202354]
 [76.16079 ]
 [76.10001 ]], R is [[76.1842804 ]
 [76.12020111]
 [76.05548096]
 [75.98982239]
 [75.92292023]].
[2019-03-26 20:28:48,348] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1902338e-17 1.0000000e+00 1.0328815e-15 4.6191424e-14 3.8803022e-19], sum to 1.0000
[2019-03-26 20:28:48,353] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7939
[2019-03-26 20:28:48,361] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.83333333333333, 75.66666666666667, 1.0, 2.0, 0.5566760394165543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777897.274046499, 777897.274046499, 192952.8135621715], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3787800.0000, 
sim time next is 3788400.0000, 
raw observation next is [29.66666666666667, 76.33333333333334, 1.0, 2.0, 0.5575228775608567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 779081.0768769619, 779081.0768769624, 193099.6265252201], 
processed observation next is [1.0, 0.8695652173913043, 0.6050552922590839, 0.7633333333333334, 1.0, 1.0, 0.46689503320585146, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21641141024360053, 0.21641141024360067, 0.288208397798836], 
reward next is 0.7118, 
noisyNet noise sample is [array([-0.9780326], dtype=float32), 0.5528899]. 
=============================================
[2019-03-26 20:28:52,078] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.3829906e-20 1.0000000e+00 6.3205706e-18 6.4037973e-16 5.2462896e-21], sum to 1.0000
[2019-03-26 20:28:52,085] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7794
[2019-03-26 20:28:52,088] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.66666666666667, 60.66666666666667, 1.0, 2.0, 0.6211640916239537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 868049.490890921, 868049.4908909217, 204755.9348768251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3849600.0000, 
sim time next is 3850200.0000, 
raw observation next is [34.75, 60.5, 1.0, 2.0, 0.6203133274136174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 866860.1001569517, 866860.1001569517, 204592.3819506234], 
processed observation next is [0.0, 0.5652173913043478, 0.8459715639810427, 0.605, 1.0, 1.0, 0.5425461776067679, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2407944722658199, 0.2407944722658199, 0.3053617641054081], 
reward next is 0.6946, 
noisyNet noise sample is [array([-1.2282217], dtype=float32), -0.3765963]. 
=============================================
[2019-03-26 20:28:52,396] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.3261674e-20 1.0000000e+00 2.9310512e-19 4.0657523e-16 1.4392377e-21], sum to 1.0000
[2019-03-26 20:28:52,406] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6234
[2019-03-26 20:28:52,412] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.0, 56.66666666666667, 1.0, 2.0, 0.6045622374870508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 844839.9029176588, 844839.9029176594, 201599.4660853402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3855000.0000, 
sim time next is 3855600.0000, 
raw observation next is [35.0, 56.0, 1.0, 2.0, 0.5995248817101846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 837797.7203946159, 837797.7203946159, 200657.9150921838], 
processed observation next is [0.0, 0.6521739130434783, 0.8578199052132701, 0.56, 1.0, 1.0, 0.5174998574821501, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23272158899850443, 0.23272158899850443, 0.2994894255107221], 
reward next is 0.7005, 
noisyNet noise sample is [array([0.0215157], dtype=float32), 0.3538759]. 
=============================================
[2019-03-26 20:28:53,814] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.6758186e-17 1.0000000e+00 9.6850832e-17 1.4426894e-14 1.9922490e-19], sum to 1.0000
[2019-03-26 20:28:53,826] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1832
[2019-03-26 20:28:53,832] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 89.0, 1.0, 2.0, 0.8809010652799849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1231230.906649581, 1231230.906649581, 264740.7812458202], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4168200.0000, 
sim time next is 4168800.0000, 
raw observation next is [28.0, 89.0, 1.0, 2.0, 0.8841526440840171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1235778.266542298, 1235778.266542298, 265618.3853730501], 
processed observation next is [1.0, 0.2608695652173913, 0.5260663507109005, 0.89, 1.0, 1.0, 0.860424872390382, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3432717407061939, 0.3432717407061939, 0.39644535130305986], 
reward next is 0.6036, 
noisyNet noise sample is [array([-0.9592869], dtype=float32), 1.3765078]. 
=============================================
[2019-03-26 20:29:02,380] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.1251773e-09 9.9999428e-01 1.4660727e-08 5.7422121e-06 1.1528311e-09], sum to 1.0000
[2019-03-26 20:29:02,388] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4539
[2019-03-26 20:29:02,394] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2969376.173182256 W.
[2019-03-26 20:29:02,398] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.0, 60.0, 1.0, 2.0, 0.7740723785544233, 1.0, 2.0, 0.7076262287914743, 1.0, 1.0, 1.03, 7.005103573421169, 6.9112, 170.5573041426782, 2969376.173182256, 2902109.223787526, 545745.3147679911], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4024800.0000, 
sim time next is 4025400.0000, 
raw observation next is [34.0, 60.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.494993859959802, 6.9112, 170.5573041426782, 3328012.156172819, 2909816.867067693, 550462.7165547883], 
processed observation next is [1.0, 0.6086956521739131, 0.8104265402843602, 0.6, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.05837938599598021, 0.0, 0.8375144448122397, 0.9244478211591164, 0.8082824630743591, 0.8215861441116243], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.78086424], dtype=float32), -0.6662792]. 
=============================================
[2019-03-26 20:29:10,732] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.1767402e-18 1.0000000e+00 8.4185554e-18 4.1942234e-15 2.3478001e-20], sum to 1.0000
[2019-03-26 20:29:10,736] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9213
[2019-03-26 20:29:10,746] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 75.0, 1.0, 2.0, 0.632694677132829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 884169.6839489749, 884169.6839489749, 206995.7315317388], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4445400.0000, 
sim time next is 4446000.0000, 
raw observation next is [32.0, 75.0, 1.0, 2.0, 0.633447829405717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 885222.6277207539, 885222.6277207533, 207143.3702792489], 
processed observation next is [0.0, 0.4782608695652174, 0.7156398104265403, 0.75, 1.0, 1.0, 0.5583708788020686, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24589517436687608, 0.2458951743668759, 0.30916920937201325], 
reward next is 0.6908, 
noisyNet noise sample is [array([0.2344977], dtype=float32), 0.042543363]. 
=============================================
[2019-03-26 20:29:10,784] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[71.74695 ]
 [71.69974 ]
 [71.65648 ]
 [71.61592 ]
 [71.567566]], R is [[71.7766571 ]
 [71.74993896]
 [71.72358704]
 [71.69732666]
 [71.67050171]].
[2019-03-26 20:29:11,431] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2923950e-14 1.0000000e+00 3.4186353e-13 9.3375974e-11 5.3662332e-15], sum to 1.0000
[2019-03-26 20:29:11,444] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2093
[2019-03-26 20:29:11,453] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2657684.574548648 W.
[2019-03-26 20:29:11,459] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.33333333333334, 69.16666666666667, 1.0, 2.0, 0.9501398153508931, 1.0, 2.0, 0.9501398153508931, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2657684.574548648, 2657684.574548648, 499597.4950276015], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4180200.0000, 
sim time next is 4180800.0000, 
raw observation next is [33.66666666666667, 67.33333333333334, 1.0, 2.0, 0.6949085594008445, 1.0, 2.0, 0.6680443192146848, 1.0, 1.0, 1.03, 7.005097330704058, 6.9112, 170.5573041426782, 2803094.244581169, 2735831.767098643, 519727.2420213423], 
processed observation next is [1.0, 0.391304347826087, 0.7946287519747238, 0.6733333333333335, 1.0, 1.0, 0.6324199510853548, 1.0, 1.0, 0.6000533966441985, 1.0, 0.5, 1.0365853658536586, 0.009389733070405804, 0.0, 0.8375144448122397, 0.7786372901614358, 0.7599532686385119, 0.7757123015243914], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.35764802], dtype=float32), 0.42265302]. 
=============================================
[2019-03-26 20:29:12,362] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.2777264e-18 1.0000000e+00 1.2442346e-16 2.7238313e-14 1.1994415e-19], sum to 1.0000
[2019-03-26 20:29:12,370] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2446
[2019-03-26 20:29:12,375] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.5, 75.0, 1.0, 2.0, 0.6176027634820951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 863070.6693976154, 863070.6693976154, 204071.4122473456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4224600.0000, 
sim time next is 4225200.0000, 
raw observation next is [31.66666666666666, 73.66666666666666, 1.0, 2.0, 0.6142260544652046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 858349.9713901208, 858349.9713901208, 203426.4550872703], 
processed observation next is [1.0, 0.9130434782608695, 0.6998420221169034, 0.7366666666666666, 1.0, 1.0, 0.5352121138134995, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23843054760836688, 0.23843054760836688, 0.30362157475711987], 
reward next is 0.6964, 
noisyNet noise sample is [array([1.5902917], dtype=float32), -0.85921127]. 
=============================================
[2019-03-26 20:29:13,864] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 20:29:13,866] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:29:13,867] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:29:13,868] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:29:13,870] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:29:13,870] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:29:13,872] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:29:13,873] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:29:13,873] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:29:13,874] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:29:13,877] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:29:13,900] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run31
[2019-03-26 20:29:13,900] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run31
[2019-03-26 20:29:13,940] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run31
[2019-03-26 20:29:13,941] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run31
[2019-03-26 20:29:13,975] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run31
[2019-03-26 20:29:24,997] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06652622], dtype=float32), 0.06053268]
[2019-03-26 20:29:24,999] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.04510238, 91.24776275, 1.0, 2.0, 0.2729342525619293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 444218.2805861628, 444218.2805861628, 163173.5436699264]
[2019-03-26 20:29:25,001] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:29:25,003] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.9135739e-17 1.0000000e+00 1.6300850e-15 8.6782883e-14 1.8172265e-18], sampled 0.9891414129784043
[2019-03-26 20:29:28,991] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06652622], dtype=float32), 0.06053268]
[2019-03-26 20:29:28,992] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.9, 92.16666666666667, 1.0, 2.0, 0.3243463421572204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 504104.9634368094, 504104.9634368094, 167107.9997366096]
[2019-03-26 20:29:28,996] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:29:28,998] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.3194172e-17 1.0000000e+00 3.4762960e-16 1.5730596e-14 1.9593580e-19], sampled 0.2359391285429404
[2019-03-26 20:29:30,040] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06652622], dtype=float32), 0.06053268]
[2019-03-26 20:29:30,041] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.7, 84.33333333333334, 1.0, 2.0, 0.2958247489382581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 472896.2280765323, 472896.2280765329, 165142.5376199511]
[2019-03-26 20:29:30,043] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:29:30,046] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.8084575e-17 1.0000000e+00 1.0882136e-15 6.1896967e-14 9.8196317e-19], sampled 0.9458441127750887
[2019-03-26 20:30:41,946] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06652622], dtype=float32), 0.06053268]
[2019-03-26 20:30:41,947] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.75, 82.66666666666667, 1.0, 2.0, 0.5344110712102559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 746773.3435512764, 746773.3435512757, 189162.8819221621]
[2019-03-26 20:30:41,948] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:30:41,951] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.50621803e-18 1.00000000e+00 1.13882031e-16 1.22893825e-14
 4.70425305e-20], sampled 0.5724848567726205
[2019-03-26 20:31:08,708] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5374 3007679688.9915 1766.0000
[2019-03-26 20:31:09,056] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5144 2842492707.2201 1131.0000
[2019-03-26 20:31:09,069] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6673 3164135639.9928 1778.0000
[2019-03-26 20:31:09,121] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6857 2927400807.7850 1338.0000
[2019-03-26 20:31:09,137] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 20:31:10,154] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 750000, evaluation results [750000.0, 7882.667340294582, 3164135639.9928446, 1778.0, 8253.68573338827, 2927400807.784972, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7997.53741177424, 3007679688.9914675, 1766.0, 8497.514395919725, 2842492707.2200756, 1131.0]
[2019-03-26 20:31:17,792] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.2160114e-12 1.0000000e+00 1.8132097e-11 5.3337184e-09 2.2458520e-13], sum to 1.0000
[2019-03-26 20:31:17,799] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9548
[2019-03-26 20:31:17,806] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.33333333333334, 65.66666666666667, 1.0, 2.0, 0.5435444189643169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 759540.6298902467, 759540.6298902467, 190702.9414364648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4383600.0000, 
sim time next is 4384200.0000, 
raw observation next is [32.16666666666666, 66.33333333333333, 1.0, 2.0, 0.5546009538050467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 774996.4983625632, 774996.4983625638, 192595.2098592759], 
processed observation next is [1.0, 0.7391304347826086, 0.7235387045813582, 0.6633333333333333, 1.0, 1.0, 0.4633746431386105, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.215276805100712, 0.21527680510071215, 0.2874555371033969], 
reward next is 0.7125, 
noisyNet noise sample is [array([-0.36371386], dtype=float32), -0.93974924]. 
=============================================
[2019-03-26 20:31:18,179] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.3466815e-20 1.0000000e+00 5.8771886e-18 8.5743938e-16 2.2655865e-21], sum to 1.0000
[2019-03-26 20:31:18,188] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7183
[2019-03-26 20:31:18,194] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666667, 67.66666666666667, 1.0, 2.0, 0.5409105871556351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 755858.8442419033, 755858.844241904, 190254.3010965207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4461600.0000, 
sim time next is 4462200.0000, 
raw observation next is [31.0, 68.5, 1.0, 2.0, 0.5535190075115133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 773484.0417379951, 773484.0417379951, 192406.5548702447], 
processed observation next is [0.0, 0.6521739130434783, 0.6682464454976303, 0.685, 1.0, 1.0, 0.46207109338736535, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21485667826055418, 0.21485667826055418, 0.28717396249290256], 
reward next is 0.7128, 
noisyNet noise sample is [array([-1.1739607], dtype=float32), -0.62988627]. 
=============================================
[2019-03-26 20:31:19,207] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.6048533e-08 9.9999571e-01 1.0420728e-07 4.1758972e-06 2.5910700e-09], sum to 1.0000
[2019-03-26 20:31:19,214] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5781
[2019-03-26 20:31:19,220] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3159183.322769613 W.
[2019-03-26 20:31:19,226] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.66666666666666, 56.83333333333333, 1.0, 2.0, 0.8644232500053548, 1.0, 2.0, 0.75280166451694, 1.0, 2.0, 1.03, 7.005110700359527, 6.9112, 170.5573041426782, 3159183.322769613, 3091911.268059032, 578293.9996124969], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4377000.0000, 
sim time next is 4377600.0000, 
raw observation next is [36.0, 57.0, 1.0, 2.0, 0.8841450590930557, 1.0, 2.0, 0.7626625690607903, 1.0, 2.0, 1.03, 7.005112256317167, 6.9112, 170.5573041426782, 3200618.307041098, 3133345.137734767, 585803.79679163], 
processed observation next is [1.0, 0.6956521739130435, 0.9052132701421801, 0.57, 1.0, 1.0, 0.860415733847055, 1.0, 1.0, 0.7140512880250486, 1.0, 1.0, 1.0365853658536586, 0.009391225631716705, 0.0, 0.8375144448122397, 0.8890606408447495, 0.8703736493707687, 0.8743340250621343], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.09306791], dtype=float32), 0.071175024]. 
=============================================
[2019-03-26 20:31:26,972] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0400049e-17 1.0000000e+00 1.1901909e-16 2.9823481e-14 1.0979310e-19], sum to 1.0000
[2019-03-26 20:31:26,984] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3712
[2019-03-26 20:31:26,992] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.5085719292308827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 710654.2619121685, 710654.261912169, 184949.4775477625], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4499400.0000, 
sim time next is 4500000.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5079176052521707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709739.6352092845, 709739.6352092845, 184845.3994978373], 
processed observation next is [0.0, 0.08695652173913043, 0.4312796208530806, 0.89, 1.0, 1.0, 0.4071296448821333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1971498986692457, 0.1971498986692457, 0.27588865596692136], 
reward next is 0.7241, 
noisyNet noise sample is [array([0.6830063], dtype=float32), 2.755337]. 
=============================================
[2019-03-26 20:31:27,008] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[66.82414 ]
 [66.967094]
 [67.14329 ]
 [67.3028  ]
 [67.52075 ]], R is [[66.78037262]
 [66.83652496]
 [66.89198303]
 [66.94684601]
 [67.00123596]].
[2019-03-26 20:31:32,014] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.8914994e-17 1.0000000e+00 5.9182785e-15 3.8377851e-13 6.5729554e-18], sum to 1.0000
[2019-03-26 20:31:32,023] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3713
[2019-03-26 20:31:32,028] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 94.0, 1.0, 2.0, 0.9217203584982179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1288318.438848376, 1288318.438848375, 275984.2101772272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4597200.0000, 
sim time next is 4597800.0000, 
raw observation next is [27.16666666666666, 94.00000000000001, 1.0, 2.0, 0.9450630098866242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1320965.517572562, 1320965.517572562, 282636.4787975866], 
processed observation next is [1.0, 0.21739130434782608, 0.4865718799368086, 0.9400000000000002, 1.0, 1.0, 0.9338108552850893, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.36693486599237835, 0.36693486599237835, 0.42184549074266653], 
reward next is 0.5782, 
noisyNet noise sample is [array([-0.8665757], dtype=float32), 0.7400825]. 
=============================================
[2019-03-26 20:31:38,548] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.5577173e-19 1.0000000e+00 7.8494451e-17 7.9870980e-15 1.4340376e-20], sum to 1.0000
[2019-03-26 20:31:38,556] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1870
[2019-03-26 20:31:38,563] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1912115.408060752 W.
[2019-03-26 20:31:38,566] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.5, 77.0, 1.0, 2.0, 0.7264307407134263, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.997361067221316, 6.9112, 168.9117644768777, 1912115.408060752, 1850990.212907785, 390815.1469627995], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4696200.0000, 
sim time next is 4696800.0000, 
raw observation next is [29.66666666666667, 76.33333333333334, 1.0, 2.0, 0.8471060634789535, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.998922709020061, 6.9112, 168.9123650485908, 2081002.218370057, 2018768.927324056, 420079.0224891172], 
processed observation next is [1.0, 0.34782608695652173, 0.6050552922590839, 0.7633333333333334, 1.0, 1.0, 0.8157904379264499, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008772270902006074, 0.0, 0.8294370408038949, 0.5780561717694602, 0.5607691464789044, 0.6269836156553988], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2094524], dtype=float32), 0.30809748]. 
=============================================
[2019-03-26 20:31:43,026] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3633833e-18 1.0000000e+00 7.1129486e-17 4.3758171e-15 3.5201253e-20], sum to 1.0000
[2019-03-26 20:31:43,036] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5582
[2019-03-26 20:31:43,041] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 74.16666666666667, 1.0, 2.0, 1.03242672510641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1443161.494803355, 1443161.494803355, 308963.4938216915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4781400.0000, 
sim time next is 4782000.0000, 
raw observation next is [30.0, 73.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 10.44574732387161, 6.9112, 168.8924281972294, 3962525.200585771, 1455300.424137647, 304721.9599729059], 
processed observation next is [1.0, 0.34782608695652173, 0.6208530805687204, 0.7333333333333334, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.35345473238716096, 0.0, 0.8293391417365804, 1.1007014446071586, 0.40425011781601305, 0.45480889548194914], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41131827], dtype=float32), -1.2705407]. 
=============================================
[2019-03-26 20:31:43,056] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[68.34485 ]
 [68.1806  ]
 [68.07509 ]
 [68.015724]
 [67.95723 ]], R is [[67.49206543]
 [67.35601044]
 [67.29131317]
 [67.24933624]
 [67.20744324]].
[2019-03-26 20:31:48,548] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.5288294e-19 1.0000000e+00 2.9671323e-17 4.0679109e-15 9.5160877e-21], sum to 1.0000
[2019-03-26 20:31:48,557] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8565
[2019-03-26 20:31:48,561] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.7042239497036771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 984175.7697041045, 984175.7697041052, 221757.8984896256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4859400.0000, 
sim time next is 4860000.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.6655394859862604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 930089.3055936471, 930089.3055936464, 213581.1324064603], 
processed observation next is [1.0, 0.2608695652173913, 0.4786729857819906, 0.84, 1.0, 1.0, 0.5970355252846511, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25835814044267974, 0.2583581404426795, 0.31877780956188106], 
reward next is 0.6812, 
noisyNet noise sample is [array([1.0071825], dtype=float32), -1.2610879]. 
=============================================
[2019-03-26 20:31:48,573] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[69.4104  ]
 [69.35226 ]
 [69.093605]
 [69.083694]
 [68.92679 ]], R is [[69.43778229]
 [69.41242981]
 [69.38811493]
 [69.37081909]
 [69.34609222]].
[2019-03-26 20:31:51,596] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.6258823e-17 1.0000000e+00 4.1475400e-16 9.0160389e-15 2.9105597e-20], sum to 1.0000
[2019-03-26 20:31:51,609] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4439
[2019-03-26 20:31:51,620] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2346739.57588912 W.
[2019-03-26 20:31:51,628] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.5, 70.0, 1.0, 2.0, 0.8390792141742882, 1.0, 1.0, 0.8390792141742882, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2346739.57588912, 2346739.57588912, 439336.9133748683], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4955400.0000, 
sim time next is 4956000.0000, 
raw observation next is [29.66666666666667, 68.66666666666667, 1.0, 2.0, 0.4987491295504229, 1.0, 2.0, 0.4987491295504229, 1.0, 1.0, 0.8514470068924643, 6.9112, 6.9112, 170.5573041426782, 2092125.14419389, 2092125.14419389, 411606.0443741106], 
processed observation next is [1.0, 0.34782608695652173, 0.6050552922590839, 0.6866666666666668, 1.0, 1.0, 0.3960832886149674, 1.0, 1.0, 0.3960832886149674, 1.0, 0.5, 0.8188378132834929, 0.0, 0.0, 0.8375144448122397, 0.5811458733871917, 0.5811458733871917, 0.6143373796628516], 
reward next is 0.3857, 
noisyNet noise sample is [array([-1.1292676], dtype=float32), 1.1404394]. 
=============================================
[2019-03-26 20:31:51,641] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[67.17787 ]
 [69.56837 ]
 [69.73377 ]
 [69.634476]
 [69.628555]], R is [[63.15390015]
 [62.86663437]
 [62.23796844]
 [62.16079712]
 [62.1914978 ]].
[2019-03-26 20:31:57,470] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.5100190e-19 1.0000000e+00 1.9469620e-17 1.8698074e-15 5.0874584e-21], sum to 1.0000
[2019-03-26 20:31:57,481] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6476
[2019-03-26 20:31:57,488] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5104633257084197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 713298.0968898302, 713298.0968898295, 185251.679123224], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5006400.0000, 
sim time next is 5007000.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.511770668521239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 715125.5328461556, 715125.5328461563, 185460.7396174659], 
processed observation next is [1.0, 0.9565217391304348, 0.4786729857819906, 0.84, 1.0, 1.0, 0.41177188978462526, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19864598134615433, 0.19864598134615452, 0.27680707405591926], 
reward next is 0.7232, 
noisyNet noise sample is [array([2.0932746], dtype=float32), 1.7701422]. 
=============================================
[2019-03-26 20:31:57,506] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[68.75598]
 [68.73906]
 [68.72165]
 [68.69559]
 [68.57114]], R is [[68.80735779]
 [68.8427887 ]
 [68.87818909]
 [68.91343689]
 [68.94832611]].
[2019-03-26 20:32:02,800] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4107081e-18 1.0000000e+00 1.8860456e-17 3.6091837e-15 5.3559504e-21], sum to 1.0000
[2019-03-26 20:32:02,809] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6553
[2019-03-26 20:32:02,812] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.482364311720772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 674146.5682088706, 674146.5682088699, 180894.5739038551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5111400.0000, 
sim time next is 5112000.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4835689770511917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 675829.8095865631, 675829.8095865624, 181077.0919183193], 
processed observation next is [0.0, 0.17391304347826086, 0.4312796208530806, 0.84, 1.0, 1.0, 0.37779394825444784, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1877305026629342, 0.187730502662934, 0.27026431629599895], 
reward next is 0.7297, 
noisyNet noise sample is [array([0.6976138], dtype=float32), -0.9487579]. 
=============================================
[2019-03-26 20:32:02,836] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[71.59801 ]
 [71.56626 ]
 [71.4053  ]
 [71.234314]
 [71.227295]], R is [[71.73087311]
 [71.74357605]
 [71.75648499]
 [71.76907349]
 [71.78136444]].
[2019-03-26 20:32:05,532] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 20:32:05,534] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:32:05,534] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:32:05,536] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:32:05,536] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:32:05,537] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:32:05,537] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:32:05,538] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:32:05,538] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:32:05,539] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:32:05,540] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:32:05,561] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run32
[2019-03-26 20:32:05,562] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run32
[2019-03-26 20:32:05,562] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run32
[2019-03-26 20:32:05,562] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run32
[2019-03-26 20:32:05,639] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run32
[2019-03-26 20:32:42,689] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07100971], dtype=float32), 0.06264745]
[2019-03-26 20:32:42,691] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.0, 89.0, 1.0, 2.0, 0.6067728303256104, 0.0, 2.0, 0.0, 1.0, 2.0, 1.021511206261907, 6.911200000000001, 6.9112, 168.9129099725272, 1696538.093735963, 1696538.093735962, 364797.6689175738]
[2019-03-26 20:32:42,693] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:32:42,695] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.9914873e-13 1.0000000e+00 1.5022285e-12 1.2030074e-10 5.6039979e-15], sampled 0.880447521820981
[2019-03-26 20:32:42,697] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1696538.093735963 W.
[2019-03-26 20:32:46,406] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07100971], dtype=float32), 0.06264745]
[2019-03-26 20:32:46,407] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.96666666666667, 69.66666666666666, 1.0, 2.0, 0.572594881529774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 800150.5905531935, 800150.5905531929, 195750.9110766879]
[2019-03-26 20:32:46,410] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:32:46,413] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.0628563e-20 1.0000000e+00 6.3807684e-19 1.6515215e-16 2.0580837e-22], sampled 0.3914909045930318
[2019-03-26 20:32:50,294] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07100971], dtype=float32), 0.06264745]
[2019-03-26 20:32:50,294] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.0, 88.0, 1.0, 2.0, 0.5180023575694004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813921.2367332013, 813921.2367332013, 196910.6037159325]
[2019-03-26 20:32:50,297] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:32:50,298] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.0012116e-19 1.0000000e+00 6.0499105e-18 6.3423387e-16 1.5102946e-21], sampled 0.887239460190495
[2019-03-26 20:32:56,725] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07100971], dtype=float32), 0.06264745]
[2019-03-26 20:32:56,726] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.4, 63.66666666666666, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.435112258544394, 6.9112, 168.9099829272536, 1825684.345054911, 1454009.500341239, 311348.5608684314]
[2019-03-26 20:32:56,728] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:32:56,733] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.4096911e-13 1.0000000e+00 4.6645993e-13 4.1738578e-11 1.0889445e-15], sampled 0.6705147389790818
[2019-03-26 20:32:56,736] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1825684.345054911 W.
[2019-03-26 20:33:48,647] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07100971], dtype=float32), 0.06264745]
[2019-03-26 20:33:48,650] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.06908732333333, 91.12243774666666, 1.0, 2.0, 0.4907619074555794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 685759.3502782556, 685759.3502782556, 182160.3525976848]
[2019-03-26 20:33:48,651] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:33:48,654] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.4172297e-19 1.0000000e+00 6.6476961e-18 1.0170272e-15 2.4017706e-21], sampled 0.7366817921817775
[2019-03-26 20:34:00,601] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.2043 2927417036.4532 1338.0000
[2019-03-26 20:34:00,718] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.3448 2842553551.5226 1131.0000
[2019-03-26 20:34:00,825] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.1789 3007672430.4622 1766.0000
[2019-03-26 20:34:00,826] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164071917.9177 1778.0000
[2019-03-26 20:34:00,869] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3694 2779190338.1949 933.0000
[2019-03-26 20:34:01,885] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 775000, evaluation results [775000.0, 7884.168443086554, 3164071917.9176674, 1778.0, 8252.204329082842, 2927417036.4532247, 1338.0, 8661.369356548688, 2779190338.194891, 933.0, 7998.178869716802, 3007672430.462179, 1766.0, 8495.344803432035, 2842553551.5226407, 1131.0]
[2019-03-26 20:34:01,949] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6709541e-14 1.0000000e+00 6.7822382e-14 6.4209697e-12 1.1717527e-15], sum to 1.0000
[2019-03-26 20:34:01,957] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6817
[2019-03-26 20:34:01,964] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.35, 93.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.053606735770643, 6.9112, 168.9119829019505, 1554851.773188323, 1453824.115894347, 311355.8895393038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5374200.0000, 
sim time next is 5374800.0000, 
raw observation next is [28.3, 94.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.068916068689807, 6.9112, 168.9117063731829, 1565719.934579369, 1453831.555382934, 311355.8516056846], 
processed observation next is [1.0, 0.21739130434782608, 0.5402843601895735, 0.94, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.015771606868980735, 0.0, 0.8294338064060992, 0.4349222040498247, 0.40384209871748167, 0.4647102262771412], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1507058], dtype=float32), 1.3223988]. 
=============================================
[2019-03-26 20:34:07,405] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.9131953e-09 9.9999917e-01 7.5491222e-09 8.3319344e-07 4.9818621e-11], sum to 1.0000
[2019-03-26 20:34:07,411] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9182
[2019-03-26 20:34:07,419] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2598129.880892421 W.
[2019-03-26 20:34:07,425] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.928870733185632, 1.0, 2.0, 0.928870733185632, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2598129.880892421, 2598129.880892421, 487489.4395305769], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5238000.0000, 
sim time next is 5238600.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.6387821546088603, 1.0, 2.0, 0.6387821546088603, 1.0, 1.0, 1.03, 7.000410993746838, 6.9112, 170.5573041426782, 2680179.356823115, 2616273.893131044, 502468.5722622339], 
processed observation next is [1.0, 0.6521739130434783, 0.7156398104265403, 0.67, 1.0, 1.0, 0.5647977766371811, 1.0, 1.0, 0.5647977766371811, 1.0, 0.5, 1.0365853658536586, 0.008921099374683817, 0.0, 0.8375144448122397, 0.7444942657841986, 0.7267427480919567, 0.7499530929287073], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04497421], dtype=float32), 0.18842618]. 
=============================================
[2019-03-26 20:34:10,945] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2411802e-07 9.9998462e-01 1.2499656e-07 1.5159923e-05 5.9369509e-09], sum to 1.0000
[2019-03-26 20:34:10,955] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7194
[2019-03-26 20:34:10,961] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2843318.940216053 W.
[2019-03-26 20:34:10,968] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [37.45, 54.0, 1.0, 2.0, 0.7140597758501153, 1.0, 2.0, 0.6776199274393203, 1.0, 1.0, 1.03, 7.005098840782406, 6.9112, 170.5573041426782, 2843318.940216053, 2776055.38100298, 525808.9248121696], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5409000.0000, 
sim time next is 5409600.0000, 
raw observation next is [37.63333333333333, 54.0, 1.0, 2.0, 0.8442336214397562, 1.0, 2.0, 0.7427068502341406, 1.0, 2.0, 1.03, 7.005109107600018, 6.9112, 170.5573041426782, 3116766.886501258, 3049495.972749102, 570758.060268389], 
processed observation next is [1.0, 0.6086956521739131, 0.9826224328593997, 0.54, 1.0, 1.0, 0.8123296643852485, 1.0, 1.0, 0.6900082532941453, 1.0, 1.0, 1.0365853658536586, 0.00939091076000178, 0.0, 0.8375144448122397, 0.8657685795836827, 0.8470822146525283, 0.8518777018931178], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7238651], dtype=float32), 1.0464923]. 
=============================================
[2019-03-26 20:34:17,295] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0632277e-16 1.0000000e+00 2.4294497e-15 1.4692358e-12 1.5824273e-18], sum to 1.0000
[2019-03-26 20:34:17,305] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3839
[2019-03-26 20:34:17,309] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.8, 79.66666666666667, 1.0, 2.0, 0.6116229153945442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 854710.751960657, 854710.751960657, 202932.1652566262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5425800.0000, 
sim time next is 5426400.0000, 
raw observation next is [30.8, 80.33333333333334, 1.0, 2.0, 0.6167525996765194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861882.12361638, 861882.12361638, 203909.3314807037], 
processed observation next is [1.0, 0.8260869565217391, 0.6587677725118484, 0.8033333333333335, 1.0, 1.0, 0.5382561441885776, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23941170100455, 0.23941170100455, 0.30434228579209505], 
reward next is 0.6957, 
noisyNet noise sample is [array([-1.0711074], dtype=float32), -1.0871136]. 
=============================================
[2019-03-26 20:34:30,255] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1459505e-18 1.0000000e+00 1.3268114e-17 8.8552560e-15 1.6148125e-20], sum to 1.0000
[2019-03-26 20:34:30,265] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6682
[2019-03-26 20:34:30,268] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.85, 92.5, 1.0, 2.0, 0.5159975761444457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 721034.0298569204, 721034.0298569197, 186140.2664358656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5621400.0000, 
sim time next is 5622000.0000, 
raw observation next is [25.8, 92.66666666666667, 1.0, 2.0, 0.5148374441949914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 719412.359690964, 719412.3596909647, 185953.2053432669], 
processed observation next is [0.0, 0.043478260869565216, 0.42180094786729866, 0.9266666666666667, 1.0, 1.0, 0.41546680023492943, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19983676658082333, 0.19983676658082353, 0.277542097527264], 
reward next is 0.7225, 
noisyNet noise sample is [array([-0.79679674], dtype=float32), 0.6730464]. 
=============================================
[2019-03-26 20:34:30,280] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[69.75572 ]
 [69.84752 ]
 [69.78987 ]
 [69.929245]
 [69.914536]], R is [[69.77669525]
 [69.80110168]
 [69.82507324]
 [69.84867859]
 [69.87174225]].
[2019-03-26 20:34:30,335] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5380542e-17 1.0000000e+00 3.5870972e-16 9.9956190e-15 1.8666597e-20], sum to 1.0000
[2019-03-26 20:34:30,340] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7643
[2019-03-26 20:34:30,347] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.63333333333333, 91.33333333333334, 1.0, 2.0, 0.5038736434684384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 704086.9247482967, 704086.9247482962, 184204.8727349343], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5629200.0000, 
sim time next is 5629800.0000, 
raw observation next is [25.61666666666667, 91.16666666666667, 1.0, 2.0, 0.5019505234115789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 701398.7692300805, 701398.7692300805, 183901.9238461858], 
processed observation next is [0.0, 0.13043478260869565, 0.41311216429699865, 0.9116666666666667, 1.0, 1.0, 0.3999403896525046, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19483299145280014, 0.19483299145280014, 0.2744804833525161], 
reward next is 0.7255, 
noisyNet noise sample is [array([0.4888514], dtype=float32), 0.23618576]. 
=============================================
[2019-03-26 20:34:33,861] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.4179558e-20 1.0000000e+00 8.0602645e-19 3.7762915e-16 1.0815221e-22], sum to 1.0000
[2019-03-26 20:34:33,871] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8162
[2019-03-26 20:34:33,874] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.43333333333333, 72.83333333333334, 1.0, 2.0, 0.5322740261263339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 743786.0419720585, 743786.0419720579, 188807.3144585471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5683800.0000, 
sim time next is 5684400.0000, 
raw observation next is [29.2, 74.0, 1.0, 2.0, 0.5315173219168408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742728.2732834636, 742728.2732834629, 188681.5681455161], 
processed observation next is [0.0, 0.8260869565217391, 0.5829383886255924, 0.74, 1.0, 1.0, 0.435563038454025, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20631340924540653, 0.20631340924540634, 0.28161428081420314], 
reward next is 0.7184, 
noisyNet noise sample is [array([0.9908239], dtype=float32), -0.15646245]. 
=============================================
[2019-03-26 20:34:35,636] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.7200877e-19 1.0000000e+00 2.7443790e-17 2.0387202e-15 2.6960191e-21], sum to 1.0000
[2019-03-26 20:34:35,645] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9561
[2019-03-26 20:34:35,652] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 80.0, 1.0, 2.0, 0.5186626171841852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 724759.320264166, 724759.3202641654, 186571.6622047571], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5727600.0000, 
sim time next is 5728200.0000, 
raw observation next is [27.96666666666667, 79.16666666666667, 1.0, 2.0, 0.5203001505872328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 727048.329947903, 727048.3299479038, 186837.6735789017], 
processed observation next is [0.0, 0.30434782608695654, 0.524486571879937, 0.7916666666666667, 1.0, 1.0, 0.4220483742014852, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20195786942997307, 0.20195786942997326, 0.2788621993714951], 
reward next is 0.7211, 
noisyNet noise sample is [array([1.2131658], dtype=float32), -0.0058676936]. 
=============================================
[2019-03-26 20:34:40,899] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.5828229e-17 1.0000000e+00 8.7395737e-16 6.1509649e-14 1.5506302e-19], sum to 1.0000
[2019-03-26 20:34:40,910] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9891
[2019-03-26 20:34:40,913] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.25, 92.66666666666666, 1.0, 2.0, 1.02165564932647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9126407906377, 1428095.189700725, 1428095.189700725, 305592.9519679165], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5802600.0000, 
sim time next is 5803200.0000, 
raw observation next is [26.2, 93.0, 1.0, 2.0, 0.9733484047002313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129564758013, 1360526.872468977, 1360526.872468976, 290910.0341345718], 
processed observation next is [1.0, 0.17391304347826086, 0.44075829383886256, 0.93, 1.0, 1.0, 0.9678896442171462, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.829439944982255, 0.3779241312413825, 0.37792413124138224, 0.43419408079786836], 
reward next is 0.5658, 
noisyNet noise sample is [array([0.26230302], dtype=float32), -0.8529768]. 
=============================================
[2019-03-26 20:34:45,823] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.70563557e-18 1.00000000e+00 1.32803186e-17 7.53746191e-16
 1.12671400e-21], sum to 1.0000
[2019-03-26 20:34:45,830] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6134
[2019-03-26 20:34:45,835] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 86.83333333333333, 1.0, 2.0, 0.7572846375360189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1058366.75090455, 1058366.75090455, 233697.3669026125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5899800.0000, 
sim time next is 5900400.0000, 
raw observation next is [28.0, 86.0, 1.0, 2.0, 0.7399295906189444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1034099.854283911, 1034099.85428391, 229701.7055847963], 
processed observation next is [1.0, 0.30434782608695654, 0.5260663507109005, 0.86, 1.0, 1.0, 0.6866621573722221, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2872499595233086, 0.28724995952330834, 0.3428383665444721], 
reward next is 0.6572, 
noisyNet noise sample is [array([-1.443759], dtype=float32), -1.2789633]. 
=============================================
[2019-03-26 20:34:52,175] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1981245e-19 1.0000000e+00 1.2475793e-18 1.2161872e-15 8.5129981e-22], sum to 1.0000
[2019-03-26 20:34:52,185] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0161
[2019-03-26 20:34:52,189] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.4, 78.33333333333334, 1.0, 2.0, 0.5282310838648453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738134.5754765758, 738134.5754765758, 188137.5857425934], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6290400.0000, 
sim time next is 6291000.0000, 
raw observation next is [28.25, 79.5, 1.0, 2.0, 0.5291039197801833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 739354.6751770646, 739354.6751770653, 188281.7942024401], 
processed observation next is [0.0, 0.8260869565217391, 0.537914691943128, 0.795, 1.0, 1.0, 0.43265532503636545, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20537629866029572, 0.20537629866029591, 0.281017603287224], 
reward next is 0.7190, 
noisyNet noise sample is [array([-1.2480351], dtype=float32), 0.044395894]. 
=============================================
[2019-03-26 20:34:52,205] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[73.159256]
 [73.110214]
 [73.05626 ]
 [73.00982 ]
 [72.975975]], R is [[73.19142914]
 [73.17871857]
 [73.16654968]
 [73.15522766]
 [73.14451599]].
[2019-03-26 20:34:56,956] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.4907502e-13 1.0000000e+00 3.4022251e-12 2.6428143e-10 2.8739049e-15], sum to 1.0000
[2019-03-26 20:34:56,961] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4856
[2019-03-26 20:34:56,970] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2027541.01003053 W.
[2019-03-26 20:34:56,976] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.93333333333333, 72.0, 1.0, 2.0, 0.7250508680104412, 1.0, 2.0, 0.7250508680104412, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2027541.01003053, 2027541.01003053, 385032.7230802483], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6082800.0000, 
sim time next is 6083400.0000, 
raw observation next is [30.06666666666667, 71.0, 1.0, 2.0, 0.7332681134794553, 1.0, 2.0, 0.7332681134794553, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2050541.806573811, 2050541.806573811, 388690.8166589456], 
processed observation next is [1.0, 0.391304347826087, 0.6240126382306479, 0.71, 1.0, 1.0, 0.6786362813005485, 1.0, 1.0, 0.6786362813005485, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.569594946270503, 0.569594946270503, 0.5801355472521575], 
reward next is 0.4199, 
noisyNet noise sample is [array([0.9844199], dtype=float32), -0.4541173]. 
=============================================
[2019-03-26 20:34:57,335] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 20:34:57,337] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:34:57,339] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:34:57,339] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:34:57,339] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:34:57,340] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:34:57,341] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:34:57,341] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:34:57,342] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:34:57,342] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:34:57,344] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:34:57,361] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run33
[2019-03-26 20:34:57,379] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run33
[2019-03-26 20:34:57,380] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run33
[2019-03-26 20:34:57,380] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run33
[2019-03-26 20:34:57,380] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run33
[2019-03-26 20:35:00,555] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07167528], dtype=float32), 0.061679263]
[2019-03-26 20:35:00,556] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.69226175333333, 98.5780558, 1.0, 2.0, 0.8039412757324162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1135751.717801432, 1135751.717801432, 246592.269168363]
[2019-03-26 20:35:00,558] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:35:00,560] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.3361856e-19 1.0000000e+00 5.8959614e-18 1.0490429e-15 8.1458428e-22], sampled 0.848483413084535
[2019-03-26 20:35:00,624] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07167528], dtype=float32), 0.061679263]
[2019-03-26 20:35:00,628] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.6, 96.0, 1.0, 2.0, 0.3543341171355828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 547783.4350458741, 547783.4350458735, 170514.375543383]
[2019-03-26 20:35:00,631] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:35:00,635] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.8837388e-19 1.0000000e+00 6.1042728e-18 1.3115100e-15 1.0501288e-21], sampled 0.040605564597344324
[2019-03-26 20:35:51,054] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07167528], dtype=float32), 0.061679263]
[2019-03-26 20:35:51,055] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.96039160333333, 68.18587109, 1.0, 2.0, 0.5064266083740188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 707655.4938998363, 707655.4938998357, 184607.9817728036]
[2019-03-26 20:35:51,056] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:35:51,060] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.6578914e-15 1.0000000e+00 2.4885869e-14 1.1887708e-12 7.6772965e-18], sampled 0.19928555101378131
[2019-03-26 20:36:16,878] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07167528], dtype=float32), 0.061679263]
[2019-03-26 20:36:16,880] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.2, 73.0, 1.0, 2.0, 0.5672390504484937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 792663.4987275783, 792663.4987275783, 194800.7560988428]
[2019-03-26 20:36:16,881] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:36:16,882] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.1391871e-20 1.0000000e+00 1.4863091e-18 5.6737311e-16 2.7465607e-22], sampled 0.8437905982073476
[2019-03-26 20:36:23,161] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07167528], dtype=float32), 0.061679263]
[2019-03-26 20:36:23,162] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.98288499333334, 85.29926642000001, 1.0, 2.0, 0.9056524966738863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9128854655964, 1345737.880678305, 1345737.880678304, 283033.0527345506]
[2019-03-26 20:36:23,163] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:36:23,165] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.1014128e-13 1.0000000e+00 1.2231960e-12 2.4727084e-10 6.2610905e-15], sampled 0.011416082279412265
[2019-03-26 20:36:29,632] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07167528], dtype=float32), 0.061679263]
[2019-03-26 20:36:29,634] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.03333333333333, 68.33333333333333, 1.0, 2.0, 0.5636544596811557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 787652.5112767582, 787652.5112767576, 194169.8309346595]
[2019-03-26 20:36:29,635] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:36:29,637] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.3426294e-19 1.0000000e+00 2.8391945e-18 6.2626164e-16 4.9006468e-22], sampled 0.095200430359621
[2019-03-26 20:36:52,183] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.5883 2927327297.4404 1338.0000
[2019-03-26 20:36:52,355] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 20:36:52,800] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.1099 2779281538.5944 933.0000
[2019-03-26 20:36:52,816] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5565 3007666902.0797 1766.0000
[2019-03-26 20:36:52,861] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.2939 2842588129.6969 1131.0000
[2019-03-26 20:36:53,876] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 800000, evaluation results [800000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8253.588267098503, 2927327297.440425, 1338.0, 8659.109938516645, 2779281538.594428, 933.0, 7997.556496139842, 3007666902.07966, 1766.0, 8495.293851511607, 2842588129.696858, 1131.0]
[2019-03-26 20:36:55,098] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8362119e-14 1.0000000e+00 3.0655323e-13 1.2897028e-11 7.3311549e-17], sum to 1.0000
[2019-03-26 20:36:55,107] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6242
[2019-03-26 20:36:55,113] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.75, 77.0, 1.0, 2.0, 0.5252405013827002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733954.1797674065, 733954.1797674065, 187645.8684115319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6114600.0000, 
sim time next is 6115200.0000, 
raw observation next is [28.56666666666666, 78.0, 1.0, 2.0, 0.5257320437657211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 734641.2827991112, 734641.2827991118, 187726.5116731009], 
processed observation next is [1.0, 0.782608695652174, 0.5529225908372825, 0.78, 1.0, 1.0, 0.42859282381412184, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20406702299975313, 0.20406702299975327, 0.2801888233926879], 
reward next is 0.7198, 
noisyNet noise sample is [array([0.8863452], dtype=float32), 0.5935223]. 
=============================================
[2019-03-26 20:36:56,568] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5836950e-19 1.0000000e+00 3.0414611e-17 1.9621743e-15 5.9020056e-21], sum to 1.0000
[2019-03-26 20:36:56,575] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2950
[2019-03-26 20:36:56,580] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 86.0, 1.0, 2.0, 0.5269159403329983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 736296.1956722644, 736296.1956722644, 187920.8085717417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6123600.0000, 
sim time next is 6124200.0000, 
raw observation next is [27.21666666666667, 86.16666666666667, 1.0, 2.0, 0.5281266562988742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 737988.600777555, 737988.6007775556, 188120.4078167687], 
processed observation next is [1.0, 0.9130434782608695, 0.48894154818325447, 0.8616666666666667, 1.0, 1.0, 0.43147789915527013, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20499683354932083, 0.204996833549321, 0.2807767280847294], 
reward next is 0.7192, 
noisyNet noise sample is [array([-0.3256776], dtype=float32), 1.1264501]. 
=============================================
[2019-03-26 20:37:05,416] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3739521e-20 1.0000000e+00 2.1979299e-18 1.0276387e-15 1.2499252e-22], sum to 1.0000
[2019-03-26 20:37:05,423] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1808
[2019-03-26 20:37:05,431] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.73333333333333, 83.33333333333334, 1.0, 2.0, 0.5343749585673689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 746722.8628641486, 746722.862864148, 189157.0941031561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6294000.0000, 
sim time next is 6294600.0000, 
raw observation next is [27.7, 83.5, 1.0, 2.0, 0.5339543842505919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 746134.9559035427, 746134.9559035427, 189086.947106703], 
processed observation next is [0.0, 0.8695652173913043, 0.5118483412322274, 0.835, 1.0, 1.0, 0.43849925813324325, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2072597099732063, 0.2072597099732063, 0.2822193240398552], 
reward next is 0.7178, 
noisyNet noise sample is [array([-0.8467525], dtype=float32), 0.40189922]. 
=============================================
[2019-03-26 20:37:16,788] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3584051e-09 9.9999940e-01 7.1982873e-09 5.7815771e-07 1.4419239e-10], sum to 1.0000
[2019-03-26 20:37:16,795] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0052
[2019-03-26 20:37:16,801] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2064149.985925456 W.
[2019-03-26 20:37:16,806] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.4, 56.0, 1.0, 2.0, 0.8350654403905928, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.966144482402706, 6.9112, 168.9126294020522, 2064149.985925456, 2025170.554551597, 417979.9620279639], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6523200.0000, 
sim time next is 6523800.0000, 
raw observation next is [31.46666666666667, 56.0, 1.0, 2.0, 0.9851750642965174, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.965588563449253, 6.9112, 168.9125886541575, 2274252.00856118, 2235666.973770525, 460085.4014719563], 
processed observation next is [1.0, 0.5217391304347826, 0.6903633491311217, 0.56, 1.0, 1.0, 0.982138631682551, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.005438856344925291, 0.0, 0.8294381388095945, 0.6317366690447722, 0.6210186038251458, 0.6866946290626214], 
reward next is 0.0414, 
noisyNet noise sample is [array([0.16309828], dtype=float32), -0.1595013]. 
=============================================
[2019-03-26 20:37:20,786] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5194080e-20 1.0000000e+00 6.3017200e-18 6.7674486e-16 4.6941737e-22], sum to 1.0000
[2019-03-26 20:37:20,796] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8692
[2019-03-26 20:37:20,802] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.6, 58.0, 1.0, 2.0, 0.4388025248677382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 633761.5362040659, 633761.5362040659, 177209.9897885411], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6976800.0000, 
sim time next is 6977400.0000, 
raw observation next is [29.51666666666667, 57.83333333333334, 1.0, 2.0, 0.4310396285639245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 625009.0755310854, 625009.075531086, 176413.4769398913], 
processed observation next is [0.0, 0.782608695652174, 0.5979462875197474, 0.5783333333333335, 1.0, 1.0, 0.31450557658304157, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17361363209196815, 0.1736136320919683, 0.2633036969252109], 
reward next is 0.7367, 
noisyNet noise sample is [array([0.7393155], dtype=float32), 0.03084915]. 
=============================================
[2019-03-26 20:37:21,960] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2292999e-18 1.0000000e+00 1.4549297e-16 1.5915659e-14 3.8479011e-20], sum to 1.0000
[2019-03-26 20:37:21,970] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2956
[2019-03-26 20:37:21,978] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 90.0, 1.0, 2.0, 0.5135106425592673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 717557.7162522693, 717557.7162522699, 185739.9079392068], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6573600.0000, 
sim time next is 6574200.0000, 
raw observation next is [26.16666666666666, 90.16666666666667, 1.0, 2.0, 0.8706117203170282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1216841.300810235, 1216841.300810236, 261979.8620683027], 
processed observation next is [1.0, 0.08695652173913043, 0.4391785150078987, 0.9016666666666667, 1.0, 1.0, 0.844110506406058, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3380114724472875, 0.3380114724472878, 0.3910147195049294], 
reward next is 0.6090, 
noisyNet noise sample is [array([0.895941], dtype=float32), 1.0803989]. 
=============================================
[2019-03-26 20:37:27,010] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.11397629e-17 1.00000000e+00 3.19068576e-16 1.24649724e-14
 2.13879745e-20], sum to 1.0000
[2019-03-26 20:37:27,017] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5339
[2019-03-26 20:37:27,022] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.88333333333333, 95.0, 1.0, 2.0, 0.6139510287585741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 857965.4815870208, 857965.4815870208, 203365.0439199614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6664200.0000, 
sim time next is 6664800.0000, 
raw observation next is [24.86666666666667, 95.0, 1.0, 2.0, 0.6050253766004485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 845487.3699859132, 845487.3699859132, 201677.6649269905], 
processed observation next is [1.0, 0.13043478260869565, 0.3775671406003162, 0.95, 1.0, 1.0, 0.5241269597595766, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23485760277386478, 0.23485760277386478, 0.301011440189538], 
reward next is 0.6990, 
noisyNet noise sample is [array([-1.3466836], dtype=float32), 0.66582507]. 
=============================================
[2019-03-26 20:37:29,064] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.9329241e-18 1.0000000e+00 1.6168067e-16 2.5738041e-15 1.2184502e-20], sum to 1.0000
[2019-03-26 20:37:29,073] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3314
[2019-03-26 20:37:29,079] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.03333333333333, 90.66666666666667, 1.0, 2.0, 0.6725707463073679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 939919.8176081327, 939919.8176081327, 215034.3510619343], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6680400.0000, 
sim time next is 6681000.0000, 
raw observation next is [26.11666666666666, 90.33333333333333, 1.0, 2.0, 0.6622723438651841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 925521.4954580624, 925521.4954580631, 212910.9042391225], 
processed observation next is [1.0, 0.30434782608695654, 0.4368088467614531, 0.9033333333333333, 1.0, 1.0, 0.5930992094761254, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2570893042939062, 0.2570893042939064, 0.31777746901361564], 
reward next is 0.6822, 
noisyNet noise sample is [array([0.1295278], dtype=float32), 0.5603151]. 
=============================================
[2019-03-26 20:37:29,097] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[70.29936]
 [70.2086 ]
 [70.22474]
 [70.18105]
 [70.15454]], R is [[70.26368713]
 [70.24010468]
 [70.20031738]
 [70.16518402]
 [70.14056396]].
[2019-03-26 20:37:33,824] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.6206487e-18 1.0000000e+00 1.3334083e-16 3.3487468e-14 4.7788812e-20], sum to 1.0000
[2019-03-26 20:37:33,832] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2147
[2019-03-26 20:37:33,836] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.53333333333333, 77.0, 1.0, 2.0, 0.3747493844665999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 588698.4156158856, 588698.4156158856, 174175.6952414407], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6766800.0000, 
sim time next is 6767400.0000, 
raw observation next is [23.66666666666667, 76.5, 1.0, 2.0, 0.3844108377844545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 603003.0325276207, 603003.0325276207, 175421.6376671486], 
processed observation next is [1.0, 0.30434782608695654, 0.3206951026856243, 0.765, 1.0, 1.0, 0.2583263105836801, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16750084236878351, 0.16750084236878351, 0.26182333980171435], 
reward next is 0.7382, 
noisyNet noise sample is [array([0.93678194], dtype=float32), 2.075052]. 
=============================================
[2019-03-26 20:37:38,157] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.25684213e-17 1.00000000e+00 2.14192901e-16 9.18383953e-15
 1.01779695e-20], sum to 1.0000
[2019-03-26 20:37:38,169] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8228
[2019-03-26 20:37:38,177] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 81.66666666666667, 1.0, 2.0, 0.3362063253829475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 525077.1570925282, 525077.1570925282, 168812.7021562097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6838800.0000, 
sim time next is 6839400.0000, 
raw observation next is [23.1, 81.83333333333334, 1.0, 2.0, 0.3367879131771817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 525679.7773040036, 525679.7773040036, 168852.8277994767], 
processed observation next is [0.0, 0.13043478260869565, 0.2938388625592418, 0.8183333333333335, 1.0, 1.0, 0.20094929298455627, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1460221603622232, 0.1460221603622232, 0.25201914596936825], 
reward next is 0.7480, 
noisyNet noise sample is [array([-2.3604803], dtype=float32), -0.8969886]. 
=============================================
[2019-03-26 20:37:43,174] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.8214390e-20 1.0000000e+00 2.7198855e-18 1.8821079e-16 1.4258867e-22], sum to 1.0000
[2019-03-26 20:37:43,184] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4481
[2019-03-26 20:37:43,193] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.88333333333334, 78.16666666666667, 1.0, 2.0, 0.4264226533309549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 620671.1091066434, 620671.1091066428, 176057.0423806288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6936600.0000, 
sim time next is 6937200.0000, 
raw observation next is [26.1, 77.0, 1.0, 2.0, 0.4275852769461792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 621469.6596054427, 621469.6596054421, 176109.5352132057], 
processed observation next is [0.0, 0.30434782608695654, 0.4360189573459717, 0.77, 1.0, 1.0, 0.3103437071640713, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17263046100151186, 0.1726304610015117, 0.26285005255702343], 
reward next is 0.7371, 
noisyNet noise sample is [array([0.18752012], dtype=float32), 0.90530056]. 
=============================================
[2019-03-26 20:37:46,058] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6530293e-19 1.0000000e+00 1.2331574e-18 2.0858095e-15 5.2062942e-22], sum to 1.0000
[2019-03-26 20:37:46,069] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2752
[2019-03-26 20:37:46,080] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.63333333333333, 52.0, 1.0, 2.0, 0.4580598965596291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 646346.3453054957, 646346.3453054951, 178099.7782756368], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6964800.0000, 
sim time next is 6965400.0000, 
raw observation next is [31.81666666666667, 52.0, 1.0, 2.0, 0.4655127809537518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 652273.3864311778, 652273.3864311778, 178603.0257078125], 
processed observation next is [0.0, 0.6086956521739131, 0.7069510268562403, 0.52, 1.0, 1.0, 0.35603949512500216, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1811870517864383, 0.1811870517864383, 0.2665716801609142], 
reward next is 0.7334, 
noisyNet noise sample is [array([0.12429328], dtype=float32), 0.7176296]. 
=============================================
[2019-03-26 20:37:47,750] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1772004e-19 1.0000000e+00 1.4034734e-17 8.9754046e-16 2.9976942e-22], sum to 1.0000
[2019-03-26 20:37:47,759] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2991
[2019-03-26 20:37:47,765] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 83.5, 1.0, 2.0, 0.3699750097547244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 560805.8883778467, 560805.8883778473, 171297.4943313054], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7235400.0000, 
sim time next is 7236000.0000, 
raw observation next is [23.8, 84.0, 1.0, 2.0, 0.3710920051502805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 563026.1201074978, 563026.1201074984, 171506.0276666304], 
processed observation next is [1.0, 0.782608695652174, 0.3270142180094788, 0.84, 1.0, 1.0, 0.2422795242774464, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15639614447430494, 0.1563961444743051, 0.25597914577109016], 
reward next is 0.7440, 
noisyNet noise sample is [array([-0.26779756], dtype=float32), -0.41508517]. 
=============================================
[2019-03-26 20:37:47,788] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[72.42532 ]
 [72.04588 ]
 [71.71389 ]
 [71.338486]
 [70.639885]], R is [[72.98972321]
 [73.00415802]
 [73.0186615 ]
 [73.03363037]
 [73.04771423]].
[2019-03-26 20:37:47,968] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1731899e-20 1.0000000e+00 7.3360671e-20 1.4142549e-16 2.0835038e-22], sum to 1.0000
[2019-03-26 20:37:47,977] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4769
[2019-03-26 20:37:47,981] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.06666666666667, 71.33333333333334, 1.0, 2.0, 0.430716646286219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 625065.2306058331, 625065.2306058324, 176433.5325010216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6992400.0000, 
sim time next is 6993000.0000, 
raw observation next is [26.95, 72.5, 1.0, 2.0, 0.4346398957204802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 628941.992582633, 628941.9925826325, 176764.8646300449], 
processed observation next is [0.0, 0.9565217391304348, 0.476303317535545, 0.725, 1.0, 1.0, 0.31884324785600027, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1747061090507314, 0.17470610905073125, 0.2638281561642461], 
reward next is 0.7362, 
noisyNet noise sample is [array([-2.7733529], dtype=float32), -1.1139872]. 
=============================================
[2019-03-26 20:37:47,994] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[75.24399 ]
 [75.210556]
 [75.17644 ]
 [75.15309 ]
 [75.14549 ]], R is [[75.26207733]
 [75.24612427]
 [75.23107147]
 [75.21648407]
 [75.2025528 ]].
[2019-03-26 20:37:49,109] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 20:37:49,111] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:37:49,112] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:37:49,113] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:37:49,114] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:37:49,114] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:37:49,116] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:37:49,116] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:37:49,116] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:37:49,115] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:37:49,121] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:37:49,136] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run34
[2019-03-26 20:37:49,137] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run34
[2019-03-26 20:37:49,137] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run34
[2019-03-26 20:37:49,192] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run34
[2019-03-26 20:37:49,192] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run34
[2019-03-26 20:38:13,556] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07537396], dtype=float32), 0.064257495]
[2019-03-26 20:38:13,558] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.53333333333333, 85.0, 1.0, 2.0, 0.7318827464191792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1114832.101468987, 1114832.101468988, 239745.0294733926]
[2019-03-26 20:38:13,560] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:38:13,564] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.6487923e-19 1.0000000e+00 5.8107560e-18 1.0002823e-15 5.8250590e-22], sampled 0.35161581266168007
[2019-03-26 20:38:15,015] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07537396], dtype=float32), 0.064257495]
[2019-03-26 20:38:15,016] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.07922330666667, 87.36184766666668, 1.0, 2.0, 0.7897306619669633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1103736.27028935, 1103736.27028935, 241405.3433691232]
[2019-03-26 20:38:15,017] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:38:15,018] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.9703337e-20 1.0000000e+00 1.5314377e-18 3.7665086e-16 1.3754634e-22], sampled 0.9123432912371211
[2019-03-26 20:39:24,089] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07537396], dtype=float32), 0.064257495]
[2019-03-26 20:39:24,090] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.8, 72.5, 1.0, 2.0, 0.5062973892159814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 707474.8693109483, 707474.8693109483, 184588.7930917196]
[2019-03-26 20:39:24,091] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:39:24,094] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.8379955e-18 1.0000000e+00 9.2323746e-17 2.4426933e-14 9.0137419e-21], sampled 0.9167653817827028
[2019-03-26 20:39:35,638] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07537396], dtype=float32), 0.064257495]
[2019-03-26 20:39:35,639] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.46666666666667, 61.66666666666667, 1.0, 2.0, 0.7309859031985598, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005977218288723, 6.9112, 168.9123160296632, 1918489.92838533, 1851251.962703742, 391509.2980740494]
[2019-03-26 20:39:35,640] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:39:35,642] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2877387e-15 1.0000000e+00 5.3112866e-15 3.8519700e-12 1.6819818e-17], sampled 0.4523704569836857
[2019-03-26 20:39:35,643] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1918489.92838533 W.
[2019-03-26 20:39:37,914] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07537396], dtype=float32), 0.064257495]
[2019-03-26 20:39:37,915] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.65, 65.0, 1.0, 2.0, 0.4598344209285375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 655066.0471925375, 655066.0471925375, 179153.9454233901]
[2019-03-26 20:39:37,916] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:39:37,923] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.4041948e-19 1.0000000e+00 3.2554628e-18 7.6562472e-16 4.5090421e-22], sampled 0.9164209293429427
[2019-03-26 20:39:43,711] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 20:39:44,385] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1249 2927277438.0038 1338.0000
[2019-03-26 20:39:44,579] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5735 3007648438.5815 1766.0000
[2019-03-26 20:39:44,631] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.3549 2842524527.6411 1131.0000
[2019-03-26 20:39:44,649] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 20:39:45,664] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 825000, evaluation results [825000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8255.124881931173, 2927277438.00382, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7997.573465804901, 3007648438.5815053, 1766.0, 8495.354936069756, 2842524527.6411414, 1131.0]
[2019-03-26 20:39:48,930] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.5953001e-17 1.0000000e+00 4.9530438e-15 1.3073388e-12 3.5047855e-19], sum to 1.0000
[2019-03-26 20:39:48,939] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1680
[2019-03-26 20:39:48,945] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.01666666666667, 79.33333333333334, 1.0, 2.0, 0.4817471921539958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 673158.771627048, 673158.771627048, 180785.7260450441], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7066200.0000, 
sim time next is 7066800.0000, 
raw observation next is [26.9, 80.0, 1.0, 2.0, 0.4821338432490095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 673699.2212934479, 673699.2212934486, 180844.1848919697], 
processed observation next is [1.0, 0.8260869565217391, 0.4739336492890995, 0.8, 1.0, 1.0, 0.3760648713843488, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18713867258151332, 0.1871386725815135, 0.2699166938686115], 
reward next is 0.7301, 
noisyNet noise sample is [array([1.1468011], dtype=float32), 0.792023]. 
=============================================
[2019-03-26 20:39:50,636] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.6104168e-19 1.0000000e+00 4.5120965e-18 2.6657258e-15 8.6747113e-22], sum to 1.0000
[2019-03-26 20:39:50,641] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5161
[2019-03-26 20:39:50,647] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 94.33333333333334, 1.0, 2.0, 0.4998698147767043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 710274.5482731145, 710274.5482731145, 185083.5276788748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7100400.0000, 
sim time next is 7101000.0000, 
raw observation next is [24.15, 94.5, 1.0, 2.0, 0.5293945642474459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 753184.2030502071, 753184.2030502065, 190045.4234577006], 
processed observation next is [1.0, 0.17391304347826086, 0.34360189573459715, 0.945, 1.0, 1.0, 0.4330054990933083, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2092178341806131, 0.20921783418061293, 0.2836498857577621], 
reward next is 0.7164, 
noisyNet noise sample is [array([0.91726536], dtype=float32), 0.8732387]. 
=============================================
[2019-03-26 20:39:50,660] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[71.06558 ]
 [70.93988 ]
 [70.825325]
 [70.65802 ]
 [70.62561 ]], R is [[71.12785339]
 [71.14032745]
 [71.12771606]
 [71.14353943]
 [71.15835571]].
[2019-03-26 20:39:52,516] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1338452e-14 1.0000000e+00 9.6741130e-14 2.3290380e-11 1.9481357e-17], sum to 1.0000
[2019-03-26 20:39:52,527] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7224
[2019-03-26 20:39:52,534] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 84.83333333333334, 1.0, 2.0, 0.4774050149871767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 667089.4214282708, 667089.4214282702, 180131.7009389495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7150200.0000, 
sim time next is 7150800.0000, 
raw observation next is [26.1, 84.66666666666667, 1.0, 2.0, 0.4787848660057578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 669018.1273309673, 669018.1273309673, 180338.8082001063], 
processed observation next is [1.0, 0.782608695652174, 0.4360189573459717, 0.8466666666666667, 1.0, 1.0, 0.3720299590430817, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18583836870304649, 0.18583836870304649, 0.2691624002986661], 
reward next is 0.7308, 
noisyNet noise sample is [array([-2.0931468], dtype=float32), 0.681693]. 
=============================================
[2019-03-26 20:39:53,813] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.3961031e-19 1.0000000e+00 6.5927432e-18 3.3907599e-15 4.4075650e-22], sum to 1.0000
[2019-03-26 20:39:53,817] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7966
[2019-03-26 20:39:53,826] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 85.0, 1.0, 2.0, 0.3838705267360344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 574791.6780117674, 574791.6780117681, 172304.2200867445], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7473600.0000, 
sim time next is 7474200.0000, 
raw observation next is [24.21666666666667, 84.50000000000001, 1.0, 2.0, 0.386239480210638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 577380.7410647481, 577380.7410647476, 172505.4138475132], 
processed observation next is [0.0, 0.5217391304347826, 0.34676145339652464, 0.8450000000000002, 1.0, 1.0, 0.2605294942296843, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16038353918465226, 0.1603835391846521, 0.2574707669365869], 
reward next is 0.7425, 
noisyNet noise sample is [array([0.96910715], dtype=float32), 2.2996824]. 
=============================================
[2019-03-26 20:39:56,003] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.570705e-19 1.000000e+00 3.349732e-17 7.099808e-15 7.571737e-21], sum to 1.0000
[2019-03-26 20:39:56,013] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1709
[2019-03-26 20:39:56,023] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 85.33333333333334, 1.0, 2.0, 0.6224901344569533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 869903.3362911043, 869903.3362911043, 205004.9677661726], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7197600.0000, 
sim time next is 7198200.0000, 
raw observation next is [27.8, 85.0, 1.0, 2.0, 0.625845564128584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 874594.3363654815, 874594.3363654815, 205654.0994703549], 
processed observation next is [1.0, 0.30434782608695654, 0.5165876777251186, 0.85, 1.0, 1.0, 0.5492115230464868, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24294287121263375, 0.24294287121263375, 0.3069464171199327], 
reward next is 0.6931, 
noisyNet noise sample is [array([-0.00293698], dtype=float32), 2.5413504]. 
=============================================
[2019-03-26 20:39:59,786] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.5866054e-19 1.0000000e+00 4.8321410e-17 7.0904162e-15 3.3055511e-21], sum to 1.0000
[2019-03-26 20:39:59,795] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2941
[2019-03-26 20:39:59,802] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 91.0, 1.0, 2.0, 0.3259975310288161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 515603.3088994767, 515603.3088994772, 168211.0703710788], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7369200.0000, 
sim time next is 7369800.0000, 
raw observation next is [21.1, 91.16666666666667, 1.0, 2.0, 0.3322420986857388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 527565.2722048846, 527565.2722048839, 169167.5007764274], 
processed observation next is [1.0, 0.30434782608695654, 0.1990521327014219, 0.9116666666666667, 1.0, 1.0, 0.19547240805510696, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14654590894580127, 0.14654590894580108, 0.25248880712899613], 
reward next is 0.7475, 
noisyNet noise sample is [array([-1.0426399], dtype=float32), 1.8951238]. 
=============================================
[2019-03-26 20:40:07,673] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1142216e-19 1.0000000e+00 3.1877384e-18 3.7712406e-15 5.8915202e-22], sum to 1.0000
[2019-03-26 20:40:07,683] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9502
[2019-03-26 20:40:07,687] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 92.83333333333333, 1.0, 2.0, 0.6387313323200511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1008690.98886403, 1008690.988864029, 221827.4207823641], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7387800.0000, 
sim time next is 7388400.0000, 
raw observation next is [21.13333333333333, 92.66666666666667, 1.0, 2.0, 0.4581793355792964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 724441.5512895911, 724441.5512895911, 186999.0418960373], 
processed observation next is [1.0, 0.5217391304347826, 0.20063191153238533, 0.9266666666666667, 1.0, 1.0, 0.34720401877023666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20123376424710865, 0.20123376424710865, 0.27910304760602583], 
reward next is 0.7209, 
noisyNet noise sample is [array([0.85444075], dtype=float32), 0.3277493]. 
=============================================
[2019-03-26 20:40:14,491] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0850901e-19 1.0000000e+00 1.6767095e-17 3.0064772e-15 1.4531621e-21], sum to 1.0000
[2019-03-26 20:40:14,495] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1445
[2019-03-26 20:40:14,504] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 93.0, 1.0, 2.0, 0.4046505640864498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 595742.8224814701, 595742.8224814708, 173904.6966147587], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7522800.0000, 
sim time next is 7523400.0000, 
raw observation next is [23.5, 93.0, 1.0, 2.0, 0.4078350447546752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 600431.5050611332, 600431.5050611338, 174339.1243004749], 
processed observation next is [0.0, 0.043478260869565216, 0.31279620853080575, 0.93, 1.0, 1.0, 0.28654824669237977, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1667865291836481, 0.16678652918364828, 0.260207648209664], 
reward next is 0.7398, 
noisyNet noise sample is [array([-0.3798772], dtype=float32), -1.079493]. 
=============================================
[2019-03-26 20:40:15,276] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2766251e-20 1.0000000e+00 1.9010182e-18 1.4271154e-16 1.0209106e-22], sum to 1.0000
[2019-03-26 20:40:15,284] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9301
[2019-03-26 20:40:15,293] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 90.0, 1.0, 2.0, 0.383760969435442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 575045.0046162286, 575045.004616228, 172340.1760897095], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7540200.0000, 
sim time next is 7540800.0000, 
raw observation next is [23.43333333333333, 90.0, 1.0, 2.0, 0.3853932460323327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 576839.8275490114, 576839.8275490114, 172480.00652421], 
processed observation next is [0.0, 0.2608695652173913, 0.30963665086887826, 0.9, 1.0, 1.0, 0.2595099349787141, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16023328543028095, 0.16023328543028095, 0.2574328455585224], 
reward next is 0.7426, 
noisyNet noise sample is [array([0.43793616], dtype=float32), -1.0533509]. 
=============================================
[2019-03-26 20:40:16,635] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:16,635] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:16,672] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run5
[2019-03-26 20:40:19,496] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4320970e-20 1.0000000e+00 4.8186435e-19 7.5852237e-17 4.8623560e-24], sum to 1.0000
[2019-03-26 20:40:19,506] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8459
[2019-03-26 20:40:19,513] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.13333333333333, 92.0, 1.0, 2.0, 0.4824504968940798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 674141.8307629039, 674141.8307629032, 180891.9996816422], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7598400.0000, 
sim time next is 7599000.0000, 
raw observation next is [25.06666666666667, 92.5, 1.0, 2.0, 0.4824780337637555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 674180.3210257734, 674180.3210257734, 180896.1693598697], 
processed observation next is [0.0, 0.9565217391304348, 0.38704581358609813, 0.925, 1.0, 1.0, 0.3764795587515127, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18727231139604816, 0.18727231139604816, 0.2699942826266712], 
reward next is 0.7300, 
noisyNet noise sample is [array([-1.1305513], dtype=float32), -0.053451143]. 
=============================================
[2019-03-26 20:40:19,526] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[79.7311  ]
 [79.673904]
 [79.61573 ]
 [79.55131 ]
 [79.47395 ]], R is [[79.71952057]
 [79.65233612]
 [79.58592987]
 [79.52018738]
 [79.45497131]].
[2019-03-26 20:40:23,675] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:23,675] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:23,720] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run5
[2019-03-26 20:40:25,294] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.3964493e-12 1.0000000e+00 1.0458670e-10 2.2087070e-09 1.4523727e-13], sum to 1.0000
[2019-03-26 20:40:25,304] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9302
[2019-03-26 20:40:25,308] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 85.0, 1.0, 2.0, 0.2916255677845448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 472958.204721603, 472958.204721603, 165136.8508836607], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 9600.0000, 
sim time next is 10200.0000, 
raw observation next is [20.93333333333333, 85.0, 1.0, 2.0, 0.2887626895459192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 467794.6389357135, 467794.6389357135, 164789.1255658762], 
processed observation next is [1.0, 0.08695652173913043, 0.19115323854660338, 0.85, 1.0, 1.0, 0.14308757776616773, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12994295525992042, 0.12994295525992042, 0.2459539187550391], 
reward next is 0.7540, 
noisyNet noise sample is [array([-0.41226256], dtype=float32), 1.2478776]. 
=============================================
[2019-03-26 20:40:26,808] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:26,809] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:26,841] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run5
[2019-03-26 20:40:28,683] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.9159071e-20 1.0000000e+00 2.1632942e-17 1.3169848e-15 1.3689889e-21], sum to 1.0000
[2019-03-26 20:40:28,691] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1932
[2019-03-26 20:40:28,698] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 87.66666666666667, 1.0, 2.0, 0.5225463123681657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 730188.1127435089, 730188.1127435095, 187204.1012011808], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7766400.0000, 
sim time next is 7767000.0000, 
raw observation next is [26.8, 88.0, 1.0, 2.0, 0.523318483537868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731267.4893892081, 731267.4893892087, 187330.321357835], 
processed observation next is [1.0, 0.9130434782608695, 0.4691943127962086, 0.88, 1.0, 1.0, 0.4256849199251422, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20312985816366894, 0.2031298581636691, 0.27959749456393285], 
reward next is 0.7204, 
noisyNet noise sample is [array([-0.2278975], dtype=float32), -1.073146]. 
=============================================
[2019-03-26 20:40:28,728] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[75.2982  ]
 [74.80735 ]
 [74.5867  ]
 [74.31655 ]
 [74.321915]], R is [[75.43218231]
 [75.39845276]
 [75.36518097]
 [75.33237457]
 [75.30001831]].
[2019-03-26 20:40:34,387] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:34,388] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:34,430] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run5
[2019-03-26 20:40:37,271] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:37,272] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:37,312] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run5
[2019-03-26 20:40:38,894] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:38,894] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:38,935] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run5
[2019-03-26 20:40:39,100] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:39,100] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,125] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run5
[2019-03-26 20:40:39,151] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:39,152] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,177] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run5
[2019-03-26 20:40:39,238] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:39,240] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,254] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:39,254] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,264] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run5
[2019-03-26 20:40:39,290] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run5
[2019-03-26 20:40:39,329] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:39,330] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,344] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run5
[2019-03-26 20:40:39,537] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:39,538] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,541] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:39,541] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,543] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run5
[2019-03-26 20:40:39,564] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:39,564] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,575] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run5
[2019-03-26 20:40:39,596] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:39,596] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,598] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:39,599] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,599] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run5
[2019-03-26 20:40:39,624] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run5
[2019-03-26 20:40:39,649] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run5
[2019-03-26 20:40:39,796] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 20:40:39,804] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:40:39,804] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,805] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run35
[2019-03-26 20:40:39,822] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:40:39,825] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,827] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run35
[2019-03-26 20:40:39,842] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:40:39,843] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,845] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run35
[2019-03-26 20:40:39,881] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:40:39,882] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,884] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run35
[2019-03-26 20:40:39,899] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:40:39,900] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,902] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run35
[2019-03-26 20:40:45,036] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07739601], dtype=float32), 0.06564205]
[2019-03-26 20:40:45,040] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.13333333333334, 72.33333333333333, 1.0, 2.0, 0.2444401960508632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 404018.0197313101, 404018.0197313095, 160289.9432297642]
[2019-03-26 20:40:45,041] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:40:45,044] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.3361252e-19 1.0000000e+00 3.0755977e-18 7.8300700e-16 4.0576675e-22], sampled 0.5239719315527005
[2019-03-26 20:40:46,448] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07739601], dtype=float32), 0.06564205]
[2019-03-26 20:40:46,449] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.43333333333333, 75.0, 1.0, 2.0, 0.2601197495710089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 426576.8301072216, 426576.8301072216, 161923.8475619994]
[2019-03-26 20:40:46,449] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:40:46,456] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2837492e-18 1.0000000e+00 3.1445860e-17 2.6750671e-15 3.3042020e-21], sampled 0.9003526681027708
[2019-03-26 20:40:47,061] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07739601], dtype=float32), 0.06564205]
[2019-03-26 20:40:47,063] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.33294102666667, 76.23386122333334, 1.0, 2.0, 0.3998241295713341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 628332.1960632943, 628332.1960632937, 177691.621134284]
[2019-03-26 20:40:47,063] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:40:47,066] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.8118480e-19 1.0000000e+00 6.7534896e-18 9.2756228e-16 6.0448000e-22], sampled 0.09307714278297896
[2019-03-26 20:40:50,235] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07739601], dtype=float32), 0.06564205]
[2019-03-26 20:40:50,235] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.7, 54.0, 1.0, 2.0, 0.6266273055150398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1028773.728638557, 1028773.728638557, 221450.6096715211]
[2019-03-26 20:40:50,237] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:40:50,239] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.0226826e-20 1.0000000e+00 1.5993835e-18 4.8004872e-16 1.8811977e-22], sampled 0.2839210029215714
[2019-03-26 20:41:12,248] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07739601], dtype=float32), 0.06564205]
[2019-03-26 20:41:12,250] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.15, 94.5, 1.0, 2.0, 0.8989701569902202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1256500.92769338, 1256500.92769338, 269651.8516837089]
[2019-03-26 20:41:12,251] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:41:12,253] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.9000222e-20 1.0000000e+00 1.1138567e-18 3.6655428e-16 8.2265937e-23], sampled 0.9722099176528001
[2019-03-26 20:41:25,651] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07739601], dtype=float32), 0.06564205]
[2019-03-26 20:41:25,653] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.05, 88.0, 1.0, 2.0, 0.5095010330825633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 711952.9825849005, 711952.9825848999, 185097.2798474207]
[2019-03-26 20:41:25,656] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:41:25,660] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.4818991e-20 1.0000000e+00 1.2675015e-18 4.2279877e-16 1.4244405e-22], sampled 0.19491789775507484
[2019-03-26 20:41:41,658] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07739601], dtype=float32), 0.06564205]
[2019-03-26 20:41:41,660] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [34.42200827666667, 72.98104162666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 8.083867604595016, 6.9112, 168.9063153848781, 3116343.488856535, 2284445.438950443, 473363.3967720806]
[2019-03-26 20:41:41,661] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:41:41,663] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.3670669e-13 1.0000000e+00 1.8146897e-12 4.8147242e-10 2.6556270e-15], sampled 0.8633711927937291
[2019-03-26 20:41:41,664] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 3116343.488856535 W.
[2019-03-26 20:41:45,291] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07739601], dtype=float32), 0.06564205]
[2019-03-26 20:41:45,293] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.33333333333333, 59.66666666666667, 1.0, 2.0, 0.6132532419454715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 856989.9664401206, 856989.96644012, 203241.0195023037]
[2019-03-26 20:41:45,294] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:41:45,296] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.2117409e-18 1.0000000e+00 1.3318019e-16 8.4063453e-14 3.9175274e-20], sampled 0.198108194317707
[2019-03-26 20:42:35,039] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.4320 2779397896.3857 933.0000
[2019-03-26 20:42:35,112] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164071917.9177 1778.0000
[2019-03-26 20:42:35,180] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 20:42:35,215] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.1321 2842497763.3803 1131.0000
[2019-03-26 20:42:35,332] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.9689 2927381913.5140 1338.0000
[2019-03-26 20:42:36,349] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 850000, evaluation results [850000.0, 7884.168443086554, 3164071917.9176674, 1778.0, 8254.968948333817, 2927381913.5140486, 1338.0, 8660.432005415354, 2779397896.3857465, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8496.132109434688, 2842497763.3802733, 1131.0]
[2019-03-26 20:42:37,582] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.5722375e-18 1.0000000e+00 3.6995924e-17 4.5629927e-15 4.2147401e-21], sum to 1.0000
[2019-03-26 20:42:37,590] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2250
[2019-03-26 20:42:37,597] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 86.0, 1.0, 2.0, 0.3213215530535128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 512655.718011903, 512655.718011903, 168040.2722682601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 21600.0000, 
sim time next is 22200.0000, 
raw observation next is [21.66666666666667, 85.66666666666667, 1.0, 2.0, 0.3690137845416782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 588413.6889443405, 588413.6889443405, 174182.9217423461], 
processed observation next is [1.0, 0.2608695652173913, 0.22590837282780438, 0.8566666666666667, 1.0, 1.0, 0.23977564402611834, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16344824692898346, 0.16344824692898346, 0.25997451006320316], 
reward next is 0.7400, 
noisyNet noise sample is [array([-0.03994741], dtype=float32), 0.69413304]. 
=============================================
[2019-03-26 20:42:41,604] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1796933e-19 1.0000000e+00 1.0075268e-17 1.6034912e-15 1.2104026e-21], sum to 1.0000
[2019-03-26 20:42:41,614] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2453
[2019-03-26 20:42:41,619] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 90.0, 1.0, 2.0, 0.4188307082407541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 645170.0220620681, 645170.0220620674, 179164.0193579936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 97800.0000, 
sim time next is 98400.0000, 
raw observation next is [22.5, 90.0, 1.0, 2.0, 0.3892222281961041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 599538.9229341301, 599538.9229341301, 174958.839227896], 
processed observation next is [1.0, 0.13043478260869565, 0.2654028436018958, 0.9, 1.0, 1.0, 0.2641231665013302, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16653858970392502, 0.16653858970392502, 0.26113259586253135], 
reward next is 0.7389, 
noisyNet noise sample is [array([-1.1280838], dtype=float32), 0.93645203]. 
=============================================
[2019-03-26 20:42:46,361] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0750581e-18 1.0000000e+00 1.6866658e-17 9.3028426e-15 2.7893566e-21], sum to 1.0000
[2019-03-26 20:42:46,372] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9704
[2019-03-26 20:42:46,377] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.1, 96.0, 1.0, 2.0, 0.2958873061110873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 474622.3086687301, 474622.3086687301, 165278.0506669351], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 178200.0000, 
sim time next is 178800.0000, 
raw observation next is [20.06666666666667, 96.0, 1.0, 2.0, 0.2946152574974321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 472899.1159788866, 472899.1159788866, 165158.8503494025], 
processed observation next is [0.0, 0.043478260869565216, 0.1500789889415484, 0.96, 1.0, 1.0, 0.15013886445473748, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13136086554969073, 0.13136086554969073, 0.24650574679015297], 
reward next is 0.7535, 
noisyNet noise sample is [array([0.8106696], dtype=float32), 0.66698897]. 
=============================================
[2019-03-26 20:42:53,692] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.4626270e-20 1.0000000e+00 8.6195394e-19 1.6349791e-16 1.8334467e-22], sum to 1.0000
[2019-03-26 20:42:53,702] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4375
[2019-03-26 20:42:53,709] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 77.0, 1.0, 2.0, 0.3093101533890999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 488096.0379017606, 488096.03790176, 166121.1053605776], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 301200.0000, 
sim time next is 301800.0000, 
raw observation next is [23.36666666666667, 77.0, 1.0, 2.0, 0.3110274341431913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 490434.1831508067, 490434.1831508067, 166284.1622592447], 
processed observation next is [0.0, 0.4782608695652174, 0.30647709320695127, 0.77, 1.0, 1.0, 0.16991257125685696, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13623171754189076, 0.13623171754189076, 0.24818531680484285], 
reward next is 0.7518, 
noisyNet noise sample is [array([1.0555973], dtype=float32), -0.10354662]. 
=============================================
[2019-03-26 20:42:53,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.4050095e-20 1.0000000e+00 4.0826732e-18 4.4626481e-16 1.1691321e-22], sum to 1.0000
[2019-03-26 20:42:53,914] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5154
[2019-03-26 20:42:53,918] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.53333333333333, 76.33333333333333, 1.0, 2.0, 0.3164592760256142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 498106.7996662029, 498106.7996662023, 166832.9639899812], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 304800.0000, 
sim time next is 305400.0000, 
raw observation next is [23.56666666666667, 76.16666666666667, 1.0, 2.0, 0.3167429366759382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 498449.7570176365, 498449.7570176359, 166856.1608256341], 
processed observation next is [0.0, 0.5217391304347826, 0.31595576619273325, 0.7616666666666667, 1.0, 1.0, 0.17679871888667256, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13845826583823237, 0.1384582658382322, 0.24903904600840912], 
reward next is 0.7510, 
noisyNet noise sample is [array([-0.15897831], dtype=float32), -0.38726303]. 
=============================================
[2019-03-26 20:42:54,293] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6141494e-20 1.0000000e+00 2.6397944e-19 5.6071139e-17 3.0097470e-23], sum to 1.0000
[2019-03-26 20:42:54,303] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5403
[2019-03-26 20:42:54,307] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 76.0, 1.0, 2.0, 0.3219655759065918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 504274.8703338532, 504274.8703338532, 167235.4415181305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 309600.0000, 
sim time next is 310200.0000, 
raw observation next is [23.73333333333333, 76.16666666666667, 1.0, 2.0, 0.3217629405699107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 504177.1305989992, 504177.1305989985, 167233.8146102949], 
processed observation next is [0.0, 0.6086956521739131, 0.3238546603475513, 0.7616666666666667, 1.0, 1.0, 0.18284691634929004, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14004920294416645, 0.14004920294416626, 0.24960270837357448], 
reward next is 0.7504, 
noisyNet noise sample is [array([1.1266578], dtype=float32), 0.28135148]. 
=============================================
[2019-03-26 20:42:54,401] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0133113e-19 1.0000000e+00 6.5182194e-19 5.1624620e-17 3.0687926e-23], sum to 1.0000
[2019-03-26 20:42:54,415] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2404
[2019-03-26 20:42:54,419] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.76666666666667, 76.0, 1.0, 2.0, 0.3200186993366982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 501627.4022096229, 501627.4022096229, 167045.3239074733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 309000.0000, 
sim time next is 309600.0000, 
raw observation next is [23.8, 76.0, 1.0, 2.0, 0.3219655759065918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 504274.8703338532, 504274.8703338532, 167235.4415181305], 
processed observation next is [0.0, 0.6086956521739131, 0.3270142180094788, 0.76, 1.0, 1.0, 0.18309105530914674, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14007635287051476, 0.14007635287051476, 0.24960513659422465], 
reward next is 0.7504, 
noisyNet noise sample is [array([-1.1211476], dtype=float32), 1.5633204]. 
=============================================
[2019-03-26 20:43:05,148] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0563907e-20 1.0000000e+00 2.3222740e-18 3.1035922e-16 3.6798920e-22], sum to 1.0000
[2019-03-26 20:43:05,156] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8609
[2019-03-26 20:43:05,162] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 55.66666666666667, 1.0, 2.0, 0.3498141191536414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 573622.1155521977, 573622.1155521977, 172483.1554737045], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 564600.0000, 
sim time next is 565200.0000, 
raw observation next is [24.4, 56.0, 1.0, 2.0, 0.3915364578328762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 642331.2885569048, 642331.2885569048, 178239.6055975177], 
processed observation next is [1.0, 0.5652173913043478, 0.3554502369668246, 0.56, 1.0, 1.0, 0.26691139497936894, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17842535793247355, 0.17842535793247355, 0.2660292620858473], 
reward next is 0.7340, 
noisyNet noise sample is [array([-0.53178525], dtype=float32), 0.67074937]. 
=============================================
[2019-03-26 20:43:09,861] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.25369424e-20 1.00000000e+00 1.48370321e-18 1.45562903e-16
 3.68949046e-23], sum to 1.0000
[2019-03-26 20:43:09,870] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4600
[2019-03-26 20:43:09,875] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.76666666666667, 61.16666666666667, 1.0, 2.0, 0.6206558011641495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1014574.779839985, 1014574.779839985, 220047.3637728094], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 573000.0000, 
sim time next is 573600.0000, 
raw observation next is [23.73333333333333, 61.33333333333334, 1.0, 2.0, 0.5598863370792512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 915356.7541321453, 915356.7541321447, 207204.7569613243], 
processed observation next is [1.0, 0.6521739130434783, 0.3238546603475513, 0.6133333333333334, 1.0, 1.0, 0.4697425747942785, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25426576503670706, 0.2542657650367069, 0.30926083128555865], 
reward next is 0.6907, 
noisyNet noise sample is [array([-1.04374], dtype=float32), 0.74726254]. 
=============================================
[2019-03-26 20:43:10,516] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.04428895e-20 1.00000000e+00 6.17389256e-19 1.81503213e-16
 1.16201302e-23], sum to 1.0000
[2019-03-26 20:43:10,525] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0824
[2019-03-26 20:43:10,533] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.36666666666667, 64.5, 1.0, 2.0, 0.3307820616167551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 539556.480864077, 539556.4808640777, 169936.0921577853], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 580200.0000, 
sim time next is 580800.0000, 
raw observation next is [23.23333333333333, 65.0, 1.0, 2.0, 0.2580634839382641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 421322.9825268023, 421322.982526803, 161681.6681969654], 
processed observation next is [1.0, 0.7391304347826086, 0.3001579778830963, 0.65, 1.0, 1.0, 0.10610058305814953, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11703416181300064, 0.11703416181300083, 0.2413159226820379], 
reward next is 0.7587, 
noisyNet noise sample is [array([0.65229833], dtype=float32), -0.5377509]. 
=============================================
[2019-03-26 20:43:20,902] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0165022e-19 1.0000000e+00 1.3159225e-19 9.4394596e-17 1.1393774e-22], sum to 1.0000
[2019-03-26 20:43:20,909] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2111
[2019-03-26 20:43:20,915] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 60.5, 1.0, 2.0, 0.2436747180262885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 402194.8189099152, 402194.8189099146, 160246.7239985138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 756600.0000, 
sim time next is 757200.0000, 
raw observation next is [22.9, 62.0, 1.0, 2.0, 0.2448529244925271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 403930.1500833399, 403930.1500833393, 160369.7330999935], 
processed observation next is [1.0, 0.782608695652174, 0.2843601895734597, 0.62, 1.0, 1.0, 0.09018424637653867, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11220281946759442, 0.11220281946759425, 0.23935781059700523], 
reward next is 0.7606, 
noisyNet noise sample is [array([-2.0333643], dtype=float32), 1.2210956]. 
=============================================
[2019-03-26 20:43:31,690] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 20:43:31,695] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:43:31,697] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:43:31,698] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:43:31,699] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:43:31,699] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:43:31,700] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:43:31,701] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:43:31,702] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:43:31,704] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:43:31,705] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:43:31,718] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run36
[2019-03-26 20:43:31,740] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run36
[2019-03-26 20:43:31,760] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run36
[2019-03-26 20:43:31,762] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run36
[2019-03-26 20:43:31,781] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run36
[2019-03-26 20:44:14,889] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07985868], dtype=float32), 0.06806123]
[2019-03-26 20:44:14,891] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.17991434833333, 96.27885883833333, 1.0, 2.0, 0.380723813008215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 575531.8401847187, 575531.840184718, 172539.0601669981]
[2019-03-26 20:44:14,892] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:44:14,895] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.1007049e-21 1.0000000e+00 2.0679713e-19 8.8532545e-17 1.9039092e-23], sampled 0.6732101055586269
[2019-03-26 20:44:21,660] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07985868], dtype=float32), 0.06806123]
[2019-03-26 20:44:21,665] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.83907307, 80.40393479, 1.0, 2.0, 0.4940533174504129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 690360.050900892, 690360.050900892, 182668.9854451985]
[2019-03-26 20:44:21,667] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:44:21,671] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.0793452e-21 1.0000000e+00 2.3889165e-19 5.7576052e-17 1.4050922e-23], sampled 0.422328808661377
[2019-03-26 20:44:24,278] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07985868], dtype=float32), 0.06806123]
[2019-03-26 20:44:24,279] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.66666666666667, 68.0, 1.0, 2.0, 0.5494874967450897, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129563846099, 767848.3972653876, 767848.3972653869, 191715.086618775]
[2019-03-26 20:44:24,281] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:44:24,284] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.3407541e-14 1.0000000e+00 2.6631163e-13 2.8277919e-10 4.0209917e-16], sampled 0.4150462403751918
[2019-03-26 20:44:45,186] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07985868], dtype=float32), 0.06806123]
[2019-03-26 20:44:45,188] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.04394837333334, 86.71592153, 1.0, 2.0, 0.5038979210108827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 704120.8601716596, 704120.8601716589, 184208.1681199142]
[2019-03-26 20:44:45,190] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:44:45,193] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5366729e-21 1.0000000e+00 4.5807349e-20 2.7347435e-17 3.2460161e-24], sampled 0.9860643490276415
[2019-03-26 20:45:08,051] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07985868], dtype=float32), 0.06806123]
[2019-03-26 20:45:08,053] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.38333333333333, 66.33333333333333, 1.0, 2.0, 0.8275988900916382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1156690.149362809, 1156690.149362809, 250797.2980358155]
[2019-03-26 20:45:08,056] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:45:08,060] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.3133404e-21 1.0000000e+00 8.2082056e-20 2.8794875e-17 4.4831048e-24], sampled 0.006334615835478008
[2019-03-26 20:45:25,783] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.6797 2779181245.9678 933.0000
[2019-03-26 20:45:25,860] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6842 2927277501.7680 1338.0000
[2019-03-26 20:45:26,087] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4154 3164020870.7600 1778.0000
[2019-03-26 20:45:26,132] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7995.2579 3007753550.6473 1766.0000
[2019-03-26 20:45:26,224] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.7375 2842583214.3812 1131.0000
[2019-03-26 20:45:27,241] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 875000, evaluation results [875000.0, 7883.415427042078, 3164020870.760028, 1778.0, 8253.684237189153, 2927277501.7679873, 1338.0, 8660.67966608941, 2779181245.96776, 933.0, 7995.25786734932, 3007753550.6473494, 1766.0, 8496.737518497717, 2842583214.381195, 1131.0]
[2019-03-26 20:45:29,124] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1506699e-19 1.0000000e+00 6.3089599e-18 1.0312668e-16 5.7359311e-22], sum to 1.0000
[2019-03-26 20:45:29,141] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1339
[2019-03-26 20:45:29,147] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 93.0, 1.0, 2.0, 0.3329765268366439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 516161.5966468404, 516161.5966468398, 168000.7902355249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 978600.0000, 
sim time next is 979200.0000, 
raw observation next is [21.9, 93.0, 1.0, 2.0, 0.3331733487724681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 516468.1102545601, 516468.1102545608, 168024.895854503], 
processed observation next is [1.0, 0.34782608695652173, 0.23696682464454974, 0.93, 1.0, 1.0, 0.1965943961114074, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14346336395960002, 0.14346336395960022, 0.25078342664851194], 
reward next is 0.7492, 
noisyNet noise sample is [array([-0.3033904], dtype=float32), 0.6503565]. 
=============================================
[2019-03-26 20:45:31,781] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.4843799e-20 1.0000000e+00 5.2850046e-18 5.5217871e-16 2.8407813e-22], sum to 1.0000
[2019-03-26 20:45:31,790] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5622
[2019-03-26 20:45:31,793] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.45, 96.16666666666666, 1.0, 2.0, 0.4858714802355741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731001.4755006314, 731001.475500632, 187824.1420854495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1044600.0000, 
sim time next is 1045200.0000, 
raw observation next is [22.3, 96.33333333333333, 1.0, 2.0, 0.397315129270448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 600258.6993975863, 600258.6993975863, 174760.7903989587], 
processed observation next is [1.0, 0.08695652173913043, 0.25592417061611383, 0.9633333333333333, 1.0, 1.0, 0.2738736497234313, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16673852761044064, 0.16673852761044064, 0.2608370005954607], 
reward next is 0.7392, 
noisyNet noise sample is [array([1.1539894], dtype=float32), -0.36162773]. 
=============================================
[2019-03-26 20:45:34,650] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4631871e-19 1.0000000e+00 3.8378488e-18 7.0046263e-16 2.0050012e-22], sum to 1.0000
[2019-03-26 20:45:34,662] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3423
[2019-03-26 20:45:34,666] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 67.16666666666667, 1.0, 2.0, 0.797217510878386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1231854.706438085, 1231854.706438085, 258606.5675795001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1093800.0000, 
sim time next is 1094400.0000, 
raw observation next is [25.7, 67.0, 1.0, 2.0, 0.7950108555506639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1229328.373533733, 1229328.373533734, 258107.6580123094], 
processed observation next is [1.0, 0.6956521739130435, 0.4170616113744076, 0.67, 1.0, 1.0, 0.7530251271694746, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.34148010375937027, 0.34148010375937055, 0.38523531046613346], 
reward next is 0.6148, 
noisyNet noise sample is [array([1.653876], dtype=float32), 2.5684278]. 
=============================================
[2019-03-26 20:45:39,330] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2981373e-20 1.0000000e+00 1.4547283e-18 1.4715858e-16 9.2894708e-23], sum to 1.0000
[2019-03-26 20:45:39,336] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2656
[2019-03-26 20:45:39,341] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 61.0, 1.0, 2.0, 0.9160060260170056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1385697.653478942, 1385697.653478942, 289429.0482113513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1173600.0000, 
sim time next is 1174200.0000, 
raw observation next is [27.6, 60.66666666666667, 1.0, 2.0, 0.9738410104176051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1474473.84463667, 1474473.844636671, 307746.788348244], 
processed observation next is [1.0, 0.6086956521739131, 0.5071090047393366, 0.6066666666666667, 1.0, 1.0, 0.9684831450814518, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.4095760679546306, 0.40957606795463086, 0.4593235646988716], 
reward next is 0.5407, 
noisyNet noise sample is [array([-0.14404657], dtype=float32), 0.8293836]. 
=============================================
[2019-03-26 20:45:40,284] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6166429e-20 1.0000000e+00 1.2464845e-19 8.3802700e-17 1.6392512e-23], sum to 1.0000
[2019-03-26 20:45:40,295] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6960
[2019-03-26 20:45:40,299] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 57.16666666666666, 1.0, 2.0, 0.8749218469490505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1349022.648056325, 1349022.648056325, 280355.8618688554], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1183800.0000, 
sim time next is 1184400.0000, 
raw observation next is [27.6, 57.0, 1.0, 2.0, 0.8641109400539346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1333435.593337787, 1333435.593337787, 277297.3716745664], 
processed observation next is [1.0, 0.7391304347826086, 0.5071090047393366, 0.57, 1.0, 1.0, 0.8362782410288369, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3703987759271631, 0.3703987759271631, 0.4138766741411439], 
reward next is 0.5861, 
noisyNet noise sample is [array([-1.4008183], dtype=float32), 0.58365977]. 
=============================================
[2019-03-26 20:45:45,042] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3885815e-20 1.0000000e+00 6.5767895e-19 9.6117666e-17 1.7557773e-23], sum to 1.0000
[2019-03-26 20:45:45,052] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5550
[2019-03-26 20:45:45,057] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.56666666666667, 98.0, 1.0, 2.0, 0.3146155162227376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 497157.3719752533, 497157.3719752527, 166806.0286991008], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1399200.0000, 
sim time next is 1399800.0000, 
raw observation next is [20.58333333333334, 98.0, 1.0, 2.0, 0.3146256245799867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 496975.2427550306, 496975.2427550299, 166788.3153678298], 
processed observation next is [0.0, 0.17391304347826086, 0.17456556082148533, 0.98, 1.0, 1.0, 0.17424774045781533, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13804867854306405, 0.13804867854306385, 0.24893778413108927], 
reward next is 0.7511, 
noisyNet noise sample is [array([-0.28005072], dtype=float32), -1.0751995]. 
=============================================
[2019-03-26 20:45:49,606] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.9642505e-20 1.0000000e+00 8.6132611e-19 3.4747846e-16 2.7675096e-23], sum to 1.0000
[2019-03-26 20:45:49,617] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3147
[2019-03-26 20:45:49,621] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.65, 94.0, 1.0, 2.0, 0.8230026852319834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1240633.399539506, 1240633.399539506, 261960.4021930824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1337400.0000, 
sim time next is 1338000.0000, 
raw observation next is [22.56666666666667, 93.66666666666667, 1.0, 2.0, 0.7483828928246812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1132725.695171514, 1132725.695171513, 242998.8884753696], 
processed observation next is [1.0, 0.4782608695652174, 0.26856240126382325, 0.9366666666666668, 1.0, 1.0, 0.696846858824917, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31464602643653167, 0.31464602643653133, 0.36268490817219345], 
reward next is 0.6373, 
noisyNet noise sample is [array([-0.21679284], dtype=float32), 0.8420483]. 
=============================================
[2019-03-26 20:45:49,630] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[76.62657 ]
 [76.50909 ]
 [76.38647 ]
 [76.254776]
 [76.17777 ]], R is [[76.57811737]
 [76.4213562 ]
 [76.2677536 ]
 [76.11073303]
 [75.97169495]].
[2019-03-26 20:45:51,901] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.1523303e-20 1.0000000e+00 1.5900160e-17 6.2941345e-16 3.1231432e-22], sum to 1.0000
[2019-03-26 20:45:51,913] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4737
[2019-03-26 20:45:51,918] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 95.0, 1.0, 2.0, 0.3185148446419488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 503382.6962452093, 503382.6962452086, 167273.6079057441], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1375200.0000, 
sim time next is 1375800.0000, 
raw observation next is [20.86666666666667, 95.16666666666667, 1.0, 2.0, 0.3180440035163916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 502811.7905038574, 502811.7905038581, 167233.9838712227], 
processed observation next is [1.0, 0.9565217391304348, 0.18799368088467638, 0.9516666666666667, 1.0, 1.0, 0.17836626929685737, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13966994180662706, 0.13966994180662726, 0.24960296100182494], 
reward next is 0.7504, 
noisyNet noise sample is [array([-0.4876025], dtype=float32), -0.36873803]. 
=============================================
[2019-03-26 20:45:54,786] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2166766e-19 1.0000000e+00 1.0779861e-18 2.0423698e-16 1.2678277e-22], sum to 1.0000
[2019-03-26 20:45:54,793] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2046
[2019-03-26 20:45:54,799] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 88.5, 1.0, 2.0, 0.3851740829385485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 577888.3025299233, 577888.302529924, 172617.3626335623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1423800.0000, 
sim time next is 1424400.0000, 
raw observation next is [23.73333333333333, 88.66666666666666, 1.0, 2.0, 0.3913579781120874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 584088.8963221629, 584088.8963221624, 173081.8393349934], 
processed observation next is [0.0, 0.4782608695652174, 0.3238546603475513, 0.8866666666666666, 1.0, 1.0, 0.2666963591711896, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16224691564504526, 0.1622469156450451, 0.2583311034850648], 
reward next is 0.7417, 
noisyNet noise sample is [array([-0.4332831], dtype=float32), -0.18839097]. 
=============================================
[2019-03-26 20:46:05,392] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6199484e-21 1.0000000e+00 2.0817671e-19 3.8411313e-17 9.9121517e-24], sum to 1.0000
[2019-03-26 20:46:05,404] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5360
[2019-03-26 20:46:05,409] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 91.66666666666666, 1.0, 2.0, 0.4765954530357104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 665957.8466101834, 665957.8466101841, 180009.9954166866], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2065200.0000, 
sim time next is 2065800.0000, 
raw observation next is [24.93333333333333, 91.83333333333333, 1.0, 2.0, 0.476418763859153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 665710.8773785756, 665710.8773785762, 179983.5260085615], 
processed observation next is [0.0, 0.9130434782608695, 0.38072669826224315, 0.9183333333333333, 1.0, 1.0, 0.3691792335652446, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18491968816071544, 0.1849196881607156, 0.26863212837098727], 
reward next is 0.7314, 
noisyNet noise sample is [array([-0.9689098], dtype=float32), 1.400089]. 
=============================================
[2019-03-26 20:46:15,892] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.9823470e-20 1.0000000e+00 1.2978960e-18 8.3954412e-16 4.1371612e-22], sum to 1.0000
[2019-03-26 20:46:15,904] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8662
[2019-03-26 20:46:15,910] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 90.66666666666667, 1.0, 2.0, 0.6036693233599966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 957533.1192305534, 957533.1192305528, 214559.1078550541], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1781400.0000, 
sim time next is 1782000.0000, 
raw observation next is [21.0, 92.0, 1.0, 2.0, 0.6004387425506822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 953896.1516256345, 953896.1516256345, 213998.0517939191], 
processed observation next is [1.0, 0.6521739130434783, 0.19431279620853087, 0.92, 1.0, 1.0, 0.5186008946393761, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.26497115322934295, 0.26497115322934295, 0.3194000773043569], 
reward next is 0.6806, 
noisyNet noise sample is [array([-0.49300402], dtype=float32), 0.28222287]. 
=============================================
[2019-03-26 20:46:15,927] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[73.28987 ]
 [73.37662 ]
 [73.45769 ]
 [73.51367 ]
 [73.562874]], R is [[73.20669556]
 [73.15439606]
 [73.09926605]
 [73.03708649]
 [72.97794342]].
[2019-03-26 20:46:18,999] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.9594033e-19 1.0000000e+00 2.0632298e-17 1.9594142e-15 1.7956344e-21], sum to 1.0000
[2019-03-26 20:46:19,006] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8260
[2019-03-26 20:46:19,010] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.26666666666667, 96.0, 1.0, 2.0, 0.3642284799019063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 552751.6089454736, 552751.6089454743, 170628.0012622536], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1834800.0000, 
sim time next is 1835400.0000, 
raw observation next is [22.38333333333333, 95.5, 1.0, 2.0, 0.3660613538979577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 554535.9567450732, 554535.9567450739, 170747.6339494929], 
processed observation next is [1.0, 0.21739130434782608, 0.25987361769352274, 0.955, 1.0, 1.0, 0.23621849867223818, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15403776576252035, 0.15403776576252054, 0.2548472148499894], 
reward next is 0.7452, 
noisyNet noise sample is [array([0.93626934], dtype=float32), 0.42998084]. 
=============================================
[2019-03-26 20:46:21,329] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.82348523e-14 1.00000000e+00 1.20341413e-13 2.14111333e-11
 1.04068016e-16], sum to 1.0000
[2019-03-26 20:46:21,337] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0856
[2019-03-26 20:46:21,341] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 85.33333333333334, 1.0, 2.0, 0.5619177285137905, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9544510202185322, 6.911200000000001, 6.9112, 168.9129565097814, 1571030.313302474, 1571030.313302474, 339282.871611386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1869600.0000, 
sim time next is 1870200.0000, 
raw observation next is [27.0, 85.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.343322821026133, 6.9112, 168.9110361441731, 1760524.205985298, 1453964.889532816, 311349.2751118926], 
processed observation next is [1.0, 0.6521739130434783, 0.4786729857819906, 0.855, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0432122821026133, 0.0, 0.8294305152748289, 0.4890345016625828, 0.40387913598133773, 0.4647004106147651], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1654463], dtype=float32), 0.4165293]. 
=============================================
[2019-03-26 20:46:21,393] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 20:46:21,393] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:46:21,394] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:46:21,394] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:46:21,395] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:46:21,396] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:46:21,397] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:46:21,398] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:46:21,400] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:46:21,400] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:46:21,403] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:46:21,422] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run37
[2019-03-26 20:46:21,441] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run37
[2019-03-26 20:46:21,441] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run37
[2019-03-26 20:46:21,461] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run37
[2019-03-26 20:46:21,463] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run37
[2019-03-26 20:46:44,501] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07702083], dtype=float32), 0.06536546]
[2019-03-26 20:46:44,503] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.0, 57.0, 1.0, 2.0, 0.3597016180012442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 549558.4744311062, 549558.4744311069, 170475.6977692278]
[2019-03-26 20:46:44,506] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:46:44,509] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.5126543e-19 1.0000000e+00 2.6586536e-18 7.4211987e-16 5.1329349e-22], sampled 0.8880373050512276
[2019-03-26 20:47:20,516] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07702083], dtype=float32), 0.06536546]
[2019-03-26 20:47:20,518] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.66666666666666, 72.33333333333333, 1.0, 2.0, 0.605403271208467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 846015.6657879984, 846015.665787999, 201757.0875099954]
[2019-03-26 20:47:20,518] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:47:20,521] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.2603662e-21 1.0000000e+00 1.3089933e-19 9.0886847e-17 1.9031249e-23], sampled 0.3366450163351785
[2019-03-26 20:48:05,810] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07702083], dtype=float32), 0.06536546]
[2019-03-26 20:48:05,812] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.78333333333333, 84.16666666666667, 1.0, 2.0, 0.4705645336530451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 663273.8861411756, 663273.8861411756, 179853.4742387891]
[2019-03-26 20:48:05,813] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:48:05,816] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.0548400e-20 1.0000000e+00 5.5419105e-19 2.3338301e-16 7.8126474e-23], sampled 0.4058108343143435
[2019-03-26 20:48:16,513] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.2473 2779265161.4241 933.0000
[2019-03-26 20:48:16,742] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.5884 2927466011.8531 1338.0000
[2019-03-26 20:48:16,744] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6674 3164201025.1587 1778.0000
[2019-03-26 20:48:16,785] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 20:48:16,916] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2767 3007680316.3481 1766.0000
[2019-03-26 20:48:17,934] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 900000, evaluation results [900000.0, 7882.66739125975, 3164201025.158725, 1778.0, 8253.588413883566, 2927466011.853124, 1338.0, 8659.247308817945, 2779265161.4241467, 933.0, 7998.276703650782, 3007680316.348062, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 20:48:20,342] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0262046e-19 1.0000000e+00 1.9878935e-17 5.0247879e-16 4.4753859e-22], sum to 1.0000
[2019-03-26 20:48:20,349] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1096
[2019-03-26 20:48:20,354] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.51666666666667, 93.33333333333334, 1.0, 2.0, 0.4608808574322754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 677225.1522928596, 677225.1522928596, 181884.2629197574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1919400.0000, 
sim time next is 1920000.0000, 
raw observation next is [23.63333333333333, 92.66666666666667, 1.0, 2.0, 0.4303234485036004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 631597.265746425, 631597.2657464244, 177259.1514627667], 
processed observation next is [1.0, 0.21739130434782608, 0.3191153238546602, 0.9266666666666667, 1.0, 1.0, 0.31364270904048236, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1754436849295625, 0.17544368492956233, 0.26456589770562194], 
reward next is 0.7354, 
noisyNet noise sample is [array([-1.5420735], dtype=float32), 0.85890603]. 
=============================================
[2019-03-26 20:48:20,380] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[72.05298 ]
 [72.004425]
 [71.999275]
 [72.03529 ]
 [71.962975]], R is [[72.07278442]
 [72.08058929]
 [72.09789276]
 [72.11463928]
 [72.13034821]].
[2019-03-26 20:48:22,790] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5490325e-13 1.0000000e+00 7.9277313e-13 3.6847958e-10 6.9752990e-15], sum to 1.0000
[2019-03-26 20:48:22,796] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9872
[2019-03-26 20:48:22,801] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.43333333333334, 83.83333333333334, 1.0, 2.0, 1.005540251031928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9127213910156, 1438975.589868758, 1438975.589868758, 305848.4243092289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1959000.0000, 
sim time next is 1959600.0000, 
raw observation next is [25.26666666666667, 84.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.093763841999584, 6.9112, 168.9119773570833, 1621476.502378422, 1491960.180284987, 317424.2395773351], 
processed observation next is [1.0, 0.6956521739130435, 0.3965244865718801, 0.8466666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.018256384199958387, 0.0, 0.829435137061107, 0.45041013954956166, 0.41443338341249636, 0.47376752175721654], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.39419955], dtype=float32), 1.8716087]. 
=============================================
[2019-03-26 20:48:30,722] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6460337e-20 1.0000000e+00 1.0969436e-18 2.9331586e-16 9.8552626e-23], sum to 1.0000
[2019-03-26 20:48:30,733] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6648
[2019-03-26 20:48:30,742] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 86.5, 1.0, 2.0, 0.5107083068985722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 713640.5373868372, 713640.5373868379, 185291.4615950815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2104200.0000, 
sim time next is 2104800.0000, 
raw observation next is [27.1, 85.66666666666667, 1.0, 2.0, 0.5132600484130145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 717207.4285421473, 717207.4285421467, 185700.380978169], 
processed observation next is [0.0, 0.34782608695652173, 0.4834123222748816, 0.8566666666666667, 1.0, 1.0, 0.4135663233891741, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19922428570615203, 0.19922428570615186, 0.27716474772861044], 
reward next is 0.7228, 
noisyNet noise sample is [array([1.3066779], dtype=float32), 1.4656998]. 
=============================================
[2019-03-26 20:48:34,490] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2869215e-18 1.0000000e+00 1.5737234e-17 4.1370495e-15 1.5285529e-20], sum to 1.0000
[2019-03-26 20:48:34,500] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8827
[2019-03-26 20:48:34,504] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 95.16666666666667, 1.0, 2.0, 0.7088116804154643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 990590.2621577844, 990590.2621577844, 222755.8968294621], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2171400.0000, 
sim time next is 2172000.0000, 
raw observation next is [24.93333333333333, 95.33333333333334, 1.0, 2.0, 0.6431525871204777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 898790.4477961449, 898790.4477961449, 209050.4975111737], 
processed observation next is [1.0, 0.13043478260869565, 0.38072669826224315, 0.9533333333333335, 1.0, 1.0, 0.5700633579764792, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2496640132767069, 0.2496640132767069, 0.31201566792712493], 
reward next is 0.6880, 
noisyNet noise sample is [array([-0.5980429], dtype=float32), 0.0478461]. 
=============================================
[2019-03-26 20:48:34,518] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.99054 ]
 [69.89104 ]
 [69.713066]
 [69.59409 ]
 [69.55251 ]], R is [[70.08892059]
 [70.05555725]
 [69.99590302]
 [69.93202209]
 [69.85423279]].
[2019-03-26 20:48:38,917] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0671234e-18 1.0000000e+00 7.3399657e-18 2.5663726e-15 1.4659504e-22], sum to 1.0000
[2019-03-26 20:48:38,923] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5396
[2019-03-26 20:48:38,934] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.55, 84.5, 1.0, 2.0, 0.531361632074012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742510.6403696458, 742510.6403696451, 188655.7856488573], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2241000.0000, 
sim time next is 2241600.0000, 
raw observation next is [27.46666666666667, 84.66666666666667, 1.0, 2.0, 0.5300039202080183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740612.7484461255, 740612.7484461262, 188430.6489737317], 
processed observation next is [1.0, 0.9565217391304348, 0.500789889415482, 0.8466666666666667, 1.0, 1.0, 0.4337396629012269, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2057257634572571, 0.2057257634572573, 0.28123977458765925], 
reward next is 0.7188, 
noisyNet noise sample is [array([1.7209266], dtype=float32), -1.3413903]. 
=============================================
[2019-03-26 20:48:56,834] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2944243e-16 1.0000000e+00 2.2556074e-15 6.7323631e-13 8.9766922e-19], sum to 1.0000
[2019-03-26 20:48:56,844] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1738
[2019-03-26 20:48:56,855] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1839698.987399578 W.
[2019-03-26 20:48:56,859] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.1, 89.0, 1.0, 2.0, 0.4386239860499572, 1.0, 1.0, 0.4386239860499572, 1.0, 2.0, 0.7566653310216834, 6.9112, 6.9112, 170.5573041426782, 1839698.987399578, 1839698.987399578, 374508.7242936583], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2538000.0000, 
sim time next is 2538600.0000, 
raw observation next is [27.21666666666667, 88.16666666666667, 1.0, 2.0, 0.4697690768911749, 1.0, 2.0, 0.4697690768911749, 1.0, 2.0, 0.8114871349464242, 6.9112, 6.9112, 170.5573041426782, 1970449.430687979, 1970449.430687979, 394138.8618716993], 
processed observation next is [1.0, 0.391304347826087, 0.48894154818325447, 0.8816666666666667, 1.0, 1.0, 0.3611675625194879, 1.0, 1.0, 0.3611675625194879, 1.0, 1.0, 0.7701062621297855, 0.0, 0.0, 0.8375144448122397, 0.5473470640799942, 0.5473470640799942, 0.5882669580174616], 
reward next is 0.4117, 
noisyNet noise sample is [array([0.74663657], dtype=float32), 1.0054524]. 
=============================================
[2019-03-26 20:49:01,824] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0160911e-18 1.0000000e+00 1.8523047e-18 2.0574070e-16 5.6377054e-22], sum to 1.0000
[2019-03-26 20:49:01,833] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2537
[2019-03-26 20:49:01,837] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666666, 85.66666666666667, 1.0, 2.0, 0.4682794274503636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 657664.9178185721, 657664.9178185728, 179205.7604229623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2619600.0000, 
sim time next is 2620200.0000, 
raw observation next is [25.83333333333334, 84.83333333333333, 1.0, 2.0, 0.4706401665435882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 659581.9644106363, 659581.9644106363, 179375.6299886161], 
processed observation next is [0.0, 0.30434782608695654, 0.42338072669826254, 0.8483333333333333, 1.0, 1.0, 0.36221706812480503, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18321721233628788, 0.18321721233628788, 0.2677248208785315], 
reward next is 0.7323, 
noisyNet noise sample is [array([-1.4587141], dtype=float32), 0.56966823]. 
=============================================
[2019-03-26 20:49:04,269] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.7154580e-18 1.0000000e+00 7.0044357e-17 2.0955953e-15 3.0385092e-21], sum to 1.0000
[2019-03-26 20:49:04,281] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8126
[2019-03-26 20:49:04,288] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 99.0, 1.0, 2.0, 0.3432213617658628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 532063.7906343807, 532063.79063438, 169267.1162802483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3127800.0000, 
sim time next is 3128400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.342328538041652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 531439.1029385976, 531439.1029385976, 169237.7812907807], 
processed observation next is [1.0, 0.21739130434782608, 0.19431279620853087, 1.0, 1.0, 1.0, 0.20762474462849634, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14762197303849933, 0.14762197303849933, 0.25259370341907567], 
reward next is 0.7474, 
noisyNet noise sample is [array([-0.03939802], dtype=float32), -0.4095337]. 
=============================================
[2019-03-26 20:49:10,717] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1833012e-19 1.0000000e+00 2.1153751e-17 2.4388094e-15 2.1448343e-21], sum to 1.0000
[2019-03-26 20:49:10,729] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4776
[2019-03-26 20:49:10,737] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.348595990499932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 537003.0584279208, 537003.0584279202, 169570.6688884929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2769000.0000, 
sim time next is 2769600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3485839557927702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 536984.4613737067, 536984.4613737067, 169569.1448971195], 
processed observation next is [1.0, 0.043478260869565216, 0.2417061611374408, 0.94, 1.0, 1.0, 0.21516139252140987, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1491623503815852, 0.1491623503815852, 0.25308827596585], 
reward next is 0.7469, 
noisyNet noise sample is [array([-2.3312628], dtype=float32), 0.4370496]. 
=============================================
[2019-03-26 20:49:13,309] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 20:49:13,313] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:49:13,314] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:49:13,316] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:49:13,317] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:49:13,319] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:49:13,320] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:49:13,321] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:49:13,322] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:49:13,322] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:49:13,323] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:49:13,337] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run38
[2019-03-26 20:49:13,358] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run38
[2019-03-26 20:49:13,358] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run38
[2019-03-26 20:49:13,398] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run38
[2019-03-26 20:49:13,415] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run38
[2019-03-26 20:49:21,367] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07750741], dtype=float32), 0.06487997]
[2019-03-26 20:49:21,369] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.76666666666667, 71.0, 1.0, 2.0, 0.7370344117010069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1041724.405904566, 1041724.405904567, 230634.8910394287]
[2019-03-26 20:49:21,370] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:49:21,373] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.3215746e-20 1.0000000e+00 9.6531678e-19 2.7009464e-16 1.2106006e-22], sampled 0.6828909828788039
[2019-03-26 20:49:39,220] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07750741], dtype=float32), 0.06487997]
[2019-03-26 20:49:39,222] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.16316816, 89.76867278, 1.0, 2.0, 0.4530122113217309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 657730.9407343311, 657730.9407343304, 179711.8010705198]
[2019-03-26 20:49:39,223] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:49:39,226] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.9217454e-20 1.0000000e+00 2.4739333e-19 1.4137480e-16 3.6315972e-23], sampled 0.1556662040066823
[2019-03-26 20:50:09,662] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07750741], dtype=float32), 0.06487997]
[2019-03-26 20:50:09,663] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [37.51666666666667, 44.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.391137885596201, 6.9112, 168.9101613151846, 1794466.949675181, 1453988.129830425, 311354.5510313082]
[2019-03-26 20:50:09,664] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:50:09,668] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.9246428e-17 1.0000000e+00 1.6689698e-16 7.4380274e-14 1.1124081e-19], sampled 0.7839813464825254
[2019-03-26 20:50:09,671] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1794466.949675181 W.
[2019-03-26 20:50:48,699] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07750741], dtype=float32), 0.06487997]
[2019-03-26 20:50:48,701] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.11666666666667, 92.83333333333333, 1.0, 2.0, 0.6530760839191702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 912664.2571650674, 912664.257165068, 211042.0464341715]
[2019-03-26 20:50:48,705] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:50:48,710] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.1681188e-20 1.0000000e+00 5.7421358e-19 1.5413559e-16 5.3950494e-23], sampled 0.45687123334982715
[2019-03-26 20:51:00,299] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07750741], dtype=float32), 0.06487997]
[2019-03-26 20:51:00,300] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.0, 72.0, 1.0, 2.0, 0.3529430983346466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 544314.467373413, 544314.467373413, 170190.4459524591]
[2019-03-26 20:51:00,301] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:51:00,302] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.5947269e-19 1.0000000e+00 9.4122715e-18 2.3171450e-15 1.9755294e-21], sampled 0.2809951132429245
[2019-03-26 20:51:08,351] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8657.7255 2779296335.4222 933.0000
[2019-03-26 20:51:08,374] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07750741], dtype=float32), 0.06487997]
[2019-03-26 20:51:08,375] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.502026755, 70.34475208666667, 1.0, 2.0, 0.6184365696060591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9128745223207, 864236.3482796514, 864236.3482796521, 204223.9528173999]
[2019-03-26 20:51:08,376] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:51:08,377] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.5834340e-15 1.0000000e+00 6.1626344e-15 3.9337613e-12 1.4335693e-17], sampled 0.8039887497259841
[2019-03-26 20:51:08,655] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.1321 2842451957.6633 1131.0000
[2019-03-26 20:51:08,692] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.8717 2927447046.3306 1338.0000
[2019-03-26 20:51:08,696] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164027848.4855 1778.0000
[2019-03-26 20:51:08,804] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 20:51:09,820] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 925000, evaluation results [925000.0, 7884.16835844559, 3164027848.485504, 1778.0, 8254.871735174753, 2927447046.3306217, 1338.0, 8657.725469675026, 2779296335.422204, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8496.132105234119, 2842451957.6632614, 1131.0]
[2019-03-26 20:51:15,978] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9949565e-19 1.0000000e+00 1.8480770e-18 8.4237358e-16 1.7393399e-21], sum to 1.0000
[2019-03-26 20:51:15,985] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3101
[2019-03-26 20:51:15,991] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 97.0, 1.0, 2.0, 0.31207332160021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 495274.6924825286, 495274.6924825286, 166706.4719911926], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2926800.0000, 
sim time next is 2927400.0000, 
raw observation next is [20.58333333333334, 96.50000000000001, 1.0, 2.0, 0.312656314054623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 495910.2715004249, 495910.2715004249, 166748.6065074436], 
processed observation next is [1.0, 0.9130434782608695, 0.17456556082148533, 0.9650000000000002, 1.0, 1.0, 0.1718750771742446, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13775285319456246, 0.13775285319456246, 0.24887851717528894], 
reward next is 0.7511, 
noisyNet noise sample is [array([0.84037113], dtype=float32), 0.86933744]. 
=============================================
[2019-03-26 20:51:16,784] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3128445e-18 1.0000000e+00 2.9495275e-17 7.3773681e-15 5.3967222e-21], sum to 1.0000
[2019-03-26 20:51:16,796] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7342
[2019-03-26 20:51:16,805] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3028660219808765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 482297.4615000679, 482297.4615000679, 165786.6792181012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2943600.0000, 
sim time next is 2944200.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3029009757181943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 482353.0474773564, 482353.0474773558, 165790.674409861], 
processed observation next is [1.0, 0.043478260869565216, 0.1469194312796209, 1.0, 1.0, 1.0, 0.16012165749180035, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.133986957632599, 0.13398695763259882, 0.24744876777591196], 
reward next is 0.7526, 
noisyNet noise sample is [array([1.323252], dtype=float32), 1.8539208]. 
=============================================
[2019-03-26 20:51:22,957] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.7163659e-18 1.0000000e+00 1.8565855e-17 5.3278051e-15 1.2102041e-21], sum to 1.0000
[2019-03-26 20:51:22,967] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5052
[2019-03-26 20:51:22,973] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 93.33333333333334, 1.0, 2.0, 0.9607025276158709, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.9129564061214, 1342839.539883344, 1342839.539883343, 287180.2992788879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3379200.0000, 
sim time next is 3379800.0000, 
raw observation next is [26.05, 93.66666666666667, 1.0, 2.0, 0.9263271978212507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104049, 1294761.4939872, 1294761.493987201, 277281.5065194667], 
processed observation next is [1.0, 0.08695652173913043, 0.43364928909952616, 0.9366666666666668, 1.0, 1.0, 0.9112375877364467, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451521746, 0.35965597055200005, 0.35965597055200027, 0.4138529948051742], 
reward next is 0.5861, 
noisyNet noise sample is [array([0.6498348], dtype=float32), -0.9050127]. 
=============================================
[2019-03-26 20:51:33,367] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.3008072e-20 1.0000000e+00 1.0600637e-18 5.7676321e-16 6.1702542e-23], sum to 1.0000
[2019-03-26 20:51:33,376] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1780
[2019-03-26 20:51:33,382] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 82.33333333333334, 1.0, 2.0, 0.4725219784565339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 660264.1175018304, 660264.1175018311, 179402.8188057252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3223200.0000, 
sim time next is 3223800.0000, 
raw observation next is [26.5, 81.5, 1.0, 2.0, 0.4734447424415968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 661553.9149877997, 661553.9149877997, 179540.0543227098], 
processed observation next is [0.0, 0.30434782608695654, 0.4549763033175356, 0.815, 1.0, 1.0, 0.36559607523083953, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1837649763854999, 0.1837649763854999, 0.2679702303324027], 
reward next is 0.7320, 
noisyNet noise sample is [array([-0.9497194], dtype=float32), -0.5410768]. 
=============================================
[2019-03-26 20:51:37,146] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.9192600e-19 1.0000000e+00 5.8726582e-19 6.8267732e-16 3.6692387e-22], sum to 1.0000
[2019-03-26 20:51:37,154] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7532
[2019-03-26 20:51:37,158] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.5368056235281804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 750120.615587785, 750120.6155877844, 189563.6615732112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3363000.0000, 
sim time next is 3363600.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.5380746063124562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 751894.4923981369, 751894.4923981369, 189776.4799464616], 
processed observation next is [0.0, 0.9565217391304348, 0.4786729857819906, 0.89, 1.0, 1.0, 0.44346338109934474, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2088595812217047, 0.2088595812217047, 0.28324847753203225], 
reward next is 0.7168, 
noisyNet noise sample is [array([0.20578817], dtype=float32), 1.0580773]. 
=============================================
[2019-03-26 20:51:38,045] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.4769392e-20 1.0000000e+00 1.7248526e-18 7.1326752e-17 4.4227717e-23], sum to 1.0000
[2019-03-26 20:51:38,057] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2673
[2019-03-26 20:51:38,062] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.4232603203675319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 619726.5050434443, 619726.5050434449, 176067.713518332], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3298800.0000, 
sim time next is 3299400.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.4228097815742998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 619072.0669224252, 619072.0669224246, 176004.9039168248], 
processed observation next is [0.0, 0.17391304347826086, 0.38388625592417064, 0.83, 1.0, 1.0, 0.3045900982822889, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.171964463034007, 0.17196446303400684, 0.2626938864430221], 
reward next is 0.7373, 
noisyNet noise sample is [array([-1.3794016], dtype=float32), 0.66576785]. 
=============================================
[2019-03-26 20:51:38,972] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0553960e-13 1.0000000e+00 1.3710884e-12 2.7675440e-10 1.4613429e-16], sum to 1.0000
[2019-03-26 20:51:38,980] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8861
[2019-03-26 20:51:38,986] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666667, 70.66666666666667, 1.0, 2.0, 0.5429697960851061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 758737.373915605, 758737.373915605, 190603.789200118], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3435000.0000, 
sim time next is 3435600.0000, 
raw observation next is [30.33333333333334, 71.33333333333334, 1.0, 2.0, 0.5430648807823452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 758870.2912250569, 758870.2912250574, 190619.3539496436], 
processed observation next is [1.0, 0.782608695652174, 0.6366508688783573, 0.7133333333333334, 1.0, 1.0, 0.4494757599787291, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21079730311807135, 0.21079730311807152, 0.2845064984323039], 
reward next is 0.7155, 
noisyNet noise sample is [array([-1.565319], dtype=float32), 1.5113715]. 
=============================================
[2019-03-26 20:51:43,874] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6908431e-15 1.0000000e+00 8.8695781e-14 2.9184558e-11 5.2808560e-17], sum to 1.0000
[2019-03-26 20:51:43,881] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2928
[2019-03-26 20:51:43,890] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2207631.835587648 W.
[2019-03-26 20:51:43,896] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 75.0, 1.0, 2.0, 0.78938524948167, 1.0, 2.0, 0.78938524948167, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2207631.835587648, 2207631.835587648, 414738.8432795599], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3402000.0000, 
sim time next is 3402600.0000, 
raw observation next is [30.16666666666666, 74.16666666666667, 1.0, 2.0, 0.9678508719757132, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.003065965862143, 6.9112, 168.9124099799762, 2250004.298296398, 2184831.631202963, 453673.2890163329], 
processed observation next is [1.0, 0.391304347826087, 0.6287519747235385, 0.7416666666666667, 1.0, 1.0, 0.9612661108141123, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.009186596586214258, 0.0, 0.8294372614375668, 0.6250011939712217, 0.6068976753341564, 0.6771243119646759], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3063295], dtype=float32), -0.98665607]. 
=============================================
[2019-03-26 20:51:49,429] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8823755e-14 1.0000000e+00 8.4103866e-14 2.3624684e-11 6.0051691e-17], sum to 1.0000
[2019-03-26 20:51:49,438] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9956
[2019-03-26 20:51:49,447] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2049816.466451498 W.
[2019-03-26 20:51:49,455] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 66.0, 1.0, 2.0, 0.7330089817639536, 1.0, 2.0, 0.7330089817639536, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2049816.466451498, 2049816.466451498, 388568.3322343022], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3489600.0000, 
sim time next is 3490200.0000, 
raw observation next is [30.0, 66.0, 1.0, 2.0, 0.9074725078271609, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.975723466243606, 6.9112, 168.9125725399419, 2165495.995462245, 2119720.931838158, 437181.3223207155], 
processed observation next is [1.0, 0.391304347826087, 0.6208530805687204, 0.66, 1.0, 1.0, 0.8885210937676637, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.0064523466243605835, 0.0, 0.8294380596814187, 0.6015266654061792, 0.5888113699550439, 0.6525094362995754], 
reward next is 0.0249, 
noisyNet noise sample is [array([-1.0427207], dtype=float32), -1.2908328]. 
=============================================
[2019-03-26 20:51:51,162] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.5795785e-14 1.0000000e+00 1.5328179e-13 6.1052641e-10 1.6988062e-16], sum to 1.0000
[2019-03-26 20:51:51,173] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7369
[2019-03-26 20:51:51,177] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.5, 72.5, 1.0, 2.0, 0.5586218292961201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780617.3135819572, 780617.3135819572, 193291.0778714404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3522600.0000, 
sim time next is 3523200.0000, 
raw observation next is [30.33333333333334, 73.33333333333334, 1.0, 2.0, 0.5570663515143547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 778442.8947538843, 778442.8947538843, 193020.7645969841], 
processed observation next is [1.0, 0.782608695652174, 0.6366508688783573, 0.7333333333333334, 1.0, 1.0, 0.4663450018245237, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21623413743163453, 0.21623413743163453, 0.2880906934283345], 
reward next is 0.7119, 
noisyNet noise sample is [array([0.7470825], dtype=float32), -0.5202774]. 
=============================================
[2019-03-26 20:52:01,294] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7544903e-06 9.9959761e-01 2.1758676e-06 3.9844695e-04 5.7565330e-08], sum to 1.0000
[2019-03-26 20:52:01,302] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8544
[2019-03-26 20:52:01,309] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2714694.317436214 W.
[2019-03-26 20:52:01,314] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.0, 59.0, 1.0, 2.0, 0.9704990560376204, 1.0, 2.0, 0.9704990560376204, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2714694.317436214, 2714694.317436213, 511410.1232128367], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3684000.0000, 
sim time next is 3684600.0000, 
raw observation next is [33.0, 59.0, 1.0, 2.0, 0.6650100431462004, 1.0, 2.0, 0.6530950610873628, 1.0, 1.0, 1.03, 7.005094973392655, 6.9112, 170.5573041426782, 2740298.801259573, 2673038.012415094, 510503.822679501], 
processed observation next is [1.0, 0.6521739130434783, 0.7630331753554502, 0.59, 1.0, 1.0, 0.5963976423448197, 1.0, 1.0, 0.5820422422739311, 1.0, 0.5, 1.0365853658536586, 0.009389497339265506, 0.0, 0.8375144448122397, 0.7611941114609925, 0.7425105590041927, 0.7619460039992553], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8835611], dtype=float32), -0.44520974]. 
=============================================
[2019-03-26 20:52:03,184] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.5373489e-18 1.0000000e+00 3.1495802e-17 7.1850227e-14 2.1187073e-20], sum to 1.0000
[2019-03-26 20:52:03,186] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0076
[2019-03-26 20:52:03,190] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.4509556509691987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 644644.5115775216, 644644.5115775221, 178136.6356711813], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3721800.0000, 
sim time next is 3722400.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.4506987407720722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 644277.5792512562, 644277.5792512568, 178099.2523405596], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.74, 1.0, 1.0, 0.33819125394225574, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17896599423646006, 0.1789659942364602, 0.2658197796127755], 
reward next is 0.7342, 
noisyNet noise sample is [array([-0.8740636], dtype=float32), 0.9314698]. 
=============================================
[2019-03-26 20:52:05,124] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.1715730e-16 1.0000000e+00 1.8039337e-15 1.9102917e-13 5.1858662e-19], sum to 1.0000
[2019-03-26 20:52:05,135] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8949
[2019-03-26 20:52:05,143] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2088521.55272127 W.
[2019-03-26 20:52:05,149] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 70.0, 1.0, 2.0, 0.8524784363192753, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.969994472172504, 6.9112, 168.912557135727, 2088521.55272127, 2046810.829232838, 422419.6750745567], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3747000.0000, 
sim time next is 3747600.0000, 
raw observation next is [29.0, 70.0, 1.0, 2.0, 0.8089966406410334, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.969935009459197, 6.9112, 168.9125587959448, 2027664.636839348, 1985996.097736989, 411276.2215164255], 
processed observation next is [1.0, 0.391304347826087, 0.5734597156398105, 0.7, 1.0, 1.0, 0.7698754706518475, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.00587350094591974, 0.0, 0.8294379921921009, 0.5632401768998189, 0.5516655827047191, 0.6138451067409335], 
reward next is 0.0925, 
noisyNet noise sample is [array([-0.54153293], dtype=float32), -1.5387342]. 
=============================================
[2019-03-26 20:52:05,254] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 20:52:05,255] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:52:05,257] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:52:05,258] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:52:05,259] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:52:05,260] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:52:05,261] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:52:05,262] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:52:05,262] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:52:05,263] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:52:05,264] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:52:05,286] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run39
[2019-03-26 20:52:05,286] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run39
[2019-03-26 20:52:05,325] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run39
[2019-03-26 20:52:05,325] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run39
[2019-03-26 20:52:05,370] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run39
[2019-03-26 20:52:20,647] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07586104], dtype=float32), 0.06269049]
[2019-03-26 20:52:20,648] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.7672784, 97.72755044499999, 1.0, 2.0, 0.3322431934724575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 522235.5257508077, 522235.5257508077, 168665.8598901371]
[2019-03-26 20:52:20,649] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:52:20,652] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1981708e-18 1.0000000e+00 1.3070138e-17 2.6377466e-15 1.0717847e-21], sampled 0.6415442451778289
[2019-03-26 20:52:21,498] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07586104], dtype=float32), 0.06269049]
[2019-03-26 20:52:21,500] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.64355299, 98.03227709, 1.0, 2.0, 0.3890059809799953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 580346.5626196684, 580346.5626196684, 172735.6094290185]
[2019-03-26 20:52:21,501] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:52:21,504] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.4414982e-18 1.0000000e+00 1.7220527e-17 5.8823787e-15 2.0602056e-21], sampled 0.8686404558511499
[2019-03-26 20:53:21,029] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07586104], dtype=float32), 0.06269049]
[2019-03-26 20:53:21,031] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.6, 61.0, 1.0, 2.0, 0.5730608329366773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 800801.9617936152, 800801.9617936147, 195833.734715194]
[2019-03-26 20:53:21,031] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:53:21,035] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2354074e-19 1.0000000e+00 1.2229310e-18 6.6359213e-16 1.2109332e-22], sampled 0.1899056118922039
[2019-03-26 20:53:48,585] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07586104], dtype=float32), 0.06269049]
[2019-03-26 20:53:48,586] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.08333333333333, 79.33333333333334, 1.0, 2.0, 0.8136092363476667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1137127.098295576, 1137127.098295576, 247285.7189269558]
[2019-03-26 20:53:48,586] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:53:48,590] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.7637021e-19 1.0000000e+00 1.9325983e-18 1.0835659e-15 1.6724317e-22], sampled 0.6329532465154235
[2019-03-26 20:53:56,094] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07586104], dtype=float32), 0.06269049]
[2019-03-26 20:53:56,095] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.33333333333334, 54.33333333333333, 1.0, 2.0, 0.5815070450223081, 0.0, 2.0, 0.0, 1.0, 2.0, 1.009885429885332, 6.911199999999999, 6.9112, 168.9129561277913, 1625840.795168864, 1625840.795168864, 355933.0405849325]
[2019-03-26 20:53:56,097] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:53:56,102] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.1681861e-16 1.0000000e+00 1.1913817e-15 1.0548230e-12 1.2411710e-18], sampled 0.8794931465563132
[2019-03-26 20:53:56,814] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07586104], dtype=float32), 0.06269049]
[2019-03-26 20:53:56,815] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.70687542666667, 82.57729515, 1.0, 2.0, 0.5561746476643238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 777196.3745264774, 777196.3745264767, 192863.2818193711]
[2019-03-26 20:53:56,817] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:53:56,820] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.851140e-20 1.000000e+00 9.017293e-19 6.787589e-16 7.849601e-23], sampled 0.8312993447198254
[2019-03-26 20:54:00,096] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8724 2842497929.8887 1131.0000
[2019-03-26 20:54:00,127] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 20:54:00,185] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4154 3163997799.2143 1778.0000
[2019-03-26 20:54:00,299] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 20:54:00,318] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.1097 2779315363.5344 933.0000
[2019-03-26 20:54:01,332] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 950000, evaluation results [950000.0, 7883.415429661524, 3163997799.214286, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8659.10971405369, 2779315363.534448, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8496.87235025343, 2842497929.888741, 1131.0]
[2019-03-26 20:54:04,396] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.4745417e-18 1.0000000e+00 1.5025398e-17 2.8769064e-14 5.7025323e-21], sum to 1.0000
[2019-03-26 20:54:04,406] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7158
[2019-03-26 20:54:04,411] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5172292827914047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722755.7521721631, 722755.7521721631, 186339.6530535103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3807600.0000, 
sim time next is 3808200.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5169078942163573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 722306.5037944618, 722306.5037944611, 186287.6925481673], 
processed observation next is [0.0, 0.043478260869565216, 0.5260663507109005, 0.79, 1.0, 1.0, 0.4179613183329606, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2006406954984616, 0.20064069549846142, 0.2780413321614437], 
reward next is 0.7220, 
noisyNet noise sample is [array([-1.0078609], dtype=float32), -0.55364186]. 
=============================================
[2019-03-26 20:54:11,310] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.6849490e-12 1.0000000e+00 2.6648401e-12 1.3737158e-09 7.9239441e-15], sum to 1.0000
[2019-03-26 20:54:11,324] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7099
[2019-03-26 20:54:11,336] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2152205.574575119 W.
[2019-03-26 20:54:11,342] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.66666666666667, 75.66666666666667, 1.0, 2.0, 0.7695863134946676, 1.0, 2.0, 0.7695863134946676, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2152205.574575119, 2152205.574575119, 405330.8848840685], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4009800.0000, 
sim time next is 4010400.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.5201952126951489, 1.0, 2.0, 0.5201952126951489, 1.0, 1.0, 0.8935859335083844, 6.911199999999999, 6.9112, 170.5573041426782, 2182177.615524209, 2182177.61552421, 427530.4201671232], 
processed observation next is [1.0, 0.43478260869565216, 0.5734597156398105, 0.74, 1.0, 1.0, 0.42192194300620345, 1.0, 1.0, 0.42192194300620345, 1.0, 0.5, 0.8702267481809567, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6061604487567247, 0.606160448756725, 0.6381051047270495], 
reward next is 0.3619, 
noisyNet noise sample is [array([0.39157015], dtype=float32), -1.3171666]. 
=============================================
[2019-03-26 20:54:14,059] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.7730954e-13 1.0000000e+00 1.7069849e-12 3.0032696e-10 2.5079748e-15], sum to 1.0000
[2019-03-26 20:54:14,067] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1118
[2019-03-26 20:54:14,075] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1941155.176729104 W.
[2019-03-26 20:54:14,083] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.83333333333333, 79.83333333333334, 1.0, 2.0, 0.4627914408725608, 1.0, 2.0, 0.4627914408725608, 1.0, 2.0, 0.8037156853274392, 6.9112, 6.9112, 170.5573041426782, 1941155.176729104, 1941155.176729104, 390369.9566309965], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3985800.0000, 
sim time next is 3986400.0000, 
raw observation next is [29.66666666666667, 80.66666666666667, 1.0, 2.0, 0.6371745502108916, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.998077467091528, 6.9112, 168.9124356057172, 1781612.722575277, 1719979.047399398, 371629.306917244], 
processed observation next is [1.0, 0.13043478260869565, 0.6050552922590839, 0.8066666666666668, 1.0, 1.0, 0.5628609038685441, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008687746709152755, 0.0, 0.8294373872716867, 0.49489242293757696, 0.4777719576109439, 0.5546706073391702], 
reward next is 0.0109, 
noisyNet noise sample is [array([1.4675952], dtype=float32), -0.47633192]. 
=============================================
[2019-03-26 20:54:24,314] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8357799e-19 1.0000000e+00 5.1455316e-18 2.6862337e-15 2.9631206e-22], sum to 1.0000
[2019-03-26 20:54:24,324] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6841
[2019-03-26 20:54:24,333] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.6253095733433646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 873845.0023829468, 873845.0023829468, 205556.1514635404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4222800.0000, 
sim time next is 4223400.0000, 
raw observation next is [31.16666666666667, 77.66666666666667, 1.0, 2.0, 0.6261640746376792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 875039.6255179587, 875039.6255179587, 205721.643896095], 
processed observation next is [1.0, 0.9130434782608695, 0.6761453396524489, 0.7766666666666667, 1.0, 1.0, 0.5495952706478062, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2430665626438774, 0.2430665626438774, 0.30704722969566417], 
reward next is 0.6930, 
noisyNet noise sample is [array([-0.4589519], dtype=float32), 0.9917569]. 
=============================================
[2019-03-26 20:54:25,229] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.4560431e-18 1.0000000e+00 1.5075742e-18 2.5905296e-15 1.4039731e-22], sum to 1.0000
[2019-03-26 20:54:25,241] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7824
[2019-03-26 20:54:25,246] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666667, 82.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.916186142425426, 6.9112, 168.9128263400949, 1457294.688481161, 1453757.350160787, 311357.4961964511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4173600.0000, 
sim time next is 4174200.0000, 
raw observation next is [31.0, 81.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.263297578968324, 6.9112, 168.9109766956921, 1703713.217283246, 1453926.004269188, 311358.1073930356], 
processed observation next is [1.0, 0.30434782608695654, 0.6682464454976303, 0.815, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.03520975789683236, 0.0, 0.8294302233555716, 0.47325367146756836, 0.4038683345192189, 0.46471359312393373], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.37031186], dtype=float32), 1.4131964]. 
=============================================
[2019-03-26 20:54:25,830] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.2655868e-11 1.0000000e+00 4.8433486e-11 2.5960787e-08 8.0358775e-14], sum to 1.0000
[2019-03-26 20:54:25,839] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1785
[2019-03-26 20:54:25,847] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2765019.118521234 W.
[2019-03-26 20:54:25,850] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.66666666666667, 67.33333333333334, 1.0, 2.0, 0.9884702075183035, 1.0, 2.0, 0.9884702075183035, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2765019.118521234, 2765019.118521235, 522068.2710250695], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4180800.0000, 
sim time next is 4181400.0000, 
raw observation next is [34.0, 65.5, 1.0, 2.0, 0.6824450434438054, 1.0, 2.0, 0.6618125612361652, 1.0, 1.0, 1.03, 7.005096348004823, 6.9112, 170.5573041426782, 2776916.909425229, 2709655.135890138, 515842.9769786153], 
processed observation next is [1.0, 0.391304347826087, 0.8104265402843602, 0.655, 1.0, 1.0, 0.6174036667997655, 1.0, 1.0, 0.5925452545014038, 1.0, 0.5, 1.0365853658536586, 0.009389634800482317, 0.0, 0.8375144448122397, 0.7713658081736747, 0.752681982191705, 0.7699148910128586], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.23936713], dtype=float32), 0.3935637]. 
=============================================
[2019-03-26 20:54:33,122] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.8665447e-11 9.9999952e-01 2.2556723e-10 5.0427627e-07 1.6100104e-13], sum to 1.0000
[2019-03-26 20:54:33,129] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4797
[2019-03-26 20:54:33,136] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [36.16666666666666, 49.66666666666667, 1.0, 2.0, 0.5571315156630094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 778533.9883165538, 778533.9883165538, 193033.9268777779], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4297800.0000, 
sim time next is 4298400.0000, 
raw observation next is [36.0, 50.0, 1.0, 2.0, 0.5650363426496096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 789584.2766094765, 789584.2766094772, 194414.7933898995], 
processed observation next is [1.0, 0.782608695652174, 0.9052132701421801, 0.5, 1.0, 1.0, 0.47594740078266207, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2193289657248546, 0.2193289657248548, 0.29017133341776047], 
reward next is 0.7098, 
noisyNet noise sample is [array([2.7395775], dtype=float32), 1.4584161]. 
=============================================
[2019-03-26 20:54:36,750] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.6764604e-06 9.9717748e-01 5.4728030e-06 2.8132154e-03 9.3442765e-08], sum to 1.0000
[2019-03-26 20:54:36,758] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2155
[2019-03-26 20:54:36,767] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3400074.57651669 W.
[2019-03-26 20:54:36,772] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.16666666666666, 59.0, 1.0, 2.0, 0.9790711017179462, 1.0, 2.0, 0.8101255903732357, 1.0, 2.0, 1.03, 7.005119746977728, 6.9112, 170.5573041426782, 3400074.57651669, 3332796.041345498, 623982.3866349928], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4360200.0000, 
sim time next is 4360800.0000, 
raw observation next is [36.33333333333334, 58.00000000000001, 1.0, 2.0, 0.9995067521537426, 1.0, 2.0, 0.8203434155911338, 1.0, 2.0, 1.03, 7.005121359877788, 6.9112, 170.5573041426782, 3443017.631362226, 3375737.940805112, 632642.1008355919], 
processed observation next is [1.0, 0.4782608695652174, 0.9210110584518172, 0.5800000000000001, 1.0, 1.0, 0.9994057254864369, 1.0, 1.0, 0.7835462838447395, 1.0, 1.0, 1.0365853658536586, 0.009392135987778794, 0.0, 0.8375144448122397, 0.9563937864895072, 0.9377049835569755, 0.9442419415456595], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4189125], dtype=float32), -0.49459237]. 
=============================================
[2019-03-26 20:54:39,848] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.2902471e-19 1.0000000e+00 4.6159801e-18 2.6697252e-15 4.3862969e-22], sum to 1.0000
[2019-03-26 20:54:39,861] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4332
[2019-03-26 20:54:39,866] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 84.0, 1.0, 2.0, 0.6186703196537894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 864563.1358813802, 864563.1358813802, 204275.9750784005], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4409400.0000, 
sim time next is 4410000.0000, 
raw observation next is [30.0, 84.0, 1.0, 2.0, 0.617992481989888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 863615.5040085978, 863615.5040085978, 204146.0588657027], 
processed observation next is [0.0, 0.043478260869565216, 0.6208530805687204, 0.84, 1.0, 1.0, 0.5397499783010699, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23989319555794383, 0.23989319555794383, 0.3046956102473175], 
reward next is 0.6953, 
noisyNet noise sample is [array([1.3637332], dtype=float32), -0.6711551]. 
=============================================
[2019-03-26 20:54:39,874] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[66.88454 ]
 [66.99882 ]
 [67.14727 ]
 [67.33492 ]
 [67.443245]], R is [[67.07459259]
 [67.09896088]
 [67.12314606]
 [67.14749146]
 [67.17181396]].
[2019-03-26 20:54:40,614] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.5605878e-19 1.0000000e+00 4.4142878e-18 4.6225599e-15 2.1152165e-22], sum to 1.0000
[2019-03-26 20:54:40,623] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3319
[2019-03-26 20:54:40,629] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.580097601090425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 810638.9769055882, 810638.9769055882, 197096.7969505157], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4425000.0000, 
sim time next is 4425600.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.5799923344610609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 810491.8192723399, 810491.8192723405, 197077.8147772468], 
processed observation next is [0.0, 0.21739130434782608, 0.5734597156398105, 0.84, 1.0, 1.0, 0.4939666680253746, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22513661646453886, 0.22513661646453903, 0.29414599220484594], 
reward next is 0.7059, 
noisyNet noise sample is [array([1.0821393], dtype=float32), -0.32375768]. 
=============================================
[2019-03-26 20:54:44,839] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4692189e-19 1.0000000e+00 2.5001952e-18 9.2652614e-16 2.1085932e-23], sum to 1.0000
[2019-03-26 20:54:44,853] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5034
[2019-03-26 20:54:44,857] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 81.5, 1.0, 2.0, 0.5315886663888735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742828.0030241485, 742828.0030241485, 188693.4436522572], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4570200.0000, 
sim time next is 4570800.0000, 
raw observation next is [28.0, 82.33333333333334, 1.0, 2.0, 0.5351957552558767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 747870.2284100746, 747870.2284100752, 189294.3949329485], 
processed observation next is [0.0, 0.9130434782608695, 0.5260663507109005, 0.8233333333333335, 1.0, 1.0, 0.4399948858504538, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20774173011390962, 0.20774173011390978, 0.28252894766111714], 
reward next is 0.7175, 
noisyNet noise sample is [array([0.07662498], dtype=float32), -1.1678042]. 
=============================================
[2019-03-26 20:54:48,692] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0938979e-18 1.0000000e+00 1.5225844e-17 1.7297519e-14 2.8262324e-22], sum to 1.0000
[2019-03-26 20:54:48,703] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2788
[2019-03-26 20:54:48,709] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.4921104465037565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 687644.3225295888, 687644.3225295888, 182368.9809710474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4825800.0000, 
sim time next is 4826400.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.4927319954189953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 688513.1175253581, 688513.1175253581, 182464.9332078178], 
processed observation next is [1.0, 0.8695652173913043, 0.5260663507109005, 0.74, 1.0, 1.0, 0.38883372942047634, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19125364375704393, 0.19125364375704393, 0.2723357212056982], 
reward next is 0.7277, 
noisyNet noise sample is [array([0.14391539], dtype=float32), 1.162186]. 
=============================================
[2019-03-26 20:54:51,615] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.9476437e-19 1.0000000e+00 1.8694979e-18 1.5790085e-14 9.4033476e-23], sum to 1.0000
[2019-03-26 20:54:51,622] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4873
[2019-03-26 20:54:51,632] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1657029.516379889 W.
[2019-03-26 20:54:51,636] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.5, 86.5, 1.0, 2.0, 0.5926579280099435, 1.0, 1.0, 0.5926579280099435, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1657029.516379889, 1657029.516379889, 331570.5197829991], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4606200.0000, 
sim time next is 4606800.0000, 
raw observation next is [29.66666666666667, 85.66666666666667, 1.0, 2.0, 0.5417827096919977, 1.0, 2.0, 0.5417827096919977, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1514685.498569606, 1514685.498569606, 313759.3328913067], 
processed observation next is [1.0, 0.30434782608695654, 0.6050552922590839, 0.8566666666666667, 1.0, 1.0, 0.4479309755325273, 1.0, 1.0, 0.4479309755325273, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4207459718248906, 0.4207459718248906, 0.4682975117780697], 
reward next is 0.5317, 
noisyNet noise sample is [array([1.4727695], dtype=float32), -0.98522353]. 
=============================================
[2019-03-26 20:54:56,640] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 20:54:56,642] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:54:56,642] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:54:56,643] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:54:56,644] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:54:56,646] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:54:56,648] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:54:56,651] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:54:56,652] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:54:56,653] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:54:56,650] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:54:56,677] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run40
[2019-03-26 20:54:56,695] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run40
[2019-03-26 20:54:56,715] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run40
[2019-03-26 20:54:56,731] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run40
[2019-03-26 20:54:56,748] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run40
[2019-03-26 20:55:11,536] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07589488], dtype=float32), 0.06134154]
[2019-03-26 20:55:11,537] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [20.6, 94.0, 1.0, 2.0, 0.3063962177478621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 488612.0705346086, 488612.070534608, 166252.2926654936]
[2019-03-26 20:55:11,539] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:55:11,541] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.7573775e-19 1.0000000e+00 7.9089236e-18 1.6560900e-15 1.4418583e-22], sampled 0.4616637784461133
[2019-03-26 20:55:49,760] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07589488], dtype=float32), 0.06134154]
[2019-03-26 20:55:49,761] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.02961140833333, 79.76100348000001, 1.0, 2.0, 0.5656710694624358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 790471.5766977441, 790471.5766977447, 194524.2443509772]
[2019-03-26 20:55:49,763] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:55:49,767] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.1480536e-20 1.0000000e+00 3.9429117e-19 4.4375916e-16 8.5998113e-24], sampled 0.8570819346350498
[2019-03-26 20:56:05,827] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07589488], dtype=float32), 0.06134154]
[2019-03-26 20:56:05,828] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 93.16666666666667, 1.0, 2.0, 0.8720731411064225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1218885.079781418, 1218885.079781418, 262372.7935790793]
[2019-03-26 20:56:05,829] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:56:05,833] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.4081589e-19 1.0000000e+00 1.2738610e-18 8.4691346e-16 2.3031414e-23], sampled 0.4009622821775939
[2019-03-26 20:56:15,325] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07589488], dtype=float32), 0.06134154]
[2019-03-26 20:56:15,327] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.6, 80.33333333333334, 1.0, 2.0, 0.6182201795144697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 863933.8300315007, 863933.8300315007, 204189.7184561313]
[2019-03-26 20:56:15,327] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:56:15,329] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.0051255e-20 1.0000000e+00 1.7852956e-19 3.1471798e-16 3.8877152e-24], sampled 0.5181715939648935
[2019-03-26 20:56:51,672] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.8893 2779265366.1414 933.0000
[2019-03-26 20:56:51,845] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.9106 3164254891.7810 1778.0000
[2019-03-26 20:56:51,893] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.0837 3007805556.0190 1766.0000
[2019-03-26 20:56:51,981] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.5590 2927409635.8428 1338.0000
[2019-03-26 20:56:51,991] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.4166 2842558242.3972 1131.0000
[2019-03-26 20:56:53,007] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 975000, evaluation results [975000.0, 7881.910573284552, 3164254891.78102, 1778.0, 8253.559004724644, 2927409635.8427854, 1338.0, 8659.88925272283, 2779265366.141443, 933.0, 7996.083716631031, 3007805556.0189595, 1766.0, 8497.416582222564, 2842558242.397172, 1131.0]
[2019-03-26 20:56:53,377] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5765639e-19 1.0000000e+00 6.4071136e-18 8.2921889e-16 5.3427220e-23], sum to 1.0000
[2019-03-26 20:56:53,391] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6407
[2019-03-26 20:56:53,396] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.00000000000001, 1.0, 2.0, 0.6504004919059506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 908923.556545309, 908923.5565453096, 210500.1410584522], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4770600.0000, 
sim time next is 4771200.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.6452299467925651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 901694.7408924326, 901694.7408924319, 209463.995573637], 
processed observation next is [1.0, 0.21739130434782608, 0.4786729857819906, 0.79, 1.0, 1.0, 0.5725662009548976, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2504707613590091, 0.25047076135900886, 0.31263282921438357], 
reward next is 0.6874, 
noisyNet noise sample is [array([-1.1273773], dtype=float32), -0.7695511]. 
=============================================
[2019-03-26 20:56:53,484] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.9681844e-11 9.9999988e-01 6.2456601e-10 1.2272162e-07 5.6923834e-13], sum to 1.0000
[2019-03-26 20:56:53,492] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7286
[2019-03-26 20:56:53,500] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1916042.581602974 W.
[2019-03-26 20:56:53,506] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.13333333333333, 65.33333333333333, 1.0, 2.0, 0.7292370626344379, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.975399280498166, 6.9112, 168.9125745541166, 1916042.581602974, 1870497.505438412, 392173.4509772705], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4966800.0000, 
sim time next is 4967400.0000, 
raw observation next is [30.16666666666667, 65.16666666666667, 1.0, 2.0, 0.7570342806752752, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.97413158129388, 6.9112, 168.9125296804085, 1954942.941756586, 1910297.224865408, 398597.7540567368], 
processed observation next is [1.0, 0.4782608695652174, 0.6287519747235389, 0.6516666666666667, 1.0, 1.0, 0.7072702176810545, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.006293158129387954, 0.0, 0.8294378492214887, 0.5430397060434962, 0.5306381180181688, 0.5949220209802042], 
reward next is 0.0904, 
noisyNet noise sample is [array([0.12073161], dtype=float32), 0.27293828]. 
=============================================
[2019-03-26 20:56:54,366] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.7387959e-10 9.9999928e-01 2.2533511e-09 7.5916904e-07 1.6432975e-12], sum to 1.0000
[2019-03-26 20:56:54,373] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1237
[2019-03-26 20:56:54,384] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1757499.476522023 W.
[2019-03-26 20:56:54,388] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.6285628589302136, 1.0, 2.0, 0.6285628589302136, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1757499.476522023, 1757499.476522023, 345042.0442080645], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4712400.0000, 
sim time next is 4713000.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.665462205573246, 1.0, 2.0, 0.665462205573246, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1860761.848449361, 1860761.848449361, 359689.5675666216], 
processed observation next is [1.0, 0.5652173913043478, 0.6682464454976303, 0.66, 1.0, 1.0, 0.5969424163533084, 1.0, 1.0, 0.5969424163533084, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5168782912359337, 0.5168782912359337, 0.5368501008457038], 
reward next is 0.4631, 
noisyNet noise sample is [array([-1.2687713], dtype=float32), 1.3870908]. 
=============================================
[2019-03-26 20:56:54,409] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[35.23207 ]
 [33.91602 ]
 [32.89676 ]
 [30.428926]
 [29.495804]], R is [[36.19873047]
 [36.32175446]
 [35.95853806]
 [35.59895325]
 [35.2429657 ]].
[2019-03-26 20:56:57,831] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.4468809e-13 1.0000000e+00 1.0990538e-12 5.6306687e-10 2.6410172e-16], sum to 1.0000
[2019-03-26 20:56:57,837] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3383
[2019-03-26 20:56:57,846] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2141342.025152147 W.
[2019-03-26 20:56:57,852] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.33333333333334, 68.66666666666667, 1.0, 2.0, 0.8902162328121819, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.988975054674748, 6.9112, 168.9124938349144, 2141342.025152147, 2086165.875690461, 431986.6997656179], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4785600.0000, 
sim time next is 4786200.0000, 
raw observation next is [30.5, 68.0, 1.0, 2.0, 0.5099463256797695, 1.0, 1.0, 0.5099463256797695, 1.0, 2.0, 0.8806616194755796, 6.9112, 6.9112, 170.5573041426782, 2139141.418509251, 2139141.418509251, 421178.9847887268], 
processed observation next is [1.0, 0.391304347826087, 0.6445497630331753, 0.68, 1.0, 1.0, 0.40957388636116804, 1.0, 0.5, 0.40957388636116804, 1.0, 1.0, 0.8544653896043655, 0.0, 0.0, 0.8375144448122397, 0.594205949585903, 0.594205949585903, 0.6286253504309355], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2804032], dtype=float32), 0.34808767]. 
=============================================
[2019-03-26 20:56:58,595] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3029884e-08 9.9999690e-01 3.2121259e-09 3.1301902e-06 3.7260282e-11], sum to 1.0000
[2019-03-26 20:56:58,603] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9421
[2019-03-26 20:56:58,613] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2049940.364235335 W.
[2019-03-26 20:56:58,617] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.4887021632903534, 1.0, 2.0, 0.4887021632903534, 1.0, 2.0, 0.8464974143791002, 6.9112, 6.9112, 170.5573041426782, 2049940.364235335, 2049940.364235335, 407031.6238271805], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4791600.0000, 
sim time next is 4792200.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.73148383836194, 1.0, 2.0, 0.73148383836194, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2045547.420800778, 2045547.420800778, 387893.0159902875], 
processed observation next is [1.0, 0.4782608695652174, 0.6682464454976303, 0.66, 1.0, 1.0, 0.6764865522433011, 1.0, 1.0, 0.6764865522433011, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.568207616889105, 0.568207616889105, 0.5789447999855037], 
reward next is 0.4211, 
noisyNet noise sample is [array([-0.4794026], dtype=float32), 1.8639405]. 
=============================================
[2019-03-26 20:57:03,387] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2798465e-19 1.0000000e+00 2.8879662e-19 6.4631388e-16 3.6257975e-23], sum to 1.0000
[2019-03-26 20:57:03,396] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5539
[2019-03-26 20:57:03,400] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.8657238211015147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1210005.662553092, 1210005.662553092, 260680.6476420635], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4945800.0000, 
sim time next is 4946400.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.698444760184059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 976095.4535506312, 976095.4535506305, 220507.5525312316], 
processed observation next is [1.0, 0.2608695652173913, 0.4312796208530806, 0.89, 1.0, 1.0, 0.6366804339566976, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.27113762598628643, 0.27113762598628627, 0.3291157500466143], 
reward next is 0.6709, 
noisyNet noise sample is [array([-0.48957855], dtype=float32), 0.5284404]. 
=============================================
[2019-03-26 20:57:13,493] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1894538e-19 1.0000000e+00 1.8257731e-18 4.9676301e-16 4.3610495e-24], sum to 1.0000
[2019-03-26 20:57:13,504] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0653
[2019-03-26 20:57:13,509] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 65.0, 1.0, 2.0, 0.508066914699337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709948.342770735, 709948.3427707345, 184870.064162707], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5048400.0000, 
sim time next is 5049000.0000, 
raw observation next is [30.5, 64.5, 1.0, 2.0, 0.5102633896284433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 713018.6215941472, 713018.6215941465, 185220.1944383688], 
processed observation next is [0.0, 0.43478260869565216, 0.6445497630331753, 0.645, 1.0, 1.0, 0.40995589111860636, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19806072822059645, 0.19806072822059625, 0.27644805140055045], 
reward next is 0.7236, 
noisyNet noise sample is [array([0.5558546], dtype=float32), -1.687391]. 
=============================================
[2019-03-26 20:57:13,521] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[72.708206]
 [72.73452 ]
 [72.744095]
 [72.75531 ]
 [72.77722 ]], R is [[72.67565155]
 [72.67297363]
 [72.67095947]
 [72.66893005]
 [72.66659546]].
[2019-03-26 20:57:17,677] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7461461e-19 1.0000000e+00 2.5193047e-18 4.3857918e-16 1.2438939e-22], sum to 1.0000
[2019-03-26 20:57:17,686] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3212
[2019-03-26 20:57:17,695] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4814376300807592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 672851.568051295, 672851.5680512957, 180754.442465774], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5115600.0000, 
sim time next is 5116200.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4811471539177737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 672445.3420356801, 672445.3420356801, 180710.5309765235], 
processed observation next is [0.0, 0.21739130434782608, 0.4312796208530806, 0.84, 1.0, 1.0, 0.3748760890575587, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18679037278768892, 0.18679037278768892, 0.2697172104127216], 
reward next is 0.7303, 
noisyNet noise sample is [array([-0.02470719], dtype=float32), -0.016369013]. 
=============================================
[2019-03-26 20:57:21,776] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3664127e-20 1.0000000e+00 4.6539362e-20 9.0203649e-17 7.0802717e-25], sum to 1.0000
[2019-03-26 20:57:21,783] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1838
[2019-03-26 20:57:21,788] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 79.0, 1.0, 2.0, 0.5060471560311154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 707125.0894830591, 707125.0894830597, 184548.2607312716], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5179200.0000, 
sim time next is 5179800.0000, 
raw observation next is [27.16666666666666, 79.0, 1.0, 2.0, 0.5006537658082684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 699586.1529506514, 699586.1529506508, 183697.824478063], 
processed observation next is [0.0, 0.9565217391304348, 0.4865718799368086, 0.79, 1.0, 1.0, 0.3983780310942992, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19432948693073648, 0.19432948693073632, 0.27417585742994477], 
reward next is 0.7258, 
noisyNet noise sample is [array([1.9712077], dtype=float32), 1.6685148]. 
=============================================
[2019-03-26 20:57:22,018] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.4522015e-09 9.9999392e-01 7.8650455e-09 6.0972034e-06 2.2117854e-11], sum to 1.0000
[2019-03-26 20:57:22,031] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5999
[2019-03-26 20:57:22,044] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2832216.513018818 W.
[2019-03-26 20:57:22,050] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.06666666666666, 52.5, 1.0, 2.0, 1.012465488733521, 1.0, 2.0, 1.012465488733521, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2832216.513018818, 2832216.513018818, 536568.9653328168], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5309400.0000, 
sim time next is 5310000.0000, 
raw observation next is [36.4, 51.0, 1.0, 2.0, 1.008226203770889, 1.0, 2.0, 1.008226203770889, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2820344.378254774, 2820344.378254774, 533981.2221668637], 
processed observation next is [1.0, 0.4782608695652174, 0.924170616113744, 0.51, 1.0, 1.0, 1.0099110888805891, 1.0, 1.0, 1.0099110888805891, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7834289939596595, 0.7834289939596595, 0.7969868987565131], 
reward next is 0.2030, 
noisyNet noise sample is [array([0.5724877], dtype=float32), 0.99173814]. 
=============================================
[2019-03-26 20:57:22,062] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[29.811827]
 [30.034449]
 [30.117075]
 [32.757328]
 [33.644188]], R is [[29.99594498]
 [29.89513588]
 [29.59618568]
 [29.3002243 ]
 [29.00722313]].
[2019-03-26 20:57:25,981] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.5300308e-19 1.0000000e+00 5.2814198e-17 3.5756656e-14 3.0403280e-22], sum to 1.0000
[2019-03-26 20:57:25,987] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4911
[2019-03-26 20:57:25,992] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.81666666666667, 78.83333333333334, 1.0, 2.0, 0.5452327300927857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 761900.6960647892, 761900.6960647892, 190986.6117764753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5255400.0000, 
sim time next is 5256000.0000, 
raw observation next is [28.8, 79.0, 1.0, 2.0, 0.5473916124312921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 764918.5746976368, 764918.5746976368, 191354.3720096959], 
processed observation next is [1.0, 0.8695652173913043, 0.5639810426540285, 0.79, 1.0, 1.0, 0.4546886896762555, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21247738186045464, 0.21247738186045464, 0.2856035403129789], 
reward next is 0.7144, 
noisyNet noise sample is [array([1.1411986], dtype=float32), -1.8633897]. 
=============================================
[2019-03-26 20:57:26,006] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[67.05404 ]
 [66.21162 ]
 [65.334984]
 [63.7592  ]
 [61.79158 ]], R is [[67.97387695]
 [68.00907898]
 [68.04467773]
 [68.0796814 ]
 [68.11398315]].
[2019-03-26 20:57:29,407] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.5487611e-10 9.9999952e-01 1.1415379e-09 5.2606936e-07 1.6391439e-12], sum to 1.0000
[2019-03-26 20:57:29,415] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6873
[2019-03-26 20:57:29,426] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2635976.034523997 W.
[2019-03-26 20:57:29,433] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.4, 60.0, 1.0, 2.0, 0.9423870472655778, 1.0, 2.0, 0.9423870472655778, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2635976.034523997, 2635976.034523997, 495152.1615209293], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5306400.0000, 
sim time next is 5307000.0000, 
raw observation next is [34.73333333333333, 58.5, 1.0, 2.0, 0.9367147163285413, 1.0, 2.0, 0.9367147163285413, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2620093.169288582, 2620093.169288582, 491925.8662141053], 
processed observation next is [1.0, 0.43478260869565216, 0.8451816745655606, 0.585, 1.0, 1.0, 0.923752670275351, 1.0, 1.0, 0.923752670275351, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7278036581357172, 0.7278036581357172, 0.7342177107673213], 
reward next is 0.2658, 
noisyNet noise sample is [array([-0.7554696], dtype=float32), -1.528562]. 
=============================================
[2019-03-26 20:57:29,447] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[32.824768]
 [33.48079 ]
 [34.577618]
 [38.071102]
 [39.212082]], R is [[32.69287872]
 [32.62691879]
 [32.30065155]
 [31.97764587]
 [31.89770317]].
[2019-03-26 20:57:33,200] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.4665632e-17 1.0000000e+00 5.3425984e-16 3.3547899e-13 4.6292161e-21], sum to 1.0000
[2019-03-26 20:57:33,209] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1671
[2019-03-26 20:57:33,219] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.68333333333334, 84.83333333333334, 1.0, 2.0, 0.9271896082850597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1295967.652439482, 1295967.652439482, 277531.9163570391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5379000.0000, 
sim time next is 5379600.0000, 
raw observation next is [29.86666666666667, 83.66666666666667, 1.0, 2.0, 1.00421400093909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1403698.707146698, 1403698.707146698, 300218.0830243566], 
processed observation next is [1.0, 0.2608695652173913, 0.6145339652448659, 0.8366666666666667, 1.0, 1.0, 1.0050771095651687, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3899163075407494, 0.3899163075407494, 0.4480866910811292], 
reward next is 0.5519, 
noisyNet noise sample is [array([0.32304898], dtype=float32), 1.2437047]. 
=============================================
[2019-03-26 20:57:35,006] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9446426e-05 9.6833313e-01 1.8082244e-05 3.1629201e-02 6.4193159e-08], sum to 1.0000
[2019-03-26 20:57:35,013] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7710
[2019-03-26 20:57:35,017] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [36.96666666666667, 58.00000000000001, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 8.757578370963664, 6.9112, 170.5573041426782, 4233506.814277962, 2910870.88128653, 541802.2791854424], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5404800.0000, 
sim time next is 5405400.0000, 
raw observation next is [36.95, 57.0, 1.0, 2.0, 1.04, 1.0, 2.0, 0.9323135439794149, 1.0, 1.0, 1.03, 7.363478861723502, 6.9112, 170.5573041426782, 3913697.883497291, 3589712.137316917, 672822.7083202585], 
processed observation next is [1.0, 0.5652173913043478, 0.9502369668246446, 0.57, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 0.9184500529872469, 1.0, 0.5, 1.0365853658536586, 0.045227886172350205, 0.0, 0.8375144448122397, 1.0871383009714697, 0.9971422603658103, 1.0042129974929233], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.522675], dtype=float32), -1.7724282]. 
=============================================
[2019-03-26 20:57:35,833] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2623643e-05 9.6017945e-01 1.3011032e-05 3.9784878e-02 4.4871747e-08], sum to 1.0000
[2019-03-26 20:57:35,841] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9909
[2019-03-26 20:57:35,847] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.5, 53.5, 1.0, 2.0, 0.83932350779629, 1.0, 2.0, 0.7402517934124074, 1.0, 1.0, 1.03, 7.005108720257568, 6.9112, 170.5573041426782, 3106451.435430883, 3039180.79914788, 568946.842622049], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5412600.0000, 
sim time next is 5413200.0000, 
raw observation next is [36.0, 53.33333333333333, 1.0, 2.0, 0.9859595428723203, 1.0, 2.0, 0.9859595428723203, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2757988.356558115, 2757988.356558115, 520565.2754785069], 
processed observation next is [1.0, 0.6521739130434783, 0.9052132701421801, 0.5333333333333333, 1.0, 1.0, 0.9830837865931571, 1.0, 1.0, 0.9830837865931571, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7661078768216987, 0.7661078768216987, 0.7769630977291149], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.75675035], dtype=float32), 0.9424458]. 
=============================================
[2019-03-26 20:57:38,484] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.0326431e-20 1.0000000e+00 4.2383184e-18 2.7788826e-15 1.7140387e-23], sum to 1.0000
[2019-03-26 20:57:38,488] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2056
[2019-03-26 20:57:38,493] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3640588e-19 1.0000000e+00 1.2787540e-18 8.8830622e-16 2.0782468e-24], sum to 1.0000
[2019-03-26 20:57:38,495] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.08333333333334, 80.16666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.961979922733856, 6.9112, 168.9124318028578, 1489804.51202544, 1453779.599035345, 311355.0240488254], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5469000.0000, 
sim time next is 5469600.0000, 
raw observation next is [30.26666666666667, 79.33333333333334, 1.0, 2.0, 0.9433032354491814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129151632572, 1318504.258749772, 1318504.258749772, 282131.7719618179], 
processed observation next is [1.0, 0.30434782608695654, 0.6334913112164299, 0.7933333333333334, 1.0, 1.0, 0.9316906451194956, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294397421187505, 0.3662511829860478, 0.3662511829860478, 0.4210921969579372], 
reward next is 0.5789, 
noisyNet noise sample is [array([-0.69866985], dtype=float32), 0.7515816]. 
=============================================
[2019-03-26 20:57:38,500] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1583
[2019-03-26 20:57:38,503] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.2, 66.5, 1.0, 2.0, 0.5188215423091408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 724981.4719438948, 724981.4719438948, 186597.6618802674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5736600.0000, 
sim time next is 5737200.0000, 
raw observation next is [30.36666666666667, 65.66666666666667, 1.0, 2.0, 0.5187050071485437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 724818.5745895375, 724818.5745895375, 186578.7846418523], 
processed observation next is [0.0, 0.391304347826087, 0.6382306477093209, 0.6566666666666667, 1.0, 1.0, 0.4201265146367996, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2013384929415382, 0.2013384929415382, 0.2784757979729139], 
reward next is 0.7215, 
noisyNet noise sample is [array([1.3217824], dtype=float32), -0.19459242]. 
=============================================
[2019-03-26 20:57:45,336] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.4683973e-09 9.9999642e-01 1.5789436e-09 3.5735914e-06 3.4662468e-12], sum to 1.0000
[2019-03-26 20:57:45,344] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9377
[2019-03-26 20:57:45,355] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2369730.995497529 W.
[2019-03-26 20:57:45,361] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.7, 60.33333333333334, 1.0, 2.0, 0.8472920335410258, 1.0, 2.0, 0.8472920335410258, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2369730.995497529, 2369730.995497529, 443551.818520732], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5570400.0000, 
sim time next is 5571000.0000, 
raw observation next is [32.8, 59.5, 1.0, 2.0, 0.5415839278569684, 1.0, 2.0, 0.5415839278569684, 1.0, 1.0, 0.940552178145734, 6.9112, 6.9112, 170.5573041426782, 2271987.745457427, 2271987.745457427, 445093.1337440636], 
processed observation next is [1.0, 0.4782608695652174, 0.7535545023696681, 0.595, 1.0, 1.0, 0.44769147934574505, 1.0, 1.0, 0.44769147934574505, 1.0, 0.5, 0.9275026562752854, 0.0, 0.0, 0.8375144448122397, 0.6311077070715075, 0.6311077070715075, 0.6643181100657666], 
reward next is 0.3357, 
noisyNet noise sample is [array([0.2438074], dtype=float32), 0.93082124]. 
=============================================
[2019-03-26 20:57:45,371] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[30.329443]
 [30.291403]
 [30.612011]
 [33.40089 ]
 [33.8848  ]], R is [[28.58640099]
 [28.63851929]
 [28.3521347 ]
 [28.06861305]
 [28.14788437]].
[2019-03-26 20:57:47,372] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.8308607e-20 1.0000000e+00 1.5160923e-18 1.6273017e-15 2.1857173e-23], sum to 1.0000
[2019-03-26 20:57:47,381] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7777
[2019-03-26 20:57:47,389] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.85, 90.0, 1.0, 2.0, 0.5414135592833833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 756561.938858219, 756561.9388582197, 190338.7116191654], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5610600.0000, 
sim time next is 5611200.0000, 
raw observation next is [26.76666666666667, 90.0, 1.0, 2.0, 0.5384643945517558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 752439.3674601886, 752439.367460188, 189841.7069438901], 
processed observation next is [1.0, 0.9565217391304348, 0.46761453396524505, 0.9, 1.0, 1.0, 0.4439330054840431, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20901093540560794, 0.20901093540560778, 0.2833458312595375], 
reward next is 0.7167, 
noisyNet noise sample is [array([0.8676477], dtype=float32), 0.51233345]. 
=============================================
[2019-03-26 20:57:47,962] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.11050815e-20 1.00000000e+00 1.34627587e-19 1.86294394e-15
 3.39774767e-25], sum to 1.0000
[2019-03-26 20:57:47,975] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5973
[2019-03-26 20:57:47,983] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.56666666666667, 87.0, 1.0, 2.0, 0.5164692057412986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 721693.2897524032, 721693.2897524037, 186216.2916922576], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5700000.0000, 
sim time next is 5700600.0000, 
raw observation next is [26.55, 87.0, 1.0, 2.0, 0.5155360072540192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 720388.8335553042, 720388.8335553035, 186065.6733481382], 
processed observation next is [0.0, 1.0, 0.4573459715639811, 0.87, 1.0, 1.0, 0.4163084424747219, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20010800932091782, 0.20010800932091763, 0.2777099602211018], 
reward next is 0.7223, 
noisyNet noise sample is [array([0.6415457], dtype=float32), 0.17649907]. 
=============================================
[2019-03-26 20:57:48,489] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 20:57:48,494] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:57:48,496] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:57:48,497] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:57:48,498] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:57:48,498] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:57:48,515] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:57:48,504] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:57:48,528] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:57:48,521] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:57:48,558] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:57:48,913] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run41
[2019-03-26 20:57:49,005] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run41
[2019-03-26 20:57:49,016] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run41
[2019-03-26 20:57:49,274] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run41
[2019-03-26 20:57:49,290] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run41
[2019-03-26 20:58:44,277] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07793801], dtype=float32), 0.06136985]
[2019-03-26 20:58:44,279] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.8430654, 62.22186902, 1.0, 2.0, 1.021662486822666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1428104.75195319, 1428104.751953189, 305596.5243679656]
[2019-03-26 20:58:44,281] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:58:44,283] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.3502437e-19 1.0000000e+00 2.4741138e-18 3.8315789e-15 7.0503352e-23], sampled 0.8424791482131408
[2019-03-26 20:59:37,709] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07793801], dtype=float32), 0.06136985]
[2019-03-26 20:59:37,709] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.36666666666667, 90.0, 1.0, 2.0, 0.3821606821028495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 573289.9408775953, 573289.9408775946, 172204.3705864997]
[2019-03-26 20:59:37,710] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:59:37,716] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1282851e-19 1.0000000e+00 1.2313148e-18 4.4661390e-16 1.1444036e-23], sampled 0.4817664702008573
[2019-03-26 20:59:42,948] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.5064 2779290623.4488 933.0000
[2019-03-26 20:59:43,348] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6749 3164129388.9823 1778.0000
[2019-03-26 20:59:43,943] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.1321 2842451957.6633 1131.0000
[2019-03-26 20:59:43,977] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.7395 3007855093.9336 1766.0000
[2019-03-26 20:59:44,069] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.8488 2927539683.3633 1338.0000
[2019-03-26 20:59:45,086] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1000000, evaluation results [1000000.0, 7882.674904135256, 3164129388.982254, 1778.0, 8252.848818411621, 2927539683.363314, 1338.0, 8658.506407847246, 2779290623.4488473, 933.0, 7996.739487620537, 3007855093.933641, 1766.0, 8496.132105234119, 2842451957.6632614, 1131.0]
[2019-03-26 20:59:47,960] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.4309854e-20 1.0000000e+00 1.9664790e-19 3.1363335e-16 1.8321934e-24], sum to 1.0000
[2019-03-26 20:59:47,968] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4520
[2019-03-26 20:59:47,972] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666666, 71.66666666666666, 1.0, 2.0, 0.5329130095245321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 744679.2539343757, 744679.2539343757, 188913.6345181573], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5683200.0000, 
sim time next is 5683800.0000, 
raw observation next is [29.43333333333333, 72.83333333333334, 1.0, 2.0, 0.5322740261263339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 743786.0419720585, 743786.0419720579, 188807.3144585471], 
processed observation next is [0.0, 0.782608695652174, 0.5939968404423379, 0.7283333333333334, 1.0, 1.0, 0.4364747302726914, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20660723388112737, 0.2066072338811272, 0.2818019618784285], 
reward next is 0.7182, 
noisyNet noise sample is [array([1.2199154], dtype=float32), -1.4340261]. 
=============================================
[2019-03-26 20:59:51,604] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.5432248e-21 1.0000000e+00 7.6346827e-19 4.8431422e-16 7.8015646e-24], sum to 1.0000
[2019-03-26 20:59:51,614] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4360
[2019-03-26 20:59:51,622] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.0, 53.0, 1.0, 2.0, 0.5359444086305802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 748916.7481963548, 748916.7481963541, 189420.552626323], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5756400.0000, 
sim time next is 5757000.0000, 
raw observation next is [33.81666666666667, 53.83333333333334, 1.0, 2.0, 0.5579740119941156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779711.722389029, 779711.722389029, 193177.2254882831], 
processed observation next is [0.0, 0.6521739130434783, 0.8017377567140602, 0.5383333333333334, 1.0, 1.0, 0.4674385686676091, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21658658955250806, 0.21658658955250806, 0.28832421714669115], 
reward next is 0.7117, 
noisyNet noise sample is [array([0.9185535], dtype=float32), 0.802647]. 
=============================================
[2019-03-26 20:59:51,640] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[71.157646]
 [71.13721 ]
 [71.13244 ]
 [71.12805 ]
 [71.13153 ]], R is [[71.18560791]
 [71.19104004]
 [71.19773865]
 [71.20547485]
 [71.21438599]].
[2019-03-26 20:59:57,097] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2660420e-18 1.0000000e+00 9.2197303e-19 2.1286772e-15 9.8179593e-24], sum to 1.0000
[2019-03-26 20:59:57,105] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0912
[2019-03-26 20:59:57,108] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 92.0, 1.0, 2.0, 0.5585769165991905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780554.5295859132, 780554.5295859132, 193282.6554188319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5958000.0000, 
sim time next is 5958600.0000, 
raw observation next is [27.15, 91.83333333333334, 1.0, 2.0, 0.5562878331980117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777354.5974442194, 777354.5974442194, 192885.0075366251], 
processed observation next is [1.0, 1.0, 0.485781990521327, 0.9183333333333334, 1.0, 1.0, 0.46540702794941163, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21593183262339427, 0.21593183262339427, 0.28788807095018676], 
reward next is 0.7121, 
noisyNet noise sample is [array([1.2558146], dtype=float32), -0.31160393]. 
=============================================
[2019-03-26 20:59:57,150] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4533846e-10 9.9999809e-01 1.6264253e-09 1.9566839e-06 9.0231875e-13], sum to 1.0000
[2019-03-26 20:59:57,156] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3242
[2019-03-26 20:59:57,164] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1955378.578880651 W.
[2019-03-26 20:59:57,169] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.6, 63.0, 1.0, 2.0, 0.6992690327235931, 1.0, 1.0, 0.6992690327235931, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1955378.578880651, 1955378.578880651, 373818.2353881682], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5835600.0000, 
sim time next is 5836200.0000, 
raw observation next is [32.65, 62.66666666666666, 1.0, 2.0, 0.5343426919900258, 1.0, 2.0, 0.5343426919900258, 1.0, 1.0, 0.9279765461581492, 6.9112, 6.9112, 170.5573041426782, 2241582.941045094, 2241582.941045094, 439707.474372201], 
processed observation next is [1.0, 0.5652173913043478, 0.7464454976303317, 0.6266666666666666, 1.0, 1.0, 0.4389670987831636, 1.0, 1.0, 0.4389670987831636, 1.0, 0.5, 0.9121665197050598, 0.0, 0.0, 0.8375144448122397, 0.6226619280680816, 0.6226619280680816, 0.6562798124958225], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2662417], dtype=float32), -1.1899747]. 
=============================================
[2019-03-26 20:59:58,013] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.7831686e-09 9.9987519e-01 3.7210850e-08 1.2476741e-04 5.2334890e-11], sum to 1.0000
[2019-03-26 20:59:58,024] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8735
[2019-03-26 20:59:58,031] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2366198.110659766 W.
[2019-03-26 20:59:58,035] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.95, 76.33333333333334, 1.0, 2.0, 0.5640200354794015, 1.0, 1.0, 0.5640200354794015, 1.0, 2.0, 0.9795162773517294, 6.9112, 6.9112, 170.5573041426782, 2366198.110659766, 2366198.110659766, 462240.0201006327], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5929800.0000, 
sim time next is 5930400.0000, 
raw observation next is [30.0, 76.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.455131074472712, 6.9112, 168.9099559417075, 2669910.247638114, 2284033.677575166, 474891.4102066854], 
processed observation next is [1.0, 0.6521739130434783, 0.6208530805687204, 0.7666666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.054393107447271216, 0.0, 0.8294252109862039, 0.7416417354550316, 0.634453799326435, 0.7087931495622171], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.16121411], dtype=float32), 1.1361517]. 
=============================================
[2019-03-26 21:00:02,717] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.7111790e-15 1.0000000e+00 1.8028657e-13 5.1826043e-11 7.8873770e-19], sum to 1.0000
[2019-03-26 21:00:02,726] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9494
[2019-03-26 21:00:02,730] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.25, 80.5, 1.0, 2.0, 0.5296007756582151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 740049.2092168102, 740049.2092168102, 188364.34514583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6201000.0000, 
sim time next is 6201600.0000, 
raw observation next is [28.16666666666666, 81.0, 1.0, 2.0, 0.5294392445132065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 739823.411539051, 739823.411539051, 188337.6208923114], 
processed observation next is [1.0, 0.782608695652174, 0.5339652448657185, 0.81, 1.0, 1.0, 0.43305933073880293, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20550650320529193, 0.20550650320529193, 0.28110092670494236], 
reward next is 0.7189, 
noisyNet noise sample is [array([-0.45639235], dtype=float32), 2.4901843]. 
=============================================
[2019-03-26 21:00:04,240] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6269205e-18 1.0000000e+00 1.2879634e-17 2.3402023e-14 2.4031153e-23], sum to 1.0000
[2019-03-26 21:00:04,248] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3828
[2019-03-26 21:00:04,252] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 83.0, 1.0, 2.0, 0.5555106039364517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 776268.1032273677, 776268.1032273677, 192750.558847794], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5947200.0000, 
sim time next is 5947800.0000, 
raw observation next is [28.43333333333333, 83.5, 1.0, 2.0, 0.5542947447851586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 774568.4474511578, 774568.4474511571, 192540.3891611593], 
processed observation next is [1.0, 0.8695652173913043, 0.546603475513428, 0.835, 1.0, 1.0, 0.46300571660862483, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21515790206976607, 0.21515790206976587, 0.2873737151659094], 
reward next is 0.7126, 
noisyNet noise sample is [array([1.241351], dtype=float32), 1.9625657]. 
=============================================
[2019-03-26 21:00:05,131] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8510434e-20 1.0000000e+00 1.1967775e-18 1.4920538e-16 3.5496492e-24], sum to 1.0000
[2019-03-26 21:00:05,142] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9070
[2019-03-26 21:00:05,150] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 92.66666666666667, 1.0, 2.0, 0.6213281476404795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 868278.8456684981, 868278.8456684987, 204779.9012124394], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5980800.0000, 
sim time next is 5981400.0000, 
raw observation next is [26.35, 92.0, 1.0, 2.0, 0.6178315982302748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 863390.5851196287, 863390.585119628, 204108.6099141939], 
processed observation next is [1.0, 0.21739130434782608, 0.4478672985781992, 0.92, 1.0, 1.0, 0.5395561424461142, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23983071808878575, 0.23983071808878556, 0.3046397162898416], 
reward next is 0.6954, 
noisyNet noise sample is [array([0.36789906], dtype=float32), -0.05980147]. 
=============================================
[2019-03-26 21:00:09,948] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1349160e-18 1.0000000e+00 1.5032271e-18 5.6211902e-15 7.9749444e-24], sum to 1.0000
[2019-03-26 21:00:09,961] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1949
[2019-03-26 21:00:09,968] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.18333333333333, 93.0, 1.0, 2.0, 0.7186882424336557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1004399.64630749, 1004399.64630749, 224930.2274513614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6059400.0000, 
sim time next is 6060000.0000, 
raw observation next is [26.16666666666667, 93.0, 1.0, 2.0, 0.6952603385547894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 971643.1022969646, 971643.1022969646, 219824.931110276], 
processed observation next is [1.0, 0.13043478260869565, 0.4391785150078992, 0.93, 1.0, 1.0, 0.6328437813913125, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.26990086174915684, 0.26990086174915684, 0.32809691210488956], 
reward next is 0.6719, 
noisyNet noise sample is [array([-0.6648938], dtype=float32), 1.9924638]. 
=============================================
[2019-03-26 21:00:09,980] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[68.728714]
 [68.463715]
 [68.21977 ]
 [68.0018  ]
 [67.94719 ]], R is [[68.90776825]
 [68.88297272]
 [68.84473419]
 [68.80590057]
 [68.75110626]].
[2019-03-26 21:00:14,324] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7348622e-19 1.0000000e+00 1.7388925e-17 4.0934731e-14 1.4944467e-23], sum to 1.0000
[2019-03-26 21:00:14,334] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4226
[2019-03-26 21:00:14,339] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.36666666666667, 85.0, 1.0, 2.0, 0.5255001495933351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 734317.1292335063, 734317.1292335069, 187688.1301361267], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6119400.0000, 
sim time next is 6120000.0000, 
raw observation next is [27.2, 86.0, 1.0, 2.0, 0.5259561978209946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 734954.6169261284, 734954.616926129, 187762.9799009111], 
processed observation next is [1.0, 0.8695652173913043, 0.4881516587677725, 0.86, 1.0, 1.0, 0.42886288894095725, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20415406025725788, 0.20415406025725805, 0.2802432535834494], 
reward next is 0.7198, 
noisyNet noise sample is [array([-0.13250867], dtype=float32), -1.4493442]. 
=============================================
[2019-03-26 21:00:14,359] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[66.3176  ]
 [65.39112 ]
 [63.774216]
 [62.45028 ]
 [60.96023 ]], R is [[67.42297363]
 [67.46861267]
 [67.51383972]
 [67.55853271]
 [67.60275269]].
[2019-03-26 21:00:15,368] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.3074065e-18 1.0000000e+00 6.5257642e-17 2.1798278e-14 6.3718317e-22], sum to 1.0000
[2019-03-26 21:00:15,377] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0312
[2019-03-26 21:00:15,383] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 92.0, 1.0, 2.0, 0.7233181724426507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1010873.264611454, 1010873.264611454, 225959.1443215516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6147000.0000, 
sim time next is 6147600.0000, 
raw observation next is [26.6, 92.0, 1.0, 2.0, 0.7153428128753893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 999722.0550100794, 999722.0550100801, 224192.0248112427], 
processed observation next is [1.0, 0.13043478260869565, 0.4597156398104266, 0.92, 1.0, 1.0, 0.6570395335848063, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.27770057083613314, 0.27770057083613336, 0.33461496240483984], 
reward next is 0.6654, 
noisyNet noise sample is [array([-0.5084024], dtype=float32), 0.8431848]. 
=============================================
[2019-03-26 21:00:33,391] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.3532893e-09 9.9996996e-01 5.0349222e-08 2.9997465e-05 3.3429655e-11], sum to 1.0000
[2019-03-26 21:00:33,397] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8788
[2019-03-26 21:00:33,412] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1810220.773710351 W.
[2019-03-26 21:00:33,417] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.66666666666667, 66.33333333333333, 1.0, 2.0, 0.6474025123708151, 1.0, 2.0, 0.6474025123708151, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1810220.773710351, 1810220.773710351, 352412.4303089677], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6712800.0000, 
sim time next is 6713400.0000, 
raw observation next is [29.63333333333333, 66.66666666666667, 1.0, 2.0, 0.4364545746800534, 1.0, 2.0, 0.4364545746800534, 1.0, 1.0, 0.7419720427454726, 6.9112, 6.9112, 170.5573041426782, 1830592.15937285, 1830592.15937285, 371474.1166860805], 
processed observation next is [1.0, 0.6956521739130435, 0.6034755134281199, 0.6666666666666667, 1.0, 1.0, 0.32102960804825714, 1.0, 1.0, 0.32102960804825714, 1.0, 0.5, 0.6853317594456982, 0.0, 0.0, 0.8375144448122397, 0.5084978220480139, 0.5084978220480139, 0.5544389801284784], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.00631179], dtype=float32), 0.6477578]. 
=============================================
[2019-03-26 21:00:34,337] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6023803e-19 1.0000000e+00 2.9531510e-18 1.1498212e-15 2.7621412e-23], sum to 1.0000
[2019-03-26 21:00:34,346] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3691
[2019-03-26 21:00:34,349] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.96666666666667, 69.66666666666667, 1.0, 2.0, 0.3764670437434964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 570601.8994316269, 570601.8994316269, 172149.2990639542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6730800.0000, 
sim time next is 6731400.0000, 
raw observation next is [25.83333333333334, 69.83333333333333, 1.0, 2.0, 0.3731243859180476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 567287.1956160339, 567287.1956160332, 171911.6274366681], 
processed observation next is [1.0, 0.9130434782608695, 0.42338072669826254, 0.6983333333333333, 1.0, 1.0, 0.2447281758048766, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1575797765600094, 0.1575797765600092, 0.25658451856219117], 
reward next is 0.7434, 
noisyNet noise sample is [array([0.00737164], dtype=float32), 0.13370189]. 
=============================================
[2019-03-26 21:00:40,844] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-26 21:00:40,846] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:00:40,846] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:00:40,848] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:00:40,849] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:00:40,850] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:00:40,851] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:00:40,852] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:00:40,852] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:00:40,853] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:00:40,853] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:00:40,869] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run42
[2019-03-26 21:00:40,891] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run42
[2019-03-26 21:00:40,892] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run42
[2019-03-26 21:00:40,893] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run42
[2019-03-26 21:00:40,966] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run42
[2019-03-26 21:01:09,398] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07977366], dtype=float32), 0.061971568]
[2019-03-26 21:01:09,399] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.21486066, 92.10327534, 1.0, 2.0, 0.7641569495440313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1067976.194540338, 1067976.194540338, 235307.4832399855]
[2019-03-26 21:01:09,399] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:01:09,403] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.6761916e-20 1.0000000e+00 3.5158997e-19 2.0953384e-16 1.5789372e-24], sampled 0.6765357857344115
[2019-03-26 21:01:28,422] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07977366], dtype=float32), 0.061971568]
[2019-03-26 21:01:28,425] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.66666666666666, 60.66666666666666, 1.0, 2.0, 0.5638425186395655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 787915.4029247942, 787915.4029247942, 194203.0972062044]
[2019-03-26 21:01:28,426] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:01:28,427] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.9015105e-20 1.0000000e+00 5.0033958e-19 8.9117088e-16 1.4045823e-24], sampled 0.141079926713367
[2019-03-26 21:01:33,571] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07977366], dtype=float32), 0.061971568]
[2019-03-26 21:01:33,572] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.28333333333333, 72.83333333333334, 1.0, 2.0, 0.5673097258708658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 792762.2978735439, 792762.2978735439, 194813.3942664599]
[2019-03-26 21:01:33,574] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:01:33,576] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2083503e-20 1.0000000e+00 1.7153570e-19 2.0298337e-16 1.0373466e-24], sampled 0.8072893700809717
[2019-03-26 21:02:36,076] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5374 3007672604.7148 1766.0000
[2019-03-26 21:02:36,207] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.9141 3164157795.0059 1778.0000
[2019-03-26 21:02:36,305] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.4067 2927264152.9822 1338.0000
[2019-03-26 21:02:36,306] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8494.6508 2842558823.8127 1131.0000
[2019-03-26 21:02:36,340] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.4941 2779356785.0158 933.0000
[2019-03-26 21:02:37,356] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1025000, evaluation results [1025000.0, 7881.914089799695, 3164157795.0059204, 1778.0, 8254.406660643592, 2927264152.9821725, 1338.0, 8660.494053451539, 2779356785.015815, 933.0, 7997.537410079355, 3007672604.7147675, 1766.0, 8494.650760429256, 2842558823.8126726, 1131.0]
[2019-03-26 21:02:48,775] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7441064e-18 1.0000000e+00 2.0352524e-17 1.4060094e-15 3.2354231e-23], sum to 1.0000
[2019-03-26 21:02:48,784] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5363
[2019-03-26 21:02:48,789] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 86.0, 1.0, 2.0, 0.3128036487553827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 499859.6428419989, 499859.6428419989, 167086.998874023], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6757200.0000, 
sim time next is 6757800.0000, 
raw observation next is [21.63333333333333, 85.5, 1.0, 2.0, 0.377430861065963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 602659.979297497, 602659.979297497, 175405.2198176705], 
processed observation next is [1.0, 0.21739130434782608, 0.2243285939968403, 0.855, 1.0, 1.0, 0.2499167000794735, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16740554980486028, 0.16740554980486028, 0.26179883554876193], 
reward next is 0.7382, 
noisyNet noise sample is [array([-0.23722439], dtype=float32), 0.20180506]. 
=============================================
[2019-03-26 21:02:53,301] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4184309e-20 1.0000000e+00 2.8263459e-18 1.5453189e-15 1.9623759e-23], sum to 1.0000
[2019-03-26 21:02:53,311] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0375
[2019-03-26 21:02:53,317] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.86666666666667, 75.66666666666667, 1.0, 2.0, 0.3368873658917485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 527164.054859657, 527164.0548596563, 169002.6861892093], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6826800.0000, 
sim time next is 6827400.0000, 
raw observation next is [23.8, 76.0, 1.0, 2.0, 0.3365327607482251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 526828.3924248168, 526828.3924248168, 168981.12464931], 
processed observation next is [0.0, 0.0, 0.3270142180094788, 0.76, 1.0, 1.0, 0.20064188041954828, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14634122011800468, 0.14634122011800468, 0.2522106338049403], 
reward next is 0.7478, 
noisyNet noise sample is [array([0.9807702], dtype=float32), -0.07956239]. 
=============================================
[2019-03-26 21:02:56,997] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.4875485e-20 1.0000000e+00 2.6181926e-19 2.9455822e-16 7.3572955e-24], sum to 1.0000
[2019-03-26 21:02:57,007] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7149
[2019-03-26 21:02:57,015] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333334, 63.16666666666666, 1.0, 2.0, 0.3688237051575706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 562188.2769463515, 562188.2769463509, 171512.6995161288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6897000.0000, 
sim time next is 6897600.0000, 
raw observation next is [26.8, 64.0, 1.0, 2.0, 0.3693110611153672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 562659.6548752574, 562659.6548752574, 171545.3113086715], 
processed observation next is [0.0, 0.8695652173913043, 0.4691943127962086, 0.64, 1.0, 1.0, 0.2401338085727316, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15629434857646038, 0.15629434857646038, 0.256037778072644], 
reward next is 0.7440, 
noisyNet noise sample is [array([1.4030846], dtype=float32), -0.24165659]. 
=============================================
[2019-03-26 21:02:57,025] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9299883e-20 1.0000000e+00 3.3759236e-19 2.6524061e-16 1.8853482e-24], sum to 1.0000
[2019-03-26 21:02:57,032] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0819
[2019-03-26 21:02:57,035] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.35, 58.5, 1.0, 2.0, 0.3891835891993862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 584786.8259990885, 584786.8259990878, 173265.0750511373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6985800.0000, 
sim time next is 6986400.0000, 
raw observation next is [28.23333333333333, 59.66666666666666, 1.0, 2.0, 0.3922925721318365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 587481.8435461828, 587481.8435461835, 173451.3244544136], 
processed observation next is [0.0, 0.8695652173913043, 0.537124802527646, 0.5966666666666666, 1.0, 1.0, 0.2678223760624536, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1631894009850508, 0.163189400985051, 0.25888257381255764], 
reward next is 0.7411, 
noisyNet noise sample is [array([0.16923036], dtype=float32), -0.27288884]. 
=============================================
[2019-03-26 21:03:05,155] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8322875e-19 1.0000000e+00 1.2797844e-17 1.9912730e-15 7.6617090e-24], sum to 1.0000
[2019-03-26 21:03:05,163] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1228
[2019-03-26 21:03:05,168] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 68.0, 1.0, 2.0, 0.390849191565308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 584974.975979596, 584974.9759795954, 173212.8141027009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7323600.0000, 
sim time next is 7324200.0000, 
raw observation next is [26.6, 68.5, 1.0, 2.0, 0.3917519939357751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 586588.1526171557, 586588.1526171563, 173367.3444991322], 
processed observation next is [1.0, 0.782608695652174, 0.4597156398104266, 0.685, 1.0, 1.0, 0.2671710770310543, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16294115350476546, 0.16294115350476562, 0.2587572305957197], 
reward next is 0.7412, 
noisyNet noise sample is [array([0.7196776], dtype=float32), -1.3186969]. 
=============================================
[2019-03-26 21:03:11,324] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0948381e-13 1.0000000e+00 5.9800922e-13 1.5376028e-09 7.0461892e-17], sum to 1.0000
[2019-03-26 21:03:11,329] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2026
[2019-03-26 21:03:11,335] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.8504309034423084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1188619.079260518, 1188619.079260517, 256662.4954915921], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7218000.0000, 
sim time next is 7218600.0000, 
raw observation next is [24.15, 98.16666666666667, 1.0, 2.0, 0.8762086344217833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1224668.537556989, 1224668.537556989, 263473.1249735946], 
processed observation next is [1.0, 0.5652173913043478, 0.34360189573459715, 0.9816666666666667, 1.0, 1.0, 0.8508537764117872, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.34018570487694133, 0.34018570487694133, 0.39324347010984273], 
reward next is 0.6068, 
noisyNet noise sample is [array([0.9686585], dtype=float32), -0.74338067]. 
=============================================
[2019-03-26 21:03:19,301] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7004169e-19 1.0000000e+00 7.7006445e-18 4.3485414e-16 6.8728386e-24], sum to 1.0000
[2019-03-26 21:03:19,314] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6677
[2019-03-26 21:03:19,321] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 87.66666666666667, 1.0, 2.0, 0.32384633556991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 510724.8929599915, 510724.8929599921, 167809.770943136], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7281600.0000, 
sim time next is 7282200.0000, 
raw observation next is [21.95, 87.33333333333333, 1.0, 2.0, 0.3237276441616025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 510450.7968378516, 510450.7968378516, 167787.0528761033], 
processed observation next is [1.0, 0.2608695652173913, 0.2393364928909953, 0.8733333333333333, 1.0, 1.0, 0.18521402911036444, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14179188801051432, 0.14179188801051432, 0.25042843712851237], 
reward next is 0.7496, 
noisyNet noise sample is [array([0.25160453], dtype=float32), -0.84819674]. 
=============================================
[2019-03-26 21:03:21,205] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.8891332e-19 1.0000000e+00 4.1327060e-18 9.6293871e-16 3.9705685e-24], sum to 1.0000
[2019-03-26 21:03:21,215] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0880
[2019-03-26 21:03:21,223] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666666, 67.83333333333333, 1.0, 2.0, 0.9211127486650742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1402809.416674592, 1402809.416674592, 292211.7475226044], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7296600.0000, 
sim time next is 7297200.0000, 
raw observation next is [26.4, 67.0, 1.0, 2.0, 0.9418648725348665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1430643.056450117, 1430643.056450116, 298180.3931317443], 
processed observation next is [1.0, 0.4782608695652174, 0.45023696682464454, 0.67, 1.0, 1.0, 0.9299576777528512, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.39740084901392136, 0.3974008490139211, 0.44504536288320046], 
reward next is 0.5550, 
noisyNet noise sample is [array([0.25845233], dtype=float32), -0.95033646]. 
=============================================
[2019-03-26 21:03:29,000] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6130471e-19 1.0000000e+00 4.0946655e-19 2.2662849e-15 7.7571107e-24], sum to 1.0000
[2019-03-26 21:03:29,010] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9158
[2019-03-26 21:03:29,018] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 92.0, 1.0, 2.0, 0.3159488283097837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 498901.1413231689, 498901.1413231689, 166928.5734579208], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7434000.0000, 
sim time next is 7434600.0000, 
raw observation next is [21.31666666666667, 91.83333333333334, 1.0, 2.0, 0.315471054679055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 498204.7504799939, 498204.7504799945, 166877.7633131374], 
processed observation next is [0.0, 0.043478260869565216, 0.20932069510268583, 0.9183333333333334, 1.0, 1.0, 0.17526633093862048, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13839020846666497, 0.13839020846666514, 0.24907128852707075], 
reward next is 0.7509, 
noisyNet noise sample is [array([-2.0107017], dtype=float32), 0.00035211712]. 
=============================================
[2019-03-26 21:03:32,693] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 21:03:32,695] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:03:32,696] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:03:32,697] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:03:32,699] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:03:32,698] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:03:32,700] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:03:32,701] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:03:32,703] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:03:32,702] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:03:32,704] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:03:32,729] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run43
[2019-03-26 21:03:32,730] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run43
[2019-03-26 21:03:32,730] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run43
[2019-03-26 21:03:32,790] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run43
[2019-03-26 21:03:32,816] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run43
[2019-03-26 21:03:34,411] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08290202], dtype=float32), 0.06448355]
[2019-03-26 21:03:34,412] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.88256137, 68.52183625, 1.0, 2.0, 0.4276134407203553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 655866.4450399788, 655866.4450399794, 180162.568699893]
[2019-03-26 21:03:34,412] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:03:34,415] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.0565868e-20 1.0000000e+00 3.5152963e-19 9.1040914e-17 1.4112421e-24], sampled 0.3439375480550202
[2019-03-26 21:03:34,599] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08290202], dtype=float32), 0.06448355]
[2019-03-26 21:03:34,600] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.6, 66.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.085176566325606, 6.9112, 168.911710699916, 1577263.509058596, 1453839.455411623, 311347.6927159446]
[2019-03-26 21:03:34,601] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:03:34,602] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.1919768e-21 1.0000000e+00 6.5636782e-20 5.1076729e-17 2.0986646e-25], sampled 0.38955668753727835
[2019-03-26 21:03:39,156] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08290202], dtype=float32), 0.06448355]
[2019-03-26 21:03:39,157] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.37765947, 86.32927121, 1.0, 2.0, 0.2815516588773362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 456574.4995621733, 456574.4995621739, 164020.9030201123]
[2019-03-26 21:03:39,158] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:03:39,162] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.3563015e-20 1.0000000e+00 6.1980095e-19 1.7052144e-16 2.6412081e-24], sampled 0.24209255342247282
[2019-03-26 21:03:48,212] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08290202], dtype=float32), 0.06448355]
[2019-03-26 21:03:48,214] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.46958, 92.498054105, 1.0, 2.0, 0.3990886911678943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 622772.9343399663, 622772.9343399663, 177160.1283730322]
[2019-03-26 21:03:48,216] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:03:48,219] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.3903147e-20 1.0000000e+00 2.1975516e-19 6.5348321e-17 7.4326958e-25], sampled 0.7113315416443193
[2019-03-26 21:04:13,130] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08290202], dtype=float32), 0.06448355]
[2019-03-26 21:04:13,132] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.46666666666667, 87.33333333333334, 1.0, 2.0, 0.4894697256452026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 685692.8063845931, 685692.8063845931, 182186.0497550252]
[2019-03-26 21:04:13,134] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:04:13,136] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.9726807e-21 1.0000000e+00 5.2157812e-20 4.5499344e-17 2.4743409e-25], sampled 0.22267362294357462
[2019-03-26 21:04:28,409] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08290202], dtype=float32), 0.06448355]
[2019-03-26 21:04:28,411] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.36379884, 81.3343327, 1.0, 2.0, 0.5850208489055833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 817521.4609198094, 817521.4609198101, 197982.9247081685]
[2019-03-26 21:04:28,411] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:04:28,415] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.2866012e-20 1.0000000e+00 2.4552334e-19 6.5515054e-17 8.1206066e-25], sampled 0.7054662135710024
[2019-03-26 21:04:53,411] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08290202], dtype=float32), 0.06448355]
[2019-03-26 21:04:53,413] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.45, 73.5, 1.0, 2.0, 0.7086100181887341, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.003939077342926, 6.9112, 168.912330510543, 1887177.327660647, 1821385.278190404, 386598.1264597398]
[2019-03-26 21:04:53,414] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:04:53,418] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.9012886e-12 1.0000000e+00 1.7190586e-11 1.6275743e-08 1.9063950e-15], sampled 0.07296844902644606
[2019-03-26 21:04:53,419] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1887177.327660647 W.
[2019-03-26 21:04:53,436] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08290202], dtype=float32), 0.06448355]
[2019-03-26 21:04:53,437] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [32.88999861833334, 52.29752701166667, 1.0, 2.0, 0.6771958170424494, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.977291405980583, 6.9112, 168.9124973594479, 1843218.15113702, 1796330.760496675, 380786.5245506929]
[2019-03-26 21:04:53,439] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:04:53,440] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.5274883e-13 1.0000000e+00 4.3844542e-12 1.7380648e-08 5.1043058e-16], sampled 0.7206344153681763
[2019-03-26 21:04:53,441] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1843218.15113702 W.
[2019-03-26 21:05:27,342] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08290202], dtype=float32), 0.06448355]
[2019-03-26 21:05:27,345] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.83641672, 63.53417991, 1.0, 2.0, 0.8331868611146985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1231820.102933269, 1231820.102933269, 261608.0963943004]
[2019-03-26 21:05:27,347] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:05:27,349] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.3507741e-20 1.0000000e+00 1.2287201e-18 5.9813036e-16 3.7630322e-24], sampled 0.433569277019753
[2019-03-26 21:05:27,859] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5144 2842492707.2201 1131.0000
[2019-03-26 21:05:27,889] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164071917.9177 1778.0000
[2019-03-26 21:05:28,112] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1249 2927277438.0038 1338.0000
[2019-03-26 21:05:28,172] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.8169 3007730089.1005 1766.0000
[2019-03-26 21:05:28,296] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8657.7539 2779338961.2007 933.0000
[2019-03-26 21:05:29,311] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1050000, evaluation results [1050000.0, 7884.168443086554, 3164071917.9176674, 1778.0, 8255.124881931173, 2927277438.00382, 1338.0, 8657.75392792439, 2779338961.200734, 933.0, 7996.8169432730165, 3007730089.1004972, 1766.0, 8497.514395919725, 2842492707.2200756, 1131.0]
[2019-03-26 21:05:30,153] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0856065e-21 1.0000000e+00 9.7926934e-20 1.1526219e-17 2.2843008e-25], sum to 1.0000
[2019-03-26 21:05:30,165] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8871
[2019-03-26 21:05:30,169] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.13333333333333, 92.0, 1.0, 2.0, 0.4824504968940798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 674141.8307629039, 674141.8307629032, 180891.9996816422], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7598400.0000, 
sim time next is 7599000.0000, 
raw observation next is [25.06666666666667, 92.5, 1.0, 2.0, 0.4824780337637555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 674180.3210257734, 674180.3210257734, 180896.1693598697], 
processed observation next is [0.0, 0.9565217391304348, 0.38704581358609813, 0.925, 1.0, 1.0, 0.3764795587515127, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18727231139604816, 0.18727231139604816, 0.2699942826266712], 
reward next is 0.7300, 
noisyNet noise sample is [array([-0.32039145], dtype=float32), -0.2470293]. 
=============================================
[2019-03-26 21:05:30,187] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[77.70188]
 [77.6506 ]
 [77.59969]
 [77.54394]
 [77.47622]], R is [[77.70192719]
 [77.65492249]
 [77.60848999]
 [77.56252289]
 [77.51688385]].
[2019-03-26 21:05:30,399] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:30,401] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:30,480] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run6
[2019-03-26 21:05:37,101] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:37,102] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:37,177] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run6
[2019-03-26 21:05:38,827] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.7879417e-20 1.0000000e+00 1.6081504e-18 5.4412863e-15 1.2817390e-24], sum to 1.0000
[2019-03-26 21:05:38,838] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9951
[2019-03-26 21:05:38,846] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.15, 85.33333333333334, 1.0, 2.0, 0.5179917238877224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723821.5202064664, 723821.5202064664, 186463.3624524275], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7762200.0000, 
sim time next is 7762800.0000, 
raw observation next is [27.1, 85.66666666666667, 1.0, 2.0, 0.5195943645146639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726061.7533430048, 726061.7533430048, 186723.2850285625], 
processed observation next is [1.0, 0.8695652173913043, 0.4834123222748816, 0.8566666666666667, 1.0, 1.0, 0.4211980295357396, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2016838203730569, 0.2016838203730569, 0.27869147019188434], 
reward next is 0.7213, 
noisyNet noise sample is [array([0.9368533], dtype=float32), 0.27399448]. 
=============================================
[2019-03-26 21:05:39,187] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:39,188] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:39,268] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run6
[2019-03-26 21:05:39,463] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1055039: loss 0.0559
[2019-03-26 21:05:39,464] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1055041: learning rate 0.0000
[2019-03-26 21:05:43,372] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.1798045e-12 9.9999988e-01 8.8524868e-11 1.3892024e-07 1.1000298e-14], sum to 1.0000
[2019-03-26 21:05:43,382] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4494
[2019-03-26 21:05:43,386] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.63333333333333, 67.66666666666667, 1.0, 2.0, 0.4644769612724171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 649019.2251040917, 649019.2251040917, 178219.793812848], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7753200.0000, 
sim time next is 7753800.0000, 
raw observation next is [29.46666666666667, 68.83333333333333, 1.0, 2.0, 0.4776343206228006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 667409.9363188114, 667409.9363188114, 180167.8236841091], 
processed observation next is [1.0, 0.7391304347826086, 0.5955766192733019, 0.6883333333333332, 1.0, 1.0, 0.37064375978650677, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18539164897744762, 0.18539164897744762, 0.26890719952852105], 
reward next is 0.7311, 
noisyNet noise sample is [array([-1.3849443], dtype=float32), -0.12660354]. 
=============================================
[2019-03-26 21:05:46,755] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1058408: loss 0.0417
[2019-03-26 21:05:46,758] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1058408: learning rate 0.0000
[2019-03-26 21:05:47,630] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:47,630] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:47,727] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run6
[2019-03-26 21:05:48,183] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9050800e-12 9.9999976e-01 1.6734107e-11 2.1552221e-07 2.0569604e-15], sum to 1.0000
[2019-03-26 21:05:48,191] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6640
[2019-03-26 21:05:48,194] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.3, 65.0, 1.0, 2.0, 0.4647916551619754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104279, 649459.0850632364, 649459.0850632364, 178266.1460314929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7925400.0000, 
sim time next is 7926000.0000, 
raw observation next is [30.13333333333333, 66.0, 1.0, 2.0, 0.4748563034256418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 663526.933694607, 663526.933694607, 179752.5839599559], 
processed observation next is [1.0, 0.7391304347826086, 0.6271721958925749, 0.66, 1.0, 1.0, 0.367296751115231, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18431303713739083, 0.18431303713739083, 0.2682874387462028], 
reward next is 0.7317, 
noisyNet noise sample is [array([0.5620112], dtype=float32), 0.26486197]. 
=============================================
[2019-03-26 21:05:48,204] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[42.517624]
 [38.204964]
 [35.048737]
 [33.662376]
 [34.080162]], R is [[45.73371506]
 [46.01031113]
 [45.55020905]
 [45.09470749]
 [44.64376068]].
[2019-03-26 21:05:48,580] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4792792e-20 1.0000000e+00 2.4026813e-18 3.1353766e-16 2.9228371e-24], sum to 1.0000
[2019-03-26 21:05:48,586] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0134
[2019-03-26 21:05:48,590] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.4, 96.0, 1.0, 2.0, 0.3854258006863907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 581924.2250599122, 581924.2250599122, 173088.8438988943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 154800.0000, 
sim time next is 155400.0000, 
raw observation next is [22.4, 96.0, 1.0, 2.0, 0.3849870078901698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 581361.768807654, 581361.7688076535, 173041.3148942467], 
processed observation next is [1.0, 0.8260869565217391, 0.2606635071090047, 0.96, 1.0, 1.0, 0.2590204914339395, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16148938022434833, 0.1614893802243482, 0.25827061924514433], 
reward next is 0.7417, 
noisyNet noise sample is [array([0.9636291], dtype=float32), -1.9269001]. 
=============================================
[2019-03-26 21:05:48,619] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1059312: loss 0.0294
[2019-03-26 21:05:48,621] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1059312: learning rate 0.0000
[2019-03-26 21:05:49,578] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1120687e-19 1.0000000e+00 5.0117054e-19 2.4391060e-16 7.5015466e-24], sum to 1.0000
[2019-03-26 21:05:49,589] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5090
[2019-03-26 21:05:49,595] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.08333333333334, 91.33333333333334, 1.0, 2.0, 0.7600381123005231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1062216.880056028, 1062216.880056028, 234336.6552992772], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7872600.0000, 
sim time next is 7873200.0000, 
raw observation next is [26.1, 91.0, 1.0, 2.0, 0.6892488017322556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 963238.0245145586, 963238.0245145586, 218540.254209167], 
processed observation next is [1.0, 0.13043478260869565, 0.4360189573459717, 0.91, 1.0, 1.0, 0.6256009659424766, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2675661179207107, 0.2675661179207107, 0.3261794838942791], 
reward next is 0.6738, 
noisyNet noise sample is [array([-1.5413265], dtype=float32), 0.5203144]. 
=============================================
[2019-03-26 21:05:50,334] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:50,334] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:50,399] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run6
[2019-03-26 21:05:53,889] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:53,890] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:53,957] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:53,958] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:53,965] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run6
[2019-03-26 21:05:53,985] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:53,989] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:54,023] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:54,024] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:54,048] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run6
[2019-03-26 21:05:54,074] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1061919: loss 0.0760
[2019-03-26 21:05:54,076] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1061919: learning rate 0.0000
[2019-03-26 21:05:54,080] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run6
[2019-03-26 21:05:54,122] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run6
[2019-03-26 21:05:54,177] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:54,177] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:54,214] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run6
[2019-03-26 21:05:54,336] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:54,336] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:54,363] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run6
[2019-03-26 21:05:54,434] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:54,434] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:54,454] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run6
[2019-03-26 21:05:54,492] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1800166e-20 1.0000000e+00 5.2940014e-19 7.5328592e-17 7.4414339e-25], sum to 1.0000
[2019-03-26 21:05:54,498] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5133
[2019-03-26 21:05:54,501] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.75, 96.0, 1.0, 2.0, 0.9123297797886507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1360691.385182906, 1360691.385182906, 285705.5645954492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 138600.0000, 
sim time next is 139200.0000, 
raw observation next is [22.73333333333333, 96.0, 1.0, 2.0, 0.8486763137904157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1266470.075735952, 1266470.075735952, 267414.8147117951], 
processed observation next is [1.0, 0.6086956521739131, 0.27646129541864134, 0.96, 1.0, 1.0, 0.8176823057715852, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3517972432599867, 0.3517972432599867, 0.3991265891220822], 
reward next is 0.6009, 
noisyNet noise sample is [array([-0.72196144], dtype=float32), 0.48471886]. 
=============================================
[2019-03-26 21:05:54,512] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:54,512] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:54,521] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run6
[2019-03-26 21:05:54,703] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:54,703] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:54,708] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run6
[2019-03-26 21:05:54,745] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:54,745] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:54,752] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run6
[2019-03-26 21:05:54,801] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:54,801] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:54,804] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run6
[2019-03-26 21:05:54,940] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1062232: loss 0.0371
[2019-03-26 21:05:54,948] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1062232: learning rate 0.0000
[2019-03-26 21:05:56,255] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1062953: loss 0.0633
[2019-03-26 21:05:56,256] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1062954: learning rate 0.0000
[2019-03-26 21:05:56,716] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1056234e-19 1.0000000e+00 4.8330418e-18 3.3605233e-16 2.0288666e-23], sum to 1.0000
[2019-03-26 21:05:56,726] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0220
[2019-03-26 21:05:56,736] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.4, 86.0, 1.0, 2.0, 0.2889412922408359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 462967.1389990058, 462967.1389990051, 164463.3166264564], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 18000.0000, 
sim time next is 18600.0000, 
raw observation next is [21.43333333333333, 86.0, 1.0, 2.0, 0.3538382837698558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 566489.6619203629, 566489.6619203629, 172316.7511963779], 
processed observation next is [1.0, 0.21739130434782608, 0.21484992101105835, 0.86, 1.0, 1.0, 0.22149190815645278, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15735823942232302, 0.15735823942232302, 0.2571891808901163], 
reward next is 0.7428, 
noisyNet noise sample is [array([0.69547355], dtype=float32), 0.03333717]. 
=============================================
[2019-03-26 21:05:58,798] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1064107: loss 0.0709
[2019-03-26 21:05:58,802] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1064107: learning rate 0.0000
[2019-03-26 21:06:01,265] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1065202: loss 0.0447
[2019-03-26 21:06:01,266] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1065203: learning rate 0.0000
[2019-03-26 21:06:01,866] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.33309534e-20 1.00000000e+00 6.29227607e-19 3.49725643e-17
 6.06389371e-24], sum to 1.0000
[2019-03-26 21:06:01,876] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1655
[2019-03-26 21:06:01,882] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.58333333333334, 90.83333333333334, 1.0, 2.0, 0.3727829568078108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 571299.4506704927, 571299.4506704921, 172387.3284338278], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 103800.0000, 
sim time next is 104400.0000, 
raw observation next is [22.6, 91.0, 1.0, 2.0, 0.3666308478678393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 561238.6564266729, 561238.6564266729, 171500.5371181019], 
processed observation next is [1.0, 0.21739130434782608, 0.27014218009478685, 0.91, 1.0, 1.0, 0.23690463598534853, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15589962678518693, 0.15589962678518693, 0.25597095092254013], 
reward next is 0.7440, 
noisyNet noise sample is [array([-0.21835263], dtype=float32), 0.7763321]. 
=============================================
[2019-03-26 21:06:03,484] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1066188: loss 0.0828
[2019-03-26 21:06:03,486] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1066188: learning rate 0.0000
[2019-03-26 21:06:03,822] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1066340: loss 0.0846
[2019-03-26 21:06:03,826] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1066342: learning rate 0.0000
[2019-03-26 21:06:03,875] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1066363: loss 0.0765
[2019-03-26 21:06:03,880] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1066365: learning rate 0.0000
[2019-03-26 21:06:03,961] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1066404: loss 0.0851
[2019-03-26 21:06:03,963] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1066404: learning rate 0.0000
[2019-03-26 21:06:04,213] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1066512: loss 0.0872
[2019-03-26 21:06:04,214] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1066512: learning rate 0.0000
[2019-03-26 21:06:04,782] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1066770: loss 0.0802
[2019-03-26 21:06:04,783] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1066770: learning rate 0.0000
[2019-03-26 21:06:04,876] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1066813: loss 0.0924
[2019-03-26 21:06:04,882] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1066816: learning rate 0.0000
[2019-03-26 21:06:05,058] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1066892: loss 0.0793
[2019-03-26 21:06:05,062] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1066892: learning rate 0.0000
[2019-03-26 21:06:05,158] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1066938: loss 0.0859
[2019-03-26 21:06:05,159] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1066938: learning rate 0.0000
[2019-03-26 21:06:05,231] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1066969: loss 0.0780
[2019-03-26 21:06:05,233] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1066969: learning rate 0.0000
[2019-03-26 21:06:05,582] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1067125: loss 0.0626
[2019-03-26 21:06:05,585] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1067126: learning rate 0.0000
[2019-03-26 21:06:08,942] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1068630: loss 0.0235
[2019-03-26 21:06:08,943] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1068630: learning rate 0.0000
[2019-03-26 21:06:09,999] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0723683e-21 1.0000000e+00 1.3823194e-19 4.3611979e-17 9.9105156e-26], sum to 1.0000
[2019-03-26 21:06:10,004] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1213
[2019-03-26 21:06:10,014] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 91.16666666666667, 1.0, 2.0, 0.2831954340292483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 455922.9584193631, 455922.9584193638, 163996.5893461507], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 256200.0000, 
sim time next is 256800.0000, 
raw observation next is [20.5, 91.33333333333334, 1.0, 2.0, 0.2833883711786864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 456068.3070089751, 456068.3070089751, 164005.9628730823], 
processed observation next is [0.0, 1.0, 0.1706161137440759, 0.9133333333333334, 1.0, 1.0, 0.13661249539600773, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12668564083582642, 0.12668564083582642, 0.24478501921355567], 
reward next is 0.7552, 
noisyNet noise sample is [array([1.1177385], dtype=float32), -0.9242308]. 
=============================================
[2019-03-26 21:06:11,183] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1069630: loss 0.0493
[2019-03-26 21:06:11,187] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1069630: learning rate 0.0000
[2019-03-26 21:06:14,151] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1070955: loss 0.0462
[2019-03-26 21:06:14,155] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1070955: learning rate 0.0000
[2019-03-26 21:06:16,557] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1072029: loss 0.0156
[2019-03-26 21:06:16,566] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1072031: learning rate 0.0000
[2019-03-26 21:06:16,827] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5170461e-19 1.0000000e+00 1.0373419e-18 1.9300437e-16 1.5279901e-24], sum to 1.0000
[2019-03-26 21:06:16,836] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1674
[2019-03-26 21:06:16,842] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 69.0, 1.0, 2.0, 0.2408189506974966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 397554.5246586306, 397554.5246586306, 159969.3600277277], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 500400.0000, 
sim time next is 501000.0000, 
raw observation next is [21.46666666666667, 70.5, 1.0, 2.0, 0.2405443348468091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 397198.3745515567, 397198.3745515567, 159938.2199016922], 
processed observation next is [1.0, 0.8260869565217391, 0.21642969984202226, 0.705, 1.0, 1.0, 0.08499317451422782, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11033288181987687, 0.11033288181987687, 0.2387137610473018], 
reward next is 0.7613, 
noisyNet noise sample is [array([0.93566656], dtype=float32), 1.2618648]. 
=============================================
[2019-03-26 21:06:16,869] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.85361 ]
 [72.84328 ]
 [72.81601 ]
 [72.85312 ]
 [72.815704]], R is [[72.87446594]
 [72.90695953]
 [72.93911743]
 [72.97103882]
 [73.00230408]].
[2019-03-26 21:06:17,386] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.0990062e-20 1.0000000e+00 3.3483889e-18 1.2300954e-16 4.2719216e-24], sum to 1.0000
[2019-03-26 21:06:17,395] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0569
[2019-03-26 21:06:17,397] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.13333333333333, 88.66666666666666, 1.0, 2.0, 0.256341999938463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 417466.0831842221, 417466.0831842227, 161473.3418926864], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 358800.0000, 
sim time next is 359400.0000, 
raw observation next is [20.11666666666667, 88.83333333333334, 1.0, 2.0, 0.25656065928945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 417798.8141201269, 417798.8141201264, 161494.3555650893], 
processed observation next is [1.0, 0.13043478260869565, 0.15244865718799394, 0.8883333333333334, 1.0, 1.0, 0.10428995095114456, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11605522614447969, 0.11605522614447956, 0.2410363515896855], 
reward next is 0.7590, 
noisyNet noise sample is [array([1.0149376], dtype=float32), 0.11223032]. 
=============================================
[2019-03-26 21:06:19,213] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1073216: loss 0.0062
[2019-03-26 21:06:19,217] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1073216: learning rate 0.0000
[2019-03-26 21:06:19,712] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.9832592e-20 1.0000000e+00 1.4014716e-18 1.6712953e-16 7.4144058e-24], sum to 1.0000
[2019-03-26 21:06:19,721] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1108
[2019-03-26 21:06:19,729] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 86.0, 1.0, 2.0, 0.245100758040299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 403372.8761155003, 403372.8761155003, 160422.9433864815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 430200.0000, 
sim time next is 430800.0000, 
raw observation next is [19.7, 86.0, 1.0, 2.0, 0.244680711747906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 402682.2676706034, 402682.2676706034, 160382.3105867617], 
processed observation next is [1.0, 1.0, 0.1327014218009479, 0.86, 1.0, 1.0, 0.08997676114205543, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1118561854640565, 0.1118561854640565, 0.239376582965316], 
reward next is 0.7606, 
noisyNet noise sample is [array([0.19533488], dtype=float32), 2.2292967]. 
=============================================
[2019-03-26 21:06:20,648] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.5217976e-20 1.0000000e+00 6.3270114e-18 1.8502808e-15 8.2606146e-24], sum to 1.0000
[2019-03-26 21:06:20,659] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6214
[2019-03-26 21:06:20,662] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 85.0, 1.0, 2.0, 0.2386394219171848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 393702.6486954252, 393702.6486954258, 159774.2805548117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 435600.0000, 
sim time next is 436200.0000, 
raw observation next is [19.6, 85.00000000000001, 1.0, 2.0, 0.2389475910213506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 394263.9203123889, 394263.9203123889, 159801.1288835176], 
processed observation next is [1.0, 0.043478260869565216, 0.127962085308057, 0.8500000000000001, 1.0, 1.0, 0.08306938677271156, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.10951775564233025, 0.10951775564233025, 0.2385091475873397], 
reward next is 0.7615, 
noisyNet noise sample is [array([-0.17485844], dtype=float32), 2.0562756]. 
=============================================
[2019-03-26 21:06:21,213] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1074107: loss 0.0303
[2019-03-26 21:06:21,218] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1074110: learning rate 0.0000
[2019-03-26 21:06:21,836] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1074384: loss 0.0310
[2019-03-26 21:06:21,841] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1074386: learning rate 0.0000
[2019-03-26 21:06:21,914] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1074422: loss 0.0242
[2019-03-26 21:06:21,915] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1074422: learning rate 0.0000
[2019-03-26 21:06:21,958] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1074442: loss 0.0269
[2019-03-26 21:06:21,960] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1074443: learning rate 0.0000
[2019-03-26 21:06:22,042] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1074476: loss 0.0222
[2019-03-26 21:06:22,045] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1074476: learning rate 0.0000
[2019-03-26 21:06:22,556] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1074705: loss 0.0206
[2019-03-26 21:06:22,557] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1074705: learning rate 0.0000
[2019-03-26 21:06:22,811] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1074818: loss 0.0257
[2019-03-26 21:06:22,817] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1074818: learning rate 0.0000
[2019-03-26 21:06:22,958] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6830831e-20 1.0000000e+00 2.8100481e-18 1.0584323e-16 2.9798824e-24], sum to 1.0000
[2019-03-26 21:06:22,972] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8946
[2019-03-26 21:06:22,976] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 82.83333333333334, 1.0, 2.0, 0.2293239952763556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 379049.5574255372, 379049.5574255366, 158867.9655074656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 447000.0000, 
sim time next is 447600.0000, 
raw observation next is [19.7, 82.66666666666667, 1.0, 2.0, 0.2282594086308865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 377369.7702676977, 377369.7702676977, 158765.3333167458], 
processed observation next is [1.0, 0.17391304347826086, 0.1327014218009479, 0.8266666666666667, 1.0, 1.0, 0.07019205859142952, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.10482493618547158, 0.10482493618547158, 0.23696318405484446], 
reward next is 0.7630, 
noisyNet noise sample is [array([0.93257254], dtype=float32), -0.7347588]. 
=============================================
[2019-03-26 21:06:23,061] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1074929: loss 0.0257
[2019-03-26 21:06:23,069] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1074931: learning rate 0.0000
[2019-03-26 21:06:23,070] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1074931: loss 0.0241
[2019-03-26 21:06:23,076] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1074932: learning rate 0.0000
[2019-03-26 21:06:23,206] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1074991: loss 0.0251
[2019-03-26 21:06:23,207] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1074992: learning rate 0.0000
[2019-03-26 21:06:23,228] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 21:06:23,229] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:06:23,230] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:06:23,230] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:06:23,231] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:06:23,232] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:06:23,233] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:06:23,233] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:06:23,234] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:06:23,236] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:06:23,236] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:06:23,254] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run44
[2019-03-26 21:06:23,276] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run44
[2019-03-26 21:06:23,296] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run44
[2019-03-26 21:06:23,325] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run44
[2019-03-26 21:06:23,326] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run44
[2019-03-26 21:06:32,827] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08592572], dtype=float32), 0.06731702]
[2019-03-26 21:06:32,829] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.11432194666667, 62.69695972, 1.0, 2.0, 0.5458816209265307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 873586.0354827372, 873586.0354827372, 203441.4063662263]
[2019-03-26 21:06:32,831] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:06:32,833] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.7898708e-21 1.0000000e+00 1.8844758e-19 5.7367993e-17 5.4709801e-25], sampled 0.35686833500091564
[2019-03-26 21:07:16,799] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08592572], dtype=float32), 0.06731702]
[2019-03-26 21:07:16,800] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.29974491, 80.33729858666668, 1.0, 2.0, 0.7900741351069266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1104216.561726777, 1104216.561726778, 241491.663838896]
[2019-03-26 21:07:16,801] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:07:16,805] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.5174949e-21 1.0000000e+00 4.2468755e-20 1.5076554e-17 7.2626467e-26], sampled 0.6710377301158987
[2019-03-26 21:07:20,212] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08592572], dtype=float32), 0.06731702]
[2019-03-26 21:07:20,213] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.17621086, 86.81932802, 1.0, 2.0, 0.5533737368674007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 773280.9675448239, 773280.9675448239, 192382.0933397757]
[2019-03-26 21:07:20,215] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:07:20,220] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.3916212e-22 1.0000000e+00 9.7677663e-21 1.2388869e-17 2.0747752e-26], sampled 0.32948952106686435
[2019-03-26 21:07:21,398] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08592572], dtype=float32), 0.06731702]
[2019-03-26 21:07:21,399] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.92360589, 73.70483926, 1.0, 2.0, 0.5345958380032326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 747031.6230699618, 747031.6230699618, 189193.0119839574]
[2019-03-26 21:07:21,399] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:07:21,404] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.9387495e-22 1.0000000e+00 6.8217577e-21 8.5359737e-18 1.6199222e-26], sampled 0.4290487672644099
[2019-03-26 21:07:31,724] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08592572], dtype=float32), 0.06731702]
[2019-03-26 21:07:31,725] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.1, 61.0, 1.0, 2.0, 0.515324500574358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 720093.1826354061, 720093.1826354061, 186031.8368039847]
[2019-03-26 21:07:31,726] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:07:31,729] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.2787012e-21 1.0000000e+00 6.4121438e-20 5.3990601e-17 2.6145616e-25], sampled 0.6914442646598028
[2019-03-26 21:07:54,606] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08592572], dtype=float32), 0.06731702]
[2019-03-26 21:07:54,608] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.90889165666667, 81.78798415, 1.0, 2.0, 0.4778755414484228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 681357.3038001166, 681357.3038001161, 181945.2943021762]
[2019-03-26 21:07:54,610] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:07:54,613] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.1298580e-22 1.0000000e+00 6.8610876e-21 7.4431920e-18 1.3653816e-26], sampled 0.6124788334260227
[2019-03-26 21:07:57,822] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08592572], dtype=float32), 0.06731702]
[2019-03-26 21:07:57,823] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.25, 91.5, 1.0, 2.0, 0.7653272860402697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1069612.665953984, 1069612.665953983, 235576.9830237671]
[2019-03-26 21:07:57,824] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:07:57,827] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.2374013e-21 1.0000000e+00 2.3662773e-20 9.5814862e-18 3.6080208e-26], sampled 0.3187663050132671
[2019-03-26 21:08:18,371] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1701 3164000012.1395 1778.0000
[2019-03-26 21:08:18,375] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.4791 3007718786.5045 1766.0000
[2019-03-26 21:08:18,581] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 21:08:18,660] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.6283 2779190527.6999 933.0000
[2019-03-26 21:08:18,694] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.9454 2927351652.0094 1338.0000
[2019-03-26 21:08:19,711] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1075000, evaluation results [1075000.0, 7884.170123390672, 3164000012.13951, 1778.0, 8252.945436711087, 2927351652.0094247, 1338.0, 8660.628342730803, 2779190527.699903, 933.0, 7997.479055512932, 3007718786.504511, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 21:08:19,935] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1075105: loss 0.0159
[2019-03-26 21:08:19,937] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1075105: learning rate 0.0000
[2019-03-26 21:08:22,866] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1076638: loss 0.0054
[2019-03-26 21:08:22,869] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1076638: learning rate 0.0000
[2019-03-26 21:08:25,053] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1077630: loss 0.0012
[2019-03-26 21:08:25,058] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1077632: learning rate 0.0000
[2019-03-26 21:08:26,918] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.3669565e-20 1.0000000e+00 3.2076091e-18 1.9816860e-16 7.1465670e-24], sum to 1.0000
[2019-03-26 21:08:26,927] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3887
[2019-03-26 21:08:26,932] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.96666666666667, 87.66666666666667, 1.0, 2.0, 0.2144727358452151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 357739.3476943186, 357739.3476943193, 156966.718099004], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 606000.0000, 
sim time next is 606600.0000, 
raw observation next is [17.9, 88.0, 1.0, 2.0, 0.2134813270544272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 356140.5977505077, 356140.5977505077, 156860.3708652732], 
processed observation next is [1.0, 0.0, 0.04739336492890995, 0.88, 1.0, 1.0, 0.052387141029430366, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.09892794381958547, 0.09892794381958547, 0.23411995651533313], 
reward next is 0.7659, 
noisyNet noise sample is [array([-0.4704142], dtype=float32), 1.9760585]. 
=============================================
[2019-03-26 21:08:28,107] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1078999: loss 0.0046
[2019-03-26 21:08:28,110] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1078999: learning rate 0.0000
[2019-03-26 21:08:28,539] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.6795247e-19 1.0000000e+00 3.8027275e-18 8.7680917e-16 6.3482674e-24], sum to 1.0000
[2019-03-26 21:08:28,548] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2143
[2019-03-26 21:08:28,553] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.96666666666667, 92.0, 1.0, 2.0, 0.2007718088497139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 335655.8152497928, 335655.8152497928, 155379.4642532544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 620400.0000, 
sim time next is 621000.0000, 
raw observation next is [16.95, 92.0, 1.0, 2.0, 0.2012261717516125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 336434.2421623027, 336434.2421623032, 155399.7682012333], 
processed observation next is [1.0, 0.17391304347826086, 0.002369668246445531, 0.92, 1.0, 1.0, 0.03762189367664156, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.0934539561561952, 0.09345395615619533, 0.23193995253915417], 
reward next is 0.7681, 
noisyNet noise sample is [array([0.4398506], dtype=float32), 1.9967679]. 
=============================================
[2019-03-26 21:08:28,579] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[72.993965]
 [73.002975]
 [73.03532 ]
 [72.95612 ]
 [72.9714  ]], R is [[72.97850037]
 [73.01680756]
 [73.0541153 ]
 [73.0915451 ]
 [73.12854004]].
[2019-03-26 21:08:30,451] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1080042: loss 0.0091
[2019-03-26 21:08:30,452] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1080042: learning rate 0.0000
[2019-03-26 21:08:32,893] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.4374510e-20 1.0000000e+00 2.5398291e-18 1.3869961e-16 7.6140713e-24], sum to 1.0000
[2019-03-26 21:08:32,907] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7400
[2019-03-26 21:08:32,915] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.71666666666667, 91.0, 1.0, 2.0, 0.2173594940760535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 362380.1638334922, 362380.1638334916, 157278.1722491333], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 709800.0000, 
sim time next is 710400.0000, 
raw observation next is [17.93333333333333, 90.0, 1.0, 2.0, 0.2147865918908541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 357865.0006242922, 357865.0006242922, 157127.2389302956], 
processed observation next is [1.0, 0.21739130434782608, 0.04897314375987352, 0.9, 1.0, 1.0, 0.05395974926608928, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.09940694461785894, 0.09940694461785894, 0.2345182670601427], 
reward next is 0.7655, 
noisyNet noise sample is [array([-0.55588794], dtype=float32), -0.5940473]. 
=============================================
[2019-03-26 21:08:32,988] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1081171: loss 0.0074
[2019-03-26 21:08:32,992] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1081172: learning rate 0.0000
[2019-03-26 21:08:35,258] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1082180: loss 0.0057
[2019-03-26 21:08:35,262] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1082181: learning rate 0.0000
[2019-03-26 21:08:35,659] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1082357: loss 0.0025
[2019-03-26 21:08:35,660] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1082357: learning rate 0.0000
[2019-03-26 21:08:35,711] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1082378: loss 0.0056
[2019-03-26 21:08:35,713] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1082379: learning rate 0.0000
[2019-03-26 21:08:35,872] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1082451: loss 0.0044
[2019-03-26 21:08:35,875] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1082451: learning rate 0.0000
[2019-03-26 21:08:35,932] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1082476: loss 0.0025
[2019-03-26 21:08:35,936] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1082476: learning rate 0.0000
[2019-03-26 21:08:36,342] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1082663: loss 0.0020
[2019-03-26 21:08:36,345] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1082663: learning rate 0.0000
[2019-03-26 21:08:36,731] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1082835: loss 0.0037
[2019-03-26 21:08:36,737] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1082836: learning rate 0.0000
[2019-03-26 21:08:36,803] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1082868: loss 0.0022
[2019-03-26 21:08:36,805] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1082868: learning rate 0.0000
[2019-03-26 21:08:36,894] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1082909: loss 0.0051
[2019-03-26 21:08:36,900] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1082910: learning rate 0.0000
[2019-03-26 21:08:37,174] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1083034: loss 0.0029
[2019-03-26 21:08:37,179] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1083034: learning rate 0.0000
[2019-03-26 21:08:37,244] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1083066: loss 0.0026
[2019-03-26 21:08:37,248] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1083067: learning rate 0.0000
[2019-03-26 21:08:41,205] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1084837: loss 0.1303
[2019-03-26 21:08:41,210] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1084837: learning rate 0.0000
[2019-03-26 21:08:42,739] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0533745e-21 1.0000000e+00 3.0979659e-21 4.8842517e-18 2.4567050e-26], sum to 1.0000
[2019-03-26 21:08:42,748] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9019
[2019-03-26 21:08:42,757] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.56666666666667, 89.0, 1.0, 2.0, 0.3091973448710491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 489324.0105647654, 489324.0105647654, 166242.3931793907], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 861000.0000, 
sim time next is 861600.0000, 
raw observation next is [21.53333333333333, 89.0, 1.0, 2.0, 0.3091584772471531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 489622.0235564462, 489622.0235564456, 166271.5381219746], 
processed observation next is [0.0, 1.0, 0.21958925750394942, 0.89, 1.0, 1.0, 0.16766081596042542, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13600611765456838, 0.13600611765456821, 0.2481664748089173], 
reward next is 0.7518, 
noisyNet noise sample is [array([1.1833712], dtype=float32), -0.08605398]. 
=============================================
[2019-03-26 21:08:42,906] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1085588: loss 0.0066
[2019-03-26 21:08:42,913] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1085589: learning rate 0.0000
[2019-03-26 21:08:46,027] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1086980: loss 0.0015
[2019-03-26 21:08:46,032] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1086982: learning rate 0.0000
[2019-03-26 21:08:46,120] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.2135577e-21 1.0000000e+00 9.8598649e-20 5.9249591e-17 3.6889377e-25], sum to 1.0000
[2019-03-26 21:08:46,128] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4273
[2019-03-26 21:08:46,134] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.51666666666667, 91.33333333333334, 1.0, 2.0, 0.4829092636687409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 688431.9385824759, 688431.9385824759, 182708.3712056043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1314600.0000, 
sim time next is 1315200.0000, 
raw observation next is [24.43333333333334, 91.66666666666667, 1.0, 2.0, 0.4445638809425742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 634802.0317618322, 634802.0317618322, 177121.6507836706], 
processed observation next is [1.0, 0.21739130434782608, 0.3570300157977887, 0.9166666666666667, 1.0, 1.0, 0.33079985655731836, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17633389771162006, 0.17633389771162006, 0.26436067281144865], 
reward next is 0.7356, 
noisyNet noise sample is [array([0.49793378], dtype=float32), -1.8702928]. 
=============================================
[2019-03-26 21:08:48,549] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1396350e-20 1.0000000e+00 1.3775035e-18 2.5936615e-17 2.1894546e-24], sum to 1.0000
[2019-03-26 21:08:48,550] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.9927991e-21 1.0000000e+00 4.9303558e-19 1.3318470e-17 2.6212926e-25], sum to 1.0000
[2019-03-26 21:08:48,559] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9587
[2019-03-26 21:08:48,561] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6615
[2019-03-26 21:08:48,565] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 93.0, 1.0, 2.0, 0.3292132708040946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 510337.8854934814, 510337.8854934814, 167546.445712559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 972600.0000, 
sim time next is 973200.0000, 
raw observation next is [21.9, 93.0, 1.0, 2.0, 0.3282851924684677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 508893.8120397911, 508893.8120397917, 167434.2684789953], 
processed observation next is [1.0, 0.2608695652173913, 0.23696682464454974, 0.93, 1.0, 1.0, 0.19070505116682857, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1413593922332753, 0.14135939223327548, 0.2499018932522318], 
reward next is 0.7501, 
noisyNet noise sample is [array([-0.22088192], dtype=float32), 0.5807401]. 
=============================================
[2019-03-26 21:08:48,569] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 92.5, 1.0, 2.0, 0.3266065538592764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 507045.1089431385, 507045.1089431385, 167315.7245968776], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 966600.0000, 
sim time next is 967200.0000, 
raw observation next is [21.9, 92.33333333333333, 1.0, 2.0, 0.3249702401700564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 504792.0294788929, 504792.0294788922, 167151.6441352735], 
processed observation next is [1.0, 0.17391304347826086, 0.23696682464454974, 0.9233333333333333, 1.0, 1.0, 0.18671113273500767, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14022000818858135, 0.14022000818858119, 0.24948006587354254], 
reward next is 0.7505, 
noisyNet noise sample is [array([0.48439136], dtype=float32), 1.1344528]. 
=============================================
[2019-03-26 21:08:48,575] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1088120: loss 0.0847
[2019-03-26 21:08:48,576] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1088120: learning rate 0.0000
[2019-03-26 21:08:51,106] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1089247: loss 0.0783
[2019-03-26 21:08:51,107] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1089248: learning rate 0.0000
[2019-03-26 21:08:53,244] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1090175: loss 0.0013
[2019-03-26 21:08:53,247] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1090175: learning rate 0.0000
[2019-03-26 21:08:53,588] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1090326: loss 0.0011
[2019-03-26 21:08:53,592] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1090328: learning rate 0.0000
[2019-03-26 21:08:53,642] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1090350: loss 0.0016
[2019-03-26 21:08:53,645] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1090351: learning rate 0.0000
[2019-03-26 21:08:53,700] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1090374: loss 0.0010
[2019-03-26 21:08:53,703] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1090374: learning rate 0.0000
[2019-03-26 21:08:53,918] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1090467: loss 0.0012
[2019-03-26 21:08:53,927] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1090469: learning rate 0.0000
[2019-03-26 21:08:54,380] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1090679: loss 0.0012
[2019-03-26 21:08:54,382] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1090679: learning rate 0.0000
[2019-03-26 21:08:54,725] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1090831: loss 0.0011
[2019-03-26 21:08:54,732] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1090831: learning rate 0.0000
[2019-03-26 21:08:54,757] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1090844: loss 0.0011
[2019-03-26 21:08:54,761] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1090844: learning rate 0.0000
[2019-03-26 21:08:54,849] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1090886: loss 0.0026
[2019-03-26 21:08:54,851] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1090886: learning rate 0.0000
[2019-03-26 21:08:55,140] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1091013: loss 0.0017
[2019-03-26 21:08:55,147] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1091014: learning rate 0.0000
[2019-03-26 21:08:55,232] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1091052: loss 0.0012
[2019-03-26 21:08:55,234] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1091053: learning rate 0.0000
[2019-03-26 21:08:57,634] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2427747e-20 1.0000000e+00 2.8062118e-19 9.0971828e-17 4.2474155e-25], sum to 1.0000
[2019-03-26 21:08:57,643] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2021
[2019-03-26 21:08:57,649] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.71666666666667, 67.0, 1.0, 2.0, 0.7495945480135784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1159024.965604882, 1159024.965604882, 246130.2975684384], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1095000.0000, 
sim time next is 1095600.0000, 
raw observation next is [25.73333333333333, 67.0, 1.0, 2.0, 0.7365807830015667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1138469.343710732, 1138469.343710732, 242778.3475346128], 
processed observation next is [1.0, 0.6956521739130435, 0.41864139020537117, 0.67, 1.0, 1.0, 0.682627449399478, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3162414843640922, 0.3162414843640922, 0.36235574258897435], 
reward next is 0.6376, 
noisyNet noise sample is [array([-0.7481846], dtype=float32), -1.279687]. 
=============================================
[2019-03-26 21:08:59,228] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1092834: loss 0.0895
[2019-03-26 21:08:59,230] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1092834: learning rate 0.0000
[2019-03-26 21:09:01,077] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1093656: loss 0.0529
[2019-03-26 21:09:01,079] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1093656: learning rate 0.0000
[2019-03-26 21:09:04,289] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1095085: loss 0.0412
[2019-03-26 21:09:04,294] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1095086: learning rate 0.0000
[2019-03-26 21:09:06,358] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1096045: loss 0.0980
[2019-03-26 21:09:06,360] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1096046: learning rate 0.0000
[2019-03-26 21:09:08,787] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1097130: loss 0.0864
[2019-03-26 21:09:08,790] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1097130: learning rate 0.0000
[2019-03-26 21:09:11,005] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1098125: loss 0.0444
[2019-03-26 21:09:11,008] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1098126: learning rate 0.0000
[2019-03-26 21:09:11,405] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1098302: loss 0.0369
[2019-03-26 21:09:11,407] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1098303: learning rate 0.0000
[2019-03-26 21:09:11,483] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1098336: loss 0.0414
[2019-03-26 21:09:11,486] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1098338: learning rate 0.0000
[2019-03-26 21:09:11,696] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1098435: loss 0.0364
[2019-03-26 21:09:11,699] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1098435: learning rate 0.0000
[2019-03-26 21:09:11,796] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1098476: loss 0.0388
[2019-03-26 21:09:11,800] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1098476: learning rate 0.0000
[2019-03-26 21:09:12,369] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1098729: loss 0.0345
[2019-03-26 21:09:12,370] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1098729: learning rate 0.0000
[2019-03-26 21:09:12,677] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1098854: loss 0.0379
[2019-03-26 21:09:12,681] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1098857: learning rate 0.0000
[2019-03-26 21:09:12,701] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1098866: loss 0.0380
[2019-03-26 21:09:12,703] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1098867: learning rate 0.0000
[2019-03-26 21:09:12,799] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1098906: loss 0.0313
[2019-03-26 21:09:12,804] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1098907: learning rate 0.0000
[2019-03-26 21:09:13,037] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1099017: loss 0.0381
[2019-03-26 21:09:13,042] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1099018: learning rate 0.0000
[2019-03-26 21:09:13,272] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1099121: loss 0.0325
[2019-03-26 21:09:13,274] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1099121: learning rate 0.0000
[2019-03-26 21:09:13,322] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.2859468e-20 1.0000000e+00 1.3803387e-18 2.6146634e-16 2.7506891e-24], sum to 1.0000
[2019-03-26 21:09:13,332] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1014
[2019-03-26 21:09:13,340] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 94.0, 1.0, 2.0, 0.3215548565950076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 507499.2158023393, 507499.2158023393, 167571.6449226296], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1364400.0000, 
sim time next is 1365000.0000, 
raw observation next is [21.11666666666667, 94.00000000000001, 1.0, 2.0, 0.3215166228207157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 507093.7928781672, 507093.7928781665, 167533.7984119957], 
processed observation next is [1.0, 0.8260869565217391, 0.19984202211690388, 0.9400000000000002, 1.0, 1.0, 0.1825501479767659, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14085938691060199, 0.1408593869106018, 0.2500504453910384], 
reward next is 0.7499, 
noisyNet noise sample is [array([-0.7796482], dtype=float32), 0.20254244]. 
=============================================
[2019-03-26 21:09:13,351] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[73.505066]
 [73.48092 ]
 [73.46737 ]
 [73.35415 ]
 [73.31429 ]], R is [[73.52435303]
 [73.53900146]
 [73.55358124]
 [73.56824493]
 [73.58250427]].
[2019-03-26 21:09:15,263] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 21:09:15,267] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:09:15,269] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:09:15,270] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:09:15,271] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:09:15,272] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:09:15,272] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:09:15,273] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:09:15,274] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:09:15,275] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:09:15,275] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:09:15,294] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run45
[2019-03-26 21:09:15,316] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run45
[2019-03-26 21:09:15,335] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run45
[2019-03-26 21:09:15,336] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run45
[2019-03-26 21:09:15,373] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run45
[2019-03-26 21:09:21,627] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08423373], dtype=float32), 0.06565747]
[2019-03-26 21:09:21,629] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.41666666666667, 78.33333333333333, 1.0, 2.0, 0.3726745707419122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 607374.3786738176, 607374.3786738182, 175496.8364599389]
[2019-03-26 21:09:21,631] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:09:21,634] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.2274894e-20 1.0000000e+00 5.9334120e-19 9.1603874e-17 2.2680303e-24], sampled 0.7960226303789947
[2019-03-26 21:09:26,186] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08423373], dtype=float32), 0.06565747]
[2019-03-26 21:09:26,187] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.63333333333334, 51.66666666666666, 1.0, 2.0, 0.3447390701928989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 554538.010472925, 554538.0104729257, 171315.3028047412]
[2019-03-26 21:09:26,188] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:09:26,190] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.4962744e-20 1.0000000e+00 2.4691060e-19 1.2428922e-16 1.3701623e-24], sampled 0.41441701446384727
[2019-03-26 21:09:26,502] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08423373], dtype=float32), 0.06565747]
[2019-03-26 21:09:26,503] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.8, 74.0, 1.0, 2.0, 0.3719148415018976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 586568.7366534609, 586568.7366534609, 174009.972652377]
[2019-03-26 21:09:26,504] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:09:26,507] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.55083466e-20 1.00000000e+00 6.38868397e-19 1.05954326e-16
 2.55800415e-24], sampled 0.5599087528453603
[2019-03-26 21:10:00,479] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08423373], dtype=float32), 0.06565747]
[2019-03-26 21:10:00,482] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.83898773, 100.0, 1.0, 2.0, 0.4214693611456272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 618229.0601706101, 618229.0601706101, 175955.1709221988]
[2019-03-26 21:10:00,483] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:10:00,485] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.9189102e-21 1.0000000e+00 1.1769468e-19 3.8667415e-17 4.1396965e-25], sampled 0.024168910715453573
[2019-03-26 21:10:27,514] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08423373], dtype=float32), 0.06565747]
[2019-03-26 21:10:27,515] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.22181319666667, 64.14957543666668, 1.0, 2.0, 0.6145498448510377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 858802.6350784826, 858802.6350784826, 203482.4973778971]
[2019-03-26 21:10:27,516] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:10:27,517] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.3263420e-21 1.0000000e+00 6.8362458e-20 4.0901110e-17 2.3356453e-25], sampled 0.046613027292070175
[2019-03-26 21:10:33,293] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08423373], dtype=float32), 0.06565747]
[2019-03-26 21:10:33,293] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.76666666666667, 68.5, 1.0, 2.0, 0.3617181194328698, 0.0, 2.0, 0.0, 1.0, 2.0, 0.628184751444867, 6.911200000000001, 6.9112, 168.912879318952, 1011038.347099405, 1011038.347099404, 243868.3470216112]
[2019-03-26 21:10:33,294] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:10:33,297] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2141772e-12 1.0000000e+00 4.8243718e-12 9.3054968e-09 5.2894672e-16], sampled 0.12112701253297309
[2019-03-26 21:10:56,003] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08423373], dtype=float32), 0.06565747]
[2019-03-26 21:10:56,004] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.33333333333333, 81.5, 1.0, 2.0, 0.8221052527498889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1149007.835626726, 1149007.835626726, 249415.0630614681]
[2019-03-26 21:10:56,007] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:10:56,010] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.1753784e-21 1.0000000e+00 5.0705083e-20 2.2537646e-17 1.2017461e-25], sampled 0.5146798500082697
[2019-03-26 21:11:07,203] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6125 2927449872.7600 1338.0000
[2019-03-26 21:11:07,241] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164071917.9177 1778.0000
[2019-03-26 21:11:07,365] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.3918 2842563638.9128 1131.0000
[2019-03-26 21:11:07,397] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.2105 2779239691.3999 933.0000
[2019-03-26 21:11:07,427] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.0936 3007789820.9736 1766.0000
[2019-03-26 21:11:08,442] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1100000, evaluation results [1100000.0, 7884.168443086554, 3164071917.9176674, 1778.0, 8253.612502082276, 2927449872.7599883, 1338.0, 8659.210464896743, 2779239691.399938, 933.0, 7996.093556430663, 3007789820.97356, 1766.0, 8495.391845542033, 2842563638.9127707, 1131.0]
[2019-03-26 21:11:10,376] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1100904: loss -162.4745
[2019-03-26 21:11:10,378] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1100905: learning rate 0.0000
[2019-03-26 21:11:11,599] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1101536: loss 0.0999
[2019-03-26 21:11:11,601] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1101537: learning rate 0.0000
[2019-03-26 21:11:11,690] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5694098e-21 1.0000000e+00 5.6209617e-20 6.6713758e-17 1.9914527e-25], sum to 1.0000
[2019-03-26 21:11:11,697] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4449
[2019-03-26 21:11:11,702] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 94.0, 1.0, 2.0, 0.3812029617447436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 574572.6535373455, 574572.6535373455, 172403.5456470895], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1458000.0000, 
sim time next is 1458600.0000, 
raw observation next is [22.63333333333333, 94.16666666666667, 1.0, 2.0, 0.3798966029423203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 573246.6561010603, 573246.6561010603, 172305.686990211], 
processed observation next is [0.0, 0.9130434782608695, 0.27172195892575024, 0.9416666666666668, 1.0, 1.0, 0.2528874734244823, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15923518225029454, 0.15923518225029454, 0.25717266714956866], 
reward next is 0.7428, 
noisyNet noise sample is [array([3.3215759], dtype=float32), 0.20806572]. 
=============================================
[2019-03-26 21:11:12,284] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.3897983e-20 1.0000000e+00 1.9568780e-19 7.3900918e-17 1.6164732e-24], sum to 1.0000
[2019-03-26 21:11:12,293] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6329
[2019-03-26 21:11:12,299] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.13333333333333, 88.33333333333334, 1.0, 2.0, 0.357434373157981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 544417.1301215849, 544417.1301215843, 169990.0831217124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1495200.0000, 
sim time next is 1495800.0000, 
raw observation next is [23.35, 87.5, 1.0, 2.0, 0.3626450143454151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 550529.1796307543, 550529.1796307543, 170445.1272456773], 
processed observation next is [0.0, 0.30434782608695654, 0.3056872037914693, 0.875, 1.0, 1.0, 0.23210242692218683, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15292477211965397, 0.15292477211965397, 0.25439571230698105], 
reward next is 0.7456, 
noisyNet noise sample is [array([0.2253707], dtype=float32), -0.21132113]. 
=============================================
[2019-03-26 21:11:14,344] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1102917: loss 0.1231
[2019-03-26 21:11:14,348] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1102917: learning rate 0.0000
[2019-03-26 21:11:17,112] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1104150: loss -167.0652
[2019-03-26 21:11:17,116] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1104153: learning rate 0.0000
[2019-03-26 21:11:17,810] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.1342421e-20 1.0000000e+00 4.8375979e-18 7.7292879e-16 2.2282315e-23], sum to 1.0000
[2019-03-26 21:11:17,818] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5838
[2019-03-26 21:11:17,823] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 89.5, 1.0, 2.0, 0.3064054166652293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 483867.5143219733, 483867.5143219727, 165820.8009257269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1571400.0000, 
sim time next is 1572000.0000, 
raw observation next is [21.6, 89.33333333333333, 1.0, 2.0, 0.307159065139851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 485294.8178840481, 485294.8178840481, 165930.2536523599], 
processed observation next is [1.0, 0.17391304347826086, 0.22274881516587688, 0.8933333333333333, 1.0, 1.0, 0.16525188571066382, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13480411607890225, 0.13480411607890225, 0.24765709500352226], 
reward next is 0.7523, 
noisyNet noise sample is [array([0.02624631], dtype=float32), -0.9367428]. 
=============================================
[2019-03-26 21:11:17,845] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[71.51296 ]
 [71.642746]
 [71.66547 ]
 [71.73228 ]
 [71.77767 ]], R is [[71.34281921]
 [71.38189697]
 [71.42062378]
 [71.45822144]
 [71.49391937]].
[2019-03-26 21:11:18,877] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.2927668e-20 1.0000000e+00 1.1412589e-18 1.4720975e-15 8.5141261e-24], sum to 1.0000
[2019-03-26 21:11:18,880] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4847
[2019-03-26 21:11:18,884] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 88.83333333333334, 1.0, 2.0, 0.3336543243877199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527088.794799645, 527088.794799645, 169094.8504072993], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1573800.0000, 
sim time next is 1574400.0000, 
raw observation next is [21.8, 88.66666666666667, 1.0, 2.0, 0.312807323646386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 493251.869358558, 493251.869358558, 166492.7018573178], 
processed observation next is [1.0, 0.21739130434782608, 0.23222748815165886, 0.8866666666666667, 1.0, 1.0, 0.17205701644142893, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.137014408155155, 0.137014408155155, 0.2484965699362952], 
reward next is 0.7515, 
noisyNet noise sample is [array([-0.51172936], dtype=float32), 0.67802435]. 
=============================================
[2019-03-26 21:11:19,735] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1105322: loss -89.0017
[2019-03-26 21:11:19,746] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1105322: learning rate 0.0000
[2019-03-26 21:11:21,596] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1106154: loss 0.0940
[2019-03-26 21:11:21,600] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1106154: learning rate 0.0000
[2019-03-26 21:11:21,729] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1106215: loss 0.1005
[2019-03-26 21:11:21,731] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1106215: learning rate 0.0000
[2019-03-26 21:11:21,799] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1106246: loss 0.0865
[2019-03-26 21:11:21,804] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1106247: learning rate 0.0000
[2019-03-26 21:11:22,191] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1106417: loss 0.1068
[2019-03-26 21:11:22,195] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1106418: learning rate 0.0000
[2019-03-26 21:11:22,228] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1106437: loss 0.0972
[2019-03-26 21:11:22,234] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1106438: learning rate 0.0000
[2019-03-26 21:11:22,807] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1106693: loss 0.0884
[2019-03-26 21:11:22,809] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1106693: learning rate 0.0000
[2019-03-26 21:11:22,994] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1106776: loss 0.0929
[2019-03-26 21:11:22,996] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1106776: learning rate 0.0000
[2019-03-26 21:11:23,115] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1106829: loss 0.0997
[2019-03-26 21:11:23,116] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1106829: learning rate 0.0000
[2019-03-26 21:11:23,386] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1106946: loss 0.0879
[2019-03-26 21:11:23,389] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1106947: learning rate 0.0000
[2019-03-26 21:11:23,484] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1106992: loss 0.0916
[2019-03-26 21:11:23,490] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1106992: learning rate 0.0000
[2019-03-26 21:11:23,716] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1107093: loss 0.0999
[2019-03-26 21:11:23,721] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1107094: learning rate 0.0000
[2019-03-26 21:11:24,942] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.259951e-21 1.000000e+00 1.933261e-19 3.927574e-17 6.014177e-25], sum to 1.0000
[2019-03-26 21:11:24,952] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3328
[2019-03-26 21:11:24,959] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.78333333333333, 88.5, 1.0, 2.0, 0.9213328693092347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1287776.504167697, 1287776.504167696, 275870.1029602659], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1680600.0000, 
sim time next is 1681200.0000, 
raw observation next is [25.9, 88.0, 1.0, 2.0, 0.9123370336778922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1275195.184950111, 1275195.184950111, 273350.8277725301], 
processed observation next is [1.0, 0.4782608695652174, 0.42654028436018954, 0.88, 1.0, 1.0, 0.8943819682866171, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.35422088470836416, 0.35422088470836416, 0.40798631010825387], 
reward next is 0.5920, 
noisyNet noise sample is [array([1.972801], dtype=float32), 1.7551898]. 
=============================================
[2019-03-26 21:11:28,142] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1109019: loss 0.0022
[2019-03-26 21:11:28,150] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1109022: learning rate 0.0000
[2019-03-26 21:11:28,872] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9967375e-20 1.0000000e+00 4.0806939e-19 2.1319430e-16 1.8628716e-24], sum to 1.0000
[2019-03-26 21:11:28,886] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3599
[2019-03-26 21:11:28,890] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.43333333333333, 88.33333333333334, 1.0, 2.0, 0.8651847732561314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1256650.847859527, 1256650.847859528, 267346.7810243415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1762800.0000, 
sim time next is 1763400.0000, 
raw observation next is [24.36666666666667, 88.16666666666667, 1.0, 2.0, 0.8792083519838492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1281363.709296258, 1281363.709296258, 271862.067511845], 
processed observation next is [1.0, 0.391304347826087, 0.3538704581358612, 0.8816666666666667, 1.0, 1.0, 0.8544678939564447, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.355934363693405, 0.355934363693405, 0.40576427986842534], 
reward next is 0.5942, 
noisyNet noise sample is [array([0.5319212], dtype=float32), -0.286507]. 
=============================================
[2019-03-26 21:11:29,465] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1109615: loss -247.1184
[2019-03-26 21:11:29,466] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1109615: learning rate 0.0000
[2019-03-26 21:11:31,940] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.9210948e-19 1.0000000e+00 4.2474306e-18 5.5901168e-16 4.3689752e-24], sum to 1.0000
[2019-03-26 21:11:31,948] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0031
[2019-03-26 21:11:31,952] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 96.0, 1.0, 2.0, 0.3493305945499476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 535988.9577849462, 535988.9577849468, 169420.9558366583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1828800.0000, 
sim time next is 1829400.0000, 
raw observation next is [21.88333333333333, 96.33333333333333, 1.0, 2.0, 0.3623963527946852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 555663.2742153206, 555663.2742153206, 171050.950247655], 
processed observation next is [1.0, 0.17391304347826086, 0.2361769352290678, 0.9633333333333333, 1.0, 1.0, 0.2318028346923918, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15435090950425573, 0.15435090950425573, 0.25529992574276866], 
reward next is 0.7447, 
noisyNet noise sample is [array([-1.2567357], dtype=float32), 1.6041706]. 
=============================================
[2019-03-26 21:11:32,572] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1111007: loss 27.1940
[2019-03-26 21:11:32,574] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1111007: learning rate 0.0000
[2019-03-26 21:11:35,325] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1112230: loss 0.0031
[2019-03-26 21:11:35,328] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1112231: learning rate 0.0000
[2019-03-26 21:11:37,756] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1113312: loss 0.0027
[2019-03-26 21:11:37,758] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1113312: learning rate 0.0000
[2019-03-26 21:11:39,570] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1114126: loss -100.4852
[2019-03-26 21:11:39,573] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1114126: learning rate 0.0000
[2019-03-26 21:11:39,808] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1114231: loss -297.9898
[2019-03-26 21:11:39,813] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1114233: learning rate 0.0000
[2019-03-26 21:11:39,891] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1114267: loss -152.7678
[2019-03-26 21:11:39,894] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1114269: learning rate 0.0000
[2019-03-26 21:11:40,216] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1114410: loss -324.4153
[2019-03-26 21:11:40,218] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1114410: learning rate 0.0000
[2019-03-26 21:11:40,442] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1114511: loss -102.9969
[2019-03-26 21:11:40,447] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1114514: learning rate 0.0000
[2019-03-26 21:11:40,771] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1114658: loss -5.7543
[2019-03-26 21:11:40,777] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1114659: learning rate 0.0000
[2019-03-26 21:11:40,788] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.839641e-15 1.000000e+00 9.189447e-15 2.650798e-12 7.248585e-19], sum to 1.0000
[2019-03-26 21:11:40,793] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6112
[2019-03-26 21:11:40,800] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 75.0, 1.0, 2.0, 0.861726977892549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1213619.04219943, 1213619.042199431, 260964.5536667316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1947600.0000, 
sim time next is 1948200.0000, 
raw observation next is [27.26666666666667, 74.83333333333333, 1.0, 2.0, 0.9468065285326769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1331721.333333103, 1331721.333333103, 284404.573827854], 
processed observation next is [1.0, 0.5652173913043478, 0.4913112164297, 0.7483333333333333, 1.0, 1.0, 0.9359114801598517, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.36992259259252863, 0.36992259259252863, 0.42448443854903584], 
reward next is 0.5755, 
noisyNet noise sample is [array([0.51665246], dtype=float32), 0.4098943]. 
=============================================
[2019-03-26 21:11:40,863] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1114695: loss -200.9751
[2019-03-26 21:11:40,869] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1114695: learning rate 0.0000
[2019-03-26 21:11:41,045] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1114779: loss -268.3929
[2019-03-26 21:11:41,049] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1114779: learning rate 0.0000
[2019-03-26 21:11:41,378] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1114899: loss -66.1485
[2019-03-26 21:11:41,383] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1114899: learning rate 0.0000
[2019-03-26 21:11:41,515] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1114960: loss -28.0619
[2019-03-26 21:11:41,518] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1114961: learning rate 0.0000
[2019-03-26 21:11:41,699] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1115041: loss -103.9128
[2019-03-26 21:11:41,707] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1115041: learning rate 0.0000
[2019-03-26 21:11:42,135] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.9370489e-20 1.0000000e+00 1.4033119e-18 5.3626900e-16 2.1943462e-24], sum to 1.0000
[2019-03-26 21:11:42,142] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5117
[2019-03-26 21:11:42,149] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.93333333333333, 95.33333333333334, 1.0, 2.0, 0.6431525871204777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 898790.4477961449, 898790.4477961449, 209050.4975111737], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2172000.0000, 
sim time next is 2172600.0000, 
raw observation next is [24.9, 95.5, 1.0, 2.0, 0.6251284712388214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 873591.8153861965, 873591.8153861965, 205511.5342816726], 
processed observation next is [1.0, 0.13043478260869565, 0.3791469194312796, 0.955, 1.0, 1.0, 0.5483475557094234, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24266439316283236, 0.24266439316283236, 0.30673363325622777], 
reward next is 0.6933, 
noisyNet noise sample is [array([-0.25209054], dtype=float32), -1.0422577]. 
=============================================
[2019-03-26 21:11:42,609] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0805990e-20 1.0000000e+00 9.1301322e-19 2.7281076e-16 2.4344482e-24], sum to 1.0000
[2019-03-26 21:11:42,618] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6558
[2019-03-26 21:11:42,623] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.56666666666667, 97.83333333333334, 1.0, 2.0, 0.4458249436070488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 639476.8617077165, 639476.8617077158, 177668.092980041], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1984200.0000, 
sim time next is 1984800.0000, 
raw observation next is [23.63333333333333, 97.66666666666667, 1.0, 2.0, 0.4488983664727622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 642619.5072123181, 642619.5072123181, 177953.8439553231], 
processed observation next is [1.0, 1.0, 0.3191153238546602, 0.9766666666666667, 1.0, 1.0, 0.3360221282804364, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17850541867008837, 0.17850541867008837, 0.26560275217212403], 
reward next is 0.7344, 
noisyNet noise sample is [array([-2.1109333], dtype=float32), 1.8200803]. 
=============================================
[2019-03-26 21:11:43,831] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3811829e-07 9.9861002e-01 3.6557703e-06 1.3859917e-03 4.1230463e-09], sum to 1.0000
[2019-03-26 21:11:43,840] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6473
[2019-03-26 21:11:43,851] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2729021.184997265 W.
[2019-03-26 21:11:43,856] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.03333333333333, 61.33333333333333, 1.0, 2.0, 0.6596403224811663, 1.0, 2.0, 0.6504102007548458, 1.0, 2.0, 1.03, 7.005094550048782, 6.9112, 170.5573041426782, 2729021.184997265, 2661760.699411222, 508883.3497826583], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2389200.0000, 
sim time next is 2389800.0000, 
raw observation next is [33.06666666666667, 61.16666666666666, 1.0, 2.0, 0.9574758162862992, 1.0, 2.0, 0.9574758162862992, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2678226.471455253, 2678226.471455253, 503819.1566545708], 
processed observation next is [1.0, 0.6521739130434783, 0.7661927330173778, 0.6116666666666666, 1.0, 1.0, 0.9487660437184328, 1.0, 1.0, 0.9487660437184328, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7439517976264592, 0.7439517976264592, 0.7519688905292101], 
reward next is 0.2480, 
noisyNet noise sample is [array([-0.9882382], dtype=float32), 0.26333082]. 
=============================================
[2019-03-26 21:11:47,007] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1117406: loss -195.9011
[2019-03-26 21:11:47,008] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1117406: learning rate 0.0000
[2019-03-26 21:11:47,474] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1117613: loss 0.0052
[2019-03-26 21:11:47,479] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1117616: learning rate 0.0000
[2019-03-26 21:11:47,627] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2205896e-20 1.0000000e+00 3.8446750e-19 1.8505824e-17 2.5764544e-24], sum to 1.0000
[2019-03-26 21:11:47,633] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8741
[2019-03-26 21:11:47,640] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 97.0, 1.0, 2.0, 0.460795891596776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 651176.1322495863, 651176.1322495863, 178624.0099571674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2088000.0000, 
sim time next is 2088600.0000, 
raw observation next is [23.96666666666667, 97.16666666666667, 1.0, 2.0, 0.4599709408056562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 650217.9598427864, 650217.9598427871, 178529.635563173], 
processed observation next is [0.0, 0.17391304347826086, 0.33491311216429714, 0.9716666666666667, 1.0, 1.0, 0.34936257928392317, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18061609995632957, 0.18061609995632977, 0.2664621426316015], 
reward next is 0.7335, 
noisyNet noise sample is [array([0.18348984], dtype=float32), 1.0461009]. 
=============================================
[2019-03-26 21:11:49,060] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1192991e-20 1.0000000e+00 1.5357895e-19 2.3498925e-16 7.1363202e-25], sum to 1.0000
[2019-03-26 21:11:49,071] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1849
[2019-03-26 21:11:49,075] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 89.0, 1.0, 2.0, 0.5041720142207456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 704503.9908351148, 704503.9908351141, 184252.7491142351], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2102400.0000, 
sim time next is 2103000.0000, 
raw observation next is [26.5, 88.16666666666667, 1.0, 2.0, 0.5059188884544717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 706945.7951191511, 706945.7951191511, 184529.1445501473], 
processed observation next is [0.0, 0.34782608695652173, 0.4549763033175356, 0.8816666666666667, 1.0, 1.0, 0.4047215523547852, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.196373831977542, 0.196373831977542, 0.27541663365693625], 
reward next is 0.7246, 
noisyNet noise sample is [array([0.35280427], dtype=float32), -2.003962]. 
=============================================
[2019-03-26 21:11:49,091] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.797165]
 [73.78884 ]
 [73.78707 ]
 [73.78059 ]
 [73.77668 ]], R is [[73.79646301]
 [73.78350067]
 [73.77094269]
 [73.75894928]
 [73.74784088]].
[2019-03-26 21:11:50,493] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1118956: loss 0.0122
[2019-03-26 21:11:50,495] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1118957: learning rate 0.0000
[2019-03-26 21:11:54,215] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1120625: loss -110.1231
[2019-03-26 21:11:54,221] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1120626: learning rate 0.0000
[2019-03-26 21:11:56,451] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1121620: loss -89.7093
[2019-03-26 21:11:56,452] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1121620: learning rate 0.0000
[2019-03-26 21:11:57,448] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1122049: loss 0.0220
[2019-03-26 21:11:57,451] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1122051: learning rate 0.0000
[2019-03-26 21:11:57,536] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1122088: loss 0.0238
[2019-03-26 21:11:57,538] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1122088: learning rate 0.0000
[2019-03-26 21:11:57,688] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1122156: loss 0.0214
[2019-03-26 21:11:57,692] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1122156: learning rate 0.0000
[2019-03-26 21:11:57,976] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1122282: loss 0.0196
[2019-03-26 21:11:57,978] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1122283: learning rate 0.0000
[2019-03-26 21:11:58,235] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1122399: loss 0.0232
[2019-03-26 21:11:58,237] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1122399: learning rate 0.0000
[2019-03-26 21:11:58,643] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1122579: loss 0.0249
[2019-03-26 21:11:58,644] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1122579: learning rate 0.0000
[2019-03-26 21:11:58,675] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1122592: loss 0.0237
[2019-03-26 21:11:58,679] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1122593: learning rate 0.0000
[2019-03-26 21:11:58,870] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1122683: loss 0.0250
[2019-03-26 21:11:58,871] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1122683: learning rate 0.0000
[2019-03-26 21:11:59,294] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1122866: loss 0.0189
[2019-03-26 21:11:59,296] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1122866: learning rate 0.0000
[2019-03-26 21:11:59,428] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1122926: loss 0.0189
[2019-03-26 21:11:59,432] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1122928: learning rate 0.0000
[2019-03-26 21:11:59,476] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1122944: loss 0.0211
[2019-03-26 21:11:59,477] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1122944: learning rate 0.0000
[2019-03-26 21:12:03,788] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.4804650e-20 1.0000000e+00 5.7871717e-19 1.3582351e-16 1.0035001e-23], sum to 1.0000
[2019-03-26 21:12:03,797] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9531
[2019-03-26 21:12:03,803] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.26666666666667, 96.33333333333333, 1.0, 2.0, 0.6876930569954549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 961062.8585341, 961062.8585341007, 218212.1327088874], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2521200.0000, 
sim time next is 2521800.0000, 
raw observation next is [26.25, 96.5, 1.0, 2.0, 0.6952171063192489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 971582.6565672379, 971582.6565672379, 219817.1580888292], 
processed observation next is [1.0, 0.17391304347826086, 0.4431279620853081, 0.965, 1.0, 1.0, 0.6327916943605408, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2698840712686772, 0.2698840712686772, 0.32808531058034207], 
reward next is 0.6719, 
noisyNet noise sample is [array([0.42683598], dtype=float32), -0.9593077]. 
=============================================
[2019-03-26 21:12:04,097] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 21:12:04,099] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:12:04,100] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:12:04,101] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:12:04,102] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:12:04,103] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:12:04,104] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:12:04,105] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:12:04,107] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:12:04,107] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:12:04,108] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:12:04,130] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run46
[2019-03-26 21:12:04,151] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run46
[2019-03-26 21:12:04,171] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run46
[2019-03-26 21:12:04,188] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run46
[2019-03-26 21:12:04,189] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run46
[2019-03-26 21:12:17,259] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08201215], dtype=float32), 0.06311699]
[2019-03-26 21:12:17,260] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.270594135, 64.15411118, 1.0, 2.0, 0.2840846769133793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 458095.3695167052, 458095.3695167052, 164143.8999177077]
[2019-03-26 21:12:17,261] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:12:17,263] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5697527e-19 1.0000000e+00 2.2090086e-18 4.1309289e-16 1.6227574e-23], sampled 0.11582998648524812
[2019-03-26 21:12:39,772] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08201215], dtype=float32), 0.06311699]
[2019-03-26 21:12:39,773] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.63225233, 70.87513911, 1.0, 2.0, 0.4042144713144424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 594509.865865903, 594509.8658659023, 173770.720325679]
[2019-03-26 21:12:39,774] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:12:39,779] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.6938877e-16 1.0000000e+00 2.1865016e-15 2.1228744e-12 3.2699096e-20], sampled 0.13640703014818167
[2019-03-26 21:12:43,299] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08201215], dtype=float32), 0.06311699]
[2019-03-26 21:12:43,301] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.33133863, 87.37679442, 1.0, 2.0, 0.4408639729878844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 644356.5954360266, 644356.5954360266, 178455.4182700059]
[2019-03-26 21:12:43,302] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:12:43,305] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.7107897e-20 1.0000000e+00 7.8917409e-19 2.7626885e-16 3.3543872e-24], sampled 0.8826415539776241
[2019-03-26 21:13:14,621] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08201215], dtype=float32), 0.06311699]
[2019-03-26 21:13:14,622] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [38.45, 39.33333333333334, 1.0, 2.0, 0.8056385544306505, 1.0, 1.0, 0.8056385544306505, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 169.0403247858759, 2253146.542325126, 2253146.542325127, 422341.0406056926]
[2019-03-26 21:13:14,622] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:13:14,624] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.11266725e-10 9.99999404e-01 3.13836374e-10 6.43024748e-07
 5.47603954e-14], sampled 0.9194603331183135
[2019-03-26 21:13:14,626] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2253146.542325126 W.
[2019-03-26 21:13:43,085] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08201215], dtype=float32), 0.06311699]
[2019-03-26 21:13:43,087] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.16666666666666, 72.0, 1.0, 2.0, 0.5233238836344907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731275.0378983855, 731275.0378983861, 187330.8146423479]
[2019-03-26 21:13:43,088] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:13:43,090] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.8719139e-20 1.0000000e+00 4.3704868e-19 2.9092225e-16 2.6674937e-24], sampled 0.18297139070266433
[2019-03-26 21:13:45,756] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08201215], dtype=float32), 0.06311699]
[2019-03-26 21:13:45,757] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.6, 95.0, 1.0, 2.0, 0.6630818087068466, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.976563347141798, 6.9112, 168.9125143333222, 1823468.435480222, 1777097.548774178, 377878.2414525484]
[2019-03-26 21:13:45,760] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:13:45,763] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.0836569e-18 1.0000000e+00 4.7519478e-17 1.7402156e-14 8.1421462e-22], sampled 0.7327040503288037
[2019-03-26 21:13:45,764] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1823468.435480222 W.
[2019-03-26 21:13:58,985] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.1682 2927441262.2667 1338.0000
[2019-03-26 21:13:59,403] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6750 3164089889.8551 1778.0000
[2019-03-26 21:13:59,629] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5752 2842451949.6408 1131.0000
[2019-03-26 21:13:59,706] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.7903 2779331027.2517 933.0000
[2019-03-26 21:13:59,728] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2222 3007669257.3412 1766.0000
[2019-03-26 21:14:00,745] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1125000, evaluation results [1125000.0, 7882.675018132028, 3164089889.8551016, 1778.0, 8252.16817576188, 2927441262.2666926, 1338.0, 8659.790305226421, 2779331027.2517376, 933.0, 7998.222170733027, 3007669257.3412185, 1766.0, 8497.575228127671, 2842451949.640752, 1131.0]
[2019-03-26 21:14:00,835] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1125052: loss 0.1955
[2019-03-26 21:14:00,838] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1125053: learning rate 0.0000
[2019-03-26 21:14:02,512] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1125829: loss -220.0051
[2019-03-26 21:14:02,513] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1125829: learning rate 0.0000
[2019-03-26 21:14:04,927] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1127124: loss -363.1436
[2019-03-26 21:14:04,934] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1127125: learning rate 0.0000
[2019-03-26 21:14:05,874] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.8151867e-20 1.0000000e+00 1.2349281e-17 8.5932916e-15 8.8395266e-23], sum to 1.0000
[2019-03-26 21:14:05,882] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3975
[2019-03-26 21:14:05,887] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.63333333333333, 80.0, 1.0, 2.0, 0.5447403130070768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 761212.3526648957, 761212.3526648963, 190902.9292745833], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2425800.0000, 
sim time next is 2426400.0000, 
raw observation next is [28.6, 80.0, 1.0, 2.0, 0.5435166482092623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 759501.8095895732, 759501.8095895732, 190695.2003592339], 
processed observation next is [1.0, 0.08695652173913043, 0.5545023696682465, 0.8, 1.0, 1.0, 0.45002005808344847, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21097272488599256, 0.21097272488599256, 0.2846197020287073], 
reward next is 0.7154, 
noisyNet noise sample is [array([0.05705239], dtype=float32), -1.0052617]. 
=============================================
[2019-03-26 21:14:05,962] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.2443713e-20 1.0000000e+00 2.0922533e-18 1.2310249e-16 1.7524577e-24], sum to 1.0000
[2019-03-26 21:14:05,975] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6380
[2019-03-26 21:14:05,982] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4745087563260036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 663170.6458928146, 663170.6458928146, 179714.9691434588], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2622600.0000, 
sim time next is 2623200.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4749715298666664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 663817.185979863, 663817.185979863, 179783.9465901326], 
processed observation next is [0.0, 0.34782608695652173, 0.4312796208530806, 0.84, 1.0, 1.0, 0.3674355781526102, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1843936627721842, 0.1843936627721842, 0.26833424864198896], 
reward next is 0.7317, 
noisyNet noise sample is [array([-1.3148242], dtype=float32), -1.5401071]. 
=============================================
[2019-03-26 21:14:06,879] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.6010795e-12 1.0000000e+00 7.2761103e-11 1.9272264e-08 1.3672499e-15], sum to 1.0000
[2019-03-26 21:14:06,886] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4560
[2019-03-26 21:14:06,895] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1994242.139152862 W.
[2019-03-26 21:14:06,901] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.4, 89.0, 1.0, 2.0, 0.4754361523061441, 1.0, 2.0, 0.4754361523061441, 1.0, 1.0, 0.8127101034304197, 6.9112, 6.9112, 170.5573041426782, 1994242.139152862, 1994242.139152862, 396343.6476665935], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2469600.0000, 
sim time next is 2470200.0000, 
raw observation next is [26.51666666666667, 88.5, 1.0, 2.0, 0.6808141627902243, 1.0, 2.0, 0.6808141627902243, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1903727.045357011, 1903727.045357011, 366013.9674520502], 
processed observation next is [1.0, 0.6086956521739131, 0.45576619273301755, 0.885, 1.0, 1.0, 0.6154387503496679, 1.0, 1.0, 0.6154387503496679, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5288130681547253, 0.5288130681547253, 0.5462895036597764], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9248359], dtype=float32), -0.99838907]. 
=============================================
[2019-03-26 21:14:07,256] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1128170: loss 0.1746
[2019-03-26 21:14:07,257] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1128170: learning rate 0.0000
[2019-03-26 21:14:09,431] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1129133: loss 0.2024
[2019-03-26 21:14:09,433] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1129134: learning rate 0.0000
[2019-03-26 21:14:09,557] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2745114e-15 1.0000000e+00 3.7720844e-14 4.3349217e-11 1.2134875e-19], sum to 1.0000
[2019-03-26 21:14:09,568] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3470
[2019-03-26 21:14:09,572] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.76666666666667, 86.33333333333334, 1.0, 2.0, 0.539127674020312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 753366.5495954424, 753366.5495954424, 189954.4600145585], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2485200.0000, 
sim time next is 2485800.0000, 
raw observation next is [27.7, 87.0, 1.0, 2.0, 0.5415113386926087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 756698.6227808386, 756698.6227808392, 190356.3363476636], 
processed observation next is [1.0, 0.782608695652174, 0.5118483412322274, 0.87, 1.0, 1.0, 0.4476040225212153, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2101940618835663, 0.21019406188356646, 0.2841139348472591], 
reward next is 0.7159, 
noisyNet noise sample is [array([1.3644946], dtype=float32), -0.6022117]. 
=============================================
[2019-03-26 21:14:11,298] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7770820e-17 1.0000000e+00 8.3029147e-17 2.5438973e-14 1.2588789e-21], sum to 1.0000
[2019-03-26 21:14:11,308] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1052
[2019-03-26 21:14:11,316] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1918526.389447049 W.
[2019-03-26 21:14:11,325] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.9, 90.33333333333333, 1.0, 2.0, 0.7310119590452874, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.989612224914922, 6.9112, 168.9124894639532, 1918526.389447049, 1862898.212164945, 392127.7423929257], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2536800.0000, 
sim time next is 2537400.0000, 
raw observation next is [27.0, 89.66666666666667, 1.0, 2.0, 0.7369929846412463, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.988198495477901, 6.9112, 168.9124345354923, 1926896.337112496, 1872271.123140178, 393535.9332281854], 
processed observation next is [1.0, 0.34782608695652173, 0.4786729857819906, 0.8966666666666667, 1.0, 1.0, 0.6831240778810196, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007699849547790105, 0.0, 0.8294373820163925, 0.5352489825312489, 0.5200753119833827, 0.5873670645196797], 
reward next is 0.0276, 
noisyNet noise sample is [array([-0.16886137], dtype=float32), -1.2949921]. 
=============================================
[2019-03-26 21:14:12,062] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1130307: loss -293.4342
[2019-03-26 21:14:12,066] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1130308: learning rate 0.0000
[2019-03-26 21:14:12,086] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1130315: loss -135.6891
[2019-03-26 21:14:12,092] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1130315: learning rate 0.0000
[2019-03-26 21:14:12,204] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1130370: loss -287.0211
[2019-03-26 21:14:12,206] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1130371: learning rate 0.0000
[2019-03-26 21:14:12,554] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1130524: loss 67.5226
[2019-03-26 21:14:12,556] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1130525: learning rate 0.0000
[2019-03-26 21:14:12,633] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1130560: loss -288.5346
[2019-03-26 21:14:12,638] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1130560: learning rate 0.0000
[2019-03-26 21:14:12,811] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1130637: loss -230.8622
[2019-03-26 21:14:12,813] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1130637: learning rate 0.0000
[2019-03-26 21:14:13,106] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1130766: loss -241.5662
[2019-03-26 21:14:13,108] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1130766: learning rate 0.0000
[2019-03-26 21:14:13,187] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1130803: loss -117.2999
[2019-03-26 21:14:13,188] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1130803: learning rate 0.0000
[2019-03-26 21:14:13,724] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1131043: loss -153.0150
[2019-03-26 21:14:13,729] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1131043: learning rate 0.0000
[2019-03-26 21:14:13,820] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1131087: loss -188.8347
[2019-03-26 21:14:13,821] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1131087: learning rate 0.0000
[2019-03-26 21:14:13,871] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1131110: loss -213.1124
[2019-03-26 21:14:13,875] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1131110: learning rate 0.0000
[2019-03-26 21:14:13,963] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.2705778e-20 1.0000000e+00 7.4479601e-19 2.4937222e-15 3.8083191e-24], sum to 1.0000
[2019-03-26 21:14:13,976] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1656
[2019-03-26 21:14:13,984] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 90.0, 1.0, 2.0, 0.5143747832153845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 718765.6378186536, 718765.6378186536, 185878.5886857517], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2586600.0000, 
sim time next is 2587200.0000, 
raw observation next is [26.0, 90.33333333333334, 1.0, 2.0, 0.5116815054405028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 715000.8983977824, 715000.8983977824, 185446.2512504732], 
processed observation next is [1.0, 0.9565217391304348, 0.4312796208530806, 0.9033333333333334, 1.0, 1.0, 0.41166446438614795, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19861136066605065, 0.19861136066605065, 0.27678544962757196], 
reward next is 0.7232, 
noisyNet noise sample is [array([0.8385967], dtype=float32), -0.1423633]. 
=============================================
[2019-03-26 21:14:16,291] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0155746e-20 1.0000000e+00 3.7344982e-19 3.0936986e-16 2.0824845e-24], sum to 1.0000
[2019-03-26 21:14:16,299] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3622
[2019-03-26 21:14:16,307] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4758616036700493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 665060.7513070958, 665060.7513070963, 179916.7981240377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2624400.0000, 
sim time next is 2625000.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4757732070636331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 664937.0254277509, 664937.0254277509, 179903.5648397444], 
processed observation next is [0.0, 0.391304347826087, 0.4312796208530806, 0.84, 1.0, 1.0, 0.3684014542935339, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18470472928548637, 0.18470472928548637, 0.2685127833429021], 
reward next is 0.7315, 
noisyNet noise sample is [array([-0.06488045], dtype=float32), -0.06427762]. 
=============================================
[2019-03-26 21:14:16,322] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[73.516975]
 [73.507   ]
 [73.50525 ]
 [73.500694]
 [73.500275]], R is [[73.52774048]
 [73.52393341]
 [73.52024841]
 [73.516716  ]
 [73.51331329]].
[2019-03-26 21:14:17,251] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1132608: loss 0.0024
[2019-03-26 21:14:17,253] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1132608: learning rate 0.0000
[2019-03-26 21:14:19,308] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1133524: loss 0.2736
[2019-03-26 21:14:19,311] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1133526: learning rate 0.0000
[2019-03-26 21:14:19,675] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9187156e-20 1.0000000e+00 1.7820781e-18 3.1633324e-16 7.5016861e-25], sum to 1.0000
[2019-03-26 21:14:19,682] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5765
[2019-03-26 21:14:19,686] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.540977909640847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 807130.6990653153, 807130.6990653153, 196616.662729004], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3070200.0000, 
sim time next is 3070800.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.4581022426458296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 683473.5253452257, 683473.5253452263, 182696.7856311444], 
processed observation next is [1.0, 0.5652173913043478, 0.28909952606635075, 0.94, 1.0, 1.0, 0.347111135717867, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18985375704034047, 0.18985375704034063, 0.272681769598723], 
reward next is 0.7273, 
noisyNet noise sample is [array([-0.62417924], dtype=float32), 0.42048186]. 
=============================================
[2019-03-26 21:14:22,499] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1134954: loss 0.2475
[2019-03-26 21:14:22,504] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1134955: learning rate 0.0000
[2019-03-26 21:14:24,833] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1135992: loss 0.0029
[2019-03-26 21:14:24,834] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1135992: learning rate 0.0000
[2019-03-26 21:14:26,993] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1136949: loss 0.0028
[2019-03-26 21:14:26,996] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1136949: learning rate 0.0000
[2019-03-26 21:14:30,008] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1138291: loss 0.2521
[2019-03-26 21:14:30,009] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1138291: learning rate 0.0000
[2019-03-26 21:14:30,121] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1138339: loss 0.2598
[2019-03-26 21:14:30,125] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1138340: learning rate 0.0000
[2019-03-26 21:14:30,180] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1138367: loss 0.2494
[2019-03-26 21:14:30,182] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1138367: learning rate 0.0000
[2019-03-26 21:14:30,613] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1138545: loss 0.2599
[2019-03-26 21:14:30,616] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1138546: learning rate 0.0000
[2019-03-26 21:14:30,622] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1138549: loss 0.2551
[2019-03-26 21:14:30,623] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1138549: learning rate 0.0000
[2019-03-26 21:14:30,855] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1138650: loss 0.2601
[2019-03-26 21:14:30,857] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1138651: learning rate 0.0000
[2019-03-26 21:14:31,124] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1138772: loss 0.2516
[2019-03-26 21:14:31,125] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1138772: learning rate 0.0000
[2019-03-26 21:14:31,393] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1138889: loss 0.2461
[2019-03-26 21:14:31,395] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1138889: learning rate 0.0000
[2019-03-26 21:14:31,748] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1139050: loss 0.2772
[2019-03-26 21:14:31,751] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1139050: learning rate 0.0000
[2019-03-26 21:14:31,897] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1139113: loss 0.2681
[2019-03-26 21:14:31,900] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1139114: learning rate 0.0000
[2019-03-26 21:14:32,008] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.7006758e-19 1.0000000e+00 2.7776597e-18 8.6623375e-16 1.2211099e-23], sum to 1.0000
[2019-03-26 21:14:32,019] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2451
[2019-03-26 21:14:32,027] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3481086805393849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 536252.434237533, 536252.4342375337, 169509.2681583941], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2857200.0000, 
sim time next is 2857800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3479205549480015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 535962.7626764473, 535962.7626764467, 169485.5977016161], 
processed observation next is [1.0, 0.043478260869565216, 0.2417061611374408, 0.94, 1.0, 1.0, 0.21436211439518252, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14887854518790203, 0.14887854518790186, 0.2529635786591285], 
reward next is 0.7470, 
noisyNet noise sample is [array([0.744723], dtype=float32), -0.021987408]. 
=============================================
[2019-03-26 21:14:32,060] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1139188: loss 0.2776
[2019-03-26 21:14:32,061] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1139188: learning rate 0.0000
[2019-03-26 21:14:33,994] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2423439e-19 1.0000000e+00 3.6254334e-18 4.3397421e-16 4.8355722e-24], sum to 1.0000
[2019-03-26 21:14:34,005] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0558
[2019-03-26 21:14:34,012] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.6897703147367458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1062221.276120694, 1062221.276120694, 230933.8717244141], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2909400.0000, 
sim time next is 2910000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.6798689586545278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1046995.521519257, 1046995.521519256, 228620.2719340856], 
processed observation next is [1.0, 0.6956521739130435, 0.2417061611374408, 0.94, 1.0, 1.0, 0.614299950186178, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2908320893109047, 0.2908320893109045, 0.3412242864687845], 
reward next is 0.6588, 
noisyNet noise sample is [array([-1.1428281], dtype=float32), -1.0826429]. 
=============================================
[2019-03-26 21:14:34,031] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[71.913925]
 [71.88842 ]
 [71.86121 ]
 [71.895164]
 [71.89322 ]], R is [[71.90898132]
 [71.84521484]
 [71.78936005]
 [71.72806549]
 [71.66543579]].
[2019-03-26 21:14:34,739] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.8885420e-21 1.0000000e+00 2.2430752e-19 5.7102064e-17 2.0200462e-24], sum to 1.0000
[2019-03-26 21:14:34,746] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9108
[2019-03-26 21:14:34,755] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 99.00000000000001, 1.0, 2.0, 0.3431875476310522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 534162.7870504323, 534162.7870504316, 169493.8753872201], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2916600.0000, 
sim time next is 2917200.0000, 
raw observation next is [21.0, 98.0, 1.0, 2.0, 0.3380407253222273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527771.1459022759, 527771.1459022759, 169022.2824738064], 
processed observation next is [1.0, 0.782608695652174, 0.19431279620853087, 0.98, 1.0, 1.0, 0.20245870520750275, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14660309608396555, 0.14660309608396555, 0.2522720633937409], 
reward next is 0.7477, 
noisyNet noise sample is [array([0.08762418], dtype=float32), 0.5569878]. 
=============================================
[2019-03-26 21:14:35,553] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1140743: loss 0.1928
[2019-03-26 21:14:35,558] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1140744: learning rate 0.0000
[2019-03-26 21:14:37,233] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.1507136e-19 1.0000000e+00 1.1269355e-17 2.8132056e-15 1.7861094e-23], sum to 1.0000
[2019-03-26 21:14:37,239] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1141497: loss 0.0022
[2019-03-26 21:14:37,241] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1141497: learning rate 0.0000
[2019-03-26 21:14:37,250] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7306
[2019-03-26 21:14:37,255] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.314803195304462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 497805.83781817, 497805.8378181707, 166861.4792520773], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2954400.0000, 
sim time next is 2955000.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.3160220621309831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 499731.7658908868, 499731.7658908868, 167005.2323440549], 
processed observation next is [1.0, 0.17391304347826086, 0.19431279620853087, 0.94, 1.0, 1.0, 0.17593019533853385, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1388143794141352, 0.1388143794141352, 0.24926154081202226], 
reward next is 0.7507, 
noisyNet noise sample is [array([-0.5861486], dtype=float32), -1.1047441]. 
=============================================
[2019-03-26 21:14:37,264] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[70.17336 ]
 [70.25808 ]
 [70.343796]
 [70.38755 ]
 [70.45644 ]], R is [[70.21414948]
 [70.26296234]
 [70.31189728]
 [70.36051178]
 [70.40692139]].
[2019-03-26 21:14:40,445] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1142917: loss 0.0027
[2019-03-26 21:14:40,449] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1142918: learning rate 0.0000
[2019-03-26 21:14:43,166] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1144135: loss 0.2172
[2019-03-26 21:14:43,167] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1144135: learning rate 0.0000
[2019-03-26 21:14:45,339] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1145106: loss 0.1874
[2019-03-26 21:14:45,342] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1145108: learning rate 0.0000
[2019-03-26 21:14:47,245] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.8770510e-19 1.0000000e+00 3.7260620e-18 2.9712806e-15 1.8757293e-23], sum to 1.0000
[2019-03-26 21:14:47,253] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5517
[2019-03-26 21:14:47,260] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 89.0, 1.0, 2.0, 0.6353656039245327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 959454.6949367183, 959454.6949367183, 216482.4968872991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3144000.0000, 
sim time next is 3144600.0000, 
raw observation next is [23.5, 89.0, 1.0, 2.0, 0.663191505572691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 996052.9649350531, 996052.9649350538, 221913.1927502466], 
processed observation next is [1.0, 0.391304347826087, 0.31279620853080575, 0.89, 1.0, 1.0, 0.5942066332201097, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2766813791486259, 0.27668137914862606, 0.33121372052275616], 
reward next is 0.6688, 
noisyNet noise sample is [array([-0.62046444], dtype=float32), -0.23261677]. 
=============================================
[2019-03-26 21:14:47,871] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1146213: loss 0.0026
[2019-03-26 21:14:47,875] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1146214: learning rate 0.0000
[2019-03-26 21:14:47,924] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1146237: loss 0.0027
[2019-03-26 21:14:47,926] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1146237: learning rate 0.0000
[2019-03-26 21:14:48,086] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1146308: loss 0.0026
[2019-03-26 21:14:48,092] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1146309: learning rate 0.0000
[2019-03-26 21:14:48,242] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1146378: loss 0.0028
[2019-03-26 21:14:48,245] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1146380: learning rate 0.0000
[2019-03-26 21:14:48,476] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1146482: loss 0.0024
[2019-03-26 21:14:48,480] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1146483: learning rate 0.0000
[2019-03-26 21:14:48,736] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1146595: loss 0.0025
[2019-03-26 21:14:48,740] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1146595: learning rate 0.0000
[2019-03-26 21:14:49,058] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1146740: loss 0.0026
[2019-03-26 21:14:49,062] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1146741: learning rate 0.0000
[2019-03-26 21:14:49,142] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1146777: loss 0.0025
[2019-03-26 21:14:49,145] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1146777: learning rate 0.0000
[2019-03-26 21:14:49,468] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1146920: loss 0.0023
[2019-03-26 21:14:49,470] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1146920: learning rate 0.0000
[2019-03-26 21:14:49,637] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1146996: loss 0.0024
[2019-03-26 21:14:49,640] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1146997: learning rate 0.0000
[2019-03-26 21:14:49,902] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1147112: loss 0.0023
[2019-03-26 21:14:49,903] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1147112: learning rate 0.0000
[2019-03-26 21:14:51,234] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.6001440e-18 1.0000000e+00 2.2386667e-17 2.3666500e-14 8.2011198e-23], sum to 1.0000
[2019-03-26 21:14:51,243] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7546
[2019-03-26 21:14:51,250] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 87.33333333333333, 1.0, 2.0, 0.4983102221022667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 696310.3400400049, 696310.3400400049, 183332.0542456736], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3177600.0000, 
sim time next is 3178200.0000, 
raw observation next is [26.16666666666667, 88.16666666666667, 1.0, 2.0, 0.498213576120285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 696175.2481932254, 696175.2481932254, 183316.855880317], 
processed observation next is [1.0, 0.782608695652174, 0.4391785150078992, 0.8816666666666667, 1.0, 1.0, 0.3954380435184157, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19338201338700706, 0.19338201338700706, 0.27360724758256266], 
reward next is 0.7264, 
noisyNet noise sample is [array([-0.39081255], dtype=float32), 1.1973318]. 
=============================================
[2019-03-26 21:14:54,639] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1149232: loss -436.6985
[2019-03-26 21:14:54,643] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1149234: learning rate 0.0000
[2019-03-26 21:14:55,335] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1149544: loss 0.1554
[2019-03-26 21:14:55,339] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1149544: learning rate 0.0000
[2019-03-26 21:14:55,511] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6139379e-20 1.0000000e+00 6.3160571e-20 1.8719832e-16 6.4222867e-25], sum to 1.0000
[2019-03-26 21:14:55,519] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4619
[2019-03-26 21:14:55,526] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5180707140281979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723931.9355733166, 723931.9355733166, 186475.836349417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3274800.0000, 
sim time next is 3275400.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5175730678558684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 723236.3073694353, 723236.3073694347, 186395.2683746903], 
processed observation next is [0.0, 0.9130434782608695, 0.5260663507109005, 0.79, 1.0, 1.0, 0.41876273235646794, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2008989742692876, 0.20089897426928743, 0.2782018930965527], 
reward next is 0.7218, 
noisyNet noise sample is [array([-0.08183684], dtype=float32), -0.45231926]. 
=============================================
[2019-03-26 21:14:55,922] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1365227e-06 9.7251928e-01 1.1242893e-06 2.7478373e-02 4.8523461e-09], sum to 1.0000
[2019-03-26 21:14:55,933] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9499
[2019-03-26 21:14:55,944] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2800618.551845738 W.
[2019-03-26 21:14:55,948] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 63.00000000000001, 1.0, 2.0, 1.001182444703939, 1.0, 2.0, 1.001182444703939, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2800618.551845738, 2800618.551845738, 529701.4728043308], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3774000.0000, 
sim time next is 3774600.0000, 
raw observation next is [33.0, 63.0, 1.0, 2.0, 0.9961382449526914, 1.0, 2.0, 0.9961382449526914, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2786492.620000559, 2786492.620000559, 526657.3601819159], 
processed observation next is [1.0, 0.6956521739130435, 0.7630331753554502, 0.63, 1.0, 1.0, 0.9953472830755319, 1.0, 1.0, 0.9953472830755319, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.774025727777933, 0.774025727777933, 0.7860557614655461], 
reward next is 0.2139, 
noisyNet noise sample is [array([-1.0199122], dtype=float32), 0.31244037]. 
=============================================
[2019-03-26 21:14:56,387] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 21:14:56,390] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:14:56,390] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:14:56,392] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:14:56,392] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:14:56,393] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:14:56,394] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:14:56,395] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:14:56,394] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:14:56,397] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:14:56,402] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:14:56,414] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run47
[2019-03-26 21:14:56,415] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run47
[2019-03-26 21:14:56,434] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run47
[2019-03-26 21:14:56,454] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run47
[2019-03-26 21:14:56,495] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run47
[2019-03-26 21:15:07,693] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08314534], dtype=float32), 0.06380846]
[2019-03-26 21:15:07,694] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [15.98225671833334, 91.21345976166667, 1.0, 2.0, 0.2339363136289077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 391331.8288856575, 391331.8288856575, 136294.9437794629]
[2019-03-26 21:15:07,694] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:15:07,696] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.3702263e-19 1.0000000e+00 3.6321191e-18 6.8414766e-16 2.0393963e-23], sampled 0.585909266968696
[2019-03-26 21:15:56,269] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08314534], dtype=float32), 0.06380846]
[2019-03-26 21:15:56,271] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.66666666666667, 75.66666666666667, 1.0, 2.0, 0.9325697108926609, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.980062429401851, 6.9112, 168.9124916666427, 2200624.679014638, 2151771.435978201, 444169.14330097]
[2019-03-26 21:15:56,272] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:15:56,274] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.0333448e-13 1.0000000e+00 8.4712960e-13 5.7718313e-10 1.6898674e-16], sampled 0.14032722413930354
[2019-03-26 21:15:56,276] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2200624.679014638 W.
[2019-03-26 21:16:10,030] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08314534], dtype=float32), 0.06380846]
[2019-03-26 21:16:10,032] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.0, 68.0, 1.0, 2.0, 0.7210927110861041, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.979425870269182, 6.9112, 168.9124964513644, 1904645.373688675, 1856243.72499579, 390231.4358330076]
[2019-03-26 21:16:10,033] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:16:10,035] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.2241704e-14 1.0000000e+00 3.6190774e-14 2.5845236e-11 5.7651403e-18], sampled 0.207939268167339
[2019-03-26 21:16:10,036] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1904645.373688675 W.
[2019-03-26 21:16:35,733] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08314534], dtype=float32), 0.06380846]
[2019-03-26 21:16:35,735] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.55, 54.0, 1.0, 2.0, 0.6698932672736555, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.005973746065319, 6.9112, 168.9117063779472, 1832999.66323427, 1765764.403529832, 378247.3213527398]
[2019-03-26 21:16:35,736] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:16:35,739] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.7258905e-17 1.0000000e+00 1.9570527e-16 2.4852204e-13 1.1589912e-20], sampled 0.33708938922001475
[2019-03-26 21:16:35,741] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1832999.66323427 W.
[2019-03-26 21:16:51,822] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0954 2842517464.9746 1131.0000
[2019-03-26 21:16:51,842] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6857 2927400807.7850 1338.0000
[2019-03-26 21:16:51,860] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.6544 2779248917.7285 933.0000
[2019-03-26 21:16:51,936] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.1633 3164105803.0955 1778.0000
[2019-03-26 21:16:52,058] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2146 3007648997.1407 1766.0000
[2019-03-26 21:16:53,077] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1150000, evaluation results [1150000.0, 7881.163293656913, 3164105803.0955105, 1778.0, 8253.68573338827, 2927400807.784972, 1338.0, 8660.654361620163, 2779248917.728524, 933.0, 7998.214591785093, 3007648997.140727, 1766.0, 8496.095384209508, 2842517464.974608, 1131.0]
[2019-03-26 21:16:54,157] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7999011e-20 1.0000000e+00 1.1830828e-18 5.6082263e-17 2.6017384e-24], sum to 1.0000
[2019-03-26 21:16:54,166] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7355
[2019-03-26 21:16:54,174] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333334, 70.66666666666667, 1.0, 2.0, 0.495279537346645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 692074.0541447345, 692074.0541447351, 182859.9811153516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3315000.0000, 
sim time next is 3315600.0000, 
raw observation next is [29.0, 70.0, 1.0, 2.0, 0.4972080054590089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 694769.66157284, 694769.6615728405, 183159.9795494174], 
processed observation next is [0.0, 0.391304347826087, 0.5734597156398105, 0.7, 1.0, 1.0, 0.3942265126012155, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1929915726591222, 0.19299157265912237, 0.2733731038051006], 
reward next is 0.7266, 
noisyNet noise sample is [array([1.1357682], dtype=float32), -0.2027638]. 
=============================================
[2019-03-26 21:16:55,182] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1151002: loss 0.1578
[2019-03-26 21:16:55,184] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1151003: learning rate 0.0000
[2019-03-26 21:16:58,225] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1152558: loss -362.8440
[2019-03-26 21:16:58,228] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1152558: learning rate 0.0000
[2019-03-26 21:16:59,664] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7861344e-18 1.0000000e+00 2.6769515e-18 5.3420070e-16 1.3643528e-23], sum to 1.0000
[2019-03-26 21:16:59,673] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2206
[2019-03-26 21:16:59,679] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 89.0, 1.0, 2.0, 0.8402982449068611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1174449.165960978, 1174449.165960978, 254045.2440379111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3394200.0000, 
sim time next is 3394800.0000, 
raw observation next is [28.0, 89.0, 1.0, 2.0, 0.8601459056015435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1202205.102822362, 1202205.102822362, 259212.7197674778], 
processed observation next is [1.0, 0.30434782608695654, 0.5260663507109005, 0.89, 1.0, 1.0, 0.831501091086197, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.33394586189510056, 0.33394586189510056, 0.38688465636936986], 
reward next is 0.6131, 
noisyNet noise sample is [array([1.4518446], dtype=float32), -0.13403946]. 
=============================================
[2019-03-26 21:17:00,482] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1153500: loss -342.4329
[2019-03-26 21:17:00,484] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1153502: learning rate 0.0000
[2019-03-26 21:17:01,969] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1154158: loss 0.1091
[2019-03-26 21:17:01,971] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1154158: learning rate 0.0000
[2019-03-26 21:17:01,989] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1154169: loss 0.1182
[2019-03-26 21:17:01,992] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1154169: learning rate 0.0000
[2019-03-26 21:17:02,114] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1154225: loss 0.1209
[2019-03-26 21:17:02,116] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1154225: learning rate 0.0000
[2019-03-26 21:17:02,240] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1154281: loss 0.1243
[2019-03-26 21:17:02,242] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1154281: learning rate 0.0000
[2019-03-26 21:17:02,530] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1154416: loss 0.1216
[2019-03-26 21:17:02,532] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1154416: learning rate 0.0000
[2019-03-26 21:17:02,736] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1154504: loss 0.1295
[2019-03-26 21:17:02,747] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1154507: learning rate 0.0000
[2019-03-26 21:17:02,945] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1154596: loss 0.1313
[2019-03-26 21:17:02,947] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1154596: learning rate 0.0000
[2019-03-26 21:17:03,247] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1154732: loss 0.1296
[2019-03-26 21:17:03,250] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1154732: learning rate 0.0000
[2019-03-26 21:17:03,333] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8981820e-21 1.0000000e+00 2.8198813e-20 5.6323244e-17 3.5721400e-26], sum to 1.0000
[2019-03-26 21:17:03,343] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5980
[2019-03-26 21:17:03,351] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.5, 75.0, 1.0, 2.0, 0.6145677356389444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 858827.6466668961, 858827.6466668961, 203491.7290027667], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3969000.0000, 
sim time next is 3969600.0000, 
raw observation next is [31.33333333333333, 76.33333333333333, 1.0, 2.0, 0.6164178685432905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 861414.1632499291, 861414.1632499298, 203844.9507847506], 
processed observation next is [0.0, 0.9565217391304348, 0.6840442338072668, 0.7633333333333333, 1.0, 1.0, 0.5378528536666151, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2392817120138692, 0.23928171201386939, 0.3042461952011203], 
reward next is 0.6958, 
noisyNet noise sample is [array([-0.5646816], dtype=float32), -0.29759014]. 
=============================================
[2019-03-26 21:17:03,466] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1154826: loss 0.1286
[2019-03-26 21:17:03,469] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1154827: learning rate 0.0000
[2019-03-26 21:17:03,643] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1154905: loss 0.1141
[2019-03-26 21:17:03,645] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1154905: learning rate 0.0000
[2019-03-26 21:17:03,955] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1155045: loss 0.1101
[2019-03-26 21:17:03,958] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1155045: learning rate 0.0000
[2019-03-26 21:17:08,732] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1157168: loss 0.0307
[2019-03-26 21:17:08,736] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1157170: learning rate 0.0000
[2019-03-26 21:17:10,157] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1157801: loss -81.2947
[2019-03-26 21:17:10,159] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1157802: learning rate 0.0000
[2019-03-26 21:17:12,039] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.3323283e-19 1.0000000e+00 1.6020955e-17 1.7359863e-13 1.8347961e-23], sum to 1.0000
[2019-03-26 21:17:12,051] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6541
[2019-03-26 21:17:12,056] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 72.0, 1.0, 2.0, 0.5456852345414839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 762533.2465050385, 762533.2465050385, 191064.4909884494], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3786000.0000, 
sim time next is 3786600.0000, 
raw observation next is [30.16666666666666, 73.5, 1.0, 2.0, 0.5498634409458047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 768373.927986347, 768373.9279863464, 191778.24675427], 
processed observation next is [1.0, 0.8260869565217391, 0.6287519747235385, 0.735, 1.0, 1.0, 0.45766679632024665, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2134372022184297, 0.21343720221842957, 0.2862361891854776], 
reward next is 0.7138, 
noisyNet noise sample is [array([-0.8814897], dtype=float32), -0.32042375]. 
=============================================
[2019-03-26 21:17:12,365] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.7813583e-21 1.0000000e+00 1.1732800e-19 1.1236571e-15 2.4357567e-25], sum to 1.0000
[2019-03-26 21:17:12,372] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4591
[2019-03-26 21:17:12,376] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666666, 72.33333333333333, 1.0, 2.0, 0.605403271208467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 846015.6657879984, 846015.665787999, 201757.0875099954], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3966000.0000, 
sim time next is 3966600.0000, 
raw observation next is [31.83333333333333, 71.66666666666667, 1.0, 2.0, 0.6070122641293909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 848265.0371713643, 848265.037171365, 202059.8077364328], 
processed observation next is [0.0, 0.9130434782608695, 0.7077409162717218, 0.7166666666666667, 1.0, 1.0, 0.5265208001558926, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23562917699204564, 0.23562917699204583, 0.3015818025916907], 
reward next is 0.6984, 
noisyNet noise sample is [array([-1.6978403], dtype=float32), 0.87026495]. 
=============================================
[2019-03-26 21:17:13,047] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1159085: loss -212.4903
[2019-03-26 21:17:13,049] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1159086: learning rate 0.0000
[2019-03-26 21:17:13,435] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1669818e-19 1.0000000e+00 1.6303624e-18 4.7467167e-15 1.0885912e-23], sum to 1.0000
[2019-03-26 21:17:13,441] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4637
[2019-03-26 21:17:13,450] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.00000000000001, 1.0, 2.0, 1.039523179617277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 169.0622343713466, 1453087.07360302, 1453087.07360302, 311222.9894951631], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3636600.0000, 
sim time next is 3637200.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.973138033165379, 6.9112, 168.9123061405828, 1497725.823755476, 1453785.020472417, 311346.8370194196], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.79, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.006193803316537938, 0.0, 0.8294367515386075, 0.4160349510431878, 0.4038291723534491, 0.4646967716707755], 
reward next is 0.2256, 
noisyNet noise sample is [array([-0.00416555], dtype=float32), -1.0803295]. 
=============================================
[2019-03-26 21:17:15,847] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1160328: loss 0.0255
[2019-03-26 21:17:15,848] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1160328: learning rate 0.0000
[2019-03-26 21:17:16,106] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7898744e-06 9.4895720e-01 2.6284020e-05 5.1012687e-02 2.2346317e-08], sum to 1.0000
[2019-03-26 21:17:16,113] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1307
[2019-03-26 21:17:16,120] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2498680.047028154 W.
[2019-03-26 21:17:16,125] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 59.0, 1.0, 2.0, 0.8933514289166565, 1.0, 2.0, 0.8933514289166565, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2498680.047028154, 2498680.047028154, 467876.2459856867], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3682800.0000, 
sim time next is 3683400.0000, 
raw observation next is [33.0, 59.0, 1.0, 2.0, 0.9622614782816608, 1.0, 2.0, 0.9622614782816608, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2691627.220941617, 2691627.220941617, 506595.0215412601], 
processed observation next is [1.0, 0.6521739130434783, 0.7630331753554502, 0.59, 1.0, 1.0, 0.9545319015441696, 1.0, 1.0, 0.9545319015441696, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7476742280393381, 0.7476742280393381, 0.756111972449642], 
reward next is 0.2439, 
noisyNet noise sample is [array([0.52369756], dtype=float32), 0.7742521]. 
=============================================
[2019-03-26 21:17:16,267] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6121976e-05 8.0225056e-01 6.4277119e-05 1.9766884e-01 2.1634388e-07], sum to 1.0000
[2019-03-26 21:17:16,275] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2541
[2019-03-26 21:17:16,285] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2697879.316262793 W.
[2019-03-26 21:17:16,290] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 59.0, 1.0, 2.0, 0.6448121911419555, 1.0, 2.0, 0.6429961350852402, 1.0, 1.0, 1.03, 7.005093381052125, 6.9112, 170.5573041426782, 2697879.316262793, 2630619.668076609, 504462.2766538461], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3686400.0000, 
sim time next is 3687000.0000, 
raw observation next is [32.83333333333334, 60.33333333333334, 1.0, 2.0, 0.8432702294253719, 1.0, 2.0, 0.8432702294253719, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2358472.082334416, 2358472.082334417, 441487.66080842], 
processed observation next is [1.0, 0.6956521739130435, 0.7551342812006324, 0.6033333333333334, 1.0, 1.0, 0.8111689511149058, 1.0, 1.0, 0.8111689511149058, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6551311339817822, 0.6551311339817825, 0.6589368071767463], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9699948], dtype=float32), 1.0836142]. 
=============================================
[2019-03-26 21:17:16,301] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[17.220102]
 [18.34777 ]
 [17.041965]
 [18.03089 ]
 [19.737537]], R is [[18.620821  ]
 [18.43461227]
 [18.47410774]
 [18.28936768]
 [18.10647392]].
[2019-03-26 21:17:16,790] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7120623e-06 9.2760926e-01 5.8744004e-06 7.2383136e-02 8.9968362e-09], sum to 1.0000
[2019-03-26 21:17:16,796] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2652
[2019-03-26 21:17:16,802] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2805294.833809647 W.
[2019-03-26 21:17:16,806] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.0, 61.0, 1.0, 2.0, 0.6959562889454433, 1.0, 2.0, 0.6685681839869841, 1.0, 1.0, 1.03, 7.005097413315289, 6.9112, 170.5573041426782, 2805294.833809647, 2738032.297149336, 520054.4530666978], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3677400.0000, 
sim time next is 3678000.0000, 
raw observation next is [33.0, 60.33333333333333, 1.0, 2.0, 0.6955951330512271, 1.0, 2.0, 0.6683876060398761, 1.0, 2.0, 1.03, 7.005097384838887, 6.9112, 170.5573041426782, 2804536.282871166, 2737273.766609659, 519940.7953161272], 
processed observation next is [1.0, 0.5652173913043478, 0.7630331753554502, 0.6033333333333333, 1.0, 1.0, 0.6332471482544905, 1.0, 1.0, 0.6004669952287663, 1.0, 1.0, 1.0365853658536586, 0.00938973848388871, 0.0, 0.8375144448122397, 0.7790378563531016, 0.7603538240582386, 0.7760310377852645], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9105157], dtype=float32), 1.1521305]. 
=============================================
[2019-03-26 21:17:16,835] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[21.846184]
 [24.001783]
 [23.075274]
 [24.587591]
 [22.724005]], R is [[20.72406769]
 [20.51682663]
 [20.31165886]
 [20.1085434 ]
 [19.90745735]].
[2019-03-26 21:17:16,946] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5568084e-16 1.0000000e+00 2.6857111e-15 2.1004335e-11 3.3114072e-21], sum to 1.0000
[2019-03-26 21:17:16,955] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7270
[2019-03-26 21:17:16,964] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 79.0, 1.0, 2.0, 0.5508000066866207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 769683.1501883166, 769683.1501883172, 191938.2722912116], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3697200.0000, 
sim time next is 3697800.0000, 
raw observation next is [29.0, 78.16666666666667, 1.0, 2.0, 0.5485338291444588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 766515.270746748, 766515.2707467487, 191549.6587717301], 
processed observation next is [1.0, 0.8260869565217391, 0.5734597156398105, 0.7816666666666667, 1.0, 1.0, 0.4560648543909142, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21292090854076332, 0.2129209085407635, 0.28589501309213444], 
reward next is 0.7141, 
noisyNet noise sample is [array([1.4336455], dtype=float32), -2.0818212]. 
=============================================
[2019-03-26 21:17:17,822] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1161198: loss 0.0315
[2019-03-26 21:17:17,825] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1161199: learning rate 0.0000
[2019-03-26 21:17:20,143] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1162216: loss -412.3802
[2019-03-26 21:17:20,146] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1162216: learning rate 0.0000
[2019-03-26 21:17:20,192] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1162238: loss -296.0158
[2019-03-26 21:17:20,197] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1162238: learning rate 0.0000
[2019-03-26 21:17:20,522] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1162383: loss -467.0630
[2019-03-26 21:17:20,524] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1162383: learning rate 0.0000
[2019-03-26 21:17:20,565] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1162403: loss -398.0273
[2019-03-26 21:17:20,569] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1162403: learning rate 0.0000
[2019-03-26 21:17:20,673] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1162449: loss -120.0203
[2019-03-26 21:17:20,676] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1162449: learning rate 0.0000
[2019-03-26 21:17:20,778] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1162499: loss -553.7234
[2019-03-26 21:17:20,780] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1162499: learning rate 0.0000
[2019-03-26 21:17:21,218] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1162688: loss -327.8951
[2019-03-26 21:17:21,220] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1162688: learning rate 0.0000
[2019-03-26 21:17:21,429] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1162781: loss -550.2480
[2019-03-26 21:17:21,432] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1162781: learning rate 0.0000
[2019-03-26 21:17:21,555] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1162840: loss -341.3045
[2019-03-26 21:17:21,559] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1162840: learning rate 0.0000
[2019-03-26 21:17:21,717] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1162910: loss -415.9772
[2019-03-26 21:17:21,721] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1162910: learning rate 0.0000
[2019-03-26 21:17:22,068] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1163063: loss -145.4347
[2019-03-26 21:17:22,070] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1163063: learning rate 0.0000
[2019-03-26 21:17:26,610] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3917739e-20 1.0000000e+00 2.1866308e-19 1.1930007e-15 3.8451786e-24], sum to 1.0000
[2019-03-26 21:17:26,620] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4045
[2019-03-26 21:17:26,624] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.33333333333334, 54.0, 1.0, 2.0, 0.5662677183640833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 791305.6474213669, 791305.6474213663, 194630.0383783326], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3864000.0000, 
sim time next is 3864600.0000, 
raw observation next is [34.0, 54.5, 1.0, 2.0, 0.5566991877508232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777929.6332983342, 777929.6332983342, 192956.6862147729], 
processed observation next is [0.0, 0.7391304347826086, 0.8104265402843602, 0.545, 1.0, 1.0, 0.46590263584436525, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21609156480509284, 0.21609156480509284, 0.28799505405189985], 
reward next is 0.7120, 
noisyNet noise sample is [array([0.7405603], dtype=float32), -0.27021682]. 
=============================================
[2019-03-26 21:17:27,157] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1165328: loss -419.5912
[2019-03-26 21:17:27,159] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1165329: learning rate 0.0000
[2019-03-26 21:17:27,829] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1165630: loss 0.0248
[2019-03-26 21:17:27,830] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1165630: learning rate 0.0000
[2019-03-26 21:17:30,897] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1166997: loss 0.0272
[2019-03-26 21:17:30,903] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1166997: learning rate 0.0000
[2019-03-26 21:17:34,391] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.5629383e-10 9.9999893e-01 9.5106334e-10 1.0617861e-06 5.0192055e-13], sum to 1.0000
[2019-03-26 21:17:34,401] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2088
[2019-03-26 21:17:34,410] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1720176.957998069 W.
[2019-03-26 21:17:34,415] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.6152205062356659, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.95481197737118, 6.9112, 168.9126122941608, 1720176.957998069, 1689237.183292734, 367408.8123819258], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3991800.0000, 
sim time next is 3992400.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.591859104004734, 1.0, 1.0, 0.591859104004734, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1654794.336752699, 1654794.336752699, 331272.8453299826], 
processed observation next is [1.0, 0.21739130434782608, 0.5734597156398105, 0.84, 1.0, 1.0, 0.5082639807285951, 1.0, 0.5, 0.5082639807285951, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.45966509354241636, 0.45966509354241636, 0.49443708258206354], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.34489375], dtype=float32), 1.1907568]. 
=============================================
[2019-03-26 21:17:34,537] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1168626: loss -229.4070
[2019-03-26 21:17:34,541] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1168627: learning rate 0.0000
[2019-03-26 21:17:36,553] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1169523: loss -189.2306
[2019-03-26 21:17:36,555] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1169524: learning rate 0.0000
[2019-03-26 21:17:38,012] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1170169: loss 0.0392
[2019-03-26 21:17:38,018] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1170170: learning rate 0.0000
[2019-03-26 21:17:38,062] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1170190: loss 0.0462
[2019-03-26 21:17:38,065] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1170190: learning rate 0.0000
[2019-03-26 21:17:38,201] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1170252: loss 0.0295
[2019-03-26 21:17:38,201] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1170252: learning rate 0.0000
[2019-03-26 21:17:38,354] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1170325: loss 0.0444
[2019-03-26 21:17:38,357] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1170325: learning rate 0.0000
[2019-03-26 21:17:38,415] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1170345: loss 0.0290
[2019-03-26 21:17:38,417] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1170346: learning rate 0.0000
[2019-03-26 21:17:38,482] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1170378: loss 0.0223
[2019-03-26 21:17:38,485] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1170379: learning rate 0.0000
[2019-03-26 21:17:39,065] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1170637: loss 0.0450
[2019-03-26 21:17:39,066] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1170637: learning rate 0.0000
[2019-03-26 21:17:39,351] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1170760: loss 0.0424
[2019-03-26 21:17:39,352] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1170761: learning rate 0.0000
[2019-03-26 21:17:39,412] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1170788: loss 0.0285
[2019-03-26 21:17:39,415] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1170790: learning rate 0.0000
[2019-03-26 21:17:39,494] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1170826: loss 0.0342
[2019-03-26 21:17:39,496] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1170827: learning rate 0.0000
[2019-03-26 21:17:39,975] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1171039: loss 0.0272
[2019-03-26 21:17:39,977] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1171039: learning rate 0.0000
[2019-03-26 21:17:40,287] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4176856e-15 1.0000000e+00 3.5221491e-15 4.8436233e-12 3.3180473e-20], sum to 1.0000
[2019-03-26 21:17:40,296] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4179
[2019-03-26 21:17:40,306] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2176614.887170687 W.
[2019-03-26 21:17:40,314] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.66666666666666, 79.83333333333334, 1.0, 2.0, 0.7783057437052899, 1.0, 2.0, 0.7783057437052899, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2176614.887170687, 2176614.887170687, 409453.4675258832], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4092600.0000, 
sim time next is 4093200.0000, 
raw observation next is [30.0, 79.0, 1.0, 2.0, 0.5013982465696953, 1.0, 2.0, 0.5013982465696953, 1.0, 1.0, 0.8707629393576196, 6.9112, 6.9112, 170.5573041426782, 2103248.422233628, 2103248.422233628, 416114.8325798362], 
processed observation next is [1.0, 0.391304347826087, 0.6208530805687204, 0.79, 1.0, 1.0, 0.3992749958671028, 1.0, 1.0, 0.3992749958671028, 1.0, 0.5, 0.8423938284849019, 0.0, 0.0, 0.8375144448122397, 0.5842356728426745, 0.5842356728426745, 0.621066914298263], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2384093], dtype=float32), 0.029048774]. 
=============================================
[2019-03-26 21:17:44,088] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.3766407e-20 1.0000000e+00 8.2349620e-19 9.2700743e-15 1.0661970e-23], sum to 1.0000
[2019-03-26 21:17:44,097] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1616
[2019-03-26 21:17:44,103] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.624745264154756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 873056.0788470854, 873056.0788470854, 205446.8751922994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4318800.0000, 
sim time next is 4319400.0000, 
raw observation next is [31.0, 79.0, 1.0, 2.0, 0.624147732083174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 872220.7092239243, 872220.7092239243, 205331.2684898376], 
processed observation next is [1.0, 1.0, 0.6682464454976303, 0.79, 1.0, 1.0, 0.5471659422688843, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.242283530339979, 0.242283530339979, 0.3064645798355785], 
reward next is 0.6935, 
noisyNet noise sample is [array([1.1886986], dtype=float32), 0.09815001]. 
=============================================
[2019-03-26 21:17:44,898] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1173232: loss 0.0393
[2019-03-26 21:17:44,903] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1173232: learning rate 0.0000
[2019-03-26 21:17:46,540] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1173958: loss -254.8239
[2019-03-26 21:17:46,541] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1173958: learning rate 0.0000
[2019-03-26 21:17:48,876] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 21:17:48,878] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:17:48,879] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:17:48,879] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:17:48,881] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:17:48,882] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:17:48,883] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:17:48,881] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:17:48,883] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:17:48,885] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:17:48,887] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:17:48,912] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run48
[2019-03-26 21:17:48,933] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run48
[2019-03-26 21:17:48,935] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run48
[2019-03-26 21:17:48,954] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run48
[2019-03-26 21:17:49,002] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run48
[2019-03-26 21:18:06,572] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08135712], dtype=float32), 0.06147834]
[2019-03-26 21:18:06,573] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [20.95, 85.5, 1.0, 2.0, 0.2851543967414766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 461129.2041853706, 461129.2041853706, 164343.2593572697]
[2019-03-26 21:18:06,574] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:18:06,577] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.7849619e-19 1.0000000e+00 1.9048075e-18 7.1769483e-16 5.8306331e-24], sampled 0.23371435371162774
[2019-03-26 21:18:56,091] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08135712], dtype=float32), 0.06147834]
[2019-03-26 21:18:56,091] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.66666666666667, 84.0, 1.0, 2.0, 0.5419766475752494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 757349.0692028189, 757349.0692028189, 190433.6967397708]
[2019-03-26 21:18:56,093] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:18:56,097] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0746757e-20 1.0000000e+00 1.1070700e-19 3.5051383e-16 3.0939914e-25], sampled 0.7339798905317283
[2019-03-26 21:19:36,638] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08135712], dtype=float32), 0.06147834]
[2019-03-26 21:19:36,640] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.76666666666667, 64.83333333333334, 1.0, 2.0, 0.8172139290730722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1142167.845330982, 1142167.845330982, 248186.9486041588]
[2019-03-26 21:19:36,640] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:19:36,644] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1549055e-18 1.0000000e+00 1.8070586e-17 7.8173043e-14 1.6376886e-23], sampled 0.2743631948242995
[2019-03-26 21:19:39,334] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08135712], dtype=float32), 0.06147834]
[2019-03-26 21:19:39,334] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.76966357, 91.42620937, 1.0, 2.0, 0.427940346170008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 627325.5793359153, 627325.5793359153, 176822.6645436213]
[2019-03-26 21:19:39,335] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:19:39,340] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.7467106e-20 1.0000000e+00 6.5784454e-19 1.2042808e-15 2.7591806e-24], sampled 0.9915637973527189
[2019-03-26 21:19:41,521] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08135712], dtype=float32), 0.06147834]
[2019-03-26 21:19:41,523] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.1082463, 87.12824193166668, 1.0, 2.0, 0.6009707311001595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 839819.0013384251, 839819.0013384244, 200927.1487270634]
[2019-03-26 21:19:41,525] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:19:41,527] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.5882512e-20 1.0000000e+00 2.5343790e-19 6.8099713e-16 6.9361261e-25], sampled 0.44584938176248834
[2019-03-26 21:19:44,042] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.1279 2779303888.4386 933.0000
[2019-03-26 21:19:44,095] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.9850 2842661141.0203 1131.0000
[2019-03-26 21:19:44,360] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5374 3007672604.7148 1766.0000
[2019-03-26 21:19:44,383] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.4067 2927264152.9822 1338.0000
[2019-03-26 21:19:44,443] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7878.5101 3164366437.3076 1776.0000
[2019-03-26 21:19:45,457] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1175000, evaluation results [1175000.0, 7878.510112814466, 3164366437.307597, 1776.0, 8254.406660643592, 2927264152.9821725, 1338.0, 8659.127917113585, 2779303888.438552, 933.0, 7997.537410079355, 3007672604.7147675, 1766.0, 8495.985009183636, 2842661141.020265, 1131.0]
[2019-03-26 21:19:45,515] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1175034: loss -132.3944
[2019-03-26 21:19:45,518] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1175035: learning rate 0.0000
[2019-03-26 21:19:48,110] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1176420: loss 0.2533
[2019-03-26 21:19:48,113] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1176422: learning rate 0.0000
[2019-03-26 21:19:49,983] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1177257: loss 0.0483
[2019-03-26 21:19:49,986] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1177258: learning rate 0.0000
[2019-03-26 21:19:51,980] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0366701e-13 1.0000000e+00 9.5781120e-13 5.4959770e-10 4.6701625e-17], sum to 1.0000
[2019-03-26 21:19:51,991] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2301
[2019-03-26 21:19:52,001] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1660813.92158735 W.
[2019-03-26 21:19:52,005] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 0.594010421204663, 1.0, 1.0, 0.594010421204663, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1660813.92158735, 1660813.92158735, 332063.9003500919], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4336200.0000, 
sim time next is 4336800.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 0.5071177965672004, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8806959062191979, 6.9112, 6.9112, 168.9129564187548, 1417716.326384359, 1417716.326384359, 312064.2457245051], 
processed observation next is [1.0, 0.17391304347826086, 0.5734597156398105, 0.89, 1.0, 1.0, 0.40616601996048235, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.854507202706339, 0.0, 0.0, 0.8294399447021306, 0.393810090662322, 0.393810090662322, 0.46576753093209716], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.15226136], dtype=float32), -0.12221882]. 
=============================================
[2019-03-26 21:19:52,351] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1178304: loss -327.7415
[2019-03-26 21:19:52,352] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1178305: learning rate 0.0000
[2019-03-26 21:19:52,356] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1178307: loss -170.5114
[2019-03-26 21:19:52,357] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1178307: learning rate 0.0000
[2019-03-26 21:19:52,388] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1178319: loss -111.2752
[2019-03-26 21:19:52,393] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1178321: learning rate 0.0000
[2019-03-26 21:19:52,581] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1178405: loss -137.1037
[2019-03-26 21:19:52,583] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1178406: learning rate 0.0000
[2019-03-26 21:19:52,588] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1178408: loss -150.7440
[2019-03-26 21:19:52,589] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1178408: learning rate 0.0000
[2019-03-26 21:19:52,627] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1178423: loss -276.4549
[2019-03-26 21:19:52,631] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1178424: learning rate 0.0000
[2019-03-26 21:19:53,217] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1178685: loss -299.2583
[2019-03-26 21:19:53,219] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1178685: learning rate 0.0000
[2019-03-26 21:19:53,418] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7102305e-06 9.8985213e-01 1.0527839e-06 1.0144073e-02 2.5393680e-09], sum to 1.0000
[2019-03-26 21:19:53,425] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2914
[2019-03-26 21:19:53,435] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3367833.139217023 W.
[2019-03-26 21:19:53,441] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.83333333333334, 71.66666666666667, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.550518623400177, 6.9112, 170.5573041426782, 3367833.139217023, 2909863.203456585, 550147.9737788067], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4355400.0000, 
sim time next is 4356000.0000, 
raw observation next is [34.0, 71.0, 1.0, 2.0, 0.9330811356586278, 1.0, 2.0, 0.7871306073435763, 1.0, 1.0, 1.03, 7.005116117588326, 6.9112, 170.5573041426782, 3303437.610754651, 3236161.675462722, 605065.5681524237], 
processed observation next is [1.0, 0.43478260869565216, 0.8104265402843602, 0.71, 1.0, 1.0, 0.9193748622393106, 1.0, 1.0, 0.7435308522211763, 1.0, 0.5, 1.0365853658536586, 0.009391611758832585, 0.0, 0.8375144448122397, 0.9176215585429586, 0.898933798739645, 0.9030829375409309], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6928713], dtype=float32), -0.28478438]. 
=============================================
[2019-03-26 21:19:53,453] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[20.669   ]
 [20.330753]
 [19.768883]
 [20.111933]
 [22.595285]], R is [[18.16444588]
 [17.98280144]
 [17.80297279]
 [17.84174347]
 [17.66332626]].
[2019-03-26 21:19:53,454] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1178786: loss -150.8948
[2019-03-26 21:19:53,456] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1178786: learning rate 0.0000
[2019-03-26 21:19:53,606] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1178853: loss -160.7012
[2019-03-26 21:19:53,608] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1178854: learning rate 0.0000
[2019-03-26 21:19:53,632] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1178864: loss -200.6031
[2019-03-26 21:19:53,636] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1178865: learning rate 0.0000
[2019-03-26 21:19:54,076] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1179063: loss -277.0827
[2019-03-26 21:19:54,079] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1179063: learning rate 0.0000
[2019-03-26 21:19:56,749] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0559290e-19 1.0000000e+00 2.5031441e-18 4.9609102e-15 1.3710093e-24], sum to 1.0000
[2019-03-26 21:19:56,754] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9182
[2019-03-26 21:19:56,761] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 84.0, 1.0, 2.0, 0.6167573076257186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 861888.7054186263, 861888.705418627, 203909.6718430076], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4407000.0000, 
sim time next is 4407600.0000, 
raw observation next is [30.0, 84.0, 1.0, 2.0, 0.6162785628958777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861219.4114177788, 861219.4114177788, 203818.1714228774], 
processed observation next is [0.0, 0.0, 0.6208530805687204, 0.84, 1.0, 1.0, 0.537685015537202, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23922761428271633, 0.23922761428271633, 0.30420622600429464], 
reward next is 0.6958, 
noisyNet noise sample is [array([1.2130746], dtype=float32), 0.21703821]. 
=============================================
[2019-03-26 21:19:58,985] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1181250: loss -138.0988
[2019-03-26 21:19:58,988] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1181251: learning rate 0.0000
[2019-03-26 21:20:00,230] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1181806: loss 0.0879
[2019-03-26 21:20:00,234] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1181807: learning rate 0.0000
[2019-03-26 21:20:02,588] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.7133850e-21 1.0000000e+00 2.9677050e-20 1.4653064e-16 2.5959573e-25], sum to 1.0000
[2019-03-26 21:20:02,594] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2573
[2019-03-26 21:20:02,598] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.83333333333334, 1.0, 2.0, 0.498187785142159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 696139.1975420427, 696139.1975420427, 183312.3870787389], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4525800.0000, 
sim time next is 4526400.0000, 
raw observation next is [28.0, 75.66666666666667, 1.0, 2.0, 0.5004519591862049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 699304.0666094151, 699304.0666094158, 183666.8470487834], 
processed observation next is [0.0, 0.391304347826087, 0.5260663507109005, 0.7566666666666667, 1.0, 1.0, 0.398134890585789, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19425112961372643, 0.19425112961372662, 0.27412962246087075], 
reward next is 0.7259, 
noisyNet noise sample is [array([-1.6714308], dtype=float32), 1.6551375]. 
=============================================
[2019-03-26 21:20:02,684] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1182889: loss 0.0308
[2019-03-26 21:20:02,685] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1182889: learning rate 0.0000
[2019-03-26 21:20:03,627] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.0904482e-20 1.0000000e+00 3.7923964e-19 2.4085752e-16 4.2606412e-25], sum to 1.0000
[2019-03-26 21:20:03,636] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1597
[2019-03-26 21:20:03,643] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 89.0, 1.0, 2.0, 0.4888727929782466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 683118.7735822961, 683118.7735822955, 181871.2613208176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5028600.0000, 
sim time next is 5029200.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.4941889482615396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 690549.6347464543, 690549.6347464537, 182690.9289405063], 
processed observation next is [0.0, 0.21739130434782608, 0.4312796208530806, 0.89, 1.0, 1.0, 0.3905890942910115, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1918193429851262, 0.19181934298512604, 0.27267302826941237], 
reward next is 0.7273, 
noisyNet noise sample is [array([2.4007027], dtype=float32), 1.8352677]. 
=============================================
[2019-03-26 21:20:04,498] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.2628326e-07 9.7232902e-01 8.7416134e-07 2.7669556e-02 2.1962552e-09], sum to 1.0000
[2019-03-26 21:20:04,509] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1884
[2019-03-26 21:20:04,516] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2639772.41901484 W.
[2019-03-26 21:20:04,521] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.66666666666667, 68.33333333333333, 1.0, 2.0, 0.6291619061905167, 1.0, 2.0, 0.6291619061905167, 1.0, 1.0, 1.03, 6.981627221812754, 6.9112, 170.5573041426782, 2639772.41901484, 2589322.535234144, 498794.4969622501], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4722600.0000, 
sim time next is 4723200.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.9663251823490009, 1.0, 2.0, 0.9663251823490009, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2703006.465926885, 2703006.465926884, 508969.4170372624], 
processed observation next is [1.0, 0.6956521739130435, 0.7156398104265403, 0.67, 1.0, 1.0, 0.959427930540965, 1.0, 1.0, 0.959427930540965, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7508351294241348, 0.7508351294241346, 0.7596558463242723], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7553476], dtype=float32), -0.7313865]. 
=============================================
[2019-03-26 21:20:06,491] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1184588: loss -129.9301
[2019-03-26 21:20:06,496] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1184588: learning rate 0.0000
[2019-03-26 21:20:08,345] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1185414: loss -125.5257
[2019-03-26 21:20:08,348] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1185414: learning rate 0.0000
[2019-03-26 21:20:08,821] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.9763456e-20 1.0000000e+00 2.4645809e-18 2.1663520e-15 6.4008647e-24], sum to 1.0000
[2019-03-26 21:20:08,831] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0798
[2019-03-26 21:20:08,836] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 78.16666666666667, 1.0, 2.0, 0.4892636336620337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 683665.0844578402, 683665.0844578402, 181930.6123048576], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4755000.0000, 
sim time next is 4755600.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.4879558388627915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 681837.0708440433, 681837.070844044, 181730.1153975545], 
processed observation next is [1.0, 0.043478260869565216, 0.4786729857819906, 0.79, 1.0, 1.0, 0.383079323931074, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18939918634556757, 0.18939918634556777, 0.27123897820530524], 
reward next is 0.7288, 
noisyNet noise sample is [array([0.6234858], dtype=float32), -2.0768561]. 
=============================================
[2019-03-26 21:20:10,066] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1186179: loss 0.1245
[2019-03-26 21:20:10,068] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1186180: learning rate 0.0000
[2019-03-26 21:20:10,136] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1186210: loss 0.0987
[2019-03-26 21:20:10,138] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1186210: learning rate 0.0000
[2019-03-26 21:20:10,204] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1186237: loss 0.1544
[2019-03-26 21:20:10,205] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1186239: learning rate 0.0000
[2019-03-26 21:20:10,305] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1186285: loss 0.1456
[2019-03-26 21:20:10,310] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1186286: learning rate 0.0000
[2019-03-26 21:20:10,342] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1186300: loss 0.0312
[2019-03-26 21:20:10,346] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1186300: learning rate 0.0000
[2019-03-26 21:20:10,425] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1186337: loss 0.0257
[2019-03-26 21:20:10,428] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1186337: learning rate 0.0000
[2019-03-26 21:20:11,259] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1186705: loss 0.1745
[2019-03-26 21:20:11,261] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1186706: learning rate 0.0000
[2019-03-26 21:20:11,329] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1186738: loss 0.0830
[2019-03-26 21:20:11,331] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1186738: learning rate 0.0000
[2019-03-26 21:20:11,544] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1186830: loss 0.3108
[2019-03-26 21:20:11,551] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1186832: learning rate 0.0000
[2019-03-26 21:20:11,649] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1186883: loss 0.1906
[2019-03-26 21:20:11,650] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1186883: learning rate 0.0000
[2019-03-26 21:20:12,217] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1187130: loss 0.0685
[2019-03-26 21:20:12,219] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1187130: learning rate 0.0000
[2019-03-26 21:20:16,820] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1189171: loss 13.1180
[2019-03-26 21:20:16,823] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1189171: learning rate 0.0000
[2019-03-26 21:20:18,577] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1189959: loss -116.6965
[2019-03-26 21:20:18,580] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1189959: learning rate 0.0000
[2019-03-26 21:20:18,590] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.6658716e-20 1.0000000e+00 1.1434677e-19 6.3100736e-16 3.3146500e-24], sum to 1.0000
[2019-03-26 21:20:18,598] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3051
[2019-03-26 21:20:18,603] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333333, 72.66666666666667, 1.0, 2.0, 0.5296395360667537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740103.3907889776, 740103.3907889769, 188370.2028500197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5165400.0000, 
sim time next is 5166000.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.52713651146288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 736604.5218805672, 736604.5218805678, 187956.8702118441], 
processed observation next is [0.0, 0.8260869565217391, 0.5734597156398105, 0.74, 1.0, 1.0, 0.4302849535697349, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20461236718904643, 0.2046123671890466, 0.28053264210723], 
reward next is 0.7195, 
noisyNet noise sample is [array([-0.5371444], dtype=float32), 0.11752178]. 
=============================================
[2019-03-26 21:20:18,616] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[72.07735 ]
 [72.057655]
 [72.017265]
 [71.99903 ]
 [71.97342 ]], R is [[72.11763763]
 [72.11531067]
 [72.11244202]
 [72.10907745]
 [72.10516357]].
[2019-03-26 21:20:20,868] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1190973: loss -159.4863
[2019-03-26 21:20:20,871] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1190973: learning rate 0.0000
[2019-03-26 21:20:23,991] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1192361: loss 18.5482
[2019-03-26 21:20:23,994] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1192362: learning rate 0.0000
[2019-03-26 21:20:25,904] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1193218: loss 19.9943
[2019-03-26 21:20:25,909] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1193219: learning rate 0.0000
[2019-03-26 21:20:28,034] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1194169: loss -159.6589
[2019-03-26 21:20:28,037] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1194169: learning rate 0.0000
[2019-03-26 21:20:28,085] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1194188: loss -144.3388
[2019-03-26 21:20:28,088] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1194189: learning rate 0.0000
[2019-03-26 21:20:28,296] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1194285: loss -125.4435
[2019-03-26 21:20:28,303] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1194285: learning rate 0.0000
[2019-03-26 21:20:28,316] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1194295: loss -125.5099
[2019-03-26 21:20:28,319] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1194295: learning rate 0.0000
[2019-03-26 21:20:28,411] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1194334: loss -159.6824
[2019-03-26 21:20:28,414] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1194334: learning rate 0.0000
[2019-03-26 21:20:28,549] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1194396: loss -125.4485
[2019-03-26 21:20:28,555] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1194400: learning rate 0.0000
[2019-03-26 21:20:29,376] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1194757: loss -139.2274
[2019-03-26 21:20:29,377] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1194757: learning rate 0.0000
[2019-03-26 21:20:29,390] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1194762: loss -117.0544
[2019-03-26 21:20:29,393] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1194763: learning rate 0.0000
[2019-03-26 21:20:29,550] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1194834: loss -139.0094
[2019-03-26 21:20:29,552] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1194836: learning rate 0.0000
[2019-03-26 21:20:29,587] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1194850: loss -159.8603
[2019-03-26 21:20:29,589] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1194850: learning rate 0.0000
[2019-03-26 21:20:30,105] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1195082: loss -116.8063
[2019-03-26 21:20:30,108] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1195082: learning rate 0.0000
[2019-03-26 21:20:31,459] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0388908e-08 9.9671078e-01 1.9181890e-08 3.2891831e-03 2.1154315e-12], sum to 1.0000
[2019-03-26 21:20:31,466] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0518
[2019-03-26 21:20:31,475] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2890690.104573426 W.
[2019-03-26 21:20:31,482] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.08333333333334, 48.16666666666666, 1.0, 2.0, 1.033344567576344, 1.0, 2.0, 1.033344567576344, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2890690.104573426, 2890690.104573425, 549459.897697895], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5497800.0000, 
sim time next is 5498400.0000, 
raw observation next is [35.96666666666667, 48.33333333333333, 1.0, 2.0, 1.014592398994442, 1.0, 2.0, 1.014592398994442, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2838172.976352855, 2838172.976352856, 537864.1206823144], 
processed observation next is [1.0, 0.6521739130434783, 0.9036334913112165, 0.4833333333333333, 1.0, 1.0, 1.0175812036077616, 1.0, 1.0, 1.0175812036077616, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7883813823202376, 0.7883813823202378, 0.8027822696750961], 
reward next is 0.1972, 
noisyNet noise sample is [array([-0.13777916], dtype=float32), -0.64000714]. 
=============================================
[2019-03-26 21:20:35,045] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1197280: loss 0.9694
[2019-03-26 21:20:35,047] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1197281: learning rate 0.0000
[2019-03-26 21:20:36,143] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1197769: loss 15.5488
[2019-03-26 21:20:36,146] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1197769: learning rate 0.0000
[2019-03-26 21:20:38,692] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1198913: loss 17.0749
[2019-03-26 21:20:38,698] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1198914: learning rate 0.0000
[2019-03-26 21:20:41,135] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 21:20:41,135] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:20:41,137] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:20:41,137] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:20:41,137] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:20:41,138] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:20:41,139] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:20:41,139] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:20:41,140] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:20:41,143] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:20:41,142] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:20:41,170] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run49
[2019-03-26 21:20:41,192] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run49
[2019-03-26 21:20:41,213] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run49
[2019-03-26 21:20:41,215] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run49
[2019-03-26 21:20:41,216] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run49
[2019-03-26 21:20:59,147] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08400325], dtype=float32), 0.06296095]
[2019-03-26 21:20:59,148] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.65685572, 72.62631583, 1.0, 2.0, 0.3123150181849904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 503303.7144943915, 503303.7144943908, 167342.9995802796]
[2019-03-26 21:20:59,151] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:20:59,155] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.8313177e-20 1.0000000e+00 2.2786246e-19 2.2279844e-16 4.8163133e-25], sampled 0.4349771983522758
[2019-03-26 21:21:02,171] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08400325], dtype=float32), 0.06296095]
[2019-03-26 21:21:02,172] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [18.22913564666667, 96.21105095833335, 1.0, 2.0, 0.2653197497154077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 438397.9655545844, 438397.9655545838, 162391.7403154108]
[2019-03-26 21:21:02,173] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:21:02,175] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.7277248e-21 1.0000000e+00 9.0940812e-20 1.7532871e-16 1.3891924e-25], sampled 0.2661206663175847
[2019-03-26 21:21:27,013] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08400325], dtype=float32), 0.06296095]
[2019-03-26 21:21:27,014] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.45, 79.16666666666667, 1.0, 2.0, 0.5768738507019132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 806132.3397436545, 806132.3397436551, 196516.13134705]
[2019-03-26 21:21:27,015] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:21:27,018] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2136258e-20 1.0000000e+00 1.1884515e-19 5.5247999e-16 2.7580323e-25], sampled 0.7664337388502234
[2019-03-26 21:21:51,921] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08400325], dtype=float32), 0.06296095]
[2019-03-26 21:21:51,922] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.86666666666667, 80.16666666666667, 1.0, 2.0, 0.6344841977655424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 886671.5231623399, 886671.5231623399, 207346.1734361458]
[2019-03-26 21:21:51,925] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:21:51,929] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.5801171e-21 1.0000000e+00 2.0978215e-20 2.0210103e-16 2.8500451e-26], sampled 0.7852021433449589
[2019-03-26 21:22:11,740] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08400325], dtype=float32), 0.06296095]
[2019-03-26 21:22:11,742] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.25409051, 90.80779371, 1.0, 2.0, 0.5231182068916913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730987.5333064273, 730987.5333064273, 187297.1668072361]
[2019-03-26 21:22:11,744] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:22:11,746] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.7840588e-21 1.0000000e+00 3.8621215e-20 2.3009894e-16 1.0143486e-25], sampled 0.10185884870772388
[2019-03-26 21:22:14,320] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08400325], dtype=float32), 0.06296095]
[2019-03-26 21:22:14,321] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.56224095, 84.84456456, 1.0, 2.0, 0.9877449369121211, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.00599270439908, 6.9112, 168.9123159237597, 2277848.960765061, 2210600.008787616, 459558.8035889899]
[2019-03-26 21:22:14,322] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:22:14,324] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.4254077e-15 1.0000000e+00 3.8686930e-15 1.7411711e-11 1.9896819e-19], sampled 0.7866367760648653
[2019-03-26 21:22:14,325] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2277848.960765061 W.
[2019-03-26 21:22:26,599] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08400325], dtype=float32), 0.06296095]
[2019-03-26 21:22:26,601] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.93333333333334, 66.83333333333333, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.405727072092882, 6.9112, 168.9101628140531, 1804823.94210967, 1453995.219404375, 311353.8089129003]
[2019-03-26 21:22:26,606] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:22:26,607] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.19975665e-20 1.00000000e+00 8.53515071e-20 3.30673245e-16
 1.23924107e-25], sampled 0.7523707144527042
[2019-03-26 21:22:26,609] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1804823.94210967 W.
[2019-03-26 21:22:27,257] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08400325], dtype=float32), 0.06296095]
[2019-03-26 21:22:27,259] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.12352057, 71.91286769333334, 1.0, 2.0, 0.4088502630617925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 609783.7012628864, 609783.7012628864, 175433.9177525747]
[2019-03-26 21:22:27,259] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:22:27,263] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.2003971e-21 1.0000000e+00 9.5391360e-20 3.5989668e-16 1.7316039e-25], sampled 0.1740063115831686
[2019-03-26 21:22:35,534] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08400325], dtype=float32), 0.06296095]
[2019-03-26 21:22:35,535] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.46666666666667, 72.66666666666666, 1.0, 2.0, 0.6657209125970925, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.984891247070262, 6.9112, 168.9124582400168, 1827161.303075747, 1774882.350363423, 378167.4749113382]
[2019-03-26 21:22:35,535] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:22:35,537] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.0540084e-12 1.0000000e+00 5.6243950e-12 3.7128498e-08 1.9344157e-15], sampled 0.8274777776002964
[2019-03-26 21:22:35,538] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1827161.303075747 W.
[2019-03-26 21:22:35,731] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7995.9990 3007799231.0350 1766.0000
[2019-03-26 21:22:35,879] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9767 2779207024.4606 933.0000
[2019-03-26 21:22:35,965] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.7366 2842517435.7223 1131.0000
[2019-03-26 21:22:35,973] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.8487 2927400550.8281 1338.0000
[2019-03-26 21:22:35,993] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.7672 3164102243.7041 1778.0000
[2019-03-26 21:22:37,010] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1200000, evaluation results [1200000.0, 7884.767168054142, 3164102243.704051, 1778.0, 8252.848719883228, 2927400550.8281245, 1338.0, 8659.976662972434, 2779207024.4606214, 933.0, 7995.998988991475, 3007799231.0350223, 1766.0, 8496.73656601701, 2842517435.72233, 1131.0]
[2019-03-26 21:22:38,152] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1200535: loss 0.9178
[2019-03-26 21:22:38,155] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1200535: learning rate 0.0000
[2019-03-26 21:22:39,559] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1201382: loss 0.5818
[2019-03-26 21:22:39,563] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1201383: learning rate 0.0000
[2019-03-26 21:22:39,903] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.76883439e-07 9.84396458e-01 1.40275529e-06 1.56013835e-02
 2.36608177e-09], sum to 1.0000
[2019-03-26 21:22:39,911] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9362
[2019-03-26 21:22:39,918] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2506869.673548613 W.
[2019-03-26 21:22:39,923] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.83333333333333, 67.5, 1.0, 2.0, 0.8962765264066731, 1.0, 2.0, 0.8962765264066731, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2506869.673548613, 2506869.673548613, 469466.7508386465], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5226600.0000, 
sim time next is 5227200.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.6232300997092302, 1.0, 2.0, 0.6232300997092302, 1.0, 1.0, 1.03, 6.970045526054255, 6.9112, 170.5573041426782, 2614858.31498394, 2572704.87098832, 496555.3594501014], 
processed observation next is [1.0, 0.5217391304347826, 0.7156398104265403, 0.67, 1.0, 1.0, 0.546060361095458, 1.0, 1.0, 0.546060361095458, 1.0, 0.5, 1.0365853658536586, 0.005884552605425508, 0.0, 0.8375144448122397, 0.7263495319399834, 0.7146402419412, 0.7411274021643304], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4317969], dtype=float32), -0.21780135]. 
=============================================
[2019-03-26 21:22:41,181] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1202107: loss 8.4912
[2019-03-26 21:22:41,183] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1202107: learning rate 0.0000
[2019-03-26 21:22:41,372] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1202189: loss 13.3774
[2019-03-26 21:22:41,375] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1202189: learning rate 0.0000
[2019-03-26 21:22:41,528] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1202258: loss 18.6006
[2019-03-26 21:22:41,529] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1202258: learning rate 0.0000
[2019-03-26 21:22:41,664] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1202312: loss 13.3687
[2019-03-26 21:22:41,667] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1202314: learning rate 0.0000
[2019-03-26 21:22:41,718] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1202338: loss 11.4199
[2019-03-26 21:22:41,719] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1202338: learning rate 0.0000
[2019-03-26 21:22:41,926] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1202426: loss 17.2092
[2019-03-26 21:22:41,928] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1202426: learning rate 0.0000
[2019-03-26 21:22:42,521] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1202667: loss 7.7152
[2019-03-26 21:22:42,523] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1202667: learning rate 0.0000
[2019-03-26 21:22:42,764] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1202776: loss 18.4249
[2019-03-26 21:22:42,770] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1202777: learning rate 0.0000
[2019-03-26 21:22:42,851] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1202809: loss 15.7913
[2019-03-26 21:22:42,853] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1202811: learning rate 0.0000
[2019-03-26 21:22:42,919] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1202838: loss 16.9189
[2019-03-26 21:22:42,921] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1202839: learning rate 0.0000
[2019-03-26 21:22:43,421] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1203063: loss 13.3802
[2019-03-26 21:22:43,429] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1203065: learning rate 0.0000
[2019-03-26 21:22:45,150] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3023689e-19 1.0000000e+00 2.7725135e-19 2.0552969e-16 7.8424696e-25], sum to 1.0000
[2019-03-26 21:22:45,160] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9374
[2019-03-26 21:22:45,165] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 75.5, 1.0, 2.0, 0.5288519511965191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 739002.459011747, 739002.4590117476, 188240.4328122601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5646600.0000, 
sim time next is 5647200.0000, 
raw observation next is [29.16666666666666, 75.0, 1.0, 2.0, 0.531538149414752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742757.3872545608, 742757.3872545602, 188685.3781932706], 
processed observation next is [0.0, 0.34782608695652173, 0.5813586097946285, 0.75, 1.0, 1.0, 0.43558813182500233, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20632149645960024, 0.20632149645960007, 0.28161996745264267], 
reward next is 0.7184, 
noisyNet noise sample is [array([-0.32740912], dtype=float32), 0.37998736]. 
=============================================
[2019-03-26 21:22:48,344] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1205261: loss 143.0851
[2019-03-26 21:22:48,345] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1205261: learning rate 0.0000
[2019-03-26 21:22:49,807] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1205909: loss 1.0923
[2019-03-26 21:22:49,808] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1205909: learning rate 0.0000
[2019-03-26 21:22:52,176] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1206964: loss 0.4241
[2019-03-26 21:22:52,179] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1206965: learning rate 0.0000
[2019-03-26 21:22:55,416] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1208399: loss 126.6764
[2019-03-26 21:22:55,417] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1208399: learning rate 0.0000
[2019-03-26 21:22:55,672] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2652529e-18 1.0000000e+00 7.9041574e-18 3.7086274e-14 1.2392518e-23], sum to 1.0000
[2019-03-26 21:22:55,677] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7909
[2019-03-26 21:22:55,683] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 76.0, 1.0, 2.0, 0.5537443060477982, 1.0, 1.0, 0.5537443060477982, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1548151.206582437, 1548151.206582437, 317808.9051794496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5472000.0000, 
sim time next is 5472600.0000, 
raw observation next is [31.21666666666667, 75.33333333333334, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.260758089179407, 6.9112, 168.9109370009364, 1701910.344950498, 1453924.770556386, 311355.9368391257], 
processed observation next is [1.0, 0.34782608695652173, 0.6785150078988943, 0.7533333333333334, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0349558089179407, 0.0, 0.8294300284361488, 0.47275287359736057, 0.40386799182121835, 0.4647103534912324], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.28485763], dtype=float32), 1.9117023]. 
=============================================
[2019-03-26 21:22:57,138] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1209161: loss 112.5775
[2019-03-26 21:22:57,141] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1209162: learning rate 0.0000
[2019-03-26 21:22:59,246] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1210092: loss 1.1318
[2019-03-26 21:22:59,248] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1210092: learning rate 0.0000
[2019-03-26 21:22:59,566] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1210238: loss 1.1188
[2019-03-26 21:22:59,569] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1210238: learning rate 0.0000
[2019-03-26 21:22:59,664] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1210277: loss 0.9326
[2019-03-26 21:22:59,666] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1210278: learning rate 0.0000
[2019-03-26 21:22:59,798] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1210338: loss 1.4951
[2019-03-26 21:22:59,804] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1210339: learning rate 0.0000
[2019-03-26 21:22:59,868] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1210367: loss 0.5299
[2019-03-26 21:22:59,871] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1210369: learning rate 0.0000
[2019-03-26 21:23:00,084] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1210462: loss 1.5038
[2019-03-26 21:23:00,085] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1210462: learning rate 0.0000
[2019-03-26 21:23:00,620] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1210706: loss 1.0661
[2019-03-26 21:23:00,623] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1210706: learning rate 0.0000
[2019-03-26 21:23:00,755] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1210764: loss 0.5399
[2019-03-26 21:23:00,756] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1210764: learning rate 0.0000
[2019-03-26 21:23:00,864] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1210810: loss 0.3206
[2019-03-26 21:23:00,865] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1210810: learning rate 0.0000
[2019-03-26 21:23:00,957] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.8921447e-08 9.9915051e-01 1.8937618e-07 8.4926526e-04 2.0558852e-10], sum to 1.0000
[2019-03-26 21:23:00,964] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5324
[2019-03-26 21:23:00,972] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2359491.177658596 W.
[2019-03-26 21:23:00,976] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.5, 62.0, 1.0, 2.0, 0.5624228417723925, 1.0, 1.0, 0.5624228417723925, 1.0, 2.0, 0.976742480082685, 6.911200000000001, 6.9112, 170.5573041426782, 2359491.177658596, 2359491.177658595, 460996.3695691614], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5569200.0000, 
sim time next is 5569800.0000, 
raw observation next is [32.6, 61.16666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 8.70033760879017, 6.9112, 168.902707803954, 3555118.640138035, 2285919.855752121, 471482.0082186539], 
processed observation next is [1.0, 0.4782608695652174, 0.7440758293838864, 0.6116666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.17891376087901695, 0.0, 0.8293896193116225, 0.9875329555938986, 0.6349777377089225, 0.7037044898785879], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.44077024], dtype=float32), 2.135496]. 
=============================================
[2019-03-26 21:23:01,014] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1210878: loss 0.4960
[2019-03-26 21:23:01,016] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1210878: learning rate 0.0000
[2019-03-26 21:23:01,103] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1250194e-06 9.8983216e-01 1.0763641e-06 1.0165555e-02 7.0161982e-10], sum to 1.0000
[2019-03-26 21:23:01,111] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2592
[2019-03-26 21:23:01,117] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2304391.305855505 W.
[2019-03-26 21:23:01,122] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.8, 59.5, 1.0, 2.0, 0.8239514930193955, 1.0, 2.0, 0.8239514930193955, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2304391.305855505, 2304391.305855505, 431700.5394947713], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5571000.0000, 
sim time next is 5571600.0000, 
raw observation next is [32.9, 58.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.360908347315324, 6.9112, 168.910701936003, 2607865.300839887, 2288830.979871539, 475361.4458912244], 
processed observation next is [1.0, 0.4782608695652174, 0.7582938388625592, 0.5866666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.044970834731532426, 0.0, 0.8294288741597126, 0.7244070280110797, 0.6357863832976497, 0.7094946953600364], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.4107122], dtype=float32), 0.13949758]. 
=============================================
[2019-03-26 21:23:01,410] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1211049: loss 1.4815
[2019-03-26 21:23:01,413] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1211049: learning rate 0.0000
[2019-03-26 21:23:01,869] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3684373e-07 8.8899928e-01 1.1498350e-06 1.1099924e-01 1.9205648e-09], sum to 1.0000
[2019-03-26 21:23:01,877] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6198
[2019-03-26 21:23:01,885] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2311349.79058196 W.
[2019-03-26 21:23:01,892] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.26666666666667, 53.66666666666667, 1.0, 2.0, 0.5509581666549442, 1.0, 2.0, 0.5509581666549442, 1.0, 2.0, 0.9510283490028572, 6.911199999999999, 6.9112, 170.5573041426782, 2311349.79058196, 2311349.790581961, 451004.8901730112], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5588400.0000, 
sim time next is 5589000.0000, 
raw observation next is [33.2, 54.0, 1.0, 2.0, 1.015871326527399, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.98826465068702, 6.9112, 168.9124985049229, 2317217.034355832, 2262544.867041226, 468881.2337122891], 
processed observation next is [1.0, 0.6956521739130435, 0.7725118483412324, 0.54, 1.0, 1.0, 1.0191220801534928, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007706465068701984, 0.0, 0.829437696135582, 0.6436713984321755, 0.6284846852892294, 0.6998227368840135], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2130554], dtype=float32), 1.3811812]. 
=============================================
[2019-03-26 21:23:01,913] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[21.988108]
 [23.568264]
 [25.091482]
 [24.132166]
 [25.83234 ]], R is [[23.12935829]
 [23.22492409]
 [22.99267578]
 [23.11175537]
 [23.17653847]].
[2019-03-26 21:23:02,080] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.3113867e-06 7.5855160e-01 2.5556388e-05 2.4141356e-01 1.1978820e-08], sum to 1.0000
[2019-03-26 21:23:02,087] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3742
[2019-03-26 21:23:02,095] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2224503.887600615 W.
[2019-03-26 21:23:02,105] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.26666666666667, 55.33333333333334, 1.0, 2.0, 0.530275051818834, 1.0, 2.0, 0.530275051818834, 1.0, 2.0, 0.9204873526333317, 6.9112, 6.9112, 170.5573041426782, 2224503.887600615, 2224503.887600615, 436631.0912284151], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5574000.0000, 
sim time next is 5574600.0000, 
raw observation next is [33.35, 54.5, 1.0, 2.0, 0.4945558914163316, 1.0, 2.0, 0.4945558914163316, 1.0, 2.0, 0.8561862661451083, 6.911199999999999, 6.9112, 170.5573041426782, 2074518.550053851, 2074518.550053852, 410921.7568213641], 
processed observation next is [1.0, 0.5217391304347826, 0.7796208530805688, 0.545, 1.0, 1.0, 0.39103119447750795, 1.0, 1.0, 0.39103119447750795, 1.0, 1.0, 0.824617397737937, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5762551527927364, 0.5762551527927366, 0.6133160549572598], 
reward next is 0.3867, 
noisyNet noise sample is [array([-0.17364308], dtype=float32), 1.0623822]. 
=============================================
[2019-03-26 21:23:06,517] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1213320: loss 0.6403
[2019-03-26 21:23:06,523] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1213320: learning rate 0.0000
[2019-03-26 21:23:07,528] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1213768: loss 109.0946
[2019-03-26 21:23:07,530] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1213768: learning rate 0.0000
[2019-03-26 21:23:09,132] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.3519380e-20 1.0000000e+00 1.2566395e-19 7.7465557e-16 2.1372668e-25], sum to 1.0000
[2019-03-26 21:23:09,145] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2379
[2019-03-26 21:23:09,151] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 88.0, 1.0, 2.0, 0.5099865169177973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712631.6026108376, 712631.6026108376, 185175.2902713618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5711400.0000, 
sim time next is 5712000.0000, 
raw observation next is [26.26666666666667, 88.33333333333333, 1.0, 2.0, 0.5103670622577988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 713163.5375938589, 713163.5375938582, 185236.0695604134], 
processed observation next is [0.0, 0.08695652173913043, 0.44391785150079005, 0.8833333333333333, 1.0, 1.0, 0.4100807979009624, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19810098266496082, 0.19810098266496062, 0.27647174561255733], 
reward next is 0.7235, 
noisyNet noise sample is [array([-1.353068], dtype=float32), -0.70136374]. 
=============================================
[2019-03-26 21:23:09,167] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[71.74466]
 [71.61865]
 [71.47135]
 [71.31036]
 [71.26924]], R is [[71.83729553]
 [71.84254456]
 [71.84780121]
 [71.85301971]
 [71.85814667]].
[2019-03-26 21:23:09,983] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1214856: loss 121.2501
[2019-03-26 21:23:09,985] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1214856: learning rate 0.0000
[2019-03-26 21:23:10,150] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0301446e-19 1.0000000e+00 1.0751032e-18 2.0099411e-14 5.3286923e-25], sum to 1.0000
[2019-03-26 21:23:10,158] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2422
[2019-03-26 21:23:10,165] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 86.0, 1.0, 2.0, 0.5304955854144774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 741300.0274749437, 741300.0274749431, 188512.1514061113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6210000.0000, 
sim time next is 6210600.0000, 
raw observation next is [27.25, 86.16666666666667, 1.0, 2.0, 0.5296273506821226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740086.3573434277, 740086.3573434271, 188368.3708849643], 
processed observation next is [1.0, 0.9130434782608695, 0.490521327014218, 0.8616666666666667, 1.0, 1.0, 0.43328596467725616, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2055795437065077, 0.20557954370650755, 0.2811468222163646], 
reward next is 0.7189, 
noisyNet noise sample is [array([-0.892524], dtype=float32), -2.1944242]. 
=============================================
[2019-03-26 21:23:11,492] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0444313e-20 1.0000000e+00 5.2203992e-20 6.1002717e-17 1.0740008e-25], sum to 1.0000
[2019-03-26 21:23:11,501] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7021
[2019-03-26 21:23:11,507] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.2, 53.0, 1.0, 2.0, 0.5179315487928451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723737.4052203717, 723737.4052203717, 186453.8137669691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5754000.0000, 
sim time next is 5754600.0000, 
raw observation next is [33.4, 53.0, 1.0, 2.0, 0.5210283406326912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 728066.2247017447, 728066.2247017447, 186957.1641838482], 
processed observation next is [0.0, 0.6086956521739131, 0.7819905213270142, 0.53, 1.0, 1.0, 0.422925711605652, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20224061797270687, 0.20224061797270687, 0.27904054355798236], 
reward next is 0.7210, 
noisyNet noise sample is [array([-0.59298915], dtype=float32), 1.4621902]. 
=============================================
[2019-03-26 21:23:12,712] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.97174915e-22 1.00000000e+00 7.66616451e-21 3.18127708e-17
 1.02666173e-25], sum to 1.0000
[2019-03-26 21:23:12,720] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4105
[2019-03-26 21:23:12,726] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.8, 79.0, 1.0, 2.0, 0.5495153097932858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 767887.2769922784, 767887.276992279, 191717.473560603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5772600.0000, 
sim time next is 5773200.0000, 
raw observation next is [28.6, 80.0, 1.0, 2.0, 0.5487683742202893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 766843.1398199901, 766843.1398199908, 191589.5144488959], 
processed observation next is [0.0, 0.8260869565217391, 0.5545023696682465, 0.8, 1.0, 1.0, 0.4563474388196257, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2130119832833306, 0.2130119832833308, 0.2859544991774566], 
reward next is 0.7140, 
noisyNet noise sample is [array([0.64179224], dtype=float32), 1.2767825]. 
=============================================
[2019-03-26 21:23:13,957] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1216620: loss 0.6366
[2019-03-26 21:23:13,959] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1216620: learning rate 0.0000
[2019-03-26 21:23:15,656] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1217376: loss 0.6375
[2019-03-26 21:23:15,658] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1217376: learning rate 0.0000
[2019-03-26 21:23:17,269] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1218087: loss 111.9658
[2019-03-26 21:23:17,271] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1218088: learning rate 0.0000
[2019-03-26 21:23:17,536] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.8810774e-09 9.9951804e-01 3.4257145e-08 4.8198522e-04 2.2129466e-12], sum to 1.0000
[2019-03-26 21:23:17,547] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3790
[2019-03-26 21:23:17,555] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1989709.042198834 W.
[2019-03-26 21:23:17,559] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.46666666666667, 63.66666666666667, 1.0, 2.0, 0.7115346668552469, 1.0, 2.0, 0.7115346668552469, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1989709.042198834, 1989709.042198834, 379107.7160382325], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5834400.0000, 
sim time next is 5835000.0000, 
raw observation next is [32.53333333333333, 63.33333333333333, 1.0, 2.0, 0.7165476263375696, 1.0, 2.0, 0.7165476263375696, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2003740.204729642, 2003740.204729642, 381294.9995167539], 
processed observation next is [1.0, 0.5217391304347826, 0.7409162717219588, 0.6333333333333333, 1.0, 1.0, 0.658491116069361, 1.0, 1.0, 0.658491116069361, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5565945013137894, 0.5565945013137894, 0.5690970142041103], 
reward next is 0.4309, 
noisyNet noise sample is [array([0.04896273], dtype=float32), 0.19310594]. 
=============================================
[2019-03-26 21:23:17,568] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[30.464855]
 [28.93668 ]
 [26.986986]
 [25.060186]
 [24.030405]], R is [[31.98306084]
 [32.09739685]
 [32.21400833]
 [32.2961235 ]
 [32.25087738]].
[2019-03-26 21:23:17,675] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1218267: loss 147.4028
[2019-03-26 21:23:17,677] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1218268: learning rate 0.0000
[2019-03-26 21:23:17,719] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1218288: loss 123.0587
[2019-03-26 21:23:17,722] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1218288: learning rate 0.0000
[2019-03-26 21:23:17,752] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1218303: loss 116.1303
[2019-03-26 21:23:17,754] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1218304: learning rate 0.0000
[2019-03-26 21:23:17,802] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1218323: loss 141.0331
[2019-03-26 21:23:17,804] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1218324: learning rate 0.0000
[2019-03-26 21:23:18,131] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1218472: loss 128.0348
[2019-03-26 21:23:18,133] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1218472: learning rate 0.0000
[2019-03-26 21:23:18,700] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1218727: loss 159.2183
[2019-03-26 21:23:18,703] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1218727: learning rate 0.0000
[2019-03-26 21:23:18,714] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1218730: loss 125.9853
[2019-03-26 21:23:18,716] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1218731: learning rate 0.0000
[2019-03-26 21:23:18,899] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1218815: loss 139.9880
[2019-03-26 21:23:18,901] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1218816: learning rate 0.0000
[2019-03-26 21:23:18,922] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.5041019e-20 1.0000000e+00 1.8409905e-19 2.3569681e-15 4.8967707e-25], sum to 1.0000
[2019-03-26 21:23:18,926] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1218823: loss 112.3442
[2019-03-26 21:23:18,930] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4001
[2019-03-26 21:23:18,930] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1218826: learning rate 0.0000
[2019-03-26 21:23:18,939] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 91.0, 1.0, 2.0, 0.5317772567758355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 743091.6264425924, 743091.6264425929, 188724.4704651713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5877000.0000, 
sim time next is 5877600.0000, 
raw observation next is [26.43333333333333, 91.33333333333333, 1.0, 2.0, 0.5309379209262786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 741918.3508864839, 741918.3508864839, 188585.1632545386], 
processed observation next is [1.0, 0.0, 0.4518167456556081, 0.9133333333333333, 1.0, 1.0, 0.4348649649714199, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2060884308018011, 0.2060884308018011, 0.2814703929172218], 
reward next is 0.7185, 
noisyNet noise sample is [array([0.44440863], dtype=float32), 0.04966415]. 
=============================================
[2019-03-26 21:23:19,455] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1219062: loss 127.3169
[2019-03-26 21:23:19,457] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1219062: learning rate 0.0000
[2019-03-26 21:23:24,302] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1221222: loss 252.1377
[2019-03-26 21:23:24,304] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1221223: learning rate 0.0000
[2019-03-26 21:23:25,870] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1221916: loss 1.3460
[2019-03-26 21:23:25,872] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1221916: learning rate 0.0000
[2019-03-26 21:23:28,070] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1222898: loss 0.5850
[2019-03-26 21:23:28,072] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1222900: learning rate 0.0000
[2019-03-26 21:23:31,617] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1224472: loss 332.4352
[2019-03-26 21:23:31,619] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1224473: learning rate 0.0000
[2019-03-26 21:23:32,253] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.4637469e-09 9.9876761e-01 5.4549545e-08 1.2322575e-03 3.6584498e-12], sum to 1.0000
[2019-03-26 21:23:32,262] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2357
[2019-03-26 21:23:32,266] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1697054.110399064 W.
[2019-03-26 21:23:32,274] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.08333333333333, 65.0, 1.0, 2.0, 0.6069619131164787, 1.0, 1.0, 0.6069619131164787, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1697054.110399064, 1697054.110399064, 336837.7745841413], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6094200.0000, 
sim time next is 6094800.0000, 
raw observation next is [31.1, 65.0, 1.0, 2.0, 0.5457478470993744, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9347403465894563, 6.9112, 6.9112, 168.9129565046544, 1525789.468863362, 1525789.468863362, 331438.9509610398], 
processed observation next is [1.0, 0.5652173913043478, 0.6729857819905214, 0.65, 1.0, 1.0, 0.45270824951731853, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.9204150568164099, 0.0, 0.0, 0.8294399451239369, 0.4238304080176005, 0.4238304080176005, 0.49468500143438776], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.20971031], dtype=float32), -1.747461]. 
=============================================
[2019-03-26 21:23:32,825] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 21:23:32,828] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:23:32,830] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:23:32,831] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:23:32,831] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:23:32,832] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:23:32,833] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:23:32,833] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:23:32,834] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:23:32,835] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:23:32,836] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:23:32,853] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run50
[2019-03-26 21:23:32,875] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run50
[2019-03-26 21:23:32,898] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run50
[2019-03-26 21:23:32,919] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run50
[2019-03-26 21:23:32,919] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run50
[2019-03-26 21:23:42,219] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08338417], dtype=float32), 0.0616029]
[2019-03-26 21:23:42,220] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.984499755, 62.80984914, 1.0, 2.0, 0.4601476861153906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 720688.1920965135, 720688.192096514, 186698.4621892015]
[2019-03-26 21:23:42,223] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:23:42,226] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.2330417e-20 1.0000000e+00 6.8026646e-19 1.0489549e-15 1.7500859e-24], sampled 0.628101877994584
[2019-03-26 21:23:45,121] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08338417], dtype=float32), 0.0616029]
[2019-03-26 21:23:45,124] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.8, 70.5, 1.0, 2.0, 0.4263707776078601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 626469.144949952, 626469.144949952, 176777.1256369181]
[2019-03-26 21:23:45,125] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:23:45,129] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2369960e-20 1.0000000e+00 1.0714016e-19 5.7396043e-16 2.2542800e-25], sampled 0.3523965877499027
[2019-03-26 21:24:32,875] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08338417], dtype=float32), 0.0616029]
[2019-03-26 21:24:32,877] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.7, 49.33333333333333, 1.0, 2.0, 0.7633736257593431, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.99050286977884, 6.9112, 168.9124203153264, 1963814.634888726, 1907554.628265087, 399574.6142779076]
[2019-03-26 21:24:32,878] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:24:32,881] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0368535e-10 9.9999809e-01 1.8346262e-10 1.8852504e-06 6.4688435e-14], sampled 0.16389060874067363
[2019-03-26 21:24:32,882] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1963814.634888726 W.
[2019-03-26 21:25:27,819] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3694 2779190338.1949 933.0000
[2019-03-26 21:25:27,997] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.1944 3164285246.3636 1778.0000
[2019-03-26 21:25:28,003] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.4067 2927264152.9822 1338.0000
[2019-03-26 21:25:28,110] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7995.9992 3007918481.8735 1766.0000
[2019-03-26 21:25:28,331] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8493.7888 2842644872.5258 1131.0000
[2019-03-26 21:25:29,347] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1225000, evaluation results [1225000.0, 7883.194427732159, 3164285246.363639, 1778.0, 8254.406660643592, 2927264152.9821725, 1338.0, 8661.369356548688, 2779190338.194891, 933.0, 7995.999216807949, 3007918481.873536, 1766.0, 8493.788820576661, 2842644872.5258255, 1131.0]
[2019-03-26 21:25:29,685] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1225159: loss 280.9514
[2019-03-26 21:25:29,686] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1225160: learning rate 0.0000
[2019-03-26 21:25:31,227] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1226051: loss 0.5791
[2019-03-26 21:25:31,228] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1226051: learning rate 0.0000
[2019-03-26 21:25:31,709] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1226302: loss 0.5766
[2019-03-26 21:25:31,711] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1226302: learning rate 0.0000
[2019-03-26 21:25:31,774] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1226329: loss 1.1248
[2019-03-26 21:25:31,776] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1226330: learning rate 0.0000
[2019-03-26 21:25:31,857] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1226368: loss 0.6815
[2019-03-26 21:25:31,861] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1226370: learning rate 0.0000
[2019-03-26 21:25:31,887] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1226383: loss 1.3706
[2019-03-26 21:25:31,889] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1226383: learning rate 0.0000
[2019-03-26 21:25:32,152] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1226497: loss 1.9119
[2019-03-26 21:25:32,153] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1226497: learning rate 0.0000
[2019-03-26 21:25:32,727] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1226754: loss 0.6893
[2019-03-26 21:25:32,731] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1226756: learning rate 0.0000
[2019-03-26 21:25:32,910] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1226832: loss 1.1241
[2019-03-26 21:25:32,912] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1226833: learning rate 0.0000
[2019-03-26 21:25:32,946] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1226850: loss 1.1117
[2019-03-26 21:25:32,949] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1226851: learning rate 0.0000
[2019-03-26 21:25:32,971] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1226863: loss 1.9113
[2019-03-26 21:25:32,973] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1226863: learning rate 0.0000
[2019-03-26 21:25:33,500] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1227096: loss 1.1261
[2019-03-26 21:25:33,503] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1227096: learning rate 0.0000
[2019-03-26 21:25:38,132] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1229160: loss 0.0056
[2019-03-26 21:25:38,135] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1229160: learning rate 0.0000
[2019-03-26 21:25:39,477] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.7914824e-21 1.0000000e+00 2.2397482e-20 3.2363112e-16 9.6626389e-26], sum to 1.0000
[2019-03-26 21:25:39,486] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2659
[2019-03-26 21:25:39,488] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.95, 66.0, 1.0, 2.0, 0.5080061117466547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 709863.3512516905, 709863.3512516911, 184860.0016052689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6283800.0000, 
sim time next is 6284400.0000, 
raw observation next is [29.8, 67.0, 1.0, 2.0, 0.510293733637623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 713061.0371501195, 713061.0371501202, 185224.5668484073], 
processed observation next is [0.0, 0.7391304347826086, 0.6113744075829385, 0.67, 1.0, 1.0, 0.4099924501658108, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19807251031947765, 0.19807251031947784, 0.2764545773856825], 
reward next is 0.7235, 
noisyNet noise sample is [array([0.22553219], dtype=float32), -0.09218661]. 
=============================================
[2019-03-26 21:25:39,538] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1229789: loss 236.0425
[2019-03-26 21:25:39,540] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1229790: learning rate 0.0000
[2019-03-26 21:25:41,816] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1230810: loss 281.7938
[2019-03-26 21:25:41,820] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1230811: learning rate 0.0000
[2019-03-26 21:25:45,907] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1232634: loss 0.0033
[2019-03-26 21:25:45,909] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1232634: learning rate 0.0000
[2019-03-26 21:25:46,421] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.0882897e-20 1.0000000e+00 1.6624162e-19 2.5064349e-15 3.0749063e-25], sum to 1.0000
[2019-03-26 21:25:46,433] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7603
[2019-03-26 21:25:46,438] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333334, 87.33333333333333, 1.0, 2.0, 0.5196885430402731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 726193.3998804901, 726193.3998804907, 186738.5075661945], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6567000.0000, 
sim time next is 6567600.0000, 
raw observation next is [26.76666666666667, 87.66666666666667, 1.0, 2.0, 0.5191735408975247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 725473.5093355966, 725473.5093355973, 186654.8340875067], 
processed observation next is [1.0, 0.0, 0.46761453396524505, 0.8766666666666667, 1.0, 1.0, 0.42069101312954776, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20152041925988795, 0.20152041925988814, 0.27858930460821896], 
reward next is 0.7214, 
noisyNet noise sample is [array([-0.69468707], dtype=float32), -1.3129363]. 
=============================================
[2019-03-26 21:25:47,303] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1233255: loss 0.0039
[2019-03-26 21:25:47,305] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1233255: learning rate 0.0000
[2019-03-26 21:25:49,152] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1234083: loss 348.2409
[2019-03-26 21:25:49,155] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1234083: learning rate 0.0000
[2019-03-26 21:25:49,741] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1234341: loss 491.8209
[2019-03-26 21:25:49,744] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1234343: learning rate 0.0000
[2019-03-26 21:25:49,784] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1234364: loss 322.5502
[2019-03-26 21:25:49,785] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1234364: learning rate 0.0000
[2019-03-26 21:25:49,803] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1234371: loss 192.0043
[2019-03-26 21:25:49,805] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1234371: learning rate 0.0000
[2019-03-26 21:25:49,953] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1234438: loss 249.3784
[2019-03-26 21:25:49,955] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1234438: learning rate 0.0000
[2019-03-26 21:25:50,210] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1234553: loss 233.4978
[2019-03-26 21:25:50,212] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1234554: learning rate 0.0000
[2019-03-26 21:25:50,714] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1234776: loss 314.1367
[2019-03-26 21:25:50,716] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1234776: learning rate 0.0000
[2019-03-26 21:25:50,823] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1234824: loss 353.5132
[2019-03-26 21:25:50,826] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1234825: learning rate 0.0000
[2019-03-26 21:25:50,887] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1234851: loss 331.1444
[2019-03-26 21:25:50,893] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1234853: learning rate 0.0000
[2019-03-26 21:25:51,065] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1234930: loss 379.3386
[2019-03-26 21:25:51,070] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1234931: learning rate 0.0000
[2019-03-26 21:25:51,617] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1235177: loss 430.8165
[2019-03-26 21:25:51,619] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1235178: learning rate 0.0000
[2019-03-26 21:25:54,620] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.0454073e-09 9.9866414e-01 3.6839854e-08 1.3358829e-03 6.8098569e-12], sum to 1.0000
[2019-03-26 21:25:54,629] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8115
[2019-03-26 21:25:54,638] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2111033.085531848 W.
[2019-03-26 21:25:54,645] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.86666666666667, 60.0, 1.0, 2.0, 0.8685621208036136, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.971040544934185, 6.9112, 168.9125999941748, 2111033.085531848, 2068580.233006262, 426658.8791892057], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6536400.0000, 
sim time next is 6537000.0000, 
raw observation next is [30.73333333333333, 60.5, 1.0, 2.0, 0.4968690047573474, 1.0, 1.0, 0.4968690047573474, 1.0, 2.0, 0.8444125819230596, 6.9112, 6.9112, 170.5573041426782, 2084230.828829935, 2084230.828829935, 409626.021599804], 
processed observation next is [1.0, 0.6521739130434783, 0.6556082148499209, 0.605, 1.0, 1.0, 0.39381807802090046, 1.0, 0.5, 0.39381807802090046, 1.0, 1.0, 0.8102592462476335, 0.0, 0.0, 0.8375144448122397, 0.5789530080083153, 0.5789530080083153, 0.6113821217907522], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04710822], dtype=float32), -0.50579023]. 
=============================================
[2019-03-26 21:25:54,659] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[31.506723]
 [31.130287]
 [31.136187]
 [32.86539 ]
 [32.15171 ]], R is [[28.81910896]
 [28.53091812]
 [28.24560928]
 [28.35224724]
 [28.47792244]].
[2019-03-26 21:25:55,707] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1236990: loss -375.3128
[2019-03-26 21:25:55,709] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1236991: learning rate 0.0000
[2019-03-26 21:25:57,890] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1237962: loss 0.0047
[2019-03-26 21:25:57,891] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1237962: learning rate 0.0000
[2019-03-26 21:25:59,964] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1238882: loss 0.0032
[2019-03-26 21:25:59,967] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1238882: learning rate 0.0000
[2019-03-26 21:26:00,663] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.2053568e-19 1.0000000e+00 9.7721050e-18 1.3787931e-12 1.5764044e-23], sum to 1.0000
[2019-03-26 21:26:00,675] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2476
[2019-03-26 21:26:00,682] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666667, 85.00000000000001, 1.0, 2.0, 0.5183179903372933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 724277.5877025435, 724277.587702544, 186516.119772264], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6635400.0000, 
sim time next is 6636000.0000, 
raw observation next is [27.13333333333334, 85.0, 1.0, 2.0, 0.517155402362409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 722652.4794647552, 722652.4794647545, 186327.840041978], 
processed observation next is [1.0, 0.8260869565217391, 0.4849921011058455, 0.85, 1.0, 1.0, 0.418259520918565, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20073679985132087, 0.20073679985132067, 0.278101253793997], 
reward next is 0.7219, 
noisyNet noise sample is [array([0.40124857], dtype=float32), 0.5921064]. 
=============================================
[2019-03-26 21:26:00,691] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[66.69967 ]
 [65.77526 ]
 [64.33292 ]
 [61.990604]
 [59.69206 ]], R is [[68.13013458]
 [68.17045593]
 [68.21005249]
 [68.24874878]
 [68.28705597]].
[2019-03-26 21:26:01,661] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5819328e-21 1.0000000e+00 1.6423332e-20 3.8321764e-16 3.9658417e-26], sum to 1.0000
[2019-03-26 21:26:01,669] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4460
[2019-03-26 21:26:01,678] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.4989342556943306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 697182.6152101486, 697182.6152101492, 183429.3100557103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6652800.0000, 
sim time next is 6653400.0000, 
raw observation next is [25.91666666666667, 89.5, 1.0, 2.0, 0.4981941303632086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 696148.0668973145, 696148.0668973145, 183313.6742048307], 
processed observation next is [1.0, 0.0, 0.4273301737756717, 0.895, 1.0, 1.0, 0.395414614895432, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19337446302703182, 0.19337446302703182, 0.27360249881318016], 
reward next is 0.7264, 
noisyNet noise sample is [array([-0.62111133], dtype=float32), -2.14773]. 
=============================================
[2019-03-26 21:26:03,209] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1240327: loss -263.5240
[2019-03-26 21:26:03,210] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1240328: learning rate 0.0000
[2019-03-26 21:26:04,519] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1240908: loss -263.5440
[2019-03-26 21:26:04,522] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1240909: learning rate 0.0000
[2019-03-26 21:26:06,451] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.1269669e-20 1.0000000e+00 2.7913090e-18 4.7229947e-14 5.5992069e-24], sum to 1.0000
[2019-03-26 21:26:06,459] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5836
[2019-03-26 21:26:06,466] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 82.0, 1.0, 2.0, 0.3709714109903833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 560684.6458244983, 560684.6458244983, 171234.8478279128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7233600.0000, 
sim time next is 7234200.0000, 
raw observation next is [24.1, 82.5, 1.0, 2.0, 0.3666782519916247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 554770.5921117193, 554770.5921117193, 170744.5219319351], 
processed observation next is [1.0, 0.7391304347826086, 0.3412322274881518, 0.825, 1.0, 1.0, 0.23696174938749962, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15410294225325535, 0.15410294225325535, 0.2548425700476643], 
reward next is 0.7452, 
noisyNet noise sample is [array([-0.58195883], dtype=float32), -0.2925236]. 
=============================================
[2019-03-26 21:26:07,142] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1242068: loss 0.0035
[2019-03-26 21:26:07,144] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1242068: learning rate 0.0000
[2019-03-26 21:26:07,861] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1242393: loss 0.0030
[2019-03-26 21:26:07,864] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1242393: learning rate 0.0000
[2019-03-26 21:26:07,895] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1242404: loss 0.0061
[2019-03-26 21:26:07,896] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1242404: learning rate 0.0000
[2019-03-26 21:26:07,941] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1242425: loss 0.0035
[2019-03-26 21:26:07,944] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1242425: learning rate 0.0000
[2019-03-26 21:26:07,957] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7037164e-19 1.0000000e+00 4.7912071e-18 7.6259115e-14 2.2520636e-24], sum to 1.0000
[2019-03-26 21:26:07,967] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5956
[2019-03-26 21:26:07,974] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 67.0, 1.0, 2.0, 0.4229472398859401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 616878.4965556355, 616878.4965556355, 175726.7397801908], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6723000.0000, 
sim time next is 6723600.0000, 
raw observation next is [27.46666666666667, 67.0, 1.0, 2.0, 0.4170665138822869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 611146.1835130262, 611146.1835130256, 175261.3542101542], 
processed observation next is [1.0, 0.8260869565217391, 0.500789889415482, 0.67, 1.0, 1.0, 0.2976704986533577, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1697628287536184, 0.16976282875361823, 0.2615841107614242], 
reward next is 0.7384, 
noisyNet noise sample is [array([-0.81784016], dtype=float32), 0.73919916]. 
=============================================
[2019-03-26 21:26:08,051] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1242474: loss 0.0047
[2019-03-26 21:26:08,052] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1242474: learning rate 0.0000
[2019-03-26 21:26:08,374] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1242619: loss 0.0044
[2019-03-26 21:26:08,378] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1242619: learning rate 0.0000
[2019-03-26 21:26:08,848] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1242829: loss 0.0039
[2019-03-26 21:26:08,851] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1242830: learning rate 0.0000
[2019-03-26 21:26:08,950] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1242876: loss 0.0041
[2019-03-26 21:26:08,952] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1242879: learning rate 0.0000
[2019-03-26 21:26:09,003] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1242900: loss 0.0034
[2019-03-26 21:26:09,009] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1242901: learning rate 0.0000
[2019-03-26 21:26:09,213] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1242993: loss 0.0038
[2019-03-26 21:26:09,215] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1242994: learning rate 0.0000
[2019-03-26 21:26:09,851] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1243276: loss 0.0049
[2019-03-26 21:26:09,856] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1243277: learning rate 0.0000
[2019-03-26 21:26:11,397] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5092421e-19 1.0000000e+00 1.4395529e-18 1.6645399e-14 8.9385642e-25], sum to 1.0000
[2019-03-26 21:26:11,407] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6664
[2019-03-26 21:26:11,414] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.38333333333334, 57.83333333333333, 1.0, 2.0, 0.3161603692651043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 500065.5567217665, 500065.5567217659, 167032.459818853], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6811800.0000, 
sim time next is 6812400.0000, 
raw observation next is [26.26666666666667, 58.66666666666667, 1.0, 2.0, 0.3170777072927994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 501115.3531999768, 501115.3531999774, 167103.2722701032], 
processed observation next is [1.0, 0.8695652173913043, 0.44391785150079005, 0.5866666666666667, 1.0, 1.0, 0.17720205697927635, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13919870922221578, 0.13919870922221594, 0.2494078690598555], 
reward next is 0.7506, 
noisyNet noise sample is [array([0.43568364], dtype=float32), -0.73195624]. 
=============================================
[2019-03-26 21:26:13,709] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1244984: loss 0.3174
[2019-03-26 21:26:13,713] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1244984: learning rate 0.0000
[2019-03-26 21:26:15,411] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1245738: loss -212.3376
[2019-03-26 21:26:15,416] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1245739: learning rate 0.0000
[2019-03-26 21:26:17,458] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4514003e-21 1.0000000e+00 1.7987411e-20 1.0505161e-16 4.3638075e-26], sum to 1.0000
[2019-03-26 21:26:17,465] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7236
[2019-03-26 21:26:17,469] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 65.66666666666667, 1.0, 2.0, 0.3727971163437828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 565719.840333914, 565719.840333914, 171743.2627513431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6898800.0000, 
sim time next is 6899400.0000, 
raw observation next is [26.6, 66.5, 1.0, 2.0, 0.3763526246168568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 569809.6062249024, 569809.606224903, 172061.2672329463], 
processed observation next is [0.0, 0.8695652173913043, 0.4597156398104266, 0.665, 1.0, 1.0, 0.2486176200203094, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.158280446173584, 0.15828044617358417, 0.25680786154171087], 
reward next is 0.7432, 
noisyNet noise sample is [array([1.0585011], dtype=float32), -0.9615205]. 
=============================================
[2019-03-26 21:26:17,851] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1246821: loss -113.8549
[2019-03-26 21:26:17,853] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1246822: learning rate 0.0000
[2019-03-26 21:26:18,545] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8447999e-20 1.0000000e+00 2.2727464e-20 1.0270699e-16 4.3138230e-26], sum to 1.0000
[2019-03-26 21:26:18,552] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4326
[2019-03-26 21:26:18,558] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 85.33333333333333, 1.0, 2.0, 0.4173424736751459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 612707.8473380536, 612707.8473380536, 175442.9996377701], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6933000.0000, 
sim time next is 6933600.0000, 
raw observation next is [24.8, 84.0, 1.0, 2.0, 0.4177037662227866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 612920.5840332492, 612920.5840332485, 175454.1703259616], 
processed observation next is [0.0, 0.2608695652173913, 0.3744075829383887, 0.84, 1.0, 1.0, 0.2984382725575742, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17025571778701365, 0.17025571778701346, 0.26187189600889793], 
reward next is 0.7381, 
noisyNet noise sample is [array([-1.7076232], dtype=float32), -0.41504687]. 
=============================================
[2019-03-26 21:26:19,116] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.4382326e-17 1.0000000e+00 3.6698781e-17 2.8097284e-13 2.7562169e-22], sum to 1.0000
[2019-03-26 21:26:19,127] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9253
[2019-03-26 21:26:19,130] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 62.0, 1.0, 2.0, 0.8260160982199958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1242852.539960537, 1242852.539960537, 262490.9453692936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7315200.0000, 
sim time next is 7315800.0000, 
raw observation next is [27.56666666666667, 62.33333333333334, 1.0, 2.0, 0.8200299170893884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1232831.337199867, 1232831.337199868, 260727.6834157234], 
processed observation next is [1.0, 0.6956521739130435, 0.505529225908373, 0.6233333333333334, 1.0, 1.0, 0.783168574806492, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3424531492221853, 0.34245314922218556, 0.38914579614287076], 
reward next is 0.6109, 
noisyNet noise sample is [array([-0.8937504], dtype=float32), -1.5998232]. 
=============================================
[2019-03-26 21:26:20,737] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.7255750e-20 1.0000000e+00 5.9037871e-20 2.9648594e-16 2.0729251e-25], sum to 1.0000
[2019-03-26 21:26:20,748] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6923
[2019-03-26 21:26:20,756] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.4, 61.0, 1.0, 2.0, 0.4492118888303161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 640416.241973249, 640416.2419732496, 177662.1532866675], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6949200.0000, 
sim time next is 6949800.0000, 
raw observation next is [29.55, 60.5, 1.0, 2.0, 0.4520916020901946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 643256.9570040583, 643256.9570040583, 177918.9500055508], 
processed observation next is [0.0, 0.43478260869565216, 0.5995260663507109, 0.605, 1.0, 1.0, 0.3398694001086682, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17868248805668285, 0.17868248805668285, 0.26555067165007584], 
reward next is 0.7344, 
noisyNet noise sample is [array([-0.02712044], dtype=float32), -0.08348547]. 
=============================================
[2019-03-26 21:26:21,464] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1248436: loss 0.2496
[2019-03-26 21:26:21,466] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1248436: learning rate 0.0000
[2019-03-26 21:26:22,765] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1249019: loss 0.2521
[2019-03-26 21:26:22,767] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1249019: learning rate 0.0000
[2019-03-26 21:26:24,974] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 21:26:24,977] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:26:24,979] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:26:24,979] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:26:24,980] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:26:24,981] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:26:24,980] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:26:24,983] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:26:24,982] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:26:24,985] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:26:24,986] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:26:25,013] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run51
[2019-03-26 21:26:25,034] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run51
[2019-03-26 21:26:25,035] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run51
[2019-03-26 21:26:25,082] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run51
[2019-03-26 21:26:25,103] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run51
[2019-03-26 21:26:26,753] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08648594], dtype=float32), 0.06388707]
[2019-03-26 21:26:26,756] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.26666666666667, 66.66666666666667, 1.0, 2.0, 0.4867018564084808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 680084.278176742, 680084.278176742, 181538.8089606444]
[2019-03-26 21:26:26,758] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:26:26,761] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.0831076e-21 1.0000000e+00 1.3895140e-20 2.0647033e-16 2.3728868e-26], sampled 0.17373490504286326
[2019-03-26 21:26:57,941] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08648594], dtype=float32), 0.06388707]
[2019-03-26 21:26:57,946] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.6, 80.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.002168712470443, 6.9112, 168.9068116577663, 2228224.112181839, 1454281.515446444, 311351.5265186779]
[2019-03-26 21:26:57,947] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:26:57,952] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.3091909e-21 1.0000000e+00 3.7888665e-20 1.5886345e-16 5.0589585e-26], sampled 0.608433638346108
[2019-03-26 21:26:57,953] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2228224.112181839 W.
[2019-03-26 21:27:22,936] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08648594], dtype=float32), 0.06388707]
[2019-03-26 21:27:22,940] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.86666666666667, 72.66666666666667, 1.0, 2.0, 0.522529123667235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730164.085593252, 730164.085593252, 187200.5153881304]
[2019-03-26 21:27:22,940] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:27:22,944] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.0056148e-21 1.0000000e+00 4.2381200e-20 1.1120026e-16 7.6527045e-26], sampled 0.7773929893881799
[2019-03-26 21:27:27,483] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08648594], dtype=float32), 0.06388707]
[2019-03-26 21:27:27,484] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.4, 61.0, 1.0, 2.0, 0.6089570585993511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 850983.8653288301, 850983.8653288301, 202425.2174620699]
[2019-03-26 21:27:27,485] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:27:27,487] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.4052710e-19 1.0000000e+00 5.7999713e-18 1.8615429e-13 5.2362844e-24], sampled 0.9978332908990928
[2019-03-26 21:27:27,843] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08648594], dtype=float32), 0.06388707]
[2019-03-26 21:27:27,845] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.8, 63.0, 1.0, 2.0, 0.5889447034860287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 823006.8690628457, 823006.8690628457, 198704.014391289]
[2019-03-26 21:27:27,846] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:27:27,849] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.3704450e-21 1.0000000e+00 2.2486613e-19 1.1431217e-14 6.3621521e-26], sampled 0.7762801708188957
[2019-03-26 21:27:52,020] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08648594], dtype=float32), 0.06388707]
[2019-03-26 21:27:52,022] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.6, 72.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.118214960345339, 6.9112, 168.9116906292082, 2430675.53121014, 2283813.094072767, 475633.5190509565]
[2019-03-26 21:27:52,023] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:27:52,026] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0464828e-11 9.9999976e-01 2.5037399e-11 2.1575686e-07 6.1031862e-15], sampled 0.7505365524129934
[2019-03-26 21:27:52,029] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2430675.53121014 W.
[2019-03-26 21:28:03,279] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08648594], dtype=float32), 0.06388707]
[2019-03-26 21:28:03,281] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.04457568166667, 92.26723350166668, 1.0, 2.0, 0.7347186287862348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1026813.674416743, 1026813.674416742, 228521.8969302607]
[2019-03-26 21:28:03,285] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:28:03,288] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.3351389e-21 1.0000000e+00 2.4035316e-20 8.4589918e-17 3.2513790e-26], sampled 0.24383679000158198
[2019-03-26 21:28:09,666] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08648594], dtype=float32), 0.06388707]
[2019-03-26 21:28:09,667] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.02918843, 85.682323185, 1.0, 2.0, 0.590287423214074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 824883.9496493955, 824883.9496493955, 198945.2463783477]
[2019-03-26 21:28:09,669] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:28:09,671] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.5636837e-21 1.0000000e+00 1.7851721e-20 1.1299062e-16 2.7303425e-26], sampled 0.29892156153413174
[2019-03-26 21:28:16,924] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08648594], dtype=float32), 0.06388707]
[2019-03-26 21:28:16,925] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.2, 78.0, 1.0, 2.0, 0.6565613067290776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 917536.9088724402, 917536.9088724396, 211752.6326119104]
[2019-03-26 21:28:16,927] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:28:16,930] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.4703408e-21 1.0000000e+00 1.4136919e-19 5.0213985e-15 3.1594693e-26], sampled 0.09278198529576032
[2019-03-26 21:28:20,082] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.4890 2927447532.3156 1338.0000
[2019-03-26 21:28:20,339] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 21:28:20,459] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.2905 3164282758.4253 1776.0000
[2019-03-26 21:28:20,588] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.8679 2779270075.9258 933.0000
[2019-03-26 21:28:20,634] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 21:28:21,652] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1250000, evaluation results [1250000.0, 7882.290494044971, 3164282758.4252844, 1776.0, 8253.48903804385, 2927447532.3155904, 1338.0, 8659.867859783146, 2779270075.9258275, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 21:28:21,795] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1250075: loss -358.9633
[2019-03-26 21:28:21,797] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1250075: learning rate 0.0000
[2019-03-26 21:28:22,495] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1250405: loss 19.5470
[2019-03-26 21:28:22,497] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1250405: learning rate 0.0000
[2019-03-26 21:28:22,510] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1250411: loss -319.0936
[2019-03-26 21:28:22,512] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1250412: learning rate 0.0000
[2019-03-26 21:28:22,624] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1250483: loss -245.7261
[2019-03-26 21:28:22,625] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1250484: loss -173.7180
[2019-03-26 21:28:22,627] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1250485: learning rate 0.0000
[2019-03-26 21:28:22,628] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1250485: learning rate 0.0000
[2019-03-26 21:28:22,847] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1250614: loss -148.0398
[2019-03-26 21:28:22,849] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1250616: learning rate 0.0000
[2019-03-26 21:28:23,204] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1250838: loss -216.5729
[2019-03-26 21:28:23,207] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1250839: learning rate 0.0000
[2019-03-26 21:28:23,239] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1250864: loss -175.3718
[2019-03-26 21:28:23,241] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1250867: learning rate 0.0000
[2019-03-26 21:28:23,249] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1250872: loss -136.3660
[2019-03-26 21:28:23,250] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1250872: learning rate 0.0000
[2019-03-26 21:28:23,333] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1250928: loss -169.2467
[2019-03-26 21:28:23,334] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1250928: learning rate 0.0000
[2019-03-26 21:28:23,913] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1251246: loss -233.3013
[2019-03-26 21:28:23,918] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1251247: learning rate 0.0000
[2019-03-26 21:28:27,441] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1252814: loss -417.9342
[2019-03-26 21:28:27,443] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1252814: learning rate 0.0000
[2019-03-26 21:28:29,578] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1253764: loss 0.2336
[2019-03-26 21:28:29,580] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1253764: learning rate 0.0000
[2019-03-26 21:28:32,142] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1254856: loss 0.2563
[2019-03-26 21:28:32,144] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1254856: learning rate 0.0000
[2019-03-26 21:28:35,037] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1256148: loss -412.1733
[2019-03-26 21:28:35,038] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1256148: learning rate 0.0000
[2019-03-26 21:28:36,273] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1256700: loss -125.0167
[2019-03-26 21:28:36,275] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1256700: learning rate 0.0000
[2019-03-26 21:28:37,647] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.8096254e-21 1.0000000e+00 1.0491889e-19 1.4776956e-15 2.9428394e-25], sum to 1.0000
[2019-03-26 21:28:37,655] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5793
[2019-03-26 21:28:37,659] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.96666666666667, 57.5, 1.0, 2.0, 1.000270505240883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1526743.240083183, 1526743.240083183, 318064.6699848701], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7308600.0000, 
sim time next is 7309200.0000, 
raw observation next is [27.93333333333333, 58.00000000000001, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.964758930878284, 6.9112, 168.9124963630703, 1622594.904888347, 1584598.459476157, 331221.0055080327], 
processed observation next is [1.0, 0.6086956521739131, 0.522906793048973, 0.5800000000000001, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.005355893087828356, 0.0, 0.8294376856181053, 0.45072080691342975, 0.44016623874337696, 0.49435970971348164], 
reward next is 0.2378, 
noisyNet noise sample is [array([1.1988012], dtype=float32), 1.1601605]. 
=============================================
[2019-03-26 21:28:39,242] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1258015: loss 0.2168
[2019-03-26 21:28:39,248] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1258017: learning rate 0.0000
[2019-03-26 21:28:40,147] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1258424: loss 0.2188
[2019-03-26 21:28:40,151] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1258426: learning rate 0.0000
[2019-03-26 21:28:40,170] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1258433: loss 0.1965
[2019-03-26 21:28:40,172] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1258434: learning rate 0.0000
[2019-03-26 21:28:40,182] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1258438: loss 0.2174
[2019-03-26 21:28:40,187] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1258438: learning rate 0.0000
[2019-03-26 21:28:40,323] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1258502: loss 0.2088
[2019-03-26 21:28:40,324] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1258502: learning rate 0.0000
[2019-03-26 21:28:40,442] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1258549: loss 0.2092
[2019-03-26 21:28:40,444] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1258549: learning rate 0.0000
[2019-03-26 21:28:41,204] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1258887: loss 0.2087
[2019-03-26 21:28:41,209] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1258889: learning rate 0.0000
[2019-03-26 21:28:41,212] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1258892: loss 0.2067
[2019-03-26 21:28:41,216] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1258894: learning rate 0.0000
[2019-03-26 21:28:41,330] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1258948: loss 0.1925
[2019-03-26 21:28:41,333] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1258949: learning rate 0.0000
[2019-03-26 21:28:41,373] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1258963: loss 0.2115
[2019-03-26 21:28:41,374] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1258963: learning rate 0.0000
[2019-03-26 21:28:42,140] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1259306: loss 0.1929
[2019-03-26 21:28:42,142] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1259307: learning rate 0.0000
[2019-03-26 21:28:43,378] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.0782621e-21 1.0000000e+00 5.1848941e-20 6.1773181e-16 1.2671489e-25], sum to 1.0000
[2019-03-26 21:28:43,386] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4149
[2019-03-26 21:28:43,392] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.96666666666667, 92.0, 1.0, 2.0, 0.6419716570852705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1021055.069585225, 1021055.069585225, 223176.3890289467], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7392000.0000, 
sim time next is 7392600.0000, 
raw observation next is [20.95, 92.0, 1.0, 2.0, 0.6429167467192056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1022892.708885162, 1022892.708885162, 223417.3396784005], 
processed observation next is [1.0, 0.5652173913043478, 0.19194312796208532, 0.92, 1.0, 1.0, 0.5697792129147056, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2841368635792117, 0.2841368635792117, 0.33345871593791115], 
reward next is 0.6665, 
noisyNet noise sample is [array([0.09412554], dtype=float32), -1.6988257]. 
=============================================
[2019-03-26 21:28:46,868] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.934040e-21 1.000000e+00 8.595270e-20 5.989817e-17 2.941682e-26], sum to 1.0000
[2019-03-26 21:28:46,875] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6176
[2019-03-26 21:28:46,879] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.36666666666667, 95.0, 1.0, 2.0, 0.3275686066064395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 511935.0396896502, 511935.0396896502, 167793.3385526447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7453200.0000, 
sim time next is 7453800.0000, 
raw observation next is [21.4, 95.0, 1.0, 2.0, 0.3283968108683529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 512782.1031462479, 512782.1031462479, 167846.8008654031], 
processed observation next is [0.0, 0.2608695652173913, 0.21327014218009477, 0.95, 1.0, 1.0, 0.1908395311666902, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14243947309617996, 0.14243947309617996, 0.2505176132319449], 
reward next is 0.7495, 
noisyNet noise sample is [array([-0.81154436], dtype=float32), 0.3129102]. 
=============================================
[2019-03-26 21:28:47,190] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:28:47,191] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:28:47,234] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1261557: loss -277.2499
[2019-03-26 21:28:47,238] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1261557: learning rate 0.0000
[2019-03-26 21:28:47,253] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run7
[2019-03-26 21:28:49,485] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1262686: loss -353.7505
[2019-03-26 21:28:49,490] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1262687: learning rate 0.0000
[2019-03-26 21:28:51,053] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.8257199e-21 1.0000000e+00 3.3179458e-20 4.7729857e-17 2.6393422e-26], sum to 1.0000
[2019-03-26 21:28:51,064] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9211
[2019-03-26 21:28:51,073] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.36666666666667, 92.33333333333333, 1.0, 2.0, 0.3984910285097117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 590974.3716383805, 590974.3716383805, 173596.6020012604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7526400.0000, 
sim time next is 7527000.0000, 
raw observation next is [23.33333333333333, 92.16666666666667, 1.0, 2.0, 0.3961341364923872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 588624.7158582052, 588624.7158582046, 173415.9105777418], 
processed observation next is [0.0, 0.08695652173913043, 0.30489731437598716, 0.9216666666666667, 1.0, 1.0, 0.27245076685829783, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1635068655161681, 0.16350686551616794, 0.25882971728021165], 
reward next is 0.7412, 
noisyNet noise sample is [array([-0.6147398], dtype=float32), -0.8609969]. 
=============================================
[2019-03-26 21:28:51,104] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[75.68044 ]
 [75.614136]
 [75.507355]
 [75.37582 ]
 [75.22286 ]], R is [[75.75268555]
 [75.7360611 ]
 [75.71914673]
 [75.70196533]
 [75.68463898]].
[2019-03-26 21:28:54,249] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:28:54,249] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:28:54,310] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run7
[2019-03-26 21:28:54,930] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1981709e-20 1.0000000e+00 2.3049995e-20 1.1563792e-16 2.2035711e-26], sum to 1.0000
[2019-03-26 21:28:54,935] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5944
[2019-03-26 21:28:54,940] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 86.0, 1.0, 2.0, 0.9297888318773552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1306386.105237717, 1306386.105237716, 279286.7140862102], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7633800.0000, 
sim time next is 7634400.0000, 
raw observation next is [25.86666666666667, 84.33333333333334, 1.0, 2.0, 1.020149849039546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1431354.713377931, 1431354.71337793, 305976.8251228392], 
processed observation next is [1.0, 0.34782608695652173, 0.42496050552922615, 0.8433333333333334, 1.0, 1.0, 1.0242769265536698, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3975985314938697, 0.3975985314938694, 0.45668182854155104], 
reward next is 0.5433, 
noisyNet noise sample is [array([-1.7582473], dtype=float32), -1.2566968]. 
=============================================
[2019-03-26 21:28:55,216] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:28:55,217] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:28:55,278] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run7
[2019-03-26 21:28:55,912] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.0542932e-21 1.0000000e+00 5.7057555e-20 1.0089197e-16 1.2849646e-25], sum to 1.0000
[2019-03-26 21:28:55,918] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1265729: loss -466.9236
[2019-03-26 21:28:55,920] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2728
[2019-03-26 21:28:55,921] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1265729: learning rate 0.0000
[2019-03-26 21:28:55,928] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.61666666666667, 94.16666666666667, 1.0, 2.0, 0.4206526883465597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 613550.8751311552, 613550.8751311547, 175408.2829786099], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7624200.0000, 
sim time next is 7624800.0000, 
raw observation next is [23.7, 94.0, 1.0, 2.0, 0.424038380884282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 616986.5242341505, 616986.52423415, 175694.964490759], 
processed observation next is [1.0, 0.2608695652173913, 0.3222748815165877, 0.94, 1.0, 1.0, 0.3060703384147976, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17138514562059737, 0.1713851456205972, 0.2622312902847149], 
reward next is 0.7378, 
noisyNet noise sample is [array([-0.49373084], dtype=float32), 0.70228386]. 
=============================================
[2019-03-26 21:28:56,574] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1266086: loss -317.1784
[2019-03-26 21:28:56,578] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1266086: learning rate 0.0000
[2019-03-26 21:28:56,733] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1266159: loss -297.9633
[2019-03-26 21:28:56,734] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1266159: learning rate 0.0000
[2019-03-26 21:28:56,761] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1266168: loss -93.5624
[2019-03-26 21:28:56,763] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1266168: learning rate 0.0000
[2019-03-26 21:28:56,799] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1266183: loss -264.2244
[2019-03-26 21:28:56,805] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1266186: learning rate 0.0000
[2019-03-26 21:28:56,932] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1266244: loss -433.2254
[2019-03-26 21:28:56,935] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1266244: learning rate 0.0000
[2019-03-26 21:28:57,004] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.2333688e-11 9.9999321e-01 2.6565428e-10 6.8258764e-06 1.1605757e-13], sum to 1.0000
[2019-03-26 21:28:57,013] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0815
[2019-03-26 21:28:57,020] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1886183.747199874 W.
[2019-03-26 21:28:57,024] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.23333333333333, 71.0, 1.0, 2.0, 0.7078999992611321, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.976167691954519, 6.9112, 168.9125174233428, 1886183.747199874, 1840093.550323142, 387408.6972833925], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7662000.0000, 
sim time next is 7662600.0000, 
raw observation next is [29.1, 72.0, 1.0, 2.0, 0.6472231837616804, 1.0, 1.0, 0.6472231837616804, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1809718.924389934, 1809718.924389934, 352344.3597162862], 
processed observation next is [1.0, 0.6956521739130435, 0.5781990521327015, 0.72, 1.0, 1.0, 0.574967691279133, 1.0, 0.5, 0.574967691279133, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5026997012194261, 0.5026997012194261, 0.5258871040541585], 
reward next is 0.4741, 
noisyNet noise sample is [array([0.38587478], dtype=float32), -0.9151017]. 
=============================================
[2019-03-26 21:28:57,626] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1266551: loss -390.9491
[2019-03-26 21:28:57,627] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1266552: loss -361.8381
[2019-03-26 21:28:57,631] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1266552: learning rate 0.0000
[2019-03-26 21:28:57,633] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1266552: learning rate 0.0000
[2019-03-26 21:28:57,857] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1266654: loss -394.3419
[2019-03-26 21:28:57,858] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1266654: learning rate 0.0000
[2019-03-26 21:28:57,917] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1266679: loss -477.2451
[2019-03-26 21:28:57,918] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1266679: learning rate 0.0000
[2019-03-26 21:28:58,494] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1266935: loss -557.6746
[2019-03-26 21:28:58,498] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1266935: learning rate 0.0000
[2019-03-26 21:29:01,636] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.8347101e-22 1.0000000e+00 1.0610898e-21 7.9761246e-18 8.5134963e-27], sum to 1.0000
[2019-03-26 21:29:01,643] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3792
[2019-03-26 21:29:01,652] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 89.0, 1.0, 2.0, 0.2975081561231734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 475638.0772194005, 475638.0772194005, 165336.4330564601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 244800.0000, 
sim time next is 245400.0000, 
raw observation next is [21.06666666666667, 89.16666666666667, 1.0, 2.0, 0.2971860017110175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 475310.4594983634, 475310.4594983628, 165315.2776146498], 
processed observation next is [0.0, 0.8695652173913043, 0.19747235387045833, 0.8916666666666667, 1.0, 1.0, 0.1532361466397801, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13203068319398983, 0.13203068319398967, 0.24673922032037282], 
reward next is 0.7533, 
noisyNet noise sample is [array([1.3380648], dtype=float32), -0.16048622]. 
=============================================
[2019-03-26 21:29:01,924] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.3620730e-20 1.0000000e+00 3.6672853e-19 2.1402382e-16 3.6543966e-26], sum to 1.0000
[2019-03-26 21:29:01,930] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4854
[2019-03-26 21:29:01,935] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.95, 89.5, 1.0, 2.0, 0.5670199560653355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 792357.2206313496, 792357.2206313496, 194757.8761450187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7713000.0000, 
sim time next is 7713600.0000, 
raw observation next is [26.1, 89.0, 1.0, 2.0, 0.5906521114172282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 825393.7730333562, 825393.7730333562, 199011.0620205457], 
processed observation next is [1.0, 0.2608695652173913, 0.4360189573459717, 0.89, 1.0, 1.0, 0.5068097727918411, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22927604806482116, 0.22927604806482116, 0.2970314358515608], 
reward next is 0.7030, 
noisyNet noise sample is [array([0.06119556], dtype=float32), 1.577503]. 
=============================================
[2019-03-26 21:29:04,734] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3661855e-21 1.0000000e+00 9.9163698e-20 9.2972983e-17 1.5442031e-25], sum to 1.0000
[2019-03-26 21:29:04,742] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4041
[2019-03-26 21:29:04,746] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.25, 86.0, 1.0, 2.0, 0.7689883759087291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1074731.952577922, 1074731.952577922, 236438.2149592526], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7785000.0000, 
sim time next is 7785600.0000, 
raw observation next is [26.2, 86.33333333333334, 1.0, 2.0, 0.7306928848008548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1021184.748826417, 1021184.748826418, 227606.9774991266], 
processed observation next is [1.0, 0.08695652173913043, 0.44075829383886256, 0.8633333333333334, 1.0, 1.0, 0.6755335961456082, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2836624302295603, 0.28366243022956056, 0.3397119067151143], 
reward next is 0.6603, 
noisyNet noise sample is [array([0.599056], dtype=float32), -0.30967113]. 
=============================================
[2019-03-26 21:29:05,229] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:05,230] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:05,317] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run7
[2019-03-26 21:29:07,196] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:07,197] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:07,254] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run7
[2019-03-26 21:29:10,529] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.9755187e-21 1.0000000e+00 3.0884449e-20 1.6374687e-17 2.8672530e-26], sum to 1.0000
[2019-03-26 21:29:10,543] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6217
[2019-03-26 21:29:10,547] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.03333333333333, 83.33333333333334, 1.0, 2.0, 0.2963295790978868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 471918.240543293, 471918.2405432923, 165048.3676505503], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 289200.0000, 
sim time next is 289800.0000, 
raw observation next is [22.1, 83.0, 1.0, 2.0, 0.2966076757588989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 472137.6107390649, 472137.6107390655, 165060.0192987906], 
processed observation next is [0.0, 0.34782608695652173, 0.24644549763033188, 0.83, 1.0, 1.0, 0.15253936838421553, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13114933631640693, 0.13114933631640707, 0.24635823775938898], 
reward next is 0.7536, 
noisyNet noise sample is [array([0.09433413], dtype=float32), -1.8061823]. 
=============================================
[2019-03-26 21:29:12,847] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.1302936e-21 1.0000000e+00 9.4644681e-20 8.6958096e-16 1.1435252e-25], sum to 1.0000
[2019-03-26 21:29:12,856] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9455
[2019-03-26 21:29:12,859] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.06666666666666, 87.0, 1.0, 2.0, 0.5281639946045908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738040.7943496994, 738040.7943496994, 188126.4933777913], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7940400.0000, 
sim time next is 7941000.0000, 
raw observation next is [26.98333333333333, 87.5, 1.0, 2.0, 0.5277780746609507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 737501.3339908647, 737501.3339908654, 188062.8238960693], 
processed observation next is [1.0, 0.9130434782608695, 0.4778830963665086, 0.875, 1.0, 1.0, 0.4310579212782539, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20486148166412907, 0.20486148166412926, 0.2806907819344318], 
reward next is 0.7193, 
noisyNet noise sample is [array([-0.38041598], dtype=float32), 0.6992662]. 
=============================================
[2019-03-26 21:29:12,867] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[72.95212 ]
 [72.675316]
 [73.171616]
 [73.38717 ]
 [73.64855 ]], R is [[72.73819733]
 [72.73003387]
 [72.72224426]
 [72.71460724]
 [72.70667267]].
[2019-03-26 21:29:13,426] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1316029e-21 1.0000000e+00 3.0464028e-20 3.0034497e-16 3.3531559e-26], sum to 1.0000
[2019-03-26 21:29:13,434] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6838
[2019-03-26 21:29:13,439] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 89.5, 1.0, 2.0, 0.5296601283048128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740132.1758280952, 740132.1758280959, 188373.6006343171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7943400.0000, 
sim time next is 7944000.0000, 
raw observation next is [26.63333333333333, 90.0, 1.0, 2.0, 0.528340222514659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738287.1356138209, 738287.1356138209, 188155.5502397603], 
processed observation next is [1.0, 0.9565217391304348, 0.46129541864139006, 0.9, 1.0, 1.0, 0.43173520784898667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20507975989272803, 0.20507975989272803, 0.2808291794623288], 
reward next is 0.7192, 
noisyNet noise sample is [array([-1.9409417], dtype=float32), 0.67960477]. 
=============================================
[2019-03-26 21:29:13,446] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[72.85538 ]
 [72.80806 ]
 [72.75723 ]
 [72.442696]
 [72.81244 ]], R is [[72.8993988 ]
 [72.88925171]
 [72.87921906]
 [72.86982727]
 [72.86076355]].
[2019-03-26 21:29:13,542] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:13,543] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:13,602] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run7
[2019-03-26 21:29:14,302] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:14,303] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:14,363] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run7
[2019-03-26 21:29:14,539] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:14,539] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:14,552] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:14,553] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:14,590] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run7
[2019-03-26 21:29:14,628] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run7
[2019-03-26 21:29:14,698] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:14,699] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:14,744] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run7
[2019-03-26 21:29:14,779] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:14,779] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:14,820] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run7
[2019-03-26 21:29:15,011] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:15,011] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:15,036] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run7
[2019-03-26 21:29:15,133] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:15,134] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:15,138] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:15,140] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:15,158] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run7
[2019-03-26 21:29:15,191] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run7
[2019-03-26 21:29:15,208] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:15,209] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:15,214] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run7
[2019-03-26 21:29:15,396] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:15,396] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:15,405] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run7
[2019-03-26 21:29:15,800] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 21:29:15,802] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:29:15,802] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:15,803] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:29:15,804] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:15,804] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:29:15,805] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:15,809] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run52
[2019-03-26 21:29:15,833] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run52
[2019-03-26 21:29:15,853] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:29:15,853] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run52
[2019-03-26 21:29:15,887] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:15,891] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run52
[2019-03-26 21:29:15,966] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:29:15,966] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:15,982] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run52
[2019-03-26 21:30:18,643] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08788411], dtype=float32), 0.06503229]
[2019-03-26 21:30:18,644] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [36.06126448666667, 45.52305199666667, 1.0, 2.0, 0.5735379794390227, 0.0, 2.0, 0.0, 1.0, 2.0, 0.986730187661172, 6.911200000000001, 6.9112, 168.912887357429, 1603543.181827596, 1603543.181827595, 348953.006932994]
[2019-03-26 21:30:18,645] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:30:18,649] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5890659e-11 9.9999809e-01 6.2966604e-11 1.8751178e-06 4.9839283e-15], sampled 0.5318292385052036
[2019-03-26 21:30:35,069] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08788411], dtype=float32), 0.06503229]
[2019-03-26 21:30:35,072] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.66353907666667, 86.2391336, 1.0, 2.0, 0.9467613730549543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1323340.890862259, 1323340.890862259, 283133.1456735725]
[2019-03-26 21:30:35,073] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:30:35,075] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5329609e-21 1.0000000e+00 9.1659270e-21 8.8604503e-17 7.3921968e-27], sampled 0.6989441226715484
[2019-03-26 21:30:36,384] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08788411], dtype=float32), 0.06503229]
[2019-03-26 21:30:36,385] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.04935265333333, 82.66651133333333, 1.0, 2.0, 0.5207678534935817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 727702.1046817146, 727702.1046817146, 186912.9017703226]
[2019-03-26 21:30:36,386] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:30:36,389] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.0598038e-22 1.0000000e+00 2.2363405e-21 2.5840919e-17 2.1089830e-27], sampled 0.03684434337811837
[2019-03-26 21:30:37,311] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08788411], dtype=float32), 0.06503229]
[2019-03-26 21:30:37,313] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.86905448666667, 59.10317726833333, 1.0, 2.0, 0.8874287573245148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1240359.957744914, 1240359.957744914, 266500.1977003572]
[2019-03-26 21:30:37,315] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:30:37,317] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.4088674e-21 1.0000000e+00 2.0567594e-20 1.2155186e-16 3.3250059e-26], sampled 0.07161568916237437
[2019-03-26 21:31:02,469] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08788411], dtype=float32), 0.06503229]
[2019-03-26 21:31:02,470] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.85683427, 69.569237195, 1.0, 2.0, 0.4222274299614619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 619669.4204588145, 619669.4204588139, 176101.7698827869]
[2019-03-26 21:31:02,472] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:31:02,478] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.8394388e-21 1.0000000e+00 3.5462050e-20 1.1498119e-16 6.8915764e-26], sampled 0.5836861485009444
[2019-03-26 21:31:10,928] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3694 2779190338.1949 933.0000
[2019-03-26 21:31:11,046] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.1321 2842434697.4997 1131.0000
[2019-03-26 21:31:11,121] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5735 3007648438.5815 1766.0000
[2019-03-26 21:31:11,182] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.0192 3164167292.2096 1778.0000
[2019-03-26 21:31:11,240] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1249 2927277438.0038 1338.0000
[2019-03-26 21:31:12,255] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1275000, evaluation results [1275000.0, 7884.019182849356, 3164167292.2095833, 1778.0, 8255.124881931173, 2927277438.00382, 1338.0, 8661.369356548688, 2779190338.194891, 933.0, 7997.573465804901, 3007648438.5815053, 1766.0, 8496.132106361554, 2842434697.4996533, 1131.0]
[2019-03-26 21:31:13,711] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4081905e-20 1.0000000e+00 1.0993728e-19 7.7449563e-17 2.1205050e-25], sum to 1.0000
[2019-03-26 21:31:13,729] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3481
[2019-03-26 21:31:13,733] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.3, 84.0, 1.0, 2.0, 0.3294673707365959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 520693.2050942397, 520693.2050942397, 168598.3714326102], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 28800.0000, 
sim time next is 29400.0000, 
raw observation next is [22.51666666666667, 83.0, 1.0, 2.0, 0.3567915519874122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 562941.8508880638, 562941.8508880638, 171995.7415537664], 
processed observation next is [1.0, 0.34782608695652173, 0.2661927330173777, 0.83, 1.0, 1.0, 0.22505006263543637, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1563727363577955, 0.1563727363577955, 0.25671006202054686], 
reward next is 0.7433, 
noisyNet noise sample is [array([0.7716933], dtype=float32), 1.0136361]. 
=============================================
[2019-03-26 21:31:20,599] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0552839e-21 1.0000000e+00 9.7067011e-21 5.8244520e-17 2.6241726e-26], sum to 1.0000
[2019-03-26 21:31:20,612] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0086
[2019-03-26 21:31:20,619] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.61666666666667, 96.0, 1.0, 2.0, 0.7387576761770659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1107018.206574379, 1107018.206574378, 239246.3671416086], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 143400.0000, 
sim time next is 144000.0000, 
raw observation next is [22.6, 96.0, 1.0, 2.0, 0.7789358315697448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1167888.554337311, 1167888.554337311, 249431.4727295514], 
processed observation next is [1.0, 0.6956521739130435, 0.27014218009478685, 0.96, 1.0, 1.0, 0.7336576283972829, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.32441348731591974, 0.32441348731591974, 0.3722857801933603], 
reward next is 0.6277, 
noisyNet noise sample is [array([0.12963986], dtype=float32), -0.6374442]. 
=============================================
[2019-03-26 21:31:20,632] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[73.56706 ]
 [73.63834 ]
 [73.650024]
 [73.66855 ]
 [73.61947 ]], R is [[73.4826355 ]
 [73.39072418]
 [73.30191803]
 [73.21971893]
 [73.13638306]].
[2019-03-26 21:31:23,240] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4129518e-21 1.0000000e+00 2.8124797e-20 2.9407739e-18 3.3608506e-27], sum to 1.0000
[2019-03-26 21:31:23,248] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4066
[2019-03-26 21:31:23,253] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 96.0, 1.0, 2.0, 0.2860759064107357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 460796.9032282293, 460796.9032282293, 164327.4826521666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 186000.0000, 
sim time next is 186600.0000, 
raw observation next is [19.9, 96.0, 1.0, 2.0, 0.286127378626733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 460879.9610897925, 460879.9610897932, 164333.1420590986], 
processed observation next is [0.0, 0.13043478260869565, 0.14218009478672985, 0.96, 1.0, 1.0, 0.1399125043695578, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12802221141383124, 0.12802221141383144, 0.2452733463568636], 
reward next is 0.7547, 
noisyNet noise sample is [array([2.236741], dtype=float32), 0.22945686]. 
=============================================
[2019-03-26 21:31:28,302] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6550226e-20 1.0000000e+00 4.4152957e-19 9.2640549e-17 2.8241802e-25], sum to 1.0000
[2019-03-26 21:31:28,309] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7340
[2019-03-26 21:31:28,314] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.3, 68.5, 1.0, 2.0, 0.4605003215267129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 755739.554287621, 755739.5542876205, 188959.1340844114], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 469800.0000, 
sim time next is 470400.0000, 
raw observation next is [22.43333333333333, 67.66666666666667, 1.0, 2.0, 0.4671205029577186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 766549.5944158662, 766549.5944158655, 190072.9993363132], 
processed observation next is [1.0, 0.43478260869565216, 0.2622432859399683, 0.6766666666666667, 1.0, 1.0, 0.35797650958761285, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21293044289329616, 0.21293044289329596, 0.2836910437855421], 
reward next is 0.7163, 
noisyNet noise sample is [array([0.8932592], dtype=float32), 0.8757659]. 
=============================================
[2019-03-26 21:31:34,835] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4487017e-20 1.0000000e+00 5.6069132e-20 1.5068801e-16 6.0176393e-26], sum to 1.0000
[2019-03-26 21:31:34,847] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5745
[2019-03-26 21:31:34,855] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 85.66666666666667, 1.0, 2.0, 0.2425464766337609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 399465.4648517597, 399465.4648517604, 160169.9418480094], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 433200.0000, 
sim time next is 433800.0000, 
raw observation next is [19.65, 85.5, 1.0, 2.0, 0.2416396750564468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 398145.4098398074, 398145.4098398067, 160078.15637442], 
processed observation next is [1.0, 0.0, 0.13033175355450236, 0.855, 1.0, 1.0, 0.0863128615137913, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11059594717772428, 0.11059594717772409, 0.23892262145435822], 
reward next is 0.7611, 
noisyNet noise sample is [array([-0.12037892], dtype=float32), 1.4494618]. 
=============================================
[2019-03-26 21:31:37,923] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.4755826e-22 1.0000000e+00 3.8989643e-21 1.3269988e-17 2.2778854e-27], sum to 1.0000
[2019-03-26 21:31:37,931] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4784
[2019-03-26 21:31:37,937] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.56666666666667, 89.0, 1.0, 2.0, 0.3091973448710491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 489324.0105647654, 489324.0105647654, 166242.3931793907], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 861000.0000, 
sim time next is 861600.0000, 
raw observation next is [21.53333333333333, 89.0, 1.0, 2.0, 0.3091584772471531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 489622.0235564462, 489622.0235564456, 166271.5381219746], 
processed observation next is [0.0, 1.0, 0.21958925750394942, 0.89, 1.0, 1.0, 0.16766081596042542, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13600611765456838, 0.13600611765456821, 0.2481664748089173], 
reward next is 0.7518, 
noisyNet noise sample is [array([-1.8895836], dtype=float32), -0.66020215]. 
=============================================
[2019-03-26 21:31:41,065] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.8977864e-21 1.0000000e+00 2.3193411e-20 5.4878289e-17 6.4222836e-26], sum to 1.0000
[2019-03-26 21:31:41,071] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9481
[2019-03-26 21:31:41,082] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.15, 53.0, 1.0, 2.0, 0.5912178189896552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 967586.2510941398, 967586.2510941398, 213693.0376814211], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 485400.0000, 
sim time next is 486000.0000, 
raw observation next is [25.1, 53.0, 1.0, 2.0, 0.580819256691232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 951152.6045233355, 951152.6045233348, 211520.7097591924], 
processed observation next is [1.0, 0.6521739130434783, 0.38862559241706174, 0.53, 1.0, 1.0, 0.4949629598689542, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.26420905681203766, 0.26420905681203743, 0.3157025518793916], 
reward next is 0.6843, 
noisyNet noise sample is [array([-0.69742125], dtype=float32), 0.3306481]. 
=============================================
[2019-03-26 21:31:41,101] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[72.32659 ]
 [72.36243 ]
 [72.374344]
 [72.45465 ]
 [72.477165]], R is [[72.30708313]
 [72.26506805]
 [72.2205658 ]
 [72.16687775]
 [72.11756134]].
[2019-03-26 21:31:52,600] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.1324873e-21 1.0000000e+00 1.8275412e-20 3.1405460e-17 2.3468885e-26], sum to 1.0000
[2019-03-26 21:31:52,610] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4064
[2019-03-26 21:31:52,618] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 78.33333333333333, 1.0, 2.0, 0.2456158105228543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 405761.9823307951, 405761.9823307945, 160415.6371487835], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 679200.0000, 
sim time next is 679800.0000, 
raw observation next is [20.21666666666667, 79.16666666666667, 1.0, 2.0, 0.2448214115971884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 404476.7633929561, 404476.7633929567, 160337.0956815377], 
processed observation next is [1.0, 0.8695652173913043, 0.15718799368088482, 0.7916666666666667, 1.0, 1.0, 0.0901462790327571, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11235465649804337, 0.11235465649804352, 0.2393090980321458], 
reward next is 0.7607, 
noisyNet noise sample is [array([-1.0955143], dtype=float32), -0.8193315]. 
=============================================
[2019-03-26 21:31:59,250] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.7850661e-22 1.0000000e+00 3.7986331e-21 3.9255047e-18 5.4453023e-27], sum to 1.0000
[2019-03-26 21:31:59,262] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8830
[2019-03-26 21:31:59,267] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 93.0, 1.0, 2.0, 0.2614158155734548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 427152.6805199397, 427152.6805199391, 162031.5824299034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 793800.0000, 
sim time next is 794400.0000, 
raw observation next is [19.4, 93.0, 1.0, 2.0, 0.2612251365279191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 426841.1356951171, 426841.1356951177, 162012.107858232], 
processed observation next is [0.0, 0.17391304347826086, 0.11848341232227487, 0.93, 1.0, 1.0, 0.10990980304568568, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11856698213753253, 0.1185669821375327, 0.2418091162063164], 
reward next is 0.7582, 
noisyNet noise sample is [array([-0.5971836], dtype=float32), -0.40077654]. 
=============================================
[2019-03-26 21:32:07,883] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 21:32:07,884] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:32:07,885] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:32:07,886] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:32:07,888] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:32:07,889] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:32:07,891] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:32:07,890] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:32:07,893] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:32:07,894] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:32:07,896] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:32:07,916] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run53
[2019-03-26 21:32:07,937] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run53
[2019-03-26 21:32:07,960] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run53
[2019-03-26 21:32:07,961] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run53
[2019-03-26 21:32:07,997] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run53
[2019-03-26 21:32:16,097] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0901381], dtype=float32), 0.06715797]
[2019-03-26 21:32:16,099] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.68683525, 52.69275473, 1.0, 2.0, 0.4560649435929559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 734442.6030743744, 734442.6030743744, 187665.7028377665]
[2019-03-26 21:32:16,100] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:32:16,103] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.2799961e-21 1.0000000e+00 1.7331878e-20 2.4343176e-17 2.9944081e-26], sampled 0.6602852113815284
[2019-03-26 21:32:56,381] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0901381], dtype=float32), 0.06715797]
[2019-03-26 21:32:56,383] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.0, 84.0, 1.0, 2.0, 0.4776390051154442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 667542.1365439373, 667542.1365439373, 180182.5460899989]
[2019-03-26 21:32:56,385] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:32:56,387] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.5028527e-22 1.0000000e+00 2.3214024e-21 1.1346915e-17 2.8437014e-27], sampled 0.9435369421507791
[2019-03-26 21:33:27,359] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0901381], dtype=float32), 0.06715797]
[2019-03-26 21:33:27,361] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [33.64856362, 63.69352908, 1.0, 2.0, 0.9866511905373005, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9129565059739, 1379133.317707846, 1379133.317707847, 294891.0746613542]
[2019-03-26 21:33:27,364] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:33:27,366] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.3526260e-17 1.0000000e+00 2.7447676e-16 1.5390125e-11 1.0794371e-21], sampled 0.9518028723374465
[2019-03-26 21:33:28,085] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0901381], dtype=float32), 0.06715797]
[2019-03-26 21:33:28,086] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.46666666666667, 75.33333333333334, 1.0, 2.0, 0.5556369824682177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 776444.7685845308, 776444.7685845308, 192771.7029487066]
[2019-03-26 21:33:28,087] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:33:28,092] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.5103643e-23 1.0000000e+00 4.1098855e-22 4.6388752e-18 3.1439807e-28], sampled 0.9376725575340955
[2019-03-26 21:33:47,720] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0901381], dtype=float32), 0.06715797]
[2019-03-26 21:33:47,721] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.58409433, 59.72631165, 1.0, 2.0, 0.4202265238787661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 619858.8363460053, 619858.8363460053, 176204.4519318843]
[2019-03-26 21:33:47,722] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:33:47,724] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.5750715e-22 1.0000000e+00 2.0751128e-21 8.1740615e-18 2.7446790e-27], sampled 0.8413476938778428
[2019-03-26 21:33:47,867] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0901381], dtype=float32), 0.06715797]
[2019-03-26 21:33:47,868] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.0, 52.0, 1.0, 2.0, 0.4749011103075036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 663589.5628702575, 663589.5628702568, 179757.0766193429]
[2019-03-26 21:33:47,870] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:33:47,873] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.9736335e-22 1.0000000e+00 2.9033945e-21 9.4795808e-18 3.9991862e-27], sampled 0.06365252836778468
[2019-03-26 21:33:54,781] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0901381], dtype=float32), 0.06715797]
[2019-03-26 21:33:54,782] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.074196705, 86.28207691, 1.0, 2.0, 0.3661620589985237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 561758.9467176615, 561758.9467176622, 171579.4099537619]
[2019-03-26 21:33:54,783] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:33:54,786] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.531864e-22 1.000000e+00 2.766077e-21 4.539582e-18 2.419991e-27], sampled 0.47827212583512957
[2019-03-26 21:33:59,458] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7885.4542 3163966814.6649 1776.0000
[2019-03-26 21:33:59,914] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.4906 2927457840.3776 1338.0000
[2019-03-26 21:33:59,937] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8656.2704 2779489215.6768 933.0000
[2019-03-26 21:33:59,959] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 21:33:59,970] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0947 2842476605.5833 1131.0000
[2019-03-26 21:34:00,986] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1300000, evaluation results [1300000.0, 7885.45417667598, 3163966814.6649485, 1776.0, 8253.490594747309, 2927457840.3775544, 1338.0, 8656.27039530621, 2779489215.676816, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8496.094724748822, 2842476605.583347, 1131.0]
[2019-03-26 21:34:06,123] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8968574e-21 1.0000000e+00 4.7454735e-20 2.4795761e-17 1.0284565e-26], sum to 1.0000
[2019-03-26 21:34:06,135] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5867
[2019-03-26 21:34:06,142] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 97.0, 1.0, 2.0, 0.3607928405584966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 551556.2841985874, 551556.2841985868, 170654.4179159135], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1029600.0000, 
sim time next is 1030200.0000, 
raw observation next is [21.91666666666667, 97.16666666666667, 1.0, 2.0, 0.3622591237435236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 553264.9287388698, 553264.9287388698, 170782.7768147032], 
processed observation next is [1.0, 0.9565217391304348, 0.23775671406003188, 0.9716666666666667, 1.0, 1.0, 0.231637498486173, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15368470242746385, 0.15368470242746385, 0.2548996668876167], 
reward next is 0.7451, 
noisyNet noise sample is [array([-0.24521168], dtype=float32), 0.97219133]. 
=============================================
[2019-03-26 21:34:14,231] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.2303208e-21 1.0000000e+00 4.5917397e-20 1.4563511e-16 6.8947848e-26], sum to 1.0000
[2019-03-26 21:34:14,241] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1273
[2019-03-26 21:34:14,245] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 85.0, 1.0, 2.0, 0.7575287462398848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1135957.378612038, 1135957.378612038, 244002.6636194027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1603200.0000, 
sim time next is 1603800.0000, 
raw observation next is [24.05, 85.0, 1.0, 2.0, 0.7897740726728175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1183587.757241845, 1183587.757241845, 252176.5898389725], 
processed observation next is [1.0, 0.5652173913043478, 0.3388625592417062, 0.85, 1.0, 1.0, 0.7467157502082139, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3287743770116236, 0.3287743770116236, 0.3763829699089142], 
reward next is 0.6236, 
noisyNet noise sample is [array([1.5236118], dtype=float32), 0.09409756]. 
=============================================
[2019-03-26 21:34:16,388] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.3618015e-22 1.0000000e+00 2.5038567e-21 6.3488436e-18 5.9779856e-27], sum to 1.0000
[2019-03-26 21:34:16,396] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0794
[2019-03-26 21:34:16,404] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 70.0, 1.0, 2.0, 0.4530481645940554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 639946.9700882114, 639946.9700882114, 177459.5854733691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1440000.0000, 
sim time next is 1440600.0000, 
raw observation next is [27.93333333333334, 69.83333333333334, 1.0, 2.0, 0.4519402142382168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 639298.9911641382, 639298.9911641382, 177417.5316918393], 
processed observation next is [0.0, 0.6956521739130435, 0.5229067930489735, 0.6983333333333335, 1.0, 1.0, 0.3396870051062853, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1775830531011495, 0.1775830531011495, 0.26480228610722284], 
reward next is 0.7352, 
noisyNet noise sample is [array([-1.1914445], dtype=float32), 1.689843]. 
=============================================
[2019-03-26 21:34:20,224] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3808695e-13 9.9999988e-01 5.5738803e-12 7.6498551e-08 7.5870177e-17], sum to 1.0000
[2019-03-26 21:34:20,232] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6249
[2019-03-26 21:34:20,239] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1962684.722225581 W.
[2019-03-26 21:34:20,247] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.33333333333334, 73.83333333333334, 1.0, 2.0, 0.7625662410992566, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.971277568012139, 6.9112, 168.9125986740915, 1962684.722225581, 1920063.718058791, 399971.6693565893], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1263000.0000, 
sim time next is 1263600.0000, 
raw observation next is [28.3, 74.0, 1.0, 2.0, 0.7719034677860027, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.969660211857937, 6.9112, 168.9125595342627, 1975751.966340749, 1934278.377474224, 402228.3661260952], 
processed observation next is [1.0, 0.6521739130434783, 0.5402843601895735, 0.74, 1.0, 1.0, 0.7251849009469912, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.00584602118579367, 0.0, 0.8294379958175798, 0.548819990650208, 0.5372995492983955, 0.6003408449643212], 
reward next is 0.1074, 
noisyNet noise sample is [array([-1.6103414], dtype=float32), -1.3092178]. 
=============================================
[2019-03-26 21:34:24,653] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3781318e-20 1.0000000e+00 3.9753961e-20 4.5151488e-16 2.8326933e-25], sum to 1.0000
[2019-03-26 21:34:24,664] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0487
[2019-03-26 21:34:24,673] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 88.0, 1.0, 2.0, 0.6708684931586075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1065116.051333728, 1065116.051333728, 229682.4849613019], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1346400.0000, 
sim time next is 1347000.0000, 
raw observation next is [21.46666666666667, 88.16666666666667, 1.0, 2.0, 0.5704487401589996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 906774.0291150539, 906774.0291150539, 207844.0228276239], 
processed observation next is [1.0, 0.6086956521739131, 0.21642969984202226, 0.8816666666666667, 1.0, 1.0, 0.4824683616373489, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.25188167475418166, 0.25188167475418166, 0.3102149594442148], 
reward next is 0.6898, 
noisyNet noise sample is [array([-0.1260429], dtype=float32), 0.88081944]. 
=============================================
[2019-03-26 21:34:24,700] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[73.678215]
 [73.642845]
 [73.74164 ]
 [73.77269 ]
 [73.85411 ]], R is [[73.65369415]
 [73.57434845]
 [73.49263763]
 [73.41475677]
 [73.35221863]].
[2019-03-26 21:34:30,633] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4525524e-22 1.0000000e+00 6.6206291e-22 7.7431500e-18 3.9947034e-27], sum to 1.0000
[2019-03-26 21:34:30,640] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1140
[2019-03-26 21:34:30,647] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 70.0, 1.0, 2.0, 0.4530481645940554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 639946.9700882114, 639946.9700882114, 177459.5854733691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1440000.0000, 
sim time next is 1440600.0000, 
raw observation next is [27.93333333333334, 69.83333333333334, 1.0, 2.0, 0.4519402142382168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 639298.9911641382, 639298.9911641382, 177417.5316918393], 
processed observation next is [0.0, 0.6956521739130435, 0.5229067930489735, 0.6983333333333335, 1.0, 1.0, 0.3396870051062853, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1775830531011495, 0.1775830531011495, 0.26480228610722284], 
reward next is 0.7352, 
noisyNet noise sample is [array([-0.10301185], dtype=float32), -0.22420616]. 
=============================================
[2019-03-26 21:34:32,172] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3972837e-22 1.0000000e+00 4.4790602e-21 1.1547040e-16 3.6183702e-27], sum to 1.0000
[2019-03-26 21:34:32,183] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4235
[2019-03-26 21:34:32,189] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 92.66666666666667, 1.0, 2.0, 0.4540390997547379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 647804.9490534874, 647804.9490534874, 178428.8729174199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1899600.0000, 
sim time next is 1900200.0000, 
raw observation next is [24.31666666666667, 92.83333333333333, 1.0, 2.0, 0.4532830282060038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 646585.4820240797, 646585.4820240802, 178300.4118952776], 
processed observation next is [1.0, 1.0, 0.3515007898894157, 0.9283333333333332, 1.0, 1.0, 0.34130485326024557, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17960707834002212, 0.1796070783400223, 0.2661200177541457], 
reward next is 0.7339, 
noisyNet noise sample is [array([1.1220037], dtype=float32), -0.33999735]. 
=============================================
[2019-03-26 21:34:32,611] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2125268e-21 1.0000000e+00 3.9316903e-20 1.4111463e-15 2.6431796e-27], sum to 1.0000
[2019-03-26 21:34:32,621] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3588
[2019-03-26 21:34:32,629] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.65, 86.5, 1.0, 2.0, 0.5082943590738291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 710266.2688861516, 710266.2688861516, 184905.9869181053], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1714200.0000, 
sim time next is 1714800.0000, 
raw observation next is [26.6, 87.0, 1.0, 2.0, 0.5097277816118588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712269.9366325306, 712269.9366325306, 185134.3652466727], 
processed observation next is [1.0, 0.8695652173913043, 0.4597156398104266, 0.87, 1.0, 1.0, 0.4093105802552516, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19785276017570297, 0.19785276017570297, 0.2763199481293622], 
reward next is 0.7237, 
noisyNet noise sample is [array([-0.8961941], dtype=float32), 1.1785257]. 
=============================================
[2019-03-26 21:34:37,107] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.8191476e-23 1.0000000e+00 4.9587165e-22 7.1122668e-18 9.4503235e-28], sum to 1.0000
[2019-03-26 21:34:37,121] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7866
[2019-03-26 21:34:37,126] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.26666666666667, 90.0, 1.0, 2.0, 0.3444579342784178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 533972.0111294887, 533972.0111294887, 169421.1715931408], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1550400.0000, 
sim time next is 1551000.0000, 
raw observation next is [22.18333333333333, 90.5, 1.0, 2.0, 0.3435328483465633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 532828.480562943, 532828.480562943, 169336.7082593457], 
processed observation next is [0.0, 0.9565217391304348, 0.2503949447077408, 0.905, 1.0, 1.0, 0.20907572089947382, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14800791126748417, 0.14800791126748417, 0.2527413556109637], 
reward next is 0.7473, 
noisyNet noise sample is [array([-1.2970089], dtype=float32), -0.8595739]. 
=============================================
[2019-03-26 21:34:37,140] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[78.0659 ]
 [78.0096 ]
 [77.95387]
 [77.89461]
 [77.82318]], R is [[78.07931519]
 [78.0456543 ]
 [78.01233673]
 [77.97930145]
 [77.94641876]].
[2019-03-26 21:34:39,171] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.0514061e-21 1.0000000e+00 1.0061585e-19 1.2953994e-16 1.5930755e-25], sum to 1.0000
[2019-03-26 21:34:39,180] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5197
[2019-03-26 21:34:39,187] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.41666666666667, 85.00000000000001, 1.0, 2.0, 0.3914057450573952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 598482.06138325, 598482.0613832506, 174773.1832725219], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1584600.0000, 
sim time next is 1585200.0000, 
raw observation next is [23.43333333333333, 85.0, 1.0, 2.0, 0.4809180021870427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 734962.9368181376, 734962.9368181371, 188286.2661040828], 
processed observation next is [1.0, 0.34782608695652173, 0.30963665086887826, 0.85, 1.0, 1.0, 0.3746000026349912, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20415637133837156, 0.20415637133837142, 0.2810242777672878], 
reward next is 0.7190, 
noisyNet noise sample is [array([0.5409486], dtype=float32), 1.0171347]. 
=============================================
[2019-03-26 21:34:40,135] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2744673e-20 1.0000000e+00 2.2996771e-20 3.1246664e-16 2.0248208e-25], sum to 1.0000
[2019-03-26 21:34:40,147] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7916
[2019-03-26 21:34:40,152] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.93333333333333, 85.0, 1.0, 2.0, 0.6382923479185131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 960205.2470163631, 960205.2470163625, 216681.1652413676], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1599600.0000, 
sim time next is 1600200.0000, 
raw observation next is [23.95, 85.0, 1.0, 2.0, 0.6123591816638826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 920756.4851794781, 920756.4851794788, 211193.4751485365], 
processed observation next is [1.0, 0.5217391304347826, 0.3341232227488152, 0.85, 1.0, 1.0, 0.5329628694745573, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2557656903276328, 0.25576569032763297, 0.31521414201274106], 
reward next is 0.6848, 
noisyNet noise sample is [array([0.5422349], dtype=float32), 0.30081767]. 
=============================================
[2019-03-26 21:34:42,728] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.3774523e-23 1.0000000e+00 8.6200197e-22 1.1059399e-17 9.0244445e-28], sum to 1.0000
[2019-03-26 21:34:42,738] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8211
[2019-03-26 21:34:42,744] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.53333333333333, 94.0, 1.0, 2.0, 0.4687473294656851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 657740.7315000216, 657740.7315000216, 179200.0333773325], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2072400.0000, 
sim time next is 2073000.0000, 
raw observation next is [24.51666666666667, 94.0, 1.0, 2.0, 0.4682872902829175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 657590.738664544, 657590.738664544, 179195.8874800015], 
processed observation next is [0.0, 1.0, 0.36097946287519767, 0.94, 1.0, 1.0, 0.3593822774492981, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18266409407348444, 0.18266409407348444, 0.2674565484776142], 
reward next is 0.7325, 
noisyNet noise sample is [array([0.06600285], dtype=float32), 0.09238917]. 
=============================================
[2019-03-26 21:34:42,761] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[78.48384]
 [78.45159]
 [78.42311]
 [78.38984]
 [78.34655]], R is [[78.45426178]
 [78.40225983]
 [78.35077667]
 [78.29975128]
 [78.24909973]].
[2019-03-26 21:34:53,374] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.5465257e-20 1.0000000e+00 2.1820645e-19 1.5893074e-16 4.3224731e-25], sum to 1.0000
[2019-03-26 21:34:53,383] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0457
[2019-03-26 21:34:53,386] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.96666666666667, 93.16666666666666, 1.0, 2.0, 0.3460372273495639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 535188.9095105969, 535188.9095105969, 169485.4041763998], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1821000.0000, 
sim time next is 1821600.0000, 
raw observation next is [22.0, 93.0, 1.0, 2.0, 0.3453446244914873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 533927.2220454625, 533927.2220454625, 169377.4132252798], 
processed observation next is [1.0, 0.08695652173913043, 0.2417061611374408, 0.93, 1.0, 1.0, 0.21125858372468348, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1483131172348507, 0.1483131172348507, 0.2528021092914624], 
reward next is 0.7472, 
noisyNet noise sample is [array([-0.321376], dtype=float32), 0.37672597]. 
=============================================
[2019-03-26 21:34:56,614] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 21:34:56,615] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:34:56,617] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:34:56,617] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:34:56,618] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:34:56,619] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:34:56,621] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:34:56,622] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:34:56,623] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:34:56,620] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:34:56,626] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:34:56,648] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run54
[2019-03-26 21:34:56,668] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run54
[2019-03-26 21:34:56,669] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run54
[2019-03-26 21:34:56,712] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run54
[2019-03-26 21:34:56,713] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run54
[2019-03-26 21:35:31,702] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0875577], dtype=float32), 0.06456214]
[2019-03-26 21:35:31,705] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.3, 82.0, 1.0, 2.0, 0.670485267407717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 937004.0683421745, 937004.0683421738, 214601.8070888437]
[2019-03-26 21:35:31,705] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:35:31,707] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.9034354e-21 1.0000000e+00 2.8677428e-20 5.2601874e-17 3.5830035e-26], sampled 0.9239168022402716
[2019-03-26 21:36:24,534] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0875577], dtype=float32), 0.06456214]
[2019-03-26 21:36:24,535] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.42037378666667, 84.62601232, 1.0, 2.0, 0.8211244365255366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1147636.266052719, 1147636.266052718, 249159.2234722598]
[2019-03-26 21:36:24,538] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:36:24,540] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.0719103e-18 1.0000000e+00 2.3133009e-17 5.6931982e-13 5.4375501e-23], sampled 0.8855004277214499
[2019-03-26 21:36:51,658] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 21:36:51,668] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.4098 3164190979.9668 1776.0000
[2019-03-26 21:36:51,693] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8494.5146 2842683451.9042 1131.0000
[2019-03-26 21:36:51,832] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9767 2779231803.5959 933.0000
[2019-03-26 21:36:51,852] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.1919 2927406475.0554 1338.0000
[2019-03-26 21:36:52,867] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1325000, evaluation results [1325000.0, 7884.409754350378, 3164190979.9668245, 1776.0, 8254.191907072065, 2927406475.055425, 1338.0, 8659.976680226611, 2779231803.5959473, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8494.514649158495, 2842683451.9041815, 1131.0]
[2019-03-26 21:37:01,861] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1516658e-21 1.0000000e+00 1.2230831e-21 1.8666270e-17 6.5989779e-27], sum to 1.0000
[2019-03-26 21:37:01,868] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2329
[2019-03-26 21:37:01,873] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.08333333333333, 90.66666666666666, 1.0, 2.0, 0.5076028214960224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709299.624672002, 709299.624672002, 184796.0986747059], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2029800.0000, 
sim time next is 2030400.0000, 
raw observation next is [26.2, 90.0, 1.0, 2.0, 0.5083006152379825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 710275.0138739177, 710275.0138739183, 184907.0869315164], 
processed observation next is [0.0, 0.5217391304347826, 0.44075829383886256, 0.9, 1.0, 1.0, 0.40759110269636445, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19729861496497716, 0.1972986149649773, 0.2759807267634573], 
reward next is 0.7240, 
noisyNet noise sample is [array([1.5614467], dtype=float32), 1.9114809]. 
=============================================
[2019-03-26 21:37:05,621] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8818878e-21 1.0000000e+00 4.2881572e-21 6.8487552e-18 4.3978799e-27], sum to 1.0000
[2019-03-26 21:37:05,630] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0684
[2019-03-26 21:37:05,637] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.51666666666667, 82.83333333333334, 1.0, 2.0, 0.555518474074829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 776279.1049432408, 776279.1049432408, 192751.8861035321], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2142600.0000, 
sim time next is 2143200.0000, 
raw observation next is [28.33333333333334, 83.66666666666667, 1.0, 2.0, 0.553274880189025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 773142.7755715012, 773142.7755715012, 192364.2066249187], 
processed observation next is [0.0, 0.8260869565217391, 0.5418641390205374, 0.8366666666666667, 1.0, 1.0, 0.46177696408316266, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21476188210319477, 0.21476188210319477, 0.2871107561565951], 
reward next is 0.7129, 
noisyNet noise sample is [array([0.41693655], dtype=float32), 0.3788306]. 
=============================================
[2019-03-26 21:37:06,522] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6832951e-22 1.0000000e+00 2.3993989e-21 3.7256637e-18 6.6970185e-27], sum to 1.0000
[2019-03-26 21:37:06,532] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3897
[2019-03-26 21:37:06,537] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.95, 93.0, 1.0, 2.0, 0.5198918164369748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726477.5436797593, 726477.5436797593, 186771.2839850073], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2158200.0000, 
sim time next is 2158800.0000, 
raw observation next is [25.9, 93.0, 1.0, 2.0, 0.5191090304567378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 725383.3341017362, 725383.3341017356, 186644.0276892886], 
processed observation next is [0.0, 1.0, 0.42654028436018954, 0.93, 1.0, 1.0, 0.42061328970691303, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20149537058381561, 0.20149537058381545, 0.27857317565565465], 
reward next is 0.7214, 
noisyNet noise sample is [array([2.229203], dtype=float32), 1.3567632]. 
=============================================
[2019-03-26 21:37:07,078] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6461459e-21 1.0000000e+00 3.8862088e-21 7.3203921e-18 1.6707704e-26], sum to 1.0000
[2019-03-26 21:37:07,084] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1918
[2019-03-26 21:37:07,093] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 75.83333333333333, 1.0, 2.0, 0.5619807788988245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 785312.8399107563, 785312.8399107563, 193877.3503473001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2119800.0000, 
sim time next is 2120400.0000, 
raw observation next is [30.0, 76.0, 1.0, 2.0, 0.5622836267046358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 785736.1964479298, 785736.1964479298, 193930.428104229], 
processed observation next is [0.0, 0.5652173913043478, 0.6208530805687204, 0.76, 1.0, 1.0, 0.472630875547754, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2182600545688694, 0.2182600545688694, 0.28944840015556567], 
reward next is 0.7106, 
noisyNet noise sample is [array([1.1753764], dtype=float32), 0.7685897]. 
=============================================
[2019-03-26 21:37:08,538] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1452782e-21 1.0000000e+00 6.2221665e-21 2.1174906e-17 4.3270388e-27], sum to 1.0000
[2019-03-26 21:37:08,546] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9612
[2019-03-26 21:37:08,550] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.03333333333333, 80.33333333333333, 1.0, 2.0, 0.5604960811354082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 783237.3559466929, 783237.3559466923, 193617.3095072526], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2140800.0000, 
sim time next is 2141400.0000, 
raw observation next is [28.86666666666667, 81.16666666666667, 1.0, 2.0, 0.5592848233189696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 781544.1212854272, 781544.1212854272, 193406.0303552382], 
processed observation next is [0.0, 0.782608695652174, 0.567140600315956, 0.8116666666666668, 1.0, 1.0, 0.4690178594204452, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21709558924595201, 0.21709558924595201, 0.2886657169481167], 
reward next is 0.7113, 
noisyNet noise sample is [array([1.5181198], dtype=float32), 0.4241985]. 
=============================================
[2019-03-26 21:37:11,900] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1215077e-17 1.0000000e+00 6.9493170e-17 4.9326472e-13 5.8936553e-22], sum to 1.0000
[2019-03-26 21:37:11,909] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4064
[2019-03-26 21:37:11,914] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.35, 80.83333333333333, 1.0, 2.0, 0.9601684494163023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1342092.55043601, 1342092.550436011, 287024.9714171542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2429400.0000, 
sim time next is 2430000.0000, 
raw observation next is [28.3, 81.0, 1.0, 2.0, 0.8873752454859619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1240285.12051485, 1240285.120514849, 266488.8410854603], 
processed observation next is [1.0, 0.13043478260869565, 0.5402843601895735, 0.81, 1.0, 1.0, 0.8643075246818818, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3445236445874583, 0.34452364458745804, 0.39774453893352285], 
reward next is 0.6023, 
noisyNet noise sample is [array([-1.2960314], dtype=float32), -2.1344721]. 
=============================================
[2019-03-26 21:37:11,923] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[60.555763]
 [59.829803]
 [59.749493]
 [62.352207]
 [68.12783 ]], R is [[61.22146606]
 [61.18085861]
 [61.12465286]
 [60.51340866]
 [60.36859512]].
[2019-03-26 21:37:17,416] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.6947063e-21 1.0000000e+00 1.8763978e-20 2.7618126e-17 3.1979928e-26], sum to 1.0000
[2019-03-26 21:37:17,425] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8663
[2019-03-26 21:37:17,430] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.4787173979121028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 668923.8227857114, 668923.8227857107, 180328.5257766519], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2704800.0000, 
sim time next is 2705400.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.4792667362554635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 669691.6689820278, 669691.6689820278, 180411.1458100419], 
processed observation next is [0.0, 0.30434782608695654, 0.3364928909952607, 1.0, 1.0, 1.0, 0.3726105256089922, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18602546360611882, 0.18602546360611882, 0.26927036688065953], 
reward next is 0.7307, 
noisyNet noise sample is [array([1.6953311], dtype=float32), -0.7962104]. 
=============================================
[2019-03-26 21:37:19,864] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.5177733e-21 1.0000000e+00 8.8098483e-20 5.6242977e-16 2.1448135e-25], sum to 1.0000
[2019-03-26 21:37:19,874] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9075
[2019-03-26 21:37:19,878] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.05, 81.0, 1.0, 2.0, 0.5323853369376412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 743941.6393067535, 743941.6393067541, 188825.6811382481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2337000.0000, 
sim time next is 2337600.0000, 
raw observation next is [28.0, 81.0, 1.0, 2.0, 0.5300839181191508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 740724.5742801601, 740724.5742801601, 188443.8136541813], 
processed observation next is [1.0, 0.043478260869565216, 0.5260663507109005, 0.81, 1.0, 1.0, 0.4338360459266877, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20575682618893337, 0.20575682618893337, 0.2812594233644497], 
reward next is 0.7187, 
noisyNet noise sample is [array([-1.8713219], dtype=float32), -0.3573822]. 
=============================================
[2019-03-26 21:37:25,606] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.1019958e-21 1.0000000e+00 3.9542501e-21 3.9009656e-17 9.0085242e-27], sum to 1.0000
[2019-03-26 21:37:25,615] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6943
[2019-03-26 21:37:25,621] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 89.0, 1.0, 2.0, 0.4329971793528517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 628663.3576408663, 628663.3576408663, 176793.8160702822], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2659200.0000, 
sim time next is 2659800.0000, 
raw observation next is [24.16666666666666, 89.0, 1.0, 2.0, 0.4262090879940847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 622792.4104582334, 622792.4104582329, 176329.4834988362], 
processed observation next is [0.0, 0.782608695652174, 0.34439178515007873, 0.89, 1.0, 1.0, 0.30868564818564426, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17299789179395372, 0.17299789179395358, 0.26317833358035253], 
reward next is 0.7368, 
noisyNet noise sample is [array([0.56903577], dtype=float32), 1.4266963]. 
=============================================
[2019-03-26 21:37:29,450] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.3321696e-15 1.0000000e+00 1.1444619e-13 9.8279074e-09 9.4938714e-19], sum to 1.0000
[2019-03-26 21:37:29,460] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6950
[2019-03-26 21:37:29,466] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 85.0, 1.0, 2.0, 0.5352298734017962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 747917.9211063155, 747917.9211063149, 189300.8957934801], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2484000.0000, 
sim time next is 2484600.0000, 
raw observation next is [27.83333333333333, 85.66666666666667, 1.0, 2.0, 0.5380186720661125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 751816.3033612807, 751816.3033612807, 189768.0132462828], 
processed observation next is [1.0, 0.782608695652174, 0.518167456556082, 0.8566666666666667, 1.0, 1.0, 0.4433959904410994, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2088378620448002, 0.2088378620448002, 0.2832358406660937], 
reward next is 0.7168, 
noisyNet noise sample is [array([-0.21419172], dtype=float32), -0.41168654]. 
=============================================
[2019-03-26 21:37:33,348] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1263456e-19 1.0000000e+00 9.9199314e-19 5.3100711e-15 6.0124794e-25], sum to 1.0000
[2019-03-26 21:37:33,360] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3366
[2019-03-26 21:37:33,366] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.5572093849708507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 880900.4277450659, 880900.4277450665, 204798.8753002407], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2991000.0000, 
sim time next is 2991600.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.5497304460693864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 869077.117597409, 869077.117597409, 203339.2766194669], 
processed observation next is [1.0, 0.6521739130434783, 0.19431279620853087, 0.94, 1.0, 1.0, 0.45750656152938113, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2414103104437247, 0.2414103104437247, 0.3034914576409954], 
reward next is 0.6965, 
noisyNet noise sample is [array([-0.43554452], dtype=float32), -0.14047705]. 
=============================================
[2019-03-26 21:37:38,464] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.79383385e-21 1.00000000e+00 6.11330497e-21 3.61504993e-17
 1.13624135e-26], sum to 1.0000
[2019-03-26 21:37:38,473] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1778
[2019-03-26 21:37:38,476] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 82.33333333333334, 1.0, 2.0, 0.495270425329538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 692061.3174084985, 692061.3174084985, 182858.6997948849], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2637600.0000, 
sim time next is 2638200.0000, 
raw observation next is [27.0, 83.16666666666666, 1.0, 2.0, 0.499595863403963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 698107.4123252076, 698107.4123252076, 183533.1453478362], 
processed observation next is [0.0, 0.5217391304347826, 0.4786729857819906, 0.8316666666666666, 1.0, 1.0, 0.39710344988429275, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.193918725645891, 0.193918725645891, 0.2739300676833376], 
reward next is 0.7261, 
noisyNet noise sample is [array([-0.8078866], dtype=float32), -1.9997584]. 
=============================================
[2019-03-26 21:37:41,372] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8787737e-22 1.0000000e+00 3.4498511e-22 1.3357291e-17 1.5222339e-27], sum to 1.0000
[2019-03-26 21:37:41,381] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1397
[2019-03-26 21:37:41,385] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3953053316863929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 589854.1961933773, 589854.1961933773, 173604.2388289574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2672400.0000, 
sim time next is 2673000.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.395570217914681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 590249.5026353665, 590249.5026353665, 173640.5113558316], 
processed observation next is [0.0, 0.9565217391304348, 0.28909952606635075, 0.94, 1.0, 1.0, 0.2717713468851578, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1639581951764907, 0.1639581951764907, 0.2591649423221367], 
reward next is 0.7408, 
noisyNet noise sample is [array([0.2278064], dtype=float32), -0.5840729]. 
=============================================
[2019-03-26 21:37:41,395] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[77.14997 ]
 [77.130875]
 [77.10249 ]
 [77.08114 ]
 [77.077576]], R is [[77.13703918]
 [77.10655975]
 [77.07635498]
 [77.0464325 ]
 [77.01677704]].
[2019-03-26 21:37:42,766] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2507313e-22 1.0000000e+00 9.5575196e-22 8.7777875e-18 3.3466881e-27], sum to 1.0000
[2019-03-26 21:37:42,776] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0625
[2019-03-26 21:37:42,784] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 100.0, 1.0, 2.0, 0.4157842069799606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 610144.6145788797, 610144.6145788797, 175191.8476672653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2715600.0000, 
sim time next is 2716200.0000, 
raw observation next is [22.5, 100.0, 1.0, 2.0, 0.409181697380103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 604254.4559888901, 604254.4559888901, 174749.847841923], 
processed observation next is [0.0, 0.43478260869565216, 0.2654028436018958, 1.0, 1.0, 1.0, 0.28817071973506386, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16784845999691392, 0.16784845999691392, 0.2608206684207806], 
reward next is 0.7392, 
noisyNet noise sample is [array([0.06267849], dtype=float32), -0.23126113]. 
=============================================
[2019-03-26 21:37:44,511] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.4792029e-20 1.0000000e+00 1.5232393e-19 2.0097396e-16 3.8976476e-25], sum to 1.0000
[2019-03-26 21:37:44,524] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6142
[2019-03-26 21:37:44,528] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3395761230537678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 523113.9895834465, 523113.9895834465, 168447.6071190568], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2786400.0000, 
sim time next is 2787000.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.3540312321264625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 545380.3656194228, 545380.3656194228, 170261.4877199658], 
processed observation next is [1.0, 0.2608695652173913, 0.2417061611374408, 0.9400000000000002, 1.0, 1.0, 0.2217243760559789, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15149454600539522, 0.15149454600539522, 0.25412162346263556], 
reward next is 0.7459, 
noisyNet noise sample is [array([0.49589723], dtype=float32), -1.094522]. 
=============================================
[2019-03-26 21:37:44,544] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[70.25965 ]
 [70.24596 ]
 [70.249626]
 [70.18637 ]
 [70.18753 ]], R is [[70.3234787 ]
 [70.36883545]
 [70.41387939]
 [70.458992  ]
 [70.5037384 ]].
[2019-03-26 21:37:48,913] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 21:37:48,915] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:37:48,916] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:37:48,916] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:37:48,917] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:37:48,917] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:37:48,919] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:37:48,920] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:37:48,921] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:37:48,922] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:37:48,919] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:37:48,948] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run55
[2019-03-26 21:37:48,971] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run55
[2019-03-26 21:37:48,991] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run55
[2019-03-26 21:37:48,992] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run55
[2019-03-26 21:37:48,992] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run55
[2019-03-26 21:38:00,766] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08833862], dtype=float32), 0.06461437]
[2019-03-26 21:38:00,767] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.16666666666667, 63.0, 1.0, 2.0, 0.5394786453902297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 793003.3734057762, 793003.3734057762, 194927.454905237]
[2019-03-26 21:38:00,768] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:38:00,770] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.2293385e-21 1.0000000e+00 2.8924519e-20 8.1829881e-17 7.7698966e-26], sampled 0.6436575233186347
[2019-03-26 21:38:06,547] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08833862], dtype=float32), 0.06461437]
[2019-03-26 21:38:06,548] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [18.97532288, 87.80325855333334, 1.0, 2.0, 0.2478166041198559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 409387.4780435792, 409387.4780435792, 160630.3681051942]
[2019-03-26 21:38:06,555] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:38:06,557] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.6298513e-21 1.0000000e+00 1.7878368e-20 4.7816419e-17 3.6967825e-26], sampled 0.4814984254245177
[2019-03-26 21:38:30,181] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08833862], dtype=float32), 0.06461437]
[2019-03-26 21:38:30,185] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.00552509, 93.07956085500001, 1.0, 2.0, 0.4288647517287349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 622451.8972772129, 622451.8972772129, 176180.8770957744]
[2019-03-26 21:38:30,187] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:38:30,191] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.8767795e-22 1.0000000e+00 3.6429648e-21 1.6955553e-17 6.9137180e-27], sampled 0.45935323145394
[2019-03-26 21:38:52,826] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08833862], dtype=float32), 0.06461437]
[2019-03-26 21:38:52,827] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.9, 48.0, 1.0, 2.0, 0.8215131335627761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1148179.818258198, 1148179.818258198, 249262.5482471369]
[2019-03-26 21:38:52,828] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:38:52,835] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.0820151e-21 1.0000000e+00 4.9415191e-20 2.0392102e-15 3.1672285e-26], sampled 0.7498436453368027
[2019-03-26 21:38:56,433] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08833862], dtype=float32), 0.06461437]
[2019-03-26 21:38:56,435] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.0, 79.0, 1.0, 2.0, 0.5220185791478016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729450.423422317, 729450.423422317, 187117.5868678702]
[2019-03-26 21:38:56,438] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:38:56,440] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.9521669e-22 1.0000000e+00 2.2549727e-21 2.6162783e-17 4.5063306e-27], sampled 0.25074812862739526
[2019-03-26 21:39:19,505] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08833862], dtype=float32), 0.06461437]
[2019-03-26 21:39:19,506] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.7, 83.0, 1.0, 2.0, 0.6477390935359809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 905202.712892234, 905202.712892234, 209968.9129767291]
[2019-03-26 21:39:19,508] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:39:19,512] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.6266632e-21 1.0000000e+00 1.3192038e-20 6.0957123e-17 2.4701241e-26], sampled 0.4693940892498941
[2019-03-26 21:39:24,937] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08833862], dtype=float32), 0.06461437]
[2019-03-26 21:39:24,938] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.7, 67.0, 1.0, 2.0, 1.025993549854838, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.988357202091168, 6.9112, 168.9123390349152, 2331385.263497718, 2276647.488887561, 472060.6787407757]
[2019-03-26 21:39:24,940] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:39:24,942] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.8706812e-11 9.9999869e-01 6.3100088e-11 1.3269488e-06 1.7495118e-14], sampled 0.6014035348137232
[2019-03-26 21:39:24,946] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2331385.263497718 W.
[2019-03-26 21:39:33,498] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08833862], dtype=float32), 0.06461437]
[2019-03-26 21:39:33,500] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.60954662, 96.19937646999999, 1.0, 2.0, 0.3996362001461938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 598735.197610952, 598735.1976109525, 174488.5120262746]
[2019-03-26 21:39:33,502] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:39:33,505] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.9708319e-22 1.0000000e+00 4.3038732e-21 2.6481888e-17 6.6609412e-27], sampled 0.20264204875557068
[2019-03-26 21:39:43,274] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.2429 2842674582.9284 1131.0000
[2019-03-26 21:39:43,429] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.3926 3164442528.8259 1776.0000
[2019-03-26 21:39:43,803] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.2902 2927416332.5773 1338.0000
[2019-03-26 21:39:43,854] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7995.9992 3007752696.8220 1766.0000
[2019-03-26 21:39:43,860] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.7905 2779406902.0110 933.0000
[2019-03-26 21:39:44,878] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1350000, evaluation results [1350000.0, 7881.392586968131, 3164442528.825886, 1776.0, 8254.290164618182, 2927416332.5773025, 1338.0, 8659.79050061645, 2779406902.011044, 933.0, 7995.999162255429, 3007752696.8219523, 1766.0, 8497.242939638712, 2842674582.928353, 1131.0]
[2019-03-26 21:39:47,115] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.0749964e-20 1.0000000e+00 3.2883994e-19 6.9073504e-16 9.0493824e-25], sum to 1.0000
[2019-03-26 21:39:47,127] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5382
[2019-03-26 21:39:47,136] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3479205549480015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 535962.7626764473, 535962.7626764467, 169485.5977016161], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2857800.0000, 
sim time next is 2858400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3477500604550242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 535700.2321383464, 535700.2321383464, 169464.1551222687], 
processed observation next is [1.0, 0.08695652173913043, 0.2417061611374408, 0.94, 1.0, 1.0, 0.21415669934340267, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14880562003842956, 0.14880562003842956, 0.2529315748093563], 
reward next is 0.7471, 
noisyNet noise sample is [array([1.1476845], dtype=float32), -1.0336843]. 
=============================================
[2019-03-26 21:39:47,934] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9601280e-21 1.0000000e+00 1.1019628e-20 4.1165173e-17 6.1244702e-26], sum to 1.0000
[2019-03-26 21:39:47,945] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2854
[2019-03-26 21:39:47,951] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.7874252853470698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1174616.704686965, 1174616.704686964, 250870.7695471696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3065400.0000, 
sim time next is 3066000.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.7852241844331339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1171331.216517576, 1171331.216517575, 250300.4449124924], 
processed observation next is [1.0, 0.4782608695652174, 0.28909952606635075, 0.94, 1.0, 1.0, 0.741233957148354, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.32536978236599334, 0.32536978236599307, 0.37358275360073495], 
reward next is 0.6264, 
noisyNet noise sample is [array([0.8332605], dtype=float32), -0.005760203]. 
=============================================
[2019-03-26 21:39:47,965] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[70.36443 ]
 [70.35556 ]
 [70.327644]
 [70.37346 ]
 [70.35174 ]], R is [[70.28408813]
 [70.20681   ]
 [70.13398743]
 [70.04800415]
 [70.00372314]].
[2019-03-26 21:39:48,391] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.4383455e-20 1.0000000e+00 2.2644744e-19 2.0498160e-16 1.8049983e-25], sum to 1.0000
[2019-03-26 21:39:48,397] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3244
[2019-03-26 21:39:48,404] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3460187749729142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 533033.0938952587, 533033.0938952581, 169246.8263457333], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2868000.0000, 
sim time next is 2868600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3453979577601216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 532077.8387668893, 532077.83876689, 169169.26886832], 
processed observation next is [1.0, 0.17391304347826086, 0.2417061611374408, 0.94, 1.0, 1.0, 0.2113228406748453, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14779939965746924, 0.14779939965746944, 0.25249144607211943], 
reward next is 0.7475, 
noisyNet noise sample is [array([-0.02559144], dtype=float32), 1.5031172]. 
=============================================
[2019-03-26 21:39:48,494] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.6909395e-21 1.0000000e+00 2.1742362e-20 9.2484126e-17 1.0401193e-26], sum to 1.0000
[2019-03-26 21:39:48,509] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3420
[2019-03-26 21:39:48,514] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 97.0, 1.0, 2.0, 0.3158403466178733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 500954.1734709924, 500954.1734709924, 167123.6546730745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2921400.0000, 
sim time next is 2922000.0000, 
raw observation next is [20.33333333333333, 98.0, 1.0, 2.0, 0.3125757397116858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 496358.7754493747, 496358.7754493747, 166791.2369796498], 
processed observation next is [1.0, 0.8260869565217391, 0.16271721958925733, 0.98, 1.0, 1.0, 0.17177799965263346, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1378774376248263, 0.1378774376248263, 0.248942144745746], 
reward next is 0.7511, 
noisyNet noise sample is [array([0.6402647], dtype=float32), 0.8156177]. 
=============================================
[2019-03-26 21:39:48,526] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[72.46383]
 [72.4363 ]
 [72.45232]
 [72.44858]
 [72.40666]], R is [[72.46326447]
 [72.48919678]
 [72.51445007]
 [72.53929138]
 [72.56374359]].
[2019-03-26 21:39:50,404] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.6087266e-20 1.0000000e+00 2.9284123e-20 3.4416727e-16 2.0608460e-25], sum to 1.0000
[2019-03-26 21:39:50,413] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8565
[2019-03-26 21:39:50,420] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.6692399577254918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1027449.271806899, 1027449.271806899, 225822.4052598489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2902800.0000, 
sim time next is 2903400.0000, 
raw observation next is [22.5, 91.5, 1.0, 2.0, 0.6907842199617018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1058590.6258932, 1058590.625893201, 230597.951246472], 
processed observation next is [1.0, 0.6086956521739131, 0.2654028436018958, 0.915, 1.0, 1.0, 0.6274508674237371, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.294052951637, 0.2940529516370003, 0.34417604663652535], 
reward next is 0.6558, 
noisyNet noise sample is [array([-1.5535686], dtype=float32), -1.0803365]. 
=============================================
[2019-03-26 21:39:50,884] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.3095277e-21 1.0000000e+00 8.4197668e-20 5.0554346e-16 6.2887024e-26], sum to 1.0000
[2019-03-26 21:39:50,895] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7701
[2019-03-26 21:39:50,900] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.526962387468613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 787175.6370659193, 787175.6370659193, 194221.3347785668], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2898000.0000, 
sim time next is 2898600.0000, 
raw observation next is [22.83333333333334, 94.00000000000001, 1.0, 2.0, 0.5686072264897417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 851744.2705237466, 851744.2705237466, 202139.1769588858], 
processed observation next is [1.0, 0.5652173913043478, 0.2812006319115327, 0.9400000000000002, 1.0, 1.0, 0.4802496704695683, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23659563070104073, 0.23659563070104073, 0.30170026411774], 
reward next is 0.6983, 
noisyNet noise sample is [array([-0.10503859], dtype=float32), -0.88228166]. 
=============================================
[2019-03-26 21:39:56,531] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.5697336e-22 1.0000000e+00 2.6176706e-21 5.5695308e-17 8.5216191e-27], sum to 1.0000
[2019-03-26 21:39:56,538] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2351
[2019-03-26 21:39:56,545] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.5, 73.0, 1.0, 2.0, 0.5976650794464909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 835197.743714509, 835197.7437145095, 200312.3403662385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3259800.0000, 
sim time next is 3260400.0000, 
raw observation next is [31.33333333333333, 73.66666666666667, 1.0, 2.0, 0.5970997092513171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 834407.3656158712, 834407.3656158712, 200207.3675610389], 
processed observation next is [0.0, 0.7391304347826086, 0.6840442338072668, 0.7366666666666667, 1.0, 1.0, 0.514577962953394, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23177982378218642, 0.23177982378218642, 0.2988169665090133], 
reward next is 0.7012, 
noisyNet noise sample is [array([-1.6769469], dtype=float32), -0.30736753]. 
=============================================
[2019-03-26 21:39:59,340] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.6650460e-20 1.0000000e+00 6.0716601e-20 6.9856501e-17 6.1043407e-26], sum to 1.0000
[2019-03-26 21:39:59,350] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1329
[2019-03-26 21:39:59,355] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 97.0, 1.0, 2.0, 0.3158891045644832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 495703.1224979213, 495703.1224979213, 166614.58172773], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3040200.0000, 
sim time next is 3040800.0000, 
raw observation next is [21.0, 98.0, 1.0, 2.0, 0.3202592044005328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 501052.8149874106, 501052.8149874106, 166975.7383874612], 
processed observation next is [1.0, 0.17391304347826086, 0.19431279620853087, 0.98, 1.0, 1.0, 0.1810351860247383, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13918133749650294, 0.13918133749650294, 0.24921751998128538], 
reward next is 0.7508, 
noisyNet noise sample is [array([-1.5741282], dtype=float32), -1.3306655]. 
=============================================
[2019-03-26 21:40:01,566] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.4453425e-22 1.0000000e+00 3.9607112e-21 5.3883607e-17 7.7353212e-27], sum to 1.0000
[2019-03-26 21:40:01,577] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5619
[2019-03-26 21:40:01,584] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 96.0, 1.0, 2.0, 0.4113425000650328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 607420.662355208, 607420.662355208, 175045.2776978148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3094800.0000, 
sim time next is 3095400.0000, 
raw observation next is [23.0, 95.0, 1.0, 2.0, 0.4068317331916693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 603477.5571900024, 603477.557190003, 174755.8674228257], 
processed observation next is [1.0, 0.8260869565217391, 0.28909952606635075, 0.95, 1.0, 1.0, 0.2853394375803245, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16763265477500067, 0.16763265477500083, 0.2608296528698891], 
reward next is 0.7392, 
noisyNet noise sample is [array([1.1818283], dtype=float32), 0.4087742]. 
=============================================
[2019-03-26 21:40:10,783] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.9275438e-22 1.0000000e+00 3.2857377e-21 2.0756317e-17 7.5857643e-27], sum to 1.0000
[2019-03-26 21:40:10,793] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8575
[2019-03-26 21:40:10,800] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.0, 63.00000000000001, 1.0, 2.0, 0.5817994424674762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813018.0712923688, 813018.0712923688, 197404.7590774237], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3252000.0000, 
sim time next is 3252600.0000, 
raw observation next is [33.0, 63.0, 1.0, 2.0, 0.5804348998496559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 811110.5043199442, 811110.5043199449, 197158.2650330917], 
processed observation next is [0.0, 0.6521739130434783, 0.7630331753554502, 0.63, 1.0, 1.0, 0.4944998793369348, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22530847342220672, 0.22530847342220692, 0.29426606721356974], 
reward next is 0.7057, 
noisyNet noise sample is [array([1.5064458], dtype=float32), 1.5541929]. 
=============================================
[2019-03-26 21:40:11,447] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.9818897e-08 8.2733506e-01 1.0080794e-06 1.7266387e-01 4.5978063e-10], sum to 1.0000
[2019-03-26 21:40:11,460] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3545
[2019-03-26 21:40:11,467] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1782942.533973231 W.
[2019-03-26 21:40:11,470] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.83333333333333, 63.0, 1.0, 2.0, 0.4251032702943192, 1.0, 1.0, 0.4251032702943192, 1.0, 2.0, 0.7382637967014997, 6.911200000000001, 6.9112, 170.5573041426782, 1782942.533973231, 1782942.53397323, 367220.5120167193], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3675000.0000, 
sim time next is 3675600.0000, 
raw observation next is [33.0, 63.0, 1.0, 2.0, 0.9750755925458502, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.005991982593865, 6.9112, 168.9123931190018, 2260116.281991317, 2192867.811351934, 455723.2308837916], 
processed observation next is [1.0, 0.5652173913043478, 0.7630331753554502, 0.63, 1.0, 1.0, 0.9699705934287352, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.009479198259386479, 0.0, 0.8294371786424636, 0.6278100783309214, 0.6091299475977594, 0.6801839266922263], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6420575], dtype=float32), -1.5392275]. 
=============================================
[2019-03-26 21:40:24,627] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1586076e-21 1.0000000e+00 7.2525597e-21 2.1526912e-17 3.7745854e-27], sum to 1.0000
[2019-03-26 21:40:24,634] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3119
[2019-03-26 21:40:24,641] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 92.33333333333334, 1.0, 2.0, 0.5751620359736044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 803739.3186089606, 803739.3186089612, 196209.1342637642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3904800.0000, 
sim time next is 3905400.0000, 
raw observation next is [27.16666666666666, 93.16666666666667, 1.0, 2.0, 0.5728608688741702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 800522.4243562263, 800522.4243562256, 195798.149770918], 
processed observation next is [0.0, 0.17391304347826086, 0.4865718799368086, 0.9316666666666668, 1.0, 1.0, 0.48537454081225323, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22236734009895176, 0.22236734009895157, 0.292236044434206], 
reward next is 0.7078, 
noisyNet noise sample is [array([-0.84954035], dtype=float32), 1.812223]. 
=============================================
[2019-03-26 21:40:30,414] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.3620598e-17 1.0000000e+00 2.4091359e-16 8.3318682e-13 3.0451467e-21], sum to 1.0000
[2019-03-26 21:40:30,422] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3559
[2019-03-26 21:40:30,430] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2017694.678239445 W.
[2019-03-26 21:40:30,439] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.66666666666667, 71.33333333333333, 1.0, 2.0, 0.4810220811758265, 1.0, 2.0, 0.4810220811758265, 1.0, 1.0, 0.8259709581907494, 6.9112, 6.9112, 170.5573041426782, 2017694.678239445, 2017694.678239445, 400636.8523954644], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3573600.0000, 
sim time next is 3574200.0000, 
raw observation next is [29.83333333333333, 70.66666666666667, 1.0, 2.0, 0.4802432234385203, 1.0, 2.0, 0.4802432234385203, 1.0, 2.0, 0.8277669493668788, 6.911200000000001, 6.9112, 170.5573041426782, 2014424.610894525, 2014424.610894524, 400671.1605479777], 
processed observation next is [1.0, 0.34782608695652173, 0.6129541864139019, 0.7066666666666667, 1.0, 1.0, 0.3737870161909883, 1.0, 1.0, 0.3737870161909883, 1.0, 1.0, 0.789959694349852, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5595623919151458, 0.5595623919151456, 0.5980166575342951], 
reward next is 0.4020, 
noisyNet noise sample is [array([2.3840146], dtype=float32), 0.769831]. 
=============================================
[2019-03-26 21:40:32,680] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9232582e-18 1.0000000e+00 5.9094967e-17 4.3526058e-13 3.9122667e-22], sum to 1.0000
[2019-03-26 21:40:32,689] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6860
[2019-03-26 21:40:32,701] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2029067.733308447 W.
[2019-03-26 21:40:32,709] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 79.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.721612155932043, 6.9112, 168.9084636780111, 2029067.733308447, 1454148.750049689, 311359.7393482932], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4176000.0000, 
sim time next is 4176600.0000, 
raw observation next is [32.16666666666667, 77.66666666666667, 1.0, 2.0, 0.4860521657983033, 1.0, 1.0, 0.4860521657983033, 1.0, 1.0, 0.8441118720841736, 6.9112, 6.9112, 170.5573041426782, 2038813.942923142, 2038813.942923142, 405637.4101606821], 
processed observation next is [1.0, 0.34782608695652173, 0.7235387045813588, 0.7766666666666667, 1.0, 1.0, 0.38078574192566667, 1.0, 0.5, 0.38078574192566667, 1.0, 0.5, 0.809892526931919, 0.0, 0.0, 0.8375144448122397, 0.5663372063675395, 0.5663372063675395, 0.6054289703890777], 
reward next is 0.3946, 
noisyNet noise sample is [array([2.019282], dtype=float32), 0.7280932]. 
=============================================
[2019-03-26 21:40:40,497] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.77670350e-19 1.00000000e+00 2.60021827e-18 2.58387892e-14
 1.27036385e-23], sum to 1.0000
[2019-03-26 21:40:40,506] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8035
[2019-03-26 21:40:40,513] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 77.33333333333334, 1.0, 2.0, 0.7423142376266154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1055433.815284891, 1055433.815284892, 232701.0231211197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3738000.0000, 
sim time next is 3738600.0000, 
raw observation next is [27.0, 76.5, 1.0, 2.0, 0.7581051865048776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1068852.72550017, 1068852.72550017, 235174.7294630643], 
processed observation next is [1.0, 0.2608695652173913, 0.4786729857819906, 0.765, 1.0, 1.0, 0.7085604656685272, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2969035348611583, 0.2969035348611583, 0.3510070589000959], 
reward next is 0.6490, 
noisyNet noise sample is [array([0.5454497], dtype=float32), -0.030519783]. 
=============================================
[2019-03-26 21:40:40,857] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 21:40:40,859] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:40:40,859] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:40:40,860] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:40:40,861] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:40:40,861] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:40:40,862] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:40:40,864] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:40:40,865] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:40:40,867] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:40:40,868] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:40:40,894] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run56
[2019-03-26 21:40:40,895] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run56
[2019-03-26 21:40:40,941] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run56
[2019-03-26 21:40:40,959] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run56
[2019-03-26 21:40:40,976] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run56
[2019-03-26 21:40:58,762] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08623674], dtype=float32), 0.06263782]
[2019-03-26 21:40:58,765] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.85, 71.5, 1.0, 2.0, 0.2850245150826354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 461050.5064525169, 461050.5064525163, 164336.7713182959]
[2019-03-26 21:40:58,766] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:40:58,770] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.7484119e-20 1.0000000e+00 1.4728022e-19 4.1408370e-16 6.0360580e-25], sampled 0.0685908624241236
[2019-03-26 21:41:04,045] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08623674], dtype=float32), 0.06263782]
[2019-03-26 21:41:04,049] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.92854687, 58.29713357333333, 1.0, 2.0, 0.4585527560685961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 652317.5938059192, 652317.5938059192, 178847.017060014]
[2019-03-26 21:41:04,049] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:41:04,051] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.3163586e-20 1.0000000e+00 4.8198913e-20 3.6856071e-16 1.9817072e-25], sampled 0.491719894217009
[2019-03-26 21:41:09,446] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08623674], dtype=float32), 0.06263782]
[2019-03-26 21:41:09,448] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.0, 92.0, 1.0, 2.0, 0.3938423498093755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 592707.8376502629, 592707.8376502629, 174012.0430028924]
[2019-03-26 21:41:09,450] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:41:09,454] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.2720583e-21 1.0000000e+00 1.9429526e-20 2.6887544e-16 5.0137907e-26], sampled 0.6631923515660998
[2019-03-26 21:41:25,781] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08623674], dtype=float32), 0.06263782]
[2019-03-26 21:41:25,782] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.9, 85.66666666666667, 1.0, 2.0, 0.5272546475909481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 736769.6589615996, 736769.6589616003, 187975.6571304573]
[2019-03-26 21:41:25,782] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:41:25,784] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.5106785e-21 1.0000000e+00 2.2696967e-20 7.6333836e-16 6.6178127e-26], sampled 0.044383559949372486
[2019-03-26 21:41:30,792] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08623674], dtype=float32), 0.06263782]
[2019-03-26 21:41:30,792] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.9, 57.0, 1.0, 2.0, 0.5225064344145554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730132.3695216742, 730132.3695216742, 187196.8082727306]
[2019-03-26 21:41:30,793] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:41:30,795] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.4863526e-21 1.0000000e+00 2.2778848e-20 5.1842323e-16 9.7242804e-26], sampled 0.6203703046030882
[2019-03-26 21:41:35,223] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08623674], dtype=float32), 0.06263782]
[2019-03-26 21:41:35,224] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.46666666666667, 70.66666666666667, 1.0, 2.0, 0.7155666738942693, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.995791155100795, 6.9112, 168.9123845764277, 1896912.305934782, 1836900.632301754, 388449.9390054462]
[2019-03-26 21:41:35,228] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:41:35,230] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.1757576e-10 9.9985898e-01 1.3282705e-09 1.4105543e-04 3.5990961e-13], sampled 0.40637578812400565
[2019-03-26 21:41:35,231] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1896912.305934782 W.
[2019-03-26 21:42:00,987] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08623674], dtype=float32), 0.06263782]
[2019-03-26 21:42:00,988] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [36.3, 52.0, 1.0, 2.0, 0.8964133751278818, 1.0, 2.0, 0.8964133751278818, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2507252.82103856, 2507252.82103856, 469547.7604301787]
[2019-03-26 21:42:00,990] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:42:00,995] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.3108500e-09 9.4016826e-01 2.7740697e-08 5.9831753e-02 8.6106192e-12], sampled 0.0930854097422682
[2019-03-26 21:42:01,000] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2507252.82103856 W.
[2019-03-26 21:42:08,244] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08623674], dtype=float32), 0.06263782]
[2019-03-26 21:42:08,245] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.02662909333334, 83.004423835, 1.0, 2.0, 0.5806289780837517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 811381.8164353975, 811381.8164353975, 197192.3383919733]
[2019-03-26 21:42:08,247] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:42:08,249] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.8664829e-21 1.0000000e+00 1.5370079e-20 6.8112439e-16 3.0409019e-26], sampled 0.688651871264443
[2019-03-26 21:42:22,594] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08623674], dtype=float32), 0.06263782]
[2019-03-26 21:42:22,595] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.2, 96.0, 1.0, 2.0, 0.9565172646157628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1336985.828242042, 1336985.828242042, 285955.0246124357]
[2019-03-26 21:42:22,598] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:42:22,600] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.10067524e-16 1.00000000e+00 1.48231878e-16 2.39701748e-12
 3.47990926e-21], sampled 0.7400979869388266
[2019-03-26 21:42:35,023] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.7489 3164467322.9939 1774.0000
[2019-03-26 21:42:35,186] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7995.9781 3007694799.5541 1766.0000
[2019-03-26 21:42:35,195] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.8473 2927457511.3295 1338.0000
[2019-03-26 21:42:35,360] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.4953 2779298065.2516 933.0000
[2019-03-26 21:42:35,378] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0344 2842500170.3949 1131.0000
[2019-03-26 21:42:36,394] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1375000, evaluation results [1375000.0, 7883.748880879658, 3164467322.993868, 1774.0, 8252.84734365943, 2927457511.3294744, 1338.0, 8658.49531214752, 2779298065.2516174, 933.0, 7995.978053101541, 3007694799.554066, 1766.0, 8496.034361333246, 2842500170.394918, 1131.0]
[2019-03-26 21:42:48,495] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7065376e-21 1.0000000e+00 7.0919097e-21 2.4178270e-16 1.8802039e-26], sum to 1.0000
[2019-03-26 21:42:48,505] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6027
[2019-03-26 21:42:48,507] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4295640e-20 1.0000000e+00 3.1992961e-20 2.6255779e-16 2.4377367e-25], sum to 1.0000
[2019-03-26 21:42:48,508] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.5, 73.0, 1.0, 2.0, 0.6041539172788504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 844269.0728390906, 844269.0728390906, 201522.530803418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3965400.0000, 
sim time next is 3966000.0000, 
raw observation next is [31.66666666666666, 72.33333333333333, 1.0, 2.0, 0.605403271208467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 846015.6657879984, 846015.665787999, 201757.0875099954], 
processed observation next is [0.0, 0.9130434782608695, 0.6998420221169034, 0.7233333333333333, 1.0, 1.0, 0.5245822544680325, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23500435160777733, 0.23500435160777752, 0.3011299813582021], 
reward next is 0.6989, 
noisyNet noise sample is [array([-0.5417014], dtype=float32), -0.646222]. 
=============================================
[2019-03-26 21:42:48,517] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5251
[2019-03-26 21:42:48,522] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[73.75029]
 [73.74129]
 [73.70403]
 [73.64249]
 [73.56388]], R is [[73.74545288]
 [73.70721436]
 [73.6692276 ]
 [73.62994385]
 [73.59354401]].
[2019-03-26 21:42:48,523] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 87.33333333333334, 1.0, 2.0, 0.5074482523920161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709083.5651957112, 709083.5651957105, 184771.0468655145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4515600.0000, 
sim time next is 4516200.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.5085835229625861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 710670.4678615045, 710670.4678615045, 184951.6564859185], 
processed observation next is [0.0, 0.2608695652173913, 0.4549763033175356, 0.865, 1.0, 1.0, 0.40793195537660976, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19740846329486236, 0.19740846329486236, 0.2760472484864455], 
reward next is 0.7240, 
noisyNet noise sample is [array([1.3058047], dtype=float32), 0.1997451]. 
=============================================
[2019-03-26 21:42:48,865] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3560930e-12 9.9985790e-01 1.5454650e-11 1.4203068e-04 5.3540593e-16], sum to 1.0000
[2019-03-26 21:42:48,874] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5261
[2019-03-26 21:42:48,882] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.33333333333334, 65.66666666666667, 1.0, 2.0, 0.5435444189643169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 759540.6298902467, 759540.6298902467, 190702.9414364648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4383600.0000, 
sim time next is 4384200.0000, 
raw observation next is [32.16666666666666, 66.33333333333333, 1.0, 2.0, 0.5546009538050467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 774996.4983625632, 774996.4983625638, 192595.2098592759], 
processed observation next is [1.0, 0.7391304347826086, 0.7235387045813582, 0.6633333333333333, 1.0, 1.0, 0.4633746431386105, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.215276805100712, 0.21527680510071215, 0.2874555371033969], 
reward next is 0.7125, 
noisyNet noise sample is [array([1.1290386], dtype=float32), -0.48360342]. 
=============================================
[2019-03-26 21:42:49,415] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.4802200e-22 1.0000000e+00 4.4391379e-21 1.0143378e-16 2.2921981e-27], sum to 1.0000
[2019-03-26 21:42:49,423] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2272
[2019-03-26 21:42:49,427] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.16666666666666, 83.16666666666666, 1.0, 2.0, 0.6205568352776938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 867200.5304170754, 867200.5304170754, 204638.3574451312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3973800.0000, 
sim time next is 3974400.0000, 
raw observation next is [30.0, 84.0, 1.0, 2.0, 0.6196818803016998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 865977.3213539168, 865977.3213539174, 204470.1066768142], 
processed observation next is [1.0, 0.0, 0.6208530805687204, 0.84, 1.0, 1.0, 0.5417853979538552, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24054925593164356, 0.24054925593164372, 0.30517926369673765], 
reward next is 0.6948, 
noisyNet noise sample is [array([-1.3217442], dtype=float32), -0.33472845]. 
=============================================
[2019-03-26 21:42:54,568] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2700343e-20 1.0000000e+00 1.3048005e-19 1.5396591e-14 1.3199505e-25], sum to 1.0000
[2019-03-26 21:42:54,574] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0408
[2019-03-26 21:42:54,580] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.6231511112308057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 870827.4017313664, 870827.4017313664, 205138.6838726971], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4320000.0000, 
sim time next is 4320600.0000, 
raw observation next is [30.83333333333334, 79.83333333333334, 1.0, 2.0, 0.6263210589470625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 875259.0952998261, 875259.0952998255, 205752.1866650157], 
processed observation next is [1.0, 0.0, 0.6603475513428123, 0.7983333333333335, 1.0, 1.0, 0.5497844083699548, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24312752647217392, 0.24312752647217376, 0.30709281591793386], 
reward next is 0.6929, 
noisyNet noise sample is [array([1.0020816], dtype=float32), -1.7320025]. 
=============================================
[2019-03-26 21:42:55,942] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.1205532e-09 1.5312723e-02 3.4043392e-08 9.8468727e-01 7.3679240e-12], sum to 1.0000
[2019-03-26 21:42:55,948] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9925
[2019-03-26 21:42:55,953] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.66666666666667, 68.33333333333334, 1.0, 2.0, 0.3083886617554669, 1.0, 2.0, 0.3083886617554669, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 861913.3162742543, 861913.3162742543, 251538.5000548629], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4123200.0000, 
sim time next is 4123800.0000, 
raw observation next is [33.5, 69.0, 1.0, 2.0, 0.3054191406077121, 1.0, 2.0, 0.3054191406077121, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 853610.5194181312, 853610.5194181312, 250952.5416520915], 
processed observation next is [1.0, 0.7391304347826086, 0.7867298578199052, 0.69, 1.0, 1.0, 0.163155591093629, 1.0, 1.0, 0.163155591093629, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.23711403317170313, 0.23711403317170313, 0.37455603231655443], 
reward next is 0.6254, 
noisyNet noise sample is [array([3.8850987], dtype=float32), 0.970674]. 
=============================================
[2019-03-26 21:43:01,548] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.62437552e-21 1.00000000e+00 1.15862865e-20 2.32761530e-16
 1.08289463e-26], sum to 1.0000
[2019-03-26 21:43:01,553] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1866
[2019-03-26 21:43:01,556] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 81.5, 1.0, 2.0, 0.5835800211355796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 815507.2424217336, 815507.2424217336, 197726.8947056104], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4433400.0000, 
sim time next is 4434000.0000, 
raw observation next is [29.66666666666667, 80.66666666666667, 1.0, 2.0, 0.5844406942784548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 816710.4279373143, 816710.4279373143, 197883.1917347989], 
processed observation next is [0.0, 0.30434782608695654, 0.6050552922590839, 0.8066666666666668, 1.0, 1.0, 0.49932613768488526, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22686400776036508, 0.22686400776036508, 0.29534804736537146], 
reward next is 0.7047, 
noisyNet noise sample is [array([-0.00836619], dtype=float32), 0.078427956]. 
=============================================
[2019-03-26 21:43:01,566] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[71.87411]
 [71.87487]
 [71.86579]
 [71.84547]
 [71.82927]], R is [[71.86144257]
 [71.84771729]
 [71.8343811 ]
 [71.82146454]
 [71.80890656]].
[2019-03-26 21:43:11,467] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.9494666e-20 1.0000000e+00 8.3349536e-20 4.3883186e-16 4.9134029e-26], sum to 1.0000
[2019-03-26 21:43:11,475] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9888
[2019-03-26 21:43:11,479] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 85.66666666666667, 1.0, 2.0, 0.4890695399877618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 683393.7833797967, 683393.7833797967, 181900.7411829323], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4508400.0000, 
sim time next is 4509000.0000, 
raw observation next is [26.0, 86.5, 1.0, 2.0, 0.4916380989483277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 686984.0802107382, 686984.0802107382, 182295.9628613867], 
processed observation next is [0.0, 0.17391304347826086, 0.4312796208530806, 0.865, 1.0, 1.0, 0.3875157818654551, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1908289111696495, 0.1908289111696495, 0.27208352665878616], 
reward next is 0.7279, 
noisyNet noise sample is [array([2.279204], dtype=float32), 0.50083464]. 
=============================================
[2019-03-26 21:43:11,494] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[70.94415 ]
 [71.050125]
 [71.19735 ]
 [71.2498  ]
 [71.386604]], R is [[70.84243011]
 [70.86251068]
 [70.88285828]
 [70.9030838 ]
 [70.92211914]].
[2019-03-26 21:43:15,820] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.21535386e-20 1.00000000e+00 9.43879706e-20 9.18499129e-16
 7.20068783e-26], sum to 1.0000
[2019-03-26 21:43:15,830] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8015
[2019-03-26 21:43:15,834] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.0, 51.5, 1.0, 2.0, 0.5282437871637812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738152.332860504, 738152.332860504, 188140.407343605], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4545000.0000, 
sim time next is 4545600.0000, 
raw observation next is [34.0, 52.0, 1.0, 2.0, 0.5316923754061694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 742972.973956, 742972.9739560005, 188711.4153926059], 
processed observation next is [0.0, 0.6086956521739131, 0.8104265402843602, 0.52, 1.0, 1.0, 0.4357739462724933, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20638138165444442, 0.20638138165444458, 0.2816588289441879], 
reward next is 0.7183, 
noisyNet noise sample is [array([1.037641], dtype=float32), 0.9493289]. 
=============================================
[2019-03-26 21:43:16,887] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.19141593e-19 1.00000000e+00 6.53582285e-19 1.16931086e-14
 7.87821137e-25], sum to 1.0000
[2019-03-26 21:43:16,894] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3150
[2019-03-26 21:43:16,898] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6945860471020369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 970700.3330538451, 970700.3330538458, 219677.5756208749], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4765200.0000, 
sim time next is 4765800.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.708105031886024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 989602.2348464536, 989602.2348464536, 222601.007603375], 
processed observation next is [1.0, 0.13043478260869565, 0.4786729857819906, 0.79, 1.0, 1.0, 0.6483193155253302, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.27488950967957043, 0.27488950967957043, 0.3322403098557836], 
reward next is 0.6678, 
noisyNet noise sample is [array([0.8361412], dtype=float32), 0.5570114]. 
=============================================
[2019-03-26 21:43:18,060] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.8339348e-21 1.0000000e+00 6.4021479e-20 2.4108989e-14 7.8659516e-27], sum to 1.0000
[2019-03-26 21:43:18,069] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9387
[2019-03-26 21:43:18,075] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.4916469807593624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 686996.4951066292, 686996.4951066292, 182297.5075026217], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4824600.0000, 
sim time next is 4825200.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.4917798306321272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 687182.1911867269, 687182.1911867263, 182317.988432442], 
processed observation next is [1.0, 0.8695652173913043, 0.5260663507109005, 0.74, 1.0, 1.0, 0.38768654293027377, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19088394199631303, 0.19088394199631287, 0.27211640064543585], 
reward next is 0.7279, 
noisyNet noise sample is [array([-1.1921592], dtype=float32), 0.42496464]. 
=============================================
[2019-03-26 21:43:18,309] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.1674155e-15 1.0000000e+00 4.3666793e-15 5.2173276e-11 5.1658622e-20], sum to 1.0000
[2019-03-26 21:43:18,310] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7877
[2019-03-26 21:43:18,311] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2110689.940516744 W.
[2019-03-26 21:43:18,314] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.83333333333334, 85.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.836591079902609, 6.9112, 168.9080727557776, 2110689.940516744, 1454204.640339447, 311351.6167532798], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4590600.0000, 
sim time next is 4591200.0000, 
raw observation next is [27.66666666666667, 87.33333333333334, 1.0, 2.0, 0.6199977019235015, 1.0, 1.0, 0.6199977019235015, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1733531.411995558, 1733531.411995558, 341758.0542806917], 
processed observation next is [1.0, 0.13043478260869565, 0.5102685624012641, 0.8733333333333334, 1.0, 1.0, 0.5421659059319295, 1.0, 0.5, 0.5421659059319295, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.48153650333209946, 0.48153650333209946, 0.5100866481801369], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.60416156], dtype=float32), -0.46346667]. 
=============================================
[2019-03-26 21:43:22,403] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 21:43:22,405] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:43:22,406] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:43:22,407] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:43:22,408] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:43:22,408] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:43:22,409] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:43:22,409] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:43:22,411] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:43:22,413] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:43:22,412] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:43:22,433] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run57
[2019-03-26 21:43:22,451] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run57
[2019-03-26 21:43:22,469] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run57
[2019-03-26 21:43:22,486] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run57
[2019-03-26 21:43:22,507] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run57
[2019-03-26 21:43:29,457] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0869686], dtype=float32), 0.063423045]
[2019-03-26 21:43:29,457] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [17.55141358833333, 82.54672072833334, 1.0, 2.0, 0.1984260857322282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 331920.9120095365, 331920.9120095359, 144649.2408638663]
[2019-03-26 21:43:29,458] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:43:29,461] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.0157721e-21 1.0000000e+00 1.2195941e-20 1.0625627e-16 3.0213607e-26], sampled 0.6999599876628328
[2019-03-26 21:43:38,519] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0869686], dtype=float32), 0.063423045]
[2019-03-26 21:43:38,521] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.70086586333333, 95.47565069999999, 1.0, 2.0, 0.5144807578823076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 738145.0711114771, 738145.0711114777, 188343.7254724487]
[2019-03-26 21:43:38,522] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:43:38,530] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.7553659e-21 1.0000000e+00 2.8039846e-20 2.1222061e-16 5.8125059e-26], sampled 0.09215349146266527
[2019-03-26 21:43:42,518] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0869686], dtype=float32), 0.063423045]
[2019-03-26 21:43:42,520] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.937147985, 97.97597239999999, 1.0, 2.0, 0.4775756851458438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 671870.740742597, 671870.7407425963, 180742.4242351757]
[2019-03-26 21:43:42,521] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:43:42,523] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.5246723e-21 1.0000000e+00 1.3930062e-20 1.1739130e-16 2.7388967e-26], sampled 0.4185027873404207
[2019-03-26 21:44:04,863] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0869686], dtype=float32), 0.063423045]
[2019-03-26 21:44:04,864] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.53333333333333, 67.83333333333334, 1.0, 2.0, 0.5501857074120904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 768824.4230489734, 768824.4230489734, 191831.8394665512]
[2019-03-26 21:44:04,867] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:44:04,870] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.1263040e-21 1.0000000e+00 1.8713368e-20 4.5290179e-16 6.9336091e-26], sampled 0.6895972211548241
[2019-03-26 21:44:18,232] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0869686], dtype=float32), 0.063423045]
[2019-03-26 21:44:18,235] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [35.0, 56.66666666666667, 1.0, 2.0, 0.9341456396989677, 1.0, 2.0, 0.7876628593637466, 1.0, 1.0, 1.03, 7.005116201589427, 6.9112, 170.5573041426782, 3305674.328041233, 3238398.332575899, 605492.4773824506]
[2019-03-26 21:44:18,236] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:44:18,239] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.3399706e-07 9.2127490e-01 2.1453940e-07 7.8724757e-02 6.3376426e-10], sampled 0.6656214461141287
[2019-03-26 21:44:18,241] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 3305674.328041233 W.
[2019-03-26 21:44:20,636] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0869686], dtype=float32), 0.063423045]
[2019-03-26 21:44:20,636] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.83333333333334, 61.0, 1.0, 2.0, 0.5820174898314836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813322.8916605702, 813322.8916605702, 197442.7890554515]
[2019-03-26 21:44:20,637] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:44:20,640] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.8339012e-22 1.0000000e+00 3.5550478e-21 3.5206159e-16 5.9231436e-27], sampled 0.7648261754932
[2019-03-26 21:44:50,473] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0869686], dtype=float32), 0.063423045]
[2019-03-26 21:44:50,474] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.93333333333333, 83.0, 1.0, 2.0, 0.7029972418040268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 982460.6127035277, 982460.6127035277, 221493.8093798092]
[2019-03-26 21:44:50,474] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:44:50,477] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.5012737e-21 1.0000000e+00 1.5340672e-20 2.5528673e-16 3.0549353e-26], sampled 0.44961730583347315
[2019-03-26 21:44:53,470] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0869686], dtype=float32), 0.063423045]
[2019-03-26 21:44:53,471] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.44008523500001, 76.30308219666667, 1.0, 2.0, 0.4766017010118945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 675312.4995554831, 675312.4995554831, 181211.107939546]
[2019-03-26 21:44:53,473] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:44:53,476] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.2770235e-21 1.0000000e+00 6.7033267e-21 3.1164049e-16 1.4710227e-26], sampled 0.6008111799677385
[2019-03-26 21:45:10,106] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.9447 2927328032.1726 1338.0000
[2019-03-26 21:45:10,136] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4308 2779149198.4617 933.0000
[2019-03-26 21:45:10,143] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0572 2842501283.5234 1131.0000
[2019-03-26 21:45:10,149] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.1786 3007673141.5034 1766.0000
[2019-03-26 21:45:10,315] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7886.1432 3164247243.6115 1774.0000
[2019-03-26 21:45:11,329] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1400000, evaluation results [1400000.0, 7886.143234674578, 3164247243.611454, 1774.0, 8252.944690175233, 2927328032.1725616, 1338.0, 8661.430759135581, 2779149198.4616733, 933.0, 7998.178555504131, 3007673141.5034175, 1766.0, 8496.057156619567, 2842501283.523376, 1131.0]
[2019-03-26 21:45:11,992] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.2536621e-10 9.9991322e-01 6.0184746e-10 8.6736363e-05 4.6464536e-13], sum to 1.0000
[2019-03-26 21:45:12,004] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7012
[2019-03-26 21:45:12,014] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2608439.862430869 W.
[2019-03-26 21:45:12,019] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.33333333333334, 73.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.364504169455659, 6.9112, 168.9107342542745, 2608439.862430869, 2286854.513997095, 475252.0999860935], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4702800.0000, 
sim time next is 4703400.0000, 
raw observation next is [30.5, 72.5, 1.0, 2.0, 0.9141295910176921, 1.0, 1.0, 0.9141295910176921, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2556855.472532397, 2556855.472532398, 479258.3450189958], 
processed observation next is [1.0, 0.43478260869565216, 0.6445497630331753, 0.725, 1.0, 1.0, 0.8965416759249302, 1.0, 0.5, 0.8965416759249302, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7102376312589992, 0.7102376312589994, 0.7153109627149191], 
reward next is 0.2847, 
noisyNet noise sample is [array([-0.33137867], dtype=float32), -0.7775185]. 
=============================================
[2019-03-26 21:45:14,141] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.6637177e-17 1.0000000e+00 3.3886892e-16 3.3059289e-10 1.6973314e-21], sum to 1.0000
[2019-03-26 21:45:14,150] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4747
[2019-03-26 21:45:14,154] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 72.0, 1.0, 2.0, 0.5182711362656339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 724212.0933095437, 724212.0933095431, 186509.159270535], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4732200.0000, 
sim time next is 4732800.0000, 
raw observation next is [29.33333333333334, 72.66666666666666, 1.0, 2.0, 0.5182901086495677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 724238.6136246986, 724238.6136246986, 186512.1054916852], 
processed observation next is [1.0, 0.782608695652174, 0.5892575039494474, 0.7266666666666666, 1.0, 1.0, 0.41962663692719, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20117739267352738, 0.20117739267352738, 0.2783762768532615], 
reward next is 0.7216, 
noisyNet noise sample is [array([0.22083218], dtype=float32), -1.4552605]. 
=============================================
[2019-03-26 21:45:14,350] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2768756e-21 1.0000000e+00 2.5858924e-20 2.2114654e-15 4.8423971e-26], sum to 1.0000
[2019-03-26 21:45:14,360] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2710
[2019-03-26 21:45:14,366] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5156445368819844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 720540.5398331, 720540.5398331007, 186083.7356781453], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4741200.0000, 
sim time next is 4741800.0000, 
raw observation next is [28.0, 79.00000000000001, 1.0, 2.0, 0.5152865481673516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 720040.1315345133, 720040.131534514, 186026.0277832874], 
processed observation next is [1.0, 0.9130434782608695, 0.5260663507109005, 0.7900000000000001, 1.0, 1.0, 0.41600788935825495, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2000111476484759, 0.2000111476484761, 0.27765078773624985], 
reward next is 0.7223, 
noisyNet noise sample is [array([-0.8929174], dtype=float32), 0.12581585]. 
=============================================
[2019-03-26 21:45:15,003] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7889416e-21 1.0000000e+00 5.3489292e-20 2.6414621e-15 1.0567124e-26], sum to 1.0000
[2019-03-26 21:45:15,012] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8065
[2019-03-26 21:45:15,019] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5172390205246137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722769.3639248497, 722769.3639248497, 186341.2278548926], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4738800.0000, 
sim time next is 4739400.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5176297980677346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723315.606932321, 723315.606932321, 186404.4491686033], 
processed observation next is [1.0, 0.8695652173913043, 0.5260663507109005, 0.79, 1.0, 1.0, 0.41883108200931873, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20092100192564472, 0.20092100192564472, 0.2782155957740348], 
reward next is 0.7218, 
noisyNet noise sample is [array([-0.85841066], dtype=float32), 0.6708544]. 
=============================================
[2019-03-26 21:45:20,945] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.6015550e-20 1.0000000e+00 3.8251892e-19 4.6272173e-15 2.0988406e-25], sum to 1.0000
[2019-03-26 21:45:20,954] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4089
[2019-03-26 21:45:20,963] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.83333333333334, 1.0, 2.0, 0.6573587196675788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 918651.7662806674, 918651.7662806674, 211907.3129420844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4849800.0000, 
sim time next is 4850400.0000, 
raw observation next is [27.0, 80.66666666666667, 1.0, 2.0, 0.6177226191331104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 863238.2300704888, 863238.2300704888, 204085.358952211], 
processed observation next is [1.0, 0.13043478260869565, 0.4786729857819906, 0.8066666666666668, 1.0, 1.0, 0.5394248423290487, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23978839724180243, 0.23978839724180243, 0.30460501336150897], 
reward next is 0.6954, 
noisyNet noise sample is [array([-0.7610256], dtype=float32), 0.7225747]. 
=============================================
[2019-03-26 21:45:21,725] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.4341157e-17 1.0000000e+00 2.8440954e-17 6.0475605e-13 8.4653944e-22], sum to 1.0000
[2019-03-26 21:45:21,737] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3427
[2019-03-26 21:45:21,749] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1808603.723828035 W.
[2019-03-26 21:45:21,756] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.83333333333334, 74.83333333333334, 1.0, 2.0, 0.6468246826410453, 1.0, 1.0, 0.6468246826410453, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1808603.723828035, 1808603.723828034, 352187.5675818318], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4870200.0000, 
sim time next is 4870800.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.6767943381885638, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.982147736548567, 6.9112, 168.9125342158584, 1842656.356813855, 1792323.716509205, 380557.8074935816], 
processed observation next is [1.0, 0.391304347826087, 0.5734597156398105, 0.74, 1.0, 1.0, 0.6105955881789925, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.007094773654856734, 0.0, 0.8294378714926238, 0.5118489880038486, 0.49786769903033473, 0.5679967276023606], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.70604765], dtype=float32), 0.21059945]. 
=============================================
[2019-03-26 21:45:22,942] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.2411830e-21 1.0000000e+00 5.7719972e-21 1.5208618e-15 2.9720350e-26], sum to 1.0000
[2019-03-26 21:45:22,950] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0620
[2019-03-26 21:45:22,955] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.6, 81.0, 1.0, 2.0, 0.585524400314107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 818225.4061662189, 818225.4061662189, 198080.1773798122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5439600.0000, 
sim time next is 5440200.0000, 
raw observation next is [29.51666666666667, 81.66666666666667, 1.0, 2.0, 0.5852508628324261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 817843.0113683267, 817843.0113683267, 198030.4800677657], 
processed observation next is [1.0, 1.0, 0.5979462875197474, 0.8166666666666668, 1.0, 1.0, 0.500302244376417, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22717861426897965, 0.22717861426897965, 0.29556788069815776], 
reward next is 0.7044, 
noisyNet noise sample is [array([-1.053817], dtype=float32), -0.17942849]. 
=============================================
[2019-03-26 21:45:24,648] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.8116955e-21 1.0000000e+00 1.8355829e-20 1.5820314e-15 2.6561794e-26], sum to 1.0000
[2019-03-26 21:45:24,660] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2598
[2019-03-26 21:45:24,666] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5093660140353766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 711764.250056138, 711764.2500561386, 185076.5959637272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4924200.0000, 
sim time next is 4924800.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5096187058562838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712117.4681467947, 712117.4681467941, 185116.8829735978], 
processed observation next is [1.0, 0.0, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4091791636822696, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19781040781855408, 0.1978104078185539, 0.2762938551844743], 
reward next is 0.7237, 
noisyNet noise sample is [array([-0.40518558], dtype=float32), 0.293513]. 
=============================================
[2019-03-26 21:45:26,163] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3867423e-12 9.9988115e-01 3.0666563e-11 1.1880904e-04 3.6832857e-16], sum to 1.0000
[2019-03-26 21:45:26,174] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0827
[2019-03-26 21:45:26,177] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.5, 66.5, 1.0, 2.0, 0.4924591315085748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104277, 688131.7109321343, 688131.7109321349, 182425.4557901119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4987800.0000, 
sim time next is 4988400.0000, 
raw observation next is [30.33333333333334, 67.66666666666667, 1.0, 2.0, 0.500553902188531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 699446.5630565452, 699446.5630565452, 183685.0184589372], 
processed observation next is [1.0, 0.7391304347826086, 0.6366508688783573, 0.6766666666666667, 1.0, 1.0, 0.3982577134801578, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19429071196015144, 0.19429071196015144, 0.274156743968563], 
reward next is 0.7258, 
noisyNet noise sample is [array([-1.1588613], dtype=float32), -0.55875224]. 
=============================================
[2019-03-26 21:45:26,383] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.1068896e-20 1.0000000e+00 2.0902258e-19 1.7381779e-15 3.0698199e-25], sum to 1.0000
[2019-03-26 21:45:26,394] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6453
[2019-03-26 21:45:26,402] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.684493244645606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 956589.0518646694, 956589.0518646694, 217531.3911643132], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4939200.0000, 
sim time next is 4939800.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.6460255973272189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 902807.1177020743, 902807.1177020743, 209623.98524625], 
processed observation next is [1.0, 0.17391304347826086, 0.4312796208530806, 0.89, 1.0, 1.0, 0.5735248160568902, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.25077975491724286, 0.25077975491724286, 0.3128716197705224], 
reward next is 0.6871, 
noisyNet noise sample is [array([0.6783683], dtype=float32), 1.4417771]. 
=============================================
[2019-03-26 21:45:33,947] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.6270270e-21 1.0000000e+00 5.5934514e-21 3.0685928e-16 3.2665316e-27], sum to 1.0000
[2019-03-26 21:45:33,954] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6936
[2019-03-26 21:45:33,967] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 70.0, 1.0, 2.0, 0.5292462505008002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 739553.6332888254, 739553.6332888254, 188305.6682446461], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5074200.0000, 
sim time next is 5074800.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.5301177846642534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740771.9149529611, 740771.9149529617, 188449.8289393672], 
processed observation next is [0.0, 0.7391304347826086, 0.6208530805687204, 0.7, 1.0, 1.0, 0.4338768489930764, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20576997637582253, 0.2057699763758227, 0.2812684014020406], 
reward next is 0.7187, 
noisyNet noise sample is [array([-0.883559], dtype=float32), -0.47218546]. 
=============================================
[2019-03-26 21:45:33,985] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.5573249e-21 1.0000000e+00 5.4434288e-21 3.0126521e-16 3.1338524e-27], sum to 1.0000
[2019-03-26 21:45:33,992] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8411
[2019-03-26 21:45:33,998] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 70.0, 1.0, 2.0, 0.5301177846642534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740771.9149529611, 740771.9149529617, 188449.8289393672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5074800.0000, 
sim time next is 5075400.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.5304522940026406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 741239.512132653, 741239.5121326536, 188505.219979638], 
processed observation next is [0.0, 0.7391304347826086, 0.6208530805687204, 0.7, 1.0, 1.0, 0.43427987229233805, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20589986448129252, 0.20589986448129266, 0.2813510745964746], 
reward next is 0.7186, 
noisyNet noise sample is [array([-0.883559], dtype=float32), -0.47218546]. 
=============================================
[2019-03-26 21:45:36,613] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.5953879e-22 1.0000000e+00 1.5314295e-21 4.6097579e-15 1.6032061e-27], sum to 1.0000
[2019-03-26 21:45:36,625] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9169
[2019-03-26 21:45:36,629] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.6238121772107247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 871751.5926885338, 871751.5926885332, 205266.4086801062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5346000.0000, 
sim time next is 5346600.0000, 
raw observation next is [30.9, 79.33333333333334, 1.0, 2.0, 0.6252346842520463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 873740.3048395718, 873740.3048395718, 205541.5433098654], 
processed observation next is [1.0, 0.9130434782608695, 0.6635071090047393, 0.7933333333333334, 1.0, 1.0, 0.5484755231952365, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2427056402332144, 0.2427056402332144, 0.30677842285054535], 
reward next is 0.6932, 
noisyNet noise sample is [array([-1.206114], dtype=float32), 0.32701188]. 
=============================================
[2019-03-26 21:45:37,833] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.1559039e-22 1.0000000e+00 1.0015927e-21 8.2997165e-17 2.2653129e-26], sum to 1.0000
[2019-03-26 21:45:37,842] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1225
[2019-03-26 21:45:37,850] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 70.0, 1.0, 2.0, 0.5205520509824388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 727400.4468327963, 727400.4468327957, 186878.614573153], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5128200.0000, 
sim time next is 5128800.0000, 
raw observation next is [29.66666666666667, 68.66666666666667, 1.0, 2.0, 0.5190657316220347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 725322.8092902369, 725322.8092902362, 186636.9319086387], 
processed observation next is [0.0, 0.34782608695652173, 0.6050552922590839, 0.6866666666666668, 1.0, 1.0, 0.4205611224361864, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20147855813617693, 0.20147855813617674, 0.27856258493826674], 
reward next is 0.7214, 
noisyNet noise sample is [array([1.1779928], dtype=float32), -0.43156844]. 
=============================================
[2019-03-26 21:45:37,973] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.1848610e-21 1.0000000e+00 2.9554246e-20 4.8528699e-16 8.1930083e-26], sum to 1.0000
[2019-03-26 21:45:37,983] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8274
[2019-03-26 21:45:37,991] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.5, 64.5, 1.0, 2.0, 0.5153740946603607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 720162.5068553776, 720162.506855377, 186040.0357613687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5135400.0000, 
sim time next is 5136000.0000, 
raw observation next is [30.66666666666666, 64.0, 1.0, 2.0, 0.5176329147832306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 723319.9635912878, 723319.9635912871, 186405.0226921558], 
processed observation next is [0.0, 0.43478260869565216, 0.6524486571879934, 0.64, 1.0, 1.0, 0.4188348370882296, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20092221210869107, 0.20092221210869088, 0.278216451779337], 
reward next is 0.7218, 
noisyNet noise sample is [array([0.7345555], dtype=float32), -0.18627559]. 
=============================================
[2019-03-26 21:45:38,010] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[72.77322 ]
 [72.77239 ]
 [72.75664 ]
 [72.73601 ]
 [72.716255]], R is [[72.78111267]
 [72.77562714]
 [72.77088928]
 [72.76648712]
 [72.76239014]].
[2019-03-26 21:45:39,829] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2437373e-22 1.0000000e+00 6.3381351e-22 3.1244739e-17 9.4563815e-28], sum to 1.0000
[2019-03-26 21:45:39,842] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5967
[2019-03-26 21:45:39,846] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333334, 74.83333333333334, 1.0, 2.0, 0.5311699439436665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742242.6868791814, 742242.6868791814, 188623.3436413643], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5166600.0000, 
sim time next is 5167200.0000, 
raw observation next is [28.66666666666667, 75.66666666666667, 1.0, 2.0, 0.5249734835066681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733580.9287377773, 733580.9287377767, 187601.2697214166], 
processed observation next is [0.0, 0.8260869565217391, 0.5576619273301741, 0.7566666666666667, 1.0, 1.0, 0.4276788957911663, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20377248020493813, 0.20377248020493796, 0.28000189510659196], 
reward next is 0.7200, 
noisyNet noise sample is [array([-0.63390464], dtype=float32), -0.5592537]. 
=============================================
[2019-03-26 21:45:47,656] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1431717e-18 1.0000000e+00 7.0024553e-18 7.3933311e-14 2.2640810e-23], sum to 1.0000
[2019-03-26 21:45:47,662] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0963
[2019-03-26 21:45:47,666] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666667, 77.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 11.75283424908882, 6.9112, 168.8685647585163, 4889765.386420733, 1455846.114157649, 299196.9234843202], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5300400.0000, 
sim time next is 5301000.0000, 
raw observation next is [31.5, 75.5, 1.0, 2.0, 1.036652154833552, 1.0, 1.0, 0.8389161169310383, 1.0, 1.0, 1.03, 7.005124291892358, 6.9112, 170.5573041426782, 3521077.997828701, 3453796.206950285, 648781.8044736482], 
processed observation next is [1.0, 0.34782608695652173, 0.6919431279620853, 0.755, 1.0, 1.0, 1.0441592226910266, 1.0, 0.5, 0.8059230324470341, 1.0, 0.5, 1.0365853658536586, 0.009392429189235774, 0.0, 0.8375144448122397, 0.9780772216190836, 0.9593878352639681, 0.9683310514532063], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.20753978], dtype=float32), -0.5808916]. 
=============================================
[2019-03-26 21:45:47,683] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[61.035545]
 [62.037846]
 [61.941544]
 [65.14544 ]
 [65.22013 ]], R is [[52.93901825]
 [52.40962982]
 [51.88553238]
 [51.86304092]
 [51.34440994]].
[2019-03-26 21:45:48,303] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.2008596e-09 4.1915843e-01 7.0020931e-08 5.8084154e-01 7.0600800e-12], sum to 1.0000
[2019-03-26 21:45:48,314] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1430
[2019-03-26 21:45:48,324] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2852930.335029153 W.
[2019-03-26 21:45:48,329] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.5, 49.0, 1.0, 2.0, 1.019861854306987, 1.0, 2.0, 1.019861854306987, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2852930.335029153, 2852930.335029153, 541099.8863627198], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5500800.0000, 
sim time next is 5501400.0000, 
raw observation next is [35.36666666666667, 49.33333333333334, 1.0, 2.0, 1.009643713537285, 1.0, 2.0, 1.009643713537285, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2824314.107559268, 2824314.107559269, 534836.5678082221], 
processed observation next is [1.0, 0.6956521739130435, 0.8751974723538705, 0.4933333333333334, 1.0, 1.0, 1.0116189319726328, 1.0, 1.0, 1.0116189319726328, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.784531696544241, 0.7845316965442414, 0.7982635340421226], 
reward next is 0.2017, 
noisyNet noise sample is [array([-0.44268528], dtype=float32), 2.1460423]. 
=============================================
[2019-03-26 21:45:51,249] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8724353e-09 9.8866779e-01 3.7322510e-09 1.1332181e-02 4.5421981e-13], sum to 1.0000
[2019-03-26 21:45:51,258] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6482
[2019-03-26 21:45:51,265] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2415041.406095639 W.
[2019-03-26 21:45:51,270] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.53333333333333, 52.0, 1.0, 2.0, 0.8634770301384399, 1.0, 2.0, 0.8634770301384399, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2415041.406095639, 2415041.406095639, 451950.8522690794], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5586000.0000, 
sim time next is 5586600.0000, 
raw observation next is [33.46666666666666, 52.5, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.529324229199976, 6.9112, 168.9095384319202, 2737104.573157879, 2298594.84451731, 475431.5710872942], 
processed observation next is [1.0, 0.6521739130434783, 0.7851500789889413, 0.525, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.061812422919997626, 0.0, 0.8294231608220115, 0.7603068258771887, 0.6384985679214751, 0.7095993598317824], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8388942], dtype=float32), 0.06861622]. 
=============================================
[2019-03-26 21:45:56,728] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.3742632e-22 1.0000000e+00 5.1090269e-21 1.2911573e-15 1.4105409e-26], sum to 1.0000
[2019-03-26 21:45:56,737] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1261
[2019-03-26 21:45:56,742] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.18333333333334, 84.33333333333334, 1.0, 2.0, 0.5873787972320692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 820817.7848168855, 820817.7848168849, 198418.3753768629], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5442600.0000, 
sim time next is 5443200.0000, 
raw observation next is [29.1, 85.0, 1.0, 2.0, 0.5875141679837166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 821007.0283939315, 821007.0283939309, 198443.1342128485], 
processed observation next is [1.0, 0.0, 0.5781990521327015, 0.85, 1.0, 1.0, 0.5030291180526706, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2280575078872032, 0.22805750788720303, 0.2961837824072366], 
reward next is 0.7038, 
noisyNet noise sample is [array([0.83983153], dtype=float32), -0.17083849]. 
=============================================
[2019-03-26 21:45:57,834] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6831865e-19 1.0000000e+00 5.7707511e-18 9.8279762e-14 4.5107575e-24], sum to 1.0000
[2019-03-26 21:45:57,842] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6315
[2019-03-26 21:45:57,847] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.26666666666667, 79.33333333333334, 1.0, 2.0, 0.9358232013179181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104062, 1308042.582860445, 1308042.582860445, 279986.5684641337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5469600.0000, 
sim time next is 5470200.0000, 
raw observation next is [30.45, 78.5, 1.0, 2.0, 0.9400975065883735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1314020.670704297, 1314020.670704297, 281210.4904184974], 
processed observation next is [1.0, 0.30434782608695654, 0.6421800947867299, 0.785, 1.0, 1.0, 0.9278283211908115, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3650057418623047, 0.3650057418623047, 0.41971714987835435], 
reward next is 0.5803, 
noisyNet noise sample is [array([-0.33410734], dtype=float32), 0.13293505]. 
=============================================
[2019-03-26 21:46:07,282] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 21:46:07,284] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:46:07,284] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:46:07,284] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:46:07,285] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:46:07,286] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:46:07,287] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:46:07,287] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:46:07,285] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:46:07,291] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:46:07,288] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:46:07,318] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run58
[2019-03-26 21:46:07,337] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run58
[2019-03-26 21:46:07,359] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run58
[2019-03-26 21:46:07,359] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run58
[2019-03-26 21:46:07,360] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run58
[2019-03-26 21:46:18,350] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08761801], dtype=float32), 0.06364371]
[2019-03-26 21:46:18,351] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [17.65237719833333, 86.07428733, 1.0, 2.0, 0.2034399489272492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 340175.4968373241, 340175.4968373247, 155543.6978595927]
[2019-03-26 21:46:18,352] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:46:18,354] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.2322481e-21 1.0000000e+00 3.9746513e-21 6.2613708e-17 8.9925929e-27], sampled 0.9859811586572612
[2019-03-26 21:46:27,525] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08761801], dtype=float32), 0.06364371]
[2019-03-26 21:46:27,526] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.99323937, 100.0, 1.0, 2.0, 0.513688999780989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 747531.9927893039, 747531.9927893033, 189521.7590435774]
[2019-03-26 21:46:27,527] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:46:27,530] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.5583008e-21 1.0000000e+00 5.6141015e-21 7.5967202e-17 1.0709320e-26], sampled 0.1724215513920626
[2019-03-26 21:46:33,132] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08761801], dtype=float32), 0.06364371]
[2019-03-26 21:46:33,133] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.08333333333334, 84.33333333333333, 1.0, 2.0, 0.9243969496240806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1292061.873570758, 1292061.873570759, 276735.2945956448]
[2019-03-26 21:46:33,134] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:46:33,136] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.5643795e-20 1.0000000e+00 3.0313908e-20 1.9838956e-15 1.3212805e-25], sampled 0.5173888481566401
[2019-03-26 21:46:39,456] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08761801], dtype=float32), 0.06364371]
[2019-03-26 21:46:39,457] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.36666666666667, 75.33333333333334, 1.0, 2.0, 0.5736805237774774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 801668.2518703135, 801668.251870313, 195945.5078429384]
[2019-03-26 21:46:39,459] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:46:39,465] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.3701126e-22 1.0000000e+00 1.5767908e-21 6.1870549e-17 3.5134185e-27], sampled 0.680753265444246
[2019-03-26 21:46:55,944] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08761801], dtype=float32), 0.06364371]
[2019-03-26 21:46:55,945] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.66666666666667, 65.66666666666667, 1.0, 2.0, 0.5863683956701757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 819405.2798309708, 819405.2798309708, 198234.6409096399]
[2019-03-26 21:46:55,946] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:46:55,949] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.2040338e-22 1.0000000e+00 1.7488741e-21 8.5161381e-17 4.5049215e-27], sampled 0.11154687209334646
[2019-03-26 21:46:56,261] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08761801], dtype=float32), 0.06364371]
[2019-03-26 21:46:56,263] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.22052363833333, 77.36795293166668, 1.0, 2.0, 0.5544159501516707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 774737.8809358594, 774737.8809358594, 192560.8144809414]
[2019-03-26 21:46:56,266] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:46:56,269] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.1776913e-22 1.0000000e+00 6.9819830e-22 4.3471461e-17 1.4286706e-27], sampled 0.9439672910589357
[2019-03-26 21:47:08,723] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08761801], dtype=float32), 0.06364371]
[2019-03-26 21:47:08,724] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.63871918, 87.88542050000001, 1.0, 2.0, 0.6233961145274907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 871169.923924532, 871169.9239245327, 205186.1568314561]
[2019-03-26 21:47:08,726] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:47:08,729] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.72937617e-21 1.00000000e+00 4.07488759e-21 2.32578704e-16
 1.04857294e-26], sampled 0.11483225570873923
[2019-03-26 21:47:14,511] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08761801], dtype=float32), 0.06364371]
[2019-03-26 21:47:14,512] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.91366349, 81.08974592333334, 1.0, 2.0, 0.5346127534275705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 747055.2685972002, 747055.2685972007, 189196.328471801]
[2019-03-26 21:47:14,512] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:47:14,516] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.4443207e-22 1.0000000e+00 1.0842904e-21 6.2105356e-17 2.3644913e-27], sampled 0.33345359998683666
[2019-03-26 21:47:25,976] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08761801], dtype=float32), 0.06364371]
[2019-03-26 21:47:25,976] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.98333333333333, 71.5, 1.0, 2.0, 0.585531005899189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 818234.6405198533, 818234.6405198526, 198080.7393308922]
[2019-03-26 21:47:25,977] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:47:25,979] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.6213506e-19 1.0000000e+00 1.5332732e-18 6.5912640e-13 1.3460311e-24], sampled 0.1016614775721092
[2019-03-26 21:47:57,972] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08761801], dtype=float32), 0.06364371]
[2019-03-26 21:47:57,973] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.63333333333333, 91.33333333333334, 1.0, 2.0, 0.5852324403612141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 831151.5802689774, 831151.5802689774, 199743.1143115084]
[2019-03-26 21:47:57,974] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:47:57,976] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.2370025e-21 1.0000000e+00 8.4910453e-21 9.1046129e-17 1.6802939e-26], sampled 0.7254621359637802
[2019-03-26 21:48:01,236] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2953 3007596012.4260 1766.0000
[2019-03-26 21:48:01,458] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5144 2842492707.2201 1131.0000
[2019-03-26 21:48:01,525] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8656.1801 2779481114.8303 933.0000
[2019-03-26 21:48:01,659] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.1701 3164469851.8135 1776.0000
[2019-03-26 21:48:01,710] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8251.3672 2927466060.9598 1338.0000
[2019-03-26 21:48:02,725] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1425000, evaluation results [1425000.0, 7881.1700524112575, 3164469851.8134804, 1776.0, 8251.367175640993, 2927466060.959789, 1338.0, 8656.18011356307, 2779481114.830308, 933.0, 7998.295259250187, 3007596012.4259605, 1766.0, 8497.514395919725, 2842492707.2200756, 1131.0]
[2019-03-26 21:48:04,524] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7842316e-21 1.0000000e+00 6.1295808e-21 5.7695212e-17 1.3212899e-26], sum to 1.0000
[2019-03-26 21:48:04,534] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6779
[2019-03-26 21:48:04,541] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.46666666666667, 60.0, 1.0, 2.0, 0.551524761842415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 770696.2841701536, 770696.284170153, 192062.6559332326], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5667000.0000, 
sim time next is 5667600.0000, 
raw observation next is [32.43333333333334, 60.00000000000001, 1.0, 2.0, 0.5469084769276154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 764243.2039768497, 764243.2039768504, 191272.2893454655], 
processed observation next is [0.0, 0.6086956521739131, 0.7361769352290681, 0.6000000000000001, 1.0, 1.0, 0.45410659870797027, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21228977888245823, 0.21228977888245842, 0.28548102887382915], 
reward next is 0.7145, 
noisyNet noise sample is [array([0.62220126], dtype=float32), -0.14802285]. 
=============================================
[2019-03-26 21:48:04,555] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.5205534e-21 1.0000000e+00 1.5230991e-20 1.3414597e-15 6.2878119e-27], sum to 1.0000
[2019-03-26 21:48:04,563] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0451
[2019-03-26 21:48:04,568] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 86.33333333333334, 1.0, 2.0, 0.528573020536152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738612.5538424747, 738612.5538424747, 188194.0872299482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6211200.0000, 
sim time next is 6211800.0000, 
raw observation next is [27.15, 86.5, 1.0, 2.0, 0.5278203877085342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 737560.481508499, 737560.4815084997, 188069.856583729], 
processed observation next is [1.0, 0.9130434782608695, 0.485781990521327, 0.865, 1.0, 1.0, 0.43110890085365566, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20487791153013862, 0.20487791153013882, 0.2807012784831776], 
reward next is 0.7193, 
noisyNet noise sample is [array([2.2338402], dtype=float32), 2.270911]. 
=============================================
[2019-03-26 21:48:05,124] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5016147e-21 1.0000000e+00 2.5630102e-20 1.4897797e-15 2.5190640e-26], sum to 1.0000
[2019-03-26 21:48:05,133] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4726
[2019-03-26 21:48:05,138] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.76666666666667, 87.0, 1.0, 2.0, 0.5567330500304989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777976.9696666499, 777976.9696666499, 192961.9888492085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5865600.0000, 
sim time next is 5866200.0000, 
raw observation next is [27.7, 87.0, 1.0, 2.0, 0.5536812715813269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 773710.871128941, 773710.871128941, 192433.9467760243], 
processed observation next is [1.0, 0.9130434782608695, 0.5118483412322274, 0.87, 1.0, 1.0, 0.46226659226665884, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21491968642470582, 0.21491968642470582, 0.28721484593436464], 
reward next is 0.7128, 
noisyNet noise sample is [array([-0.58217955], dtype=float32), 1.4237242]. 
=============================================
[2019-03-26 21:48:09,423] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.0538897e-22 1.0000000e+00 1.7046573e-21 3.8420399e-17 1.5622500e-26], sum to 1.0000
[2019-03-26 21:48:09,432] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1076
[2019-03-26 21:48:09,438] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333333, 88.83333333333334, 1.0, 2.0, 0.5379146463188768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 751670.888473976, 751670.8884739766, 189749.3929585985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5791800.0000, 
sim time next is 5792400.0000, 
raw observation next is [26.9, 89.0, 1.0, 2.0, 0.5372087543229461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 750684.140932508, 750684.1409325086, 189630.9578230292], 
processed observation next is [1.0, 0.043478260869565216, 0.4739336492890995, 0.89, 1.0, 1.0, 0.44242018593126037, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20852337248125224, 0.20852337248125238, 0.2830312803328794], 
reward next is 0.7170, 
noisyNet noise sample is [array([-0.7467367], dtype=float32), 0.30591357]. 
=============================================
[2019-03-26 21:48:10,508] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.7688808e-21 1.0000000e+00 1.5067276e-20 1.0444111e-15 2.0502122e-26], sum to 1.0000
[2019-03-26 21:48:10,516] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5063
[2019-03-26 21:48:10,521] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.93333333333334, 87.0, 1.0, 2.0, 0.5608901216826657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 783788.1914569404, 783788.191456941, 193685.9157795505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5952000.0000, 
sim time next is 5952600.0000, 
raw observation next is [27.85, 87.5, 1.0, 2.0, 0.5594376765184098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 781757.7968147881, 781757.7968147881, 193432.5290155013], 
processed observation next is [1.0, 0.9130434782608695, 0.5189573459715641, 0.875, 1.0, 1.0, 0.4692020199016985, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21715494355966336, 0.21715494355966336, 0.2887052671873154], 
reward next is 0.7113, 
noisyNet noise sample is [array([0.12103814], dtype=float32), -1.2240093]. 
=============================================
[2019-03-26 21:48:12,681] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.2733809e-22 1.0000000e+00 8.4465925e-21 2.3162412e-17 1.2905395e-26], sum to 1.0000
[2019-03-26 21:48:12,687] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6415
[2019-03-26 21:48:12,692] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333334, 63.0, 1.0, 2.0, 0.561503829226798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 784646.1035036643, 784646.1035036643, 193792.5561376019], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6351000.0000, 
sim time next is 6351600.0000, 
raw observation next is [31.66666666666667, 63.00000000000001, 1.0, 2.0, 0.5446081712998979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 761027.6335776714, 761027.633577672, 190880.4809788294], 
processed observation next is [0.0, 0.5217391304347826, 0.6998420221169038, 0.6300000000000001, 1.0, 1.0, 0.4513351461444553, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2113965648826865, 0.21139656488268666, 0.2848962402669096], 
reward next is 0.7151, 
noisyNet noise sample is [array([0.07582276], dtype=float32), 1.5841739]. 
=============================================
[2019-03-26 21:48:16,349] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.7512691e-20 1.0000000e+00 4.7064116e-18 1.5047182e-11 1.1330531e-23], sum to 1.0000
[2019-03-26 21:48:16,360] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8736
[2019-03-26 21:48:16,364] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 75.66666666666667, 1.0, 2.0, 0.5579658161244295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779700.265294291, 779700.265294291, 193177.157757118], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5856000.0000, 
sim time next is 5856600.0000, 
raw observation next is [29.8, 76.83333333333333, 1.0, 2.0, 0.5583851429277124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780286.446919334, 780286.446919334, 193250.050459017], 
processed observation next is [1.0, 0.782608695652174, 0.6113744075829385, 0.7683333333333333, 1.0, 1.0, 0.4679339071418221, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21674623525537057, 0.21674623525537057, 0.2884329111328612], 
reward next is 0.7116, 
noisyNet noise sample is [array([-1.6761053], dtype=float32), -0.96214974]. 
=============================================
[2019-03-26 21:48:24,109] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9747018e-20 1.0000000e+00 8.0659506e-20 2.1020723e-15 2.7270234e-25], sum to 1.0000
[2019-03-26 21:48:24,118] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1063
[2019-03-26 21:48:24,123] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.95, 86.5, 1.0, 2.0, 0.7215532050365911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1008405.463406446, 1008405.463406446, 225567.9730546769], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5987400.0000, 
sim time next is 5988000.0000, 
raw observation next is [28.1, 86.0, 1.0, 2.0, 0.7260829362993917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1014739.006210879, 1014739.00621088, 226577.8577497597], 
processed observation next is [1.0, 0.30434782608695654, 0.5308056872037916, 0.86, 1.0, 1.0, 0.6699794413245683, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2818719461696886, 0.2818719461696889, 0.3381759070891936], 
reward next is 0.6618, 
noisyNet noise sample is [array([-1.514498], dtype=float32), -1.3185301]. 
=============================================
[2019-03-26 21:48:24,135] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[67.33843 ]
 [67.279236]
 [67.247475]
 [67.34944 ]
 [67.46392 ]], R is [[67.32678986]
 [67.31685638]
 [67.30060577]
 [67.27347565]
 [67.25357819]].
[2019-03-26 21:48:27,786] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.9966271e-10 9.9999452e-01 1.9669197e-10 5.4849934e-06 9.2424332e-14], sum to 1.0000
[2019-03-26 21:48:27,795] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1773
[2019-03-26 21:48:27,806] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2019078.728238197 W.
[2019-03-26 21:48:27,814] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.1, 74.0, 1.0, 2.0, 0.8028618742387844, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.985070802802207, 6.9112, 168.9125165924237, 2019078.728238197, 1966672.374781298, 409307.7760137274], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6602400.0000, 
sim time next is 6603000.0000, 
raw observation next is [29.26666666666667, 73.16666666666667, 1.0, 2.0, 0.8516222205635412, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.983003480018635, 6.9112, 168.9124692335083, 2087323.164567308, 2036383.451507381, 421823.3598456293], 
processed observation next is [1.0, 0.43478260869565216, 0.5860979462875199, 0.7316666666666667, 1.0, 1.0, 0.8212315910404111, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007180348001863468, 0.0, 0.8294375523995359, 0.5798119901575856, 0.5656620698631614, 0.6295871042472079], 
reward next is 0.0114, 
noisyNet noise sample is [array([-0.09314965], dtype=float32), 0.32700992]. 
=============================================
[2019-03-26 21:48:27,842] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[34.034393]
 [35.713783]
 [39.444527]
 [43.52005 ]
 [45.10679 ]], R is [[32.55627823]
 [32.25045395]
 [32.3368721 ]
 [32.43333435]
 [32.585392  ]].
[2019-03-26 21:48:33,085] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1093839e-21 1.0000000e+00 1.8774216e-20 6.3723861e-16 3.5745254e-26], sum to 1.0000
[2019-03-26 21:48:33,095] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0543
[2019-03-26 21:48:33,102] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.06666666666667, 89.16666666666667, 1.0, 2.0, 0.537561471824019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 751177.1951789671, 751177.1951789678, 189690.614403418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6135000.0000, 
sim time next is 6135600.0000, 
raw observation next is [27.03333333333333, 89.33333333333334, 1.0, 2.0, 0.5369403903072633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 750309.002293081, 750309.002293081, 189586.4630404996], 
processed observation next is [1.0, 0.0, 0.48025276461295413, 0.8933333333333334, 1.0, 1.0, 0.4420968557918834, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2084191673036336, 0.2084191673036336, 0.2829648702097009], 
reward next is 0.7170, 
noisyNet noise sample is [array([1.1314055], dtype=float32), -0.58069754]. 
=============================================
[2019-03-26 21:48:40,620] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.0921942e-21 1.0000000e+00 9.8805361e-20 2.9371011e-15 1.9373228e-25], sum to 1.0000
[2019-03-26 21:48:40,631] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0626
[2019-03-26 21:48:40,640] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.21666666666667, 66.16666666666667, 1.0, 2.0, 0.3277187477992832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 514768.4370488538, 514768.4370488538, 168076.9358525724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6817800.0000, 
sim time next is 6818400.0000, 
raw observation next is [25.1, 67.0, 1.0, 2.0, 0.3282635290664391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515354.9726420644, 515354.9726420644, 168116.2032777758], 
processed observation next is [1.0, 0.9565217391304348, 0.38862559241706174, 0.67, 1.0, 1.0, 0.19067895068245672, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1431541590672401, 0.1431541590672401, 0.25091970638474004], 
reward next is 0.7491, 
noisyNet noise sample is [array([0.09961744], dtype=float32), -0.40093553]. 
=============================================
[2019-03-26 21:48:41,190] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9938350e-22 1.0000000e+00 2.6178703e-21 6.1320255e-17 1.6738380e-27], sum to 1.0000
[2019-03-26 21:48:41,203] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0152
[2019-03-26 21:48:41,209] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.86666666666667, 62.66666666666666, 1.0, 2.0, 0.5167895115338861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722141.0243194941, 722141.0243194941, 186268.4968835686], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6270000.0000, 
sim time next is 6270600.0000, 
raw observation next is [30.88333333333333, 62.33333333333334, 1.0, 2.0, 0.5146297733259568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 719122.070858105, 719122.0708581056, 185920.072765458], 
processed observation next is [0.0, 0.5652173913043478, 0.6627172195892573, 0.6233333333333334, 1.0, 1.0, 0.4152165943686227, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19975613079391805, 0.1997561307939182, 0.277492645918594], 
reward next is 0.7225, 
noisyNet noise sample is [array([0.22825433], dtype=float32), 0.43001407]. 
=============================================
[2019-03-26 21:48:41,673] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.0645311e-21 1.0000000e+00 2.5836838e-20 2.1621249e-15 3.7902135e-26], sum to 1.0000
[2019-03-26 21:48:41,681] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5601
[2019-03-26 21:48:41,685] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.4, 84.33333333333334, 1.0, 2.0, 0.5257489392812211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 734664.9002209393, 734664.9002209399, 187728.8035180014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6474000.0000, 
sim time next is 6474600.0000, 
raw observation next is [27.35, 85.0, 1.0, 2.0, 0.5270079968073125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 736424.87716059, 736424.8771605907, 187935.9629441486], 
processed observation next is [1.0, 0.9565217391304348, 0.4952606635071091, 0.85, 1.0, 1.0, 0.4301301166353162, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20456246587794166, 0.20456246587794186, 0.28050143723007254], 
reward next is 0.7195, 
noisyNet noise sample is [array([-2.046802], dtype=float32), -1.3756441]. 
=============================================
[2019-03-26 21:48:43,321] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.0174147e-23 1.0000000e+00 8.1720492e-22 6.0824959e-17 8.4174203e-28], sum to 1.0000
[2019-03-26 21:48:43,329] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3594
[2019-03-26 21:48:43,333] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.1, 80.66666666666666, 1.0, 2.0, 0.5301681045499398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740842.2550885848, 740842.2550885843, 188457.8951091644], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6291600.0000, 
sim time next is 6292200.0000, 
raw observation next is [27.95, 81.83333333333334, 1.0, 2.0, 0.5317184949596887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 743009.485499889, 743009.4854998883, 188715.0068130046], 
processed observation next is [0.0, 0.8260869565217391, 0.523696682464455, 0.8183333333333335, 1.0, 1.0, 0.43580541561408276, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20639152374996916, 0.20639152374996897, 0.2816641892731412], 
reward next is 0.7183, 
noisyNet noise sample is [array([0.1483366], dtype=float32), -1.3145583]. 
=============================================
[2019-03-26 21:48:43,691] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9386658e-20 1.0000000e+00 6.5008835e-20 3.4690912e-15 2.3550597e-25], sum to 1.0000
[2019-03-26 21:48:43,702] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0050
[2019-03-26 21:48:43,708] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.41666666666667, 85.16666666666667, 1.0, 2.0, 0.9250014301611457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1292907.291572742, 1292907.291572741, 276907.1900368137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6509400.0000, 
sim time next is 6510000.0000, 
raw observation next is [27.63333333333334, 83.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.631521474754371, 6.9112, 168.9093597728707, 1965114.921603189, 1454104.957251263, 311350.1458003531], 
processed observation next is [1.0, 0.34782608695652173, 0.5086887835703005, 0.8333333333333335, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.07203214747543711, 0.0, 0.8294222835242879, 0.5458652560008859, 0.4039180436809064, 0.46470171014978073], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2389194], dtype=float32), -1.5408614]. 
=============================================
[2019-03-26 21:48:43,726] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.09243 ]
 [68.18045 ]
 [68.19586 ]
 [68.21486 ]
 [68.184784]], R is [[67.06571198]
 [66.98176575]
 [66.9547348 ]
 [66.9683609 ]
 [66.97901917]].
[2019-03-26 21:48:44,584] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0963236e-21 1.0000000e+00 2.6330837e-21 3.4133118e-17 8.3604311e-27], sum to 1.0000
[2019-03-26 21:48:44,588] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8028
[2019-03-26 21:48:44,595] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 80.33333333333333, 1.0, 2.0, 0.522397246669101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 729979.7419275157, 729979.7419275151, 187179.6792625401], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6333000.0000, 
sim time next is 6333600.0000, 
raw observation next is [28.0, 79.66666666666667, 1.0, 2.0, 0.5220100882952503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729438.5545294686, 729438.5545294686, 187116.4846361777], 
processed observation next is [0.0, 0.30434782608695654, 0.5260663507109005, 0.7966666666666667, 1.0, 1.0, 0.4241085401147594, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20262182070263018, 0.20262182070263018, 0.27927833527787715], 
reward next is 0.7207, 
noisyNet noise sample is [array([-0.90982395], dtype=float32), -1.1525056]. 
=============================================
