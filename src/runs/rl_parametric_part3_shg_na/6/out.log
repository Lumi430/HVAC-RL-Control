Using TensorFlow backend.
[2019-03-26 19:03:08,870] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='linear', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Shg-Train-v1', eval_act_func='part3_shg_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=5e-06, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[19, 1], model_type='nn', num_threads=16, output='./Part3-NA-Shg-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Shg-Test-v1', 'Part3-NA-Shg-Test-v2', 'Part3-NA-Shg-Test-v3', 'Part3-NA-Shg-Test-v4'], test_mode='Multiple', train_act_func='part3_shg_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=29)
[2019-03-26 19:03:08,871] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-26 19:03:08.904754: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-26 19:03:26,090] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-26 19:03:26,090] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Shg-Train-v1', 'Part3-NA-Shg-Test-v1', 'Part3-NA-Shg-Test-v2', 'Part3-NA-Shg-Test-v3', 'Part3-NA-Shg-Test-v4'] ...
[2019-03-26 19:03:26,100] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation worker starts!
[2019-03-26 19:03:26,105] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation worker starts!
[2019-03-26 19:03:26,110] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation worker starts!
[2019-03-26 19:03:26,115] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation worker starts!
[2019-03-26 19:03:26,118] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation worker starts!
[2019-03-26 19:03:26,118] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:26,118] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-26 19:03:26,172] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:26,173] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run1
[2019-03-26 19:03:27,119] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:27,121] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-26 19:03:27,208] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:27,208] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run1
[2019-03-26 19:03:27,398] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 19:03:27,399] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:03:27,399] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:03:27,400] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:27,400] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:03:27,400] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:27,401] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:03:27,401] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:03:27,401] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:27,402] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:27,401] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:27,405] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run1
[2019-03-26 19:03:27,412] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run1
[2019-03-26 19:03:27,413] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run1
[2019-03-26 19:03:27,431] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run1
[2019-03-26 19:03:27,439] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run1
[2019-03-26 19:03:28,122] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:28,124] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-26 19:03:28,202] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:28,203] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run1
[2019-03-26 19:03:29,125] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:29,131] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-26 19:03:29,188] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:29,189] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run1
[2019-03-26 19:03:30,130] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:30,135] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-26 19:03:30,190] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:30,192] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run1
[2019-03-26 19:03:31,134] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:31,140] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-26 19:03:31,198] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:31,199] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run1
[2019-03-26 19:03:32,140] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:32,146] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-26 19:03:32,207] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:32,208] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run1
[2019-03-26 19:03:32,847] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:03:32,850] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.043454935, 76.345169215, 1.0, 2.0, 0.1932606799572578, 1.0, 2.0, 0.1932606799572578, 0.0, 1.0, 0.0, 6.9112, 6.9112, 171.5212843490159, 576492.608630164, 576492.608630164, 238976.7888216684]
[2019-03-26 19:03:32,852] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:03:32,854] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.3493895  0.05616868 0.26718083 0.12049624 0.20676482], sampled 0.6730808118273379
[2019-03-26 19:03:33,143] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:33,147] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-26 19:03:33,204] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:33,205] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run1
[2019-03-26 19:03:34,147] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:34,150] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-26 19:03:34,205] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:34,206] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run1
[2019-03-26 19:03:35,151] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:35,152] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-26 19:03:35,242] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:35,242] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run1
[2019-03-26 19:03:35,605] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:03:35,606] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.18842945666667, 72.87171755666667, 1.0, 1.0, 0.17, 1.0, 1.0, 0.17, 1.0, 2.0, 0.18, 6.911200000000001, 6.9112, 184.5923449428631, 423878.3050479115, 423878.3050479108, 219184.2707636857]
[2019-03-26 19:03:35,607] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:03:35,611] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.18934318 0.04818379 0.4538049  0.12988633 0.17878188], sampled 0.11506482711735855
[2019-03-26 19:03:36,153] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:36,157] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-26 19:03:36,213] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:36,215] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run1
[2019-03-26 19:03:37,158] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:37,161] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-26 19:03:37,263] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:37,264] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run1
[2019-03-26 19:03:38,163] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:38,169] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-26 19:03:38,256] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:38,258] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run1
[2019-03-26 19:03:39,168] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:39,172] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-26 19:03:39,228] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:39,229] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run1
[2019-03-26 19:03:40,172] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:40,175] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-26 19:03:40,235] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:40,236] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run1
[2019-03-26 19:03:41,175] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 19:03:41,179] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-26 19:03:41,238] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:41,239] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run1
[2019-03-26 19:03:42,422] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.13617662 0.17334475 0.19868997 0.23414966 0.25763896], sum to 1.0000
[2019-03-26 19:03:42,423] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9858
[2019-03-26 19:03:42,498] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.3, 89.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2061999732655149, 6.911200000000001, 6.9112, 170.5573041426782, 535887.6784477276, 535887.6784477269, 235515.6743966998], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 0.0000, 
sim time next is 600.0000, 
raw observation next is [21.95, 88.16666666666667, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2014978073796613, 6.9112, 6.9112, 170.5573041426782, 525509.9952246582, 525509.9952246582, 233898.4183255517], 
processed observation next is [1.0, 0.0, 0.2393364928909953, 0.8816666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.026216838267879645, 0.0, 0.0, 0.8375144448122397, 0.14597499867351615, 0.14597499867351615, 0.3491021169038085], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.10971364], dtype=float32), 0.004678865]. 
=============================================
[2019-03-26 19:04:11,034] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:04:11,035] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.66666666666667, 96.0, 1.0, 2.0, 0.17, 1.0, 1.0, 0.17, 1.0, 2.0, 0.2279225535585934, 6.911200000000001, 6.9112, 170.5573041426782, 584257.5596722799, 584257.5596722792, 242792.7472378796]
[2019-03-26 19:04:11,037] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:04:11,039] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.31099546 0.02637459 0.28145462 0.20106639 0.18010902], sampled 0.10136506430039727
[2019-03-26 19:04:18,463] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:04:18,463] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.4, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.01735537771074, 6.911200000000001, 6.9112, 168.912841376484, 819155.3815513499, 819155.3815513493, 251508.5559178342]
[2019-03-26 19:04:18,464] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:04:18,465] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.26275766 0.03296933 0.29318637 0.13345562 0.277631  ], sampled 0.7962377880533587
[2019-03-26 19:04:28,240] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:04:28,241] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [35.0, 56.0, 1.0, 2.0, 0.3022282267638391, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5248704814868965, 6.9112, 6.9112, 168.912956510431, 844692.0173203994, 844692.0173203994, 222682.0185678745]
[2019-03-26 19:04:28,242] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:04:28,244] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.30441177 0.03144247 0.31150758 0.16829415 0.18434408], sampled 0.10985532052538627
[2019-03-26 19:04:39,141] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:04:39,142] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.421581615, 85.547961115, 1.0, 2.0, 0.2345268315418887, 1.0, 2.0, 0.2345268315418887, 0.0, 1.0, 0.0, 6.9112, 6.9112, 172.86236624, 657925.5152850494, 657925.5152850494, 239353.7732999047]
[2019-03-26 19:04:39,143] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:04:39,146] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.37574178 0.03117302 0.24985543 0.11585367 0.2273761 ], sampled 0.4383466787972349
[2019-03-26 19:04:43,780] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:04:43,783] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.66666666666667, 65.33333333333334, 1.0, 2.0, 0.17, 1.0, 1.0, 0.17, 1.0, 2.0, 0.2838351168043002, 6.9112, 6.9112, 170.5573041426782, 696870.954764058, 696870.954764058, 259617.7451051596]
[2019-03-26 19:04:43,785] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:04:43,788] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.36205158 0.03655883 0.2992262  0.0561734  0.24599   ], sampled 0.2868754064692809
[2019-03-26 19:05:07,518] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:05:07,519] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.41666666666666, 60.5, 1.0, 2.0, 0.5657232185117502, 1.0, 1.0, 0.5657232185117502, 1.0, 2.0, 0.9705462912869911, 6.9112, 6.9112, 170.5573041426782, 2373350.153508206, 2373350.153508206, 461086.0098507075]
[2019-03-26 19:05:07,519] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:05:07,522] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.54091877 0.00880077 0.2266839  0.09519111 0.12840548], sampled 0.7057681341831169
[2019-03-26 19:05:12,636] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 19:05:12,637] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.8, 94.66666666666666, 1.0, 2.0, 0.2650075586924859, 1.0, 2.0, 0.2650075586924859, 0.0, 1.0, 0.0, 6.9112, 6.9112, 172.86236624, 740622.5015235187, 740622.5015235187, 243957.5134153714]
[2019-03-26 19:05:12,638] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:05:12,640] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.2151837  0.01651797 0.2370728  0.3256554  0.20557012], sampled 0.5423594415998014
[2019-03-26 19:05:26,100] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 3713.7671 3305900940.3303 1019.0000
[2019-03-26 19:05:26,287] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 3685.6271 3179370089.8050 752.0000
[2019-03-26 19:05:26,307] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 3605.9546 3361035482.9674 1381.0000
[2019-03-26 19:05:26,312] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 3597.2711 3509105056.6804 1469.0000
[2019-03-26 19:05:26,415] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 3667.6344 3212437603.7918 883.0000
[2019-03-26 19:05:27,430] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 3597.271076560201, 3509105056.6804333, 1469.0, 3713.767103582124, 3305900940.3302994, 1019.0, 3685.6270645076092, 3179370089.8049545, 752.0, 3605.9545705277974, 3361035482.9673758, 1381.0, 3667.634380807916, 3212437603.7917557, 883.0]
[2019-03-26 19:05:27,498] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.20238549 0.13663988 0.2562452  0.22353724 0.18119219], sum to 1.0000
[2019-03-26 19:05:27,501] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3899
[2019-03-26 19:05:27,608] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.25, 86.5, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 1.0, 0.1873378713061431, 6.911200000000001, 6.9112, 170.5573041426782, 492964.2798343205, 492964.2798343198, 228862.5650552935], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1800.0000, 
sim time next is 2400.0000, 
raw observation next is [20.9, 85.66666666666667, 1.0, 2.0, 0.17, 0.0, 1.0, 0.0, 1.0, 2.0, 0.2689366614452952, 6.9112, 6.9112, 168.912956510431, 474714.5483896466, 474714.5483896466, 187049.8907572855], 
processed observation next is [1.0, 0.0, 0.1895734597156398, 0.8566666666666667, 1.0, 1.0, 0.0, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.10845934322596977, 0.0, 0.0, 0.8294399451523027, 0.13186515233045737, 0.13186515233045737, 0.2791789414287843], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.12385303], dtype=float32), -0.18089195]. 
=============================================
[2019-03-26 19:05:30,803] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.36461216 0.00840882 0.40737176 0.0956273  0.12397999], sum to 1.0000
[2019-03-26 19:05:30,812] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9545
[2019-03-26 19:05:30,913] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.86666666666667, 84.66666666666667, 1.0, 2.0, 0.1797626411524613, 0.0, 1.0, 0.0, 1.0, 2.0, 0.3250123264908784, 6.9112, 6.9112, 168.912956510431, 569967.856636187, 569967.856636187, 197868.1470504054], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 24000.0000, 
sim time next is 24600.0000, 
raw observation next is [21.93333333333334, 84.33333333333333, 1.0, 2.0, 0.17, 1.0, 1.0, 0.17, 1.0, 2.0, 0.2154305864928921, 6.911199999999999, 6.9112, 170.5573041426782, 565415.7288318975, 565415.7288318981, 239030.1772545824], 
processed observation next is [1.0, 0.2608695652173913, 0.23854660347551382, 0.8433333333333333, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.043208032308404996, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.15705992467552707, 0.15705992467552723, 0.35676145858892894], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6560114], dtype=float32), 2.2457104]. 
=============================================
[2019-03-26 19:05:31,273] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.27634725 0.0356736  0.37411374 0.12154908 0.19231626], sum to 1.0000
[2019-03-26 19:05:31,281] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5070
[2019-03-26 19:05:31,286] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.51666666666667, 83.0, 1.0, 1.0, 0.1788987962172246, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3220198529766282, 6.9112, 6.9112, 168.912956510431, 562941.8508880638, 562941.8508880638, 197367.6821839887], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 29400.0000, 
sim time next is 30000.0000, 
raw observation next is [22.73333333333333, 82.0, 1.0, 2.0, 0.2721449769944146, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4890267430144132, 6.911199999999999, 6.9112, 168.912956510431, 854020.5062737424, 854020.5062737431, 221649.061016318], 
processed observation next is [1.0, 0.34782608695652173, 0.27646129541864134, 0.82, 1.0, 1.0, 0.12306623734266817, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3768618817248941, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2372279184093729, 0.2372279184093731, 0.33081949405420596], 
reward next is 0.6692, 
noisyNet noise sample is [array([-0.7550399], dtype=float32), 0.5863071]. 
=============================================
[2019-03-26 19:05:31,304] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-1.7841644]
 [-2.7233658]
 [-2.010471 ]
 [-2.467718 ]
 [-2.1519742]], R is [[-1.55273998]
 [-1.53721261]
 [-0.76845491]
 [-0.05311036]
 [-0.05257926]].
[2019-03-26 19:05:46,752] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 7922: loss -3.0075
[2019-03-26 19:05:46,812] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 7922: learning rate 0.0000
[2019-03-26 19:05:46,832] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7936: loss 10.1072
[2019-03-26 19:05:46,838] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 7939: learning rate 0.0000
[2019-03-26 19:05:46,838] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 7939: loss 7.4644
[2019-03-26 19:05:46,842] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 7940: learning rate 0.0000
[2019-03-26 19:05:46,855] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7948: loss 1.1754
[2019-03-26 19:05:46,858] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7949: learning rate 0.0000
[2019-03-26 19:05:46,865] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7952: loss 7.6062
[2019-03-26 19:05:46,869] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 7955: learning rate 0.0000
[2019-03-26 19:05:46,897] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 7965: loss 2.6963
[2019-03-26 19:05:46,900] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 7967: learning rate 0.0000
[2019-03-26 19:05:46,925] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7977: loss 6.2902
[2019-03-26 19:05:46,928] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 7979: learning rate 0.0000
[2019-03-26 19:05:46,940] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 7982: loss 1.9891
[2019-03-26 19:05:46,942] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 7982: learning rate 0.0000
[2019-03-26 19:05:46,957] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 7993: loss 1.6006
[2019-03-26 19:05:46,962] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 7995: loss 0.4579
[2019-03-26 19:05:46,963] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 7994: learning rate 0.0000
[2019-03-26 19:05:46,967] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 7998: learning rate 0.0000
[2019-03-26 19:05:46,974] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7999: loss 0.9157
[2019-03-26 19:05:46,977] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 7999: learning rate 0.0000
[2019-03-26 19:05:46,993] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 8008: loss 8.6509
[2019-03-26 19:05:46,993] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 8008: loss -3.4138
[2019-03-26 19:05:46,994] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 8008: learning rate 0.0000
[2019-03-26 19:05:46,995] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 8008: learning rate 0.0000
[2019-03-26 19:05:47,019] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 8020: loss 2.8534
[2019-03-26 19:05:47,022] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 8021: learning rate 0.0000
[2019-03-26 19:05:47,058] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 8036: loss 0.1554
[2019-03-26 19:05:47,061] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 8037: learning rate 0.0000
[2019-03-26 19:05:47,265] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 8132: loss 7.2285
[2019-03-26 19:05:47,270] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 8133: learning rate 0.0000
[2019-03-26 19:05:49,961] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.3014036  0.14557053 0.18615232 0.22027385 0.14659968], sum to 1.0000
[2019-03-26 19:05:49,969] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0222
[2019-03-26 19:05:50,075] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.3, 87.0, 1.0, 2.0, 0.17, 0.0, 1.0, 0.0, 1.0, 2.0, 0.238842313435484, 6.911200000000001, 6.9112, 168.912956510431, 423558.7193722062, 423558.7193722056, 180361.0129768866], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 352800.0000, 
sim time next is 353400.0000, 
raw observation next is [20.28333333333333, 87.16666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5177220430356722, 6.9112, 6.9112, 168.912956510431, 459653.3068350803, 459653.3068350803, 154187.6223620376], 
processed observation next is [1.0, 0.08695652173913043, 0.16034755134281198, 0.8716666666666667, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4118561500435026, 0.0, 0.0, 0.8294399451523027, 0.12768147412085565, 0.12768147412085565, 0.23013077964483222], 
reward next is 0.7699, 
noisyNet noise sample is [array([1.2245314], dtype=float32), 0.005785821]. 
=============================================
[2019-03-26 19:05:53,617] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.15178114 0.1962167  0.45697945 0.11825611 0.07676662], sum to 1.0000
[2019-03-26 19:05:53,621] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8563
[2019-03-26 19:05:53,624] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.66666666666667, 80.33333333333333, 1.0, 2.0, 0.2564390091728924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 420498.6523125551, 420498.6523125558, 161550.8064610493], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 416400.0000, 
sim time next is 417000.0000, 
raw observation next is [20.58333333333334, 80.16666666666667, 1.0, 2.0, 0.17, 1.0, 1.0, 0.17, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 417852.2964674792, 417852.2964674792, 216769.6198578114], 
processed observation next is [1.0, 0.8260869565217391, 0.17456556082148533, 0.8016666666666667, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.11607008235207755, 0.11607008235207755, 0.3235367460564349], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8422306], dtype=float32), 0.13424735]. 
=============================================
[2019-03-26 19:05:53,637] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[1.5962468]
 [2.149513 ]
 [1.8963089]
 [1.86449  ]
 [2.0396433]], R is [[1.48939121]
 [2.23337674]
 [2.21104288]
 [2.96598554]
 [2.93632579]].
[2019-03-26 19:05:54,215] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.26353258 0.33089897 0.23620656 0.07328696 0.09607496], sum to 1.0000
[2019-03-26 19:05:54,220] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7857
[2019-03-26 19:05:54,300] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.75, 85.66666666666667, 1.0, 2.0, 0.2470864188695453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 406555.8672708419, 406555.8672708425, 160617.3790305967], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 427800.0000, 
sim time next is 428400.0000, 
raw observation next is [19.7, 86.0, 1.0, 2.0, 0.17, 0.0, 2.0, 0.0, 1.0, 1.0, 0.2270616203915882, 6.911200000000001, 6.9112, 168.912956510431, 405354.9084954147, 405354.9084954141, 177573.3819189367], 
processed observation next is [1.0, 1.0, 0.1327014218009479, 0.86, 1.0, 1.0, 0.0, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.057392219989741707, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11259858569317076, 0.11259858569317059, 0.2650348983864727], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.21147627], dtype=float32), -1.2631955]. 
=============================================
[2019-03-26 19:05:55,232] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.24683176 0.2137696  0.38980523 0.06401867 0.08557469], sum to 1.0000
[2019-03-26 19:05:55,239] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2024
[2019-03-26 19:05:55,348] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.73333333333333, 82.00000000000001, 1.0, 2.0, 0.17, 0.0, 2.0, 0.0, 1.0, 1.0, 0.2178075504685653, 6.911200000000001, 6.9112, 168.912956510431, 390202.8409977127, 390202.8409977121, 175433.7511983159], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 450600.0000, 
sim time next is 451200.0000, 
raw observation next is [19.76666666666667, 82.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4220891698670383, 6.9112, 6.9112, 168.912956510431, 378149.2841175299, 378149.2841175299, 142857.7724204221], 
processed observation next is [1.0, 0.21739130434782608, 0.13586097946287537, 0.82, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.2952306949598028, 0.0, 0.0, 0.8294399451523027, 0.10504146781042498, 0.10504146781042498, 0.21322055585137625], 
reward next is 0.7868, 
noisyNet noise sample is [array([0.6476533], dtype=float32), -0.03393223]. 
=============================================
[2019-03-26 19:06:00,292] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.11289306 0.49842492 0.30404717 0.03980233 0.04483248], sum to 1.0000
[2019-03-26 19:06:00,302] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0374
[2019-03-26 19:06:00,308] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.75, 90.5, 1.0, 2.0, 0.17, 1.0, 1.0, 0.17, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 352910.2482507726, 352910.2482507726, 203408.1019079837], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 534600.0000, 
sim time next is 535200.0000, 
raw observation next is [17.7, 90.66666666666667, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3890927499516679, 6.9112, 6.9112, 168.912956510431, 350731.3372910572, 350731.3372910572, 139427.5285326798], 
processed observation next is [1.0, 0.17391304347826086, 0.03791469194312799, 0.9066666666666667, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.2549911584776438, 0.0, 0.0, 0.8294399451523027, 0.09742537146973812, 0.09742537146973812, 0.20810078885474598], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4923708], dtype=float32), -0.11117475]. 
=============================================
[2019-03-26 19:06:04,021] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 15914: loss -0.8935
[2019-03-26 19:06:04,024] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 15914: learning rate 0.0000
[2019-03-26 19:06:04,026] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 15915: loss 9.0709
[2019-03-26 19:06:04,028] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 15915: learning rate 0.0000
[2019-03-26 19:06:04,068] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 15932: loss 2.9494
[2019-03-26 19:06:04,071] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 15933: learning rate 0.0000
[2019-03-26 19:06:04,091] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 15944: loss 3.2799
[2019-03-26 19:06:04,093] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 15944: loss -2.7356
[2019-03-26 19:06:04,094] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 15944: learning rate 0.0000
[2019-03-26 19:06:04,096] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 15944: learning rate 0.0000
[2019-03-26 19:06:04,142] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 15963: loss 12.6027
[2019-03-26 19:06:04,143] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 15963: learning rate 0.0000
[2019-03-26 19:06:04,157] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 15971: loss 7.9824
[2019-03-26 19:06:04,159] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 15972: learning rate 0.0000
[2019-03-26 19:06:04,162] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 15974: loss 8.0760
[2019-03-26 19:06:04,165] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 15974: learning rate 0.0000
[2019-03-26 19:06:04,181] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 15984: loss 10.5225
[2019-03-26 19:06:04,182] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 15984: learning rate 0.0000
[2019-03-26 19:06:04,222] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 16000: loss 9.4778
[2019-03-26 19:06:04,223] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 16000: learning rate 0.0000
[2019-03-26 19:06:04,244] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 16007: loss 8.6871
[2019-03-26 19:06:04,248] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 16008: learning rate 0.0000
[2019-03-26 19:06:04,266] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 16015: loss 6.3854
[2019-03-26 19:06:04,270] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 16016: learning rate 0.0000
[2019-03-26 19:06:04,280] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 16022: loss 0.8023
[2019-03-26 19:06:04,283] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 16024: learning rate 0.0000
[2019-03-26 19:06:04,305] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 16036: loss -0.0445
[2019-03-26 19:06:04,307] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 16036: learning rate 0.0000
[2019-03-26 19:06:04,325] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 16045: loss 6.9061
[2019-03-26 19:06:04,328] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 16046: learning rate 0.0000
[2019-03-26 19:06:04,534] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 16134: loss 6.3108
[2019-03-26 19:06:04,536] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 16135: learning rate 0.0000
[2019-03-26 19:06:13,537] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.00141725 0.9903706  0.00540673 0.00164555 0.0011599 ], sum to 1.0000
[2019-03-26 19:06:13,550] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4100
[2019-03-26 19:06:13,652] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 63.5, 1.0, 2.0, 0.2440252528498042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 402372.2842304306, 402372.28423043, 160297.3331151968], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 757800.0000, 
sim time next is 758400.0000, 
raw observation next is [22.5, 65.0, 1.0, 2.0, 0.2450190389611186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 403835.3042693184, 403835.3042693177, 160399.4502776505], 
processed observation next is [1.0, 0.782608695652174, 0.2654028436018958, 0.65, 1.0, 1.0, 0.09038438429050433, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.112176473408144, 0.11217647340814381, 0.23940216459350822], 
reward next is 0.7606, 
noisyNet noise sample is [array([0.24773146], dtype=float32), 0.7161588]. 
=============================================
[2019-03-26 19:06:14,695] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.00129686 0.9899603  0.00584477 0.00158128 0.00131675], sum to 1.0000
[2019-03-26 19:06:14,706] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5424
[2019-03-26 19:06:14,713] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.56666666666667, 88.33333333333334, 1.0, 2.0, 0.2552014212143335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 419218.9642377191, 419218.9642377191, 161427.2336434695], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 775200.0000, 
sim time next is 775800.0000, 
raw observation next is [19.55, 88.5, 1.0, 2.0, 0.2543699431186543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 417835.6658879847, 417835.6658879847, 161344.0834414767], 
processed observation next is [1.0, 1.0, 0.12559241706161148, 0.885, 1.0, 1.0, 0.10165053387789673, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1160654627466624, 0.1160654627466624, 0.24081206483802492], 
reward next is 0.7592, 
noisyNet noise sample is [array([1.6631523], dtype=float32), 0.3307605]. 
=============================================
[2019-03-26 19:06:18,082] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.00143128 0.9881094  0.00570488 0.00220247 0.00255199], sum to 1.0000
[2019-03-26 19:06:18,091] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5987
[2019-03-26 19:06:18,191] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.43333333333333, 66.33333333333333, 1.0, 2.0, 0.2938091098117316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 469094.101236043, 469094.101236043, 164868.587597187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 831000.0000, 
sim time next is 831600.0000, 
raw observation next is [24.4, 67.0, 1.0, 2.0, 0.2960799492552072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 472020.0737030072, 472020.0737030066, 165063.6170354874], 
processed observation next is [0.0, 0.6521739130434783, 0.3554502369668246, 0.67, 1.0, 1.0, 0.15190355331952674, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13111668713972421, 0.13111668713972405, 0.24636360751565284], 
reward next is 0.7536, 
noisyNet noise sample is [array([-0.9151177], dtype=float32), -0.39356807]. 
=============================================
[2019-03-26 19:06:21,770] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.00113004 0.98760635 0.00641536 0.00283572 0.00201254], sum to 1.0000
[2019-03-26 19:06:21,781] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2747
[2019-03-26 19:06:21,893] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.4, 79.33333333333334, 1.0, 2.0, 0.2910488064414534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 465268.5318146853, 465268.5318146859, 164610.1486551551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 892200.0000, 
sim time next is 892800.0000, 
raw observation next is [22.5, 79.0, 1.0, 2.0, 0.2922412664094219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 466670.2044195034, 466670.204419504, 164700.6656892739], 
processed observation next is [0.0, 0.34782608695652173, 0.2654028436018958, 0.79, 1.0, 1.0, 0.14727863422821913, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12963061233875095, 0.12963061233875112, 0.24582188908846853], 
reward next is 0.7542, 
noisyNet noise sample is [array([1.5152217], dtype=float32), -0.6467264]. 
=============================================
[2019-03-26 19:06:21,934] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 23836: loss 0.2153
[2019-03-26 19:06:21,936] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 23836: learning rate 0.0000
[2019-03-26 19:06:22,017] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 23870: loss 3.5341
[2019-03-26 19:06:22,022] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 23870: learning rate 0.0000
[2019-03-26 19:06:22,120] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 23920: loss 0.2046
[2019-03-26 19:06:22,124] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 23920: learning rate 0.0000
[2019-03-26 19:06:22,143] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 23928: loss 5.9310
[2019-03-26 19:06:22,146] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 23928: learning rate 0.0000
[2019-03-26 19:06:22,153] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 23934: loss 5.9232
[2019-03-26 19:06:22,155] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 23934: learning rate 0.0000
[2019-03-26 19:06:22,240] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 23971: loss 9.1741
[2019-03-26 19:06:22,242] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 23971: learning rate 0.0000
[2019-03-26 19:06:22,252] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 23976: loss 5.8195
[2019-03-26 19:06:22,256] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 23977: learning rate 0.0000
[2019-03-26 19:06:22,270] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 23987: loss 6.1621
[2019-03-26 19:06:22,273] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 23987: learning rate 0.0000
[2019-03-26 19:06:22,273] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23987: loss 5.9149
[2019-03-26 19:06:22,280] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 23988: learning rate 0.0000
[2019-03-26 19:06:22,286] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23992: loss 5.9728
[2019-03-26 19:06:22,288] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 23993: learning rate 0.0000
[2019-03-26 19:06:22,329] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 24010: loss 4.9527
[2019-03-26 19:06:22,330] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 24010: learning rate 0.0000
[2019-03-26 19:06:22,354] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 24019: loss 6.3600
[2019-03-26 19:06:22,355] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 24019: loss 5.8900
[2019-03-26 19:06:22,356] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 24019: learning rate 0.0000
[2019-03-26 19:06:22,359] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 24020: learning rate 0.0000
[2019-03-26 19:06:22,475] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 24072: loss 5.8725
[2019-03-26 19:06:22,477] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 24072: learning rate 0.0000
[2019-03-26 19:06:22,506] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 24088: loss 5.8356
[2019-03-26 19:06:22,508] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 24088: learning rate 0.0000
[2019-03-26 19:06:22,769] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 24200: loss 2.6441
[2019-03-26 19:06:22,774] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 24203: learning rate 0.0000
[2019-03-26 19:06:24,153] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7805057e-04 9.9768329e-01 1.3446833e-03 4.6381491e-04 3.3011060e-04], sum to 1.0000
[2019-03-26 19:06:24,165] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0980
[2019-03-26 19:06:24,171] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.18333333333334, 81.33333333333334, 1.0, 2.0, 0.3290145769842875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 513310.819311581, 513310.8193115816, 167875.7974355611], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 931800.0000, 
sim time next is 932400.0000, 
raw observation next is [23.1, 82.0, 1.0, 2.0, 0.3290152649457214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 513191.5550425368, 513191.5550425375, 167863.1858485076], 
processed observation next is [0.0, 0.8260869565217391, 0.2938388625592418, 0.82, 1.0, 1.0, 0.19158465656111015, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.142553209734038, 0.1425532097340382, 0.25054206843060833], 
reward next is 0.7495, 
noisyNet noise sample is [array([-0.15781215], dtype=float32), -1.1876116]. 
=============================================
[2019-03-26 19:06:24,535] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 19:06:24,539] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:06:24,541] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:06:24,542] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:06:24,543] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:06:24,544] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:06:24,545] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:06:24,545] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:06:24,548] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:06:24,546] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:06:24,549] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:06:24,565] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run2
[2019-03-26 19:06:24,566] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run2
[2019-03-26 19:06:24,566] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run2
[2019-03-26 19:06:24,597] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run2
[2019-03-26 19:06:24,629] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run2
[2019-03-26 19:06:40,882] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00740112], dtype=float32), 0.016795382]
[2019-03-26 19:06:40,885] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.78333333333333, 84.16666666666667, 1.0, 2.0, 0.3021437113078593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 482478.6210010134, 482478.6210010134, 165817.2531501559]
[2019-03-26 19:06:40,887] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:06:40,891] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.8213046e-04 9.9736661e-01 1.3175053e-03 8.0450095e-04 3.2928432e-04], sampled 0.7717537152852257
[2019-03-26 19:06:51,837] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00740112], dtype=float32), 0.016795382]
[2019-03-26 19:06:51,839] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.46666666666667, 88.0, 1.0, 2.0, 0.7475995732008608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1044824.428437385, 1044824.428437384, 231451.1021800936]
[2019-03-26 19:06:51,841] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:06:51,845] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.04001585e-04 9.98566687e-01 7.08469364e-04 4.35887720e-04
 1.84981822e-04], sampled 0.6669410751707118
[2019-03-26 19:07:28,827] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00740112], dtype=float32), 0.016795382]
[2019-03-26 19:07:28,828] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [36.3, 51.0, 1.0, 2.0, 0.5829407764474777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104262, 814613.6056249735, 814613.6056249735, 197612.605346075]
[2019-03-26 19:07:28,829] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:07:28,834] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.1511690e-04 9.9763978e-01 8.9959422e-04 8.3079102e-04 2.1468793e-04], sampled 0.17277805574396743
[2019-03-26 19:07:34,200] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00740112], dtype=float32), 0.016795382]
[2019-03-26 19:07:34,202] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.18333333333334, 65.83333333333334, 1.0, 2.0, 0.9355408642771195, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.992653187881313, 6.9112, 168.91240622783, 2204783.039182538, 2146997.532550705, 444605.6886470554]
[2019-03-26 19:07:34,204] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:07:34,208] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.8693865e-04 9.9831176e-01 4.9332523e-04 6.1886077e-04 2.8924292e-04], sampled 0.4962996642521853
[2019-03-26 19:07:34,209] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2204783.039182538 W.
[2019-03-26 19:07:58,179] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00740112], dtype=float32), 0.016795382]
[2019-03-26 19:07:58,180] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.6, 89.0, 1.0, 2.0, 0.5239633614847792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 732168.9305094335, 732168.9305094341, 187435.6785391268]
[2019-03-26 19:07:58,182] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:07:58,186] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.5474816e-04 9.9577928e-01 2.1915962e-03 1.1241118e-03 5.5022916e-04], sampled 0.05405894394637367
[2019-03-26 19:08:20,120] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7845.3565 3165277058.1310 1778.0000
[2019-03-26 19:08:20,351] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8613.8101 2780900037.9315 934.0000
[2019-03-26 19:08:20,409] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8219.3020 2928638013.1037 1339.0000
[2019-03-26 19:08:20,426] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7969.2459 3008997731.0004 1766.0000
[2019-03-26 19:08:20,496] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8465.3408 2843558243.3889 1130.0000
[2019-03-26 19:08:21,511] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 25000, evaluation results [25000.0, 7845.356539077429, 3165277058.131015, 1778.0, 8219.301960020453, 2928638013.1036763, 1339.0, 8613.810081958865, 2780900037.9314685, 934.0, 7969.245858049016, 3008997731.0004463, 1766.0, 8465.340803819327, 2843558243.388918, 1130.0]
[2019-03-26 19:08:22,750] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.6032981e-04 9.9492574e-01 3.6757160e-03 8.2464778e-04 3.1355055e-04], sum to 1.0000
[2019-03-26 19:08:22,755] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0754
[2019-03-26 19:08:22,855] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 92.66666666666667, 1.0, 2.0, 0.3313461095703727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 514104.4202601747, 514104.4202601747, 167854.2908459639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 966000.0000, 
sim time next is 966600.0000, 
raw observation next is [21.9, 92.5, 1.0, 2.0, 0.3266065538592764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 507045.1089431385, 507045.1089431385, 167315.7245968776], 
processed observation next is [1.0, 0.17391304347826086, 0.23696682464454974, 0.925, 1.0, 1.0, 0.18868259501117637, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14084586359531626, 0.14084586359531626, 0.24972496208489195], 
reward next is 0.7503, 
noisyNet noise sample is [array([1.4470477], dtype=float32), -0.7911643]. 
=============================================
[2019-03-26 19:08:30,328] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8432173e-06 9.9992239e-01 4.0954859e-05 2.6476609e-05 8.3807299e-06], sum to 1.0000
[2019-03-26 19:08:30,336] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3978
[2019-03-26 19:08:30,343] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 89.5, 1.0, 2.0, 0.2928451233047513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 469547.5094624624, 469547.5094624631, 164921.6273135842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1125000.0000, 
sim time next is 1125600.0000, 
raw observation next is [20.86666666666667, 89.66666666666667, 1.0, 2.0, 0.292297394789205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 468788.9812294227, 468788.9812294221, 164869.7039335522], 
processed observation next is [1.0, 0.0, 0.18799368088467638, 0.8966666666666667, 1.0, 1.0, 0.14734625878217472, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13021916145261742, 0.13021916145261725, 0.24607418497545105], 
reward next is 0.7539, 
noisyNet noise sample is [array([0.4067587], dtype=float32), -0.9143302]. 
=============================================
[2019-03-26 19:08:31,856] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2476008e-06 9.9993849e-01 3.8355742e-05 1.7107564e-05 3.6419488e-06], sum to 1.0000
[2019-03-26 19:08:31,866] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8157
[2019-03-26 19:08:31,874] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.95, 75.5, 1.0, 2.0, 0.6276188675638236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 981068.4198427381, 981068.4198427381, 218421.2473973475], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1157400.0000, 
sim time next is 1158000.0000, 
raw observation next is [24.13333333333333, 74.66666666666667, 1.0, 2.0, 0.6905006168336422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1077805.185289239, 1077805.185289239, 232630.4473362391], 
processed observation next is [1.0, 0.391304347826087, 0.3428120063191152, 0.7466666666666667, 1.0, 1.0, 0.6271091769080026, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.29939032924701087, 0.29939032924701087, 0.3472096228899091], 
reward next is 0.6528, 
noisyNet noise sample is [array([-2.0621781], dtype=float32), 1.8269966]. 
=============================================
[2019-03-26 19:08:31,883] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[20.30212 ]
 [20.227592]
 [20.126377]
 [20.00479 ]
 [19.899727]], R is [[20.87117195]
 [21.33645821]
 [21.80268097]
 [22.25635147]
 [22.68859291]].
[2019-03-26 19:08:33,507] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31808: loss 2.5735
[2019-03-26 19:08:33,511] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 31808: learning rate 0.0000
[2019-03-26 19:08:33,569] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 31841: loss 2.5324
[2019-03-26 19:08:33,570] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 31841: learning rate 0.0000
[2019-03-26 19:08:33,651] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 31880: loss 2.6929
[2019-03-26 19:08:33,652] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 31880: learning rate 0.0000
[2019-03-26 19:08:33,681] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 31900: loss 2.5212
[2019-03-26 19:08:33,683] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 31900: learning rate 0.0000
[2019-03-26 19:08:33,755] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 31937: loss 2.6226
[2019-03-26 19:08:33,760] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 31937: learning rate 0.0000
[2019-03-26 19:08:33,767] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 31942: loss 2.6269
[2019-03-26 19:08:33,770] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 31943: learning rate 0.0000
[2019-03-26 19:08:33,777] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 31947: loss 2.5837
[2019-03-26 19:08:33,779] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 31947: learning rate 0.0000
[2019-03-26 19:08:33,811] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 31966: loss 2.6512
[2019-03-26 19:08:33,813] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 31968: learning rate 0.0000
[2019-03-26 19:08:33,832] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 31980: loss 2.5556
[2019-03-26 19:08:33,834] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 31981: learning rate 0.0000
[2019-03-26 19:08:33,851] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 31995: loss 2.5969
[2019-03-26 19:08:33,852] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 31995: learning rate 0.0000
[2019-03-26 19:08:33,875] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 32005: loss 2.5890
[2019-03-26 19:08:33,876] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 32006: learning rate 0.0000
[2019-03-26 19:08:33,897] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 32017: loss 2.6136
[2019-03-26 19:08:33,899] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 32019: learning rate 0.0000
[2019-03-26 19:08:34,008] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 32081: loss 2.6087
[2019-03-26 19:08:34,010] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 32081: learning rate 0.0000
[2019-03-26 19:08:34,020] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1150008e-07 9.9997330e-01 1.8250157e-05 6.8886370e-06 1.3269821e-06], sum to 1.0000
[2019-03-26 19:08:34,027] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2182
[2019-03-26 19:08:34,032] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 87.0, 1.0, 2.0, 0.3565731776975517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 549146.8796949072, 549146.8796949066, 170571.0982558838], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1206000.0000, 
sim time next is 1206600.0000, 
raw observation next is [22.85, 87.16666666666667, 1.0, 2.0, 0.3557153872458308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 548072.2460944823, 548072.2460944816, 170488.2475067229], 
processed observation next is [1.0, 1.0, 0.28199052132701435, 0.8716666666666667, 1.0, 1.0, 0.22375347860943468, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15224229058180064, 0.15224229058180044, 0.25446007090555656], 
reward next is 0.7455, 
noisyNet noise sample is [array([0.657558], dtype=float32), -0.07758926]. 
=============================================
[2019-03-26 19:08:34,052] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 32102: loss 2.5218
[2019-03-26 19:08:34,053] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 32102: learning rate 0.0000
[2019-03-26 19:08:34,141] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 32149: loss 2.5470
[2019-03-26 19:08:34,143] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 32149: learning rate 0.0000
[2019-03-26 19:08:34,310] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 32257: loss 2.4523
[2019-03-26 19:08:34,314] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 32260: learning rate 0.0000
[2019-03-26 19:08:35,060] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4565509e-06 9.9985743e-01 1.1146855e-04 2.1652859e-05 7.9913434e-06], sum to 1.0000
[2019-03-26 19:08:35,068] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1286
[2019-03-26 19:08:35,072] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 94.0, 1.0, 2.0, 0.3523946565407417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 547468.391229226, 547468.3912292254, 170556.3222392198], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1225800.0000, 
sim time next is 1226400.0000, 
raw observation next is [21.66666666666667, 94.33333333333333, 1.0, 2.0, 0.3556166477422023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 552366.4180396085, 552366.4180396092, 170960.6782596908], 
processed observation next is [1.0, 0.17391304347826086, 0.22590837282780438, 0.9433333333333332, 1.0, 1.0, 0.22363451535205098, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15343511612211347, 0.15343511612211366, 0.2551651914323743], 
reward next is 0.7448, 
noisyNet noise sample is [array([1.2342368], dtype=float32), -0.68451846]. 
=============================================
[2019-03-26 19:08:40,142] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8933396e-07 9.9998009e-01 1.3982917e-05 5.1928741e-06 5.2624381e-07], sum to 1.0000
[2019-03-26 19:08:40,151] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9471
[2019-03-26 19:08:40,254] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.53333333333333, 91.66666666666667, 1.0, 2.0, 0.5137428404186826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730800.3274593552, 730800.3274593552, 187428.4019170274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1311600.0000, 
sim time next is 1312200.0000, 
raw observation next is [24.55, 91.5, 1.0, 2.0, 0.5153362958853872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733246.0981006918, 733246.0981006911, 187712.6272447009], 
processed observation next is [1.0, 0.17391304347826086, 0.3625592417061612, 0.915, 1.0, 1.0, 0.4160678263679364, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2036794716946366, 0.2036794716946364, 0.2801681003652252], 
reward next is 0.7198, 
noisyNet noise sample is [array([0.05181984], dtype=float32), 0.4107741]. 
=============================================
[2019-03-26 19:08:40,481] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.2417091e-07 9.9998546e-01 8.0940936e-06 5.0037520e-06 1.0443658e-06], sum to 1.0000
[2019-03-26 19:08:40,492] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3900
[2019-03-26 19:08:40,499] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 91.0, 1.0, 2.0, 0.4899368075859202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 697606.7093396898, 697606.7093396892, 183697.8037423817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1314000.0000, 
sim time next is 1314600.0000, 
raw observation next is [24.51666666666667, 91.33333333333334, 1.0, 2.0, 0.4829092636687409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 688431.9385824759, 688431.9385824759, 182708.3712056043], 
processed observation next is [1.0, 0.21739130434782608, 0.36097946287519767, 0.9133333333333334, 1.0, 1.0, 0.37699911285390464, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19123109405068775, 0.19123109405068775, 0.2726990615009019], 
reward next is 0.7273, 
noisyNet noise sample is [array([0.27884427], dtype=float32), 1.178482]. 
=============================================
[2019-03-26 19:08:42,801] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.92528553e-08 9.99997616e-01 1.53153110e-06 7.08139964e-07
 1.14736515e-07], sum to 1.0000
[2019-03-26 19:08:42,809] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5626
[2019-03-26 19:08:42,820] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 91.0, 1.0, 2.0, 0.7091606161431733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1130087.578516714, 1130087.578516714, 239288.0164668727], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1353600.0000, 
sim time next is 1354200.0000, 
raw observation next is [20.96666666666667, 91.16666666666667, 1.0, 2.0, 0.6389362483018863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1018434.12291141, 1018434.122911409, 222670.5488732789], 
processed observation next is [1.0, 0.6956521739130435, 0.1927330173775673, 0.9116666666666667, 1.0, 1.0, 0.5649834316890197, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2828983674753917, 0.2828983674753914, 0.3323441027959386], 
reward next is 0.6677, 
noisyNet noise sample is [array([1.0233693], dtype=float32), 0.7451691]. 
=============================================
[2019-03-26 19:08:44,737] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.1893270e-08 9.9999404e-01 2.5111233e-06 2.8735583e-06 5.1555253e-07], sum to 1.0000
[2019-03-26 19:08:44,749] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3441
[2019-03-26 19:08:44,756] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 97.5, 1.0, 2.0, 0.3068023820804128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 488327.5231009396, 488327.5231009396, 166219.2769416711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1387800.0000, 
sim time next is 1388400.0000, 
raw observation next is [20.26666666666667, 97.66666666666666, 1.0, 2.0, 0.3058459772450906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 486958.926968225, 486958.9269682244, 166122.0727794527], 
processed observation next is [0.0, 0.043478260869565216, 0.15955766192733034, 0.9766666666666666, 1.0, 1.0, 0.1636698521025188, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13526636860228472, 0.13526636860228455, 0.24794339220813835], 
reward next is 0.7521, 
noisyNet noise sample is [array([0.70989907], dtype=float32), 1.3559415]. 
=============================================
[2019-03-26 19:08:45,202] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.6540375e-08 9.9998713e-01 7.3450701e-06 4.8547577e-06 5.8223679e-07], sum to 1.0000
[2019-03-26 19:08:45,211] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5959
[2019-03-26 19:08:45,217] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 98.0, 1.0, 2.0, 0.3077453330171429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 488643.4134052232, 488643.4134052238, 166223.5209646378], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1394400.0000, 
sim time next is 1395000.0000, 
raw observation next is [20.4, 98.0, 1.0, 2.0, 0.3099197336711298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 491720.4763980514, 491720.4763980507, 166442.265502585], 
processed observation next is [0.0, 0.13043478260869565, 0.16587677725118483, 0.98, 1.0, 1.0, 0.16857799237485516, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13658902122168096, 0.13658902122168076, 0.248421291794903], 
reward next is 0.7516, 
noisyNet noise sample is [array([-1.2343343], dtype=float32), 0.63542604]. 
=============================================
[2019-03-26 19:08:45,232] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[25.1558  ]
 [25.454561]
 [25.577265]
 [25.802446]
 [26.034842]], R is [[25.58180809]
 [26.07789612]
 [26.56918335]
 [27.05568314]
 [27.53734589]].
[2019-03-26 19:08:48,275] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3410916e-08 9.9999726e-01 1.0817951e-06 1.3004229e-06 3.4558943e-07], sum to 1.0000
[2019-03-26 19:08:48,289] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8179
[2019-03-26 19:08:48,294] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.35, 74.83333333333333, 1.0, 2.0, 0.4201252165336955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 612031.5313201292, 612031.5313201298, 175240.9820735452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1446600.0000, 
sim time next is 1447200.0000, 
raw observation next is [26.1, 76.0, 1.0, 2.0, 0.4176003942456843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 609794.8782963161, 609794.8782963167, 175070.5709150185], 
processed observation next is [0.0, 0.782608695652174, 0.4360189573459717, 0.76, 1.0, 1.0, 0.2983137280068485, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16938746619342115, 0.16938746619342132, 0.2612993595746545], 
reward next is 0.7387, 
noisyNet noise sample is [array([-1.636092], dtype=float32), 1.2319255]. 
=============================================
[2019-03-26 19:08:51,065] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 39794: loss 3.5272
[2019-03-26 19:08:51,068] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 39795: learning rate 0.0000
[2019-03-26 19:08:51,080] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 39799: loss 3.6126
[2019-03-26 19:08:51,081] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 39800: learning rate 0.0000
[2019-03-26 19:08:51,294] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39894: loss 3.5664
[2019-03-26 19:08:51,297] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 39894: learning rate 0.0000
[2019-03-26 19:08:51,323] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 39904: loss 3.5902
[2019-03-26 19:08:51,326] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 39904: learning rate 0.0000
[2019-03-26 19:08:51,353] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 39917: loss 3.5446
[2019-03-26 19:08:51,357] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 39919: learning rate 0.0000
[2019-03-26 19:08:51,415] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 39948: loss 3.5424
[2019-03-26 19:08:51,419] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 39948: learning rate 0.0000
[2019-03-26 19:08:51,442] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39959: loss 3.5458
[2019-03-26 19:08:51,446] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 39960: learning rate 0.0000
[2019-03-26 19:08:51,456] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 39967: loss 3.5497
[2019-03-26 19:08:51,456] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 39967: loss 3.5576
[2019-03-26 19:08:51,457] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 39967: learning rate 0.0000
[2019-03-26 19:08:51,458] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 39967: learning rate 0.0000
[2019-03-26 19:08:51,542] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 40000: loss 3.6004
[2019-03-26 19:08:51,544] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 40000: learning rate 0.0000
[2019-03-26 19:08:51,561] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 40008: loss 3.5517
[2019-03-26 19:08:51,566] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 40012: learning rate 0.0000
[2019-03-26 19:08:51,578] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 40019: loss 3.5997
[2019-03-26 19:08:51,580] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 40019: learning rate 0.0000
[2019-03-26 19:08:51,723] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 40081: loss 3.5525
[2019-03-26 19:08:51,725] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 40081: learning rate 0.0000
[2019-03-26 19:08:51,799] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 40117: loss 3.5297
[2019-03-26 19:08:51,801] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 40117: learning rate 0.0000
[2019-03-26 19:08:51,855] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 40139: loss 3.5028
[2019-03-26 19:08:51,857] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 40140: learning rate 0.0000
[2019-03-26 19:08:52,127] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 40260: loss 3.6193
[2019-03-26 19:08:52,130] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 40261: learning rate 0.0000
[2019-03-26 19:09:02,226] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.7993644e-11 1.0000000e+00 5.4484300e-08 2.6352867e-08 2.2727678e-09], sum to 1.0000
[2019-03-26 19:09:02,240] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4573
[2019-03-26 19:09:02,246] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.43333333333333, 90.0, 1.0, 2.0, 0.9086910339732761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1270096.036179465, 1270096.036179465, 272336.1166628831], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1678800.0000, 
sim time next is 1679400.0000, 
raw observation next is [25.55, 89.5, 1.0, 2.0, 0.9582083846393582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1339351.106769004, 1339351.106769004, 286447.7388908998], 
processed observation next is [1.0, 0.43478260869565216, 0.40995260663507116, 0.895, 1.0, 1.0, 0.9496486561919978, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.37204197410250106, 0.37204197410250106, 0.42753393864313405], 
reward next is 0.5725, 
noisyNet noise sample is [array([1.4319698], dtype=float32), 1.8376054]. 
=============================================
[2019-03-26 19:09:06,582] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.5627058e-11 1.0000000e+00 8.2024609e-09 1.5128928e-09 4.1621578e-10], sum to 1.0000
[2019-03-26 19:09:06,589] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0137
[2019-03-26 19:09:06,598] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.15, 89.33333333333333, 1.0, 2.0, 0.4664865109814356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 654881.2491352783, 654881.2491352777, 178906.5591946662], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1756200.0000, 
sim time next is 1756800.0000, 
raw observation next is [25.2, 89.0, 1.0, 2.0, 0.5579299271410525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 783100.424087762, 783100.424087762, 193610.5593701128], 
processed observation next is [1.0, 0.34782608695652173, 0.3933649289099526, 0.89, 1.0, 1.0, 0.46738545438681023, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2175278955799339, 0.2175278955799339, 0.28897098413449673], 
reward next is 0.7110, 
noisyNet noise sample is [array([1.484673], dtype=float32), 0.6885005]. 
=============================================
[2019-03-26 19:09:07,184] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4565112e-10 1.0000000e+00 4.5454794e-08 2.1340632e-08 9.8708663e-10], sum to 1.0000
[2019-03-26 19:09:07,192] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7817
[2019-03-26 19:09:07,300] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 89.66666666666666, 1.0, 2.0, 0.4630044367811743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 650127.7876267509, 650127.7876267516, 178412.4582639883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1755600.0000, 
sim time next is 1756200.0000, 
raw observation next is [25.15, 89.33333333333333, 1.0, 2.0, 0.4664865109814356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 654881.2491352783, 654881.2491352777, 178906.5591946662], 
processed observation next is [1.0, 0.30434782608695654, 0.3909952606635071, 0.8933333333333333, 1.0, 1.0, 0.357212663833055, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18191145809313286, 0.1819114580931327, 0.2670247152159197], 
reward next is 0.7330, 
noisyNet noise sample is [array([-0.24690257], dtype=float32), -0.34955016]. 
=============================================
[2019-03-26 19:09:08,873] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.5388164e-12 1.0000000e+00 7.3940414e-09 2.1268169e-09 1.4562028e-10], sum to 1.0000
[2019-03-26 19:09:08,886] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7266
[2019-03-26 19:09:08,891] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.85, 88.0, 1.0, 2.0, 0.3195953847722333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 504038.244491728, 504038.2444917274, 167301.682872369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1794600.0000, 
sim time next is 1795200.0000, 
raw observation next is [21.8, 88.33333333333333, 1.0, 2.0, 0.3178032969868665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 501301.812656998, 501301.8126569974, 167097.3435697311], 
processed observation next is [1.0, 0.782608695652174, 0.23222748815165886, 0.8833333333333333, 1.0, 1.0, 0.1780762614299596, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13925050351583276, 0.13925050351583262, 0.24939902025333002], 
reward next is 0.7506, 
noisyNet noise sample is [array([0.03101814], dtype=float32), 0.6684523]. 
=============================================
[2019-03-26 19:09:08,942] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 47792: loss 1.1268
[2019-03-26 19:09:08,946] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 47792: learning rate 0.0000
[2019-03-26 19:09:08,973] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 47806: loss 1.1108
[2019-03-26 19:09:08,977] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 47806: learning rate 0.0000
[2019-03-26 19:09:09,160] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 47890: loss 1.1683
[2019-03-26 19:09:09,161] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 47890: learning rate 0.0000
[2019-03-26 19:09:09,174] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 47894: loss 1.1102
[2019-03-26 19:09:09,178] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 47894: learning rate 0.0000
[2019-03-26 19:09:09,193] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 47904: loss 1.1357
[2019-03-26 19:09:09,194] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 47904: learning rate 0.0000
[2019-03-26 19:09:09,239] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 47923: loss 1.1589
[2019-03-26 19:09:09,243] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 47924: loss 1.1780
[2019-03-26 19:09:09,245] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 47925: learning rate 0.0000
[2019-03-26 19:09:09,245] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 47925: learning rate 0.0000
[2019-03-26 19:09:09,288] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 47945: loss 1.1384
[2019-03-26 19:09:09,296] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 47946: learning rate 0.0000
[2019-03-26 19:09:09,319] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 47957: loss 1.0690
[2019-03-26 19:09:09,321] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 47957: learning rate 0.0000
[2019-03-26 19:09:09,445] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 48015: loss 1.1911
[2019-03-26 19:09:09,449] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 48016: learning rate 0.0000
[2019-03-26 19:09:09,485] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.4010850e-11 1.0000000e+00 1.5660293e-08 1.0516270e-08 1.0233616e-10], sum to 1.0000
[2019-03-26 19:09:09,498] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4826
[2019-03-26 19:09:09,502] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 48042: loss 1.0130
[2019-03-26 19:09:09,504] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.43333333333333, 94.66666666666667, 1.0, 2.0, 0.3361926734803173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 525136.4967936483, 525136.4967936483, 168819.4305102034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1808400.0000, 
sim time next is 1809000.0000, 
raw observation next is [21.45, 95.0, 1.0, 2.0, 0.3386862032060498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 528242.5919976203, 528242.5919976203, 169046.6448126051], 
processed observation next is [1.0, 0.9565217391304348, 0.2156398104265403, 0.95, 1.0, 1.0, 0.2032363894048793, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1467340533326723, 0.1467340533326723, 0.2523084250934405], 
reward next is 0.7477, 
noisyNet noise sample is [array([-0.8468711], dtype=float32), -0.70662904]. 
=============================================
[2019-03-26 19:09:09,505] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 48042: learning rate 0.0000
[2019-03-26 19:09:09,522] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[41.574627]
 [41.519688]
 [41.46462 ]
 [41.445934]
 [41.51115 ]], R is [[41.95997238]
 [42.28840637]
 [42.6139183 ]
 [42.93632889]
 [43.25536346]].
[2019-03-26 19:09:09,585] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 48072: loss 1.0882
[2019-03-26 19:09:09,587] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 48073: learning rate 0.0000
[2019-03-26 19:09:09,612] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 48084: loss 1.0315
[2019-03-26 19:09:09,614] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 48086: learning rate 0.0000
[2019-03-26 19:09:09,737] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 48140: loss 1.0871
[2019-03-26 19:09:09,742] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 48141: learning rate 0.0000
[2019-03-26 19:09:09,856] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 48198: loss 1.1182
[2019-03-26 19:09:09,857] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 48199: learning rate 0.0000
[2019-03-26 19:09:09,884] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 48210: loss 1.0709
[2019-03-26 19:09:09,886] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 48211: learning rate 0.0000
[2019-03-26 19:09:12,418] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.5040846e-12 1.0000000e+00 1.8476308e-09 1.0861351e-09 1.2796810e-11], sum to 1.0000
[2019-03-26 19:09:12,430] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5478
[2019-03-26 19:09:12,439] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.25, 91.0, 1.0, 2.0, 0.8637238646207229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1248636.462475907, 1248636.462475906, 266115.14753887], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1848600.0000, 
sim time next is 1849200.0000, 
raw observation next is [24.36666666666667, 90.66666666666667, 1.0, 2.0, 0.8773852283162079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1264676.635659685, 1264676.635659684, 269362.8476898289], 
processed observation next is [1.0, 0.391304347826087, 0.3538704581358612, 0.9066666666666667, 1.0, 1.0, 0.852271359417118, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3512990654610236, 0.3512990654610233, 0.40203410102959536], 
reward next is 0.5980, 
noisyNet noise sample is [array([-0.04021373], dtype=float32), -1.0556904]. 
=============================================
[2019-03-26 19:09:12,542] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1701872e-11 1.0000000e+00 1.3296804e-08 2.0257296e-09 3.8326172e-11], sum to 1.0000
[2019-03-26 19:09:12,551] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6312
[2019-03-26 19:09:12,556] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.36666666666667, 90.66666666666667, 1.0, 2.0, 0.8773852283162079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1264676.635659685, 1264676.635659684, 269362.8476898289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1849200.0000, 
sim time next is 1849800.0000, 
raw observation next is [24.48333333333333, 90.33333333333333, 1.0, 2.0, 0.8876414164202816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1275697.956631741, 1275697.956631741, 271685.1948351348], 
processed observation next is [1.0, 0.391304347826087, 0.3593996840442337, 0.9033333333333333, 1.0, 1.0, 0.8646282125545561, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.35436054350881696, 0.35436054350881696, 0.40550029079870864], 
reward next is 0.5945, 
noisyNet noise sample is [array([0.9127766], dtype=float32), -0.08622866]. 
=============================================
[2019-03-26 19:09:13,884] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 19:09:13,887] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:09:13,888] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:09:13,889] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:09:13,889] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:09:13,890] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:09:13,891] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:09:13,891] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:09:13,893] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:09:13,894] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:09:13,895] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:09:13,909] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run3
[2019-03-26 19:09:13,926] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run3
[2019-03-26 19:09:13,944] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run3
[2019-03-26 19:09:13,945] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run3
[2019-03-26 19:09:13,980] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run3
[2019-03-26 19:09:23,253] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03055709], dtype=float32), 0.039423596]
[2019-03-26 19:09:23,254] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.03333333333333, 69.5, 1.0, 2.0, 0.253045115210523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 415820.7852035931, 415820.7852035924, 161210.9314993903]
[2019-03-26 19:09:23,256] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:09:23,260] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.8287128e-11 1.0000000e+00 9.2631565e-09 8.1038847e-09 4.5868609e-10], sampled 0.6284861864743193
[2019-03-26 19:09:34,837] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03055709], dtype=float32), 0.039423596]
[2019-03-26 19:09:34,838] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [17.56577737, 100.0, 1.0, 2.0, 0.2535471588811318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 418937.268631948, 418937.2686319486, 161192.0512370615]
[2019-03-26 19:09:34,841] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:09:34,845] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.7551528e-10 1.0000000e+00 4.4384137e-08 4.1140009e-08 1.9259614e-09], sampled 0.8620335810842847
[2019-03-26 19:10:19,492] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03055709], dtype=float32), 0.039423596]
[2019-03-26 19:10:19,494] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.23782091, 83.19318412, 1.0, 2.0, 0.5490734609019385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 767269.618707834, 767269.618707834, 191639.4508816759]
[2019-03-26 19:10:19,496] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:10:19,499] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.2484080e-11 1.0000000e+00 1.4247822e-08 1.3019514e-08 7.1494538e-10], sampled 0.6689278507839538
[2019-03-26 19:11:01,225] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03055709], dtype=float32), 0.039423596]
[2019-03-26 19:11:01,226] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.66666666666667, 87.0, 1.0, 2.0, 0.2817976931909142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 456471.5194258331, 456471.5194258331, 164021.1520503433]
[2019-03-26 19:11:01,227] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:11:01,230] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.8819942e-11 1.0000000e+00 6.3624013e-09 5.1384248e-09 2.7282043e-10], sampled 0.05065066771279958
[2019-03-26 19:11:08,171] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.0653 2927317329.7462 1338.0000
[2019-03-26 19:11:08,331] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8335 2842452168.1498 1131.0000
[2019-03-26 19:11:08,481] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.8889 2779256332.3854 933.0000
[2019-03-26 19:11:08,482] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7995.3168 3007810081.4350 1766.0000
[2019-03-26 19:11:08,534] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.9141 3164158593.5985 1778.0000
[2019-03-26 19:11:09,548] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 50000, evaluation results [50000.0, 7881.914089779894, 3164158593.5985365, 1778.0, 8255.065342017213, 2927317329.746172, 1338.0, 8659.888853383243, 2779256332.3854055, 933.0, 7995.316824600767, 3007810081.435039, 1766.0, 8496.833495916873, 2842452168.149761, 1131.0]
[2019-03-26 19:11:11,209] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.3290095e-13 1.0000000e+00 1.7760690e-10 2.3174691e-10 9.5975016e-12], sum to 1.0000
[2019-03-26 19:11:11,219] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2167
[2019-03-26 19:11:11,222] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 95.0, 1.0, 2.0, 0.4625432617026303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 652647.5764196299, 652647.5764196299, 178752.9072299544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1904400.0000, 
sim time next is 1905000.0000, 
raw observation next is [24.28333333333333, 95.16666666666667, 1.0, 2.0, 0.463167910437884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 653043.0560201956, 653043.0560201956, 178782.3635346329], 
processed observation next is [1.0, 0.043478260869565216, 0.34992101105845175, 0.9516666666666667, 1.0, 1.0, 0.3532143499251615, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18140084889449878, 0.18140084889449878, 0.2668393485591536], 
reward next is 0.7332, 
noisyNet noise sample is [array([0.55186695], dtype=float32), -0.8516756]. 
=============================================
[2019-03-26 19:11:11,229] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[45.233574]
 [45.358173]
 [45.514557]
 [45.72231 ]
 [45.89965 ]], R is [[45.29293442]
 [45.57320786]
 [45.85083008]
 [46.12592316]
 [46.39864731]].
[2019-03-26 19:11:11,906] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.4733522e-12 1.0000000e+00 5.0767008e-09 1.5237119e-09 5.3608423e-11], sum to 1.0000
[2019-03-26 19:11:11,915] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4351
[2019-03-26 19:11:12,036] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.68333333333333, 87.5, 1.0, 2.0, 0.4242001502744097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 614077.919594889, 614077.9195948885, 175322.9939811042], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1925400.0000, 
sim time next is 1926000.0000, 
raw observation next is [24.8, 87.0, 1.0, 2.0, 0.4274254435734332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 617571.7663213384, 617571.7663213384, 175626.4153832308], 
processed observation next is [1.0, 0.30434782608695654, 0.3744075829383887, 0.87, 1.0, 1.0, 0.31015113683546175, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17154771286703843, 0.17154771286703843, 0.26212897818392655], 
reward next is 0.7379, 
noisyNet noise sample is [array([-1.257782], dtype=float32), 0.97636074]. 
=============================================
[2019-03-26 19:11:12,049] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[43.31497 ]
 [43.320732]
 [43.32249 ]
 [43.309456]
 [43.310898]], R is [[43.55079269]
 [43.85360718]
 [44.15371323]
 [44.45090485]
 [44.74451065]].
[2019-03-26 19:11:13,315] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1825264e-13 1.0000000e+00 6.6603223e-11 2.8640951e-10 1.2464017e-11], sum to 1.0000
[2019-03-26 19:11:13,321] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2778
[2019-03-26 19:11:13,330] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1761181.771013905 W.
[2019-03-26 19:11:13,337] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.73333333333333, 77.33333333333334, 1.0, 2.0, 0.6298737005094822, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.932776970644581, 6.9112, 168.9128066346003, 1761181.771013905, 1745874.338998861, 371737.5165412119], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1943400.0000, 
sim time next is 1944000.0000, 
raw observation next is [26.8, 77.0, 1.0, 2.0, 0.6332061098174978, 1.0, 1.0, 0.6332061098174978, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1770493.010228548, 1770493.010228548, 346827.0876358328], 
processed observation next is [1.0, 0.5217391304347826, 0.4691943127962086, 0.77, 1.0, 1.0, 0.5580796503825275, 1.0, 0.5, 0.5580796503825275, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.49180361395237443, 0.49180361395237443, 0.5176523696057206], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2726012], dtype=float32), -0.34002793]. 
=============================================
[2019-03-26 19:11:13,353] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[47.503654]
 [47.4247  ]
 [47.353397]
 [47.75909 ]
 [47.66959 ]], R is [[47.15209198]
 [46.68057251]
 [46.21376801]
 [45.75162888]
 [45.29411316]].
[2019-03-26 19:11:21,599] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 55726: loss 1.6212
[2019-03-26 19:11:21,608] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 55727: learning rate 0.0000
[2019-03-26 19:11:21,625] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 55735: loss 1.5508
[2019-03-26 19:11:21,627] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 55735: learning rate 0.0000
[2019-03-26 19:11:21,846] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 55834: loss 1.6689
[2019-03-26 19:11:21,848] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 55834: learning rate 0.0000
[2019-03-26 19:11:21,963] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 55888: loss 1.7072
[2019-03-26 19:11:21,966] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 55889: learning rate 0.0000
[2019-03-26 19:11:22,039] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 55920: loss 1.6470
[2019-03-26 19:11:22,042] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 55921: learning rate 0.0000
[2019-03-26 19:11:22,050] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 55924: loss 1.6890
[2019-03-26 19:11:22,054] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 55924: learning rate 0.0000
[2019-03-26 19:11:22,087] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 55940: loss 1.6739
[2019-03-26 19:11:22,088] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 55940: learning rate 0.0000
[2019-03-26 19:11:22,090] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 55940: loss 1.6596
[2019-03-26 19:11:22,095] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 55940: learning rate 0.0000
[2019-03-26 19:11:22,174] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 55982: loss 1.6639
[2019-03-26 19:11:22,176] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 55982: learning rate 0.0000
[2019-03-26 19:11:22,257] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 56012: loss 1.5700
[2019-03-26 19:11:22,260] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 56015: learning rate 0.0000
[2019-03-26 19:11:22,382] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 56070: loss 1.6349
[2019-03-26 19:11:22,385] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 56071: learning rate 0.0000
[2019-03-26 19:11:22,413] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 56084: loss 1.5481
[2019-03-26 19:11:22,416] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 56085: learning rate 0.0000
[2019-03-26 19:11:22,482] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 56112: loss 1.5886
[2019-03-26 19:11:22,486] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 56113: learning rate 0.0000
[2019-03-26 19:11:22,542] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 56141: loss 1.5161
[2019-03-26 19:11:22,543] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 56141: learning rate 0.0000
[2019-03-26 19:11:22,735] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 56229: loss 1.6409
[2019-03-26 19:11:22,737] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 56229: learning rate 0.0000
[2019-03-26 19:11:22,763] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 56238: loss 1.5381
[2019-03-26 19:11:22,772] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 56239: learning rate 0.0000
[2019-03-26 19:11:28,957] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1684597e-13 1.0000000e+00 3.0539973e-11 1.1560563e-10 3.2549123e-13], sum to 1.0000
[2019-03-26 19:11:28,962] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5810
[2019-03-26 19:11:28,972] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2396024.631874281 W.
[2019-03-26 19:11:28,976] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.95, 66.5, 1.0, 2.0, 0.5711228402370171, 1.0, 1.0, 0.5711228402370171, 1.0, 2.0, 0.9918515002822804, 6.9112, 6.9112, 170.5573041426782, 2396024.631874281, 2396024.631874281, 467812.8072981542], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2215800.0000, 
sim time next is 2216400.0000, 
raw observation next is [31.93333333333333, 66.66666666666667, 1.0, 2.0, 0.5790467927138014, 1.0, 2.0, 0.5790467927138014, 1.0, 2.0, 1.005612785243327, 6.9112, 6.9112, 170.5573041426782, 2429300.205697396, 2429300.205697396, 474111.4863450146], 
processed observation next is [1.0, 0.6521739130434783, 0.7124802527646128, 0.6666666666666667, 1.0, 1.0, 0.4928274611009656, 1.0, 1.0, 0.4928274611009656, 1.0, 1.0, 1.0068448600528377, 0.0, 0.0, 0.8375144448122397, 0.6748056126937211, 0.6748056126937211, 0.7076290840970367], 
reward next is 0.2924, 
noisyNet noise sample is [array([0.98815185], dtype=float32), 1.3416663]. 
=============================================
[2019-03-26 19:11:30,245] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.6438256e-14 1.0000000e+00 3.6966766e-11 6.2443202e-12 2.0352720e-13], sum to 1.0000
[2019-03-26 19:11:30,252] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0661
[2019-03-26 19:11:30,259] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 82.33333333333334, 1.0, 2.0, 0.5445081688488133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 760887.8415388272, 760887.8415388279, 190863.5972684024], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2236200.0000, 
sim time next is 2236800.0000, 
raw observation next is [28.2, 82.66666666666667, 1.0, 2.0, 0.5433030048505412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 759203.1609540338, 759203.1609540345, 190659.0467544961], 
processed observation next is [1.0, 0.9130434782608695, 0.5355450236966824, 0.8266666666666667, 1.0, 1.0, 0.4497626564464351, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21088976693167608, 0.21088976693167627, 0.28456574142462104], 
reward next is 0.7154, 
noisyNet noise sample is [array([0.54126215], dtype=float32), 1.192624]. 
=============================================
[2019-03-26 19:11:36,289] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3714112e-14 1.0000000e+00 1.4992951e-11 1.9494167e-11 6.6645562e-14], sum to 1.0000
[2019-03-26 19:11:36,297] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0597
[2019-03-26 19:11:36,303] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.1, 81.0, 1.0, 2.0, 0.5344076175475718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 746768.5157886085, 746768.5157886085, 189162.5425645207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2336400.0000, 
sim time next is 2337000.0000, 
raw observation next is [28.05, 81.0, 1.0, 2.0, 0.5323853369376412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 743941.6393067535, 743941.6393067541, 188825.6811382481], 
processed observation next is [1.0, 0.043478260869565216, 0.528436018957346, 0.81, 1.0, 1.0, 0.43660883968390507, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2066504553629871, 0.20665045536298726, 0.28182937483320614], 
reward next is 0.7182, 
noisyNet noise sample is [array([0.47535133], dtype=float32), -2.3643458]. 
=============================================
[2019-03-26 19:11:36,320] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[56.606304]
 [56.79956 ]
 [57.01548 ]
 [57.28782 ]
 [57.507477]], R is [[56.46939468]
 [56.62236786]
 [56.77349091]
 [56.92274094]
 [57.07010269]].
[2019-03-26 19:11:39,397] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 63716: loss 2.2832
[2019-03-26 19:11:39,398] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 63717: learning rate 0.0000
[2019-03-26 19:11:39,439] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 63736: loss 2.5906
[2019-03-26 19:11:39,440] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 63737: learning rate 0.0000
[2019-03-26 19:11:39,640] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 63822: loss 2.4102
[2019-03-26 19:11:39,641] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 63823: learning rate 0.0000
[2019-03-26 19:11:39,792] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 63889: loss 2.1074
[2019-03-26 19:11:39,794] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 63891: learning rate 0.0000
[2019-03-26 19:11:39,833] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 63907: loss 1.8187
[2019-03-26 19:11:39,835] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 63907: learning rate 0.0000
[2019-03-26 19:11:39,870] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 63923: loss 0.9182
[2019-03-26 19:11:39,872] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 63924: learning rate 0.0000
[2019-03-26 19:11:39,902] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 63939: loss 1.4725
[2019-03-26 19:11:39,905] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 63940: learning rate 0.0000
[2019-03-26 19:11:39,952] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 63959: loss 1.3215
[2019-03-26 19:11:39,954] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 63959: learning rate 0.0000
[2019-03-26 19:11:39,981] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 63972: loss 2.1238
[2019-03-26 19:11:39,982] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 63972: learning rate 0.0000
[2019-03-26 19:11:40,014] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 63984: loss 0.7484
[2019-03-26 19:11:40,018] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 63985: learning rate 0.0000
[2019-03-26 19:11:40,225] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 64082: loss 0.6501
[2019-03-26 19:11:40,226] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 64082: learning rate 0.0000
[2019-03-26 19:11:40,247] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 64089: loss 1.5752
[2019-03-26 19:11:40,253] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 64090: learning rate 0.0000
[2019-03-26 19:11:40,383] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 64152: loss 1.5021
[2019-03-26 19:11:40,386] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 64152: learning rate 0.0000
[2019-03-26 19:11:40,421] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 64166: loss 0.4082
[2019-03-26 19:11:40,423] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 64166: learning rate 0.0000
[2019-03-26 19:11:40,694] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 64291: loss 1.1496
[2019-03-26 19:11:40,700] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 64291: learning rate 0.0000
[2019-03-26 19:11:40,764] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 64324: loss 1.8430
[2019-03-26 19:11:40,767] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 64324: learning rate 0.0000
[2019-03-26 19:11:41,061] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.9781521e-15 1.0000000e+00 1.2866487e-11 1.0215007e-11 1.5103987e-13], sum to 1.0000
[2019-03-26 19:11:41,072] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5848
[2019-03-26 19:11:41,075] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 77.33333333333334, 1.0, 2.0, 0.5780193806038082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 807733.7294120664, 807733.729412067, 196722.4401446359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2410800.0000, 
sim time next is 2411400.0000, 
raw observation next is [29.9, 77.66666666666666, 1.0, 2.0, 0.5762160637791944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 805212.7898215837, 805212.7898215842, 196398.7064164983], 
processed observation next is [1.0, 0.9130434782608695, 0.6161137440758293, 0.7766666666666666, 1.0, 1.0, 0.48941694431228244, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22367021939488435, 0.22367021939488452, 0.2931323976365646], 
reward next is 0.7069, 
noisyNet noise sample is [array([-0.54684377], dtype=float32), -1.1404568]. 
=============================================
[2019-03-26 19:11:41,701] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9391395e-16 1.0000000e+00 1.6633513e-12 2.5763228e-12 2.3326888e-14], sum to 1.0000
[2019-03-26 19:11:41,711] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7595
[2019-03-26 19:11:41,716] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.9, 80.0, 1.0, 2.0, 0.5547100137790519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 775148.9538129104, 775148.9538129104, 192611.8932705215], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2421600.0000, 
sim time next is 2422200.0000, 
raw observation next is [28.85, 80.0, 1.0, 2.0, 0.5530945427769307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 772890.6815433354, 772890.681543336, 192332.9599338659], 
processed observation next is [1.0, 0.0, 0.5663507109004741, 0.8, 1.0, 1.0, 0.4615596900926876, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21469185598425986, 0.21469185598426, 0.28706411930427744], 
reward next is 0.7129, 
noisyNet noise sample is [array([1.4361565], dtype=float32), -0.12470704]. 
=============================================
[2019-03-26 19:11:42,170] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.2634848e-15 1.0000000e+00 1.3059655e-12 1.8242157e-12 2.3306476e-14], sum to 1.0000
[2019-03-26 19:11:42,174] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0541
[2019-03-26 19:11:42,279] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.76666666666667, 80.0, 1.0, 2.0, 0.5502540305683199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 768919.9317527176, 768919.9317527176, 191844.3924685367], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2423400.0000, 
sim time next is 2424000.0000, 
raw observation next is [28.73333333333333, 80.0, 1.0, 2.0, 0.5487826762094897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 766863.1324832169, 766863.1324832164, 191592.2849676814], 
processed observation next is [1.0, 0.043478260869565216, 0.560821484992101, 0.8, 1.0, 1.0, 0.4563646701319153, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21301753680089358, 0.21301753680089344, 0.28595863428012147], 
reward next is 0.7140, 
noisyNet noise sample is [array([0.62126845], dtype=float32), 0.49092412]. 
=============================================
[2019-03-26 19:11:42,308] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[55.332336]
 [55.598362]
 [55.768047]
 [55.97591 ]
 [56.22657 ]], R is [[55.29698563]
 [55.45767975]
 [55.61641312]
 [55.77318573]
 [55.9279747 ]].
[2019-03-26 19:11:47,726] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.9835258e-15 1.0000000e+00 7.3040726e-11 6.1686767e-12 2.8727842e-13], sum to 1.0000
[2019-03-26 19:11:47,735] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7131
[2019-03-26 19:11:47,741] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 95.33333333333333, 1.0, 2.0, 0.7050951351341217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 985393.8444012653, 985393.8444012653, 221949.5710385862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2528400.0000, 
sim time next is 2529000.0000, 
raw observation next is [26.35, 95.0, 1.0, 2.0, 0.7298930664276032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1020066.420432293, 1020066.420432294, 227430.54580256], 
processed observation next is [1.0, 0.2608695652173913, 0.4478672985781992, 0.95, 1.0, 1.0, 0.6745699595513291, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2833517834534147, 0.283351783453415, 0.33944857582471644], 
reward next is 0.6606, 
noisyNet noise sample is [array([0.23932584], dtype=float32), -0.24327609]. 
=============================================
[2019-03-26 19:11:47,758] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[54.73582 ]
 [54.524864]
 [54.44263 ]
 [54.40882 ]
 [54.54895 ]], R is [[54.84028625]
 [54.96061707]
 [55.07760239]
 [55.20399857]
 [55.3086853 ]].
[2019-03-26 19:11:47,789] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.0133529e-14 1.0000000e+00 1.9509939e-11 8.0765594e-12 2.0029616e-13], sum to 1.0000
[2019-03-26 19:11:47,799] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0146
[2019-03-26 19:11:47,805] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.36666666666667, 94.66666666666666, 1.0, 2.0, 0.6889343645853419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 962798.393559916, 962798.393559916, 218475.4372980976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2529600.0000, 
sim time next is 2530200.0000, 
raw observation next is [26.38333333333333, 94.33333333333334, 1.0, 2.0, 0.6745944939554251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 942749.2668443718, 942749.2668443718, 215457.5680809156], 
processed observation next is [1.0, 0.2608695652173913, 0.44944707740916257, 0.9433333333333335, 1.0, 1.0, 0.6079451734402712, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.26187479634565886, 0.26187479634565886, 0.3215784598222621], 
reward next is 0.6784, 
noisyNet noise sample is [array([-0.95008415], dtype=float32), -0.3338085]. 
=============================================
[2019-03-26 19:11:53,145] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.4155849e-13 1.0000000e+00 2.3483404e-10 6.5956629e-10 1.7692146e-11], sum to 1.0000
[2019-03-26 19:11:53,153] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0967
[2019-03-26 19:11:53,157] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 86.5, 1.0, 2.0, 0.4660689571230514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 655977.7309307858, 655977.7309307863, 179061.9022285829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2619000.0000, 
sim time next is 2619600.0000, 
raw observation next is [25.66666666666666, 85.66666666666667, 1.0, 2.0, 0.4682794274503636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 657664.9178185721, 657664.9178185728, 179205.7604229623], 
processed observation next is [0.0, 0.30434782608695654, 0.4154818325434437, 0.8566666666666667, 1.0, 1.0, 0.35937280415706463, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18268469939404783, 0.18268469939404802, 0.26747128421337657], 
reward next is 0.7325, 
noisyNet noise sample is [array([-0.8717306], dtype=float32), 0.18629448]. 
=============================================
[2019-03-26 19:11:56,646] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.7007436e-13 1.0000000e+00 1.4162083e-10 1.8529306e-10 5.2955552e-12], sum to 1.0000
[2019-03-26 19:11:56,657] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7835
[2019-03-26 19:11:56,662] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 98.0, 1.0, 2.0, 0.4309244411845149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 623563.9284298284, 623563.9284298284, 176236.7602489321], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2683200.0000, 
sim time next is 2683800.0000, 
raw observation next is [23.5, 97.0, 1.0, 2.0, 0.4332689551429648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 625832.8628156359, 625832.8628156359, 176427.988253219], 
processed observation next is [0.0, 0.043478260869565216, 0.31279620853080575, 0.97, 1.0, 1.0, 0.3171915122204395, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1738424618932322, 0.1738424618932322, 0.2633253556018194], 
reward next is 0.7367, 
noisyNet noise sample is [array([0.23396145], dtype=float32), -0.95733327]. 
=============================================
[2019-03-26 19:11:57,331] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 71703: loss 1.5328
[2019-03-26 19:11:57,335] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 71705: learning rate 0.0000
[2019-03-26 19:11:57,354] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 71715: loss 1.4035
[2019-03-26 19:11:57,359] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 71716: learning rate 0.0000
[2019-03-26 19:11:57,540] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 71799: loss 1.4598
[2019-03-26 19:11:57,541] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 71800: learning rate 0.0000
[2019-03-26 19:11:57,599] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71822: loss 1.3866
[2019-03-26 19:11:57,601] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 71822: learning rate 0.0000
[2019-03-26 19:11:57,637] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 71838: loss 1.3878
[2019-03-26 19:11:57,638] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 71838: learning rate 0.0000
[2019-03-26 19:11:57,751] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 71892: loss 1.5013
[2019-03-26 19:11:57,753] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 71892: learning rate 0.0000
[2019-03-26 19:11:57,913] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 71967: loss 1.4345
[2019-03-26 19:11:57,917] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 71967: learning rate 0.0000
[2019-03-26 19:11:57,930] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 71975: loss 1.3927
[2019-03-26 19:11:57,932] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 71976: learning rate 0.0000
[2019-03-26 19:11:57,977] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 71992: loss 1.3798
[2019-03-26 19:11:57,981] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 71992: learning rate 0.0000
[2019-03-26 19:11:58,138] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 72067: loss 1.4670
[2019-03-26 19:11:58,140] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 72067: learning rate 0.0000
[2019-03-26 19:11:58,164] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 72076: loss 1.4017
[2019-03-26 19:11:58,166] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 72076: learning rate 0.0000
[2019-03-26 19:11:58,249] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 72116: loss 1.4001
[2019-03-26 19:11:58,250] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 72118: learning rate 0.0000
[2019-03-26 19:11:58,266] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 72126: loss 1.4242
[2019-03-26 19:11:58,268] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 72126: learning rate 0.0000
[2019-03-26 19:11:58,348] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 72157: loss 1.4773
[2019-03-26 19:11:58,349] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 72157: learning rate 0.0000
[2019-03-26 19:11:58,499] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 72228: loss 1.4012
[2019-03-26 19:11:58,505] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 72229: learning rate 0.0000
[2019-03-26 19:11:58,717] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 72325: loss 1.4020
[2019-03-26 19:11:58,721] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 72325: learning rate 0.0000
[2019-03-26 19:12:01,058] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1014492e-14 1.0000000e+00 3.7764743e-11 5.7117595e-11 7.4717158e-13], sum to 1.0000
[2019-03-26 19:12:01,069] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0732
[2019-03-26 19:12:01,077] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 95.0, 1.0, 2.0, 0.3911062162407326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 584174.1603886123, 584174.1603886123, 173103.7404002603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2747400.0000, 
sim time next is 2748000.0000, 
raw observation next is [22.66666666666667, 96.0, 1.0, 2.0, 0.3899526964879866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 583306.3079049023, 583306.3079049016, 173051.4434765129], 
processed observation next is [0.0, 0.8260869565217391, 0.27330173775671435, 0.96, 1.0, 1.0, 0.26500324878070675, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16202952997358397, 0.16202952997358377, 0.25828573653210884], 
reward next is 0.7417, 
noisyNet noise sample is [array([1.1143516], dtype=float32), -0.42511392]. 
=============================================
[2019-03-26 19:12:01,092] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[51.85147 ]
 [51.8022  ]
 [51.759758]
 [51.718555]
 [51.666943]], R is [[52.11964798]
 [52.34008789]
 [52.55818939]
 [52.77389526]
 [52.98734283]].
[2019-03-26 19:12:04,653] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 19:12:04,654] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:12:04,655] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:12:04,655] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:12:04,655] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:12:04,656] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:12:04,656] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:12:04,656] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:12:04,658] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:12:04,661] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:12:04,660] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:12:04,681] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run4
[2019-03-26 19:12:04,699] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run4
[2019-03-26 19:12:04,720] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run4
[2019-03-26 19:12:04,720] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run4
[2019-03-26 19:12:04,752] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run4
[2019-03-26 19:12:08,244] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04227491], dtype=float32), 0.050825693]
[2019-03-26 19:12:08,245] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [20.95, 76.5, 1.0, 2.0, 0.256774358388316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 422565.9762311082, 422565.9762311075, 161576.9304545495]
[2019-03-26 19:12:08,247] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:12:08,251] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.0732827e-12 1.0000000e+00 8.3351392e-10 6.3163541e-10 1.9377357e-11], sampled 0.7212156221774515
[2019-03-26 19:12:12,922] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04227491], dtype=float32), 0.050825693]
[2019-03-26 19:12:12,923] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.05, 74.0, 1.0, 2.0, 0.3075215585899375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 492330.2077422648, 492330.2077422641, 166540.1115642805]
[2019-03-26 19:12:12,925] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:12:12,928] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.17935430e-14 1.00000000e+00 1.04783925e-11 1.48365764e-11
 2.33108427e-13], sampled 0.5279303203213633
[2019-03-26 19:12:24,091] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04227491], dtype=float32), 0.050825693]
[2019-03-26 19:12:24,094] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.98514422, 77.19883146, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.325589305357572, 6.9112, 168.9105925456277, 1747934.196027124, 1453956.274954546, 311353.5751280135]
[2019-03-26 19:12:24,094] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:12:24,097] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.4131978e-16 1.0000000e+00 3.7933702e-13 9.9988138e-13 9.0335276e-15], sampled 0.199529924457596
[2019-03-26 19:12:24,099] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1747934.196027124 W.
[2019-03-26 19:13:18,898] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04227491], dtype=float32), 0.050825693]
[2019-03-26 19:13:18,899] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.01666666666667, 62.5, 1.0, 2.0, 0.6759777585446368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 944683.2459729238, 944683.2459729232, 215751.9224778498]
[2019-03-26 19:13:18,900] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:13:18,903] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.5967037e-15 1.0000000e+00 1.7212625e-12 3.1488854e-12 4.7064932e-14], sampled 0.46409513477371744
[2019-03-26 19:13:59,085] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.1321 2842492854.9742 1131.0000
[2019-03-26 19:13:59,149] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 19:13:59,586] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6673 3164091574.6358 1778.0000
[2019-03-26 19:13:59,626] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2605 3007618784.0356 1766.0000
[2019-03-26 19:13:59,642] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4308 2779149198.4617 933.0000
[2019-03-26 19:14:00,658] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 75000, evaluation results [75000.0, 7882.667340288573, 3164091574.635788, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8661.430759135581, 2779149198.4616733, 933.0, 7998.26053894139, 3007618784.0355844, 1766.0, 8496.132107770307, 2842492854.9741545, 1131.0]
[2019-03-26 19:14:01,625] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.9032876e-17 1.0000000e+00 5.8449182e-13 1.6169355e-13 6.4597125e-16], sum to 1.0000
[2019-03-26 19:14:01,635] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2358
[2019-03-26 19:14:01,638] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.4059744611742992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 598168.7936836937, 598168.793683693, 174143.7409613761], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2828400.0000, 
sim time next is 2829000.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.4040913762003742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 595394.5450848016, 595394.545084801, 173887.1380199762], 
processed observation next is [1.0, 0.7391304347826086, 0.3364928909952607, 0.89, 1.0, 1.0, 0.28203780265105327, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16538737363466713, 0.16538737363466696, 0.25953304182086], 
reward next is 0.7405, 
noisyNet noise sample is [array([-1.6436402], dtype=float32), 0.54103625]. 
=============================================
[2019-03-26 19:14:01,652] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[63.49984]
 [63.38213]
 [63.50554]
 [63.53166]
 [63.5199 ]], R is [[63.56882858]
 [63.6732254 ]
 [63.7769928 ]
 [63.87956619]
 [63.96368027]].
[2019-03-26 19:14:03,802] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9318272e-15 1.0000000e+00 1.5755054e-12 5.7173918e-12 1.5876184e-14], sum to 1.0000
[2019-03-26 19:14:03,810] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8011
[2019-03-26 19:14:03,822] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.463536188504447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 714057.5529147636, 714057.552914763, 186056.7008064638], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2859000.0000, 
sim time next is 2859600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3977644377628135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 612691.2463478635, 612691.2463478629, 176141.2239813128], 
processed observation next is [1.0, 0.08695652173913043, 0.2417061611374408, 0.94, 1.0, 1.0, 0.2744149852564018, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17019201287440652, 0.17019201287440636, 0.26289734922584], 
reward next is 0.7371, 
noisyNet noise sample is [array([-1.4504198], dtype=float32), -1.4809229]. 
=============================================
[2019-03-26 19:14:10,342] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 79690: loss 0.1002
[2019-03-26 19:14:10,345] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 79691: learning rate 0.0000
[2019-03-26 19:14:10,462] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 79709: loss 0.0819
[2019-03-26 19:14:10,466] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 79711: learning rate 0.0000
[2019-03-26 19:14:10,741] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 79809: loss 0.1002
[2019-03-26 19:14:10,745] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 79809: learning rate 0.0000
[2019-03-26 19:14:10,961] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 79880: loss 0.0913
[2019-03-26 19:14:10,965] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 79880: learning rate 0.0000
[2019-03-26 19:14:11,061] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 79891: loss 0.0992
[2019-03-26 19:14:11,065] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 79891: learning rate 0.0000
[2019-03-26 19:14:11,159] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 79906: loss 0.0705
[2019-03-26 19:14:11,160] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 79906: learning rate 0.0000
[2019-03-26 19:14:11,281] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 79938: loss 0.1008
[2019-03-26 19:14:11,288] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 79940: learning rate 0.0000
[2019-03-26 19:14:11,374] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 79950: loss 0.0730
[2019-03-26 19:14:11,377] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 79950: learning rate 0.0000
[2019-03-26 19:14:11,380] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 79952: loss 0.0989
[2019-03-26 19:14:11,457] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 79955: learning rate 0.0000
[2019-03-26 19:14:11,586] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 79983: loss 0.1051
[2019-03-26 19:14:11,588] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 79984: learning rate 0.0000
[2019-03-26 19:14:11,765] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 80044: loss 0.0849
[2019-03-26 19:14:11,766] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 80044: learning rate 0.0000
[2019-03-26 19:14:11,932] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 80084: loss 0.0853
[2019-03-26 19:14:11,935] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 80086: learning rate 0.0000
[2019-03-26 19:14:12,137] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 80147: loss 0.1079
[2019-03-26 19:14:12,139] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 80148: learning rate 0.0000
[2019-03-26 19:14:12,283] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 80187: loss 0.0835
[2019-03-26 19:14:12,286] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 80188: learning rate 0.0000
[2019-03-26 19:14:12,379] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 80199: loss 0.0924
[2019-03-26 19:14:12,380] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 80199: learning rate 0.0000
[2019-03-26 19:14:12,728] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 80334: loss 0.0827
[2019-03-26 19:14:12,730] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 80334: learning rate 0.0000
[2019-03-26 19:14:13,900] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.0635146e-17 1.0000000e+00 1.7755582e-13 9.0430139e-14 6.9171596e-16], sum to 1.0000
[2019-03-26 19:14:13,907] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3514
[2019-03-26 19:14:13,912] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3015956000108688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 480274.6810608006, 480274.6810608006, 165641.5433232328], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3027600.0000, 
sim time next is 3028200.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3019530957307914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 480844.2237597334, 480844.2237597327, 165682.3570734033], 
processed observation next is [1.0, 0.043478260869565216, 0.1469194312796209, 1.0, 1.0, 1.0, 0.15897963341059201, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13356783993325927, 0.13356783993325907, 0.24728710010955718], 
reward next is 0.7527, 
noisyNet noise sample is [array([-2.314031], dtype=float32), 0.55304587]. 
=============================================
[2019-03-26 19:14:19,866] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.5788475e-16 1.0000000e+00 1.0742744e-12 1.9273476e-12 2.4536573e-14], sum to 1.0000
[2019-03-26 19:14:19,875] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3573
[2019-03-26 19:14:19,879] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2212550e-16 1.0000000e+00 8.6318765e-12 8.8574612e-13 6.1967250e-14], sum to 1.0000
[2019-03-26 19:14:19,881] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.361786056609901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 556647.5646419071, 556647.5646419071, 171187.8250084225], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3124800.0000, 
sim time next is 3125400.0000, 
raw observation next is [21.83333333333334, 95.0, 1.0, 2.0, 0.3824516615590052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 589629.2817722468, 589629.2817722461, 174084.2236438014], 
processed observation next is [1.0, 0.17391304347826086, 0.23380726698262277, 0.95, 1.0, 1.0, 0.2559658573000062, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1637859116034019, 0.1637859116034017, 0.2598271994683603], 
reward next is 0.7402, 
noisyNet noise sample is [array([-0.7734629], dtype=float32), 0.39774498]. 
=============================================
[2019-03-26 19:14:19,889] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1740
[2019-03-26 19:14:19,895] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.361786056609901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 556647.5646419071, 556647.5646419071, 171187.8250084225], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3124800.0000, 
sim time next is 3125400.0000, 
raw observation next is [21.83333333333334, 95.0, 1.0, 2.0, 0.3824516615590052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 589629.2817722468, 589629.2817722461, 174084.2236438014], 
processed observation next is [1.0, 0.17391304347826086, 0.23380726698262277, 0.95, 1.0, 1.0, 0.2559658573000062, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1637859116034019, 0.1637859116034017, 0.2598271994683603], 
reward next is 0.7402, 
noisyNet noise sample is [array([0.02310084], dtype=float32), -0.14209804]. 
=============================================
[2019-03-26 19:14:23,200] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2011759e-19 1.0000000e+00 5.7896267e-14 1.2499685e-14 4.5153384e-16], sum to 1.0000
[2019-03-26 19:14:23,208] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0623
[2019-03-26 19:14:23,215] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 90.66666666666667, 1.0, 2.0, 0.4947539045591702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 691339.3272651251, 691339.3272651251, 182778.2510657697], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3180000.0000, 
sim time next is 3180600.0000, 
raw observation next is [25.5, 91.5, 1.0, 2.0, 0.4924721973161032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 688149.9741911981, 688149.9741911988, 182425.0814064551], 
processed observation next is [1.0, 0.8260869565217391, 0.40758293838862564, 0.915, 1.0, 1.0, 0.3885207196579557, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19115277060866614, 0.19115277060866634, 0.2722762409051569], 
reward next is 0.7277, 
noisyNet noise sample is [array([-0.21705016], dtype=float32), 0.8189175]. 
=============================================
[2019-03-26 19:14:24,755] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.4734694e-15 1.0000000e+00 5.3297137e-12 5.1007349e-12 4.8215243e-14], sum to 1.0000
[2019-03-26 19:14:24,765] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0251
[2019-03-26 19:14:24,771] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 78.16666666666667, 1.0, 2.0, 0.4784003462120729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 668480.6591032878, 668480.6591032878, 180281.2126089916], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3226200.0000, 
sim time next is 3226800.0000, 
raw observation next is [27.33333333333334, 77.33333333333334, 1.0, 2.0, 0.4801970682299169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 670992.0562059153, 670992.0562059153, 180551.6786721637], 
processed observation next is [0.0, 0.34782608695652173, 0.4944707740916275, 0.7733333333333334, 1.0, 1.0, 0.373731407505924, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1863866822794209, 0.1863866822794209, 0.2694801174211398], 
reward next is 0.7305, 
noisyNet noise sample is [array([-0.25590512], dtype=float32), 1.0358304]. 
=============================================
[2019-03-26 19:14:26,522] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1393423e-15 1.0000000e+00 4.7920166e-12 3.4639921e-12 3.1064320e-14], sum to 1.0000
[2019-03-26 19:14:26,532] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5140
[2019-03-26 19:14:26,537] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.66666666666667, 63.0, 1.0, 2.0, 0.5639949699404903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 788128.5179131179, 788128.5179131179, 194231.0397517385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3246000.0000, 
sim time next is 3246600.0000, 
raw observation next is [32.83333333333333, 63.0, 1.0, 2.0, 0.5693407449678668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 795601.5200955024, 795601.5200955024, 195174.2476920109], 
processed observation next is [0.0, 0.5652173913043478, 0.7551342812006318, 0.63, 1.0, 1.0, 0.48113342767212863, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22100042224875066, 0.22100042224875066, 0.2913048473015088], 
reward next is 0.7087, 
noisyNet noise sample is [array([-0.8442966], dtype=float32), 2.4710932]. 
=============================================
[2019-03-26 19:14:26,935] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0691900e-16 1.0000000e+00 1.2338947e-13 4.0185117e-14 4.6079821e-15], sum to 1.0000
[2019-03-26 19:14:26,944] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3037
[2019-03-26 19:14:26,949] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.0, 63.0, 1.0, 2.0, 0.5819015969336226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813160.8786120126, 813160.8786120126, 197423.2344444387], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3247800.0000, 
sim time next is 3248400.0000, 
raw observation next is [33.0, 63.00000000000001, 1.0, 2.0, 0.5794404456166239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 809720.305816154, 809720.305816154, 196978.9719834855], 
processed observation next is [0.0, 0.6086956521739131, 0.7630331753554502, 0.6300000000000001, 1.0, 1.0, 0.49330174170677576, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22492230717115388, 0.22492230717115388, 0.2939984656469933], 
reward next is 0.7060, 
noisyNet noise sample is [array([-0.69041896], dtype=float32), -0.6455156]. 
=============================================
[2019-03-26 19:14:29,121] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 87654: loss 0.1108
[2019-03-26 19:14:29,124] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 87654: learning rate 0.0000
[2019-03-26 19:14:29,140] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 87659: loss 0.1693
[2019-03-26 19:14:29,144] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 87659: learning rate 0.0000
[2019-03-26 19:14:29,491] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 87819: loss 0.1235
[2019-03-26 19:14:29,497] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 87821: learning rate 0.0000
[2019-03-26 19:14:29,664] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 87893: loss 0.1589
[2019-03-26 19:14:29,666] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 87893: learning rate 0.0000
[2019-03-26 19:14:29,726] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 87919: loss 0.1151
[2019-03-26 19:14:29,728] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 87919: learning rate 0.0000
[2019-03-26 19:14:29,744] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 87930: loss 0.1785
[2019-03-26 19:14:29,746] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 87930: learning rate 0.0000
[2019-03-26 19:14:29,767] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 87940: loss 0.1305
[2019-03-26 19:14:29,769] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 87940: learning rate 0.0000
[2019-03-26 19:14:29,791] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 87952: loss 0.1532
[2019-03-26 19:14:29,793] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 87952: learning rate 0.0000
[2019-03-26 19:14:29,798] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 87953: loss 0.0993
[2019-03-26 19:14:29,802] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 87954: learning rate 0.0000
[2019-03-26 19:14:30,026] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 88056: loss 0.1735
[2019-03-26 19:14:30,029] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 88056: learning rate 0.0000
[2019-03-26 19:14:30,048] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 88063: loss 0.1109
[2019-03-26 19:14:30,059] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 88064: learning rate 0.0000
[2019-03-26 19:14:30,112] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 88095: loss 0.1905
[2019-03-26 19:14:30,114] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 88095: learning rate 0.0000
[2019-03-26 19:14:30,189] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 88129: loss 0.1182
[2019-03-26 19:14:30,191] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 88129: learning rate 0.0000
[2019-03-26 19:14:30,336] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 88193: loss 0.1587
[2019-03-26 19:14:30,338] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 88194: learning rate 0.0000
[2019-03-26 19:14:30,354] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 88202: loss 0.0874
[2019-03-26 19:14:30,356] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 88202: learning rate 0.0000
[2019-03-26 19:14:30,629] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.5767279e-15 1.0000000e+00 6.0297344e-12 9.2203961e-12 6.4626310e-13], sum to 1.0000
[2019-03-26 19:14:30,639] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4747
[2019-03-26 19:14:30,647] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 72.66666666666667, 1.0, 2.0, 0.4904327901074785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 685299.3143714768, 685299.3143714775, 182110.7996345521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3313200.0000, 
sim time next is 3313800.0000, 
raw observation next is [28.5, 72.0, 1.0, 2.0, 0.4921111322998788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 687645.2811283108, 687645.2811283114, 182369.4389374428], 
processed observation next is [0.0, 0.34782608695652173, 0.5497630331753555, 0.72, 1.0, 1.0, 0.388085701566119, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19101257809119745, 0.19101257809119762, 0.2721931924439445], 
reward next is 0.7278, 
noisyNet noise sample is [array([-1.3000842], dtype=float32), -0.5196116]. 
=============================================
[2019-03-26 19:14:30,666] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 88338: loss 0.1017
[2019-03-26 19:14:30,667] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 88338: learning rate 0.0000
[2019-03-26 19:14:34,987] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0707075e-18 1.0000000e+00 1.2775385e-13 4.3067790e-14 5.6111608e-16], sum to 1.0000
[2019-03-26 19:14:34,994] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8936
[2019-03-26 19:14:35,092] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 92.33333333333334, 1.0, 2.0, 0.8219963233802569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1148855.509134595, 1148855.509134595, 249381.2279087122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3388800.0000, 
sim time next is 3389400.0000, 
raw observation next is [26.5, 91.5, 1.0, 2.0, 0.8171736454974532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1142111.5132643, 1142111.5132643, 248169.615476196], 
processed observation next is [1.0, 0.21739130434782608, 0.4549763033175356, 0.915, 1.0, 1.0, 0.7797272837318713, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.31725319812897224, 0.31725319812897224, 0.3704024111585015], 
reward next is 0.6296, 
noisyNet noise sample is [array([-1.9652206], dtype=float32), -1.2420442]. 
=============================================
[2019-03-26 19:14:37,618] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0879220e-17 1.0000000e+00 8.5795561e-14 4.1996127e-14 6.7711925e-16], sum to 1.0000
[2019-03-26 19:14:37,625] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7283
[2019-03-26 19:14:37,632] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2476449.548809365 W.
[2019-03-26 19:14:37,728] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 66.5, 1.0, 2.0, 0.5902741612727836, 1.0, 2.0, 0.5902741612727836, 1.0, 1.0, 1.02511101148276, 6.9112, 6.9112, 170.5573041426782, 2476449.548809365, 2476449.548809365, 483183.9534743266], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3429000.0000, 
sim time next is 3429600.0000, 
raw observation next is [31.66666666666666, 67.66666666666667, 1.0, 2.0, 0.5848687322188065, 1.0, 2.0, 0.5848687322188065, 1.0, 2.0, 1.015723568818706, 6.9112, 6.9112, 170.5573041426782, 2453749.223159217, 2453749.223159217, 478794.2774818378], 
processed observation next is [1.0, 0.6956521739130435, 0.6998420221169034, 0.6766666666666667, 1.0, 1.0, 0.49984184604675486, 1.0, 1.0, 0.49984184604675486, 1.0, 1.0, 1.0191750839252514, 0.0, 0.0, 0.8375144448122397, 0.6815970064331158, 0.6815970064331158, 0.7146183245997578], 
reward next is 0.2854, 
noisyNet noise sample is [array([-0.34029925], dtype=float32), -1.1161087]. 
=============================================
[2019-03-26 19:14:42,172] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7193903e-16 1.0000000e+00 1.6342209e-13 3.3809166e-12 6.6636760e-15], sum to 1.0000
[2019-03-26 19:14:42,178] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5811
[2019-03-26 19:14:42,179] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2106806.201918879 W.
[2019-03-26 19:14:42,183] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.5, 65.0, 1.0, 2.0, 0.7533683409787825, 1.0, 1.0, 0.7533683409787825, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2106806.201918879, 2106806.20191888, 397815.2172754777], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3501000.0000, 
sim time next is 3501600.0000, 
raw observation next is [32.66666666666667, 64.33333333333334, 1.0, 2.0, 0.7803813883056274, 1.0, 2.0, 0.7803813883056274, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2182425.561878879, 2182425.561878878, 410440.0099967236], 
processed observation next is [1.0, 0.5217391304347826, 0.7472353870458138, 0.6433333333333334, 1.0, 1.0, 0.7353992630188282, 1.0, 1.0, 0.7353992630188282, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6062293227441331, 0.6062293227441328, 0.6125970298458562], 
reward next is 0.3874, 
noisyNet noise sample is [array([0.9032931], dtype=float32), 1.8103135]. 
=============================================
[2019-03-26 19:14:47,285] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 95710: loss -112.3743
[2019-03-26 19:14:47,290] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 95710: learning rate 0.0000
[2019-03-26 19:14:47,349] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 95737: loss -96.4638
[2019-03-26 19:14:47,350] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 95738: learning rate 0.0000
[2019-03-26 19:14:47,616] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 95855: loss -176.7233
[2019-03-26 19:14:47,618] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 95855: learning rate 0.0000
[2019-03-26 19:14:47,744] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 95912: loss -126.9196
[2019-03-26 19:14:47,747] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 95912: learning rate 0.0000
[2019-03-26 19:14:47,785] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 95933: loss -120.6778
[2019-03-26 19:14:47,788] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 95933: learning rate 0.0000
[2019-03-26 19:14:47,818] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 95945: loss -71.2824
[2019-03-26 19:14:47,819] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 95946: loss -195.8051
[2019-03-26 19:14:47,820] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 95947: learning rate 0.0000
[2019-03-26 19:14:47,822] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 95947: learning rate 0.0000
[2019-03-26 19:14:47,880] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 95970: loss -80.1960
[2019-03-26 19:14:47,882] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 95970: loss -151.9980
[2019-03-26 19:14:47,884] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 95970: learning rate 0.0000
[2019-03-26 19:14:47,887] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 95970: learning rate 0.0000
[2019-03-26 19:14:48,026] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 96035: loss -229.3071
[2019-03-26 19:14:48,031] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 96036: learning rate 0.0000
[2019-03-26 19:14:48,039] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 96043: loss -242.8874
[2019-03-26 19:14:48,041] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 96043: learning rate 0.0000
[2019-03-26 19:14:48,135] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 96085: loss -157.1530
[2019-03-26 19:14:48,138] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 96087: learning rate 0.0000
[2019-03-26 19:14:48,141] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 96087: loss -155.7293
[2019-03-26 19:14:48,143] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 96088: learning rate 0.0000
[2019-03-26 19:14:48,318] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 96166: loss -157.9733
[2019-03-26 19:14:48,319] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 96166: learning rate 0.0000
[2019-03-26 19:14:48,547] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 96267: loss -166.1686
[2019-03-26 19:14:48,549] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 96267: learning rate 0.0000
[2019-03-26 19:14:48,638] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 96307: loss -119.0342
[2019-03-26 19:14:48,640] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 96307: learning rate 0.0000
[2019-03-26 19:14:56,703] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7877313e-16 1.0000000e+00 1.5584479e-13 2.2144677e-14 1.8758791e-16], sum to 1.0000
[2019-03-26 19:14:56,708] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2312
[2019-03-26 19:14:56,719] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2062983.959265002 W.
[2019-03-26 19:14:56,724] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 70.0, 1.0, 2.0, 0.4918087420556662, 1.0, 2.0, 0.4918087420556662, 1.0, 1.0, 0.8370957068639571, 6.9112, 6.9112, 170.5573041426782, 2062983.959265002, 2062983.959265002, 406473.3558160912], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3746400.0000, 
sim time next is 3747000.0000, 
raw observation next is [29.0, 70.0, 1.0, 2.0, 0.8454169978441758, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.972791119782486, 6.9112, 168.9125894608698, 2078638.158959193, 2034943.393732124, 420494.9932672253], 
processed observation next is [1.0, 0.34782608695652173, 0.5734597156398105, 0.7, 1.0, 1.0, 0.8137554190893684, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.006159111978248611, 0.0, 0.8294381427709212, 0.5773994885997759, 0.5652620538144789, 0.6276044675630228], 
reward next is 0.0644, 
noisyNet noise sample is [array([0.15927756], dtype=float32), -0.54407924]. 
=============================================
[2019-03-26 19:14:56,749] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[66.18069 ]
 [66.42349 ]
 [66.538445]
 [66.220436]
 [65.96243 ]], R is [[65.31555176]
 [65.0557251 ]
 [64.75084686]
 [64.10334015]
 [64.040802  ]].
[2019-03-26 19:14:56,865] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 19:14:56,866] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:14:56,867] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:14:56,867] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:14:56,868] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:14:56,868] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:14:56,870] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:14:56,870] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:14:56,870] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:14:56,871] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:14:56,874] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:14:56,894] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run5
[2019-03-26 19:14:56,894] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run5
[2019-03-26 19:14:56,894] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run5
[2019-03-26 19:14:56,947] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run5
[2019-03-26 19:14:56,967] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run5
[2019-03-26 19:15:17,733] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04623463], dtype=float32), 0.054562334]
[2019-03-26 19:15:17,734] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.63333333333333, 55.33333333333334, 1.0, 2.0, 0.2780890495636003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 455558.539575731, 455558.5395757304, 163806.5424939839]
[2019-03-26 19:15:17,736] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:15:17,739] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.9575638e-15 1.0000000e+00 3.0908795e-12 3.7745492e-12 6.9597540e-14], sampled 0.3395424667807948
[2019-03-26 19:15:35,939] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04623463], dtype=float32), 0.054562334]
[2019-03-26 19:15:35,942] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.55, 94.0, 1.0, 2.0, 0.4884136833719727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 684781.0828366879, 684781.0828366879, 182096.8427798822]
[2019-03-26 19:15:35,945] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:15:35,947] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.0394969e-16 1.0000000e+00 3.3205789e-13 5.1249364e-13 6.0183847e-15], sampled 0.07236746241533665
[2019-03-26 19:15:48,490] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04623463], dtype=float32), 0.054562334]
[2019-03-26 19:15:48,493] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.05, 84.0, 1.0, 2.0, 0.522595952874793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730257.5025111719, 730257.5025111719, 187211.4015552242]
[2019-03-26 19:15:48,494] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:15:48,498] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.3186599e-17 1.0000000e+00 8.9650970e-14 2.0078614e-13 1.1624966e-15], sampled 0.35895976205488755
[2019-03-26 19:16:08,668] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04623463], dtype=float32), 0.054562334]
[2019-03-26 19:16:08,669] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.57884538333333, 78.33823529, 1.0, 2.0, 0.6218242191781677, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.92921199217451, 6.9112, 168.9128428016408, 1738656.281904349, 1725877.963332936, 369942.4884948288]
[2019-03-26 19:16:08,670] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:16:08,672] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.4485321e-15 1.0000000e+00 1.8286364e-12 2.9500356e-12 5.1897380e-14], sampled 0.010027633141285408
[2019-03-26 19:16:08,674] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1738656.281904349 W.
[2019-03-26 19:16:10,123] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04623463], dtype=float32), 0.054562334]
[2019-03-26 19:16:10,124] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.88571024666667, 84.09582312666667, 1.0, 2.0, 0.448982013929365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 649817.0278310522, 649817.0278310529, 178856.9160423405]
[2019-03-26 19:16:10,125] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:16:10,128] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.1896312e-17 1.0000000e+00 9.6568017e-14 1.6700359e-13 1.6949039e-15], sampled 0.9842074912631023
[2019-03-26 19:16:24,744] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04623463], dtype=float32), 0.054562334]
[2019-03-26 19:16:24,746] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.03333333333333, 94.33333333333334, 1.0, 2.0, 0.5335523139768186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 745572.9154383411, 745572.9154383418, 189019.6070186341]
[2019-03-26 19:16:24,749] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:16:24,752] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.7531040e-17 1.0000000e+00 1.4923009e-13 1.6288590e-13 2.0921286e-15], sampled 0.6198868308441684
[2019-03-26 19:16:51,065] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8724 2842497929.8887 1131.0000
[2019-03-26 19:16:51,762] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4188 3164139523.4469 1778.0000
[2019-03-26 19:16:51,775] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.9085 2927359888.4909 1338.0000
[2019-03-26 19:16:51,784] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7281 2779199535.5119 933.0000
[2019-03-26 19:16:51,825] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2767 3007680316.3481 1766.0000
[2019-03-26 19:16:52,839] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 100000, evaluation results [100000.0, 7883.41881391125, 3164139523.4469013, 1778.0, 8252.908535966402, 2927359888.490912, 1338.0, 8660.728066421085, 2779199535.5119066, 933.0, 7998.276703650782, 3007680316.348062, 1766.0, 8496.87235025343, 2842497929.888741, 1131.0]
[2019-03-26 19:16:57,943] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.30625308e-16 1.00000000e+00 2.68719481e-13 3.73191766e-13
 1.01900435e-14], sum to 1.0000
[2019-03-26 19:16:57,948] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0566
[2019-03-26 19:16:57,953] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.0, 63.0, 1.0, 2.0, 0.616474343870628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861493.1167962622, 861493.1167962622, 203856.0112491574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3844200.0000, 
sim time next is 3844800.0000, 
raw observation next is [34.0, 63.0, 1.0, 2.0, 0.6167753717940899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861913.9594688974, 861913.9594688974, 203913.5549506455], 
processed observation next is [0.0, 0.5217391304347826, 0.8104265402843602, 0.63, 1.0, 1.0, 0.5382835804748071, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23942054429691595, 0.23942054429691595, 0.3043485894785754], 
reward next is 0.6957, 
noisyNet noise sample is [array([-0.34889734], dtype=float32), -0.0058359]. 
=============================================
[2019-03-26 19:17:00,275] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 103641: loss 0.2669
[2019-03-26 19:17:00,277] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 103642: learning rate 0.0000
[2019-03-26 19:17:00,442] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 103718: loss 0.2849
[2019-03-26 19:17:00,444] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 103718: learning rate 0.0000
[2019-03-26 19:17:00,689] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 103824: loss 0.2946
[2019-03-26 19:17:00,696] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 103828: learning rate 0.0000
[2019-03-26 19:17:00,748] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 103854: loss 0.2191
[2019-03-26 19:17:00,750] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 103855: learning rate 0.0000
[2019-03-26 19:17:00,858] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 103900: loss 0.2646
[2019-03-26 19:17:00,860] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 103901: learning rate 0.0000
[2019-03-26 19:17:00,881] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 103910: loss 0.2079
[2019-03-26 19:17:00,882] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 103911: learning rate 0.0000
[2019-03-26 19:17:00,937] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 103938: loss 0.3067
[2019-03-26 19:17:00,940] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 103938: learning rate 0.0000
[2019-03-26 19:17:00,993] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 103961: loss 0.2523
[2019-03-26 19:17:00,996] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 103962: learning rate 0.0000
[2019-03-26 19:17:01,019] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 103972: loss 0.2689
[2019-03-26 19:17:01,021] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 103972: learning rate 0.0000
[2019-03-26 19:17:01,101] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 104008: loss 0.2636
[2019-03-26 19:17:01,105] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 104011: learning rate 0.0000
[2019-03-26 19:17:01,116] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 104018: loss 0.2237
[2019-03-26 19:17:01,118] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 104018: learning rate 0.0000
[2019-03-26 19:17:01,197] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 104052: loss 0.3617
[2019-03-26 19:17:01,202] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 104053: learning rate 0.0000
[2019-03-26 19:17:01,332] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 104113: loss 0.2273
[2019-03-26 19:17:01,334] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 104113: learning rate 0.0000
[2019-03-26 19:17:01,442] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 104161: loss 0.3351
[2019-03-26 19:17:01,446] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 104163: learning rate 0.0000
[2019-03-26 19:17:01,871] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 104353: loss 0.2722
[2019-03-26 19:17:01,872] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 104353: learning rate 0.0000
[2019-03-26 19:17:01,921] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 104372: loss 0.2917
[2019-03-26 19:17:01,926] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 104373: learning rate 0.0000
[2019-03-26 19:17:04,692] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.8038739e-17 1.0000000e+00 4.3892942e-14 4.9326098e-13 9.0893877e-15], sum to 1.0000
[2019-03-26 19:17:04,699] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5906
[2019-03-26 19:17:04,708] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333334, 73.66666666666667, 1.0, 2.0, 0.6046563939403528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 844971.5333202941, 844971.5333202948, 201616.6447879491], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3964800.0000, 
sim time next is 3965400.0000, 
raw observation next is [31.5, 73.0, 1.0, 2.0, 0.6041539172788504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 844269.0728390906, 844269.0728390906, 201522.530803418], 
processed observation next is [0.0, 0.9130434782608695, 0.6919431279620853, 0.73, 1.0, 1.0, 0.5230770087696992, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23451918689974738, 0.23451918689974738, 0.3007798967215194], 
reward next is 0.6992, 
noisyNet noise sample is [array([1.8721497], dtype=float32), 0.6424938]. 
=============================================
[2019-03-26 19:17:09,127] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.8619967e-16 1.0000000e+00 1.3366264e-13 3.9849129e-14 9.0535328e-16], sum to 1.0000
[2019-03-26 19:17:09,134] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2016
[2019-03-26 19:17:09,141] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2124896.498553457 W.
[2019-03-26 19:17:09,150] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.5, 61.5, 1.0, 2.0, 0.7598308019405092, 1.0, 2.0, 0.7598308019405092, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2124896.498553457, 2124896.498553457, 400798.1268826625], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4019400.0000, 
sim time next is 4020000.0000, 
raw observation next is [33.66666666666666, 61.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.423973578900526, 6.9112, 168.9105357534865, 2647787.283036864, 2284013.271321117, 474974.4001908873], 
processed observation next is [1.0, 0.5217391304347826, 0.7946287519747232, 0.61, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.05127735789005259, 0.0, 0.8294280581274779, 0.73549646751024, 0.6344481309225325, 0.7089170152102795], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.27170926], dtype=float32), -0.61140573]. 
=============================================
[2019-03-26 19:17:09,167] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[63.48995 ]
 [64.37244 ]
 [63.38777 ]
 [63.570744]
 [63.98113 ]], R is [[63.37678528]
 [63.14481354]
 [62.8429184 ]
 [62.21448898]
 [61.59234619]].
[2019-03-26 19:17:16,291] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.2289747e-18 1.0000000e+00 5.0301793e-15 6.6507279e-14 3.2787470e-16], sum to 1.0000
[2019-03-26 19:17:16,298] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7376
[2019-03-26 19:17:16,303] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1923309.877128724 W.
[2019-03-26 19:17:16,306] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.6878111287525216, 1.0, 1.0, 0.6878111287525216, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1923309.877128724, 1923309.877128724, 368957.5828904677], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4155600.0000, 
sim time next is 4156200.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.5330950167705134, 1.0, 2.0, 0.5330950167705134, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1490380.050495132, 1490380.050495132, 310863.3212973434], 
processed observation next is [1.0, 0.08695652173913043, 0.5734597156398105, 0.84, 1.0, 1.0, 0.4374638756271246, 1.0, 1.0, 0.4374638756271246, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.41399445847087, 0.41399445847087, 0.4639751064139454], 
reward next is 0.5360, 
noisyNet noise sample is [array([-0.8086007], dtype=float32), 1.0297892]. 
=============================================
[2019-03-26 19:17:18,282] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 111639: loss -164.1275
[2019-03-26 19:17:18,285] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 111641: learning rate 0.0000
[2019-03-26 19:17:18,611] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 111787: loss -243.3610
[2019-03-26 19:17:18,615] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 111788: learning rate 0.0000
[2019-03-26 19:17:18,725] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 111836: loss -133.8401
[2019-03-26 19:17:18,727] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 111836: learning rate 0.0000
[2019-03-26 19:17:18,825] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 111878: loss -137.5553
[2019-03-26 19:17:18,829] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 111880: learning rate 0.0000
[2019-03-26 19:17:18,950] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 111936: loss -145.5616
[2019-03-26 19:17:18,952] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 111936: learning rate 0.0000
[2019-03-26 19:17:18,975] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 111947: loss -141.7310
[2019-03-26 19:17:18,976] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 111947: learning rate 0.0000
[2019-03-26 19:17:18,980] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 111949: loss -216.5026
[2019-03-26 19:17:18,982] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 111950: learning rate 0.0000
[2019-03-26 19:17:19,044] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 111974: loss -165.7156
[2019-03-26 19:17:19,046] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 111974: learning rate 0.0000
[2019-03-26 19:17:19,057] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 111980: loss -111.7663
[2019-03-26 19:17:19,059] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 111980: learning rate 0.0000
[2019-03-26 19:17:19,100] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 112000: loss -156.5109
[2019-03-26 19:17:19,103] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 112000: learning rate 0.0000
[2019-03-26 19:17:19,132] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 112013: loss -170.8295
[2019-03-26 19:17:19,137] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 112014: learning rate 0.0000
[2019-03-26 19:17:19,189] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 112037: loss -167.7600
[2019-03-26 19:17:19,191] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 112038: learning rate 0.0000
[2019-03-26 19:17:19,401] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 112129: loss -193.8288
[2019-03-26 19:17:19,402] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 112130: learning rate 0.0000
[2019-03-26 19:17:19,478] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 112166: loss -121.8132
[2019-03-26 19:17:19,480] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 112166: learning rate 0.0000
[2019-03-26 19:17:19,742] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 112281: loss -165.5312
[2019-03-26 19:17:19,746] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 112282: learning rate 0.0000
[2019-03-26 19:17:19,861] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 112335: loss -153.2684
[2019-03-26 19:17:19,867] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 112335: learning rate 0.0000
[2019-03-26 19:17:21,048] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2231604e-19 1.0000000e+00 4.0233239e-16 1.6111125e-15 8.8609192e-18], sum to 1.0000
[2019-03-26 19:17:21,056] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2763
[2019-03-26 19:17:21,067] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 75.0, 1.0, 2.0, 0.601006346581114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 839868.7914228167, 839868.7914228167, 200933.5713125359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4234200.0000, 
sim time next is 4234800.0000, 
raw observation next is [31.0, 75.0, 1.0, 2.0, 0.6011041619487852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 840005.536335655, 840005.5363356543, 200951.8184427393], 
processed observation next is [1.0, 0.0, 0.6682464454976303, 0.75, 1.0, 1.0, 0.5194026047575726, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23333487120434862, 0.23333487120434843, 0.2999280872279691], 
reward next is 0.7001, 
noisyNet noise sample is [array([0.8043951], dtype=float32), 0.29185122]. 
=============================================
[2019-03-26 19:17:24,459] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.9440701e-17 1.0000000e+00 9.6623979e-15 2.5250264e-13 5.3809070e-16], sum to 1.0000
[2019-03-26 19:17:24,467] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4298
[2019-03-26 19:17:24,475] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3265291.590979741 W.
[2019-03-26 19:17:24,483] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [38.0, 47.0, 1.0, 2.0, 0.914926293732134, 1.0, 2.0, 0.7780531863803296, 1.0, 1.0, 1.03, 7.005114685017497, 6.9112, 170.5573041426782, 3265291.590979741, 3198016.681896571, 597814.0549506356], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4290000.0000, 
sim time next is 4290600.0000, 
raw observation next is [38.0, 46.0, 1.0, 2.0, 0.8445867256523988, 1.0, 2.0, 0.7428834023404619, 1.0, 2.0, 1.03, 7.005109135455475, 6.9112, 170.5573041426782, 3117508.711562159, 3050237.777856007, 570886.9021970299], 
processed observation next is [1.0, 0.6521739130434783, 1.0, 0.46, 1.0, 1.0, 0.8127550911474684, 1.0, 1.0, 0.6902209666752553, 1.0, 1.0, 1.0365853658536586, 0.00939091354554753, 0.0, 0.8375144448122397, 0.8659746421005997, 0.8472882716266686, 0.8520700032791492], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7278043], dtype=float32), -0.19327027]. 
=============================================
[2019-03-26 19:17:26,521] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7105756e-17 1.0000000e+00 1.4871288e-14 1.0438924e-13 9.9815487e-17], sum to 1.0000
[2019-03-26 19:17:26,529] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7657
[2019-03-26 19:17:26,536] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 0.5071179505396199, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8806961736183713, 6.911200000000001, 6.9112, 168.9129564187469, 1417716.757122501, 1417716.7571225, 312064.3302363054], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4336800.0000, 
sim time next is 4337400.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 0.9733432481370654, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104081, 1360519.660109657, 1360519.660109658, 290914.5343847317], 
processed observation next is [1.0, 0.17391304347826086, 0.5734597156398105, 0.89, 1.0, 1.0, 0.9678834314904402, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451521902, 0.3779221278082381, 0.37792212780823836, 0.4342007975891518], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5960288], dtype=float32), -2.5281415]. 
=============================================
[2019-03-26 19:17:29,917] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.70678431e-16 1.00000000e+00 3.83912296e-14 6.22853223e-13
 1.01252955e-14], sum to 1.0000
[2019-03-26 19:17:29,926] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6819
[2019-03-26 19:17:29,935] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2789310.671279005 W.
[2019-03-26 19:17:29,940] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.0, 63.0, 1.0, 2.0, 0.6883459764416906, 1.0, 2.0, 0.664763027735108, 1.0, 1.0, 1.03, 7.005096813265062, 6.9112, 170.5573041426782, 2789310.671279005, 2722048.56445908, 517673.3088671597], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4381200.0000, 
sim time next is 4381800.0000, 
raw observation next is [32.83333333333334, 63.66666666666666, 1.0, 2.0, 0.2756033532785964, 1.0, 2.0, 0.2756033532785964, 1.0, 2.0, 0.4786318812232396, 6.911200000000001, 6.9112, 170.5573041426782, 1155580.981666428, 1155580.981666427, 294725.0785110372], 
processed observation next is [1.0, 0.7391304347826086, 0.7551342812006324, 0.6366666666666666, 1.0, 1.0, 0.12723295575734508, 1.0, 1.0, 0.12723295575734508, 1.0, 1.0, 0.3641852210039507, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.32099471712956335, 0.32099471712956307, 0.4398881768821451], 
reward next is 0.5601, 
noisyNet noise sample is [array([-1.203163], dtype=float32), -1.5562963]. 
=============================================
[2019-03-26 19:17:36,162] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 119607: loss 0.5232
[2019-03-26 19:17:36,166] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 119608: learning rate 0.0000
[2019-03-26 19:17:36,337] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 119687: loss 0.4196
[2019-03-26 19:17:36,343] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 119690: learning rate 0.0000
[2019-03-26 19:17:36,588] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 119800: loss 0.5189
[2019-03-26 19:17:36,593] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 119802: learning rate 0.0000
[2019-03-26 19:17:36,614] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 119810: loss 0.3949
[2019-03-26 19:17:36,618] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 119811: learning rate 0.0000
[2019-03-26 19:17:36,842] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 119914: loss 0.4510
[2019-03-26 19:17:36,843] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 119914: learning rate 0.0000
[2019-03-26 19:17:36,864] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 119922: loss 0.5530
[2019-03-26 19:17:36,867] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 119922: learning rate 0.0000
[2019-03-26 19:17:36,928] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 119949: loss 0.4939
[2019-03-26 19:17:36,930] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 119949: learning rate 0.0000
[2019-03-26 19:17:36,951] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 119958: loss 0.3827
[2019-03-26 19:17:36,953] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 119959: learning rate 0.0000
[2019-03-26 19:17:37,015] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 119986: loss 0.3451
[2019-03-26 19:17:37,019] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 119986: learning rate 0.0000
[2019-03-26 19:17:37,021] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 119988: loss 0.4662
[2019-03-26 19:17:37,025] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 119989: learning rate 0.0000
[2019-03-26 19:17:37,041] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 119999: loss 0.3905
[2019-03-26 19:17:37,043] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 119999: learning rate 0.0000
[2019-03-26 19:17:37,273] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 120100: loss 0.4076
[2019-03-26 19:17:37,275] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 120101: learning rate 0.0000
[2019-03-26 19:17:37,322] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 120124: loss 0.5464
[2019-03-26 19:17:37,324] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 120124: learning rate 0.0000
[2019-03-26 19:17:37,481] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 120192: loss 0.3605
[2019-03-26 19:17:37,483] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 120192: learning rate 0.0000
[2019-03-26 19:17:37,887] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 120374: loss 0.3716
[2019-03-26 19:17:37,889] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 120375: learning rate 0.0000
[2019-03-26 19:17:37,916] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 120390: loss 0.4855
[2019-03-26 19:17:37,919] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 120391: learning rate 0.0000
[2019-03-26 19:17:45,029] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4748998e-16 1.0000000e+00 3.3547052e-14 1.9683200e-13 5.0391894e-14], sum to 1.0000
[2019-03-26 19:17:45,036] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7452
[2019-03-26 19:17:45,043] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2787067.1634074 W.
[2019-03-26 19:17:45,047] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.0, 63.5, 1.0, 2.0, 0.6872777990793262, 1.0, 2.0, 0.6642289390539258, 1.0, 2.0, 1.03, 7.00509672904372, 6.9112, 170.5573041426782, 2787067.1634074, 2719805.116918648, 517341.8285553029], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4635000.0000, 
sim time next is 4635600.0000, 
raw observation next is [33.66666666666667, 64.66666666666667, 1.0, 2.0, 0.9659955597231925, 1.0, 2.0, 0.9659955597231925, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2702083.447851221, 2702083.447851222, 508784.4978078904], 
processed observation next is [1.0, 0.6521739130434783, 0.7946287519747238, 0.6466666666666667, 1.0, 1.0, 0.9590307948472199, 1.0, 1.0, 0.9590307948472199, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.750578735514228, 0.7505787355142284, 0.7593798474744633], 
reward next is 0.2406, 
noisyNet noise sample is [array([-0.6399709], dtype=float32), -0.84195596]. 
=============================================
[2019-03-26 19:17:45,286] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.20687781e-17 1.00000000e+00 7.65707281e-14 1.00843636e-13
 1.57803530e-15], sum to 1.0000
[2019-03-26 19:17:45,295] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9904
[2019-03-26 19:17:45,304] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2597576.447200915 W.
[2019-03-26 19:17:45,309] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.66666666666666, 69.0, 1.0, 2.0, 0.6191153851566878, 1.0, 2.0, 0.6191153851566878, 1.0, 1.0, 1.03, 6.962011789905626, 6.9112, 170.5573041426782, 2597576.447200915, 2561177.89520005, 495013.8736025171], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4639200.0000, 
sim time next is 4639800.0000, 
raw observation next is [31.33333333333334, 69.5, 1.0, 2.0, 0.6173539896821628, 1.0, 2.0, 0.6173539896821628, 1.0, 2.0, 1.03, 6.95857280362926, 6.9112, 170.5573041426782, 2590178.630736399, 2556243.564494313, 494356.6700243732], 
processed observation next is [1.0, 0.6956521739130435, 0.6840442338072673, 0.695, 1.0, 1.0, 0.5389807104604372, 1.0, 1.0, 0.5389807104604372, 1.0, 1.0, 1.0365853658536586, 0.004737280362926022, 0.0, 0.8375144448122397, 0.7194940640934442, 0.7100676568039759, 0.737845776155781], 
reward next is 0.0253, 
noisyNet noise sample is [array([0.14253552], dtype=float32), -1.9578289]. 
=============================================
[2019-03-26 19:17:48,202] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 19:17:48,205] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:17:48,206] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:17:48,207] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:17:48,209] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:17:48,209] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:17:48,210] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:17:48,211] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:17:48,211] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:17:48,212] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:17:48,213] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:17:48,229] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run6
[2019-03-26 19:17:48,230] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run6
[2019-03-26 19:17:48,266] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run6
[2019-03-26 19:17:48,267] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run6
[2019-03-26 19:17:48,300] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run6
[2019-03-26 19:18:07,218] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:18:07,220] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.55, 87.33333333333334, 1.0, 2.0, 0.4150440338059782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 626248.9733533538, 626248.9733533538, 177151.9139097347]
[2019-03-26 19:18:07,220] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:18:07,225] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.4654860e-15 1.0000000e+00 1.5331843e-12 7.7670140e-13 2.4286911e-14], sampled 0.7546745069314356
[2019-03-26 19:18:10,747] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:18:10,747] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.78127594333333, 88.28734331333334, 1.0, 2.0, 0.3794947305961779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 580563.339004929, 580563.339004929, 173174.5800897474]
[2019-03-26 19:18:10,748] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:18:10,750] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5852799e-17 1.0000000e+00 2.9343142e-14 3.0189481e-14 5.5598539e-16], sampled 0.35057972193367826
[2019-03-26 19:18:14,999] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:18:15,000] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.05, 86.5, 1.0, 2.0, 0.708797764454538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1016242.482101053, 1016242.482101053, 226194.6978298636]
[2019-03-26 19:18:15,000] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:18:15,004] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.8363502e-16 1.0000000e+00 3.4683801e-13 2.1622095e-13 5.3278250e-15], sampled 0.7434299341365955
[2019-03-26 19:18:23,843] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:18:23,844] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 67.0, 1.0, 2.0, 0.9299918984992019, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.993074082248562, 6.9112, 168.9124036783209, 2197016.843341964, 2138932.741609407, 442996.4726729438]
[2019-03-26 19:18:23,846] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:18:23,850] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.1582669e-17 1.0000000e+00 2.6605867e-14 5.2321381e-14 1.3615974e-15], sampled 0.06698686820096866
[2019-03-26 19:18:23,851] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2197016.843341964 W.
[2019-03-26 19:18:30,701] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:18:30,702] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.9, 86.33333333333334, 1.0, 2.0, 0.5614103787475387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 784515.467470032, 784515.467470032, 193776.4623206108]
[2019-03-26 19:18:30,703] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:18:30,706] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.6375071e-16 1.0000000e+00 1.6399412e-13 5.4814558e-14 1.1182478e-15], sampled 0.7097461436455178
[2019-03-26 19:18:39,339] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:18:39,340] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [33.17996338, 68.70456304, 1.0, 2.0, 0.9523543838281067, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005990810240634, 6.9112, 168.9123142148168, 2228315.125761221, 2161067.518240239, 449005.7962843012]
[2019-03-26 19:18:39,341] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:18:39,343] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0813521e-16 1.0000000e+00 4.1627129e-14 8.0820374e-14 1.6761037e-15], sampled 0.2748726252869437
[2019-03-26 19:18:39,345] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2228315.125761221 W.
[2019-03-26 19:18:46,835] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:18:46,836] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [36.34047633666667, 55.27472302666666, 1.0, 2.0, 0.6530348483005204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 912606.6062336339, 912606.6062336345, 211042.5208615054]
[2019-03-26 19:18:46,837] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:18:46,839] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.6344108e-18 1.0000000e+00 1.5204392e-14 1.7958669e-14 4.0460564e-16], sampled 0.47270754163947726
[2019-03-26 19:18:48,467] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:18:48,468] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.74960774, 85.02726514, 1.0, 2.0, 0.5815958999952543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 812733.5281868078, 812733.5281868078, 197367.0863609062]
[2019-03-26 19:18:48,470] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:18:48,474] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.6931694e-18 1.0000000e+00 4.0310688e-15 5.0766564e-15 7.9433354e-17], sampled 0.931516481541117
[2019-03-26 19:18:57,793] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:18:57,795] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.22053080666667, 67.45841237833334, 1.0, 2.0, 0.615099440573715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 859570.9783672922, 859570.9783672922, 203584.1174217544]
[2019-03-26 19:18:57,796] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:18:57,799] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.6279644e-17 1.0000000e+00 2.4968121e-14 2.1750766e-14 5.4421761e-16], sampled 0.5592193322210922
[2019-03-26 19:19:01,699] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:19:01,700] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.61050685833333, 74.33731686166666, 1.0, 2.0, 0.5023687150549787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 701983.3209104481, 701983.3209104481, 183966.5231569328]
[2019-03-26 19:19:01,704] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:19:01,707] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.1584543e-18 1.0000000e+00 1.4800488e-14 1.5427928e-14 2.3102771e-16], sampled 0.8655810218509723
[2019-03-26 19:19:20,472] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:19:20,474] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.1, 85.66666666666667, 1.0, 2.0, 0.5237910485583507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731928.0632159087, 731928.0632159094, 187407.5278585231]
[2019-03-26 19:19:20,475] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:19:20,477] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.5583539e-16 1.0000000e+00 4.2806402e-13 2.7634359e-13 7.8904626e-15], sampled 0.7526436697199741
[2019-03-26 19:19:26,497] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:19:26,500] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.13557419666667, 57.49463220333334, 1.0, 2.0, 0.7511769498146428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1111512.864986999, 1111512.864986998, 240533.4150105368]
[2019-03-26 19:19:26,502] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:19:26,507] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.9263455e-17 1.0000000e+00 6.0813916e-14 4.8234098e-14 1.2437465e-15], sampled 0.49570658975349813
[2019-03-26 19:19:36,243] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04778782], dtype=float32), 0.055722896]
[2019-03-26 19:19:36,245] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.21666666666667, 94.83333333333333, 1.0, 2.0, 0.3224974911412962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 506079.5579301456, 506079.5579301456, 167398.0400135795]
[2019-03-26 19:19:36,246] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:19:36,251] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.0922556e-15 1.0000000e+00 5.6746084e-12 2.8783143e-12 1.0104368e-13], sampled 0.12792377837240565
[2019-03-26 19:19:42,226] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 19:19:42,597] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.5678 2842630539.9971 1131.0000
[2019-03-26 19:19:42,750] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7281 2779199535.5119 933.0000
[2019-03-26 19:19:42,758] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5735 3007608940.6579 1766.0000
[2019-03-26 19:19:42,809] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6584 3164060843.9104 1778.0000
[2019-03-26 19:19:43,823] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 125000, evaluation results [125000.0, 7882.658396093389, 3164060843.9103956, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8660.728066421085, 2779199535.5119066, 933.0, 7997.573463137595, 3007608940.657916, 1766.0, 8496.567753251295, 2842630539.997116, 1131.0]
[2019-03-26 19:19:46,121] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.15318981e-17 1.00000000e+00 1.04836394e-13 4.39704493e-14
 8.33614728e-16], sum to 1.0000
[2019-03-26 19:19:46,130] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4645
[2019-03-26 19:19:46,135] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.5173717296712005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 722954.869546444, 722954.8695464433, 186363.1535348479], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4734000.0000, 
sim time next is 4734600.0000, 
raw observation next is [28.83333333333334, 74.83333333333334, 1.0, 2.0, 0.5163743409950602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 721560.684549907, 721560.6845499076, 186201.8923903371], 
processed observation next is [1.0, 0.8260869565217391, 0.5655608214849924, 0.7483333333333334, 1.0, 1.0, 0.4173184831265785, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20043352348608529, 0.20043352348608542, 0.2779132722243837], 
reward next is 0.7221, 
noisyNet noise sample is [array([0.5915043], dtype=float32), 0.25187916]. 
=============================================
[2019-03-26 19:19:47,635] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.1208720e-18 1.0000000e+00 1.6010715e-14 2.2573474e-14 1.8674897e-16], sum to 1.0000
[2019-03-26 19:19:47,644] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5233
[2019-03-26 19:19:47,650] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5176297980677346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723315.606932321, 723315.606932321, 186404.4491686033], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4739400.0000, 
sim time next is 4740000.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5172384432464104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 722768.5569846696, 722768.5569846702, 186341.1345189717], 
processed observation next is [1.0, 0.8695652173913043, 0.5260663507109005, 0.79, 1.0, 1.0, 0.4183595701763981, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2007690436068527, 0.20076904360685285, 0.2781210962969727], 
reward next is 0.7219, 
noisyNet noise sample is [array([1.4471401], dtype=float32), 0.030792275]. 
=============================================
[2019-03-26 19:19:47,664] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[68.44923 ]
 [68.262375]
 [67.60139 ]
 [67.62548 ]
 [67.0087  ]], R is [[67.85813141]
 [67.90133667]
 [67.94419861]
 [67.98694611]
 [68.02938843]].
[2019-03-26 19:19:49,043] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.03773474e-16 1.00000000e+00 1.21135917e-13 8.12306900e-14
 1.11132883e-15], sum to 1.0000
[2019-03-26 19:19:49,051] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5024
[2019-03-26 19:19:49,058] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666667, 81.0, 1.0, 2.0, 0.8259522448463741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1154387.471438376, 1154387.471438376, 250382.1220618755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4778400.0000, 
sim time next is 4779000.0000, 
raw observation next is [29.0, 79.5, 1.0, 2.0, 0.8609422907561163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1203318.821810219, 1203318.821810219, 259421.2778980691], 
processed observation next is [1.0, 0.30434782608695654, 0.5734597156398105, 0.795, 1.0, 1.0, 0.8324605912724292, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3342552282806164, 0.3342552282806164, 0.38719593716129713], 
reward next is 0.6128, 
noisyNet noise sample is [array([-0.8766872], dtype=float32), -0.24584395]. 
=============================================
[2019-03-26 19:19:49,071] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[66.57118 ]
 [66.47088 ]
 [66.433266]
 [66.549644]
 [66.46586 ]], R is [[66.62809753]
 [66.58811188]
 [66.56907654]
 [66.5991745 ]
 [66.63043213]].
[2019-03-26 19:19:49,421] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 127634: loss -87.5876
[2019-03-26 19:19:49,423] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 127634: learning rate 0.0000
[2019-03-26 19:19:49,668] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 127788: loss -156.5206
[2019-03-26 19:19:49,670] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 127789: loss -128.4874
[2019-03-26 19:19:49,671] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 127789: learning rate 0.0000
[2019-03-26 19:19:49,673] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 127789: learning rate 0.0000
[2019-03-26 19:19:49,724] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 127822: loss -54.5109
[2019-03-26 19:19:49,727] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 127823: learning rate 0.0000
[2019-03-26 19:19:49,921] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 127945: loss -128.4667
[2019-03-26 19:19:49,922] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 127945: learning rate 0.0000
[2019-03-26 19:19:49,931] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 127950: loss -112.2324
[2019-03-26 19:19:49,932] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 127950: learning rate 0.0000
[2019-03-26 19:19:49,955] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 127966: loss -35.2863
[2019-03-26 19:19:49,958] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 127966: learning rate 0.0000
[2019-03-26 19:19:49,971] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 127977: loss -84.8801
[2019-03-26 19:19:49,973] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 127977: learning rate 0.0000
[2019-03-26 19:19:49,980] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 127981: loss -111.8173
[2019-03-26 19:19:49,981] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 127982: learning rate 0.0000
[2019-03-26 19:19:49,981] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 127982: loss -92.6337
[2019-03-26 19:19:49,982] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 127982: learning rate 0.0000
[2019-03-26 19:19:50,024] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 128014: loss -118.3807
[2019-03-26 19:19:50,026] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 128014: learning rate 0.0000
[2019-03-26 19:19:50,090] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 128059: loss -67.5607
[2019-03-26 19:19:50,092] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 128059: learning rate 0.0000
[2019-03-26 19:19:50,179] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 128123: loss -40.2970
[2019-03-26 19:19:50,180] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 128124: learning rate 0.0000
[2019-03-26 19:19:50,218] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 128146: loss -111.5125
[2019-03-26 19:19:50,221] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 128147: learning rate 0.0000
[2019-03-26 19:19:50,551] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 128311: loss -38.0599
[2019-03-26 19:19:50,553] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 128311: learning rate 0.0000
[2019-03-26 19:19:50,604] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 128329: loss -181.4739
[2019-03-26 19:19:50,605] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 128329: learning rate 0.0000
[2019-03-26 19:19:52,731] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0143527e-17 1.0000000e+00 2.7132704e-13 2.0401449e-14 1.9557840e-16], sum to 1.0000
[2019-03-26 19:19:52,735] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9597
[2019-03-26 19:19:52,748] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.4848186778890622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 677452.0127284338, 677452.0127284338, 181251.4184775893], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4845600.0000, 
sim time next is 4846200.0000, 
raw observation next is [27.0, 79.00000000000001, 1.0, 2.0, 0.9806421946334349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1370728.567619118, 1370728.567619118, 293079.7629098151], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.7900000000000001, 1.0, 1.0, 0.9766773429318493, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.38075793544975495, 0.38075793544975495, 0.43743248195494794], 
reward next is 0.5626, 
noisyNet noise sample is [array([1.0799448], dtype=float32), -0.13428578]. 
=============================================
[2019-03-26 19:20:00,267] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.7739750e-15 1.0000000e+00 2.5556057e-12 7.3073292e-12 3.5660640e-13], sum to 1.0000
[2019-03-26 19:20:00,280] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1849
[2019-03-26 19:20:00,290] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2223135.614649753 W.
[2019-03-26 19:20:00,293] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.8, 63.0, 1.0, 2.0, 0.5299491740930115, 1.0, 2.0, 0.5299491740930115, 1.0, 2.0, 0.9086141068093557, 6.911199999999999, 6.9112, 170.5573041426782, 2223135.614649753, 2223135.614649754, 434199.9807300368], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4978800.0000, 
sim time next is 4979400.0000, 
raw observation next is [30.83333333333334, 63.0, 1.0, 2.0, 0.4947342357720285, 1.0, 2.0, 0.4947342357720285, 1.0, 2.0, 0.8482164622806077, 6.9112, 6.9112, 170.5573041426782, 2075267.377542447, 2075267.377542447, 409553.470439431], 
processed observation next is [1.0, 0.6521739130434783, 0.6603475513428123, 0.63, 1.0, 1.0, 0.3912460671952151, 1.0, 1.0, 0.3912460671952151, 1.0, 1.0, 0.8148981247324484, 0.0, 0.0, 0.8375144448122397, 0.5764631604284575, 0.5764631604284575, 0.6112738364767627], 
reward next is 0.3887, 
noisyNet noise sample is [array([2.0738661], dtype=float32), -1.5538118]. 
=============================================
[2019-03-26 19:20:00,834] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2202563e-15 1.0000000e+00 7.2743124e-13 3.4148162e-13 2.8271551e-14], sum to 1.0000
[2019-03-26 19:20:00,844] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6948
[2019-03-26 19:20:00,851] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 67.66666666666667, 1.0, 2.0, 0.5005539020913188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 699446.5629206613, 699446.5629206606, 183685.0184415001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4988400.0000, 
sim time next is 4989000.0000, 
raw observation next is [30.16666666666666, 68.83333333333333, 1.0, 2.0, 0.506324710356891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 707513.0592325422, 707513.0592325422, 184594.8456621898], 
processed observation next is [1.0, 0.7391304347826086, 0.6287519747235385, 0.6883333333333332, 1.0, 1.0, 0.4052104944058927, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19653140534237282, 0.19653140534237282, 0.2755146950181937], 
reward next is 0.7245, 
noisyNet noise sample is [array([1.6718009], dtype=float32), 1.2088906]. 
=============================================
[2019-03-26 19:20:00,861] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[56.563534]
 [56.369644]
 [55.83533 ]
 [54.504745]
 [55.093002]], R is [[57.00456238]
 [57.16035843]
 [57.31647873]
 [57.47004318]
 [57.50284195]].
[2019-03-26 19:20:03,138] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.3243666e-19 1.0000000e+00 5.4637056e-16 2.0067672e-16 4.9648026e-18], sum to 1.0000
[2019-03-26 19:20:03,150] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8696
[2019-03-26 19:20:03,155] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5091015903215216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 711394.6329976249, 711394.6329976243, 185034.4587508654], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5005800.0000, 
sim time next is 5006400.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5104633257084197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 713298.0968898302, 713298.0968898295, 185251.679123224], 
processed observation next is [1.0, 0.9565217391304348, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4101967779619514, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19813836024717504, 0.19813836024717485, 0.2764950434674985], 
reward next is 0.7235, 
noisyNet noise sample is [array([2.0671895], dtype=float32), -0.53118515]. 
=============================================
[2019-03-26 19:20:05,007] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.54804691e-17 1.00000000e+00 1.02954076e-13 3.48214106e-13
 6.74127392e-15], sum to 1.0000
[2019-03-26 19:20:05,015] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3947
[2019-03-26 19:20:05,022] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 63.0, 1.0, 2.0, 0.5438862664541704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 760018.4932231669, 760018.4932231669, 190758.7568232735], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5058000.0000, 
sim time next is 5058600.0000, 
raw observation next is [31.83333333333334, 63.0, 1.0, 2.0, 0.5419154270068041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 757263.4901138083, 757263.4901138083, 190424.636971973], 
processed observation next is [0.0, 0.5652173913043478, 0.7077409162717223, 0.63, 1.0, 1.0, 0.44809087591181207, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21035096947605786, 0.21035096947605786, 0.28421587607757165], 
reward next is 0.7158, 
noisyNet noise sample is [array([0.49980453], dtype=float32), -0.9552149]. 
=============================================
[2019-03-26 19:20:05,273] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.8778221e-16 1.0000000e+00 1.3369221e-13 2.5479229e-14 1.0900625e-15], sum to 1.0000
[2019-03-26 19:20:05,284] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2686
[2019-03-26 19:20:05,290] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333333, 63.0, 1.0, 2.0, 0.5393228908244629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 753639.438542164, 753639.438542164, 189987.4066432035], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5057400.0000, 
sim time next is 5058000.0000, 
raw observation next is [32.0, 63.0, 1.0, 2.0, 0.5438862664541704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 760018.4932231669, 760018.4932231669, 190758.7568232735], 
processed observation next is [0.0, 0.5652173913043478, 0.7156398104265403, 0.63, 1.0, 1.0, 0.4504653812700848, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21111624811754637, 0.21111624811754637, 0.28471456242279625], 
reward next is 0.7153, 
noisyNet noise sample is [array([0.25746447], dtype=float32), -0.5489431]. 
=============================================
[2019-03-26 19:20:05,306] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[61.172123]
 [61.12789 ]
 [61.07698 ]
 [61.024597]
 [60.971878]], R is [[61.32734299]
 [61.43050766]
 [61.53380966]
 [61.63725281]
 [61.74081039]].
[2019-03-26 19:20:06,896] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 135546: loss 0.4110
[2019-03-26 19:20:06,899] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 135546: learning rate 0.0000
[2019-03-26 19:20:07,182] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5155264e-17 1.0000000e+00 4.2703220e-14 9.5732490e-14 2.0379037e-15], sum to 1.0000
[2019-03-26 19:20:07,190] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7555
[2019-03-26 19:20:07,197] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 70.0, 1.0, 2.0, 0.5561092231212424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777104.9170712325, 777104.9170712325, 192852.4636751746], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5073000.0000, 
sim time next is 5073600.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.5314308110443645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 742607.3430174363, 742607.3430174369, 188667.4421233954], 
processed observation next is [0.0, 0.7391304347826086, 0.6208530805687204, 0.7, 1.0, 1.0, 0.43545880848718616, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20627981750484342, 0.2062798175048436, 0.2815931971990976], 
reward next is 0.7184, 
noisyNet noise sample is [array([0.14068015], dtype=float32), 0.024932094]. 
=============================================
[2019-03-26 19:20:07,275] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 135713: loss 0.3979
[2019-03-26 19:20:07,277] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 135714: learning rate 0.0000
[2019-03-26 19:20:07,416] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 135775: loss 0.3590
[2019-03-26 19:20:07,418] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 135775: learning rate 0.0000
[2019-03-26 19:20:07,516] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 135823: loss 0.3462
[2019-03-26 19:20:07,521] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 135823: learning rate 0.0000
[2019-03-26 19:20:07,759] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 135930: loss 0.4851
[2019-03-26 19:20:07,762] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 135930: learning rate 0.0000
[2019-03-26 19:20:07,831] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 135963: loss 0.4069
[2019-03-26 19:20:07,834] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 135964: learning rate 0.0000
[2019-03-26 19:20:07,846] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 135970: loss 0.4042
[2019-03-26 19:20:07,848] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 135970: learning rate 0.0000
[2019-03-26 19:20:07,860] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 135976: loss 0.3883
[2019-03-26 19:20:07,863] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 135976: learning rate 0.0000
[2019-03-26 19:20:07,877] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 135983: loss 0.4529
[2019-03-26 19:20:07,881] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 135983: learning rate 0.0000
[2019-03-26 19:20:07,882] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 135984: loss 0.4518
[2019-03-26 19:20:07,886] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 135986: learning rate 0.0000
[2019-03-26 19:20:07,901] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 135993: loss 0.4528
[2019-03-26 19:20:07,904] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 135993: learning rate 0.0000
[2019-03-26 19:20:07,913] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 135996: loss 0.4154
[2019-03-26 19:20:07,915] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 135997: learning rate 0.0000
[2019-03-26 19:20:08,267] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 136155: loss 0.5217
[2019-03-26 19:20:08,268] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 136156: learning rate 0.0000
[2019-03-26 19:20:08,346] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 136191: loss 0.3692
[2019-03-26 19:20:08,349] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 136191: learning rate 0.0000
[2019-03-26 19:20:08,793] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 136389: loss 0.4458
[2019-03-26 19:20:08,794] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 136389: learning rate 0.0000
[2019-03-26 19:20:08,836] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 136408: loss 0.3752
[2019-03-26 19:20:08,838] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 136408: learning rate 0.0000
[2019-03-26 19:20:12,701] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1475847e-18 1.0000000e+00 1.5743652e-14 6.0930218e-15 4.2056284e-16], sum to 1.0000
[2019-03-26 19:20:12,713] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9856
[2019-03-26 19:20:12,717] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 79.0, 1.0, 2.0, 0.5060471560311154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 707125.0894830591, 707125.0894830597, 184548.2607312716], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5179200.0000, 
sim time next is 5179800.0000, 
raw observation next is [27.16666666666666, 79.0, 1.0, 2.0, 0.5006537658082684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 699586.1529506514, 699586.1529506508, 183697.824478063], 
processed observation next is [0.0, 0.9565217391304348, 0.4865718799368086, 0.79, 1.0, 1.0, 0.3983780310942992, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19432948693073648, 0.19432948693073632, 0.27417585742994477], 
reward next is 0.7258, 
noisyNet noise sample is [array([0.7156667], dtype=float32), 1.5818435]. 
=============================================
[2019-03-26 19:20:16,184] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4797805e-18 1.0000000e+00 3.6376711e-15 1.4649710e-16 3.1389651e-17], sum to 1.0000
[2019-03-26 19:20:16,191] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0203
[2019-03-26 19:20:16,195] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.81666666666667, 78.83333333333334, 1.0, 2.0, 0.5452327300927857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 761900.6960647892, 761900.6960647892, 190986.6117764753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5255400.0000, 
sim time next is 5256000.0000, 
raw observation next is [28.8, 79.0, 1.0, 2.0, 0.5473916124312921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 764918.5746976368, 764918.5746976368, 191354.3720096959], 
processed observation next is [1.0, 0.8695652173913043, 0.5639810426540285, 0.79, 1.0, 1.0, 0.4546886896762555, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21247738186045464, 0.21247738186045464, 0.2856035403129789], 
reward next is 0.7144, 
noisyNet noise sample is [array([-0.66054523], dtype=float32), 0.47949088]. 
=============================================
[2019-03-26 19:20:16,213] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[68.64604]
 [68.67059]
 [67.84742]
 [67.78492]
 [67.14378]], R is [[68.48296356]
 [68.51307678]
 [68.54364014]
 [68.57365417]
 [68.60301208]].
[2019-03-26 19:20:24,344] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 143540: loss -193.1009
[2019-03-26 19:20:24,346] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 143540: learning rate 0.0000
[2019-03-26 19:20:24,865] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 143776: loss -207.4253
[2019-03-26 19:20:24,867] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 143776: learning rate 0.0000
[2019-03-26 19:20:25,014] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 143841: loss -212.3938
[2019-03-26 19:20:25,016] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 143842: learning rate 0.0000
[2019-03-26 19:20:25,098] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 143874: loss -110.6663
[2019-03-26 19:20:25,099] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 143874: learning rate 0.0000
[2019-03-26 19:20:25,157] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 143899: loss -165.5884
[2019-03-26 19:20:25,159] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 143900: learning rate 0.0000
[2019-03-26 19:20:25,225] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 143932: loss -229.1542
[2019-03-26 19:20:25,230] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 143932: learning rate 0.0000
[2019-03-26 19:20:25,251] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 143943: loss -224.8542
[2019-03-26 19:20:25,254] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 143943: learning rate 0.0000
[2019-03-26 19:20:25,266] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 143948: loss -247.0998
[2019-03-26 19:20:25,267] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 143948: learning rate 0.0000
[2019-03-26 19:20:25,304] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 143962: loss -192.0078
[2019-03-26 19:20:25,305] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 143962: learning rate 0.0000
[2019-03-26 19:20:25,396] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 144005: loss -259.3297
[2019-03-26 19:20:25,398] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 144008: learning rate 0.0000
[2019-03-26 19:20:25,466] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 144036: loss -214.3296
[2019-03-26 19:20:25,469] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 144036: learning rate 0.0000
[2019-03-26 19:20:25,504] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 144051: loss -266.0377
[2019-03-26 19:20:25,507] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 144051: learning rate 0.0000
[2019-03-26 19:20:25,719] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 144149: loss -219.5474
[2019-03-26 19:20:25,726] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 144151: learning rate 0.0000
[2019-03-26 19:20:25,776] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 144175: loss -194.0105
[2019-03-26 19:20:25,777] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 144175: learning rate 0.0000
[2019-03-26 19:20:26,097] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 144319: loss -176.4348
[2019-03-26 19:20:26,099] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 144319: learning rate 0.0000
[2019-03-26 19:20:26,197] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 144364: loss -214.2070
[2019-03-26 19:20:26,198] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 144364: learning rate 0.0000
[2019-03-26 19:20:26,483] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.0413333e-17 1.0000000e+00 1.4620861e-14 3.6704997e-14 1.1203442e-15], sum to 1.0000
[2019-03-26 19:20:26,491] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0108
[2019-03-26 19:20:26,496] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.88333333333333, 75.66666666666667, 1.0, 2.0, 0.5821301382215632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813480.3690571458, 813480.3690571458, 197465.3251334452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5422200.0000, 
sim time next is 5422800.0000, 
raw observation next is [30.86666666666667, 76.33333333333334, 1.0, 2.0, 0.5872359064941861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 820618.0285986264, 820618.0285986264, 198393.2900724918], 
processed observation next is [1.0, 0.782608695652174, 0.6619273301737759, 0.7633333333333334, 1.0, 1.0, 0.5026938632460073, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22794945238850733, 0.22794945238850733, 0.2961093881678982], 
reward next is 0.7039, 
noisyNet noise sample is [array([-0.10892162], dtype=float32), 0.8132768]. 
=============================================
[2019-03-26 19:20:28,389] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7081303e-17 1.0000000e+00 1.7534261e-14 8.8436391e-16 1.8320750e-16], sum to 1.0000
[2019-03-26 19:20:28,398] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6206
[2019-03-26 19:20:28,407] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.41666666666666, 89.66666666666667, 1.0, 2.0, 0.5883698627198274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 822203.2604925588, 822203.2604925588, 198599.4757223906], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5447400.0000, 
sim time next is 5448000.0000, 
raw observation next is [28.33333333333334, 90.33333333333334, 1.0, 2.0, 0.5889300058987476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 822986.3223094663, 822986.3223094663, 198701.9466961817], 
processed observation next is [1.0, 0.043478260869565216, 0.5418641390205374, 0.9033333333333334, 1.0, 1.0, 0.5047349468659609, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22860731175262952, 0.22860731175262952, 0.2965700696957936], 
reward next is 0.7034, 
noisyNet noise sample is [array([-0.5506013], dtype=float32), -1.2979577]. 
=============================================
[2019-03-26 19:20:28,423] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[69.85287]
 [70.21046]
 [70.47623]
 [70.78178]
 [71.1357 ]], R is [[69.59914398]
 [69.60673523]
 [69.61435699]
 [69.62181854]
 [69.6289444 ]].
[2019-03-26 19:20:34,711] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.9683454e-18 1.0000000e+00 2.9028387e-15 3.9809757e-15 2.7340148e-16], sum to 1.0000
[2019-03-26 19:20:34,723] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5283
[2019-03-26 19:20:34,731] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 95.0, 1.0, 2.0, 0.5086861770946968, 1.0, 1.0, 0.5086861770946968, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1422094.699434403, 1422094.699434403, 302973.4183357868], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5538600.0000, 
sim time next is 5539200.0000, 
raw observation next is [26.16666666666666, 95.0, 1.0, 2.0, 0.9593438232230637, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565085993, 1340939.186540829, 1340939.18654083, 286783.1953809508], 
processed observation next is [1.0, 0.08695652173913043, 0.4391785150078987, 0.95, 1.0, 1.0, 0.9510166544856189, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451433082, 0.3724831073724525, 0.37248310737245277, 0.4280346199715684], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2693074], dtype=float32), -0.58797485]. 
=============================================
[2019-03-26 19:20:35,411] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3072880e-17 1.0000000e+00 1.8763355e-14 6.3444470e-15 1.1986428e-16], sum to 1.0000
[2019-03-26 19:20:35,418] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1883
[2019-03-26 19:20:35,424] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 86.0, 1.0, 2.0, 0.8365889707277824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1169262.016483936, 1169262.016483935, 253091.0094335143], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5554800.0000, 
sim time next is 5555400.0000, 
raw observation next is [27.88333333333333, 85.33333333333334, 1.0, 2.0, 0.8302677065363072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1160422.247817472, 1160422.247817473, 251477.0291355819], 
processed observation next is [1.0, 0.30434782608695654, 0.5205371248025275, 0.8533333333333334, 1.0, 1.0, 0.7955032608871171, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.32233951328263116, 0.3223395132826314, 0.37533884945609236], 
reward next is 0.6247, 
noisyNet noise sample is [array([-0.80632854], dtype=float32), 1.5333353]. 
=============================================
[2019-03-26 19:20:38,823] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 19:20:38,826] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:20:38,828] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:20:38,828] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:20:38,829] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:20:38,830] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:20:38,832] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:20:38,833] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:20:38,835] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:20:38,831] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:20:38,839] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:20:38,849] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run7
[2019-03-26 19:20:38,866] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run7
[2019-03-26 19:20:38,866] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run7
[2019-03-26 19:20:38,907] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run7
[2019-03-26 19:20:38,907] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run7
[2019-03-26 19:21:48,000] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04674687], dtype=float32), 0.054028183]
[2019-03-26 19:21:48,002] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.1, 53.0, 1.0, 2.0, 0.5196122190562255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 726086.711139293, 726086.7111392937, 186726.1127470609]
[2019-03-26 19:21:48,004] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:21:48,006] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.7775843e-17 1.0000000e+00 1.5312452e-14 1.5397031e-14 6.2404379e-16], sampled 0.6057493074309931
[2019-03-26 19:22:04,543] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04674687], dtype=float32), 0.054028183]
[2019-03-26 19:22:04,543] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.13722007666667, 80.95624624999999, 1.0, 2.0, 0.5644907401186957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 788821.5661204283, 788821.5661204283, 194317.4268193821]
[2019-03-26 19:22:04,544] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:22:04,547] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.04375685e-17 1.00000000e+00 9.04725378e-15 8.59243944e-15
 3.08103788e-16], sampled 0.6818493705247003
[2019-03-26 19:22:33,335] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.9596 2842607972.5311 1131.0000
[2019-03-26 19:22:33,588] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9878 2779190307.3385 933.0000
[2019-03-26 19:22:33,665] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 19:22:33,688] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6679 2927328479.9021 1338.0000
[2019-03-26 19:22:33,710] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4154 3164089036.9102 1778.0000
[2019-03-26 19:22:34,723] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 150000, evaluation results [150000.0, 7883.415428030625, 3164089036.9102125, 1778.0, 8253.667895353341, 2927328479.9020863, 1338.0, 8659.987755389953, 2779190307.3384666, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8495.959645458452, 2842607972.531135, 1131.0]
[2019-03-26 19:22:37,892] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 151492: loss 0.1127
[2019-03-26 19:22:37,894] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 151492: learning rate 0.0000
[2019-03-26 19:22:38,364] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 151715: loss 0.1076
[2019-03-26 19:22:38,364] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 151715: learning rate 0.0000
[2019-03-26 19:22:38,499] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 151781: loss 0.1232
[2019-03-26 19:22:38,503] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 151783: learning rate 0.0000
[2019-03-26 19:22:38,570] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 151814: loss 0.1830
[2019-03-26 19:22:38,572] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 151814: learning rate 0.0000
[2019-03-26 19:22:38,759] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 151902: loss 0.1274
[2019-03-26 19:22:38,761] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 151903: learning rate 0.0000
[2019-03-26 19:22:38,769] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 151906: loss 0.1380
[2019-03-26 19:22:38,773] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 151907: learning rate 0.0000
[2019-03-26 19:22:38,805] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 151925: loss 0.1468
[2019-03-26 19:22:38,806] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 151925: learning rate 0.0000
[2019-03-26 19:22:38,830] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 151936: loss 0.1205
[2019-03-26 19:22:38,834] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 151936: learning rate 0.0000
[2019-03-26 19:22:38,868] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 151948: loss 0.1007
[2019-03-26 19:22:38,873] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 151950: learning rate 0.0000
[2019-03-26 19:22:38,907] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 151972: loss 0.0887
[2019-03-26 19:22:38,911] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 151973: learning rate 0.0000
[2019-03-26 19:22:38,990] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 152007: loss 0.1613
[2019-03-26 19:22:38,991] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 152008: learning rate 0.0000
[2019-03-26 19:22:39,165] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 152088: loss 0.1389
[2019-03-26 19:22:39,169] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 152089: learning rate 0.0000
[2019-03-26 19:22:39,357] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 152176: loss 0.1484
[2019-03-26 19:22:39,360] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 152176: learning rate 0.0000
[2019-03-26 19:22:39,454] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 152221: loss 0.1683
[2019-03-26 19:22:39,461] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 152224: learning rate 0.0000
[2019-03-26 19:22:39,857] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 152433: loss 0.1699
[2019-03-26 19:22:39,859] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 152433: learning rate 0.0000
[2019-03-26 19:22:39,900] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 152461: loss 0.1232
[2019-03-26 19:22:39,901] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 152461: learning rate 0.0000
[2019-03-26 19:22:42,964] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1352454e-18 1.0000000e+00 2.8752851e-16 2.8767896e-15 1.6818150e-17], sum to 1.0000
[2019-03-26 19:22:42,972] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4153
[2019-03-26 19:22:42,977] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.35, 86.5, 1.0, 2.0, 0.5406072735995959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 755434.8485502941, 755434.8485502935, 190202.6357142658], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5783400.0000, 
sim time next is 5784000.0000, 
raw observation next is [27.3, 86.66666666666667, 1.0, 2.0, 0.5397328615130403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 754212.5270855926, 754212.527085592, 190055.2146745392], 
processed observation next is [0.0, 0.9565217391304348, 0.4928909952606636, 0.8666666666666667, 1.0, 1.0, 0.4454612789313739, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20950347974599795, 0.20950347974599778, 0.2836644995142376], 
reward next is 0.7163, 
noisyNet noise sample is [array([1.114702], dtype=float32), 0.46235162]. 
=============================================
[2019-03-26 19:22:42,996] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[67.74059]
 [67.69379]
 [67.64533]
 [67.58859]
 [67.54686]], R is [[67.83040619]
 [67.86821747]
 [67.90541077]
 [67.9417572 ]
 [67.97751617]].
[2019-03-26 19:22:44,598] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.8701862e-18 1.0000000e+00 6.5700576e-15 6.0861608e-14 5.7452995e-16], sum to 1.0000
[2019-03-26 19:22:44,608] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4706
[2019-03-26 19:22:44,608] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1988716.893981853 W.
[2019-03-26 19:22:44,619] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.7, 89.66666666666667, 1.0, 2.0, 0.4741201308803493, 1.0, 1.0, 0.4741201308803493, 1.0, 1.0, 0.8177374655927996, 6.9112, 6.9112, 170.5573041426782, 1988716.893981853, 1988716.893981853, 396748.3683917068], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5797200.0000, 
sim time next is 5797800.0000, 
raw observation next is [26.65, 90.0, 1.0, 2.0, 0.5930139548157445, 0.0, 1.0, 0.0, 1.0, 2.0, 1.012322847895439, 6.9112, 6.9112, 168.9129562504637, 1658038.198419172, 1658038.198419172, 359363.0155227557], 
processed observation next is [1.0, 0.08695652173913043, 0.462085308056872, 0.9, 1.0, 1.0, 0.5096553672478848, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0150278632871206, 0.0, 0.0, 0.8294399438757443, 0.4605661662275478, 0.4605661662275478, 0.5363627097354562], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.88073486], dtype=float32), -0.026877841]. 
=============================================
[2019-03-26 19:22:49,574] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.60250681e-18 1.00000000e+00 1.39285028e-15 7.17418377e-16
 1.10274665e-17], sum to 1.0000
[2019-03-26 19:22:49,585] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3490
[2019-03-26 19:22:49,595] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 95.0, 1.0, 2.0, 0.8228677927758413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1150074.169842294, 1150074.169842294, 249600.277331638], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5889000.0000, 
sim time next is 5889600.0000, 
raw observation next is [25.7, 95.0, 1.0, 2.0, 0.8046205679501416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1124557.586466148, 1124557.586466147, 245046.9223346355], 
processed observation next is [1.0, 0.17391304347826086, 0.4170616113744076, 0.95, 1.0, 1.0, 0.7646030939158333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31237710735170776, 0.31237710735170754, 0.36574167512632166], 
reward next is 0.6343, 
noisyNet noise sample is [array([-0.44801146], dtype=float32), -1.4428802]. 
=============================================
[2019-03-26 19:22:49,716] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.5454019e-19 1.0000000e+00 2.5582195e-16 1.6316644e-16 1.1514616e-17], sum to 1.0000
[2019-03-26 19:22:49,723] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0908
[2019-03-26 19:22:49,732] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 95.33333333333334, 1.0, 2.0, 0.6529595923711611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 912501.3919981535, 912501.3919981542, 211018.2105547009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5890800.0000, 
sim time next is 5891400.0000, 
raw observation next is [25.65, 95.5, 1.0, 2.0, 0.6471841503213586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 904426.8603967883, 904426.8603967878, 209857.000412857], 
processed observation next is [1.0, 0.17391304347826086, 0.41469194312796204, 0.955, 1.0, 1.0, 0.5749206630377813, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25122968344355234, 0.2512296834435522, 0.31321940360127914], 
reward next is 0.6868, 
noisyNet noise sample is [array([0.02956136], dtype=float32), 0.79262066]. 
=============================================
[2019-03-26 19:22:55,427] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 159545: loss -204.1113
[2019-03-26 19:22:55,428] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 159545: learning rate 0.0000
[2019-03-26 19:22:55,965] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 159787: loss -222.0436
[2019-03-26 19:22:55,966] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 159788: learning rate 0.0000
[2019-03-26 19:22:56,000] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 159802: loss -206.0895
[2019-03-26 19:22:56,002] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 159802: learning rate 0.0000
[2019-03-26 19:22:56,081] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 159836: loss -240.8036
[2019-03-26 19:22:56,082] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 159836: learning rate 0.0000
[2019-03-26 19:22:56,244] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 159909: loss -254.2818
[2019-03-26 19:22:56,244] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 159909: learning rate 0.0000
[2019-03-26 19:22:56,270] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 159919: loss -237.6724
[2019-03-26 19:22:56,273] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 159920: learning rate 0.0000
[2019-03-26 19:22:56,280] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 159925: loss -303.1270
[2019-03-26 19:22:56,286] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 159925: learning rate 0.0000
[2019-03-26 19:22:56,316] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.8755265e-16 1.0000000e+00 1.3604637e-14 5.4020688e-13 9.1869930e-15], sum to 1.0000
[2019-03-26 19:22:56,324] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5005
[2019-03-26 19:22:56,332] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2414651.174187958 W.
[2019-03-26 19:22:56,335] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.1, 73.0, 1.0, 2.0, 0.5755584271937971, 1.0, 1.0, 0.5755584271937971, 1.0, 2.0, 0.9995546479551857, 6.9112, 6.9112, 170.5573041426782, 2414651.174187958, 2414651.174187958, 471328.3707642488], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5999400.0000, 
sim time next is 6000000.0000, 
raw observation next is [31.26666666666667, 72.33333333333333, 1.0, 2.0, 0.5613470064087528, 1.0, 2.0, 0.5613470064087528, 1.0, 2.0, 0.9748741098402341, 6.9112, 6.9112, 170.5573041426782, 2354973.551983547, 2354973.551983547, 460161.4562521687], 
processed observation next is [1.0, 0.43478260869565216, 0.6808846761453398, 0.7233333333333333, 1.0, 1.0, 0.4715024173599431, 1.0, 1.0, 0.4715024173599431, 1.0, 1.0, 0.9693586705368707, 0.0, 0.0, 0.8375144448122397, 0.6541593199954298, 0.6541593199954298, 0.6868081436599532], 
reward next is 0.3132, 
noisyNet noise sample is [array([-0.3948023], dtype=float32), 0.105433054]. 
=============================================
[2019-03-26 19:22:56,335] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 159943: loss -230.3793
[2019-03-26 19:22:56,336] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 159943: learning rate 0.0000
[2019-03-26 19:22:56,349] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[61.032074]
 [61.390846]
 [61.54297 ]
 [61.950912]
 [62.571674]], R is [[60.12247086]
 [59.52124786]
 [58.92603683]
 [58.33677673]
 [57.75341034]].
[2019-03-26 19:22:56,351] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 159948: loss -242.8687
[2019-03-26 19:22:56,358] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 159948: learning rate 0.0000
[2019-03-26 19:22:56,414] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 159976: loss -197.7371
[2019-03-26 19:22:56,416] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 159977: learning rate 0.0000
[2019-03-26 19:22:56,426] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 159981: loss -141.1521
[2019-03-26 19:22:56,428] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 159982: learning rate 0.0000
[2019-03-26 19:22:56,694] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 160100: loss -201.8283
[2019-03-26 19:22:56,696] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 160100: learning rate 0.0000
[2019-03-26 19:22:56,736] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 160117: loss -200.4339
[2019-03-26 19:22:56,740] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 160117: learning rate 0.0000
[2019-03-26 19:22:56,848] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 160167: loss -221.0185
[2019-03-26 19:22:56,852] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 160167: learning rate 0.0000
[2019-03-26 19:22:57,329] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 160376: loss -269.4548
[2019-03-26 19:22:57,333] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 160376: learning rate 0.0000
[2019-03-26 19:22:57,345] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 160383: loss -193.3294
[2019-03-26 19:22:57,346] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 160383: learning rate 0.0000
[2019-03-26 19:22:57,943] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.8303424e-16 1.0000000e+00 5.7259204e-14 7.3006352e-14 7.0091701e-16], sum to 1.0000
[2019-03-26 19:22:57,951] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6534
[2019-03-26 19:22:57,957] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 72.0, 1.0, 2.0, 0.5288687236323367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 739025.9044827132, 739025.9044827132, 188244.2116368087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6026400.0000, 
sim time next is 6027000.0000, 
raw observation next is [29.81666666666667, 73.0, 1.0, 2.0, 0.5333841168605511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 745337.7984546522, 745337.7984546529, 188993.0165104999], 
processed observation next is [1.0, 0.782608695652174, 0.6121642969984205, 0.73, 1.0, 1.0, 0.43781218898861574, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2070382773485145, 0.20703827734851468, 0.2820791291201491], 
reward next is 0.7179, 
noisyNet noise sample is [array([-0.6200555], dtype=float32), -1.6711618]. 
=============================================
[2019-03-26 19:22:57,971] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[60.05606 ]
 [59.199585]
 [58.126926]
 [57.71768 ]
 [57.18463 ]], R is [[61.00454712]
 [61.11354065]
 [61.22400284]
 [61.3359642 ]
 [61.44933319]].
[2019-03-26 19:23:02,703] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.6483146e-15 1.0000000e+00 1.0648028e-12 4.5431622e-13 9.9814066e-15], sum to 1.0000
[2019-03-26 19:23:02,715] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7947
[2019-03-26 19:23:02,723] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2259704.62036299 W.
[2019-03-26 19:23:02,728] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.1, 65.0, 1.0, 2.0, 0.8079878832361204, 1.0, 1.0, 0.8079878832361204, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2259704.62036299, 2259704.62036299, 423775.9715050642], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6096600.0000, 
sim time next is 6097200.0000, 
raw observation next is [31.1, 65.0, 1.0, 2.0, 0.7889009206072692, 1.0, 2.0, 0.7889009206072692, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2206275.943725944, 2206275.943725944, 414501.4921406985], 
processed observation next is [1.0, 0.5652173913043478, 0.6729857819905214, 0.65, 1.0, 1.0, 0.7456637597677942, 1.0, 1.0, 0.7456637597677942, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6128544288127622, 0.6128544288127622, 0.6186589434935799], 
reward next is 0.3813, 
noisyNet noise sample is [array([1.1997757], dtype=float32), 1.2131162]. 
=============================================
[2019-03-26 19:23:08,606] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.2930718e-18 1.0000000e+00 1.0757202e-15 2.3758618e-15 5.3855251e-17], sum to 1.0000
[2019-03-26 19:23:08,617] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4635
[2019-03-26 19:23:08,621] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.58333333333334, 84.5, 1.0, 2.0, 0.530354557545269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 741102.8902399419, 741102.8902399419, 188488.9550259797], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6205800.0000, 
sim time next is 6206400.0000, 
raw observation next is [27.5, 85.0, 1.0, 2.0, 0.5310323353892278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742050.3291968158, 742050.3291968158, 188601.2464162806], 
processed observation next is [1.0, 0.8695652173913043, 0.5023696682464456, 0.85, 1.0, 1.0, 0.43497871733641896, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20612509144355995, 0.20612509144355995, 0.2814943976362397], 
reward next is 0.7185, 
noisyNet noise sample is [array([0.76583487], dtype=float32), 0.029035555]. 
=============================================
[2019-03-26 19:23:13,124] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 167427: loss 0.2953
[2019-03-26 19:23:13,127] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 167427: learning rate 0.0000
[2019-03-26 19:23:13,760] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 167708: loss 0.2818
[2019-03-26 19:23:13,766] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 167709: learning rate 0.0000
[2019-03-26 19:23:13,927] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 167783: loss 0.3165
[2019-03-26 19:23:13,930] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 167783: learning rate 0.0000
[2019-03-26 19:23:14,123] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 167871: loss 0.2578
[2019-03-26 19:23:14,126] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 167872: learning rate 0.0000
[2019-03-26 19:23:14,144] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 167882: loss 0.2966
[2019-03-26 19:23:14,150] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 167882: learning rate 0.0000
[2019-03-26 19:23:14,160] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 167888: loss 0.2380
[2019-03-26 19:23:14,164] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 167889: loss 0.2992
[2019-03-26 19:23:14,165] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 167889: learning rate 0.0000
[2019-03-26 19:23:14,166] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 167889: learning rate 0.0000
[2019-03-26 19:23:14,230] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 167922: loss 0.2915
[2019-03-26 19:23:14,236] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 167923: learning rate 0.0000
[2019-03-26 19:23:14,279] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 167940: loss 0.3177
[2019-03-26 19:23:14,284] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 167942: learning rate 0.0000
[2019-03-26 19:23:14,373] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 167983: loss 0.2583
[2019-03-26 19:23:14,376] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 167983: learning rate 0.0000
[2019-03-26 19:23:14,427] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 168007: loss 0.3110
[2019-03-26 19:23:14,432] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 168007: learning rate 0.0000
[2019-03-26 19:23:14,615] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 168093: loss 0.2574
[2019-03-26 19:23:14,616] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 168093: learning rate 0.0000
[2019-03-26 19:23:14,795] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 168178: loss 0.2268
[2019-03-26 19:23:14,798] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 168178: learning rate 0.0000
[2019-03-26 19:23:14,927] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 168238: loss 0.2082
[2019-03-26 19:23:14,934] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 168238: learning rate 0.0000
[2019-03-26 19:23:15,446] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 168471: loss 0.2586
[2019-03-26 19:23:15,449] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 168471: learning rate 0.0000
[2019-03-26 19:23:15,503] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 168496: loss 0.2443
[2019-03-26 19:23:15,507] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 168497: learning rate 0.0000
[2019-03-26 19:23:18,096] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2627911e-18 1.0000000e+00 2.5162448e-15 5.6291298e-15 5.4489068e-16], sum to 1.0000
[2019-03-26 19:23:18,106] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2545
[2019-03-26 19:23:18,112] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.25, 70.5, 1.0, 2.0, 0.5158433814178596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 720818.4913110913, 720818.4913110913, 186115.4075364385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6367800.0000, 
sim time next is 6368400.0000, 
raw observation next is [28.9, 72.0, 1.0, 2.0, 0.5143807941019103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 718774.0400198154, 718774.0400198147, 185879.6017012107], 
processed observation next is [0.0, 0.7391304347826086, 0.5687203791469194, 0.72, 1.0, 1.0, 0.4149166193998919, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19965945556105985, 0.19965945556105966, 0.2774322413450906], 
reward next is 0.7226, 
noisyNet noise sample is [array([0.12151614], dtype=float32), -0.9556761]. 
=============================================
[2019-03-26 19:23:18,501] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9714822e-18 1.0000000e+00 1.1957617e-15 1.8226792e-15 4.8404800e-17], sum to 1.0000
[2019-03-26 19:23:18,510] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8690
[2019-03-26 19:23:18,513] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1020443e-17 1.0000000e+00 1.7439436e-14 8.5928985e-15 6.6301520e-16], sum to 1.0000
[2019-03-26 19:23:18,519] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.23333333333333, 82.0, 1.0, 2.0, 0.5136162823872085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 717705.3826788549, 717705.3826788554, 185756.5918737479], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6389400.0000, 
sim time next is 6390000.0000, 
raw observation next is [27.2, 82.0, 1.0, 2.0, 0.5123752175565013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 715970.587428095, 715970.5874280944, 185557.364716329], 
processed observation next is [0.0, 1.0, 0.4881516587677725, 0.82, 1.0, 1.0, 0.41250026211626656, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1988807187300264, 0.19888071873002622, 0.27695129062138657], 
reward next is 0.7230, 
noisyNet noise sample is [array([1.0464257], dtype=float32), 0.56431305]. 
=============================================
[2019-03-26 19:23:18,525] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5648
[2019-03-26 19:23:18,528] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 65.0, 1.0, 2.0, 0.5368629694898716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 750200.7778971322, 750200.7778971328, 189573.3209990672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6362400.0000, 
sim time next is 6363000.0000, 
raw observation next is [31.0, 64.5, 1.0, 2.0, 0.5319731121381953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 743365.4053665273, 743365.4053665273, 188757.3890295669], 
processed observation next is [0.0, 0.6521739130434783, 0.6682464454976303, 0.645, 1.0, 1.0, 0.43611218329903045, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2064903903795909, 0.2064903903795909, 0.2817274463127864], 
reward next is 0.7183, 
noisyNet noise sample is [array([-2.2071865], dtype=float32), -0.3688103]. 
=============================================
[2019-03-26 19:23:18,531] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[69.61453]
 [69.55832]
 [69.49181]
 [69.42858]
 [69.36179]], R is [[69.6950531 ]
 [69.72084808]
 [69.74610901]
 [69.77084351]
 [69.7950592 ]].
[2019-03-26 19:23:18,540] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[65.414665]
 [65.35568 ]
 [65.27524 ]
 [65.21213 ]
 [65.162796]], R is [[65.52645874]
 [65.58824921]
 [65.6445694 ]
 [65.70529938]
 [65.76651001]].
[2019-03-26 19:23:21,633] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.4781301e-19 1.0000000e+00 3.3497593e-16 8.6240580e-16 5.5566281e-17], sum to 1.0000
[2019-03-26 19:23:21,641] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5213
[2019-03-26 19:23:21,646] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.03333333333333, 83.0, 1.0, 2.0, 0.5110430279115776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 714108.4185074257, 714108.4185074263, 185344.0614224369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6399600.0000, 
sim time next is 6400200.0000, 
raw observation next is [27.01666666666667, 83.0, 1.0, 2.0, 0.510108049918798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712801.4841913255, 712801.4841913255, 185194.6590759626], 
processed observation next is [1.0, 0.043478260869565216, 0.4794628751974725, 0.83, 1.0, 1.0, 0.4097687348419253, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1980004122753682, 0.1980004122753682, 0.2764099389193472], 
reward next is 0.7236, 
noisyNet noise sample is [array([1.0511503], dtype=float32), -1.4269997]. 
=============================================
[2019-03-26 19:23:23,400] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0867327e-15 1.0000000e+00 2.1638350e-13 2.3320316e-13 1.4380739e-14], sum to 1.0000
[2019-03-26 19:23:23,411] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9379
[2019-03-26 19:23:23,418] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2311143.795650394 W.
[2019-03-26 19:23:23,422] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.95, 68.5, 1.0, 2.0, 1.011532380130795, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.983721374431889, 6.9112, 168.9125249978266, 2311143.795650394, 2259694.76806966, 467678.4066929878], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6442200.0000, 
sim time next is 6442800.0000, 
raw observation next is [29.96666666666667, 68.33333333333333, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.984564558242527, 6.9112, 168.9122820262267, 2353628.804816809, 2301581.670015926, 476746.9266698058], 
processed observation next is [1.0, 0.5652173913043478, 0.6192733017377569, 0.6833333333333332, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007336455824252663, 0.0, 0.8294366331260794, 0.6537857791157803, 0.6393282416710906, 0.7115625771191131], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5999426], dtype=float32), 1.7963725]. 
=============================================
[2019-03-26 19:23:24,828] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7649936e-20 1.0000000e+00 3.0499307e-17 3.2512946e-17 1.1359945e-18], sum to 1.0000
[2019-03-26 19:23:24,835] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0421
[2019-03-26 19:23:24,840] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 87.0, 1.0, 2.0, 0.5307494053681528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 741654.8323595145, 741654.8323595152, 188554.3217904331], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6476400.0000, 
sim time next is 6477000.0000, 
raw observation next is [27.15, 87.16666666666667, 1.0, 2.0, 0.5316882047698023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 742967.1439800152, 742967.1439800158, 188709.9675605736], 
processed observation next is [1.0, 1.0, 0.485781990521327, 0.8716666666666667, 1.0, 1.0, 0.4357689214094003, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2063797622166709, 0.20637976221667104, 0.2816566680008561], 
reward next is 0.7183, 
noisyNet noise sample is [array([-0.41152093], dtype=float32), -0.71667546]. 
=============================================
[2019-03-26 19:23:24,853] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[73.2764 ]
 [73.1873 ]
 [73.1013 ]
 [73.00292]
 [72.90278]], R is [[73.36042023]
 [73.34539032]
 [73.33086395]
 [73.31678772]
 [73.30311584]].
[2019-03-26 19:23:26,248] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8462574e-20 1.0000000e+00 7.0284173e-17 3.9329262e-17 9.4806251e-19], sum to 1.0000
[2019-03-26 19:23:26,258] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5229
[2019-03-26 19:23:26,262] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.25, 86.33333333333333, 1.0, 2.0, 0.5293408073653753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 739685.8103626199, 739685.8103626193, 188321.0480314826], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6475800.0000, 
sim time next is 6476400.0000, 
raw observation next is [27.2, 87.0, 1.0, 2.0, 0.5307494053681528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 741654.8323595145, 741654.8323595152, 188554.3217904331], 
processed observation next is [1.0, 1.0, 0.4881516587677725, 0.87, 1.0, 1.0, 0.43463783779295523, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20601523121097626, 0.20601523121097645, 0.28142436088124345], 
reward next is 0.7186, 
noisyNet noise sample is [array([-0.87686884], dtype=float32), 0.7479927]. 
=============================================
[2019-03-26 19:23:27,597] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.7959677e-18 1.0000000e+00 2.8066242e-15 6.9826732e-15 7.0756331e-16], sum to 1.0000
[2019-03-26 19:23:27,605] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2018
[2019-03-26 19:23:27,615] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1959576.516676495 W.
[2019-03-26 19:23:27,619] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.8, 66.0, 1.0, 2.0, 0.7603452491832494, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.973901029848824, 6.9112, 168.9125829936063, 1959576.516676495, 1915094.346462374, 399377.5619806084], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6516000.0000, 
sim time next is 6516600.0000, 
raw observation next is [30.01666666666667, 64.5, 1.0, 2.0, 0.7479589698833264, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.970150449466946, 6.9112, 168.912554217544, 1942242.49023792, 1900421.112072637, 396591.7797274195], 
processed observation next is [1.0, 0.43478260869565216, 0.6216429699842023, 0.645, 1.0, 1.0, 0.6963361082931644, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.005895044946694572, 0.0, 0.829437969710057, 0.5395118028438667, 0.5278947533535103, 0.5919280294439097], 
reward next is 0.1133, 
noisyNet noise sample is [array([-0.69794863], dtype=float32), -0.40293184]. 
=============================================
[2019-03-26 19:23:30,180] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 19:23:30,181] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:23:30,181] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:23:30,182] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:23:30,182] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:23:30,182] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:23:30,183] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:23:30,185] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:23:30,185] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:23:30,188] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:23:30,188] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:23:30,207] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run8
[2019-03-26 19:23:30,230] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run8
[2019-03-26 19:23:30,231] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run8
[2019-03-26 19:23:30,231] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run8
[2019-03-26 19:23:30,231] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run8
[2019-03-26 19:23:53,154] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04954733], dtype=float32), 0.056216944]
[2019-03-26 19:23:53,156] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.0, 51.0, 1.0, 2.0, 0.3428707597271431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527662.0149253301, 527662.0149253301, 168795.5129784984]
[2019-03-26 19:23:53,157] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:23:53,163] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.3002661e-16 1.0000000e+00 5.7000296e-14 4.5251285e-14 2.5119099e-15], sampled 0.27989636842963916
[2019-03-26 19:24:36,654] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04954733], dtype=float32), 0.056216944]
[2019-03-26 19:24:36,655] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.8, 70.0, 1.0, 2.0, 0.5740280698154621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 802154.1003865645, 802154.1003865645, 196006.2369027617]
[2019-03-26 19:24:36,656] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:24:36,659] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0697156e-18 1.0000000e+00 8.2811251e-16 1.0448295e-15 3.9005788e-17], sampled 0.24334539067517436
[2019-03-26 19:24:42,439] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04954733], dtype=float32), 0.056216944]
[2019-03-26 19:24:42,440] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.4312627, 65.86458985499999, 1.0, 2.0, 1.039941638767091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1453673.29157496, 1453673.29157496, 311328.8320673749]
[2019-03-26 19:24:42,440] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:24:42,445] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.4650105e-19 1.0000000e+00 3.0819664e-16 2.8961676e-16 9.7458593e-18], sampled 0.3760648932704004
[2019-03-26 19:24:55,424] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04954733], dtype=float32), 0.056216944]
[2019-03-26 19:24:55,425] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.81666666666667, 89.0, 1.0, 2.0, 0.5347091481231504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 747190.0156496192, 747190.0156496197, 189212.6271551946]
[2019-03-26 19:24:55,426] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:24:55,430] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.58969420e-18 1.00000000e+00 2.90599619e-15 2.88182017e-15
 1.03299916e-16], sampled 0.3362157855880433
[2019-03-26 19:25:13,189] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04954733], dtype=float32), 0.056216944]
[2019-03-26 19:25:13,190] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.05402274, 86.79436673, 1.0, 2.0, 0.4781697612748312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 668158.3557279297, 668158.3557279297, 180246.9755190967]
[2019-03-26 19:25:13,191] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:25:13,193] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0657118e-18 1.0000000e+00 8.9110291e-16 1.0322355e-15 3.1785480e-17], sampled 0.6463828362362957
[2019-03-26 19:25:20,244] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04954733], dtype=float32), 0.056216944]
[2019-03-26 19:25:20,245] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.16666666666667, 62.0, 1.0, 2.0, 0.4445139563660606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 633156.6034245412, 633156.6034245412, 176913.5538732694]
[2019-03-26 19:25:20,246] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:25:20,248] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.5299319e-17 1.0000000e+00 8.3209332e-15 8.3334489e-15 3.6916152e-16], sampled 0.800596673280162
[2019-03-26 19:25:24,781] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.8607 3007711637.9330 1766.0000
[2019-03-26 19:25:25,297] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 19:25:25,326] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5752 2842451949.6408 1131.0000
[2019-03-26 19:25:25,346] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1685 3164067279.4129 1778.0000
[2019-03-26 19:25:25,374] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.0653 2927317329.7462 1338.0000
[2019-03-26 19:25:26,385] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 175000, evaluation results [175000.0, 7884.168455680242, 3164067279.4128904, 1778.0, 8255.065342017213, 2927317329.746172, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7998.86073322157, 3007711637.9330444, 1766.0, 8497.575228127671, 2842451949.640752, 1131.0]
[2019-03-26 19:25:27,255] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 175414: loss -294.3286
[2019-03-26 19:25:27,257] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 175414: learning rate 0.0000
[2019-03-26 19:25:27,906] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 175709: loss -304.3748
[2019-03-26 19:25:27,909] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 175710: learning rate 0.0000
[2019-03-26 19:25:27,970] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 175739: loss -269.2860
[2019-03-26 19:25:27,974] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 175740: learning rate 0.0000
[2019-03-26 19:25:28,188] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 175841: loss -276.7523
[2019-03-26 19:25:28,192] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 175842: learning rate 0.0000
[2019-03-26 19:25:28,279] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 175889: loss -347.3416
[2019-03-26 19:25:28,281] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 175890: loss -363.8428
[2019-03-26 19:25:28,282] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 175889: learning rate 0.0000
[2019-03-26 19:25:28,284] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 175892: learning rate 0.0000
[2019-03-26 19:25:28,345] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 175915: loss -317.7029
[2019-03-26 19:25:28,347] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 175915: learning rate 0.0000
[2019-03-26 19:25:28,359] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 175923: loss -341.3283
[2019-03-26 19:25:28,360] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 175923: learning rate 0.0000
[2019-03-26 19:25:28,447] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 175963: loss -292.3640
[2019-03-26 19:25:28,449] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 175964: learning rate 0.0000
[2019-03-26 19:25:28,463] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 175970: loss -299.8959
[2019-03-26 19:25:28,464] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 175970: learning rate 0.0000
[2019-03-26 19:25:28,470] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 175970: loss -225.1577
[2019-03-26 19:25:28,473] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 175972: learning rate 0.0000
[2019-03-26 19:25:28,619] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 176038: loss -339.4980
[2019-03-26 19:25:28,622] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 176038: learning rate 0.0000
[2019-03-26 19:25:28,643] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.25219594e-16 1.00000000e+00 1.01099007e-13 3.04226045e-14
 2.07144152e-15], sum to 1.0000
[2019-03-26 19:25:28,650] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7657
[2019-03-26 19:25:28,657] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2393629.777879627 W.
[2019-03-26 19:25:28,663] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.051826120713041, 6.9112, 168.9120753330483, 2393629.777879627, 2293865.28831779, 476272.0247427998], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6609600.0000, 
sim time next is 6610200.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.8011374567282207, 1.0, 1.0, 0.8011374567282207, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2240528.817544354, 2240528.817544354, 420423.2589658666], 
processed observation next is [1.0, 0.5217391304347826, 0.6682464454976303, 0.66, 1.0, 1.0, 0.7604065743713502, 1.0, 0.5, 0.7604065743713502, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6223691159845428, 0.6223691159845428, 0.6274974014415919], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.6102808], dtype=float32), 1.2450813]. 
=============================================
[2019-03-26 19:25:28,919] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 176174: loss -221.9672
[2019-03-26 19:25:28,921] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 176175: learning rate 0.0000
[2019-03-26 19:25:29,004] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 176216: loss -261.8513
[2019-03-26 19:25:29,007] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 176217: learning rate 0.0000
[2019-03-26 19:25:29,461] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 176424: loss -299.8067
[2019-03-26 19:25:29,463] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 176424: learning rate 0.0000
[2019-03-26 19:25:29,526] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 176455: loss -336.2723
[2019-03-26 19:25:29,529] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 176455: learning rate 0.0000
[2019-03-26 19:25:34,488] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.0727707e-15 1.0000000e+00 4.9164823e-13 4.2304384e-13 2.2898187e-14], sum to 1.0000
[2019-03-26 19:25:34,496] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6817
[2019-03-26 19:25:34,503] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2026344.679728324 W.
[2019-03-26 19:25:34,509] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.86666666666667, 64.33333333333333, 1.0, 2.0, 0.4830823088089595, 1.0, 2.0, 0.4830823088089595, 1.0, 2.0, 0.8204228829160012, 6.911200000000001, 6.9112, 170.5573041426782, 2026344.679728324, 2026344.679728324, 400376.5523226307], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6709200.0000, 
sim time next is 6709800.0000, 
raw observation next is [29.83333333333334, 64.66666666666667, 1.0, 2.0, 0.7260836682427653, 1.0, 2.0, 0.7260836682427653, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2030431.882055632, 2030431.882055632, 385480.9137132887], 
processed observation next is [1.0, 0.6521739130434783, 0.6129541864139023, 0.6466666666666667, 1.0, 1.0, 0.6699803231840545, 1.0, 1.0, 0.6699803231840545, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5640088561265645, 0.5640088561265645, 0.5753446473332667], 
reward next is 0.4247, 
noisyNet noise sample is [array([-0.1350037], dtype=float32), -0.3833214]. 
=============================================
[2019-03-26 19:25:40,086] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.2872956e-19 1.0000000e+00 5.4269566e-17 1.6931260e-16 1.1046160e-17], sum to 1.0000
[2019-03-26 19:25:40,099] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8786
[2019-03-26 19:25:40,105] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.95, 50.33333333333334, 1.0, 2.0, 0.4634626496994402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 715458.3699750584, 715458.369975059, 186202.897116919], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6801000.0000, 
sim time next is 6801600.0000, 
raw observation next is [28.8, 50.66666666666667, 1.0, 2.0, 0.3253137773952314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 503269.5484397367, 503269.5484397367, 166966.0851520679], 
processed observation next is [1.0, 0.7391304347826086, 0.5639810426540285, 0.5066666666666667, 1.0, 1.0, 0.18712503300630284, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13979709678881574, 0.13979709678881574, 0.24920311216726554], 
reward next is 0.7508, 
noisyNet noise sample is [array([-0.5170728], dtype=float32), 1.9608456]. 
=============================================
[2019-03-26 19:25:43,292] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1187507e-16 1.0000000e+00 2.0297700e-14 1.6268308e-14 1.4865324e-15], sum to 1.0000
[2019-03-26 19:25:43,299] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7496
[2019-03-26 19:25:43,304] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.01666666666667, 60.5, 1.0, 2.0, 0.3552286247109708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 546793.3043005125, 546793.3043005131, 170366.6043472594], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6861000.0000, 
sim time next is 6861600.0000, 
raw observation next is [27.2, 59.0, 1.0, 2.0, 0.3515686018820105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 542502.2869446904, 542502.286944691, 170049.3311366432], 
processed observation next is [0.0, 0.43478260869565216, 0.4881516587677725, 0.59, 1.0, 1.0, 0.2187573516650729, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15069507970685844, 0.1506950797068586, 0.2538049718457361], 
reward next is 0.7462, 
noisyNet noise sample is [array([0.6795303], dtype=float32), -1.2127482]. 
=============================================
[2019-03-26 19:25:44,564] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 183374: loss 0.9002
[2019-03-26 19:25:44,567] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 183374: learning rate 0.0000
[2019-03-26 19:25:45,299] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 183702: loss 0.7385
[2019-03-26 19:25:45,302] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 183702: learning rate 0.0000
[2019-03-26 19:25:45,419] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 183755: loss 0.8462
[2019-03-26 19:25:45,421] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 183757: learning rate 0.0000
[2019-03-26 19:25:45,548] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 183813: loss 0.8692
[2019-03-26 19:25:45,551] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 183814: learning rate 0.0000
[2019-03-26 19:25:45,737] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 183892: loss 0.7662
[2019-03-26 19:25:45,740] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 183893: learning rate 0.0000
[2019-03-26 19:25:45,752] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.99524004e-17 1.00000000e+00 1.14742946e-14 2.46327955e-14
 3.75796940e-16], sum to 1.0000
[2019-03-26 19:25:45,758] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1826
[2019-03-26 19:25:45,762] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.46666666666667, 59.83333333333334, 1.0, 2.0, 0.3651673809196034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 557958.4867546587, 557958.4867546587, 171189.7000053049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6894600.0000, 
sim time next is 6895200.0000, 
raw observation next is [27.33333333333334, 60.66666666666667, 1.0, 2.0, 0.3659445231085839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 558768.4986753551, 558768.4986753558, 171247.8002511893], 
processed observation next is [0.0, 0.8260869565217391, 0.4944707740916275, 0.6066666666666667, 1.0, 1.0, 0.2360777386850408, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15521347185426532, 0.1552134718542655, 0.255593731718193], 
reward next is 0.7444, 
noisyNet noise sample is [array([-0.5418932], dtype=float32), 1.7007117]. 
=============================================
[2019-03-26 19:25:45,818] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 183932: loss 0.8357
[2019-03-26 19:25:45,820] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 183934: learning rate 0.0000
[2019-03-26 19:25:45,851] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 183947: loss 0.7952
[2019-03-26 19:25:45,854] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 183949: learning rate 0.0000
[2019-03-26 19:25:45,861] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 183951: loss 0.7348
[2019-03-26 19:25:45,865] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 183952: learning rate 0.0000
[2019-03-26 19:25:45,907] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 183969: loss 0.7909
[2019-03-26 19:25:45,909] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 183969: learning rate 0.0000
[2019-03-26 19:25:45,943] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 183986: loss 0.7273
[2019-03-26 19:25:45,947] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 183988: learning rate 0.0000
[2019-03-26 19:25:45,948] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 183989: loss 0.8553
[2019-03-26 19:25:45,953] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 183990: learning rate 0.0000
[2019-03-26 19:25:46,060] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 184036: loss 0.7213
[2019-03-26 19:25:46,062] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 184036: learning rate 0.0000
[2019-03-26 19:25:46,396] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 184186: loss 0.7230
[2019-03-26 19:25:46,399] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 184187: learning rate 0.0000
[2019-03-26 19:25:46,590] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 184278: loss 0.8132
[2019-03-26 19:25:46,595] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 184280: learning rate 0.0000
[2019-03-26 19:25:47,063] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 184491: loss 0.8804
[2019-03-26 19:25:47,067] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 184493: learning rate 0.0000
[2019-03-26 19:25:47,072] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 184496: loss 0.7172
[2019-03-26 19:25:47,078] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 184498: learning rate 0.0000
[2019-03-26 19:25:48,940] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8064324e-16 1.0000000e+00 2.6659152e-14 1.1274317e-14 1.2712222e-15], sum to 1.0000
[2019-03-26 19:25:48,946] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4590
[2019-03-26 19:25:48,950] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666666, 52.66666666666667, 1.0, 2.0, 0.4683991813756679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 655373.9722792763, 655373.972279277, 178905.9571989406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6957600.0000, 
sim time next is 6958200.0000, 
raw observation next is [31.83333333333333, 52.33333333333334, 1.0, 2.0, 0.471694100601146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 659106.9488606076, 659106.9488606076, 179279.9763761303], 
processed observation next is [0.0, 0.5217391304347826, 0.7077409162717218, 0.5233333333333334, 1.0, 1.0, 0.3634868681941518, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.183085263572391, 0.183085263572391, 0.2675820542927318], 
reward next is 0.7324, 
noisyNet noise sample is [array([1.1178935], dtype=float32), 1.6415899]. 
=============================================
[2019-03-26 19:25:49,379] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0546513e-17 1.0000000e+00 3.5628107e-15 3.0590341e-15 2.0270790e-16], sum to 1.0000
[2019-03-26 19:25:49,386] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2610
[2019-03-26 19:25:49,394] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.81666666666667, 52.0, 1.0, 2.0, 0.4655127809537518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 652273.3864311778, 652273.3864311778, 178603.0257078125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6965400.0000, 
sim time next is 6966000.0000, 
raw observation next is [32.0, 52.0, 1.0, 2.0, 0.4712522346341112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 658489.3299567733, 658489.329956774, 179214.6750887377], 
processed observation next is [0.0, 0.6521739130434783, 0.7156398104265403, 0.52, 1.0, 1.0, 0.36295449955917014, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18291370276577038, 0.18291370276577057, 0.26748458968468314], 
reward next is 0.7325, 
noisyNet noise sample is [array([0.9704349], dtype=float32), -1.3172712]. 
=============================================
[2019-03-26 19:25:49,418] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[63.965134]
 [63.900482]
 [63.828037]
 [63.764885]
 [63.704414]], R is [[64.13385773]
 [64.22594452]
 [64.31786346]
 [64.40973663]
 [64.5020752 ]].
[2019-03-26 19:25:57,060] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3865912e-20 1.0000000e+00 2.6559688e-17 4.8853161e-17 8.1663548e-20], sum to 1.0000
[2019-03-26 19:25:57,069] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6133
[2019-03-26 19:25:57,075] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.23333333333333, 88.83333333333334, 1.0, 2.0, 0.4723686625885019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 662500.8905011335, 662500.8905011329, 179696.5471681743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7084200.0000, 
sim time next is 7084800.0000, 
raw observation next is [25.2, 89.0, 1.0, 2.0, 0.4718344121776715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 662063.976337504, 662063.9763375047, 179657.2734908038], 
processed observation next is [1.0, 0.0, 0.3933649289099526, 0.89, 1.0, 1.0, 0.3636559182863512, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18390666009375112, 0.1839066600937513, 0.2681451843146326], 
reward next is 0.7319, 
noisyNet noise sample is [array([0.4288015], dtype=float32), -1.5802672]. 
=============================================
[2019-03-26 19:26:02,294] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 191303: loss 0.0867
[2019-03-26 19:26:02,301] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 191306: learning rate 0.0000
[2019-03-26 19:26:03,267] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 191732: loss 0.1174
[2019-03-26 19:26:03,270] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 191733: learning rate 0.0000
[2019-03-26 19:26:03,332] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 191764: loss 0.0937
[2019-03-26 19:26:03,335] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 191766: learning rate 0.0000
[2019-03-26 19:26:03,376] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 191783: loss 0.0823
[2019-03-26 19:26:03,377] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 191783: learning rate 0.0000
[2019-03-26 19:26:03,562] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 191865: loss 0.0844
[2019-03-26 19:26:03,566] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 191866: learning rate 0.0000
[2019-03-26 19:26:03,700] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 191923: loss 0.0727
[2019-03-26 19:26:03,702] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 191923: learning rate 0.0000
[2019-03-26 19:26:03,716] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 191931: loss 0.0771
[2019-03-26 19:26:03,719] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 191931: learning rate 0.0000
[2019-03-26 19:26:03,755] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 191953: loss 0.1080
[2019-03-26 19:26:03,758] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 191954: learning rate 0.0000
[2019-03-26 19:26:03,769] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 191959: loss 0.0934
[2019-03-26 19:26:03,771] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 191959: learning rate 0.0000
[2019-03-26 19:26:03,802] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 191971: loss 0.1184
[2019-03-26 19:26:03,804] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 191972: learning rate 0.0000
[2019-03-26 19:26:03,912] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 192021: loss 0.0874
[2019-03-26 19:26:03,919] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 192021: learning rate 0.0000
[2019-03-26 19:26:03,980] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 192051: loss 0.0889
[2019-03-26 19:26:03,982] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 192052: learning rate 0.0000
[2019-03-26 19:26:04,157] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 192128: loss 0.1160
[2019-03-26 19:26:04,163] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 192131: learning rate 0.0000
[2019-03-26 19:26:04,385] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 192228: loss 0.1227
[2019-03-26 19:26:04,390] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 192229: learning rate 0.0000
[2019-03-26 19:26:04,796] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 192411: loss 0.1072
[2019-03-26 19:26:04,797] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 192411: learning rate 0.0000
[2019-03-26 19:26:04,949] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 192468: loss 0.1050
[2019-03-26 19:26:04,951] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 192468: learning rate 0.0000
[2019-03-26 19:26:06,777] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.4221373e-20 1.0000000e+00 3.2317465e-16 3.9034534e-16 1.2789834e-18], sum to 1.0000
[2019-03-26 19:26:06,789] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3185
[2019-03-26 19:26:06,793] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.38333333333333, 91.00000000000001, 1.0, 2.0, 0.3549431300573214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 546522.4374547639, 546522.4374547639, 170348.9265087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7251000.0000, 
sim time next is 7251600.0000, 
raw observation next is [22.36666666666667, 91.0, 1.0, 2.0, 0.3542422841174849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 545710.5119515782, 545710.5119515775, 170289.0408707763], 
processed observation next is [1.0, 0.9565217391304348, 0.2590837282780413, 0.91, 1.0, 1.0, 0.2219786555632348, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15158625331988285, 0.15158625331988265, 0.25416274756832286], 
reward next is 0.7458, 
noisyNet noise sample is [array([-1.8372929], dtype=float32), 0.9780942]. 
=============================================
[2019-03-26 19:26:08,784] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8115164e-18 1.0000000e+00 7.9395829e-16 4.4568465e-16 1.1773753e-16], sum to 1.0000
[2019-03-26 19:26:08,796] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5972
[2019-03-26 19:26:08,804] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.95, 88.5, 1.0, 2.0, 0.3271061895200982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 513743.2461474621, 513743.2461474627, 167996.220911652], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7263000.0000, 
sim time next is 7263600.0000, 
raw observation next is [21.93333333333333, 88.33333333333334, 1.0, 2.0, 0.3261194198805615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 512668.71813455, 512668.71813455, 167924.1603654595], 
processed observation next is [1.0, 0.043478260869565216, 0.23854660347551332, 0.8833333333333334, 1.0, 1.0, 0.18809568660308612, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14240797725959722, 0.14240797725959722, 0.25063307517232764], 
reward next is 0.7494, 
noisyNet noise sample is [array([-0.3667988], dtype=float32), 0.30245396]. 
=============================================
[2019-03-26 19:26:08,971] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3832240e-17 1.0000000e+00 1.5375747e-15 3.6337324e-15 1.7454261e-16], sum to 1.0000
[2019-03-26 19:26:08,980] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2777
[2019-03-26 19:26:08,989] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.05, 86.66666666666667, 1.0, 2.0, 0.3440939055081151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 542383.9099507106, 542383.9099507106, 170296.9382657273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7283400.0000, 
sim time next is 7284000.0000, 
raw observation next is [22.1, 86.33333333333334, 1.0, 2.0, 0.3213458952932802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 506439.1921281008, 506439.1921281014, 167475.9403250956], 
processed observation next is [1.0, 0.30434782608695654, 0.24644549763033188, 0.8633333333333334, 1.0, 1.0, 0.18234445216057857, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14067755336891688, 0.14067755336891707, 0.24996409003745612], 
reward next is 0.7500, 
noisyNet noise sample is [array([-0.58762336], dtype=float32), 0.29740506]. 
=============================================
[2019-03-26 19:26:09,004] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[62.645916]
 [62.574757]
 [62.560516]
 [62.51705 ]
 [62.44458 ]], R is [[62.82576752]
 [62.94333649]
 [63.06378555]
 [63.18272018]
 [63.3004303 ]].
[2019-03-26 19:26:09,095] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.2736947e-18 1.0000000e+00 5.0416794e-14 1.1564288e-14 1.6065761e-16], sum to 1.0000
[2019-03-26 19:26:09,107] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3053
[2019-03-26 19:26:09,112] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.7, 78.0, 1.0, 2.0, 0.6158571413611812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 960038.4330644807, 960038.4330644801, 215619.9456759862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7290000.0000, 
sim time next is 7290600.0000, 
raw observation next is [23.91666666666666, 77.0, 1.0, 2.0, 0.6188979037045651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 963114.0137039186, 963114.0137039186, 216104.6805326202], 
processed observation next is [1.0, 0.391304347826087, 0.3325434439178513, 0.77, 1.0, 1.0, 0.5408408478368254, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2675316704733107, 0.2675316704733107, 0.32254429930241824], 
reward next is 0.6775, 
noisyNet noise sample is [array([0.19004996], dtype=float32), -0.8118576]. 
=============================================
[2019-03-26 19:26:16,355] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.0533620e-19 1.0000000e+00 1.1758627e-16 5.6411865e-16 2.7520411e-18], sum to 1.0000
[2019-03-26 19:26:16,364] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1830
[2019-03-26 19:26:16,369] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 92.0, 1.0, 2.0, 0.3159488283097837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 498901.1413231689, 498901.1413231689, 166928.5734579208], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7434000.0000, 
sim time next is 7434600.0000, 
raw observation next is [21.31666666666667, 91.83333333333334, 1.0, 2.0, 0.315471054679055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 498204.7504799939, 498204.7504799945, 166877.7633131374], 
processed observation next is [0.0, 0.043478260869565216, 0.20932069510268583, 0.9183333333333334, 1.0, 1.0, 0.17526633093862048, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13839020846666497, 0.13839020846666514, 0.24907128852707075], 
reward next is 0.7509, 
noisyNet noise sample is [array([-2.0623848], dtype=float32), 0.5054575]. 
=============================================
[2019-03-26 19:26:19,387] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.0084667e-17 1.0000000e+00 1.2695921e-14 4.2497080e-14 6.6952936e-16], sum to 1.0000
[2019-03-26 19:26:19,394] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9832
[2019-03-26 19:26:19,402] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 94.0, 1.0, 2.0, 0.343530330741215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 531024.3913743892, 531024.3913743892, 169139.5427582343], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7461000.0000, 
sim time next is 7461600.0000, 
raw observation next is [22.0, 93.66666666666667, 1.0, 2.0, 0.3452236390077541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 532743.9537262849, 532743.9537262843, 169251.9696557469], 
processed observation next is [0.0, 0.34782608695652173, 0.2417061611374408, 0.9366666666666668, 1.0, 1.0, 0.21111281808163143, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1479844315906347, 0.14798443159063454, 0.2526148800832044], 
reward next is 0.7474, 
noisyNet noise sample is [array([-0.28897288], dtype=float32), 1.0105543]. 
=============================================
[2019-03-26 19:26:20,224] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 199327: loss 0.2167
[2019-03-26 19:26:20,229] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 199329: learning rate 0.0000
[2019-03-26 19:26:21,179] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 199747: loss 0.2073
[2019-03-26 19:26:21,181] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 199748: learning rate 0.0000
[2019-03-26 19:26:21,289] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 199800: loss 0.2173
[2019-03-26 19:26:21,291] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 199800: learning rate 0.0000
[2019-03-26 19:26:21,387] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 199840: loss 0.1447
[2019-03-26 19:26:21,389] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 199840: learning rate 0.0000
[2019-03-26 19:26:21,435] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 199862: loss 0.2214
[2019-03-26 19:26:21,438] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 199862: learning rate 0.0000
[2019-03-26 19:26:21,458] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 199872: loss 0.1518
[2019-03-26 19:26:21,461] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 199872: learning rate 0.0000
[2019-03-26 19:26:21,581] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 199927: loss 0.1335
[2019-03-26 19:26:21,583] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 199927: learning rate 0.0000
[2019-03-26 19:26:21,621] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 199943: loss 0.1740
[2019-03-26 19:26:21,622] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 199943: learning rate 0.0000
[2019-03-26 19:26:21,665] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 199963: loss 0.2095
[2019-03-26 19:26:21,670] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 199963: learning rate 0.0000
[2019-03-26 19:26:21,730] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 199991: loss 0.1639
[2019-03-26 19:26:21,734] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 199992: learning rate 0.0000
[2019-03-26 19:26:21,747] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 19:26:21,749] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:26:21,750] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:26:21,751] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:26:21,751] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:26:21,752] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:26:21,755] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:26:21,757] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:26:21,759] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:26:21,756] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:26:21,764] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:26:21,782] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run9
[2019-03-26 19:26:21,801] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run9
[2019-03-26 19:26:21,801] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run9
[2019-03-26 19:26:21,819] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run9
[2019-03-26 19:26:21,851] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run9
[2019-03-26 19:26:29,680] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05307939], dtype=float32), 0.059570003]
[2019-03-26 19:26:29,681] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.13218529666667, 79.06254298000002, 1.0, 2.0, 0.211592399899161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 353125.0865723865, 353125.0865723865, 156642.8732592074]
[2019-03-26 19:26:29,682] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:26:29,687] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1775774e-16 1.0000000e+00 5.5424107e-14 2.9156192e-14 1.5283410e-15], sampled 0.5477575297190316
[2019-03-26 19:27:11,230] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05307939], dtype=float32), 0.059570003]
[2019-03-26 19:27:11,231] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.78333333333333, 70.5, 1.0, 2.0, 0.5390074614433792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 753198.5073163166, 753198.5073163166, 189932.8096527205]
[2019-03-26 19:27:11,232] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:27:11,234] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.9637708e-18 1.0000000e+00 1.9015288e-15 1.5121035e-15 7.0620115e-17], sampled 0.06529947298156813
[2019-03-26 19:27:36,529] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05307939], dtype=float32), 0.059570003]
[2019-03-26 19:27:36,530] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.33333333333333, 82.66666666666667, 1.0, 2.0, 0.5952599714634166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 831835.4469585558, 831835.4469585558, 199865.5597759124]
[2019-03-26 19:27:36,532] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:27:36,533] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.527451e-19 1.000000e+00 7.010935e-16 5.562718e-16 2.110515e-17], sampled 0.23401842292656994
[2019-03-26 19:28:08,976] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05307939], dtype=float32), 0.059570003]
[2019-03-26 19:28:08,977] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.51000905166667, 91.11139842, 1.0, 2.0, 0.2875836810369267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 463860.7490254548, 463860.7490254548, 164536.1406860835]
[2019-03-26 19:28:08,977] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:28:08,980] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.1732051e-17 1.0000000e+00 1.7622573e-14 1.0253133e-14 5.0199598e-16], sampled 0.13228922097231266
[2019-03-26 19:28:16,679] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3694 2779190338.1949 933.0000
[2019-03-26 19:28:16,885] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0947 2842476605.5833 1131.0000
[2019-03-26 19:28:17,140] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4118 3164064553.2451 1778.0000
[2019-03-26 19:28:17,145] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.3823 2927278091.4500 1338.0000
[2019-03-26 19:28:17,163] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5735 3007648438.5815 1766.0000
[2019-03-26 19:28:18,178] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 200000, evaluation results [200000.0, 7883.411789251931, 3164064553.2451096, 1778.0, 8254.382294801491, 2927278091.449961, 1338.0, 8661.369356548688, 2779190338.194891, 933.0, 7997.573465804901, 3007648438.5815053, 1766.0, 8496.094724748822, 2842476605.583347, 1131.0]
[2019-03-26 19:28:18,251] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 200039: loss 0.2366
[2019-03-26 19:28:18,255] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 200040: learning rate 0.0000
[2019-03-26 19:28:18,274] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5730487e-20 1.0000000e+00 2.9138969e-17 4.1427761e-18 3.0575478e-18], sum to 1.0000
[2019-03-26 19:28:18,281] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2981
[2019-03-26 19:28:18,286] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.45, 85.33333333333334, 1.0, 2.0, 0.402064948367434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 593435.8710656009, 593435.8710656002, 173736.6906591997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7503000.0000, 
sim time next is 7503600.0000, 
raw observation next is [24.4, 85.66666666666667, 1.0, 2.0, 0.4026875036412299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 594441.6762665659, 594441.6762665653, 173833.0508850024], 
processed observation next is [0.0, 0.8695652173913043, 0.3554502369668246, 0.8566666666666667, 1.0, 1.0, 0.28034638992919264, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16512268785182388, 0.1651226878518237, 0.2594523147537349], 
reward next is 0.7405, 
noisyNet noise sample is [array([0.15244478], dtype=float32), -1.0985347]. 
=============================================
[2019-03-26 19:28:18,311] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 200070: loss 0.1614
[2019-03-26 19:28:18,314] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 200070: learning rate 0.0000
[2019-03-26 19:28:18,493] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 200154: loss 0.1674
[2019-03-26 19:28:18,495] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 200155: learning rate 0.0000
[2019-03-26 19:28:18,821] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 200304: loss 0.1836
[2019-03-26 19:28:18,824] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 200304: learning rate 0.0000
[2019-03-26 19:28:19,171] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 200470: loss 0.1385
[2019-03-26 19:28:19,174] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 200470: learning rate 0.0000
[2019-03-26 19:28:19,306] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 200529: loss 0.1436
[2019-03-26 19:28:19,308] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 200529: learning rate 0.0000
[2019-03-26 19:28:19,366] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1124136e-17 1.0000000e+00 1.8216504e-15 2.9592566e-15 7.2604084e-17], sum to 1.0000
[2019-03-26 19:28:19,378] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3266
[2019-03-26 19:28:19,383] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 93.0, 1.0, 2.0, 0.4052288579085293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 596593.7991905018, 596593.7991905018, 173983.2925343863], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7521600.0000, 
sim time next is 7522200.0000, 
raw observation next is [23.5, 93.0, 1.0, 2.0, 0.4059162739980898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 597606.4208987879, 597606.4208987873, 174076.9876780622], 
processed observation next is [0.0, 0.043478260869565216, 0.31279620853080575, 0.93, 1.0, 1.0, 0.28423647469649377, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16600178358299664, 0.16600178358299647, 0.2598163995194958], 
reward next is 0.7402, 
noisyNet noise sample is [array([0.6087782], dtype=float32), 0.1117729]. 
=============================================
[2019-03-26 19:28:19,698] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.10545906e-17 1.00000000e+00 1.30245664e-14 7.26853541e-15
 7.32445007e-16], sum to 1.0000
[2019-03-26 19:28:19,709] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0624
[2019-03-26 19:28:19,717] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.13333333333333, 90.66666666666667, 1.0, 2.0, 0.3780343696340843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 569319.488506724, 569319.4885067233, 171924.0297224739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7532400.0000, 
sim time next is 7533000.0000, 
raw observation next is [23.1, 90.5, 1.0, 2.0, 0.3755939519671112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 566659.9541613702, 566659.9541613702, 171722.8529146654], 
processed observation next is [0.0, 0.17391304347826086, 0.2938388625592418, 0.905, 1.0, 1.0, 0.24770355658688098, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15740554282260283, 0.15740554282260283, 0.2563027655442767], 
reward next is 0.7437, 
noisyNet noise sample is [array([-0.21593644], dtype=float32), 1.0409336]. 
=============================================
[2019-03-26 19:28:19,734] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[65.41427]
 [65.63761]
 [65.92196]
 [66.12191]
 [66.41378]], R is [[65.29187012]
 [65.38235474]
 [65.47162628]
 [65.55976868]
 [65.6468811 ]].
[2019-03-26 19:28:22,082] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2890096e-18 1.0000000e+00 1.9755874e-16 8.8068424e-16 2.0548882e-17], sum to 1.0000
[2019-03-26 19:28:22,089] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5996
[2019-03-26 19:28:22,093] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.83333333333333, 62.0, 1.0, 2.0, 0.4674771543322592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 653212.7197094756, 653212.7197094751, 178657.5924909291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7571400.0000, 
sim time next is 7572000.0000, 
raw observation next is [29.66666666666667, 62.0, 1.0, 2.0, 0.4643887633404882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 648895.9474373192, 648895.9474373192, 178204.6994065632], 
processed observation next is [0.0, 0.6521739130434783, 0.6050552922590839, 0.62, 1.0, 1.0, 0.3546852570367327, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18024887428814423, 0.18024887428814423, 0.2659771632933779], 
reward next is 0.7340, 
noisyNet noise sample is [array([-0.0194503], dtype=float32), 0.53775495]. 
=============================================
[2019-03-26 19:28:22,103] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[69.58095 ]
 [69.51572 ]
 [69.45244 ]
 [69.40279 ]
 [69.346115]], R is [[69.6727066 ]
 [69.7093277 ]
 [69.74567413]
 [69.78326416]
 [69.82167816]].
[2019-03-26 19:28:24,493] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.8606702e-20 1.0000000e+00 2.4568381e-17 1.8547308e-17 2.3953682e-19], sum to 1.0000
[2019-03-26 19:28:24,501] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8882
[2019-03-26 19:28:24,508] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.45, 93.5, 1.0, 2.0, 0.4621301086147338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 652642.8195107767, 652642.8195107767, 178766.3776916693], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7605000.0000, 
sim time next is 7605600.0000, 
raw observation next is [24.4, 93.66666666666667, 1.0, 2.0, 0.460480244997354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 651126.4823016808, 651126.4823016814, 178628.5229309812], 
processed observation next is [1.0, 0.0, 0.3554502369668246, 0.9366666666666668, 1.0, 1.0, 0.3499761987919928, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18086846730602246, 0.18086846730602263, 0.26660973571788243], 
reward next is 0.7334, 
noisyNet noise sample is [array([-0.36612678], dtype=float32), 0.42628852]. 
=============================================
[2019-03-26 19:28:26,954] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.0768759e-20 1.0000000e+00 7.9382465e-17 2.7627503e-17 1.3298308e-18], sum to 1.0000
[2019-03-26 19:28:26,961] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2442
[2019-03-26 19:28:26,969] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.06666666666667, 66.66666666666667, 1.0, 2.0, 1.0035792529014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104249, 1402810.864809447, 1402810.864809446, 300014.8380955955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7641600.0000, 
sim time next is 7642200.0000, 
raw observation next is [29.33333333333334, 65.33333333333333, 1.0, 2.0, 1.014968762684523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1418741.848497398, 1418741.848497398, 303516.4204953069], 
processed observation next is [1.0, 0.43478260869565216, 0.5892575039494474, 0.6533333333333333, 1.0, 1.0, 1.0180346538367746, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3940949579159439, 0.3940949579159439, 0.45300958282881626], 
reward next is 0.5470, 
noisyNet noise sample is [array([-0.15722664], dtype=float32), -0.42084974]. 
=============================================
[2019-03-26 19:28:27,915] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0632180e-19 1.0000000e+00 7.9438166e-18 1.2484655e-17 6.3539527e-19], sum to 1.0000
[2019-03-26 19:28:27,922] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3155
[2019-03-26 19:28:27,932] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 88.00000000000001, 1.0, 2.0, 0.4874057564364518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 681068.175803685, 681068.1758036857, 181645.9529602509], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7683000.0000, 
sim time next is 7683600.0000, 
raw observation next is [25.63333333333334, 88.0, 1.0, 2.0, 0.4854030803664347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 678268.8769390162, 678268.8769390162, 181340.2800587422], 
processed observation next is [1.0, 0.9565217391304348, 0.4139020537124806, 0.88, 1.0, 1.0, 0.3800037112848611, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18840802137194892, 0.18840802137194892, 0.2706571344160332], 
reward next is 0.7293, 
noisyNet noise sample is [array([0.4016756], dtype=float32), -1.3932072]. 
=============================================
[2019-03-26 19:28:28,451] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1165437e-21 1.0000000e+00 5.4696015e-18 4.0259914e-18 1.3932141e-19], sum to 1.0000
[2019-03-26 19:28:28,460] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5135
[2019-03-26 19:28:28,466] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 88.0, 1.0, 2.0, 0.4907757578077594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 685778.7101230004, 685778.7101230004, 182163.2575080206], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7680000.0000, 
sim time next is 7680600.0000, 
raw observation next is [25.8, 88.0, 1.0, 2.0, 0.4890337036597263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 683343.6919329992, 683343.6919329999, 181895.5481705506], 
processed observation next is [1.0, 0.9130434782608695, 0.42180094786729866, 0.88, 1.0, 1.0, 0.3843779562165377, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1898176922036109, 0.18981769220361108, 0.2714858927918666], 
reward next is 0.7285, 
noisyNet noise sample is [array([-1.0430392], dtype=float32), 2.391764]. 
=============================================
[2019-03-26 19:28:31,184] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3439324e-19 1.0000000e+00 6.0176699e-16 2.6532460e-16 2.0523344e-17], sum to 1.0000
[2019-03-26 19:28:31,195] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1697
[2019-03-26 19:28:31,201] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2013634.191144428 W.
[2019-03-26 19:28:31,205] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.1, 70.0, 1.0, 2.0, 0.4800549625741918, 1.0, 1.0, 0.4800549625741918, 1.0, 2.0, 0.8285346063372513, 6.9112, 6.9112, 170.5573041426782, 2013634.191144428, 2013634.191144428, 400736.7490785991], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7726200.0000, 
sim time next is 7726800.0000, 
raw observation next is [30.3, 69.0, 1.0, 2.0, 0.7118785799921034, 1.0, 2.0, 0.7118785799921034, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1990671.641578456, 1990671.641578456, 379249.9213498148], 
processed observation next is [1.0, 0.43478260869565216, 0.6350710900473934, 0.69, 1.0, 1.0, 0.6528657590266306, 1.0, 1.0, 0.6528657590266306, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5529643448829045, 0.5529643448829045, 0.5660446587310669], 
reward next is 0.4340, 
noisyNet noise sample is [array([0.00849294], dtype=float32), 0.346206]. 
=============================================
[2019-03-26 19:28:34,165] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 207434: loss 0.0768
[2019-03-26 19:28:34,172] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 207434: learning rate 0.0000
[2019-03-26 19:28:34,863] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 207745: loss 0.0714
[2019-03-26 19:28:34,868] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 207748: learning rate 0.0000
[2019-03-26 19:28:34,892] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 207759: loss 0.0551
[2019-03-26 19:28:34,896] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 207760: learning rate 0.0000
[2019-03-26 19:28:34,999] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 207805: loss 0.0542
[2019-03-26 19:28:35,002] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 207805: learning rate 0.0000
[2019-03-26 19:28:35,099] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 207849: loss 0.0700
[2019-03-26 19:28:35,102] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 207849: learning rate 0.0000
[2019-03-26 19:28:35,108] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 207853: loss 0.0774
[2019-03-26 19:28:35,110] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 207855: learning rate 0.0000
[2019-03-26 19:28:35,352] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 207962: loss 0.0965
[2019-03-26 19:28:35,355] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 207962: learning rate 0.0000
[2019-03-26 19:28:35,364] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 207966: loss 0.0772
[2019-03-26 19:28:35,367] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 207966: learning rate 0.0000
[2019-03-26 19:28:35,393] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 207983: loss 0.0455
[2019-03-26 19:28:35,394] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 207983: learning rate 0.0000
[2019-03-26 19:28:35,426] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 207999: loss 0.0967
[2019-03-26 19:28:35,431] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 207999: learning rate 0.0000
[2019-03-26 19:28:35,490] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 208023: loss 0.0562
[2019-03-26 19:28:35,492] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 208024: learning rate 0.0000
[2019-03-26 19:28:35,589] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 208068: loss 0.0818
[2019-03-26 19:28:35,591] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 208068: learning rate 0.0000
[2019-03-26 19:28:35,615] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 208078: loss 0.0889
[2019-03-26 19:28:35,616] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 208078: learning rate 0.0000
[2019-03-26 19:28:35,966] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 208232: loss 0.0826
[2019-03-26 19:28:35,968] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 208232: learning rate 0.0000
[2019-03-26 19:28:36,325] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 208393: loss 0.0673
[2019-03-26 19:28:36,327] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 208393: learning rate 0.0000
[2019-03-26 19:28:36,385] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 208418: loss 0.1345
[2019-03-26 19:28:36,387] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 208418: learning rate 0.0000
[2019-03-26 19:28:40,840] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.43231141e-18 1.00000000e+00 1.06452284e-15 1.07590026e-16
 6.93757951e-18], sum to 1.0000
[2019-03-26 19:28:40,848] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7614
[2019-03-26 19:28:40,854] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.06666666666667, 91.66666666666667, 1.0, 2.0, 0.7750309242955185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1083181.276651891, 1083181.276651891, 237872.7383336706], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7872000.0000, 
sim time next is 7872600.0000, 
raw observation next is [26.08333333333334, 91.33333333333334, 1.0, 2.0, 0.7600381123005231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1062216.880056028, 1062216.880056028, 234336.6552992772], 
processed observation next is [1.0, 0.08695652173913043, 0.43522906793049004, 0.9133333333333334, 1.0, 1.0, 0.710889291928341, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2950602444600078, 0.2950602444600078, 0.3497562019392197], 
reward next is 0.6502, 
noisyNet noise sample is [array([-0.40009615], dtype=float32), -0.060533736]. 
=============================================
[2019-03-26 19:28:44,033] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:44,034] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:44,067] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run2
[2019-03-26 19:28:44,882] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:44,882] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:44,884] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run2
[2019-03-26 19:28:44,899] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:44,900] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:44,903] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run2
[2019-03-26 19:28:44,923] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:44,923] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:44,924] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run2
[2019-03-26 19:28:44,936] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:44,936] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:44,941] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run2
[2019-03-26 19:28:45,045] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:45,045] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:45,046] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run2
[2019-03-26 19:28:45,167] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:45,168] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:45,169] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run2
[2019-03-26 19:28:45,185] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:45,186] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:45,189] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:45,189] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:45,191] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run2
[2019-03-26 19:28:45,204] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:45,206] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:45,205] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run2
[2019-03-26 19:28:45,207] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run2
[2019-03-26 19:28:45,222] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:45,236] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:45,236] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:45,237] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:45,237] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:45,240] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:45,241] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run2
[2019-03-26 19:28:45,258] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run2
[2019-03-26 19:28:45,275] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run2
[2019-03-26 19:28:45,296] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:45,297] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:45,298] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run2
[2019-03-26 19:28:45,335] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:45,335] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:45,336] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run2
[2019-03-26 19:28:45,364] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:28:45,365] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:28:45,366] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run2
[2019-03-26 19:28:48,373] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0729493e-16 1.0000000e+00 5.1927456e-15 1.0796139e-14 8.5663142e-17], sum to 1.0000
[2019-03-26 19:28:48,381] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5427
[2019-03-26 19:28:48,389] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.53333333333333, 86.0, 1.0, 2.0, 0.3225577815003167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515338.6165904351, 515338.6165904351, 168248.5764558202], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 20400.0000, 
sim time next is 21000.0000, 
raw observation next is [21.56666666666667, 86.0, 1.0, 2.0, 0.3214659440292797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 513241.6594918593, 513241.6594918599, 168087.156031407], 
processed observation next is [1.0, 0.21739130434782608, 0.22116903633491333, 0.86, 1.0, 1.0, 0.18248908919190324, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1425671276366276, 0.14256712763662774, 0.2508763522856821], 
reward next is 0.7491, 
noisyNet noise sample is [array([1.0411466], dtype=float32), -1.0640507]. 
=============================================
[2019-03-26 19:28:48,401] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[62.310875]
 [62.176743]
 [62.112503]
 [61.934612]
 [61.572346]], R is [[62.52991486]
 [62.6534996 ]
 [62.77540588]
 [62.89616394]
 [63.01001358]].
[2019-03-26 19:28:58,390] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3364223e-17 1.0000000e+00 3.5550180e-15 1.7871186e-15 2.9711643e-17], sum to 1.0000
[2019-03-26 19:28:58,397] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2131
[2019-03-26 19:28:58,403] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.06666666666667, 89.33333333333334, 1.0, 2.0, 0.2549050236881701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 415034.4809460548, 415034.4809460548, 161326.1703894624], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 361200.0000, 
sim time next is 361800.0000, 
raw observation next is [20.05, 89.5, 1.0, 2.0, 0.2566018689352981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 417774.758054382, 417774.758054382, 161494.9195042748], 
processed observation next is [1.0, 0.17391304347826086, 0.14928909952606645, 0.895, 1.0, 1.0, 0.1043396011268652, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.116048543903995, 0.116048543903995, 0.24103719328996237], 
reward next is 0.7590, 
noisyNet noise sample is [array([0.2899802], dtype=float32), 1.3177508]. 
=============================================
[2019-03-26 19:28:58,976] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3367588e-17 1.0000000e+00 2.2728877e-14 6.9042193e-15 2.8255833e-16], sum to 1.0000
[2019-03-26 19:28:58,986] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8138
[2019-03-26 19:28:58,992] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.6, 93.0, 1.0, 2.0, 0.2955235204301194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 472817.2235251571, 472817.2235251571, 165141.3872876969], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 207000.0000, 
sim time next is 207600.0000, 
raw observation next is [20.63333333333333, 93.0, 1.0, 2.0, 0.2963497847265903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 473810.7724524142, 473810.7724524142, 165207.7891244677], 
processed observation next is [0.0, 0.391304347826087, 0.17693522906793036, 0.93, 1.0, 1.0, 0.15222865629709673, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13161410345900396, 0.13161410345900396, 0.2465787897380115], 
reward next is 0.7534, 
noisyNet noise sample is [array([0.11751735], dtype=float32), 0.08119059]. 
=============================================
[2019-03-26 19:28:59,266] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.7876909e-18 1.0000000e+00 7.0499874e-15 9.7225862e-16 8.1310240e-17], sum to 1.0000
[2019-03-26 19:28:59,273] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6966
[2019-03-26 19:28:59,278] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.63333333333333, 88.33333333333334, 1.0, 2.0, 0.311616766952448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 493580.8106055849, 493580.8106055849, 166564.0478682458], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 219000.0000, 
sim time next is 219600.0000, 
raw observation next is [21.7, 88.0, 1.0, 2.0, 0.3124876121438484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 494685.9445756486, 494685.9445756486, 166640.4764981013], 
processed observation next is [0.0, 0.5652173913043478, 0.2274881516587678, 0.88, 1.0, 1.0, 0.1716718218600583, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1374127623821246, 0.1374127623821246, 0.24871712910164376], 
reward next is 0.7513, 
noisyNet noise sample is [array([1.4042517], dtype=float32), -0.91634136]. 
=============================================
[2019-03-26 19:29:03,985] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7445199e-17 1.0000000e+00 4.4592808e-15 5.5525021e-15 1.1011834e-16], sum to 1.0000
[2019-03-26 19:29:03,995] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2137
[2019-03-26 19:29:03,998] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.85, 88.66666666666667, 1.0, 2.0, 0.2812510604852813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 452555.221064153, 452555.221064153, 163769.1885237974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 283800.0000, 
sim time next is 284400.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.282696241791992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 454294.7908719257, 454294.7908719263, 163883.2565483385], 
processed observation next is [0.0, 0.30434782608695654, 0.19431279620853087, 0.88, 1.0, 1.0, 0.13577860456866503, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1261929974644238, 0.12619299746442397, 0.24460187544528136], 
reward next is 0.7554, 
noisyNet noise sample is [array([0.16191323], dtype=float32), 0.56755567]. 
=============================================
[2019-03-26 19:29:14,870] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 19:29:14,873] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:29:14,874] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:29:14,875] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:29:14,876] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:29:14,876] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:29:14,877] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:29:14,878] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:29:14,877] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:29:14,878] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:29:14,879] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:29:14,885] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run10
[2019-03-26 19:29:14,886] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run10
[2019-03-26 19:29:14,921] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run10
[2019-03-26 19:29:14,937] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run10
[2019-03-26 19:29:14,938] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run10
[2019-03-26 19:29:17,936] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05726479], dtype=float32), 0.06340234]
[2019-03-26 19:29:17,938] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.48333333333333, 40.0, 1.0, 2.0, 0.4798731107733391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 796445.66643605, 796445.66643605, 191981.1588952663]
[2019-03-26 19:29:17,939] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:29:17,942] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.3862417e-19 1.0000000e+00 2.7580870e-16 2.2590766e-16 8.5781806e-18], sampled 0.03272165347112799
[2019-03-26 19:29:27,712] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05726479], dtype=float32), 0.06340234]
[2019-03-26 19:29:27,713] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.96213517, 79.86188213666668, 1.0, 2.0, 0.3472204156974226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 540641.579594688, 540641.5795946887, 170023.616895482]
[2019-03-26 19:29:27,714] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:29:27,717] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.69730464e-18 1.00000000e+00 4.07758993e-15 2.50174484e-15
 1.01170614e-16], sampled 0.6486065283194574
[2019-03-26 19:29:35,772] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05726479], dtype=float32), 0.06340234]
[2019-03-26 19:29:35,774] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.6, 42.33333333333334, 1.0, 2.0, 0.4466701697424912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 737751.163800436, 737751.1638004367, 186627.9216569559]
[2019-03-26 19:29:35,776] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:29:35,781] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.1290961e-19 1.0000000e+00 4.3813269e-16 3.3966098e-16 1.4185118e-17], sampled 0.5439830229141387
[2019-03-26 19:29:46,007] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05726479], dtype=float32), 0.06340234]
[2019-03-26 19:29:46,008] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.93333333333333, 91.66666666666667, 1.0, 2.0, 0.485059253392507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 677796.4941473521, 677796.4941473521, 181288.5286096499]
[2019-03-26 19:29:46,009] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:29:46,011] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.1903400e-19 1.0000000e+00 2.9417645e-16 2.1233721e-16 7.3180189e-18], sampled 0.5306209938810684
[2019-03-26 19:29:48,971] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05726479], dtype=float32), 0.06340234]
[2019-03-26 19:29:48,972] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.76666666666667, 70.16666666666667, 1.0, 2.0, 0.552833413583755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 815482.3917800939, 815482.3917800939, 197674.9927552994]
[2019-03-26 19:29:48,972] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:29:48,975] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.3723044e-20 1.0000000e+00 1.6705167e-17 1.4875919e-17 4.3291038e-19], sampled 0.5361608931863789
[2019-03-26 19:29:49,222] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05726479], dtype=float32), 0.06340234]
[2019-03-26 19:29:49,223] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.52987165333333, 74.91943655666667, 1.0, 2.0, 0.6528506830155845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 912349.12740861, 912349.12740861, 210995.8242733318]
[2019-03-26 19:29:49,225] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:29:49,229] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.0184401e-20 1.0000000e+00 7.2820997e-17 5.6483969e-17 1.9306677e-18], sampled 0.7941467924268653
[2019-03-26 19:30:08,230] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05726479], dtype=float32), 0.06340234]
[2019-03-26 19:30:08,231] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.1, 73.0, 1.0, 2.0, 0.5627061563112516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 786326.8586652633, 786326.8586652633, 194003.3580579093]
[2019-03-26 19:30:08,233] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:30:08,238] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.3641648e-21 1.0000000e+00 3.5244421e-18 4.3829943e-18 1.1410885e-19], sampled 0.8010770136169149
[2019-03-26 19:30:20,115] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05726479], dtype=float32), 0.06340234]
[2019-03-26 19:30:20,116] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [37.46666666666667, 46.66666666666667, 1.0, 2.0, 0.8518375372006398, 1.0, 2.0, 0.8518375372006398, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 169.0403247858759, 2382476.492443391, 2382476.49244339, 445618.1057812326]
[2019-03-26 19:30:20,117] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:30:20,120] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0775092e-18 1.0000000e+00 2.4424394e-16 2.9684016e-16 1.6461680e-17], sampled 0.5591665890933013
[2019-03-26 19:30:20,121] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2382476.492443391 W.
[2019-03-26 19:30:28,011] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05726479], dtype=float32), 0.06340234]
[2019-03-26 19:30:28,013] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.00011803666667, 76.15922095333333, 1.0, 2.0, 0.5115604397116678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 714831.6696304646, 714831.6696304646, 185426.5997002371]
[2019-03-26 19:30:28,016] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:30:28,019] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.7493001e-20 1.0000000e+00 3.9068329e-17 1.8575773e-17 9.8217679e-19], sampled 0.40299966251858943
[2019-03-26 19:31:02,672] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05726479], dtype=float32), 0.06340234]
[2019-03-26 19:31:02,673] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.2, 59.0, 1.0, 2.0, 0.4378727727129335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 636493.3193609954, 636493.3193609954, 177586.7658467099]
[2019-03-26 19:31:02,675] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:31:02,679] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.7606486e-20 1.0000000e+00 7.4030428e-17 7.6667361e-17 2.5850962e-18], sampled 0.554107006531885
[2019-03-26 19:31:04,275] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05726479], dtype=float32), 0.06340234]
[2019-03-26 19:31:04,277] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.20811737666666, 63.11931239333333, 1.0, 2.0, 0.3484078956830046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 540276.3655134988, 540276.3655134988, 169939.1314423248]
[2019-03-26 19:31:04,277] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:31:04,279] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6799410e-19 1.0000000e+00 1.5941711e-16 1.4748340e-16 5.3496897e-18], sampled 0.43442127570433053
[2019-03-26 19:31:09,190] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.9283 2927337382.1572 1338.0000
[2019-03-26 19:31:09,650] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5144 2842492707.2201 1131.0000
[2019-03-26 19:31:09,721] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2953 3007596012.4260 1766.0000
[2019-03-26 19:31:09,722] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9878 2779156505.7300 933.0000
[2019-03-26 19:31:09,844] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.1591 3164159331.6151 1778.0000
[2019-03-26 19:31:10,861] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 225000, evaluation results [225000.0, 7881.159086882945, 3164159331.61508, 1778.0, 8252.928345183711, 2927337382.157177, 1338.0, 8659.98778398064, 2779156505.7300115, 933.0, 7998.295259250187, 3007596012.4259605, 1766.0, 8497.514395919725, 2842492707.2200756, 1131.0]
[2019-03-26 19:31:14,814] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.5866469e-21 1.0000000e+00 9.8846925e-18 2.7303745e-18 3.8578827e-19], sum to 1.0000
[2019-03-26 19:31:14,825] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7467
[2019-03-26 19:31:14,829] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.51666666666667, 63.66666666666666, 1.0, 2.0, 0.6213822625029956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1013779.672211657, 1013779.672211657, 220151.5694562062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 579000.0000, 
sim time next is 579600.0000, 
raw observation next is [23.5, 64.0, 1.0, 2.0, 0.6167703106639623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1005722.353483141, 1005722.353483141, 219114.3159739852], 
processed observation next is [1.0, 0.7391304347826086, 0.31279620853080575, 0.64, 1.0, 1.0, 0.5382774827276654, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.27936732041198364, 0.27936732041198364, 0.32703629249848537], 
reward next is 0.6730, 
noisyNet noise sample is [array([0.5084616], dtype=float32), 0.5124934]. 
=============================================
[2019-03-26 19:31:17,554] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.5517923e-21 1.0000000e+00 2.3899045e-16 3.9783000e-17 1.3548391e-18], sum to 1.0000
[2019-03-26 19:31:17,562] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7239
[2019-03-26 19:31:17,569] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.15, 72.5, 1.0, 2.0, 0.24277941807949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 400902.2784614968, 400902.2784614962, 160151.2920609879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 589800.0000, 
sim time next is 590400.0000, 
raw observation next is [21.0, 73.0, 1.0, 2.0, 0.2414860320580799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 399087.1499936656, 399087.1499936663, 160008.93160913], 
processed observation next is [1.0, 0.8695652173913043, 0.19431279620853087, 0.73, 1.0, 1.0, 0.08612774946756613, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1108575416649071, 0.1108575416649073, 0.23881930090914924], 
reward next is 0.7612, 
noisyNet noise sample is [array([-0.91351813], dtype=float32), -0.32840994]. 
=============================================
[2019-03-26 19:31:23,834] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0427359e-18 1.0000000e+00 5.3500830e-16 3.4013553e-16 4.0875997e-17], sum to 1.0000
[2019-03-26 19:31:23,845] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0999
[2019-03-26 19:31:23,852] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.6, 92.16666666666667, 1.0, 2.0, 0.2156493060691995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 359411.5057573406, 359411.5057573401, 157168.2631591955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 705000.0000, 
sim time next is 705600.0000, 
raw observation next is [17.6, 92.0, 1.0, 2.0, 0.2149129967709744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 358225.1785073982, 358225.1785073988, 157091.67273694], 
processed observation next is [1.0, 0.17391304347826086, 0.0331753554502371, 0.92, 1.0, 1.0, 0.05411204430237877, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.09950699402983283, 0.099506994029833, 0.2344651831894627], 
reward next is 0.7655, 
noisyNet noise sample is [array([-0.16942893], dtype=float32), -0.596907]. 
=============================================
[2019-03-26 19:31:33,265] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3487866e-19 1.0000000e+00 1.1337625e-15 5.8143539e-16 3.5783072e-17], sum to 1.0000
[2019-03-26 19:31:33,280] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7384
[2019-03-26 19:31:33,285] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.95, 88.5, 1.0, 2.0, 0.2873202962730949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 461280.7366350644, 461280.7366350638, 164354.9904660491], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 876600.0000, 
sim time next is 877200.0000, 
raw observation next is [20.93333333333333, 88.33333333333334, 1.0, 2.0, 0.2867807129147474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 460748.844830786, 460748.844830786, 164320.6354003196], 
processed observation next is [0.0, 0.13043478260869565, 0.19115323854660338, 0.8833333333333334, 1.0, 1.0, 0.14069965411415347, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1279857902307739, 0.1279857902307739, 0.24525467970196954], 
reward next is 0.7547, 
noisyNet noise sample is [array([-0.05481883], dtype=float32), 0.2557316]. 
=============================================
[2019-03-26 19:31:34,628] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0330099e-18 1.0000000e+00 7.0215341e-16 6.7240112e-16 2.3823576e-17], sum to 1.0000
[2019-03-26 19:31:34,635] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1311
[2019-03-26 19:31:34,641] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 81.0, 1.0, 2.0, 0.2831950774689267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 454999.5074738975, 454999.5074738968, 163930.182327815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 889200.0000, 
sim time next is 889800.0000, 
raw observation next is [22.0, 80.66666666666667, 1.0, 2.0, 0.2841501866107968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 456166.4625647859, 456166.4625647865, 164006.5777040067], 
processed observation next is [0.0, 0.30434782608695654, 0.2417061611374408, 0.8066666666666668, 1.0, 1.0, 0.13753034531421296, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12671290626799608, 0.12671290626799625, 0.2447859368716518], 
reward next is 0.7552, 
noisyNet noise sample is [array([0.5674117], dtype=float32), -0.60158616]. 
=============================================
[2019-03-26 19:31:36,269] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9362036e-21 1.0000000e+00 5.4362575e-18 1.3165508e-18 6.0116004e-20], sum to 1.0000
[2019-03-26 19:31:36,280] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2334
[2019-03-26 19:31:36,286] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 91.0, 1.0, 2.0, 0.339550640762631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 525660.1717307077, 525660.1717307077, 168732.1414536615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 942000.0000, 
sim time next is 942600.0000, 
raw observation next is [22.15, 91.5, 1.0, 2.0, 0.3404024194911415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 526792.0208482681, 526792.0208482675, 168817.1136385364], 
processed observation next is [0.0, 0.9130434782608695, 0.24881516587677724, 0.915, 1.0, 1.0, 0.20530411986884514, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1463311169022967, 0.14633111690229653, 0.25196584125154686], 
reward next is 0.7480, 
noisyNet noise sample is [array([-0.7987525], dtype=float32), 1.0649877]. 
=============================================
[2019-03-26 19:31:40,060] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2621307e-19 1.0000000e+00 1.8264855e-16 1.0561616e-16 1.5871671e-18], sum to 1.0000
[2019-03-26 19:31:40,070] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9322
[2019-03-26 19:31:40,077] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.75, 95.16666666666667, 1.0, 2.0, 0.2720137407407139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 440269.0698627054, 440269.0698627054, 162954.1796970875], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1141800.0000, 
sim time next is 1142400.0000, 
raw observation next is [19.9, 94.33333333333333, 1.0, 2.0, 0.2725155493758764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 440664.0383251179, 440664.0383251173, 162982.4112130433], 
processed observation next is [1.0, 0.21739130434782608, 0.14218009478672985, 0.9433333333333332, 1.0, 1.0, 0.12351271009141736, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12240667731253276, 0.12240667731253259, 0.24325733016872134], 
reward next is 0.7567, 
noisyNet noise sample is [array([-1.3382695], dtype=float32), -1.7171097]. 
=============================================
[2019-03-26 19:31:40,769] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.0080115e-21 1.0000000e+00 2.4472025e-18 8.7766163e-18 9.4590539e-20], sum to 1.0000
[2019-03-26 19:31:40,773] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3120
[2019-03-26 19:31:40,780] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.654795584693358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1008446.270262785, 1008446.270262785, 222905.818017141], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 987000.0000, 
sim time next is 987600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.584112130816609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 899525.1845637473, 899525.1845637478, 207878.2152914389], 
processed observation next is [1.0, 0.43478260869565216, 0.2417061611374408, 0.94, 1.0, 1.0, 0.4989302780922999, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24986810682326313, 0.2498681068232633, 0.31026599297229684], 
reward next is 0.6897, 
noisyNet noise sample is [array([-0.7871728], dtype=float32), -0.29447854]. 
=============================================
[2019-03-26 19:31:41,087] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.0595503e-22 1.0000000e+00 1.0828707e-17 2.2228282e-19 4.2712948e-20], sum to 1.0000
[2019-03-26 19:31:41,098] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4474
[2019-03-26 19:31:41,104] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.76666666666667, 95.0, 1.0, 2.0, 0.4490403868515986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 693652.4545397687, 693652.4545397687, 183952.0066599745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 996000.0000, 
sim time next is 996600.0000, 
raw observation next is [21.73333333333333, 95.0, 1.0, 2.0, 0.4628382711410866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 715629.8000872062, 715629.8000872068, 186219.443187303], 
processed observation next is [1.0, 0.5217391304347826, 0.22906793048973137, 0.95, 1.0, 1.0, 0.3528171941458875, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1987860555797795, 0.19878605557977966, 0.2779394674437358], 
reward next is 0.7221, 
noisyNet noise sample is [array([0.84134674], dtype=float32), 0.77999574]. 
=============================================
[2019-03-26 19:31:55,339] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.4314637e-20 1.0000000e+00 4.4686102e-16 7.2660888e-17 1.0231394e-17], sum to 1.0000
[2019-03-26 19:31:55,347] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2009
[2019-03-26 19:31:55,350] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.73333333333333, 93.66666666666667, 1.0, 2.0, 0.3438181241893709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 534239.1184354243, 534239.1184354249, 169476.7890487272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1225200.0000, 
sim time next is 1225800.0000, 
raw observation next is [21.7, 94.0, 1.0, 2.0, 0.3523946565407417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 547468.391229226, 547468.3912292254, 170556.3222392198], 
processed observation next is [1.0, 0.17391304347826086, 0.2274881516587678, 0.94, 1.0, 1.0, 0.21975259824185747, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15207455311922946, 0.1520745531192293, 0.25456167498391014], 
reward next is 0.7454, 
noisyNet noise sample is [array([-0.30267206], dtype=float32), 0.35790727]. 
=============================================
[2019-03-26 19:31:56,782] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5678885e-20 1.0000000e+00 1.3476029e-17 3.2116267e-17 2.8358915e-19], sum to 1.0000
[2019-03-26 19:31:56,791] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5369
[2019-03-26 19:31:56,796] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.36666666666667, 72.83333333333333, 1.0, 2.0, 0.9314206446789248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1301885.15650952, 1301885.156509519, 278724.1967324288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1255800.0000, 
sim time next is 1256400.0000, 
raw observation next is [28.4, 73.0, 1.0, 2.0, 1.032628219743363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1443443.342415169, 1443443.34241517, 309022.4345519682], 
processed observation next is [1.0, 0.5652173913043478, 0.5450236966824644, 0.73, 1.0, 1.0, 1.0393111081245336, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.40095648400421363, 0.4009564840042139, 0.4612275142566689], 
reward next is 0.5388, 
noisyNet noise sample is [array([-0.20689884], dtype=float32), -1.7429713]. 
=============================================
[2019-03-26 19:31:58,402] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.8705477e-18 1.0000000e+00 8.5782870e-16 7.9927321e-16 1.2059668e-17], sum to 1.0000
[2019-03-26 19:31:58,414] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6589
[2019-03-26 19:31:58,419] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.65, 76.66666666666667, 1.0, 2.0, 0.4406091687475463, 1.0, 1.0, 0.4406091687475463, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1231667.726072203, 1231667.726072203, 282832.689917264], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1271400.0000, 
sim time next is 1272000.0000, 
raw observation next is [27.5, 77.33333333333334, 1.0, 2.0, 0.4753981256483927, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129560933668, 664284.2702658746, 664284.2702658746, 179831.9851621796], 
processed observation next is [1.0, 0.7391304347826086, 0.5023696682464456, 0.7733333333333334, 1.0, 1.0, 0.36794954897396703, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399431043266, 0.18452340840718737, 0.18452340840718737, 0.2684059480032531], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.30691373], dtype=float32), 0.5996945]. 
=============================================
[2019-03-26 19:31:58,432] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[70.269745]
 [70.24614 ]
 [70.17483 ]
 [70.03086 ]
 [69.551056]], R is [[70.06885529]
 [69.94602203]
 [69.24655914]
 [68.55409241]
 [68.36761475]].
[2019-03-26 19:31:59,828] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.061884e-20 1.000000e+00 4.468593e-16 3.625119e-16 1.034844e-18], sum to 1.0000
[2019-03-26 19:31:59,836] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6678
[2019-03-26 19:31:59,840] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.26666666666667, 92.33333333333334, 1.0, 2.0, 0.4391945585639844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 629226.1205875443, 629226.1205875437, 176621.3329282753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1316400.0000, 
sim time next is 1317000.0000, 
raw observation next is [24.18333333333334, 92.66666666666666, 1.0, 2.0, 0.4364102202341828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 626270.748492715, 626270.748492715, 176357.1436132321], 
processed observation next is [1.0, 0.21739130434782608, 0.3451816745655612, 0.9266666666666665, 1.0, 1.0, 0.3209761689568468, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17396409680353192, 0.17396409680353192, 0.2632196173331822], 
reward next is 0.7368, 
noisyNet noise sample is [array([-0.31390193], dtype=float32), -0.37652412]. 
=============================================
[2019-03-26 19:31:59,859] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[78.62996 ]
 [78.44763 ]
 [78.476265]
 [78.38813 ]
 [78.238205]], R is [[78.57343292]
 [78.524086  ]
 [78.47463989]
 [78.42553711]
 [78.36858368]].
[2019-03-26 19:32:00,846] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.3269810e-21 1.0000000e+00 2.6068241e-17 1.3658611e-18 1.5615644e-19], sum to 1.0000
[2019-03-26 19:32:00,854] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4851
[2019-03-26 19:32:00,864] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.98333333333333, 95.0, 1.0, 2.0, 0.8096201733490408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1202973.091506808, 1202973.091506808, 256087.5527103175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1332600.0000, 
sim time next is 1333200.0000, 
raw observation next is [22.96666666666667, 95.0, 1.0, 2.0, 0.8086954594068322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1202305.55719818, 1202305.55719818, 255934.45372449], 
processed observation next is [1.0, 0.43478260869565216, 0.2875197472353872, 0.95, 1.0, 1.0, 0.7695126016949785, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3339737658883833, 0.3339737658883833, 0.3819917219768508], 
reward next is 0.6180, 
noisyNet noise sample is [array([1.2818943], dtype=float32), 0.7203994]. 
=============================================
[2019-03-26 19:32:02,119] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.2322146e-21 1.0000000e+00 1.0120375e-17 2.8268742e-18 6.4457920e-20], sum to 1.0000
[2019-03-26 19:32:02,127] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5179
[2019-03-26 19:32:02,128] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2785863e-21 1.0000000e+00 1.6556263e-18 3.1047242e-19 4.7303075e-21], sum to 1.0000
[2019-03-26 19:32:02,133] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.36666666666667, 88.66666666666666, 1.0, 2.0, 0.5136073376258888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 817199.162105594, 817199.162105594, 196986.9948725727], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1348800.0000, 
sim time next is 1349400.0000, 
raw observation next is [21.33333333333333, 88.83333333333334, 1.0, 2.0, 0.4991752223904971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 794473.4551694791, 794473.4551694791, 194404.6104285996], 
processed observation next is [1.0, 0.6086956521739131, 0.21011058451816728, 0.8883333333333334, 1.0, 1.0, 0.39659665348252665, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22068707088041087, 0.22068707088041087, 0.29015613496805914], 
reward next is 0.7098, 
noisyNet noise sample is [array([0.4914479], dtype=float32), -1.733854]. 
=============================================
[2019-03-26 19:32:02,138] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8666
[2019-03-26 19:32:02,143] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 90.0, 1.0, 2.0, 0.6095514060263363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 954581.580616492, 954581.5806164913, 214705.5538799792], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1344000.0000, 
sim time next is 1344600.0000, 
raw observation next is [21.75, 89.5, 1.0, 2.0, 0.6325786714045516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 994203.1120139954, 994203.1120139954, 220021.807208456], 
processed observation next is [1.0, 0.5652173913043478, 0.2298578199052133, 0.895, 1.0, 1.0, 0.5573237004874115, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2761675311149987, 0.2761675311149987, 0.3283907570275463], 
reward next is 0.6716, 
noisyNet noise sample is [array([0.57302785], dtype=float32), -2.0380974]. 
=============================================
[2019-03-26 19:32:04,953] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.1691113e-19 1.0000000e+00 3.8384529e-16 3.3662325e-16 1.1850025e-18], sum to 1.0000
[2019-03-26 19:32:04,963] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5417
[2019-03-26 19:32:04,967] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 98.0, 1.0, 2.0, 0.3048391428512721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 485239.5302921806, 485239.53029218, 165995.854233575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1391400.0000, 
sim time next is 1392000.0000, 
raw observation next is [20.26666666666667, 98.0, 1.0, 2.0, 0.3050233257361261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 485352.8525933396, 485352.8525933389, 166001.3273036943], 
processed observation next is [0.0, 0.08695652173913043, 0.15955766192733034, 0.98, 1.0, 1.0, 0.16267870570617604, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13482023683148323, 0.13482023683148303, 0.24776317508014076], 
reward next is 0.7522, 
noisyNet noise sample is [array([0.13817362], dtype=float32), 0.5306325]. 
=============================================
[2019-03-26 19:32:04,979] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[72.044395]
 [72.52961 ]
 [72.84446 ]
 [73.114525]
 [73.44574 ]], R is [[71.56639099]
 [71.60297394]
 [71.63920593]
 [71.67510223]
 [71.71063232]].
[2019-03-26 19:32:06,122] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 19:32:06,124] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:32:06,125] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:32:06,126] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:32:06,126] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:32:06,127] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:32:06,129] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:32:06,128] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:32:06,129] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:32:06,136] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:32:06,138] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:32:06,147] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run11
[2019-03-26 19:32:06,165] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run11
[2019-03-26 19:32:06,181] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run11
[2019-03-26 19:32:06,207] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run11
[2019-03-26 19:32:06,207] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run11
[2019-03-26 19:32:44,355] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05821769], dtype=float32), 0.064525664]
[2019-03-26 19:32:44,356] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.5, 57.33333333333334, 1.0, 2.0, 0.5943041523887254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 830499.2324149717, 830499.2324149717, 199682.9583617348]
[2019-03-26 19:32:44,358] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:32:44,360] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.0438371e-21 1.0000000e+00 8.9397561e-18 8.5367223e-18 2.5326975e-19], sampled 0.8243976773831153
[2019-03-26 19:33:55,919] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05821769], dtype=float32), 0.064525664]
[2019-03-26 19:33:55,920] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.0, 65.5, 1.0, 2.0, 0.4654160733662236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 650501.3002128416, 650501.3002128416, 178376.8866243147]
[2019-03-26 19:33:55,921] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:33:55,926] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.3108407e-20 1.0000000e+00 7.3524683e-17 6.7300129e-17 2.1769607e-18], sampled 0.3171093499069306
[2019-03-26 19:33:59,246] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05821769], dtype=float32), 0.064525664]
[2019-03-26 19:33:59,249] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.33333333333334, 84.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.993677876991796, 6.9112, 168.912365175871, 1512307.438410374, 1453794.998645425, 311352.042452415]
[2019-03-26 19:33:59,250] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:33:59,253] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.1045624e-20 1.0000000e+00 2.0364561e-17 5.8881396e-18 2.0754079e-19], sampled 0.9421611779762993
[2019-03-26 19:34:00,345] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05821769], dtype=float32), 0.064525664]
[2019-03-26 19:34:00,346] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.056659265, 81.76690608999999, 1.0, 2.0, 0.4339676225198464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 616402.9106068049, 616402.9106068056, 175198.3106287947]
[2019-03-26 19:34:00,347] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:34:00,349] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.0170378e-20 1.0000000e+00 4.7240774e-17 2.7766971e-17 5.6455263e-19], sampled 0.9522604614045115
[2019-03-26 19:34:01,163] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7281 2779199535.5119 933.0000
[2019-03-26 19:34:01,221] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6842 2927326903.3807 1338.0000
[2019-03-26 19:34:01,295] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1685 3164067279.4129 1778.0000
[2019-03-26 19:34:01,548] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 19:34:01,574] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2722 3007609378.0304 1766.0000
[2019-03-26 19:34:02,589] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 250000, evaluation results [250000.0, 7884.168455680242, 3164067279.4128904, 1778.0, 8253.684241790532, 2927326903.3806534, 1338.0, 8660.728066421085, 2779199535.5119066, 933.0, 7998.272155887525, 3007609378.0303907, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 19:34:24,020] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0958503e-21 1.0000000e+00 6.2890161e-18 5.1139650e-19 5.4285841e-20], sum to 1.0000
[2019-03-26 19:34:24,024] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5716
[2019-03-26 19:34:24,030] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 92.33333333333334, 1.0, 2.0, 0.611183759918883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 970856.4212880665, 970856.4212880665, 216282.768564925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1782600.0000, 
sim time next is 1783200.0000, 
raw observation next is [21.0, 92.66666666666667, 1.0, 2.0, 0.5659994561674413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 898306.8904581534, 898306.8904581541, 206835.93483588], 
processed observation next is [1.0, 0.6521739130434783, 0.19431279620853087, 0.9266666666666667, 1.0, 1.0, 0.4771077785149895, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2495296917939315, 0.2495296917939317, 0.30871035050131346], 
reward next is 0.6913, 
noisyNet noise sample is [array([1.2387744], dtype=float32), -1.5983953]. 
=============================================
[2019-03-26 19:34:26,794] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5657202e-21 1.0000000e+00 5.2565312e-19 6.0787782e-19 1.6659904e-19], sum to 1.0000
[2019-03-26 19:34:26,802] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1238
[2019-03-26 19:34:26,807] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 85.0, 1.0, 2.0, 0.7470040219412213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1043991.693378904, 1043991.693378904, 231315.5883646931], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1861200.0000, 
sim time next is 1861800.0000, 
raw observation next is [26.6, 84.66666666666667, 1.0, 2.0, 0.6201111546737215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 866577.4575470068, 866577.4575470068, 204544.0130438161], 
processed observation next is [1.0, 0.5652173913043478, 0.4597156398104266, 0.8466666666666667, 1.0, 1.0, 0.5423025959924355, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2407159604297241, 0.2407159604297241, 0.30528957170718823], 
reward next is 0.6947, 
noisyNet noise sample is [array([0.9471784], dtype=float32), -0.9606523]. 
=============================================
[2019-03-26 19:34:27,625] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.3741679e-20 1.0000000e+00 3.7688781e-17 4.2151989e-17 1.3003038e-19], sum to 1.0000
[2019-03-26 19:34:27,639] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5893
[2019-03-26 19:34:27,646] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 90.33333333333333, 1.0, 2.0, 0.5678133717221682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 834684.7240467081, 834684.7240467088, 200096.5005454881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1843800.0000, 
sim time next is 1844400.0000, 
raw observation next is [23.9, 90.66666666666667, 1.0, 2.0, 0.7640117855382538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1121185.983993121, 1121185.983993122, 242503.4252908333], 
processed observation next is [1.0, 0.34782608695652173, 0.33175355450236965, 0.9066666666666667, 1.0, 1.0, 0.7156768500460888, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31144055110920027, 0.31144055110920055, 0.36194541088184073], 
reward next is 0.6381, 
noisyNet noise sample is [array([-0.06101565], dtype=float32), 1.8971374]. 
=============================================
[2019-03-26 19:34:27,797] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.4420346e-21 1.0000000e+00 2.9870974e-17 3.1876550e-17 1.1283840e-19], sum to 1.0000
[2019-03-26 19:34:27,813] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6062
[2019-03-26 19:34:27,822] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 90.0, 1.0, 2.0, 0.8642812292572144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1238442.543499014, 1238442.543499014, 264706.07610416], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1850400.0000, 
sim time next is 1851000.0000, 
raw observation next is [24.71666666666667, 89.66666666666667, 1.0, 2.0, 0.8951863576699861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1278924.57930032, 1278924.57930032, 272699.238558078], 
processed observation next is [1.0, 0.43478260869565216, 0.3704581358609796, 0.8966666666666667, 1.0, 1.0, 0.8737185032168507, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.35525682758342225, 0.35525682758342225, 0.40701378889265377], 
reward next is 0.5930, 
noisyNet noise sample is [array([2.1923866], dtype=float32), 0.8849386]. 
=============================================
[2019-03-26 19:34:27,834] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[77.23597 ]
 [76.9134  ]
 [76.56139 ]
 [76.17368 ]
 [75.790565]], R is [[77.46572876]
 [77.29598999]
 [77.11753082]
 [76.94432831]
 [76.77770233]].
[2019-03-26 19:34:34,277] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.50333515e-18 1.00000000e+00 1.10178912e-15 7.08754607e-16
 1.14101575e-17], sum to 1.0000
[2019-03-26 19:34:34,285] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0765
[2019-03-26 19:34:34,296] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1662821.938215124 W.
[2019-03-26 19:34:34,301] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.1, 76.0, 1.0, 2.0, 0.3964853707772497, 1.0, 2.0, 0.3964853707772497, 1.0, 2.0, 0.6661361602172641, 6.911200000000001, 6.9112, 170.5573041426782, 1662821.938215124, 1662821.938215123, 347760.9731873994], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1953000.0000, 
sim time next is 1953600.0000, 
raw observation next is [26.93333333333334, 76.66666666666667, 1.0, 2.0, 0.5923556269725265, 1.0, 2.0, 0.5923556269725265, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1656183.651015681, 1656183.651015681, 331432.6097315156], 
processed observation next is [1.0, 0.6086956521739131, 0.4755134281200636, 0.7666666666666667, 1.0, 1.0, 0.5088622011717187, 1.0, 1.0, 0.5088622011717187, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4600510141710225, 0.4600510141710225, 0.4946755369127098], 
reward next is 0.5053, 
noisyNet noise sample is [array([0.24482568], dtype=float32), 0.2697847]. 
=============================================
[2019-03-26 19:34:40,263] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4150176e-21 1.0000000e+00 2.5541505e-18 8.0590693e-18 8.3398514e-20], sum to 1.0000
[2019-03-26 19:34:40,273] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1468
[2019-03-26 19:34:40,282] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.95, 84.66666666666667, 1.0, 2.0, 0.5084988919999548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 710552.1690202173, 710552.1690202173, 184938.6034889804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2044200.0000, 
sim time next is 2044800.0000, 
raw observation next is [26.9, 85.0, 1.0, 2.0, 0.5087270310955853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 710871.0664116039, 710871.0664116046, 184974.9145333862], 
processed observation next is [0.0, 0.6956521739130435, 0.4739336492890995, 0.85, 1.0, 1.0, 0.40810485674166896, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19746418511433442, 0.1974641851143346, 0.2760819619901287], 
reward next is 0.7239, 
noisyNet noise sample is [array([-0.68225527], dtype=float32), -0.26687625]. 
=============================================
[2019-03-26 19:34:41,173] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.5076123e-22 1.0000000e+00 3.9618357e-18 1.3971593e-17 2.7292886e-20], sum to 1.0000
[2019-03-26 19:34:41,180] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4431
[2019-03-26 19:34:41,186] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.35, 89.33333333333334, 1.0, 2.0, 0.4770284952411142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 666563.1363382066, 666563.1363382066, 180075.0003259419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2059800.0000, 
sim time next is 2060400.0000, 
raw observation next is [25.3, 89.66666666666667, 1.0, 2.0, 0.4766639897089207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 666053.644511222, 666053.6445112227, 180020.40054449], 
processed observation next is [0.0, 0.8695652173913043, 0.39810426540284366, 0.8966666666666667, 1.0, 1.0, 0.36947468639629005, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18501490125311723, 0.18501490125311743, 0.26868716499177614], 
reward next is 0.7313, 
noisyNet noise sample is [array([-0.82921803], dtype=float32), 0.49531347]. 
=============================================
[2019-03-26 19:34:52,960] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.4608855e-20 1.0000000e+00 2.7131834e-16 2.7779154e-17 1.0490614e-18], sum to 1.0000
[2019-03-26 19:34:52,965] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6284
[2019-03-26 19:34:52,973] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.03333333333333, 86.33333333333334, 1.0, 2.0, 0.5980096843371455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 835679.4958897944, 835679.4958897944, 200367.9193378125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2265600.0000, 
sim time next is 2266200.0000, 
raw observation next is [26.2, 85.5, 1.0, 2.0, 0.5981101342203867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 835819.9232756051, 835819.9232756051, 200386.6752005977], 
processed observation next is [1.0, 0.21739130434782608, 0.44075829383886256, 0.855, 1.0, 1.0, 0.5157953424342009, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2321722009098903, 0.2321722009098903, 0.2990845898516384], 
reward next is 0.7009, 
noisyNet noise sample is [array([-1.1501998], dtype=float32), 0.4494852]. 
=============================================
[2019-03-26 19:34:54,746] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1056247e-15 1.0000000e+00 8.0773983e-14 1.8049680e-13 2.1348659e-15], sum to 1.0000
[2019-03-26 19:34:54,753] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3379
[2019-03-26 19:34:54,757] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2381646.453860939 W.
[2019-03-26 19:34:54,762] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 65.0, 1.0, 2.0, 0.5676988821021404, 1.0, 2.0, 0.5676988821021404, 1.0, 2.0, 0.9859052173222578, 6.9112, 6.9112, 170.5573041426782, 2381646.453860939, 2381646.453860939, 465117.5525601819], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2300400.0000, 
sim time next is 2301000.0000, 
raw observation next is [32.03333333333333, 64.83333333333334, 1.0, 2.0, 0.8606082591048019, 1.0, 2.0, 0.8606082591048019, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2407010.070928698, 2407010.070928699, 450457.6015973101], 
processed observation next is [1.0, 0.6521739130434783, 0.7172195892575038, 0.6483333333333334, 1.0, 1.0, 0.8320581434997613, 1.0, 1.0, 0.8320581434997613, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.668613908591305, 0.6686139085913052, 0.672324778503448], 
reward next is 0.3277, 
noisyNet noise sample is [array([-1.0314589], dtype=float32), 0.3376352]. 
=============================================
[2019-03-26 19:34:54,777] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[61.398853]
 [62.19104 ]
 [62.540577]
 [63.09732 ]
 [63.631775]], R is [[61.23053741]
 [60.92402649]
 [60.63120651]
 [60.02489471]
 [59.42464447]].
[2019-03-26 19:34:57,843] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 19:34:57,847] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:34:57,849] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:34:57,849] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:34:57,851] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:34:57,851] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:34:57,852] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:34:57,854] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:34:57,855] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:34:57,855] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:34:57,858] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:34:57,875] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run12
[2019-03-26 19:34:57,894] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run12
[2019-03-26 19:34:57,915] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run12
[2019-03-26 19:34:57,930] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run12
[2019-03-26 19:34:57,931] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run12
[2019-03-26 19:35:00,030] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05565601], dtype=float32), 0.061977856]
[2019-03-26 19:35:00,031] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.8, 82.0, 1.0, 2.0, 0.4163172136686517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 616608.3979270809, 616608.3979270816, 175962.1403774745]
[2019-03-26 19:35:00,033] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:35:00,036] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.1823234e-20 1.0000000e+00 3.8596972e-17 5.0272583e-17 1.7317752e-18], sampled 0.059980721712797
[2019-03-26 19:35:01,341] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05565601], dtype=float32), 0.061977856]
[2019-03-26 19:35:01,343] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [19.96666666666667, 96.0, 1.0, 2.0, 0.2910544883419042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 468160.597263258, 468160.5972632574, 164832.3844922244]
[2019-03-26 19:35:01,345] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:35:01,347] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.6547113e-18 1.0000000e+00 1.7731029e-15 1.6565133e-15 5.2077174e-17], sampled 0.4060135383449226
[2019-03-26 19:35:07,080] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05565601], dtype=float32), 0.061977856]
[2019-03-26 19:35:07,083] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.0, 56.5, 1.0, 2.0, 0.357109564917917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 580831.5348488641, 580831.5348488634, 173322.6289214375]
[2019-03-26 19:35:07,084] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:35:07,085] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.4485270e-18 1.0000000e+00 2.9383001e-15 2.0762912e-15 9.6074778e-17], sampled 0.3799731165423508
[2019-03-26 19:35:09,936] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05565601], dtype=float32), 0.061977856]
[2019-03-26 19:35:09,937] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.24178641, 53.21195722333334, 1.0, 2.0, 0.3741693323109748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 618906.8797173386, 618906.8797173379, 175714.0275936339]
[2019-03-26 19:35:09,939] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:35:09,941] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6202131e-18 1.0000000e+00 1.0225162e-15 7.7307622e-16 3.3821787e-17], sampled 0.4118326433601297
[2019-03-26 19:35:54,881] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05565601], dtype=float32), 0.061977856]
[2019-03-26 19:35:54,882] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.33333333333334, 85.66666666666666, 1.0, 2.0, 0.5282946385323052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 738223.4157592438, 738223.4157592432, 188148.2279317458]
[2019-03-26 19:35:54,883] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:35:54,885] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.9756521e-19 1.0000000e+00 1.7417014e-16 1.8646992e-16 5.5604847e-18], sampled 0.04937760168495264
[2019-03-26 19:36:44,313] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05565601], dtype=float32), 0.061977856]
[2019-03-26 19:36:44,314] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.65, 81.83333333333334, 1.0, 2.0, 0.6037929218037543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 843764.4028106617, 843764.4028106623, 201453.9809418314]
[2019-03-26 19:36:44,316] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:36:44,318] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.3974059e-21 1.0000000e+00 7.8766768e-18 8.6957345e-18 2.0048360e-19], sampled 0.3394205432443518
[2019-03-26 19:36:51,919] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05565601], dtype=float32), 0.061977856]
[2019-03-26 19:36:51,919] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.91666666666666, 67.0, 1.0, 2.0, 0.3268105292460267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 514972.8561502189, 514972.8561502189, 168127.5863236523]
[2019-03-26 19:36:51,920] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:36:51,925] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.1019238e-19 1.0000000e+00 1.6235433e-16 1.7661084e-16 5.8258264e-18], sampled 0.11475686025984289
[2019-03-26 19:36:52,938] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 19:36:52,972] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.7746 2842563444.1824 1131.0000
[2019-03-26 19:36:53,015] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 19:36:53,046] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 19:36:53,050] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 19:36:54,063] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 275000, evaluation results [275000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8496.774567725599, 2842563444.1823883, 1131.0]
[2019-03-26 19:36:54,199] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.3601601e-20 1.0000000e+00 1.5895915e-17 3.0282846e-18 1.2769262e-18], sum to 1.0000
[2019-03-26 19:36:54,206] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1921
[2019-03-26 19:36:54,211] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.13333333333333, 82.0, 1.0, 2.0, 0.6682611215593884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 933894.4548958407, 933894.4548958407, 214141.528037051], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2350200.0000, 
sim time next is 2350800.0000, 
raw observation next is [27.1, 82.0, 1.0, 2.0, 0.6234163866440692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 871198.2649760069, 871198.2649760064, 205181.0847337015], 
processed observation next is [1.0, 0.21739130434782608, 0.4834123222748816, 0.82, 1.0, 1.0, 0.5462848031856254, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2419995180488908, 0.24199951804889067, 0.3062404249756739], 
reward next is 0.6938, 
noisyNet noise sample is [array([1.2029525], dtype=float32), -0.98295987]. 
=============================================
[2019-03-26 19:36:54,641] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.3270681e-21 1.0000000e+00 5.3956217e-17 7.6841233e-18 1.6676308e-19], sum to 1.0000
[2019-03-26 19:36:54,650] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3224
[2019-03-26 19:36:54,658] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.03333333333333, 78.33333333333334, 1.0, 2.0, 0.7347836663053045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1026904.612226668, 1026904.612226668, 228531.0034874748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2355000.0000, 
sim time next is 2355600.0000, 
raw observation next is [28.16666666666667, 77.66666666666667, 1.0, 2.0, 0.7111225497767187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 993821.2977888229, 993821.2977888235, 223263.03256951], 
processed observation next is [1.0, 0.2608695652173913, 0.5339652448657191, 0.7766666666666667, 1.0, 1.0, 0.6519548792490587, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.27606147160800637, 0.27606147160800654, 0.33322840682016414], 
reward next is 0.6668, 
noisyNet noise sample is [array([0.03453844], dtype=float32), -1.108984]. 
=============================================
[2019-03-26 19:37:13,482] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2703039e-19 1.0000000e+00 1.1980434e-17 4.0467337e-17 3.5261786e-17], sum to 1.0000
[2019-03-26 19:37:13,488] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2558
[2019-03-26 19:37:13,493] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 96.0, 1.0, 2.0, 0.4352432743349033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 627590.2333733159, 627590.2333733152, 176570.8904051139], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2684400.0000, 
sim time next is 2685000.0000, 
raw observation next is [23.83333333333333, 95.0, 1.0, 2.0, 0.4375903340815071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 629907.8198955805, 629907.8198955805, 176771.0168835794], 
processed observation next is [0.0, 0.043478260869565216, 0.32859399684044216, 0.95, 1.0, 1.0, 0.3223979928692857, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17497439441543902, 0.17497439441543902, 0.26383733863220804], 
reward next is 0.7362, 
noisyNet noise sample is [array([-1.1322559], dtype=float32), -0.48777217]. 
=============================================
[2019-03-26 19:37:13,515] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[69.20823 ]
 [69.48181 ]
 [69.712456]
 [69.97972 ]
 [70.33451 ]], R is [[68.99178314]
 [69.03832245]
 [69.08460999]
 [69.13072968]
 [69.17677307]].
[2019-03-26 19:37:18,652] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3569176e-19 1.0000000e+00 1.3614469e-15 1.4854434e-16 2.1023589e-17], sum to 1.0000
[2019-03-26 19:37:18,664] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4109
[2019-03-26 19:37:18,672] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.337116271885331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 520451.6342583667, 520451.6342583673, 168272.3744305947], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2776800.0000, 
sim time next is 2777400.0000, 
raw observation next is [21.5, 97.0, 1.0, 2.0, 0.3334609077491934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515505.4628424659, 515505.4628424659, 167904.5039443714], 
processed observation next is [1.0, 0.13043478260869565, 0.21800947867298584, 0.97, 1.0, 1.0, 0.19694085270987158, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14319596190068498, 0.14319596190068498, 0.2506037372304051], 
reward next is 0.7494, 
noisyNet noise sample is [array([-2.3153107], dtype=float32), 0.6305576]. 
=============================================
[2019-03-26 19:37:20,992] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.0096852e-21 1.0000000e+00 6.3695878e-17 6.0238217e-17 1.2988172e-18], sum to 1.0000
[2019-03-26 19:37:21,000] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4762
[2019-03-26 19:37:21,010] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 83.0, 1.0, 2.0, 0.699917861205047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1067141.025263553, 1067141.025263553, 232137.4131958989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2807400.0000, 
sim time next is 2808000.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.6020702654444282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 913311.9876172242, 913311.9876172242, 210017.3544686618], 
processed observation next is [1.0, 0.5217391304347826, 0.3364928909952607, 0.83, 1.0, 1.0, 0.520566584872805, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.25369777433811785, 0.25369777433811785, 0.31345873801292806], 
reward next is 0.6865, 
noisyNet noise sample is [array([0.16441992], dtype=float32), 0.4460625]. 
=============================================
[2019-03-26 19:37:21,025] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[75.8404 ]
 [75.53222]
 [75.25926]
 [75.02702]
 [74.77564]], R is [[75.96512604]
 [75.85900116]
 [75.76337433]
 [75.68759155]
 [75.61869812]].
[2019-03-26 19:37:26,624] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.3802461e-21 1.0000000e+00 1.0570070e-18 1.3077462e-18 1.4329610e-19], sum to 1.0000
[2019-03-26 19:37:26,626] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8761
[2019-03-26 19:37:26,631] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 99.0, 1.0, 2.0, 0.3441424890590314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 533493.0394974338, 533493.0394974338, 169382.653889772], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2915400.0000, 
sim time next is 2916000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.3444608833846927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 534749.1700828595, 534749.1700828589, 169505.0779180692], 
processed observation next is [1.0, 0.782608695652174, 0.19431279620853087, 1.0, 1.0, 1.0, 0.21019383540324424, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14854143613412762, 0.14854143613412746, 0.25299265360905854], 
reward next is 0.7470, 
noisyNet noise sample is [array([-0.9671485], dtype=float32), -0.6702006]. 
=============================================
[2019-03-26 19:37:26,656] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[79.13316 ]
 [79.23313 ]
 [79.23019 ]
 [79.34591 ]
 [79.383896]], R is [[79.02643585]
 [78.98336792]
 [78.94070435]
 [78.89836884]
 [78.85572815]].
[2019-03-26 19:37:26,933] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1740567e-22 1.0000000e+00 2.8807371e-19 1.1706295e-18 4.3866337e-21], sum to 1.0000
[2019-03-26 19:37:26,941] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7960
[2019-03-26 19:37:26,944] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.8386034150715587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1216916.286248577, 1216916.286248577, 259959.349771019], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3078000.0000, 
sim time next is 3078600.0000, 
raw observation next is [23.16666666666667, 99.00000000000001, 1.0, 2.0, 0.7888085287301458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1143192.121185025, 1143192.121185024, 246814.0474492084], 
processed observation next is [1.0, 0.6521739130434783, 0.2969984202211693, 0.9900000000000001, 1.0, 1.0, 0.7455524442531878, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31755336699584025, 0.31755336699584, 0.36837917529732594], 
reward next is 0.6316, 
noisyNet noise sample is [array([-0.5366179], dtype=float32), -0.6612233]. 
=============================================
[2019-03-26 19:37:31,258] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1155587e-19 1.0000000e+00 2.9464349e-17 2.0590233e-17 2.5645569e-19], sum to 1.0000
[2019-03-26 19:37:31,271] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4542
[2019-03-26 19:37:31,280] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3046781921487323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 485182.2398720158, 485182.2398720158, 165994.6212026615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3012600.0000, 
sim time next is 3013200.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3047168758067159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 485243.725406528, 485243.7254065274, 165999.0642198544], 
processed observation next is [1.0, 0.9130434782608695, 0.1469194312796209, 1.0, 1.0, 1.0, 0.1623094889237541, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13478992372403556, 0.1347899237240354, 0.24775979734306625], 
reward next is 0.7522, 
noisyNet noise sample is [array([0.21753184], dtype=float32), 1.323396]. 
=============================================
[2019-03-26 19:37:36,112] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.2527393e-21 1.0000000e+00 1.1230645e-17 1.7094397e-18 6.1361815e-20], sum to 1.0000
[2019-03-26 19:37:36,121] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7250
[2019-03-26 19:37:36,126] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.8214801701034867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1180295.802366947, 1180295.802366947, 253793.5278438263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3081600.0000, 
sim time next is 3082200.0000, 
raw observation next is [23.83333333333333, 95.0, 1.0, 2.0, 0.8370665503745157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1203420.733259079, 1203420.73325908, 257979.0417563959], 
processed observation next is [1.0, 0.6956521739130435, 0.32859399684044216, 0.95, 1.0, 1.0, 0.8036946390054406, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33428353701641084, 0.3342835370164111, 0.3850433459050685], 
reward next is 0.6150, 
noisyNet noise sample is [array([0.5313991], dtype=float32), -1.3131673]. 
=============================================
[2019-03-26 19:37:36,862] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.4140565e-23 1.0000000e+00 1.3332588e-19 2.0368038e-19 3.1231791e-22], sum to 1.0000
[2019-03-26 19:37:36,876] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5958
[2019-03-26 19:37:36,882] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.4221929928478546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 612799.3362681925, 612799.3362681925, 175248.3666270096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3087000.0000, 
sim time next is 3087600.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.4274092874770286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 620381.1581846853, 620381.158184686, 175980.4027678079], 
processed observation next is [1.0, 0.7391304347826086, 0.28909952606635075, 1.0, 1.0, 1.0, 0.31013167165907063, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1723280994957459, 0.1723280994957461, 0.2626573175638924], 
reward next is 0.7373, 
noisyNet noise sample is [array([-0.1100225], dtype=float32), 0.16533302]. 
=============================================
[2019-03-26 19:37:41,741] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.2524473e-22 1.0000000e+00 2.8180025e-18 1.3384777e-18 2.8984716e-20], sum to 1.0000
[2019-03-26 19:37:41,748] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6139
[2019-03-26 19:37:41,751] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1920434.13011275 W.
[2019-03-26 19:37:41,756] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.568582472989275, 6.9112, 168.909338348425, 1920434.13011275, 1454074.368183976, 311348.7219669761], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3169800.0000, 
sim time next is 3170400.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.6083343895578213, 1.0, 1.0, 0.6083343895578213, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1700894.574175727, 1700894.574175727, 337345.1371460482], 
processed observation next is [1.0, 0.6956521739130435, 0.4786729857819906, 0.84, 1.0, 1.0, 0.5281137223588208, 1.0, 0.5, 0.5281137223588208, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4724707150488131, 0.4724707150488131, 0.5035002046955943], 
reward next is 0.4965, 
noisyNet noise sample is [array([-0.04194869], dtype=float32), 0.4392926]. 
=============================================
[2019-03-26 19:37:42,525] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5748380e-20 1.0000000e+00 2.8991506e-17 5.7751778e-18 6.6330765e-19], sum to 1.0000
[2019-03-26 19:37:42,529] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6050
[2019-03-26 19:37:42,537] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1700050.750541642 W.
[2019-03-26 19:37:42,540] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.16666666666667, 84.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.25813918599143, 6.9112, 168.9106585972182, 1700050.750541642, 1453923.499665862, 311346.7066446837], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3165000.0000, 
sim time next is 3165600.0000, 
raw observation next is [26.33333333333334, 84.0, 1.0, 2.0, 0.5498827592089649, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9200576805495063, 6.911199999999999, 6.9112, 168.9126739768374, 1537358.136168443, 1537358.136168444, 329271.8069460293], 
processed observation next is [1.0, 0.6521739130434783, 0.44707740916271754, 0.84, 1.0, 1.0, 0.4576900713361023, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.9025093665237881, -8.881784197001253e-17, 0.0, 0.8294385577830137, 0.42704392671345637, 0.4270439267134567, 0.49145045812840193], 
reward next is 0.5085, 
noisyNet noise sample is [array([-0.32030421], dtype=float32), 1.2456933]. 
=============================================
[2019-03-26 19:37:46,445] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1658517e-19 1.0000000e+00 1.3632026e-16 2.1971610e-16 9.1376624e-18], sum to 1.0000
[2019-03-26 19:37:46,458] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8620
[2019-03-26 19:37:46,462] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 87.33333333333334, 1.0, 2.0, 0.4599948506132508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 648857.8977596752, 648857.8977596757, 178354.138512402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3219600.0000, 
sim time next is 3220200.0000, 
raw observation next is [25.5, 86.5, 1.0, 2.0, 0.4623547181189223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 650751.4531206937, 650751.4531206937, 178515.4787447156], 
processed observation next is [0.0, 0.2608695652173913, 0.40758293838862564, 0.865, 1.0, 1.0, 0.35223460014327995, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18076429253352602, 0.18076429253352602, 0.26644101305181433], 
reward next is 0.7336, 
noisyNet noise sample is [array([-1.7745023], dtype=float32), 1.6533628]. 
=============================================
[2019-03-26 19:37:46,489] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.03374374e-20 1.00000000e+00 1.05124515e-17 2.24702571e-17
 2.69179957e-18], sum to 1.0000
[2019-03-26 19:37:46,500] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2375
[2019-03-26 19:37:46,504] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.0, 63.0, 1.0, 2.0, 0.5753130607095253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 803950.4425160888, 803950.4425160888, 196237.9633904234], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3247200.0000, 
sim time next is 3247800.0000, 
raw observation next is [33.0, 63.0, 1.0, 2.0, 0.5819015969336226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813160.8786120126, 813160.8786120126, 197423.2344444387], 
processed observation next is [0.0, 0.6086956521739131, 0.7630331753554502, 0.63, 1.0, 1.0, 0.49626698425737664, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22587802183667016, 0.22587802183667016, 0.29466154394692345], 
reward next is 0.7053, 
noisyNet noise sample is [array([0.72461444], dtype=float32), 0.71049917]. 
=============================================
[2019-03-26 19:37:49,464] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 19:37:49,466] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:37:49,466] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:37:49,467] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:37:49,467] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:37:49,468] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:37:49,469] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:37:49,470] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:37:49,470] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:37:49,472] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:37:49,474] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:37:49,494] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run13
[2019-03-26 19:37:49,511] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run13
[2019-03-26 19:37:49,530] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run13
[2019-03-26 19:37:49,558] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run13
[2019-03-26 19:37:49,559] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run13
[2019-03-26 19:38:04,748] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05677506], dtype=float32), 0.062971726]
[2019-03-26 19:38:04,750] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.9, 93.0, 1.0, 2.0, 0.3329765268366439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 516161.5966468404, 516161.5966468398, 168000.7902355249]
[2019-03-26 19:38:04,751] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:38:04,753] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.8177672e-18 1.0000000e+00 1.2138789e-15 7.6824025e-16 3.1609546e-17], sampled 0.7210521776488957
[2019-03-26 19:38:20,104] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05677506], dtype=float32), 0.062971726]
[2019-03-26 19:38:20,104] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.30953026333334, 94.16526289666668, 1.0, 2.0, 0.4200472211254917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 620295.5546930638, 620295.5546930633, 176265.0073790366]
[2019-03-26 19:38:20,105] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:38:20,108] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.2230401e-19 1.0000000e+00 1.8442055e-16 1.5241135e-16 5.5729710e-18], sampled 0.3234980312082827
[2019-03-26 19:38:45,226] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05677506], dtype=float32), 0.062971726]
[2019-03-26 19:38:45,229] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.1, 54.0, 1.0, 2.0, 0.8642471573981884, 1.0, 1.0, 0.8642471573981884, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 169.0403247858759, 2417218.423423579, 2417218.423423578, 452079.6584607888]
[2019-03-26 19:38:45,230] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:38:45,232] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.2546587e-20 1.0000000e+00 1.6171575e-17 3.4480048e-17 1.2405887e-18], sampled 0.8091302020540331
[2019-03-26 19:38:45,234] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2417218.423423579 W.
[2019-03-26 19:38:45,783] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05677506], dtype=float32), 0.062971726]
[2019-03-26 19:38:45,787] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [34.17233667333333, 56.94751432666666, 1.0, 2.0, 0.9851741966273223, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9129564413349, 1377067.448142527, 1377067.448142527, 294444.8618396401]
[2019-03-26 19:38:45,787] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:38:45,791] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.4116484e-22 1.0000000e+00 7.8963483e-19 1.0075033e-18 3.3896133e-20], sampled 0.8530482192462642
[2019-03-26 19:38:46,178] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05677506], dtype=float32), 0.062971726]
[2019-03-26 19:38:46,179] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.094697485, 84.43570449, 1.0, 2.0, 0.5797585627165631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 810165.017804742, 810165.017804742, 197033.4505731201]
[2019-03-26 19:38:46,180] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:38:46,182] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.1158874e-21 1.0000000e+00 2.8629912e-18 3.7700986e-18 9.1223287e-20], sampled 0.24194647942990855
[2019-03-26 19:38:55,780] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05677506], dtype=float32), 0.062971726]
[2019-03-26 19:38:55,782] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [34.65165876, 66.8011921, 1.0, 2.0, 0.6810496568129507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 951774.4323940699, 951774.4323940706, 216818.2293686434]
[2019-03-26 19:38:55,782] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:38:55,784] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.040786e-21 1.000000e+00 7.474348e-18 8.996031e-18 2.951021e-19], sampled 0.3445474078480665
[2019-03-26 19:38:57,540] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05677506], dtype=float32), 0.062971726]
[2019-03-26 19:38:57,542] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.78333333333333, 68.5, 1.0, 2.0, 0.6343859703447748, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.964389546319739, 6.9112, 168.9125780837924, 1773809.01730184, 1736074.607038747, 372083.6007143952]
[2019-03-26 19:38:57,543] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:38:57,545] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.0935807e-19 1.0000000e+00 2.2873720e-16 4.1052913e-16 1.7214945e-17], sampled 0.24966808415804154
[2019-03-26 19:38:57,546] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1773809.01730184 W.
[2019-03-26 19:39:00,220] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05677506], dtype=float32), 0.062971726]
[2019-03-26 19:39:00,221] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 79.0, 1.0, 2.0, 0.4846202610063223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 677174.6703606546, 677174.670360654, 181221.2402177604]
[2019-03-26 19:39:00,222] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:39:00,224] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.6521031e-20 1.0000000e+00 6.4764874e-17 7.0088456e-17 2.2612126e-18], sampled 0.6682391806943317
[2019-03-26 19:39:21,669] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05677506], dtype=float32), 0.062971726]
[2019-03-26 19:39:21,670] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.5, 87.66666666666667, 1.0, 2.0, 0.5917484141111213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 826926.3734350005, 826926.3734350012, 199218.1585199925]
[2019-03-26 19:39:21,671] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:39:21,674] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.8171503e-20 1.0000000e+00 2.8587799e-17 3.4088484e-17 9.5451835e-19], sampled 0.7505008964037392
[2019-03-26 19:39:44,408] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.3130 3007656030.3370 1766.0000
[2019-03-26 19:39:44,709] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 19:39:44,789] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0954 2842517464.9746 1131.0000
[2019-03-26 19:39:44,806] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4188 3164139523.4469 1778.0000
[2019-03-26 19:39:44,875] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 19:39:45,889] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 300000, evaluation results [300000.0, 7883.41881391125, 3164139523.4469013, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7998.312951428424, 3007656030.3370423, 1766.0, 8496.095384209508, 2842517464.974608, 1131.0]
[2019-03-26 19:39:54,425] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.0269941e-17 1.0000000e+00 2.0713151e-15 2.1653190e-15 2.3970813e-16], sum to 1.0000
[2019-03-26 19:39:54,433] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0149
[2019-03-26 19:39:54,439] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.5, 65.0, 1.0, 2.0, 0.5474955680421482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 765063.8933554917, 765063.8933554917, 191375.1170108264], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3605400.0000, 
sim time next is 3606000.0000, 
raw observation next is [32.33333333333334, 65.66666666666667, 1.0, 2.0, 0.5568726483659189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 778172.1153874714, 778172.1153874714, 192988.5860635341], 
processed observation next is [1.0, 0.7391304347826086, 0.7314375987361774, 0.6566666666666667, 1.0, 1.0, 0.46611162453725163, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21615892094096428, 0.21615892094096428, 0.2880426657664688], 
reward next is 0.7120, 
noisyNet noise sample is [array([0.7817407], dtype=float32), 0.00749091]. 
=============================================
[2019-03-26 19:39:54,456] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[64.25863 ]
 [64.67958 ]
 [62.579853]
 [62.24084 ]
 [61.789604]], R is [[66.74385834]
 [66.79078674]
 [66.83627319]
 [66.75748444]
 [66.34304047]].
[2019-03-26 19:39:56,787] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.7004780e-19 1.0000000e+00 1.3688089e-17 9.0897944e-17 2.3692694e-18], sum to 1.0000
[2019-03-26 19:39:56,798] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5198
[2019-03-26 19:39:56,806] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1970296.43106178 W.
[2019-03-26 19:39:56,813] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.33333333333334, 68.66666666666667, 1.0, 2.0, 0.704598951313661, 1.0, 2.0, 0.704598951313661, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1970296.43106178, 1970296.43106178, 376091.6380241393], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3487200.0000, 
sim time next is 3487800.0000, 
raw observation next is [29.66666666666666, 67.33333333333333, 1.0, 2.0, 0.714342793359177, 1.0, 2.0, 0.714342793359177, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1997568.903432091, 1997568.90343209, 380317.5903818132], 
processed observation next is [1.0, 0.34782608695652173, 0.6050552922590835, 0.6733333333333333, 1.0, 1.0, 0.6558346907941892, 1.0, 1.0, 0.6558346907941892, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5548802509533586, 0.5548802509533584, 0.5676381945997212], 
reward next is 0.4324, 
noisyNet noise sample is [array([0.9737801], dtype=float32), -0.259037]. 
=============================================
[2019-03-26 19:40:03,991] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0440601e-17 1.0000000e+00 3.7321275e-15 4.9304788e-15 1.6301029e-16], sum to 1.0000
[2019-03-26 19:40:03,999] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8042
[2019-03-26 19:40:04,006] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333334, 66.83333333333334, 1.0, 2.0, 0.5675168131537903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 793051.7910204724, 793051.791020473, 194851.0513613692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3607800.0000, 
sim time next is 3608400.0000, 
raw observation next is [31.66666666666667, 66.66666666666667, 1.0, 2.0, 0.5594867318126384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 781826.3718749982, 781826.3718749982, 193441.8728858562], 
processed observation next is [1.0, 0.782608695652174, 0.6998420221169038, 0.6666666666666667, 1.0, 1.0, 0.46926112266582937, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2171739921874995, 0.2171739921874995, 0.2887192132624719], 
reward next is 0.7113, 
noisyNet noise sample is [array([0.20898713], dtype=float32), 1.9243644]. 
=============================================
[2019-03-26 19:40:06,467] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3144524e-19 1.0000000e+00 8.7596336e-16 1.4949594e-16 1.1368095e-18], sum to 1.0000
[2019-03-26 19:40:06,475] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8742
[2019-03-26 19:40:06,479] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.7243636465149337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1012335.063248648, 1012335.063248648, 226188.5617082594], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3642000.0000, 
sim time next is 3642600.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.7028789668046981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 982295.2432512394, 982295.24325124, 221464.4733701137], 
processed observation next is [1.0, 0.13043478260869565, 0.4786729857819906, 0.79, 1.0, 1.0, 0.6420228515719254, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.272859789792011, 0.2728597897920111, 0.3305439901046473], 
reward next is 0.6695, 
noisyNet noise sample is [array([-0.61972743], dtype=float32), 1.4581832]. 
=============================================
[2019-03-26 19:40:10,974] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.6877513e-20 1.0000000e+00 2.5325854e-16 1.8367213e-16 2.9715481e-18], sum to 1.0000
[2019-03-26 19:40:10,985] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9582
[2019-03-26 19:40:10,995] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.83333333333334, 1.0, 2.0, 0.4655929563119225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 660767.0441381582, 660767.0441381582, 179691.3630170218], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3718200.0000, 
sim time next is 3718800.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.4579791345538589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 653507.9042580575, 653507.9042580575, 179018.0397899096], 
processed observation next is [1.0, 0.043478260869565216, 0.4786729857819906, 0.74, 1.0, 1.0, 0.3469628127154927, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18152997340501598, 0.18152997340501598, 0.2671911041640442], 
reward next is 0.7328, 
noisyNet noise sample is [array([-0.9167766], dtype=float32), -0.40593034]. 
=============================================
[2019-03-26 19:40:13,843] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.3592749e-16 1.0000000e+00 6.5130410e-14 6.8715758e-14 2.9816472e-15], sum to 1.0000
[2019-03-26 19:40:13,852] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5430
[2019-03-26 19:40:13,863] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2668754.120072258 W.
[2019-03-26 19:40:13,868] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.16666666666667, 60.0, 1.0, 2.0, 0.9540930288506443, 1.0, 2.0, 0.9540930288506443, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2668754.120072258, 2668754.120072259, 501868.3568129042], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3768600.0000, 
sim time next is 3769200.0000, 
raw observation next is [34.0, 60.0, 1.0, 2.0, 0.9060309752979046, 1.0, 2.0, 0.9060309752979046, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2534180.362660288, 2534180.362660288, 474798.8446431714], 
processed observation next is [1.0, 0.6521739130434783, 0.8104265402843602, 0.6, 1.0, 1.0, 0.8867843075878368, 1.0, 1.0, 0.8867843075878368, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7039389896278577, 0.7039389896278577, 0.7086549920047335], 
reward next is 0.2913, 
noisyNet noise sample is [array([1.9714502], dtype=float32), -1.665355]. 
=============================================
[2019-03-26 19:40:28,636] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9156378e-16 1.0000000e+00 9.5474962e-15 1.0974188e-14 4.3866807e-15], sum to 1.0000
[2019-03-26 19:40:28,645] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3956
[2019-03-26 19:40:28,656] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2469600.841162183 W.
[2019-03-26 19:40:28,660] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.5886433490521819, 1.0, 2.0, 0.5886433490521819, 1.0, 1.0, 1.020514599017459, 6.9112, 6.9112, 170.5573041426782, 2469600.841162183, 2469600.841162183, 481473.9577230118], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4014000.0000, 
sim time next is 4014600.0000, 
raw observation next is [31.33333333333334, 65.5, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.189474743851661, 6.9112, 168.911156231198, 2487897.63909574, 2290482.062413257, 475820.6315103745], 
processed observation next is [1.0, 0.4782608695652174, 0.6840442338072673, 0.655, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.027827474385166084, 0.0, 0.8294311049570973, 0.6910826775265945, 0.6362450173370159, 0.7101800470304097], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.01953975], dtype=float32), 0.056496065]. 
=============================================
[2019-03-26 19:40:31,268] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1958505e-19 1.0000000e+00 4.4026549e-16 1.3006430e-16 2.1332343e-18], sum to 1.0000
[2019-03-26 19:40:31,280] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3656
[2019-03-26 19:40:31,284] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666666, 76.33333333333333, 1.0, 2.0, 0.6317607026905631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 882863.9433764647, 882863.9433764641, 206812.6283973069], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4221600.0000, 
sim time next is 4222200.0000, 
raw observation next is [31.33333333333334, 77.66666666666667, 1.0, 2.0, 0.6299860219547007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 880382.8599504848, 880382.8599504848, 206465.6320131386], 
processed observation next is [1.0, 0.8695652173913043, 0.6840442338072673, 0.7766666666666667, 1.0, 1.0, 0.5542000264514465, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24455079443069022, 0.24455079443069022, 0.3081576597211024], 
reward next is 0.6918, 
noisyNet noise sample is [array([-0.95440656], dtype=float32), 0.4743574]. 
=============================================
[2019-03-26 19:40:32,619] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5554282e-20 1.0000000e+00 5.0784138e-17 2.6431036e-16 1.3557232e-18], sum to 1.0000
[2019-03-26 19:40:32,629] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1113
[2019-03-26 19:40:32,633] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.7025231281703276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 981797.7178059865, 981797.7178059865, 221390.9508297546], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4081800.0000, 
sim time next is 4082400.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.6571349986278583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 918338.9833539705, 918338.9833539705, 211865.1391908308], 
processed observation next is [1.0, 0.2608695652173913, 0.4786729857819906, 0.89, 1.0, 1.0, 0.586909636901034, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2550941620427696, 0.2550941620427696, 0.31621662565795644], 
reward next is 0.6838, 
noisyNet noise sample is [array([0.5138942], dtype=float32), -1.1223524]. 
=============================================
[2019-03-26 19:40:38,281] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.4766793e-20 1.0000000e+00 2.0222045e-17 6.6762641e-17 1.3362592e-17], sum to 1.0000
[2019-03-26 19:40:38,292] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1083
[2019-03-26 19:40:38,301] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2929153.919404369 W.
[2019-03-26 19:40:38,305] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.66666666666667, 73.66666666666666, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 6.938842000438483, 6.9112, 170.5573041426782, 2929153.919404369, 2909352.830085596, 553500.6711901841], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4178400.0000, 
sim time next is 4179000.0000, 
raw observation next is [32.83333333333333, 72.33333333333334, 1.0, 2.0, 1.009805134932769, 1.0, 2.0, 1.009805134932769, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2824766.168203464, 2824766.168203464, 534950.5262125253], 
processed observation next is [1.0, 0.34782608695652173, 0.7551342812006318, 0.7233333333333334, 1.0, 1.0, 1.0118134155816494, 1.0, 1.0, 1.0118134155816494, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7846572689454065, 0.7846572689454065, 0.7984336212127243], 
reward next is 0.2016, 
noisyNet noise sample is [array([-0.6563466], dtype=float32), 2.1504238]. 
=============================================
[2019-03-26 19:40:38,324] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[67.73652 ]
 [68.370026]
 [70.12559 ]
 [71.863   ]
 [72.56757 ]], R is [[66.6005249 ]
 [65.97018433]
 [65.31048584]
 [64.65737915]
 [64.4334259 ]].
[2019-03-26 19:40:38,478] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0435087e-15 1.0000000e+00 6.8482207e-14 1.5973784e-13 4.2079435e-14], sum to 1.0000
[2019-03-26 19:40:38,485] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3622
[2019-03-26 19:40:38,493] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2593522.208585792 W.
[2019-03-26 19:40:38,496] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.33333333333334, 55.0, 1.0, 2.0, 0.6181500857297006, 1.0, 2.0, 0.6181500857297006, 1.0, 1.0, 1.03, 6.960127116095882, 6.9112, 170.5573041426782, 2593522.208585792, 2558473.725098476, 494654.2978803412], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4188000.0000, 
sim time next is 4188600.0000, 
raw observation next is [35.5, 54.5, 1.0, 2.0, 0.9317025613867884, 1.0, 2.0, 0.9317025613867884, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2606059.004275845, 2606059.004275845, 489089.5801814198], 
processed observation next is [1.0, 0.4782608695652174, 0.8815165876777251, 0.545, 1.0, 1.0, 0.9177139293816728, 1.0, 1.0, 0.9177139293816728, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7239052789655125, 0.7239052789655125, 0.7299844480319698], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0093365], dtype=float32), -0.016266515]. 
=============================================
[2019-03-26 19:40:40,997] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 19:40:40,999] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:40:41,002] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:40:41,004] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:40:41,005] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:40:41,006] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:40:41,007] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:40:41,007] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:40:41,008] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:40:41,010] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:40:41,011] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:40:41,032] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run14
[2019-03-26 19:40:41,032] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run14
[2019-03-26 19:40:41,050] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run14
[2019-03-26 19:40:41,050] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run14
[2019-03-26 19:40:41,102] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run14
[2019-03-26 19:40:50,444] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05296812], dtype=float32), 0.058477927]
[2019-03-26 19:40:50,445] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.33772216333333, 67.97927718666666, 1.0, 2.0, 0.289527848048624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 479911.3591907573, 479911.3591907579, 164909.0922686436]
[2019-03-26 19:40:50,448] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:40:50,450] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.7862578e-17 1.0000000e+00 5.8516272e-15 4.8455286e-15 2.2156357e-16], sampled 0.08599247914596442
[2019-03-26 19:41:06,846] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05296812], dtype=float32), 0.058477927]
[2019-03-26 19:41:06,846] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.55, 76.0, 1.0, 2.0, 0.4792057180084694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104275, 669606.3797527608, 669606.37975276, 180404.6233446581]
[2019-03-26 19:41:06,847] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:41:06,850] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.5973550e-17 1.0000000e+00 4.2631177e-15 1.0137701e-14 3.7089490e-16], sampled 0.9393460153584768
[2019-03-26 19:41:10,857] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05296812], dtype=float32), 0.058477927]
[2019-03-26 19:41:10,858] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.96666666666667, 95.0, 1.0, 2.0, 0.5070163310171788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 708479.8179550462, 708479.8179550468, 184701.7266617256]
[2019-03-26 19:41:10,859] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:41:10,863] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.9265743e-20 1.0000000e+00 3.2325709e-17 3.6308186e-17 1.0689078e-18], sampled 0.04721672965595691
[2019-03-26 19:41:31,477] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05296812], dtype=float32), 0.058477927]
[2019-03-26 19:41:31,482] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.41445593, 89.04328233, 1.0, 2.0, 0.533508299852628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 745511.3895977411, 745511.3895977405, 189011.3613265754]
[2019-03-26 19:41:31,483] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:41:31,488] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.5497186e-20 1.0000000e+00 1.8180178e-17 2.6036440e-17 7.2675504e-19], sampled 0.7223264828753647
[2019-03-26 19:42:14,168] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05296812], dtype=float32), 0.058477927]
[2019-03-26 19:42:14,169] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.93333333333333, 84.33333333333334, 1.0, 2.0, 0.5223941021454377, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8822173837785204, 6.911199999999999, 6.9112, 168.912712370336, 1460452.682526844, 1460452.682526844, 315690.476064947]
[2019-03-26 19:42:14,170] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:42:14,174] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.1126024e-18 1.0000000e+00 1.7306486e-15 3.0635651e-15 1.0544748e-16], sampled 0.4298158472081445
[2019-03-26 19:42:19,311] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05296812], dtype=float32), 0.058477927]
[2019-03-26 19:42:19,312] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.1, 90.0, 1.0, 2.0, 0.4973505556749084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 696810.393198897, 696810.3931988977, 183417.9902960376]
[2019-03-26 19:42:19,315] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:42:19,317] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.0247252e-18 1.0000000e+00 1.9405724e-15 1.2880874e-15 5.3899850e-17], sampled 0.6891071093017368
[2019-03-26 19:42:35,841] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6673 3164154095.2556 1778.0000
[2019-03-26 19:42:35,941] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5749 3007726976.5989 1766.0000
[2019-03-26 19:42:36,024] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.4067 2927264152.9822 1338.0000
[2019-03-26 19:42:36,194] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 19:42:36,257] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 19:42:37,272] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 325000, evaluation results [325000.0, 7882.667338675547, 3164154095.2555733, 1778.0, 8254.406660643592, 2927264152.9821725, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7997.574940102971, 3007726976.5988917, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 19:42:38,245] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.4307239e-18 1.0000000e+00 1.5947070e-15 1.5649838e-16 4.7262225e-17], sum to 1.0000
[2019-03-26 19:42:38,253] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5720
[2019-03-26 19:42:38,258] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 79.0, 1.0, 2.0, 0.8630526313377184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1206270.070790945, 1206270.070790946, 259977.8209068921], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4254000.0000, 
sim time next is 4254600.0000, 
raw observation next is [29.0, 79.0, 1.0, 2.0, 0.8641396242585072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1207790.201490409, 1207790.201490408, 260265.107691575], 
processed observation next is [1.0, 0.21739130434782608, 0.5734597156398105, 0.79, 1.0, 1.0, 0.8363128003114545, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33549727819178027, 0.33549727819178, 0.388455384614291], 
reward next is 0.6115, 
noisyNet noise sample is [array([-0.51335824], dtype=float32), -0.011062168]. 
=============================================
[2019-03-26 19:42:38,341] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3453935e-18 1.0000000e+00 6.8446615e-16 1.3325641e-16 3.0784635e-17], sum to 1.0000
[2019-03-26 19:42:38,355] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6125
[2019-03-26 19:42:38,358] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 79.0, 1.0, 2.0, 0.9187025758693804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1284097.835336189, 1284097.835336189, 275136.2849042831], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4256400.0000, 
sim time next is 4257000.0000, 
raw observation next is [29.5, 79.0, 1.0, 2.0, 0.9834529039382823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1374659.88324726, 1374659.883247259, 293927.35968535], 
processed observation next is [1.0, 0.2608695652173913, 0.5971563981042655, 0.79, 1.0, 1.0, 0.9800637396846775, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.38184996756868334, 0.38184996756868306, 0.4386975517691791], 
reward next is 0.5613, 
noisyNet noise sample is [array([-0.51335824], dtype=float32), -0.011062168]. 
=============================================
[2019-03-26 19:42:38,372] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[68.76318]
 [68.36515]
 [67.77888]
 [67.43662]
 [67.03794]], R is [[68.63433075]
 [68.53733826]
 [68.40435791]
 [68.3368988 ]
 [68.26507568]].
[2019-03-26 19:42:38,824] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9973962e-16 1.0000000e+00 8.7952852e-14 3.2508467e-14 7.2240315e-15], sum to 1.0000
[2019-03-26 19:42:38,831] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0183
[2019-03-26 19:42:38,839] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2489802.377639234 W.
[2019-03-26 19:42:38,845] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.66666666666666, 76.5, 1.0, 2.0, 0.8901805607784536, 1.0, 2.0, 0.8901805607784536, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2489802.377639234, 2489802.377639234, 466181.8677456414], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4265400.0000, 
sim time next is 4266000.0000, 
raw observation next is [33.0, 75.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 10.39583552277784, 6.9112, 168.8926852242995, 4757784.527329366, 2285960.835355663, 466441.8714244304], 
processed observation next is [1.0, 0.391304347826087, 0.7630331753554502, 0.75, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.348463552277784, 0.0, 0.829340403857162, 1.321606813147046, 0.6349891209321287, 0.6961818976484035], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.00857912], dtype=float32), -2.3245585]. 
=============================================
[2019-03-26 19:42:38,855] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[58.927174]
 [59.440395]
 [60.34884 ]
 [61.079056]
 [62.523106]], R is [[57.60799789]
 [57.03191757]
 [56.46159744]
 [56.0947113 ]
 [55.71247101]].
[2019-03-26 19:42:59,490] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0784114e-15 1.0000000e+00 3.4418008e-14 1.8893150e-13 2.0853650e-14], sum to 1.0000
[2019-03-26 19:42:59,498] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6462
[2019-03-26 19:42:59,503] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.5241637676044307, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 732449.0678878941, 732449.0678878941, 187471.9760826372], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4641600.0000, 
sim time next is 4642200.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.5179499162533343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 723763.0799391958, 723763.0799391952, 186460.0130775358], 
processed observation next is [1.0, 0.7391304347826086, 0.6682464454976303, 0.7, 1.0, 1.0, 0.4192167665702823, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20104529998310994, 0.20104529998310977, 0.27829852698139673], 
reward next is 0.7217, 
noisyNet noise sample is [array([-0.8937153], dtype=float32), 1.2514234]. 
=============================================
[2019-03-26 19:43:01,811] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.4891852e-19 1.0000000e+00 7.4266647e-16 1.0017099e-16 7.0522631e-18], sum to 1.0000
[2019-03-26 19:43:01,822] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5868
[2019-03-26 19:43:01,829] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 74.0, 1.0, 2.0, 0.4745648029814758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 669080.7530330656, 669080.753033065, 180474.7162654271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4651800.0000, 
sim time next is 4652400.0000, 
raw observation next is [26.66666666666667, 78.0, 1.0, 2.0, 0.4718766926789524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 665992.9614055092, 665992.9614055092, 180161.2066178872], 
processed observation next is [1.0, 0.8695652173913043, 0.4628751974723541, 0.78, 1.0, 1.0, 0.3637068586493402, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18499804483486365, 0.18499804483486365, 0.2688973233102794], 
reward next is 0.7311, 
noisyNet noise sample is [array([-0.33310634], dtype=float32), -0.7326628]. 
=============================================
[2019-03-26 19:43:04,620] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.5539116e-20 1.0000000e+00 5.1168582e-17 1.1719616e-17 2.5634821e-18], sum to 1.0000
[2019-03-26 19:43:04,628] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7774
[2019-03-26 19:43:04,632] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666666, 85.66666666666667, 1.0, 2.0, 0.830988013210304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1161429.53381116, 1161429.53381116, 251659.916831695], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4689600.0000, 
sim time next is 4690200.0000, 
raw observation next is [27.83333333333334, 84.83333333333333, 1.0, 2.0, 0.7939864652292251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1109687.335726188, 1109687.335726188, 242440.7364978558], 
processed observation next is [1.0, 0.2608695652173913, 0.5181674565560824, 0.8483333333333333, 1.0, 1.0, 0.7517909219629219, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.30824648214616335, 0.30824648214616335, 0.36185184551918775], 
reward next is 0.6381, 
noisyNet noise sample is [array([-1.1613365], dtype=float32), 0.6078402]. 
=============================================
[2019-03-26 19:43:08,472] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5467648e-19 1.0000000e+00 3.6762691e-16 1.3000082e-16 6.5818124e-18], sum to 1.0000
[2019-03-26 19:43:08,482] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1776
[2019-03-26 19:43:08,486] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 83.16666666666666, 1.0, 2.0, 0.5046798576487501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 705213.8606261248, 705213.8606261241, 184332.621123565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4917000.0000, 
sim time next is 4917600.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5069177657347922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 708342.0417301061, 708342.0417301061, 184687.246725973], 
processed observation next is [1.0, 0.9565217391304348, 0.4786729857819906, 0.84, 1.0, 1.0, 0.40592501895758093, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1967616782583628, 0.1967616782583628, 0.27565260705369105], 
reward next is 0.7243, 
noisyNet noise sample is [array([-0.03573929], dtype=float32), 0.73009694]. 
=============================================
[2019-03-26 19:43:10,677] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.4474447e-14 1.0000000e+00 1.7616308e-12 1.8196078e-12 4.7002316e-14], sum to 1.0000
[2019-03-26 19:43:10,685] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8128
[2019-03-26 19:43:10,693] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2631120.966697341 W.
[2019-03-26 19:43:10,701] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.83333333333334, 63.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.393893572548272, 6.9112, 168.9106565411589, 2631120.966697341, 2288686.196058571, 475278.2102427921], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4800000.0000, 
sim time next is 4800600.0000, 
raw observation next is [31.75, 64.0, 1.0, 2.0, 0.9194610789759076, 1.0, 1.0, 0.9194610789759076, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2571783.195808665, 2571783.195808665, 482217.2438343287], 
processed observation next is [1.0, 0.5652173913043478, 0.7037914691943128, 0.64, 1.0, 1.0, 0.9029651553926598, 1.0, 0.5, 0.9029651553926598, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7143842210579625, 0.7143842210579625, 0.7197272296034757], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.68679655], dtype=float32), 1.0220206]. 
=============================================
[2019-03-26 19:43:12,110] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.8227996e-20 1.0000000e+00 5.3264175e-17 3.9168461e-17 3.1294210e-19], sum to 1.0000
[2019-03-26 19:43:12,118] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5004
[2019-03-26 19:43:12,123] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 77.0, 1.0, 2.0, 0.4933954913837593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 689440.5464808679, 689440.5464808679, 182567.4639977381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4834800.0000, 
sim time next is 4835400.0000, 
raw observation next is [27.41666666666667, 77.33333333333334, 1.0, 2.0, 0.4927984996387762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 688606.0765155231, 688606.0765155231, 182475.1169427546], 
processed observation next is [1.0, 1.0, 0.4984202211690366, 0.7733333333333334, 1.0, 1.0, 0.3889138549864773, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19127946569875642, 0.19127946569875642, 0.2723509208100815], 
reward next is 0.7276, 
noisyNet noise sample is [array([0.21865311], dtype=float32), -0.5462186]. 
=============================================
[2019-03-26 19:43:14,633] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.7214612e-15 1.0000000e+00 1.0741570e-13 2.0529689e-13 7.2711705e-15], sum to 1.0000
[2019-03-26 19:43:14,644] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8516
[2019-03-26 19:43:14,656] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2121844.163933615 W.
[2019-03-26 19:43:14,664] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.33333333333334, 66.0, 1.0, 2.0, 0.7587404132496529, 1.0, 2.0, 0.7587404132496529, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2121844.163933615, 2121844.163933615, 400278.9596105331], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4898400.0000, 
sim time next is 4899000.0000, 
raw observation next is [30.16666666666666, 66.0, 1.0, 2.0, 0.8883254560520302, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.97901440710323, 6.9112, 168.9125525434709, 2138695.497806663, 2090585.738473943, 431787.596118502], 
processed observation next is [1.0, 0.6956521739130435, 0.6287519747235385, 0.66, 1.0, 1.0, 0.865452356689193, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.006781440710322962, 0.0, 0.8294379614895917, 0.5940820827240731, 0.5807182606872063, 0.6444590986843314], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7380303], dtype=float32), -1.8917187]. 
=============================================
[2019-03-26 19:43:14,680] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[51.70642 ]
 [50.985916]
 [51.27365 ]
 [50.672253]
 [49.97812 ]], R is [[51.12129593]
 [51.01265335]
 [50.50252914]
 [49.99750519]
 [49.92007828]].
[2019-03-26 19:43:16,213] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.02594325e-14 1.00000000e+00 1.23168500e-12 2.21150680e-12
 3.72961942e-13], sum to 1.0000
[2019-03-26 19:43:16,222] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6517
[2019-03-26 19:43:16,229] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2264256.917773158 W.
[2019-03-26 19:43:16,234] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.5397427636077559, 1.0, 2.0, 0.5397427636077559, 1.0, 2.0, 0.9355470525564837, 6.911199999999999, 6.9112, 170.5573041426782, 2264256.917773158, 2264256.917773159, 443362.0937871474], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4882200.0000, 
sim time next is 4882800.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.7189621116555488, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.993098915122884, 6.9112, 168.9124678838482, 1901663.832509764, 1843562.091454017, 389299.5325798089], 
processed observation next is [1.0, 0.5217391304347826, 0.6682464454976303, 0.66, 1.0, 1.0, 0.6614001345247575, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008189891512288393, 0.0, 0.8294375457720868, 0.5282399534749345, 0.5121005809594492, 0.5810440784773268], 
reward next is 0.0095, 
noisyNet noise sample is [array([-0.35370484], dtype=float32), 0.39745578]. 
=============================================
[2019-03-26 19:43:18,303] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9999167e-19 1.0000000e+00 8.8420830e-17 1.5499702e-16 2.0678303e-18], sum to 1.0000
[2019-03-26 19:43:18,312] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5696
[2019-03-26 19:43:18,318] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 83.16666666666666, 1.0, 2.0, 0.5046798576487501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 705213.8606261248, 705213.8606261241, 184332.621123565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4917000.0000, 
sim time next is 4917600.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5069177657347922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 708342.0417301061, 708342.0417301061, 184687.246725973], 
processed observation next is [1.0, 0.9565217391304348, 0.4786729857819906, 0.84, 1.0, 1.0, 0.40592501895758093, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1967616782583628, 0.1967616782583628, 0.27565260705369105], 
reward next is 0.7243, 
noisyNet noise sample is [array([-1.8889177], dtype=float32), -0.18938804]. 
=============================================
[2019-03-26 19:43:18,346] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3843629e-17 1.0000000e+00 1.9468972e-15 1.8315029e-15 7.8780888e-18], sum to 1.0000
[2019-03-26 19:43:18,357] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4096
[2019-03-26 19:43:18,362] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333333, 72.66666666666666, 1.0, 2.0, 0.493160040738451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 689111.4355003275, 689111.4355003275, 182531.3177667337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4909200.0000, 
sim time next is 4909800.0000, 
raw observation next is [28.16666666666667, 73.33333333333334, 1.0, 2.0, 0.491514018420261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 686810.6418548356, 686810.6418548356, 182277.1349528615], 
processed observation next is [1.0, 0.8260869565217391, 0.5339652448657191, 0.7333333333333334, 1.0, 1.0, 0.38736628725332645, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19078073384856542, 0.19078073384856542, 0.2720554253027784], 
reward next is 0.7279, 
noisyNet noise sample is [array([-0.09904627], dtype=float32), 0.035801552]. 
=============================================
[2019-03-26 19:43:21,455] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2539559e-15 1.0000000e+00 3.6734833e-14 4.0746009e-13 3.5122157e-14], sum to 1.0000
[2019-03-26 19:43:21,464] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2303
[2019-03-26 19:43:21,472] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1937157.043919639 W.
[2019-03-26 19:43:21,476] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 66.66666666666666, 1.0, 2.0, 0.7443250523690309, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.977998522901091, 6.9112, 168.912558603634, 1937157.043919639, 1889767.984380139, 395536.4316458591], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4963800.0000, 
sim time next is 4964400.0000, 
raw observation next is [30.0, 66.0, 1.0, 2.0, 0.6823166599555295, 1.0, 1.0, 0.6823166599555295, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1907932.144857525, 1907932.144857525, 366639.9261944883], 
processed observation next is [1.0, 0.4782608695652174, 0.6208530805687204, 0.66, 1.0, 1.0, 0.6172489878982282, 1.0, 0.5, 0.6172489878982282, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5299811513493125, 0.5299811513493125, 0.5472237704395347], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.90573263], dtype=float32), 0.3675214]. 
=============================================
[2019-03-26 19:43:22,005] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.7057122e-14 1.0000000e+00 1.9183620e-12 8.2308145e-12 4.0194413e-13], sum to 1.0000
[2019-03-26 19:43:22,012] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6086
[2019-03-26 19:43:22,022] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2154942.380835171 W.
[2019-03-26 19:43:22,028] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 63.0, 1.0, 2.0, 0.7705639580925725, 1.0, 2.0, 0.7705639580925725, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2154942.380835171, 2154942.380835171, 405789.8729411034], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4982400.0000, 
sim time next is 4983000.0000, 
raw observation next is [31.0, 63.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.026373329329161, 6.9112, 168.912318858162, 2382150.755391345, 2300443.140055411, 476615.6045046633], 
processed observation next is [1.0, 0.6956521739130435, 0.6682464454976303, 0.63, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.01151733293291608, 0.0, 0.8294368139877434, 0.6617085431642624, 0.6390119833487253, 0.7113665738875572], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4936316], dtype=float32), 1.0863042]. 
=============================================
[2019-03-26 19:43:22,041] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[50.01803 ]
 [49.298023]
 [49.644985]
 [49.792053]
 [50.00976 ]], R is [[50.19977951]
 [50.09212494]
 [49.5912056 ]
 [49.09529495]
 [49.01625443]].
[2019-03-26 19:43:23,145] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1771136e-18 1.0000000e+00 8.0833353e-17 9.4512777e-17 2.0505960e-18], sum to 1.0000
[2019-03-26 19:43:23,154] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8008
[2019-03-26 19:43:23,157] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 79.0, 1.0, 2.0, 0.5055472138692355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 706426.262918072, 706426.2629180714, 184469.471636405], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4998600.0000, 
sim time next is 4999200.0000, 
raw observation next is [27.33333333333334, 79.0, 1.0, 2.0, 0.5008635856409079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 699879.4402785505, 699879.4402785498, 183731.1038394858], 
processed observation next is [1.0, 0.8695652173913043, 0.4944707740916275, 0.79, 1.0, 1.0, 0.398630826073383, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1944109556329307, 0.1944109556329305, 0.2742255281186355], 
reward next is 0.7258, 
noisyNet noise sample is [array([-0.31428334], dtype=float32), -0.22784586]. 
=============================================
[2019-03-26 19:43:28,327] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.1140192e-18 1.0000000e+00 1.2686450e-15 5.6225168e-16 1.0399336e-17], sum to 1.0000
[2019-03-26 19:43:28,337] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2896
[2019-03-26 19:43:28,343] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4814624873965489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 672885.4902672878, 672885.4902672871, 180758.0926966805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5113800.0000, 
sim time next is 5114400.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4805817283252084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 671654.9019920448, 671654.9019920448, 180625.1653267668], 
processed observation next is [0.0, 0.17391304347826086, 0.4312796208530806, 0.84, 1.0, 1.0, 0.3741948534038655, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1865708061089013, 0.1865708061089013, 0.2695897989951743], 
reward next is 0.7304, 
noisyNet noise sample is [array([0.15287596], dtype=float32), -0.16687141]. 
=============================================
[2019-03-26 19:43:28,866] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3746622e-20 1.0000000e+00 3.4099409e-17 8.4192618e-18 4.0519022e-20], sum to 1.0000
[2019-03-26 19:43:28,873] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5200
[2019-03-26 19:43:28,878] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 81.33333333333333, 1.0, 2.0, 0.5497328995329734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 768191.4446982018, 768191.4446982018, 191754.9222320282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5263800.0000, 
sim time next is 5264400.0000, 
raw observation next is [28.5, 81.66666666666667, 1.0, 2.0, 0.5508259599999857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 769719.4302636089, 769719.4302636089, 191942.5302566618], 
processed observation next is [1.0, 0.9565217391304348, 0.5497630331753555, 0.8166666666666668, 1.0, 1.0, 0.4588264578313081, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2138109528510025, 0.2138109528510025, 0.2864813884427788], 
reward next is 0.7135, 
noisyNet noise sample is [array([0.72638094], dtype=float32), -0.59520704]. 
=============================================
[2019-03-26 19:43:30,517] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5461369e-17 1.0000000e+00 2.3271627e-16 1.1430214e-14 1.6424611e-17], sum to 1.0000
[2019-03-26 19:43:30,526] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6439
[2019-03-26 19:43:30,530] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666666, 65.66666666666667, 1.0, 2.0, 0.5497628870783279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 768233.3641580797, 768233.3641580797, 191761.1359522969], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5139600.0000, 
sim time next is 5140200.0000, 
raw observation next is [31.83333333333333, 66.33333333333333, 1.0, 2.0, 0.5587821854353346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 780841.4773765682, 780841.4773765688, 193319.4404316455], 
processed observation next is [0.0, 0.4782608695652174, 0.7077409162717218, 0.6633333333333333, 1.0, 1.0, 0.4684122716088369, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21690041038238006, 0.21690041038238023, 0.2885364782561873], 
reward next is 0.7115, 
noisyNet noise sample is [array([-0.6115732], dtype=float32), -1.0206851]. 
=============================================
[2019-03-26 19:43:32,616] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 19:43:32,618] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:43:32,619] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:43:32,621] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:43:32,622] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:43:32,622] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:43:32,623] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:43:32,623] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:43:32,624] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:43:32,631] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:43:32,632] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:43:32,641] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run15
[2019-03-26 19:43:32,642] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run15
[2019-03-26 19:43:32,679] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run15
[2019-03-26 19:43:32,679] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run15
[2019-03-26 19:43:32,680] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run15
[2019-03-26 19:43:52,639] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05564673], dtype=float32), 0.06013382]
[2019-03-26 19:43:52,640] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.6, 61.0, 1.0, 2.0, 0.2138469448450036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 356711.8742454565, 356711.8742454559, 156906.8123916593]
[2019-03-26 19:43:52,642] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:43:52,645] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.1337471e-18 1.0000000e+00 7.3444829e-16 1.2828748e-15 2.6932183e-17], sampled 0.7428927719777261
[2019-03-26 19:44:15,395] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05564673], dtype=float32), 0.06013382]
[2019-03-26 19:44:15,396] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.66746608333333, 87.49665469333334, 1.0, 2.0, 0.3252960847292656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515805.6435442958, 515805.6435442958, 168246.7099716463]
[2019-03-26 19:44:15,400] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:44:15,403] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.8279754e-20 1.0000000e+00 1.6050010e-17 2.8767208e-17 4.3815711e-19], sampled 0.1926096308371149
[2019-03-26 19:44:53,186] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05564673], dtype=float32), 0.06013382]
[2019-03-26 19:44:53,186] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [34.83333333333334, 50.66666666666666, 1.0, 2.0, 0.9739266691691698, 1.0, 2.0, 0.9739266691691698, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2724292.541434822, 2724292.541434822, 513424.8680944377]
[2019-03-26 19:44:53,188] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:44:53,191] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9867997e-18 1.0000000e+00 8.9296077e-16 4.1923836e-15 1.0046106e-16], sampled 0.7890927167288683
[2019-03-26 19:44:53,194] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2724292.541434822 W.
[2019-03-26 19:44:53,740] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05564673], dtype=float32), 0.06013382]
[2019-03-26 19:44:53,742] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.6, 80.0, 1.0, 2.0, 0.5882373266902848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 822017.9795488719, 822017.9795488719, 198574.4301363589]
[2019-03-26 19:44:53,745] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:44:53,748] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.877364e-20 1.000000e+00 1.227779e-17 2.568848e-17 4.172066e-19], sampled 0.5772824499463848
[2019-03-26 19:45:23,684] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05564673], dtype=float32), 0.06013382]
[2019-03-26 19:45:23,685] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.76906323, 92.34299742666666, 1.0, 2.0, 0.4285675626270312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 627385.3517349544, 627385.3517349544, 176806.2468638065]
[2019-03-26 19:45:23,686] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:45:23,689] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.2867246e-19 1.0000000e+00 4.5435516e-17 9.0136918e-17 1.4910566e-18], sampled 0.21869069104769712
[2019-03-26 19:45:27,484] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.5883 2927390983.0870 1338.0000
[2019-03-26 19:45:27,683] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164071917.9177 1778.0000
[2019-03-26 19:45:27,842] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9767 2779231803.5959 933.0000
[2019-03-26 19:45:27,970] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2178 3007719775.7786 1766.0000
[2019-03-26 19:45:27,971] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5144 2842492707.2201 1131.0000
[2019-03-26 19:45:28,990] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 350000, evaluation results [350000.0, 7884.168443086554, 3164071917.9176674, 1778.0, 8253.588268818321, 2927390983.087013, 1338.0, 8659.976680226611, 2779231803.5959473, 933.0, 7998.217808978373, 3007719775.7785764, 1766.0, 8497.514395919725, 2842492707.2200756, 1131.0]
[2019-03-26 19:45:29,089] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.5882004e-21 1.0000000e+00 3.6239812e-18 1.6017532e-17 1.5667793e-19], sum to 1.0000
[2019-03-26 19:45:29,100] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5549
[2019-03-26 19:45:29,103] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333333, 65.0, 1.0, 2.0, 0.5454243160662059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 762168.5117103031, 762168.5117103037, 191019.3302135518], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5157600.0000, 
sim time next is 5158200.0000, 
raw observation next is [31.16666666666667, 65.5, 1.0, 2.0, 0.5437880349774372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 759881.1769350927, 759881.1769350927, 190741.2701560888], 
processed observation next is [0.0, 0.6956521739130435, 0.6761453396524489, 0.655, 1.0, 1.0, 0.45034703009329785, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21107810470419242, 0.21107810470419242, 0.28468846291953553], 
reward next is 0.7153, 
noisyNet noise sample is [array([1.3733265], dtype=float32), -0.13471727]. 
=============================================
[2019-03-26 19:45:29,775] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.7351380e-21 1.0000000e+00 4.9037073e-17 6.4424060e-18 5.4253572e-19], sum to 1.0000
[2019-03-26 19:45:29,784] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4126
[2019-03-26 19:45:29,790] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5228320007704005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 730587.4611039674, 730587.4611039667, 187250.3871592841], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5173200.0000, 
sim time next is 5173800.0000, 
raw observation next is [28.0, 79.00000000000001, 1.0, 2.0, 0.5234912123965862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731508.9379428031, 731508.9379428037, 187358.1546805001], 
processed observation next is [0.0, 0.9130434782608695, 0.5260663507109005, 0.7900000000000001, 1.0, 1.0, 0.42589302698383885, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2031969272063342, 0.20319692720633437, 0.2796390368365673], 
reward next is 0.7204, 
noisyNet noise sample is [array([0.9373598], dtype=float32), -0.4376378]. 
=============================================
[2019-03-26 19:45:33,965] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1384054e-20 1.0000000e+00 4.2231822e-17 3.2107446e-17 1.4503778e-19], sum to 1.0000
[2019-03-26 19:45:33,972] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3916
[2019-03-26 19:45:33,977] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 88.0, 1.0, 2.0, 0.8229685654645147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1150215.090218088, 1150215.090218088, 249630.8066591812], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5291400.0000, 
sim time next is 5292000.0000, 
raw observation next is [28.6, 88.0, 1.0, 2.0, 0.9495685690163033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1327267.117137036, 1327267.117137035, 283940.5516541216], 
processed observation next is [1.0, 0.2608695652173913, 0.5545023696682465, 0.88, 1.0, 1.0, 0.9392392397786786, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.36868531031584334, 0.368685310315843, 0.42379186814048003], 
reward next is 0.5762, 
noisyNet noise sample is [array([0.7820945], dtype=float32), 0.30401194]. 
=============================================
[2019-03-26 19:45:33,990] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[72.40549 ]
 [72.37161 ]
 [71.32143 ]
 [71.206245]
 [70.887985]], R is [[72.7261734 ]
 [72.62632751]
 [72.52643585]
 [72.42599487]
 [72.32875824]].
[2019-03-26 19:45:43,069] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6175616e-13 1.0000000e+00 1.8743308e-12 2.3153372e-12 3.4824864e-13], sum to 1.0000
[2019-03-26 19:45:43,077] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8458
[2019-03-26 19:45:43,083] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 3090059.437883598 W.
[2019-03-26 19:45:43,086] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [37.08333333333334, 54.0, 1.0, 2.0, 0.831520898793349, 1.0, 2.0, 0.736350488910937, 1.0, 2.0, 1.03, 7.005108104748982, 6.9112, 170.5573041426782, 3090059.437883598, 3022789.242514433, 566089.6732177786], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5407800.0000, 
sim time next is 5408400.0000, 
raw observation next is [37.26666666666667, 54.00000000000001, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 6.933629152856978, 6.9112, 170.5573041426782, 2925415.39588875, 2909348.481337691, 553529.2515987892], 
processed observation next is [1.0, 0.6086956521739131, 0.9652448657187996, 0.54, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.0022429152856977552, 0.0, 0.8375144448122397, 0.812615387746875, 0.8081523559271364, 0.8261630620877451], 
reward next is 0.0617, 
noisyNet noise sample is [array([1.0934097], dtype=float32), -0.5270402]. 
=============================================
[2019-03-26 19:45:46,264] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2088305e-19 1.0000000e+00 2.2940304e-16 2.5260918e-16 2.6457843e-18], sum to 1.0000
[2019-03-26 19:45:46,272] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3030
[2019-03-26 19:45:46,282] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 92.66666666666667, 1.0, 2.0, 0.5148374441949914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 719412.359690964, 719412.3596909647, 185953.2053432669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5622000.0000, 
sim time next is 5622600.0000, 
raw observation next is [25.75, 92.83333333333333, 1.0, 2.0, 0.513362587680311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 717350.7608672512, 717350.7608672512, 185715.9903424979], 
processed observation next is [0.0, 0.043478260869565216, 0.41943127962085314, 0.9283333333333332, 1.0, 1.0, 0.4136898646750734, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1992641002409031, 0.1992641002409031, 0.27718804528731034], 
reward next is 0.7228, 
noisyNet noise sample is [array([-1.364653], dtype=float32), -2.2020736]. 
=============================================
[2019-03-26 19:45:47,416] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9246609e-17 1.0000000e+00 2.4094760e-16 1.5497878e-15 1.3125604e-16], sum to 1.0000
[2019-03-26 19:45:47,426] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7930
[2019-03-26 19:45:47,432] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2790366.101185709 W.
[2019-03-26 19:45:47,439] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.23333333333333, 69.33333333333333, 1.0, 2.0, 0.9975214240039615, 1.0, 2.0, 0.9975214240039615, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2790366.101185709, 2790366.101185709, 527500.3130354084], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5478000.0000, 
sim time next is 5478600.0000, 
raw observation next is [33.46666666666667, 68.66666666666667, 1.0, 2.0, 0.723032004088866, 1.0, 2.0, 0.6821060415586957, 1.0, 1.0, 1.03, 7.005099548278348, 6.9112, 170.5573041426782, 2862164.410644935, 2794900.344623739, 528703.9564017417], 
processed observation next is [1.0, 0.391304347826087, 0.7851500789889416, 0.6866666666666668, 1.0, 1.0, 0.6663036193841759, 1.0, 1.0, 0.6169952307936093, 1.0, 0.5, 1.0365853658536586, 0.009389954827834756, 0.0, 0.8375144448122397, 0.795045669623593, 0.7763612068399275, 0.7891103826891668], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.43136278], dtype=float32), -1.2409884]. 
=============================================
[2019-03-26 19:46:18,586] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3869423e-17 1.0000000e+00 6.0692409e-16 1.5165689e-15 5.4319277e-17], sum to 1.0000
[2019-03-26 19:46:18,592] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0917
[2019-03-26 19:46:18,603] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2009565.3128503 W.
[2019-03-26 19:46:18,606] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.53333333333333, 79.83333333333334, 1.0, 2.0, 0.7186287625451112, 1.0, 2.0, 0.7186287625451112, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2009565.3128503, 2009565.3128503, 382207.3359840713], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5993400.0000, 
sim time next is 5994000.0000, 
raw observation next is [29.7, 79.0, 1.0, 2.0, 0.8292189130183596, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.005983309842643, 6.9112, 168.9123931883171, 2055967.201461748, 1988724.883522459, 415172.0304382888], 
processed observation next is [1.0, 0.391304347826087, 0.6066350710900474, 0.79, 1.0, 1.0, 0.7942396542389875, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.009478330984264271, 0.0, 0.8294371789828335, 0.5711020004060411, 0.5524235787562386, 0.6196597469228191], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.9964186], dtype=float32), -1.9157926]. 
=============================================
[2019-03-26 19:46:18,619] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[68.09162 ]
 [69.29627 ]
 [71.39424 ]
 [72.65381 ]
 [72.477905]], R is [[66.16539001]
 [65.93328094]
 [65.67879486]
 [65.0220108 ]
 [64.37178802]].
[2019-03-26 19:46:24,220] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 19:46:24,223] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:46:24,227] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:46:24,227] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:46:24,228] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:46:24,228] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:46:24,230] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:46:24,233] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:46:24,234] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:46:24,234] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:46:24,234] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:46:24,257] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run16
[2019-03-26 19:46:24,258] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run16
[2019-03-26 19:46:24,289] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run16
[2019-03-26 19:46:24,290] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run16
[2019-03-26 19:46:24,322] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run16
[2019-03-26 19:46:40,522] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05519924], dtype=float32), 0.058578614]
[2019-03-26 19:46:40,523] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.999055045, 95.75021419, 1.0, 2.0, 0.3587496140662904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 547448.8494004188, 547448.8494004188, 170277.3770509686]
[2019-03-26 19:46:40,525] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:46:40,528] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.8365647e-18 1.0000000e+00 9.4707717e-16 2.2295669e-15 1.8663493e-17], sampled 0.7642876371049957
[2019-03-26 19:47:39,375] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05519924], dtype=float32), 0.058578614]
[2019-03-26 19:47:39,377] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.03333333333333, 73.33333333333334, 1.0, 2.0, 0.6071775903924442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 848496.1634830114, 848496.1634830114, 202089.6746038916]
[2019-03-26 19:47:39,379] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:47:39,382] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.0859265e-19 1.0000000e+00 6.2386974e-17 1.5630806e-16 1.4580284e-18], sampled 0.27613846437001366
[2019-03-26 19:47:50,724] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05519924], dtype=float32), 0.058578614]
[2019-03-26 19:47:50,726] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.016911825, 86.53358144, 1.0, 2.0, 0.6326602883205923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 884121.6067298009, 884121.6067298015, 206986.1483559282]
[2019-03-26 19:47:50,728] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:47:50,730] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.5154898e-20 1.0000000e+00 6.0290606e-18 2.9635350e-17 9.5687659e-20], sampled 0.6105401622891975
[2019-03-26 19:47:53,565] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05519924], dtype=float32), 0.058578614]
[2019-03-26 19:47:53,566] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.73333333333333, 90.0, 1.0, 2.0, 0.6436713855520295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 899515.7632904821, 899515.7632904828, 209156.4573357524]
[2019-03-26 19:47:53,569] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:47:53,571] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.24939777e-19 1.00000000e+00 1.01736426e-16 2.04275164e-16
 2.02801277e-18], sampled 0.06221881142751462
[2019-03-26 19:48:16,911] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05519924], dtype=float32), 0.058578614]
[2019-03-26 19:48:16,912] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.85, 63.0, 1.0, 2.0, 0.3392041555904872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 531451.666160379, 531451.6661603784, 169358.752545204]
[2019-03-26 19:48:16,913] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:48:16,919] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.3817044e-19 1.0000000e+00 8.4097329e-17 2.4935686e-16 2.2532046e-18], sampled 0.5812717375844187
[2019-03-26 19:48:18,413] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 19:48:19,098] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164027848.4855 1778.0000
[2019-03-26 19:48:19,194] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.1049 2927540863.5018 1338.0000
[2019-03-26 19:48:19,248] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5144 2842492707.2201 1131.0000
[2019-03-26 19:48:19,409] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 19:48:20,423] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 375000, evaluation results [375000.0, 7884.16835844559, 3164027848.485504, 1778.0, 8252.10492501701, 2927540863.501752, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8497.514395919725, 2842492707.2200756, 1131.0]
[2019-03-26 19:48:26,844] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6911354e-20 1.0000000e+00 3.7994213e-18 2.6726265e-17 6.4799371e-20], sum to 1.0000
[2019-03-26 19:48:26,853] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6864
[2019-03-26 19:48:26,860] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.25, 86.16666666666667, 1.0, 2.0, 0.5296273506821226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740086.3573434277, 740086.3573434271, 188368.3708849643], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6210600.0000, 
sim time next is 6211200.0000, 
raw observation next is [27.2, 86.33333333333334, 1.0, 2.0, 0.528573020536152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738612.5538424747, 738612.5538424747, 188194.0872299482], 
processed observation next is [1.0, 0.9130434782608695, 0.4881516587677725, 0.8633333333333334, 1.0, 1.0, 0.43201568739295415, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20517015384513188, 0.20517015384513188, 0.28088669735813165], 
reward next is 0.7191, 
noisyNet noise sample is [array([-1.9670889], dtype=float32), 0.81371105]. 
=============================================
[2019-03-26 19:48:34,619] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0350297e-19 1.0000000e+00 2.3235877e-16 1.6643603e-16 2.3032087e-18], sum to 1.0000
[2019-03-26 19:48:34,626] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3773
[2019-03-26 19:48:34,634] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.4, 68.66666666666667, 1.0, 2.0, 0.5390066517151064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 753197.3754166679, 753197.3754166673, 189933.3915772869], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6344400.0000, 
sim time next is 6345000.0000, 
raw observation next is [30.55, 68.0, 1.0, 2.0, 0.5387501720062388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 752838.8486701441, 752838.8486701441, 189890.3342784654], 
processed observation next is [0.0, 0.43478260869565216, 0.6469194312796209, 0.68, 1.0, 1.0, 0.44427731567016715, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20912190240837336, 0.20912190240837336, 0.2834184093708439], 
reward next is 0.7166, 
noisyNet noise sample is [array([-0.34130827], dtype=float32), -0.02633147]. 
=============================================
[2019-03-26 19:48:34,678] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[69.99794]
 [69.93581]
 [69.86797]
 [69.80746]
 [69.75668]], R is [[70.07138062]
 [70.08718109]
 [70.1031723 ]
 [70.11960602]
 [70.13633728]].
[2019-03-26 19:48:38,206] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4122836e-21 1.0000000e+00 3.6378026e-19 7.6097390e-18 8.0312832e-21], sum to 1.0000
[2019-03-26 19:48:38,213] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1773
[2019-03-26 19:48:38,218] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.1, 83.0, 1.0, 2.0, 0.5124905265649867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 716131.769476908, 716131.769476908, 185575.9632581578], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6394800.0000, 
sim time next is 6395400.0000, 
raw observation next is [27.1, 83.0, 1.0, 2.0, 0.5123525211006227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 715938.8617114736, 715938.8617114729, 185553.8411422499], 
processed observation next is [1.0, 0.0, 0.4834123222748816, 0.83, 1.0, 1.0, 0.412472916988702, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19887190603096488, 0.1988719060309647, 0.2769460315555969], 
reward next is 0.7231, 
noisyNet noise sample is [array([-1.1604565], dtype=float32), -0.1493118]. 
=============================================
[2019-03-26 19:48:40,252] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.9473559e-13 1.0000000e+00 1.9598656e-12 3.4306100e-12 1.6304444e-13], sum to 1.0000
[2019-03-26 19:48:40,260] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0070
[2019-03-26 19:48:40,270] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1667533.072976858 W.
[2019-03-26 19:48:40,275] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.9, 69.0, 1.0, 2.0, 0.3976078264270595, 1.0, 2.0, 0.3976078264270595, 1.0, 1.0, 0.6819561752372282, 6.9112, 6.9112, 170.5573041426782, 1667533.072976858, 1667533.072976858, 350374.5714163264], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6439200.0000, 
sim time next is 6439800.0000, 
raw observation next is [29.9, 69.0, 1.0, 2.0, 0.5741325721626768, 1.0, 2.0, 0.5741325721626768, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1605195.145474094, 1605195.145474094, 324891.4988676415], 
processed observation next is [1.0, 0.5217391304347826, 0.6161137440758293, 0.69, 1.0, 1.0, 0.48690671344900815, 1.0, 1.0, 0.48690671344900815, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.44588754040947054, 0.44588754040947054, 0.48491268487707684], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0055792], dtype=float32), 1.5572702]. 
=============================================
[2019-03-26 19:48:48,616] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6463987e-19 1.0000000e+00 7.4941088e-17 4.2478723e-16 6.9886282e-19], sum to 1.0000
[2019-03-26 19:48:48,623] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6628
[2019-03-26 19:48:48,628] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.91666666666666, 91.83333333333333, 1.0, 2.0, 0.6900972663872862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 964424.3080547536, 964424.3080547536, 218720.6287760917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6580200.0000, 
sim time next is 6580800.0000, 
raw observation next is [25.9, 92.0, 1.0, 2.0, 0.6567178005377173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 917755.7016708504, 917755.7016708504, 211778.6193700534], 
processed observation next is [1.0, 0.17391304347826086, 0.42654028436018954, 0.92, 1.0, 1.0, 0.5864069885996595, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.254932139353014, 0.254932139353014, 0.31608749159709465], 
reward next is 0.6839, 
noisyNet noise sample is [array([-0.18459073], dtype=float32), 0.9622695]. 
=============================================
[2019-03-26 19:48:50,770] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.1093023e-16 1.0000000e+00 2.2526936e-14 6.9732272e-14 2.7632063e-15], sum to 1.0000
[2019-03-26 19:48:50,780] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7839
[2019-03-26 19:48:50,789] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2128787.582506141 W.
[2019-03-26 19:48:50,799] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.5, 80.5, 1.0, 2.0, 0.8812468307965657, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.99036914745939, 6.9112, 168.912420995886, 2128787.582506141, 2072622.442570848, 429491.5815498587], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6623400.0000, 
sim time next is 6624000.0000, 
raw observation next is [28.0, 84.0, 1.0, 2.0, 0.8338394477633783, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.991181730604744, 6.9112, 168.9124160842159, 2062434.086559327, 2005692.475651342, 416926.3796088968], 
processed observation next is [1.0, 0.6956521739130435, 0.5260663507109005, 0.84, 1.0, 1.0, 0.7998065635703352, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.00799817306047439, 0.0, 0.8294372914121783, 0.5728983573775909, 0.5571367987920395, 0.6222781785207415], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.572288], dtype=float32), -0.39241916]. 
=============================================
[2019-03-26 19:48:50,810] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[54.620483]
 [54.5911  ]
 [54.791214]
 [54.241943]
 [54.959072]], R is [[53.96572495]
 [53.42606735]
 [52.89180756]
 [52.36288834]
 [51.8392601 ]].
[2019-03-26 19:48:53,694] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.0290810e-19 1.0000000e+00 8.8559902e-17 6.4518043e-17 1.4664344e-18], sum to 1.0000
[2019-03-26 19:48:53,706] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4867
[2019-03-26 19:48:53,713] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.85, 95.0, 1.0, 2.0, 0.6174718364561248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 862887.6307443506, 862887.6307443506, 204037.042439798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6665400.0000, 
sim time next is 6666000.0000, 
raw observation next is [24.83333333333333, 95.0, 1.0, 2.0, 0.5671261544422777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 792505.6782678583, 792505.6782678589, 194775.735778482], 
processed observation next is [1.0, 0.13043478260869565, 0.3759873617693521, 0.95, 1.0, 1.0, 0.47846524631599713, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2201404661855162, 0.22014046618551636, 0.29071005340071937], 
reward next is 0.7093, 
noisyNet noise sample is [array([-2.143614], dtype=float32), -0.42633125]. 
=============================================
[2019-03-26 19:48:53,728] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.45843 ]
 [68.549904]
 [68.64959 ]
 [68.66852 ]
 [68.734406]], R is [[68.51200867]
 [68.52235413]
 [68.53611755]
 [68.54722595]
 [68.56468964]].
[2019-03-26 19:48:56,370] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5283418e-13 1.0000000e+00 7.5724357e-12 9.6957173e-12 3.1321237e-13], sum to 1.0000
[2019-03-26 19:48:56,380] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7847
[2019-03-26 19:48:56,391] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2056190.423498849 W.
[2019-03-26 19:48:56,395] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.06666666666667, 62.0, 1.0, 2.0, 0.4901907377908207, 1.0, 1.0, 0.4901907377908207, 1.0, 2.0, 0.8290755036650568, 6.9112, 6.9112, 170.5573041426782, 2056190.423498849, 2056190.423498849, 404429.4595725613], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6705600.0000, 
sim time next is 6706200.0000, 
raw observation next is [30.03333333333333, 62.5, 1.0, 2.0, 0.4885131945097581, 1.0, 2.0, 0.4885131945097581, 1.0, 2.0, 0.8278296625931516, 6.911200000000001, 6.9112, 170.5573041426782, 2049146.945972024, 2049146.945972024, 403615.169271498], 
processed observation next is [1.0, 0.6086956521739131, 0.622432859399684, 0.625, 1.0, 1.0, 0.3837508367587448, 1.0, 1.0, 0.3837508367587448, 1.0, 1.0, 0.7900361738940873, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5692074849922288, 0.5692074849922288, 0.6024107004052208], 
reward next is 0.3976, 
noisyNet noise sample is [array([0.9982049], dtype=float32), 0.37755936]. 
=============================================
[2019-03-26 19:49:09,154] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3884822e-18 1.0000000e+00 7.5691241e-17 2.4331397e-16 4.3453840e-19], sum to 1.0000
[2019-03-26 19:49:09,163] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7856
[2019-03-26 19:49:09,168] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.96666666666667, 89.66666666666666, 1.0, 2.0, 0.4177167231459037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 613994.5689308227, 613994.5689308232, 175586.1054938332], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6925800.0000, 
sim time next is 6926400.0000, 
raw observation next is [23.9, 90.0, 1.0, 2.0, 0.4165771048668537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 612831.3522172116, 612831.3522172116, 175490.061568499], 
processed observation next is [0.0, 0.17391304347826086, 0.33175355450236965, 0.9, 1.0, 1.0, 0.2970808492371731, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17023093117144766, 0.17023093117144766, 0.26192546502761044], 
reward next is 0.7381, 
noisyNet noise sample is [array([0.39613867], dtype=float32), -0.9154595]. 
=============================================
[2019-03-26 19:49:12,880] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.9513786e-21 1.0000000e+00 5.6182231e-18 1.2151842e-17 7.3270618e-20], sum to 1.0000
[2019-03-26 19:49:12,889] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7194
[2019-03-26 19:49:12,896] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.53333333333333, 66.66666666666667, 1.0, 2.0, 0.4144269176033511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 608711.9609456295, 608711.9609456295, 175072.9004370057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6990000.0000, 
sim time next is 6990600.0000, 
raw observation next is [27.41666666666666, 67.83333333333333, 1.0, 2.0, 0.4183159584869597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 612532.4056348385, 612532.4056348385, 175380.4542522756], 
processed observation next is [0.0, 0.9130434782608695, 0.4984202211690361, 0.6783333333333332, 1.0, 1.0, 0.2991758535987466, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17014789045412182, 0.17014789045412182, 0.2617618720183218], 
reward next is 0.7382, 
noisyNet noise sample is [array([0.97277164], dtype=float32), 1.3964994]. 
=============================================
[2019-03-26 19:49:15,051] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1839797e-20 1.0000000e+00 6.0865314e-18 3.0406475e-18 5.9210635e-20], sum to 1.0000
[2019-03-26 19:49:15,061] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0659
[2019-03-26 19:49:15,065] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 79.0, 1.0, 2.0, 0.5855903575358012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 837296.2155166777, 837296.215516677, 200529.5002674691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7021200.0000, 
sim time next is 7021800.0000, 
raw observation next is [26.35, 78.0, 1.0, 2.0, 0.5977991114801654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 854855.0022633283, 854855.0022633277, 202843.5922504146], 
processed observation next is [1.0, 0.2608695652173913, 0.4478672985781992, 0.78, 1.0, 1.0, 0.5154206162411631, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23745972285092454, 0.23745972285092437, 0.3027516302244994], 
reward next is 0.6972, 
noisyNet noise sample is [array([0.3189848], dtype=float32), 0.8453561]. 
=============================================
[2019-03-26 19:49:15,536] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-26 19:49:15,537] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:49:15,538] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:49:15,539] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:49:15,540] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:49:15,540] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:49:15,541] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:49:15,544] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:49:15,545] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:49:15,546] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:49:15,544] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:49:15,566] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run17
[2019-03-26 19:49:15,583] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run17
[2019-03-26 19:49:15,609] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run17
[2019-03-26 19:49:15,609] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run17
[2019-03-26 19:49:15,625] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run17
[2019-03-26 19:49:43,322] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05921049], dtype=float32), 0.061885834]
[2019-03-26 19:49:43,325] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.16666666666667, 89.66666666666666, 1.0, 2.0, 0.3817332303297106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 576854.1256120398, 576854.1256120398, 172650.8097071538]
[2019-03-26 19:49:43,325] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:49:43,330] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.3551159e-19 1.0000000e+00 1.0836811e-16 3.1690576e-16 1.8161176e-18], sampled 0.6992387991905706
[2019-03-26 19:49:51,900] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05921049], dtype=float32), 0.061885834]
[2019-03-26 19:49:51,906] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.3, 80.0, 1.0, 2.0, 0.5726442381513778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 800219.5880377964, 800219.5880377964, 195759.9957346452]
[2019-03-26 19:49:51,907] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:49:51,910] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.2644088e-21 1.0000000e+00 3.0231815e-19 1.9081748e-18 6.3846089e-21], sampled 0.35192945311550117
[2019-03-26 19:50:05,316] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05921049], dtype=float32), 0.061885834]
[2019-03-26 19:50:05,319] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.0, 72.0, 1.0, 2.0, 0.5350461803463259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 747661.1423160979, 747661.1423160972, 189270.173455255]
[2019-03-26 19:50:05,320] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:50:05,323] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1691696e-19 1.0000000e+00 1.8801981e-17 7.1309335e-17 4.1212899e-19], sampled 0.007373717358497678
[2019-03-26 19:50:06,940] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05921049], dtype=float32), 0.061885834]
[2019-03-26 19:50:06,941] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.56788245166667, 78.63359188666666, 1.0, 2.0, 0.5352262408849944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 747912.8433238264, 747912.8433238271, 189299.4480417905]
[2019-03-26 19:50:06,942] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:50:06,946] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.6601538e-21 1.0000000e+00 7.8580059e-19 4.5327814e-18 1.7343585e-20], sampled 0.37577112858491457
[2019-03-26 19:50:07,465] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05921049], dtype=float32), 0.061885834]
[2019-03-26 19:50:07,469] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.45, 84.0, 1.0, 2.0, 0.6277783149459266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 877296.3944237874, 877296.3944237867, 206025.7130306941]
[2019-03-26 19:50:07,470] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:50:07,472] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.4554945e-20 1.0000000e+00 1.5485925e-17 4.9726899e-17 2.7354398e-19], sampled 0.22260262212652193
[2019-03-26 19:50:14,965] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05921049], dtype=float32), 0.061885834]
[2019-03-26 19:50:14,967] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.66666666666667, 65.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 8.500124651128505, 6.9112, 168.9036748247824, 3418025.364243168, 2290849.47134295, 472384.8356354238]
[2019-03-26 19:50:14,968] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:50:14,971] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.5940815e-17 1.0000000e+00 2.0766791e-15 9.2995781e-15 1.4574016e-16], sampled 0.7528668729455467
[2019-03-26 19:50:14,972] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 3418025.364243168 W.
[2019-03-26 19:50:24,513] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05921049], dtype=float32), 0.061885834]
[2019-03-26 19:50:24,514] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.5, 46.0, 1.0, 2.0, 0.5171509128484197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722646.20386177, 722646.20386177, 186326.462411284]
[2019-03-26 19:50:24,516] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:50:24,521] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.0318971e-21 1.0000000e+00 4.4616370e-19 3.0501038e-18 1.2767543e-20], sampled 0.7914954316017878
[2019-03-26 19:50:58,287] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05921049], dtype=float32), 0.061885834]
[2019-03-26 19:50:58,291] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.02022825166667, 79.61062333333334, 1.0, 2.0, 0.365388044031228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 562945.4494296713, 562945.449429672, 171743.9764166109]
[2019-03-26 19:50:58,293] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:50:58,295] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.5757085e-20 1.0000000e+00 1.0939146e-17 2.9775068e-17 1.9241451e-19], sampled 0.9439939616487488
[2019-03-26 19:51:08,225] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05921049], dtype=float32), 0.061885834]
[2019-03-26 19:51:08,226] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.27689129, 68.46143072, 1.0, 2.0, 0.9453610688729287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.91295651043, 1379453.681034031, 1379453.681034031, 291406.9556104089]
[2019-03-26 19:51:08,226] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:51:08,228] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.4355399e-22 1.0000000e+00 1.3403981e-19 6.3506326e-19 2.4536580e-21], sampled 0.49175649172109936
[2019-03-26 19:51:09,928] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 19:51:10,036] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7281 2779199535.5119 933.0000
[2019-03-26 19:51:10,301] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.0766 3007691463.1510 1766.0000
[2019-03-26 19:51:10,365] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 19:51:10,396] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6466 2927350664.6004 1338.0000
[2019-03-26 19:51:11,411] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 400000, evaluation results [400000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8253.646569330924, 2927350664.600389, 1338.0, 8660.728066421085, 2779199535.5119066, 933.0, 7996.076579686626, 3007691463.1509957, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 19:51:15,200] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.8282110e-19 1.0000000e+00 2.4375315e-18 1.5498342e-16 2.7677476e-19], sum to 1.0000
[2019-03-26 19:51:15,207] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9348
[2019-03-26 19:51:15,215] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 72.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.050295756754078, 6.9112, 168.9119923231301, 1574211.495455671, 1475532.741588167, 314828.173526949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7117200.0000, 
sim time next is 7117800.0000, 
raw observation next is [27.6, 71.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.865800084982329, 6.9112, 168.9075676307972, 2151868.761937186, 1474664.212596213, 314626.0437618887], 
processed observation next is [1.0, 0.391304347826087, 0.5071090047393366, 0.7166666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.09546000849823288, 0.0, 0.8294134832862609, 0.5977413227603294, 0.4096289479433925, 0.4695911100923712], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.46500054], dtype=float32), -0.8459873]. 
=============================================
[2019-03-26 19:51:20,399] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6485993e-18 1.0000000e+00 3.4585319e-16 1.8978186e-15 8.5268606e-18], sum to 1.0000
[2019-03-26 19:51:20,408] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6113
[2019-03-26 19:51:20,419] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2048237.739469575 W.
[2019-03-26 19:51:20,424] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 83.16666666666667, 1.0, 2.0, 0.4882966482206731, 1.0, 1.0, 0.4882966482206731, 1.0, 2.0, 0.8480097957901503, 6.9112, 6.9112, 170.5573041426782, 2048237.739469575, 2048237.739469575, 407147.4158852476], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7204200.0000, 
sim time next is 7204800.0000, 
raw observation next is [29.0, 82.33333333333334, 1.0, 2.0, 0.6923012553699236, 1.0, 2.0, 0.6923012553699236, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1935876.854578043, 1935876.854578043, 370851.5704089983], 
processed observation next is [1.0, 0.391304347826087, 0.5734597156398105, 0.8233333333333335, 1.0, 1.0, 0.6292786209276188, 1.0, 1.0, 0.6292786209276188, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5377435707161231, 0.5377435707161231, 0.5535098065805945], 
reward next is 0.4465, 
noisyNet noise sample is [array([-0.8638154], dtype=float32), 0.80068624]. 
=============================================
[2019-03-26 19:51:22,590] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.0042436e-20 1.0000000e+00 5.4749873e-18 1.6053195e-17 1.5501866e-19], sum to 1.0000
[2019-03-26 19:51:22,598] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9103
[2019-03-26 19:51:22,604] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 83.5, 1.0, 2.0, 0.871551739259961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1303050.687787422, 1303050.687787421, 274202.9493284149], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7230600.0000, 
sim time next is 7231200.0000, 
raw observation next is [24.33333333333334, 82.66666666666667, 1.0, 2.0, 0.8681887734308278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1301619.070462619, 1301619.070462619, 273715.6453515906], 
processed observation next is [1.0, 0.6956521739130435, 0.35229067930489766, 0.8266666666666667, 1.0, 1.0, 0.841191293290154, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.36156085290628304, 0.36156085290628304, 0.4085308139575979], 
reward next is 0.5915, 
noisyNet noise sample is [array([-0.17995039], dtype=float32), 0.17388897]. 
=============================================
[2019-03-26 19:51:23,329] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.4702241e-18 1.0000000e+00 5.3808869e-16 1.2252863e-15 2.1115849e-18], sum to 1.0000
[2019-03-26 19:51:23,337] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2894
[2019-03-26 19:51:23,343] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.85, 88.0, 1.0, 2.0, 0.3243149078412004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 511550.5761409131, 511550.5761409138, 167874.7034761465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7281000.0000, 
sim time next is 7281600.0000, 
raw observation next is [21.9, 87.66666666666667, 1.0, 2.0, 0.32384633556991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 510724.8929599915, 510724.8929599921, 167809.770943136], 
processed observation next is [1.0, 0.2608695652173913, 0.23696682464454974, 0.8766666666666667, 1.0, 1.0, 0.18535703080712046, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14186802582221986, 0.14186802582222002, 0.2504623446912478], 
reward next is 0.7495, 
noisyNet noise sample is [array([1.1855236], dtype=float32), -0.21460553]. 
=============================================
[2019-03-26 19:51:24,957] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.6053576e-18 1.0000000e+00 3.2916550e-16 1.9792543e-15 3.0353744e-18], sum to 1.0000
[2019-03-26 19:51:24,966] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0032
[2019-03-26 19:51:24,973] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.63333333333333, 89.66666666666667, 1.0, 2.0, 0.3310579444283711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 522246.5324323068, 522246.5324323062, 168702.9998408542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7270800.0000, 
sim time next is 7271400.0000, 
raw observation next is [21.61666666666667, 89.83333333333333, 1.0, 2.0, 0.3282927001426869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 517834.9143904585, 517834.9143904591, 168359.0085167426], 
processed observation next is [1.0, 0.13043478260869565, 0.22353870458135885, 0.8983333333333333, 1.0, 1.0, 0.1907140965574541, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14384303177512736, 0.14384303177512753, 0.2512821022637949], 
reward next is 0.7487, 
noisyNet noise sample is [array([-0.74322695], dtype=float32), 2.3602133]. 
=============================================
[2019-03-26 19:51:25,979] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6655462e-20 1.0000000e+00 2.6274074e-19 8.1112859e-18 1.7495355e-20], sum to 1.0000
[2019-03-26 19:51:25,988] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5797
[2019-03-26 19:51:25,993] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.86666666666667, 59.0, 1.0, 2.0, 0.5469681215190736, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9581572722657448, 6.9112, 6.9112, 168.9127464997505, 1648931.145085765, 1648931.145085765, 345106.5565319973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7310400.0000, 
sim time next is 7311000.0000, 
raw observation next is [27.83333333333334, 59.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.15293579318967, 6.9112, 168.9114645934991, 1744184.825315209, 1572690.648451388, 329547.3156867361], 
processed observation next is [1.0, 0.6086956521739131, 0.5181674565560824, 0.595, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.024173579318966975, 0.0, 0.8294326191571645, 0.4844957848097803, 0.4368585134587189, 0.4918616652040837], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5968661], dtype=float32), 0.7710906]. 
=============================================
[2019-03-26 19:51:26,015] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[77.51412 ]
 [79.117256]
 [78.86098 ]
 [78.63438 ]
 [78.342384]], R is [[76.66648102]
 [76.38473511]
 [75.62088776]
 [75.1025238 ]
 [74.87677765]].
[2019-03-26 19:51:32,381] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8888641e-21 1.0000000e+00 4.5031015e-19 1.6675934e-18 3.3100068e-20], sum to 1.0000
[2019-03-26 19:51:32,395] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2922
[2019-03-26 19:51:32,400] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.76666666666667, 91.33333333333334, 1.0, 2.0, 0.5568043743383154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 890735.134253962, 890735.1342539614, 205559.217615906], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7396800.0000, 
sim time next is 7397400.0000, 
raw observation next is [20.73333333333333, 91.16666666666667, 1.0, 2.0, 0.5776088857498417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 924981.165246668, 924981.165246668, 209820.0580557807], 
processed observation next is [1.0, 0.6086956521739131, 0.18167456556082143, 0.9116666666666667, 1.0, 1.0, 0.4910950430720984, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2569392125685189, 0.2569392125685189, 0.3131642657548966], 
reward next is 0.6868, 
noisyNet noise sample is [array([-2.4423778], dtype=float32), 0.81518155]. 
=============================================
[2019-03-26 19:51:38,484] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0112521e-21 1.0000000e+00 8.3271083e-19 1.6973599e-18 6.0471814e-20], sum to 1.0000
[2019-03-26 19:51:38,494] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0414
[2019-03-26 19:51:38,498] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.43333333333333, 80.0, 1.0, 2.0, 0.4123104407429036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 603519.7908392458, 603519.7908392464, 174521.6613810738], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7497600.0000, 
sim time next is 7498200.0000, 
raw observation next is [25.31666666666667, 80.5, 1.0, 2.0, 0.4102745150565296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 601467.1663904247, 601467.1663904247, 174357.7980464165], 
processed observation next is [0.0, 0.782608695652174, 0.39889415481832563, 0.805, 1.0, 1.0, 0.2894873675379875, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1670742128862291, 0.1670742128862291, 0.2602355194722634], 
reward next is 0.7398, 
noisyNet noise sample is [array([0.6747626], dtype=float32), -0.25849488]. 
=============================================
[2019-03-26 19:51:39,914] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.3754888e-20 1.0000000e+00 4.4664924e-18 4.3559771e-17 1.8545380e-19], sum to 1.0000
[2019-03-26 19:51:39,922] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4144
[2019-03-26 19:51:39,926] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 93.0, 1.0, 2.0, 0.4055862931466801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 597113.5328769247, 597113.5328769247, 174031.1522881732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7521000.0000, 
sim time next is 7521600.0000, 
raw observation next is [23.5, 93.0, 1.0, 2.0, 0.4052288579085293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 596593.7991905018, 596593.7991905018, 173983.2925343863], 
processed observation next is [0.0, 0.043478260869565216, 0.31279620853080575, 0.93, 1.0, 1.0, 0.28340826254039675, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1657204997751394, 0.1657204997751394, 0.2596765560214721], 
reward next is 0.7403, 
noisyNet noise sample is [array([0.15004037], dtype=float32), 0.24195799]. 
=============================================
[2019-03-26 19:51:42,898] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9706372e-20 1.0000000e+00 7.4744048e-18 1.9718433e-18 2.6144685e-20], sum to 1.0000
[2019-03-26 19:51:42,909] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0683
[2019-03-26 19:51:42,914] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 95.0, 1.0, 2.0, 0.5300940610091275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 763228.287883301, 763228.2878833016, 191303.9255806483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7612200.0000, 
sim time next is 7612800.0000, 
raw observation next is [23.76666666666667, 95.0, 1.0, 2.0, 0.5236451941342106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 755012.724271016, 755012.724271016, 190340.6590097879], 
processed observation next is [1.0, 0.08695652173913043, 0.32543443917851517, 0.95, 1.0, 1.0, 0.4260785471496513, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20972575674194888, 0.20972575674194888, 0.2840905358355043], 
reward next is 0.7159, 
noisyNet noise sample is [array([0.22489421], dtype=float32), 1.3161705]. 
=============================================
[2019-03-26 19:51:44,037] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.08825035e-21 1.00000000e+00 1.11554911e-18 1.06664775e-17
 3.41832324e-20], sum to 1.0000
[2019-03-26 19:51:44,048] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5010
[2019-03-26 19:51:44,054] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.86666666666667, 87.66666666666667, 1.0, 2.0, 0.4889998492040688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 683296.3707179198, 683296.3707179191, 181890.3967815603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7591800.0000, 
sim time next is 7592400.0000, 
raw observation next is [25.8, 88.0, 1.0, 2.0, 0.4895780379250799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 684104.5539272211, 684104.5539272205, 181979.0735598011], 
processed observation next is [0.0, 0.9130434782608695, 0.42180094786729866, 0.88, 1.0, 1.0, 0.3850337806326264, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1900290427575614, 0.19002904275756125, 0.2716105575519419], 
reward next is 0.7284, 
noisyNet noise sample is [array([0.9337822], dtype=float32), -0.22026187]. 
=============================================
[2019-03-26 19:51:48,080] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9055181e-16 1.0000000e+00 3.5447670e-15 4.9001337e-14 4.3827811e-16], sum to 1.0000
[2019-03-26 19:51:48,088] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2624
[2019-03-26 19:51:48,097] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1769927.922432672 W.
[2019-03-26 19:51:48,104] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.7, 75.0, 1.0, 2.0, 0.6330041763594831, 1.0, 2.0, 0.6330041763594831, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1769927.922432672, 1769927.922432672, 346758.1678247926], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7664400.0000, 
sim time next is 7665000.0000, 
raw observation next is [28.55, 75.66666666666667, 1.0, 2.0, 0.2137140057038233, 1.0, 2.0, 0.2137140057038233, 1.0, 1.0, 0.3645497942321031, 6.911200000000001, 6.9112, 170.5573041426782, 895975.8952359201, 895975.8952359195, 273372.4198518081], 
processed observation next is [1.0, 0.7391304347826086, 0.552132701421801, 0.7566666666666667, 1.0, 1.0, 0.05266747675159431, 1.0, 1.0, 0.05266747675159431, 1.0, 0.5, 0.22506072467329646, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.24888219312108892, 0.24888219312108875, 0.4080185370922509], 
reward next is 0.5920, 
noisyNet noise sample is [array([0.45733565], dtype=float32), 0.8257063]. 
=============================================
[2019-03-26 19:51:48,115] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[58.458942]
 [57.470848]
 [57.705948]
 [58.460274]
 [58.264893]], R is [[58.05401611]
 [57.95592499]
 [57.85358047]
 [57.27504349]
 [56.7022934 ]].
[2019-03-26 19:51:56,481] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:51:56,483] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:51:56,532] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run3
[2019-03-26 19:52:02,832] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:02,832] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:02,859] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run3
[2019-03-26 19:52:03,637] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:03,638] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:03,659] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run3
[2019-03-26 19:52:04,417] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:04,417] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:04,423] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run3
[2019-03-26 19:52:04,777] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:04,778] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:04,792] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run3
[2019-03-26 19:52:04,840] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:04,841] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:04,857] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run3
[2019-03-26 19:52:05,011] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:05,011] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:05,025] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run3
[2019-03-26 19:52:05,075] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:05,075] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:05,088] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run3
[2019-03-26 19:52:05,151] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:05,152] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:05,162] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run3
[2019-03-26 19:52:05,163] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:05,178] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:05,185] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:05,186] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:05,194] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:05,194] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:05,203] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run3
[2019-03-26 19:52:05,205] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:05,206] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run3
[2019-03-26 19:52:05,206] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:05,246] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:05,247] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:05,250] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:05,248] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:05,246] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run3
[2019-03-26 19:52:05,277] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run3
[2019-03-26 19:52:05,293] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run3
[2019-03-26 19:52:05,295] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 19:52:05,296] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:05,321] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run3
[2019-03-26 19:52:05,356] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run3
[2019-03-26 19:52:06,302] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 19:52:06,304] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:52:06,305] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:06,306] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run18
[2019-03-26 19:52:06,348] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:52:06,349] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:06,350] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run18
[2019-03-26 19:52:06,391] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:52:06,392] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:06,393] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run18
[2019-03-26 19:52:06,473] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:52:06,473] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:06,475] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run18
[2019-03-26 19:52:06,526] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:52:06,526] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:52:06,528] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run18
[2019-03-26 19:52:12,655] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06111745], dtype=float32), 0.06350275]
[2019-03-26 19:52:12,656] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.5, 67.5, 1.0, 2.0, 0.2389830045320122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 396234.6210847562, 396234.6210847569, 159659.9616555557]
[2019-03-26 19:52:12,657] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:52:12,660] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.48977589e-18 1.00000000e+00 6.51283580e-16 1.94931970e-15
 1.35109795e-17], sampled 0.5995541598541746
[2019-03-26 19:52:42,363] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06111745], dtype=float32), 0.06350275]
[2019-03-26 19:52:42,365] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.9, 67.33333333333334, 1.0, 2.0, 0.4933085302763801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 735219.0766219446, 735219.0766219452, 188251.3169994063]
[2019-03-26 19:52:42,368] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:52:42,370] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.8782955e-20 1.0000000e+00 3.4637965e-18 1.5014225e-17 6.8682661e-20], sampled 0.03457080012524094
[2019-03-26 19:52:44,087] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06111745], dtype=float32), 0.06350275]
[2019-03-26 19:52:44,088] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.27251383, 79.33985786, 1.0, 2.0, 0.6904564421865076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 964926.4912333217, 964926.4912333217, 218801.0484692432]
[2019-03-26 19:52:44,090] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:52:44,092] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.5941026e-21 1.0000000e+00 1.0464793e-18 4.4093231e-18 1.7381535e-20], sampled 0.009758172847089797
[2019-03-26 19:52:49,399] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06111745], dtype=float32), 0.06350275]
[2019-03-26 19:52:49,400] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.41666666666666, 79.66666666666667, 1.0, 2.0, 0.5962280057221058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 833188.7397804743, 833188.7397804743, 200038.5179753048]
[2019-03-26 19:52:49,402] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:52:49,406] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.0000852e-20 1.0000000e+00 7.7767782e-18 2.3329656e-17 1.2919923e-19], sampled 0.2479922896247495
[2019-03-26 19:53:23,128] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06111745], dtype=float32), 0.06350275]
[2019-03-26 19:53:23,130] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.51331567833333, 75.18405805666667, 1.0, 2.0, 0.6882076395287314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 961782.3220983496, 961782.322098349, 218316.8536132956]
[2019-03-26 19:53:23,130] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:53:23,135] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.3232578e-21 1.0000000e+00 1.5515659e-18 5.0609673e-18 3.4436224e-20], sampled 0.8316997404254081
[2019-03-26 19:53:47,272] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06111745], dtype=float32), 0.06350275]
[2019-03-26 19:53:47,275] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.8, 84.66666666666667, 1.0, 2.0, 0.4240072970887338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 619883.8812531757, 619883.8812531751, 176057.0589635421]
[2019-03-26 19:53:47,276] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:53:47,279] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.3113849e-20 1.0000000e+00 8.4139323e-18 3.8221154e-17 1.8719874e-19], sampled 0.5991358469925003
[2019-03-26 19:54:00,807] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.5921 2779214994.0068 933.0000
[2019-03-26 19:54:00,948] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.0653 2927317329.7462 1338.0000
[2019-03-26 19:54:01,133] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.4166 2842558242.3972 1131.0000
[2019-03-26 19:54:01,242] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164071917.9177 1778.0000
[2019-03-26 19:54:01,252] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.3130 3007656030.3370 1766.0000
[2019-03-26 19:54:02,267] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 425000, evaluation results [425000.0, 7884.168443086554, 3164071917.9176674, 1778.0, 8255.065342017213, 2927317329.746172, 1338.0, 8660.592086161303, 2779214994.0067887, 933.0, 7998.312951428424, 3007656030.3370423, 1766.0, 8497.416582222564, 2842558242.397172, 1131.0]
[2019-03-26 19:54:06,822] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.6520017e-20 1.0000000e+00 3.2964016e-18 1.6768119e-17 3.7802474e-20], sum to 1.0000
[2019-03-26 19:54:06,836] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8839
[2019-03-26 19:54:06,838] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.28333333333333, 88.66666666666667, 1.0, 2.0, 0.3438367295255514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 535122.9142332589, 535122.9142332589, 169570.2271388917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 82200.0000, 
sim time next is 82800.0000, 
raw observation next is [22.2, 89.0, 1.0, 2.0, 0.3420326641599545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 532885.1997642361, 532885.1997642361, 169404.0686306888], 
processed observation next is [1.0, 1.0, 0.2511848341232228, 0.89, 1.0, 1.0, 0.2072682700722343, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1480236666011767, 0.1480236666011767, 0.25284189347864], 
reward next is 0.7472, 
noisyNet noise sample is [array([1.9817569], dtype=float32), -0.2886709]. 
=============================================
[2019-03-26 19:54:13,714] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.3186573e-19 1.0000000e+00 4.6899437e-17 4.2145881e-17 8.9752198e-19], sum to 1.0000
[2019-03-26 19:54:13,726] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3588
[2019-03-26 19:54:13,731] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 93.0, 1.0, 2.0, 0.2927604075809669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 469301.1687311629, 469301.1687311629, 164903.6486414795], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 205200.0000, 
sim time next is 205800.0000, 
raw observation next is [20.53333333333333, 93.0, 1.0, 2.0, 0.2935388023309903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 470281.9536565233, 470281.9536565239, 164969.8636236899], 
processed observation next is [0.0, 0.391304347826087, 0.17219589257503945, 0.93, 1.0, 1.0, 0.1488419305192654, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13063387601570092, 0.1306338760157011, 0.24622367705028342], 
reward next is 0.7538, 
noisyNet noise sample is [array([-0.26260087], dtype=float32), 1.0051402]. 
=============================================
[2019-03-26 19:54:17,249] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.8363591e-19 1.0000000e+00 8.9487681e-17 7.2051719e-17 1.0448718e-18], sum to 1.0000
[2019-03-26 19:54:17,259] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5839
[2019-03-26 19:54:17,266] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 92.66666666666667, 1.0, 2.0, 0.2846646876911634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 457752.9761656316, 457752.9761656316, 164118.6441627186], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 267600.0000, 
sim time next is 268200.0000, 
raw observation next is [20.3, 93.0, 1.0, 2.0, 0.2839837324739529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 456896.6056773736, 456896.6056773742, 164061.5322567067], 
processed observation next is [0.0, 0.08695652173913043, 0.16113744075829392, 0.93, 1.0, 1.0, 0.13732979816138904, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12691572379927044, 0.1269157237992706, 0.24486795859209956], 
reward next is 0.7551, 
noisyNet noise sample is [array([-0.9364947], dtype=float32), -0.36944553]. 
=============================================
[2019-03-26 19:54:17,843] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2708905e-18 1.0000000e+00 2.1637161e-16 5.1831248e-16 2.5866744e-18], sum to 1.0000
[2019-03-26 19:54:17,853] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3238
[2019-03-26 19:54:17,863] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.85, 94.5, 1.0, 2.0, 0.2754767701685673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 445380.6546891804, 445380.6546891811, 163291.4703041285], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 271800.0000, 
sim time next is 272400.0000, 
raw observation next is [19.76666666666667, 94.66666666666666, 1.0, 2.0, 0.2734517028126561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 442613.6084806612, 442613.6084806618, 163106.7859766746], 
processed observation next is [0.0, 0.13043478260869565, 0.13586097946287537, 0.9466666666666665, 1.0, 1.0, 0.12464060579838081, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12294822457796144, 0.12294822457796162, 0.24344296414429045], 
reward next is 0.7566, 
noisyNet noise sample is [array([-1.4464068], dtype=float32), -0.47595698]. 
=============================================
[2019-03-26 19:54:23,416] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8392147e-19 1.0000000e+00 1.4624750e-16 3.1613645e-17 1.3682340e-18], sum to 1.0000
[2019-03-26 19:54:23,426] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8930
[2019-03-26 19:54:23,432] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 86.5, 1.0, 2.0, 0.2609633783394137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 425208.3495388778, 425208.3495388784, 161948.2201520966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 367800.0000, 
sim time next is 368400.0000, 
raw observation next is [20.43333333333333, 86.0, 1.0, 2.0, 0.258034591050252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 420407.3492760002, 420407.3492760009, 161650.391173464], 
processed observation next is [1.0, 0.2608695652173913, 0.1674565560821484, 0.86, 1.0, 1.0, 0.1060657723497012, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1167798192433334, 0.1167798192433336, 0.24126924055740898], 
reward next is 0.7587, 
noisyNet noise sample is [array([0.3542886], dtype=float32), -1.5004483]. 
=============================================
[2019-03-26 19:54:32,168] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.9027997e-21 1.0000000e+00 4.5469998e-18 8.8559520e-18 2.7165128e-20], sum to 1.0000
[2019-03-26 19:54:32,182] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6819
[2019-03-26 19:54:32,187] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.15, 85.5, 1.0, 2.0, 0.2350162099216474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 389299.1388566919, 389299.1388566919, 159325.0359620243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 513000.0000, 
sim time next is 513600.0000, 
raw observation next is [19.06666666666666, 86.0, 1.0, 2.0, 0.2341557513240907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 387957.2324333502, 387957.2324333495, 159236.4573550978], 
processed observation next is [1.0, 0.9565217391304348, 0.10268562401263795, 0.86, 1.0, 1.0, 0.07729608593263938, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10776589789815283, 0.10776589789815263, 0.23766635426134], 
reward next is 0.7623, 
noisyNet noise sample is [array([-0.10613801], dtype=float32), -0.894553]. 
=============================================
[2019-03-26 19:54:41,440] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.2311213e-21 1.0000000e+00 6.2701604e-19 2.6938334e-18 1.0592218e-20], sum to 1.0000
[2019-03-26 19:54:41,449] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4248
[2019-03-26 19:54:41,455] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.96666666666667, 62.66666666666667, 1.0, 2.0, 0.2497542569032178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 411159.580403137, 411159.5804031377, 160874.469992949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 670800.0000, 
sim time next is 671400.0000, 
raw observation next is [22.75, 64.0, 1.0, 2.0, 0.2477770852107169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 407900.3416524674, 407900.341652468, 160680.6588433189], 
processed observation next is [1.0, 0.782608695652174, 0.27725118483412325, 0.64, 1.0, 1.0, 0.09370733157917698, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11330565045901872, 0.1133056504590189, 0.23982187887062523], 
reward next is 0.7602, 
noisyNet noise sample is [array([0.9537367], dtype=float32), -0.03282666]. 
=============================================
[2019-03-26 19:54:57,300] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 19:54:57,303] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:54:57,304] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:54:57,304] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:54:57,305] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:54:57,306] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:54:57,304] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:54:57,306] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:54:57,311] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:54:57,309] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:54:57,311] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:54:57,326] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run19
[2019-03-26 19:54:57,343] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run19
[2019-03-26 19:54:57,365] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run19
[2019-03-26 19:54:57,366] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run19
[2019-03-26 19:54:57,401] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run19
[2019-03-26 19:55:05,953] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06728558], dtype=float32), 0.06944348]
[2019-03-26 19:55:05,956] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.4, 75.0, 1.0, 2.0, 0.2877483491362977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 464776.1418924236, 464776.1418924242, 164595.6741045941]
[2019-03-26 19:55:05,958] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:55:05,961] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.2270095e-22 1.0000000e+00 1.7137480e-19 8.5675475e-19 2.2506326e-21], sampled 0.2910294475113331
[2019-03-26 19:55:11,977] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06728558], dtype=float32), 0.06944348]
[2019-03-26 19:55:11,979] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.26666666666667, 83.16666666666667, 1.0, 2.0, 0.3528521330088455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 545528.8790141412, 545528.8790141412, 170328.3782700332]
[2019-03-26 19:55:11,981] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:55:11,984] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.8910427e-22 1.0000000e+00 1.3107421e-19 7.0221663e-19 1.7090133e-21], sampled 0.5556514950228093
[2019-03-26 19:55:50,397] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06728558], dtype=float32), 0.06944348]
[2019-03-26 19:55:50,398] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.04237875, 76.55597132666668, 1.0, 2.0, 0.7812632521670521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1091896.040711273, 1091896.040711273, 239366.6320025753]
[2019-03-26 19:55:50,399] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:55:50,401] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.9881575e-22 1.0000000e+00 2.9306487e-19 1.0083915e-18 2.7745738e-21], sampled 0.06270183923524364
[2019-03-26 19:55:58,934] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06728558], dtype=float32), 0.06944348]
[2019-03-26 19:55:58,935] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.83333333333334, 84.83333333333333, 1.0, 2.0, 0.5806682511980742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 811436.7183846717, 811436.7183846717, 197199.6546098688]
[2019-03-26 19:55:58,937] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:55:58,940] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.0871790e-24 1.0000000e+00 2.1352014e-21 1.8219794e-20 2.9465832e-23], sampled 0.5383081958649533
[2019-03-26 19:56:06,544] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06728558], dtype=float32), 0.06944348]
[2019-03-26 19:56:06,546] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.23333333333333, 59.66666666666667, 1.0, 2.0, 0.5782666207506277, 0.0, 2.0, 0.0, 1.0, 2.0, 0.989869502266446, 6.911199999999999, 6.9112, 168.912930643303, 1616773.963280848, 1616773.963280849, 350790.2468031103]
[2019-03-26 19:56:06,548] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:56:06,551] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.7947431e-21 1.0000000e+00 1.1755161e-18 9.5688485e-18 3.8223573e-20], sampled 0.48506894035377324
[2019-03-26 19:56:14,417] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06728558], dtype=float32), 0.06944348]
[2019-03-26 19:56:14,418] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.57122835, 64.59482235666667, 1.0, 2.0, 0.9574800222568087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1338332.384873556, 1338332.384873556, 286239.5444864454]
[2019-03-26 19:56:14,419] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:56:14,427] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.5955129e-24 1.0000000e+00 1.1484764e-21 7.3059581e-21 1.3095600e-23], sampled 0.5203962656821803
[2019-03-26 19:56:24,323] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06728558], dtype=float32), 0.06944348]
[2019-03-26 19:56:24,325] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.36215347, 74.68111176, 1.0, 2.0, 0.5596482119719388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104262, 782052.1072080545, 782052.1072080551, 193470.4491103898]
[2019-03-26 19:56:24,328] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:56:24,331] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.2115920e-20 1.0000000e+00 3.4927217e-18 1.7367246e-17 7.3393422e-20], sampled 0.005393800214342326
[2019-03-26 19:56:52,417] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 19:56:52,429] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8724 2842497929.8887 1131.0000
[2019-03-26 19:56:52,487] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.2362 2779138868.9993 933.0000
[2019-03-26 19:56:52,488] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4187 3164052187.7637 1778.0000
[2019-03-26 19:56:52,558] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.0653 2927317329.7462 1338.0000
[2019-03-26 19:56:53,573] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 450000, evaluation results [450000.0, 7883.418744751638, 3164052187.7636957, 1778.0, 8255.065342017213, 2927317329.746172, 1338.0, 8659.23621041285, 2779138868.999297, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8496.87235025343, 2842497929.888741, 1131.0]
[2019-03-26 19:56:54,342] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6617067e-19 1.0000000e+00 1.0570438e-17 1.3222445e-16 8.8193687e-19], sum to 1.0000
[2019-03-26 19:56:54,354] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9244
[2019-03-26 19:56:54,361] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.05, 79.33333333333334, 1.0, 2.0, 0.4675282410209698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 653284.125842108, 653284.1258421086, 178665.6062579418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1273800.0000, 
sim time next is 1274400.0000, 
raw observation next is [26.9, 80.0, 1.0, 2.0, 0.4722703246041702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 659912.3674762726, 659912.3674762732, 179365.9376944303], 
processed observation next is [1.0, 0.782608695652174, 0.4739336492890995, 0.8, 1.0, 1.0, 0.3641811139809279, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18330899096563127, 0.18330899096563144, 0.2677103547678064], 
reward next is 0.7323, 
noisyNet noise sample is [array([-2.433145], dtype=float32), -0.0014274601]. 
=============================================
[2019-03-26 19:56:57,004] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2176504e-21 1.0000000e+00 3.9341077e-19 4.2906324e-19 5.7146371e-22], sum to 1.0000
[2019-03-26 19:56:57,010] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0549
[2019-03-26 19:56:57,037] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 95.0, 1.0, 2.0, 0.4102773023912795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 634948.3089447392, 634948.3089447386, 178232.2694986775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 997200.0000, 
sim time next is 997800.0000, 
raw observation next is [21.68333333333333, 95.16666666666667, 1.0, 2.0, 0.3863456947753357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 598072.0404958345, 598072.0404958345, 174882.9244018733], 
processed observation next is [1.0, 0.5652173913043478, 0.22669826224328585, 0.9516666666666667, 1.0, 1.0, 0.2606574635847418, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16613112235995403, 0.16613112235995403, 0.26101929015204967], 
reward next is 0.7390, 
noisyNet noise sample is [array([0.42582256], dtype=float32), 0.7846402]. 
=============================================
[2019-03-26 19:57:03,124] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.8731936e-20 1.0000000e+00 1.7205154e-18 3.5281681e-18 5.6083246e-20], sum to 1.0000
[2019-03-26 19:57:03,135] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7845
[2019-03-26 19:57:03,141] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 93.0, 1.0, 2.0, 0.5285086589159383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 753666.2896072889, 753666.2896072895, 190117.0290542869], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1306800.0000, 
sim time next is 1307400.0000, 
raw observation next is [24.33333333333333, 92.83333333333333, 1.0, 2.0, 0.5427297502722095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 773743.6861823428, 773743.6861823434, 192522.4575212592], 
processed observation next is [1.0, 0.13043478260869565, 0.35229067930489716, 0.9283333333333332, 1.0, 1.0, 0.44907198827977046, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21492880171731746, 0.21492880171731762, 0.2873469515242675], 
reward next is 0.7127, 
noisyNet noise sample is [array([0.9695765], dtype=float32), -1.0164219]. 
=============================================
[2019-03-26 19:57:05,258] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.9859644e-22 1.0000000e+00 1.8701103e-19 3.5896787e-19 1.1328771e-21], sum to 1.0000
[2019-03-26 19:57:05,274] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2353
[2019-03-26 19:57:05,278] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 91.0, 1.0, 2.0, 0.562827691920754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 875034.8951867357, 875034.8951867357, 204526.2362519844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1342800.0000, 
sim time next is 1343400.0000, 
raw observation next is [21.91666666666667, 90.50000000000001, 1.0, 2.0, 0.5491828657643029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 856840.7394381252, 856840.7394381252, 202185.1770847914], 
processed observation next is [1.0, 0.5652173913043478, 0.23775671406003188, 0.9050000000000001, 1.0, 1.0, 0.45684682622205164, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23801131651059032, 0.23801131651059032, 0.3017689210220767], 
reward next is 0.6982, 
noisyNet noise sample is [array([0.14566137], dtype=float32), -1.6694459]. 
=============================================
[2019-03-26 19:57:08,578] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.1173095e-22 1.0000000e+00 1.1727884e-18 6.8822258e-18 2.8377933e-21], sum to 1.0000
[2019-03-26 19:57:08,590] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0130
[2019-03-26 19:57:08,595] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 85.33333333333334, 1.0, 2.0, 0.3554413071659422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 547751.2515474142, 547751.2515474149, 170464.3484644801], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1204800.0000, 
sim time next is 1205400.0000, 
raw observation next is [23.0, 86.16666666666666, 1.0, 2.0, 0.3560965178943104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 548579.436239281, 548579.436239281, 170528.3612299317], 
processed observation next is [1.0, 0.9565217391304348, 0.28909952606635075, 0.8616666666666666, 1.0, 1.0, 0.22421267216181975, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1523831767331336, 0.1523831767331336, 0.2545199421342264], 
reward next is 0.7455, 
noisyNet noise sample is [array([0.21568042], dtype=float32), 0.31534064]. 
=============================================
[2019-03-26 19:57:10,984] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.5404303e-21 1.0000000e+00 2.4424460e-18 4.7332541e-19 3.5216815e-21], sum to 1.0000
[2019-03-26 19:57:10,992] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6046
[2019-03-26 19:57:11,002] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.23333333333334, 73.66666666666667, 1.0, 2.0, 0.586624993963457, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9821851794979696, 6.911200000000001, 6.9112, 168.9126160012299, 1654672.817811926, 1654672.817811925, 352071.2666277591], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1246800.0000, 
sim time next is 1247400.0000, 
raw observation next is [27.45, 73.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 8.427819295231911, 6.9112, 168.9043175481157, 2544361.943899262, 1468475.046325171, 312858.0191178528], 
processed observation next is [1.0, 0.43478260869565216, 0.5, 0.73, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.15166192952319113, 0.0, 0.8293975238924005, 0.706767206638684, 0.40790973509032524, 0.4669522673400788], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7507211], dtype=float32), 0.93416727]. 
=============================================
[2019-03-26 19:57:19,688] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.7580442e-20 1.0000000e+00 1.4626082e-17 7.4648921e-17 2.0361977e-19], sum to 1.0000
[2019-03-26 19:57:19,694] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6191
[2019-03-26 19:57:19,698] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.26666666666667, 98.0, 1.0, 2.0, 0.3050233257361261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 485352.8525933396, 485352.8525933389, 166001.3273036943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1392000.0000, 
sim time next is 1392600.0000, 
raw observation next is [20.28333333333333, 98.0, 1.0, 2.0, 0.3052578858737106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 485545.4604064184, 485545.460406419, 166012.4568929832], 
processed observation next is [0.0, 0.08695652173913043, 0.16034755134281198, 0.98, 1.0, 1.0, 0.16296130828157904, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1348737390017829, 0.13487373900178307, 0.2477797864074376], 
reward next is 0.7522, 
noisyNet noise sample is [array([-0.16091628], dtype=float32), 1.1882353]. 
=============================================
[2019-03-26 19:57:27,043] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.3056234e-20 1.0000000e+00 3.5999258e-17 1.3726476e-16 3.9584196e-19], sum to 1.0000
[2019-03-26 19:57:27,049] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8019
[2019-03-26 19:57:27,054] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.1, 51.0, 1.0, 2.0, 0.3480171406727051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 534257.5264887547, 534257.5264887554, 169288.3780549595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1512000.0000, 
sim time next is 1512600.0000, 
raw observation next is [29.16666666666667, 51.0, 1.0, 2.0, 0.3501266927854602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 536672.4447150303, 536672.4447150296, 169459.796027057], 
processed observation next is [0.0, 0.5217391304347826, 0.581358609794629, 0.51, 1.0, 1.0, 0.2170201117897111, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1490756790875084, 0.1490756790875082, 0.25292506869709996], 
reward next is 0.7471, 
noisyNet noise sample is [array([0.25235927], dtype=float32), -0.3023281]. 
=============================================
[2019-03-26 19:57:30,488] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.1236478e-20 1.0000000e+00 4.1197850e-17 9.3210556e-17 1.1666657e-19], sum to 1.0000
[2019-03-26 19:57:30,497] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3853
[2019-03-26 19:57:30,507] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 88.66666666666667, 1.0, 2.0, 0.312807323646386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 493251.869358558, 493251.869358558, 166492.7018573178], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1574400.0000, 
sim time next is 1575000.0000, 
raw observation next is [21.9, 88.5, 1.0, 2.0, 0.3139729591363515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 494165.2074130095, 494165.2074130089, 166538.1748206596], 
processed observation next is [1.0, 0.21739130434782608, 0.23696682464454974, 0.885, 1.0, 1.0, 0.17346139654982107, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13726811317028043, 0.13726811317028026, 0.24856444003083522], 
reward next is 0.7514, 
noisyNet noise sample is [array([0.19402282], dtype=float32), 0.03845071]. 
=============================================
[2019-03-26 19:57:30,523] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[73.14405 ]
 [73.099594]
 [73.01228 ]
 [72.97137 ]
 [72.97257 ]], R is [[73.17154694]
 [73.19133759]
 [73.20704651]
 [73.2274704 ]
 [73.24758148]].
[2019-03-26 19:57:33,116] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5275807e-20 1.0000000e+00 1.6410823e-18 1.9660449e-18 1.4308683e-20], sum to 1.0000
[2019-03-26 19:57:33,128] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0053
[2019-03-26 19:57:33,136] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.65, 86.5, 1.0, 2.0, 0.5082943590738291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 710266.2688861516, 710266.2688861516, 184905.9869181053], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1714200.0000, 
sim time next is 1714800.0000, 
raw observation next is [26.6, 87.0, 1.0, 2.0, 0.5097277816118588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712269.9366325306, 712269.9366325306, 185134.3652466727], 
processed observation next is [1.0, 0.8695652173913043, 0.4597156398104266, 0.87, 1.0, 1.0, 0.4093105802552516, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19785276017570297, 0.19785276017570297, 0.2763199481293622], 
reward next is 0.7237, 
noisyNet noise sample is [array([-0.37278548], dtype=float32), 1.3886857]. 
=============================================
[2019-03-26 19:57:42,372] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0455599e-21 1.0000000e+00 3.3838899e-20 2.7275728e-19 5.6523270e-22], sum to 1.0000
[2019-03-26 19:57:42,381] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4269
[2019-03-26 19:57:42,388] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 85.66666666666667, 1.0, 2.0, 0.6935849271315306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1064085.705241788, 1064085.705241787, 231391.2392456986], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1772400.0000, 
sim time next is 1773000.0000, 
raw observation next is [23.1, 85.5, 1.0, 2.0, 0.6861817415830092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1055454.805219974, 1055454.805219974, 229954.8168320121], 
processed observation next is [1.0, 0.5217391304347826, 0.2938388625592418, 0.855, 1.0, 1.0, 0.6219057127506135, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.29318189033888165, 0.29318189033888165, 0.3432161445253912], 
reward next is 0.6568, 
noisyNet noise sample is [array([-0.05810556], dtype=float32), 0.044565145]. 
=============================================
[2019-03-26 19:57:42,403] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[81.94388]
 [81.82996]
 [81.64748]
 [81.43601]
 [81.19887]], R is [[81.82976532]
 [81.66610718]
 [81.48033905]
 [81.28297424]
 [81.10296631]].
[2019-03-26 19:57:47,860] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5010831e-19 1.0000000e+00 4.3049331e-17 8.8019343e-17 2.6720325e-19], sum to 1.0000
[2019-03-26 19:57:47,868] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8487
[2019-03-26 19:57:47,876] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1700658.699447867 W.
[2019-03-26 19:57:47,881] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 85.0, 1.0, 2.0, 0.4055000630266437, 1.0, 2.0, 0.4055000630266437, 1.0, 1.0, 0.6923941493429925, 6.9112, 6.9112, 170.5573041426782, 1700658.699447867, 1700658.699447867, 354258.0431163031], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1868400.0000, 
sim time next is 1869000.0000, 
raw observation next is [27.0, 85.16666666666667, 1.0, 2.0, 0.7059492461448087, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.979031525207995, 6.9112, 168.9125530051116, 1883453.927850718, 1835332.024242843, 386895.8790384034], 
processed observation next is [1.0, 0.6521739130434783, 0.4786729857819906, 0.8516666666666667, 1.0, 1.0, 0.6457219833069984, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.006783152520799529, 0.0, 0.8294379637564588, 0.5231816466251994, 0.5098144511785675, 0.577456535878214], 
reward next is 0.0834, 
noisyNet noise sample is [array([1.7445846], dtype=float32), 0.1889078]. 
=============================================
[2019-03-26 19:57:47,891] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[72.54582 ]
 [75.11616 ]
 [76.135925]
 [77.422646]
 [77.39901 ]], R is [[70.71311951]
 [70.00598907]
 [69.30593109]
 [68.82355499]
 [68.13532257]].
[2019-03-26 19:57:48,481] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 19:57:48,483] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:57:48,484] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:57:48,485] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:57:48,486] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:57:48,486] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:57:48,487] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:57:48,488] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:57:48,488] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:57:48,493] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:57:48,495] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:57:48,512] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run20
[2019-03-26 19:57:48,530] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run20
[2019-03-26 19:57:48,548] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run20
[2019-03-26 19:57:48,570] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run20
[2019-03-26 19:57:48,571] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run20
[2019-03-26 19:57:53,677] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06363729], dtype=float32), 0.065985516]
[2019-03-26 19:57:53,679] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.03155166, 96.78515807, 1.0, 2.0, 0.2593864843163288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 424017.0022345468, 424017.0022345468, 161829.3948232712]
[2019-03-26 19:57:53,680] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:57:53,684] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.1101037e-19 1.0000000e+00 1.0342175e-16 2.2595162e-16 1.3434139e-18], sampled 0.4070760306897071
[2019-03-26 19:58:25,772] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06363729], dtype=float32), 0.065985516]
[2019-03-26 19:58:25,774] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.131631515, 85.727532315, 1.0, 2.0, 0.5649156647033784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 789415.5780497944, 789415.578049795, 194391.3958831663]
[2019-03-26 19:58:25,776] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:58:25,778] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.8028698e-23 1.0000000e+00 1.5237035e-20 8.3134560e-20 2.3505041e-22], sampled 0.5434441835293274
[2019-03-26 19:58:27,623] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06363729], dtype=float32), 0.065985516]
[2019-03-26 19:58:27,624] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.23333333333333, 92.0, 1.0, 2.0, 0.4449993894872299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 639556.9271264095, 639556.9271264095, 177708.6451254884]
[2019-03-26 19:58:27,625] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:58:27,626] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1436853e-20 1.0000000e+00 2.5812924e-18 1.2774043e-17 4.3716515e-20], sampled 0.5346700230602262
[2019-03-26 19:59:29,474] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06363729], dtype=float32), 0.065985516]
[2019-03-26 19:59:29,475] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.85, 90.33333333333333, 1.0, 2.0, 0.416518356706541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 613002.4067127772, 613002.4067127772, 175513.5447305596]
[2019-03-26 19:59:29,477] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:59:29,480] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.1547375e-20 1.0000000e+00 1.4498870e-17 4.1566137e-17 1.8435557e-19], sampled 0.477167194945074
[2019-03-26 19:59:32,878] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06363729], dtype=float32), 0.065985516]
[2019-03-26 19:59:32,879] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.5, 81.0, 1.0, 2.0, 0.5890346358179845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 823132.5915734464, 823132.5915734464, 198720.4108676804]
[2019-03-26 19:59:32,880] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:59:32,883] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.6134901e-21 1.0000000e+00 5.8864969e-19 2.7050268e-18 4.3121067e-21], sampled 0.9783667221032952
[2019-03-26 19:59:37,281] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06363729], dtype=float32), 0.065985516]
[2019-03-26 19:59:37,283] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.15, 72.0, 1.0, 2.0, 0.4487509930980948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 645985.8495900566, 645985.8495900566, 178384.6913701158]
[2019-03-26 19:59:37,285] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:59:37,289] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.3406768e-20 1.0000000e+00 9.2789399e-18 4.2872827e-17 1.7187565e-19], sampled 0.17396397068655178
[2019-03-26 19:59:43,252] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 19:59:43,560] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 19:59:43,579] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0954 2842522369.8966 1131.0000
[2019-03-26 19:59:43,589] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4188 3164134907.6624 1778.0000
[2019-03-26 19:59:43,618] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.3130 3007656030.3370 1766.0000
[2019-03-26 19:59:44,631] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 475000, evaluation results [475000.0, 7883.418813853433, 3164134907.662386, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7998.312951428424, 3007656030.3370423, 1766.0, 8496.095385747887, 2842522369.896584, 1131.0]
[2019-03-26 19:59:46,782] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.4007735e-22 1.0000000e+00 5.1528331e-20 4.4840572e-19 1.0087786e-21], sum to 1.0000
[2019-03-26 19:59:46,792] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0035
[2019-03-26 19:59:46,801] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1686719.542674613 W.
[2019-03-26 19:59:46,810] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.3, 79.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.20485821959964, 6.9112, 168.9109806922303, 1686719.542674613, 1478390.731658793, 315270.6679004913], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1939200.0000, 
sim time next is 1939800.0000, 
raw observation next is [26.35, 79.16666666666667, 1.0, 2.0, 0.5459845359732179, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9149025619274422, 6.9112, 6.9112, 168.9127173680542, 1541786.975338964, 1541786.975338964, 328455.847558539], 
processed observation next is [1.0, 0.43478260869565216, 0.4478672985781992, 0.7916666666666667, 1.0, 1.0, 0.45299341683520233, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.8962226364968808, 0.0, 0.0, 0.8294387708537527, 0.4282741598163789, 0.4282741598163789, 0.49023260829632687], 
reward next is 0.5098, 
noisyNet noise sample is [array([0.05842074], dtype=float32), 0.32724893]. 
=============================================
[2019-03-26 19:59:51,569] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3121340e-19 1.0000000e+00 3.8372942e-17 1.9223505e-16 4.3126044e-19], sum to 1.0000
[2019-03-26 19:59:51,581] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9049
[2019-03-26 19:59:51,588] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 96.0, 1.0, 2.0, 0.4763922924712487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 665673.8767111677, 665673.8767111677, 179979.8213440143], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2008800.0000, 
sim time next is 2009400.0000, 
raw observation next is [24.58333333333334, 95.83333333333333, 1.0, 2.0, 0.478267751760229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 668295.3233105448, 668295.3233105455, 180261.1107287601], 
processed observation next is [0.0, 0.2608695652173913, 0.3641390205371251, 0.9583333333333333, 1.0, 1.0, 0.37140692983160123, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1856375898084847, 0.18563758980848488, 0.26904643392352257], 
reward next is 0.7310, 
noisyNet noise sample is [array([-0.07590588], dtype=float32), -0.49073142]. 
=============================================
[2019-03-26 19:59:52,727] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.8627889e-22 1.0000000e+00 2.0525368e-18 9.7088637e-18 1.8648377e-20], sum to 1.0000
[2019-03-26 19:59:52,735] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1810
[2019-03-26 19:59:52,742] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.56666666666667, 94.0, 1.0, 2.0, 0.505891989172379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 706908.1948985324, 706908.194898533, 184524.5759677409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2020800.0000, 
sim time next is 2021400.0000, 
raw observation next is [25.55, 94.0, 1.0, 2.0, 0.5061863276668502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 707319.625740364, 707319.6257403634, 184571.1629275885], 
processed observation next is [0.0, 0.391304347826087, 0.40995260663507116, 0.94, 1.0, 1.0, 0.4050437682733135, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19647767381676776, 0.19647767381676762, 0.27547934765311716], 
reward next is 0.7245, 
noisyNet noise sample is [array([0.22798164], dtype=float32), -2.6903937]. 
=============================================
[2019-03-26 19:59:57,647] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8496691e-20 1.0000000e+00 1.8793151e-18 1.0020228e-17 3.9800545e-20], sum to 1.0000
[2019-03-26 19:59:57,660] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0555
[2019-03-26 19:59:57,664] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.15, 81.5, 1.0, 2.0, 0.5281077366108463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 737962.1537803897, 737962.1537803903, 188117.8881391904], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2107800.0000, 
sim time next is 2108400.0000, 
raw observation next is [28.36666666666667, 80.66666666666667, 1.0, 2.0, 0.5318864316745767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 743244.2379628149, 743244.2379628143, 188743.5019594662], 
processed observation next is [0.0, 0.391304347826087, 0.543443917851501, 0.8066666666666668, 1.0, 1.0, 0.4360077490055141, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20645673276744858, 0.20645673276744841, 0.28170671934248687], 
reward next is 0.7183, 
noisyNet noise sample is [array([-0.4162641], dtype=float32), -0.9934521]. 
=============================================
[2019-03-26 20:00:23,613] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.3628383e-16 1.0000000e+00 5.7325862e-14 3.1112428e-13 8.1551993e-15], sum to 1.0000
[2019-03-26 20:00:23,622] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8086
[2019-03-26 20:00:23,630] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2006885.467406774 W.
[2019-03-26 20:00:23,635] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 82.66666666666667, 1.0, 2.0, 0.7176713356475061, 1.0, 2.0, 0.7176713356475061, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2006885.467406774, 2006885.467406774, 381779.7596064435], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2542800.0000, 
sim time next is 2543400.0000, 
raw observation next is [28.1, 82.0, 1.0, 2.0, 0.722942014291491, 1.0, 2.0, 0.722942014291491, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2021638.221660466, 2021638.221660466, 384098.9403695185], 
processed observation next is [1.0, 0.43478260869565216, 0.5308056872037916, 0.82, 1.0, 1.0, 0.6661951979415554, 1.0, 1.0, 0.6661951979415554, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5615661726834628, 0.5615661726834628, 0.5732820005515201], 
reward next is 0.4267, 
noisyNet noise sample is [array([1.0883607], dtype=float32), -0.57750344]. 
=============================================
[2019-03-26 20:00:30,320] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.8852672e-20 1.0000000e+00 1.0640990e-18 7.2524326e-18 8.1517577e-20], sum to 1.0000
[2019-03-26 20:00:30,333] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2487
[2019-03-26 20:00:30,337] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 98.0, 1.0, 2.0, 0.4309244411845149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 623563.9284298284, 623563.9284298284, 176236.7602489321], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2683200.0000, 
sim time next is 2683800.0000, 
raw observation next is [23.5, 97.0, 1.0, 2.0, 0.4332689551429648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 625832.8628156359, 625832.8628156359, 176427.988253219], 
processed observation next is [0.0, 0.043478260869565216, 0.31279620853080575, 0.97, 1.0, 1.0, 0.3171915122204395, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1738424618932322, 0.1738424618932322, 0.2633253556018194], 
reward next is 0.7367, 
noisyNet noise sample is [array([-0.32159454], dtype=float32), 1.0110785]. 
=============================================
[2019-03-26 20:00:32,356] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2479567e-19 1.0000000e+00 3.9341287e-16 1.4997125e-15 1.5085817e-17], sum to 1.0000
[2019-03-26 20:00:32,368] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1379
[2019-03-26 20:00:32,374] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.4412583521901511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 633801.0473858996, 633801.047385899, 177121.2809928687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2688000.0000, 
sim time next is 2688600.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.4404975202183125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 632708.5283133048, 632708.5283133048, 177012.2143808495], 
processed observation next is [0.0, 0.08695652173913043, 0.3364928909952607, 0.94, 1.0, 1.0, 0.32590062676905124, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17575236897591798, 0.17575236897591798, 0.2641973348967903], 
reward next is 0.7358, 
noisyNet noise sample is [array([0.59778583], dtype=float32), -0.7877382]. 
=============================================
[2019-03-26 20:00:39,789] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 20:00:39,790] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:00:39,792] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:00:39,797] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:00:39,797] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run21
[2019-03-26 20:00:39,797] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:00:39,797] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:00:39,814] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:00:39,815] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:00:39,816] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:00:39,817] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:00:39,817] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:00:39,824] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run21
[2019-03-26 20:00:39,840] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run21
[2019-03-26 20:00:39,858] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run21
[2019-03-26 20:00:39,876] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run21
[2019-03-26 20:00:52,868] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06254766], dtype=float32), 0.064320944]
[2019-03-26 20:00:52,870] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.51877271, 87.41917794, 1.0, 2.0, 0.2807809287120449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 450464.1666915458, 450464.1666915452, 163620.3170610011]
[2019-03-26 20:00:52,871] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:00:52,874] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6375866e-18 1.0000000e+00 1.9685534e-16 6.4359279e-16 3.0393833e-18], sampled 0.5860714108827834
[2019-03-26 20:00:54,740] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06254766], dtype=float32), 0.064320944]
[2019-03-26 20:00:54,741] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.55135225, 70.75108699, 1.0, 2.0, 0.3336597313225179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 522330.6860132111, 522330.6860132111, 168625.8757702336]
[2019-03-26 20:00:54,742] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:00:54,744] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.6877902e-20 1.0000000e+00 6.3185457e-18 4.0273604e-17 1.3637415e-19], sampled 0.8130200499117076
[2019-03-26 20:00:56,456] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06254766], dtype=float32), 0.064320944]
[2019-03-26 20:00:56,458] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.77183080333333, 98.68818472666666, 1.0, 2.0, 0.3615678229497324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 553687.8066590249, 553687.8066590242, 170863.3193081645]
[2019-03-26 20:00:56,459] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:00:56,464] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.3710965e-19 1.0000000e+00 1.7198733e-17 9.9291035e-17 3.8082126e-19], sampled 0.8351573086645544
[2019-03-26 20:01:27,305] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06254766], dtype=float32), 0.064320944]
[2019-03-26 20:01:27,308] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [36.25, 51.16666666666666, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.354094903133099, 6.9112, 168.9108928272122, 1768171.173643763, 1453970.124873062, 311355.8235681532]
[2019-03-26 20:01:27,308] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:01:27,312] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.5622717e-20 1.0000000e+00 2.6035332e-18 2.7620232e-17 1.2042738e-19], sampled 0.3311429970653227
[2019-03-26 20:01:27,314] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1768171.173643763 W.
[2019-03-26 20:01:41,390] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06254766], dtype=float32), 0.064320944]
[2019-03-26 20:01:41,391] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.2, 60.0, 1.0, 2.0, 0.5626333366689277, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9771080401062405, 6.911199999999999, 6.9112, 168.9129564911561, 1573032.519558855, 1573032.519558856, 344212.1178963138]
[2019-03-26 20:01:41,392] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:01:41,398] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.3073079e-17 1.0000000e+00 3.1466755e-16 2.5184920e-15 4.1857159e-17], sampled 0.6540909801521106
[2019-03-26 20:01:48,281] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06254766], dtype=float32), 0.064320944]
[2019-03-26 20:01:48,284] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.74813474333333, 83.55211527666668, 1.0, 2.0, 0.7094008300679965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 991414.0046824624, 991414.0046824631, 222885.0414376433]
[2019-03-26 20:01:48,285] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:01:48,287] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.8736216e-21 1.0000000e+00 3.2068122e-19 1.8951028e-18 4.9900288e-21], sampled 0.68060934906171
[2019-03-26 20:01:54,146] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06254766], dtype=float32), 0.064320944]
[2019-03-26 20:01:54,147] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.82523647666667, 67.38149264, 1.0, 2.0, 0.8869445770480832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1239682.823461318, 1239682.823461319, 266374.9848668071]
[2019-03-26 20:01:54,149] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:01:54,153] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0455361e-21 1.0000000e+00 1.3800379e-19 1.1189373e-18 2.4070077e-21], sampled 0.7233422740896487
[2019-03-26 20:02:34,949] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164071917.9177 1778.0000
[2019-03-26 20:02:35,063] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8356 2842522561.2823 1131.0000
[2019-03-26 20:02:35,326] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 20:02:35,348] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.3273 2927391892.5307 1338.0000
[2019-03-26 20:02:35,481] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9767 2779207024.4606 933.0000
[2019-03-26 20:02:36,494] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 500000, evaluation results [500000.0, 7884.168443086554, 3164071917.9176674, 1778.0, 8254.327253941756, 2927391892.530706, 1338.0, 8659.976662972434, 2779207024.4606214, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8496.835586979434, 2842522561.2823186, 1131.0]
[2019-03-26 20:02:37,722] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.8531055e-22 1.0000000e+00 2.3580694e-19 4.5989662e-18 1.3442020e-20], sum to 1.0000
[2019-03-26 20:02:37,736] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6186
[2019-03-26 20:02:37,745] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.4094262076607182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 603250.7644546658, 603250.7644546658, 174616.0758322382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2833800.0000, 
sim time next is 2834400.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.4091672451503332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 602870.9496955557, 602870.9496955563, 174580.6887437804], 
processed observation next is [1.0, 0.8260869565217391, 0.3364928909952607, 0.89, 1.0, 1.0, 0.28815330741004, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1674641526932099, 0.16746415269321008, 0.2605681921548961], 
reward next is 0.7394, 
noisyNet noise sample is [array([1.830136], dtype=float32), -0.18794633]. 
=============================================
[2019-03-26 20:02:51,722] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1368880e-21 1.0000000e+00 8.2883135e-20 1.5041613e-19 1.9613441e-22], sum to 1.0000
[2019-03-26 20:02:51,729] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0900
[2019-03-26 20:02:51,738] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 98.0, 1.0, 2.0, 0.792185365789055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1146047.146729372, 1146047.146729373, 247390.1156672415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3079200.0000, 
sim time next is 3079800.0000, 
raw observation next is [23.5, 97.0, 1.0, 2.0, 0.8129721434911567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1174031.285721376, 1174031.285721376, 252419.0025796037], 
processed observation next is [1.0, 0.6521739130434783, 0.31279620853080575, 0.97, 1.0, 1.0, 0.7746652331218755, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3261198015892711, 0.3261198015892711, 0.37674477996955774], 
reward next is 0.6233, 
noisyNet noise sample is [array([0.85431737], dtype=float32), 0.85443]. 
=============================================
[2019-03-26 20:02:52,475] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.0548817e-21 1.0000000e+00 3.4534377e-19 2.3703723e-18 1.0176450e-21], sum to 1.0000
[2019-03-26 20:02:52,485] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4279
[2019-03-26 20:02:52,490] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 99.00000000000001, 1.0, 2.0, 0.4264394184050594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 621010.880074416, 621010.8800744154, 176098.6453409253], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3093000.0000, 
sim time next is 3093600.0000, 
raw observation next is [23.0, 98.0, 1.0, 2.0, 0.4229290631167505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 618778.816211871, 618778.816211871, 175963.6500937533], 
processed observation next is [1.0, 0.8260869565217391, 0.28909952606635075, 0.98, 1.0, 1.0, 0.3047338109840367, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1718830045032975, 0.1718830045032975, 0.2626323135727661], 
reward next is 0.7374, 
noisyNet noise sample is [array([0.86493576], dtype=float32), -0.8246787]. 
=============================================
[2019-03-26 20:02:57,757] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8497820e-20 1.0000000e+00 6.2975386e-18 5.5510114e-18 9.4637055e-21], sum to 1.0000
[2019-03-26 20:02:57,766] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7064
[2019-03-26 20:02:57,771] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333333, 92.33333333333334, 1.0, 2.0, 0.4914239763024455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 686684.7820207494, 686684.7820207487, 182263.2816266926], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3181200.0000, 
sim time next is 3181800.0000, 
raw observation next is [25.16666666666667, 93.16666666666667, 1.0, 2.0, 0.4920327516193084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 687535.7214298253, 687535.7214298247, 182357.0076422961], 
processed observation next is [1.0, 0.8260869565217391, 0.39178515007898923, 0.9316666666666668, 1.0, 1.0, 0.3879912670112149, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19098214484161813, 0.19098214484161796, 0.27217463827208377], 
reward next is 0.7278, 
noisyNet noise sample is [array([-2.4468236], dtype=float32), 1.0072206]. 
=============================================
[2019-03-26 20:02:59,184] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.7179640e-20 1.0000000e+00 1.0149217e-17 3.7695107e-17 1.5225661e-18], sum to 1.0000
[2019-03-26 20:02:59,197] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0090
[2019-03-26 20:02:59,200] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 90.33333333333333, 1.0, 2.0, 0.4682276596196061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 657270.9418419404, 657270.9418419404, 179156.5997873862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3207000.0000, 
sim time next is 3207600.0000, 
raw observation next is [25.0, 90.0, 1.0, 2.0, 0.4657045598329232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 655042.1432493017, 655042.1432493011, 178953.5943287883], 
processed observation next is [0.0, 0.13043478260869565, 0.38388625592417064, 0.9, 1.0, 1.0, 0.3562705540155702, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1819561509025838, 0.18195615090258366, 0.2670949169086393], 
reward next is 0.7329, 
noisyNet noise sample is [array([0.18290746], dtype=float32), 0.75012815]. 
=============================================
[2019-03-26 20:03:03,075] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.8118207e-22 1.0000000e+00 9.3672731e-20 1.7700590e-18 1.4049436e-21], sum to 1.0000
[2019-03-26 20:03:03,085] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5123
[2019-03-26 20:03:03,091] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5199735503351353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 726591.7946593971, 726591.7946593978, 186784.5782920096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3273600.0000, 
sim time next is 3274200.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5187093207022149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 724824.6042412353, 724824.604241236, 186579.3330116044], 
processed observation next is [0.0, 0.9130434782608695, 0.5260663507109005, 0.79, 1.0, 1.0, 0.4201317116894155, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2013401678447876, 0.20134016784478778, 0.2784766164352305], 
reward next is 0.7215, 
noisyNet noise sample is [array([-1.0132524], dtype=float32), 0.25514087]. 
=============================================
[2019-03-26 20:03:18,986] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8772372e-20 1.0000000e+00 1.3280210e-18 5.7073318e-17 2.2622025e-20], sum to 1.0000
[2019-03-26 20:03:18,996] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4709
[2019-03-26 20:03:19,001] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5192605690757257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 725595.1607614532, 725595.1607614526, 186668.7689581645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3536400.0000, 
sim time next is 3537000.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5183974007267487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 724388.5905567933, 724388.590556794, 186528.7661862407], 
processed observation next is [1.0, 0.9565217391304348, 0.5260663507109005, 0.79, 1.0, 1.0, 0.4197559044900586, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20121905293244258, 0.20121905293244277, 0.2784011435615533], 
reward next is 0.7216, 
noisyNet noise sample is [array([0.34664685], dtype=float32), 0.05251203]. 
=============================================
[2019-03-26 20:03:19,014] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[77.203835]
 [77.19744 ]
 [77.01343 ]
 [76.82687 ]
 [76.80594 ]], R is [[77.15372467]
 [77.10357666]
 [77.05362701]
 [77.00352478]
 [76.95243073]].
[2019-03-26 20:03:23,102] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.6812927e-15 1.0000000e+00 4.8406076e-14 4.1790475e-13 6.5778784e-16], sum to 1.0000
[2019-03-26 20:03:23,110] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9604
[2019-03-26 20:03:23,113] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.5612244348728901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 784255.5333745743, 784255.5333745749, 193746.0851466803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3607200.0000, 
sim time next is 3607800.0000, 
raw observation next is [31.83333333333334, 66.83333333333334, 1.0, 2.0, 0.5675168131537903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 793051.7910204724, 793051.791020473, 194851.0513613695], 
processed observation next is [1.0, 0.782608695652174, 0.7077409162717223, 0.6683333333333334, 1.0, 1.0, 0.47893591946239794, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22029216417235345, 0.22029216417235362, 0.2908224647184619], 
reward next is 0.7092, 
noisyNet noise sample is [array([-2.7305787], dtype=float32), -0.20390463]. 
=============================================
[2019-03-26 20:03:23,831] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0405317e-19 1.0000000e+00 7.9122168e-17 5.1220363e-16 1.9512502e-19], sum to 1.0000
[2019-03-26 20:03:23,842] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9873
[2019-03-26 20:03:23,846] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.5271852845638958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 736672.6995608315, 736672.6995608315, 187964.9008016786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3617400.0000, 
sim time next is 3618000.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.52709078992367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 736540.6098425238, 736540.6098425244, 187949.3416142548], 
processed observation next is [1.0, 0.9130434782608695, 0.5734597156398105, 0.74, 1.0, 1.0, 0.43022986737791563, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20459461384514552, 0.20459461384514566, 0.2805214053944102], 
reward next is 0.7195, 
noisyNet noise sample is [array([-0.5627615], dtype=float32), -0.57583654]. 
=============================================
[2019-03-26 20:03:23,858] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[74.12827 ]
 [73.823555]
 [73.555016]
 [72.9921  ]
 [72.316284]], R is [[74.71614075]
 [74.68843079]
 [74.66117096]
 [74.63465118]
 [74.60868835]].
[2019-03-26 20:03:27,934] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0927062e-15 1.0000000e+00 1.9128503e-14 2.9082227e-13 1.1861304e-15], sum to 1.0000
[2019-03-26 20:03:27,948] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0279
[2019-03-26 20:03:27,955] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2507403.010056572 W.
[2019-03-26 20:03:27,960] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 70.0, 1.0, 2.0, 0.896467018101429, 1.0, 2.0, 0.896467018101429, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2507403.010056572, 2507403.010056571, 469561.4511383821], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4012200.0000, 
sim time next is 4012800.0000, 
raw observation next is [30.33333333333333, 68.66666666666667, 1.0, 2.0, 0.6053428862770062, 1.0, 2.0, 0.6053428862770062, 1.0, 1.0, 1.03, 6.930485905498368, 6.9112, 170.5573041426782, 2539733.467777269, 2525918.18916831, 490117.6272911948], 
processed observation next is [1.0, 0.43478260869565216, 0.6366508688783569, 0.6866666666666668, 1.0, 1.0, 0.5245095015385616, 1.0, 1.0, 0.5245095015385616, 1.0, 0.5, 1.0365853658536586, 0.001928590549836784, 0.0, 0.8375144448122397, 0.7054815188270191, 0.7016439414356416, 0.7315188467032758], 
reward next is 0.1721, 
noisyNet noise sample is [array([1.5319337], dtype=float32), -1.0571455]. 
=============================================
[2019-03-26 20:03:31,665] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 20:03:31,667] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:03:31,668] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:03:31,668] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:03:31,669] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:03:31,670] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:03:31,670] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:03:31,671] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:03:31,670] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:03:31,674] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:03:31,675] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:03:31,693] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run22
[2019-03-26 20:03:31,711] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run22
[2019-03-26 20:03:31,739] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run22
[2019-03-26 20:03:31,740] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run22
[2019-03-26 20:03:31,783] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run22
[2019-03-26 20:03:42,804] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06099479], dtype=float32), 0.062472243]
[2019-03-26 20:03:42,805] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.33333333333334, 78.33333333333333, 1.0, 2.0, 0.2456158105228543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 405761.9823307951, 405761.9823307945, 160415.6371487835]
[2019-03-26 20:03:42,806] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:03:42,808] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.4144410e-19 1.0000000e+00 5.1309706e-17 3.1698313e-16 8.1312635e-19], sampled 0.7367246971662377
[2019-03-26 20:04:02,113] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06099479], dtype=float32), 0.062472243]
[2019-03-26 20:04:02,114] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.46666666666667, 95.0, 1.0, 2.0, 0.3814813294063354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 577232.7169003858, 577232.7169003865, 172706.7820029893]
[2019-03-26 20:04:02,115] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:04:02,117] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2968270e-18 1.0000000e+00 1.2578692e-16 6.4085136e-16 1.6927174e-18], sampled 0.04367319190105767
[2019-03-26 20:04:03,807] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06099479], dtype=float32), 0.062472243]
[2019-03-26 20:04:03,809] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.38855372333334, 82.12890383999999, 1.0, 2.0, 0.5123552407480795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 715942.6633078043, 715942.6633078043, 185554.622128656]
[2019-03-26 20:04:03,810] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:04:03,813] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.0555348e-21 1.0000000e+00 8.1445506e-19 1.1141038e-17 1.5732649e-20], sampled 0.35835022520037263
[2019-03-26 20:04:15,783] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06099479], dtype=float32), 0.062472243]
[2019-03-26 20:04:15,784] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.4, 72.33333333333334, 1.0, 2.0, 0.5028782659800126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 702695.5757724827, 702695.5757724821, 184047.7235745593]
[2019-03-26 20:04:15,786] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:04:15,790] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.1446626e-20 1.0000000e+00 9.3877803e-18 9.2252628e-17 2.0932660e-19], sampled 0.35433412000262654
[2019-03-26 20:04:27,766] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06099479], dtype=float32), 0.062472243]
[2019-03-26 20:04:27,772] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.25, 79.0, 1.0, 2.0, 0.5703259144975626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 796978.7207220218, 796978.7207220218, 195347.283774873]
[2019-03-26 20:04:27,773] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:04:27,775] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.5542432e-21 1.0000000e+00 6.2077341e-19 8.3122917e-18 1.1645042e-20], sampled 0.3175307588889664
[2019-03-26 20:04:35,683] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06099479], dtype=float32), 0.062472243]
[2019-03-26 20:04:35,684] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [36.43022303333333, 66.58049874833334, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.36027864882101, 6.9112, 171.5212843490159, 3233196.897959994, 2909685.402158093, 551462.2009372489]
[2019-03-26 20:04:35,685] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:04:35,688] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1724720e-16 1.0000000e+00 1.7038954e-15 2.6082357e-14 2.1644757e-16], sampled 0.7694277816143111
[2019-03-26 20:04:35,689] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 3233196.897959994 W.
[2019-03-26 20:04:45,793] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06099479], dtype=float32), 0.062472243]
[2019-03-26 20:04:45,794] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.80713717666666, 77.17547555, 1.0, 2.0, 0.5951266143471479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 831649.016472477, 831649.016472477, 199839.8131191835]
[2019-03-26 20:04:45,796] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:04:45,798] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.2531984e-20 1.0000000e+00 7.7124327e-18 6.2321323e-17 1.1913747e-19], sampled 0.11760678695673343
[2019-03-26 20:05:05,714] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06099479], dtype=float32), 0.062472243]
[2019-03-26 20:05:05,715] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.61666666666667, 86.83333333333333, 1.0, 2.0, 0.8100175178758163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1132104.518057822, 1132104.518057821, 246382.8546300093]
[2019-03-26 20:05:05,716] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:05:05,720] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.5114949e-19 1.0000000e+00 1.1441845e-17 6.7450742e-17 2.0284451e-19], sampled 0.09511631271803767
[2019-03-26 20:05:26,470] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 20:05:26,543] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06099479], dtype=float32), 0.062472243]
[2019-03-26 20:05:26,545] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.2, 82.66666666666667, 1.0, 2.0, 0.6842778206632252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 956287.858239193, 956287.8582391937, 217486.5422263585]
[2019-03-26 20:05:26,546] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:05:26,548] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.711886e-20 1.000000e+00 5.227459e-18 3.479943e-17 6.907626e-20], sampled 0.7539556661658942
[2019-03-26 20:05:26,607] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9878 2779131868.1217 933.0000
[2019-03-26 20:05:26,792] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5374 3007679688.9915 1766.0000
[2019-03-26 20:05:26,923] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4154 3164065956.6075 1778.0000
[2019-03-26 20:05:26,926] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0344 2842563115.2351 1131.0000
[2019-03-26 20:05:27,941] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 525000, evaluation results [525000.0, 7883.415429619458, 3164065956.607484, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8659.98775396918, 2779131868.121704, 933.0, 7997.53741177424, 3007679688.9914675, 1766.0, 8496.034363079138, 2842563115.235065, 1131.0]
[2019-03-26 20:05:35,868] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.1461553e-20 1.0000000e+00 2.7998403e-18 3.8049494e-17 4.3421509e-20], sum to 1.0000
[2019-03-26 20:05:35,879] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2933
[2019-03-26 20:05:35,882] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 86.5, 1.0, 2.0, 0.5815642600583141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 812689.2970028928, 812689.2970028921, 197361.2961121615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3889800.0000, 
sim time next is 3890400.0000, 
raw observation next is [28.33333333333333, 87.33333333333333, 1.0, 2.0, 0.5798409008873147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 810280.1225297259, 810280.1225297266, 197050.0828706015], 
processed observation next is [0.0, 0.0, 0.541864139020537, 0.8733333333333333, 1.0, 1.0, 0.49378421793652366, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22507781181381276, 0.22507781181381295, 0.29410460129940524], 
reward next is 0.7059, 
noisyNet noise sample is [array([-0.06163444], dtype=float32), 0.0038978378]. 
=============================================
[2019-03-26 20:05:43,176] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3600397e-12 1.0000000e+00 1.3393143e-12 8.6578342e-11 2.8643421e-13], sum to 1.0000
[2019-03-26 20:05:43,183] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4294
[2019-03-26 20:05:43,188] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2599585.59850934 W.
[2019-03-26 20:05:43,193] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.33333333333334, 64.0, 1.0, 2.0, 0.9293906333915453, 1.0, 2.0, 0.9293906333915453, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2599585.59850934, 2599585.598509341, 487780.2560557653], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4016400.0000, 
sim time next is 4017000.0000, 
raw observation next is [32.66666666666666, 63.5, 1.0, 2.0, 0.9458899858078658, 1.0, 2.0, 0.9458899858078658, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2645784.572398904, 2645784.572398904, 497147.5688820257], 
processed observation next is [1.0, 0.4782608695652174, 0.7472353870458132, 0.635, 1.0, 1.0, 0.9348072118167058, 1.0, 1.0, 0.9348072118167058, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7349401589996954, 0.7349401589996954, 0.7420112968388444], 
reward next is 0.2580, 
noisyNet noise sample is [array([-0.12314231], dtype=float32), 1.1648729]. 
=============================================
[2019-03-26 20:05:43,215] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[43.43711 ]
 [43.660748]
 [43.684334]
 [44.376896]
 [44.37462 ]], R is [[44.35858154]
 [44.18696594]
 [44.02859879]
 [43.58831406]
 [43.15243149]].
[2019-03-26 20:05:43,582] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.2906741e-12 1.0000000e+00 1.8479321e-11 1.9781234e-10 4.9124446e-12], sum to 1.0000
[2019-03-26 20:05:43,593] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3790
[2019-03-26 20:05:43,608] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 3030474.860359993 W.
[2019-03-26 20:05:43,612] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.0, 60.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.080119858922294, 6.9112, 170.5573041426782, 3030474.860359993, 2909470.694193412, 552768.1524028128], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4024800.0000, 
sim time next is 4025400.0000, 
raw observation next is [34.0, 60.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.580282098197825, 6.9112, 170.5573041426782, 3389178.765665298, 2909888.042206557, 549955.3752569812], 
processed observation next is [1.0, 0.6086956521739131, 0.8104265402843602, 0.6, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.2195121951219512, 0.06690820981978254, 0.0, 0.8375144448122397, 0.9414385460181383, 0.8083022339462659, 0.8208289182940018], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.15200341], dtype=float32), -0.5871043]. 
=============================================
[2019-03-26 20:05:46,153] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7451161e-17 1.0000000e+00 7.1585740e-16 3.0720279e-14 3.0752944e-17], sum to 1.0000
[2019-03-26 20:05:46,163] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6094
[2019-03-26 20:05:46,169] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 86.5, 1.0, 2.0, 0.981870285484318, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9129563853388, 1372446.286244371, 1372446.286244372, 293451.0719904648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4069800.0000, 
sim time next is 4070400.0000, 
raw observation next is [27.46666666666667, 86.66666666666667, 1.0, 2.0, 0.8849166075513234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565103997, 1236846.678605359, 1236846.67860536, 265822.6957625303], 
processed observation next is [1.0, 0.08695652173913043, 0.500789889415482, 0.8666666666666667, 1.0, 1.0, 0.8613453103027993, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.829439945152149, 0.34356852183482195, 0.3435685218348222, 0.39675029218288105], 
reward next is 0.6032, 
noisyNet noise sample is [array([0.07127967], dtype=float32), 0.24374896]. 
=============================================
[2019-03-26 20:06:02,836] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4113677e-14 1.0000000e+00 2.2641745e-13 2.5678160e-12 4.4837583e-15], sum to 1.0000
[2019-03-26 20:06:02,843] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1228
[2019-03-26 20:06:02,847] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 87.33333333333334, 1.0, 2.0, 0.9635828688030784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510413, 1346868.143392806, 1346868.143392806, 288032.0336900885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4342800.0000, 
sim time next is 4343400.0000, 
raw observation next is [29.5, 86.5, 1.0, 2.0, 0.9740883625639153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1361561.833994603, 1361561.833994603, 291136.0962298395], 
processed observation next is [1.0, 0.2608695652173913, 0.5971563981042655, 0.865, 1.0, 1.0, 0.9687811597155606, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3782116205540564, 0.3782116205540564, 0.4345314869102082], 
reward next is 0.5655, 
noisyNet noise sample is [array([1.5623565], dtype=float32), -0.46983367]. 
=============================================
[2019-03-26 20:06:03,918] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1008323e-09 9.9999988e-01 1.4666199e-09 7.2729570e-08 3.6654624e-10], sum to 1.0000
[2019-03-26 20:06:03,930] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0743
[2019-03-26 20:06:03,939] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3386455.323147359 W.
[2019-03-26 20:06:03,945] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.83333333333334, 55.0, 1.0, 2.0, 0.9725898533281696, 1.0, 2.0, 0.8068849661783476, 1.0, 2.0, 1.03, 7.005119235463171, 6.9112, 170.5573041426782, 3386455.323147359, 3319177.154394852, 621268.2722152502], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4362600.0000, 
sim time next is 4363200.0000, 
raw observation next is [37.0, 54.0, 1.0, 2.0, 0.9717108592642465, 1.0, 2.0, 0.806445469146386, 1.0, 2.0, 1.03, 7.00511916609186, 6.9112, 170.5573041426782, 3384608.27640494, 3317330.157345924, 620901.3489319627], 
processed observation next is [1.0, 0.5217391304347826, 0.95260663507109, 0.54, 1.0, 1.0, 0.9659166979087307, 1.0, 1.0, 0.7668017700558868, 1.0, 1.0, 1.0365853658536586, 0.00939191660918599, 0.0, 0.8375144448122397, 0.9401689656680389, 0.9214805992627567, 0.9267184312417355], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.16079777], dtype=float32), -0.29032555]. 
=============================================
[2019-03-26 20:06:06,357] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3167617e-18 1.0000000e+00 3.9368760e-16 8.7215896e-16 9.5124373e-18], sum to 1.0000
[2019-03-26 20:06:06,363] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7551
[2019-03-26 20:06:06,369] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.5053018078412719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 706083.230902521, 706083.2309025218, 184430.5922021657], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4512600.0000, 
sim time next is 4513200.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5056966229924541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 706635.1091571717, 706635.1091571723, 184493.0712654031], 
processed observation next is [0.0, 0.21739130434782608, 0.4312796208530806, 0.89, 1.0, 1.0, 0.40445376264151095, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1962875303214366, 0.19628753032143675, 0.27536279293343746], 
reward next is 0.7246, 
noisyNet noise sample is [array([0.39275354], dtype=float32), -0.6449489]. 
=============================================
[2019-03-26 20:06:15,772] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3545806e-20 1.0000000e+00 1.9752170e-17 1.1991917e-16 2.0109406e-19], sum to 1.0000
[2019-03-26 20:06:15,778] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9834
[2019-03-26 20:06:15,782] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 80.66666666666667, 1.0, 2.0, 0.5285315391338506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 738554.5687871398, 738554.5687871391, 188187.0811544497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4569600.0000, 
sim time next is 4570200.0000, 
raw observation next is [28.0, 81.5, 1.0, 2.0, 0.5315886663888735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742828.0030241485, 742828.0030241485, 188693.4436522572], 
processed observation next is [0.0, 0.9130434782608695, 0.5260663507109005, 0.815, 1.0, 1.0, 0.43564899564924514, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20634111195115237, 0.20634111195115237, 0.28163200545113015], 
reward next is 0.7184, 
noisyNet noise sample is [array([-1.6084656], dtype=float32), 0.42853507]. 
=============================================
[2019-03-26 20:06:22,162] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1934358e-18 1.0000000e+00 2.7281791e-17 7.6449822e-16 2.2287037e-19], sum to 1.0000
[2019-03-26 20:06:22,170] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8769
[2019-03-26 20:06:22,176] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 90.66666666666667, 1.0, 2.0, 0.5004445329501753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 699293.6861796705, 699293.6861796705, 183665.4725159302], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4666800.0000, 
sim time next is 4667400.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5023556926498313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 701965.1180817671, 701965.1180817671, 183965.8295202671], 
processed observation next is [1.0, 0.0, 0.4312796208530806, 0.89, 1.0, 1.0, 0.40042854536124245, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19499031057826866, 0.19499031057826866, 0.2745758649556226], 
reward next is 0.7254, 
noisyNet noise sample is [array([0.6251195], dtype=float32), -1.2226177]. 
=============================================
[2019-03-26 20:06:23,172] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3857473e-19 1.0000000e+00 2.2913006e-17 2.1405322e-16 2.5814487e-19], sum to 1.0000
[2019-03-26 20:06:23,181] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4443
[2019-03-26 20:06:23,185] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.7433204213897285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1038841.079339711, 1038841.079339712, 230473.8937004936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4683600.0000, 
sim time next is 4684200.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.6741954722451413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 942191.3845995613, 942191.3845995606, 215374.1392244629], 
processed observation next is [1.0, 0.21739130434782608, 0.4786729857819906, 0.89, 1.0, 1.0, 0.6074644243917365, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.26171982905543373, 0.2617198290554335, 0.3214539391409894], 
reward next is 0.6785, 
noisyNet noise sample is [array([-1.2420728], dtype=float32), 0.6315327]. 
=============================================
[2019-03-26 20:06:23,296] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 20:06:23,299] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:06:23,301] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:06:23,301] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:06:23,302] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:06:23,303] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:06:23,304] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:06:23,302] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:06:23,305] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:06:23,305] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:06:23,306] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:06:23,331] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run23
[2019-03-26 20:06:23,332] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run23
[2019-03-26 20:06:23,373] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run23
[2019-03-26 20:06:23,390] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run23
[2019-03-26 20:06:23,391] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run23
[2019-03-26 20:07:53,545] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06017824], dtype=float32), 0.060150836]
[2019-03-26 20:07:53,546] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.40313472666666, 97.42619406333333, 1.0, 2.0, 0.6327322838225168, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.981144323082724, 6.9112, 168.9124455795614, 1769181.284924045, 1719560.524925544, 371083.9771619783]
[2019-03-26 20:07:53,548] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:07:53,557] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.4143220e-14 1.0000000e+00 5.0502381e-13 9.9598368e-12 4.1301767e-14], sampled 0.24348016535252903
[2019-03-26 20:07:53,558] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1769181.284924045 W.
[2019-03-26 20:08:00,367] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06017824], dtype=float32), 0.060150836]
[2019-03-26 20:08:00,369] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.5, 87.0, 1.0, 2.0, 0.5072361923811978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 708787.1439663708, 708787.1439663714, 184737.6452244647]
[2019-03-26 20:08:00,370] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:08:00,373] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1397921e-19 1.0000000e+00 9.6427943e-18 2.6922543e-16 9.1502105e-20], sampled 0.3204028115794755
[2019-03-26 20:08:18,214] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.4067 2927264152.9822 1338.0000
[2019-03-26 20:08:18,427] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 20:08:18,522] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.6275 2779190785.3580 933.0000
[2019-03-26 20:08:18,529] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6674 3164196406.5138 1778.0000
[2019-03-26 20:08:18,576] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.1321 2842451957.6633 1131.0000
[2019-03-26 20:08:19,592] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 550000, evaluation results [550000.0, 7882.667391253915, 3164196406.5138016, 1778.0, 8254.406660643592, 2927264152.9821725, 1338.0, 8660.627510841134, 2779190785.357956, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8496.132105234119, 2842451957.6632614, 1131.0]
[2019-03-26 20:08:19,826] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0021910e-17 1.0000000e+00 3.0029684e-16 3.2795744e-15 9.1353930e-19], sum to 1.0000
[2019-03-26 20:08:19,833] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3978
[2019-03-26 20:08:19,839] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.7674757770387476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1072616.888923591, 1072616.888923591, 236084.0565103992], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4682400.0000, 
sim time next is 4683000.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.7580254610233658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1059402.628320965, 1059402.628320965, 233868.611976253], 
processed observation next is [1.0, 0.17391304347826086, 0.4786729857819906, 0.89, 1.0, 1.0, 0.708464410871525, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2942785078669347, 0.2942785078669347, 0.349057629815303], 
reward next is 0.6509, 
noisyNet noise sample is [array([-0.41288865], dtype=float32), 0.30005804]. 
=============================================
[2019-03-26 20:08:19,849] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[68.531395]
 [68.25198 ]
 [68.066864]
 [67.74963 ]
 [67.478874]], R is [[68.64374542]
 [68.60494232]
 [68.56214905]
 [68.51739502]
 [68.45489502]].
[2019-03-26 20:08:28,459] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2742116e-17 1.0000000e+00 4.2535152e-16 3.7086768e-14 5.9102832e-18], sum to 1.0000
[2019-03-26 20:08:28,470] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2897
[2019-03-26 20:08:28,474] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.83333333333334, 1.0, 2.0, 0.6573587196675788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 918651.7662806674, 918651.7662806674, 211907.3129420844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4849800.0000, 
sim time next is 4850400.0000, 
raw observation next is [27.0, 80.66666666666667, 1.0, 2.0, 0.6177226191331104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 863238.2300704888, 863238.2300704888, 204085.358952211], 
processed observation next is [1.0, 0.13043478260869565, 0.4786729857819906, 0.8066666666666668, 1.0, 1.0, 0.5394248423290487, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23978839724180243, 0.23978839724180243, 0.30460501336150897], 
reward next is 0.6954, 
noisyNet noise sample is [array([-0.51146525], dtype=float32), -0.6888645]. 
=============================================
[2019-03-26 20:08:33,851] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.9249410e-18 1.0000000e+00 3.7971359e-16 2.5181076e-15 1.2344471e-18], sum to 1.0000
[2019-03-26 20:08:33,862] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4601
[2019-03-26 20:08:33,870] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.7044352568551113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 984471.2151669071, 984471.2151669076, 221803.1410403291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4938000.0000, 
sim time next is 4938600.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.6908605370632511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 965491.4784959515, 965491.4784959509, 218882.5216439698], 
processed observation next is [1.0, 0.13043478260869565, 0.4312796208530806, 0.89, 1.0, 1.0, 0.6275428157388567, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2681920773599865, 0.26819207735998635, 0.32669033081189525], 
reward next is 0.6733, 
noisyNet noise sample is [array([-0.356874], dtype=float32), -0.010334531]. 
=============================================
[2019-03-26 20:08:46,351] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.0425240e-20 1.0000000e+00 3.4113574e-18 3.5926294e-16 1.4770163e-19], sum to 1.0000
[2019-03-26 20:08:46,361] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3208
[2019-03-26 20:08:46,369] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 63.66666666666666, 1.0, 2.0, 0.557372386554527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 778870.7040187203, 778870.7040187209, 193073.4920540554], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5143800.0000, 
sim time next is 5144400.0000, 
raw observation next is [32.0, 63.0, 1.0, 2.0, 0.553675118974134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 773702.2703814851, 773702.2703814845, 192433.2994364631], 
processed observation next is [0.0, 0.5652173913043478, 0.7156398104265403, 0.63, 1.0, 1.0, 0.4622591794869084, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21491729732819032, 0.21491729732819015, 0.28721387975591506], 
reward next is 0.7128, 
noisyNet noise sample is [array([0.9717966], dtype=float32), -0.34114853]. 
=============================================
[2019-03-26 20:08:50,591] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.5990483e-14 1.0000000e+00 1.2434899e-12 8.5172196e-11 2.4207470e-13], sum to 1.0000
[2019-03-26 20:08:50,597] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0312
[2019-03-26 20:08:50,606] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2493798.584060474 W.
[2019-03-26 20:08:50,611] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 68.0, 1.0, 2.0, 0.5944052683676839, 1.0, 1.0, 0.5944052683676839, 1.0, 2.0, 1.03, 6.913769087138583, 6.9112, 170.5573041426782, 2493798.584060474, 2491958.242439325, 485957.7661089038], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5221800.0000, 
sim time next is 5222400.0000, 
raw observation next is [31.0, 68.66666666666667, 1.0, 2.0, 0.861550631605336, 1.0, 2.0, 0.861550631605336, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2409648.306250701, 2409648.306250702, 450948.3550177966], 
processed observation next is [1.0, 0.43478260869565216, 0.6682464454976303, 0.6866666666666668, 1.0, 1.0, 0.8331935320546217, 1.0, 1.0, 0.8331935320546217, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6693467517363059, 0.6693467517363062, 0.6730572462952188], 
reward next is 0.3269, 
noisyNet noise sample is [array([0.584231], dtype=float32), -0.9675605]. 
=============================================
[2019-03-26 20:08:51,710] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1514297e-19 1.0000000e+00 2.4909623e-17 2.0177221e-15 2.3480788e-19], sum to 1.0000
[2019-03-26 20:08:51,722] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4193
[2019-03-26 20:08:51,728] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.36666666666667, 87.33333333333333, 1.0, 2.0, 0.8011567345204668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1119713.894792561, 1119713.894792561, 244195.3564651177], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5553600.0000, 
sim time next is 5554200.0000, 
raw observation next is [27.53333333333333, 86.66666666666667, 1.0, 2.0, 0.808371934136521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1129803.377829184, 1129803.377829185, 245976.7765173571], 
processed observation next is [1.0, 0.2608695652173913, 0.5039494470774091, 0.8666666666666667, 1.0, 1.0, 0.7691228122126759, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3138342716192178, 0.31383427161921806, 0.36712951719008524], 
reward next is 0.6329, 
noisyNet noise sample is [array([-1.1662263], dtype=float32), -0.91041255]. 
=============================================
[2019-03-26 20:08:53,051] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.7469243e-19 1.0000000e+00 1.1302123e-16 3.6484674e-16 2.5032383e-19], sum to 1.0000
[2019-03-26 20:08:53,059] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8229
[2019-03-26 20:08:53,067] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.7, 79.5, 1.0, 2.0, 0.5479810284523111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 765742.5145672448, 765742.5145672441, 191454.9592761847], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5257800.0000, 
sim time next is 5258400.0000, 
raw observation next is [28.66666666666667, 79.66666666666666, 1.0, 2.0, 0.5469552025755323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 764308.521315797, 764308.5213157964, 191279.8565869479], 
processed observation next is [1.0, 0.8695652173913043, 0.5576619273301741, 0.7966666666666665, 1.0, 1.0, 0.45416289466931603, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21230792258772138, 0.21230792258772122, 0.28549232326410134], 
reward next is 0.7145, 
noisyNet noise sample is [array([1.2964685], dtype=float32), 0.07980985]. 
=============================================
[2019-03-26 20:08:57,351] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.1280511e-11 1.0000000e+00 2.6966615e-10 1.5628604e-08 2.9703802e-11], sum to 1.0000
[2019-03-26 20:08:57,358] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0264
[2019-03-26 20:08:57,365] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3193637.673315919 W.
[2019-03-26 20:08:57,374] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.03333333333333, 53.0, 1.0, 2.0, 0.8808225327557211, 1.0, 2.0, 0.7610013058921233, 1.0, 2.0, 1.03, 7.005111994178296, 6.9112, 170.5573041426782, 3193637.673315919, 3126364.691790323, 584527.6566708083], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5326800.0000, 
sim time next is 5327400.0000, 
raw observation next is [36.01666666666667, 53.0, 1.0, 2.0, 0.8723186418154435, 1.0, 2.0, 0.7567493604219845, 1.0, 2.0, 1.03, 7.005111323256286, 6.9112, 170.5573041426782, 3175771.161114664, 3108498.660197797, 581282.3676185374], 
processed observation next is [1.0, 0.6521739130434783, 0.9060031595576622, 0.53, 1.0, 1.0, 0.8461670383318596, 1.0, 1.0, 0.7069269402674512, 1.0, 1.0, 1.0365853658536586, 0.009391132325628604, 0.0, 0.8375144448122397, 0.8821586558651844, 0.8634718500549436, 0.8675856233112499], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.00488964], dtype=float32), 1.5195434]. 
=============================================
[2019-03-26 20:08:58,356] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.0898574e-20 1.0000000e+00 2.1755421e-17 9.9807544e-16 5.5498197e-20], sum to 1.0000
[2019-03-26 20:08:58,366] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4667
[2019-03-26 20:08:58,371] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.8, 79.66666666666667, 1.0, 2.0, 0.6217062605328083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 868807.4579748324, 868807.457974833, 204859.7899359629], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5347200.0000, 
sim time next is 5347800.0000, 
raw observation next is [30.7, 80.0, 1.0, 2.0, 0.6197149989281698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 866023.6220010631, 866023.6220010631, 204476.6192047563], 
processed observation next is [1.0, 0.9130434782608695, 0.6540284360189573, 0.8, 1.0, 1.0, 0.5418252999134576, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24056211722251752, 0.24056211722251752, 0.305188983887696], 
reward next is 0.6948, 
noisyNet noise sample is [array([-0.32081187], dtype=float32), -0.53710663]. 
=============================================
[2019-03-26 20:08:58,821] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.1467216e-19 1.0000000e+00 5.2911197e-17 5.3357956e-16 1.3905115e-19], sum to 1.0000
[2019-03-26 20:08:58,828] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4048
[2019-03-26 20:08:58,836] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.06666666666666, 83.0, 1.0, 2.0, 0.6145502430742251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 858803.1918004336, 858803.191800433, 203488.1768498952], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5352000.0000, 
sim time next is 5352600.0000, 
raw observation next is [29.98333333333333, 83.5, 1.0, 2.0, 0.6136009548963426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 857476.0736089996, 857476.0736089996, 203307.4196781815], 
processed observation next is [1.0, 0.9565217391304348, 0.6200631911532385, 0.835, 1.0, 1.0, 0.5344589818028224, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2381877982247221, 0.2381877982247221, 0.3034439099674351], 
reward next is 0.6966, 
noisyNet noise sample is [array([-0.74446], dtype=float32), 1.5628046]. 
=============================================
[2019-03-26 20:08:59,672] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0726499e-16 1.0000000e+00 1.0350514e-14 6.1118493e-13 1.6431073e-16], sum to 1.0000
[2019-03-26 20:08:59,681] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0587
[2019-03-26 20:08:59,688] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.1, 88.0, 1.0, 2.0, 0.392875012384643, 1.0, 2.0, 0.392875012384643, 1.0, 1.0, 0.6822939707601474, 6.911199999999999, 6.9112, 170.5573041426782, 1647668.798498359, 1647668.79849836, 348980.6828116485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5366400.0000, 
sim time next is 5367000.0000, 
raw observation next is [29.05, 88.5, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.573792740115747, 6.9112, 168.9092278978081, 1924132.619249037, 1454076.901045732, 311355.8990120316], 
processed observation next is [1.0, 0.08695652173913043, 0.575829383886256, 0.885, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.06625927401157475, 0.0, 0.8294216359573581, 0.5344812831247325, 0.4039102502904811, 0.464710297032883], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.027443], dtype=float32), -0.89892185]. 
=============================================
[2019-03-26 20:08:59,703] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[61.75839 ]
 [64.635376]
 [66.20158 ]
 [69.82811 ]
 [70.012535]], R is [[61.31115723]
 [60.69804764]
 [60.09106827]
 [59.49015808]
 [58.89525604]].
[2019-03-26 20:09:01,452] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9416421e-19 1.0000000e+00 5.0464916e-17 8.0926264e-16 9.1425346e-20], sum to 1.0000
[2019-03-26 20:09:01,458] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6134
[2019-03-26 20:09:01,466] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333333, 82.00000000000001, 1.0, 2.0, 0.6182834709956576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 864022.3128965896, 864022.3128965896, 204201.8626631692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5433000.0000, 
sim time next is 5433600.0000, 
raw observation next is [30.26666666666667, 82.0, 1.0, 2.0, 0.6158046336834332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 860556.8500148747, 860556.8500148754, 203727.530860143], 
processed observation next is [1.0, 0.9130434782608695, 0.6334913112164299, 0.82, 1.0, 1.0, 0.537114016486064, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2390435694485763, 0.2390435694485765, 0.30407094158230297], 
reward next is 0.6959, 
noisyNet noise sample is [array([0.0511503], dtype=float32), -0.7280457]. 
=============================================
[2019-03-26 20:09:02,455] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.8445133e-09 9.9999976e-01 2.7369560e-09 2.5438499e-07 5.6712807e-10], sum to 1.0000
[2019-03-26 20:09:02,465] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3352
[2019-03-26 20:09:02,472] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3335595.504709763 W.
[2019-03-26 20:09:02,481] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.93333333333333, 56.0, 1.0, 2.0, 0.9483856169712718, 1.0, 2.0, 0.7947828479998986, 1.0, 2.0, 1.03, 7.005117325309504, 6.9112, 170.5573041426782, 3335595.504709763, 3268318.704278028, 611272.6995241009], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5406000.0000, 
sim time next is 5406600.0000, 
raw observation next is [36.91666666666666, 55.0, 1.0, 2.0, 0.9157275387585274, 1.0, 2.0, 0.7784538088935263, 1.0, 2.0, 1.03, 7.005114748240672, 6.9112, 170.5573041426782, 3266975.101225567, 3199700.146853064, 598132.4161562971], 
processed observation next is [1.0, 0.5652173913043478, 0.9486571879936805, 0.55, 1.0, 1.0, 0.8984669141669005, 1.0, 1.0, 0.7330768781849715, 1.0, 1.0, 1.0365853658536586, 0.009391474824067192, 0.0, 0.8375144448122397, 0.9074930836737686, 0.8888055963480734, 0.8927349494870106], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9353967], dtype=float32), 0.27896032]. 
=============================================
[2019-03-26 20:09:14,972] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 20:09:14,974] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:09:14,975] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:09:14,976] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:09:14,977] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:09:14,978] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:09:14,977] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:09:14,980] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:09:14,980] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:09:14,983] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:09:14,985] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:09:15,000] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run24
[2019-03-26 20:09:15,021] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run24
[2019-03-26 20:09:15,022] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run24
[2019-03-26 20:09:15,022] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run24
[2019-03-26 20:09:15,023] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run24
[2019-03-26 20:09:45,269] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06244335], dtype=float32), 0.060314335]
[2019-03-26 20:09:45,270] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.31666666666666, 89.33333333333333, 1.0, 2.0, 0.5098641702574394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712460.5837063199, 712460.5837063199, 185156.2316180599]
[2019-03-26 20:09:45,271] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:09:45,276] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.9086838e-19 1.0000000e+00 4.9358559e-17 2.2395403e-15 2.1614936e-19], sampled 0.12929960845281363
[2019-03-26 20:10:14,685] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06244335], dtype=float32), 0.060314335]
[2019-03-26 20:10:14,688] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.6, 60.0, 1.0, 2.0, 0.9569951609427456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1337654.235570436, 1337654.235570435, 286095.7807622626]
[2019-03-26 20:10:14,689] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:10:14,693] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.6024260e-19 1.0000000e+00 4.1397925e-17 1.9570014e-15 1.3171529e-19], sampled 0.7420776972526409
[2019-03-26 20:10:16,555] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06244335], dtype=float32), 0.060314335]
[2019-03-26 20:10:16,557] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.0, 89.0, 1.0, 2.0, 0.7854270605475355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1097718.400631324, 1097718.400631323, 240367.9100953076]
[2019-03-26 20:10:16,561] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:10:16,563] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.7332159e-18 1.0000000e+00 8.0866977e-17 3.4690118e-15 4.4550381e-19], sampled 0.08669866215989241
[2019-03-26 20:10:19,330] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06244335], dtype=float32), 0.060314335]
[2019-03-26 20:10:19,334] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.2, 59.66666666666667, 1.0, 2.0, 0.5434930867981185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 759468.8734655033, 759468.8734655033, 190690.908137785]
[2019-03-26 20:10:19,335] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:10:19,337] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.8895132e-19 1.0000000e+00 5.0657600e-17 3.1150397e-15 3.7146779e-19], sampled 0.012704523681996371
[2019-03-26 20:10:21,570] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06244335], dtype=float32), 0.060314335]
[2019-03-26 20:10:21,570] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.58333333333334, 54.5, 1.0, 2.0, 0.6208461471579345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 867604.9960122979, 867604.9960122986, 204691.1645420538]
[2019-03-26 20:10:21,570] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:10:21,574] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.5810832e-20 1.0000000e+00 2.0616238e-18 2.1716710e-16 1.2725435e-20], sampled 0.45028777354052496
[2019-03-26 20:10:32,112] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06244335], dtype=float32), 0.060314335]
[2019-03-26 20:10:32,112] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.2, 61.0, 1.0, 2.0, 0.892653030782841, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005987315677585, 6.9112, 168.9123159668307, 2144752.831495714, 2077507.702431118, 432031.2669668394]
[2019-03-26 20:10:32,113] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:10:32,120] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.8163698e-15 1.0000000e+00 2.1179501e-14 1.9202363e-12 1.5501425e-15], sampled 0.45513980868737247
[2019-03-26 20:10:32,120] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2144752.831495714 W.
[2019-03-26 20:10:40,824] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06244335], dtype=float32), 0.060314335]
[2019-03-26 20:10:40,825] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.64260755, 67.52887272, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.212076045745453, 6.9112, 168.9109621534419, 1667350.418019215, 1453901.116040908, 311348.4356018196]
[2019-03-26 20:10:40,827] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:10:40,830] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.7069396e-19 1.0000000e+00 2.1056417e-17 4.0129490e-15 2.5545390e-19], sampled 0.1451266266074962
[2019-03-26 20:10:40,831] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1667350.418019215 W.
[2019-03-26 20:10:45,565] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06244335], dtype=float32), 0.060314335]
[2019-03-26 20:10:45,566] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.40000000000001, 54.66666666666667, 1.0, 2.0, 0.9358997974116459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1308149.710658237, 1308149.710658237, 280004.2559988697]
[2019-03-26 20:10:45,566] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:10:45,570] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.2539642e-19 1.0000000e+00 2.1245945e-17 3.0238797e-15 2.8798252e-19], sampled 0.5505561871399199
[2019-03-26 20:10:46,324] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06244335], dtype=float32), 0.060314335]
[2019-03-26 20:10:46,324] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.91346258, 84.019137885, 1.0, 2.0, 0.5433905842366326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 759325.5867675231, 759325.5867675231, 190673.6889802349]
[2019-03-26 20:10:46,326] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:10:46,329] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.0747993e-18 1.0000000e+00 1.5677563e-16 4.6087207e-15 5.8363450e-19], sampled 0.6477415391333561
[2019-03-26 20:10:49,420] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06244335], dtype=float32), 0.060314335]
[2019-03-26 20:10:49,421] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.12770873, 66.6999072, 1.0, 2.0, 0.8189222690124941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1144556.770065525, 1144556.770065525, 248609.7542255623]
[2019-03-26 20:10:49,423] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:10:49,425] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.4868107e-19 1.0000000e+00 1.6657695e-17 9.8677115e-16 8.1627107e-20], sampled 0.32531622007048255
[2019-03-26 20:11:09,874] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164071917.9177 1778.0000
[2019-03-26 20:11:10,112] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2767 3007680316.3481 1766.0000
[2019-03-26 20:11:10,190] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.5681 2927329776.9375 1338.0000
[2019-03-26 20:11:10,247] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9503 2779156117.6396 933.0000
[2019-03-26 20:11:10,310] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5385 2842476554.9448 1131.0000
[2019-03-26 20:11:11,325] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 575000, evaluation results [575000.0, 7884.168443086554, 3164071917.9176674, 1778.0, 8253.568068259077, 2927329776.937506, 1338.0, 8659.950256865504, 2779156117.6396384, 933.0, 7998.276703650782, 3007680316.348062, 1766.0, 8497.538503793214, 2842476554.944838, 1131.0]
[2019-03-26 20:11:12,112] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0232269e-10 1.0000000e+00 5.1697130e-10 1.2392494e-08 7.6525730e-11], sum to 1.0000
[2019-03-26 20:11:12,121] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6241
[2019-03-26 20:11:12,131] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2003740.204729647 W.
[2019-03-26 20:11:12,136] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.53333333333333, 63.33333333333333, 1.0, 2.0, 0.477698417558381, 1.0, 2.0, 0.477698417558381, 1.0, 1.0, 0.8296041740181869, 6.9112, 6.9112, 170.5573041426782, 2003740.204729647, 2003740.204729647, 400066.8009101085], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5835000.0000, 
sim time next is 5835600.0000, 
raw observation next is [32.6, 63.0, 1.0, 2.0, 0.7809049764986088, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.005980292312801, 6.9112, 168.9123932062552, 1988349.534301391, 1921109.357087348, 403163.75063905], 
processed observation next is [1.0, 0.5652173913043478, 0.7440758293838864, 0.63, 1.0, 1.0, 0.7360300921669986, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.009478029231280072, 0.0, 0.8294371790709176, 0.5523193150837198, 0.5336414880798188, 0.6017369412523134], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13938668], dtype=float32), 1.3480135]. 
=============================================
[2019-03-26 20:11:19,043] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2530563e-20 1.0000000e+00 1.5572108e-18 5.5681532e-16 9.1512232e-20], sum to 1.0000
[2019-03-26 20:11:19,046] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2927
[2019-03-26 20:11:19,053] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.53333333333334, 89.5, 1.0, 2.0, 0.5570404966408042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 778406.7519905453, 778406.7519905453, 193015.6653702966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5955000.0000, 
sim time next is 5955600.0000, 
raw observation next is [27.46666666666667, 90.0, 1.0, 2.0, 0.5575782937230792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779158.5436857993, 779158.5436857993, 193109.0351841725], 
processed observation next is [1.0, 0.9565217391304348, 0.500789889415482, 0.9, 1.0, 1.0, 0.4669617996663605, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21643292880161094, 0.21643292880161094, 0.2882224405733918], 
reward next is 0.7118, 
noisyNet noise sample is [array([-1.3129013], dtype=float32), -0.85389626]. 
=============================================
[2019-03-26 20:11:26,753] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.2057968e-19 1.0000000e+00 1.3150564e-16 7.5552237e-16 1.3619063e-19], sum to 1.0000
[2019-03-26 20:11:26,760] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4259
[2019-03-26 20:11:26,764] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 90.16666666666667, 1.0, 2.0, 0.6862671686628288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 959069.2553212187, 959069.2553212187, 217909.5682786445], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5897400.0000, 
sim time next is 5898000.0000, 
raw observation next is [27.2, 89.33333333333334, 1.0, 2.0, 0.7328978633174595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1024267.817487945, 1024267.817487945, 228107.2523535618], 
processed observation next is [1.0, 0.2608695652173913, 0.4881516587677725, 0.8933333333333334, 1.0, 1.0, 0.6781901967680235, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2845188381910958, 0.2845188381910958, 0.34045858560233105], 
reward next is 0.6595, 
noisyNet noise sample is [array([-0.19153848], dtype=float32), -0.9862089]. 
=============================================
[2019-03-26 20:11:26,782] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[72.13903 ]
 [72.06741 ]
 [72.026665]
 [71.91456 ]
 [71.63398 ]], R is [[72.1448288 ]
 [72.0981369 ]
 [72.05387115]
 [72.00395966]
 [71.95728302]].
[2019-03-26 20:11:29,436] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.7361713e-11 1.0000000e+00 5.1358451e-10 2.5223805e-08 2.5724645e-11], sum to 1.0000
[2019-03-26 20:11:29,445] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6251
[2019-03-26 20:11:29,454] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2479679.323958042 W.
[2019-03-26 20:11:29,460] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.05, 77.0, 1.0, 2.0, 0.8865648468982897, 1.0, 1.0, 0.8865648468982897, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2479679.323958042, 2479679.323958042, 464217.2104673041], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5931000.0000, 
sim time next is 5931600.0000, 
raw observation next is [30.1, 77.33333333333334, 1.0, 2.0, 0.81500052378915, 1.0, 2.0, 0.81500052378915, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2279334.799607124, 2279334.799607124, 427245.0721098267], 
processed observation next is [1.0, 0.6521739130434783, 0.6255924170616115, 0.7733333333333334, 1.0, 1.0, 0.7771090648062048, 1.0, 1.0, 0.7771090648062048, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6331485554464233, 0.6331485554464233, 0.637679212104219], 
reward next is 0.3623, 
noisyNet noise sample is [array([1.0306038], dtype=float32), 0.43998274]. 
=============================================
[2019-03-26 20:11:29,734] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.8603205e-11 1.0000000e+00 2.6754260e-10 2.1605949e-08 1.7678520e-11], sum to 1.0000
[2019-03-26 20:11:29,750] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4873
[2019-03-26 20:11:29,760] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2353069.278584643 W.
[2019-03-26 20:11:29,766] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.4, 79.0, 1.0, 2.0, 0.5608935182103151, 1.0, 1.0, 0.5608935182103151, 1.0, 2.0, 0.974086550810387, 6.911199999999999, 6.9112, 170.5573041426782, 2353069.278584643, 2353069.278584644, 459810.022093982], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5936400.0000, 
sim time next is 5937000.0000, 
raw observation next is [30.3, 79.16666666666667, 1.0, 2.0, 0.3989318209810866, 1.0, 2.0, 0.3989318209810866, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1115103.336142019, 1115103.336142019, 271871.5588717372], 
processed observation next is [1.0, 0.7391304347826086, 0.6350710900473934, 0.7916666666666667, 1.0, 1.0, 0.27582147106155014, 1.0, 1.0, 0.27582147106155014, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.30975092670611637, 0.30975092670611637, 0.40577844607721975], 
reward next is 0.5942, 
noisyNet noise sample is [array([-1.0905402], dtype=float32), 1.0583745]. 
=============================================
[2019-03-26 20:11:29,781] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[41.043   ]
 [42.3436  ]
 [41.635044]
 [41.247574]
 [40.817017]], R is [[41.89152145]
 [41.78632355]
 [41.36846161]
 [40.95477676]
 [40.89967346]].
[2019-03-26 20:11:30,577] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0202364e-19 1.0000000e+00 6.2355806e-17 2.3920583e-15 2.2955577e-20], sum to 1.0000
[2019-03-26 20:11:30,587] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6146
[2019-03-26 20:11:30,594] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 91.33333333333334, 1.0, 2.0, 0.5486649305677026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 766698.5365819472, 766698.5365819478, 191572.0490867477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5960400.0000, 
sim time next is 5961000.0000, 
raw observation next is [26.95, 91.16666666666667, 1.0, 2.0, 0.5459869711336645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 762955.0406100419, 762955.0406100419, 191114.8963855663], 
processed observation next is [1.0, 1.0, 0.476303317535545, 0.9116666666666667, 1.0, 1.0, 0.4529963507634511, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21193195572501164, 0.21193195572501164, 0.2852461140083079], 
reward next is 0.7148, 
noisyNet noise sample is [array([-0.27492154], dtype=float32), 0.26359856]. 
=============================================
[2019-03-26 20:11:30,608] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[73.773056]
 [73.74751 ]
 [73.723724]
 [73.69253 ]
 [73.65142 ]], R is [[73.77190399]
 [73.7482605 ]
 [73.72415161]
 [73.69962311]
 [73.67474365]].
[2019-03-26 20:11:42,580] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6742890e-17 1.0000000e+00 4.0855287e-16 3.4373986e-14 2.6879004e-18], sum to 1.0000
[2019-03-26 20:11:42,587] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0872
[2019-03-26 20:11:42,593] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.28333333333333, 91.16666666666667, 1.0, 2.0, 0.8330963961850133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1164377.92881062, 1164377.928810619, 252195.8502293417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6491400.0000, 
sim time next is 6492000.0000, 
raw observation next is [26.26666666666667, 91.33333333333334, 1.0, 2.0, 0.7212835638125493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1008028.447919334, 1008028.447919334, 225505.3897366343], 
processed observation next is [1.0, 0.13043478260869565, 0.44391785150079005, 0.9133333333333334, 1.0, 1.0, 0.6641970648343968, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.28000790219981503, 0.28000790219981503, 0.33657520856214074], 
reward next is 0.6634, 
noisyNet noise sample is [array([-0.07149874], dtype=float32), -0.39108923]. 
=============================================
[2019-03-26 20:11:42,621] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[68.739624]
 [68.539696]
 [68.42865 ]
 [68.36093 ]
 [68.49635 ]], R is [[68.81526184]
 [68.7507019 ]
 [68.73891449]
 [68.72216034]
 [68.69636536]].
[2019-03-26 20:11:43,648] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8443524e-12 1.0000000e+00 4.2439149e-11 1.6346108e-09 2.3928561e-12], sum to 1.0000
[2019-03-26 20:11:43,660] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9522
[2019-03-26 20:11:43,670] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2060943.713189248 W.
[2019-03-26 20:11:43,675] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.63333333333333, 75.0, 1.0, 2.0, 0.8327745908975518, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.994815612057216, 6.9112, 168.9123887651723, 2060943.713189248, 2001624.119552534, 416520.8907345228], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6176400.0000, 
sim time next is 6177000.0000, 
raw observation next is [29.71666666666667, 74.5, 1.0, 2.0, 0.7257715651096982, 1.0, 1.0, 0.7257715651096982, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2029558.285170601, 2029558.285170601, 385353.5717273353], 
processed observation next is [1.0, 0.4782608695652174, 0.6074249605055293, 0.745, 1.0, 1.0, 0.6696042953128893, 1.0, 0.5, 0.6696042953128893, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.563766190325167, 0.563766190325167, 0.5751545846676646], 
reward next is 0.4248, 
noisyNet noise sample is [array([-0.69448453], dtype=float32), -0.01788928]. 
=============================================
[2019-03-26 20:11:43,687] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[44.35409 ]
 [44.407776]
 [44.630936]
 [46.682785]
 [46.759674]], R is [[44.26078033]
 [43.81817245]
 [43.37998962]
 [42.94618988]
 [42.51672745]].
[2019-03-26 20:11:43,797] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.7886200e-12 1.0000000e+00 6.9313486e-11 2.9115810e-09 7.5456620e-12], sum to 1.0000
[2019-03-26 20:11:43,810] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2130
[2019-03-26 20:11:43,820] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1710476.678265951 W.
[2019-03-26 20:11:43,825] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.21666666666667, 71.5, 1.0, 2.0, 0.6117539995786992, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.938419982632098, 6.9112, 168.9127462850561, 1710476.678265951, 1691165.909781031, 367129.0224828239], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6180600.0000, 
sim time next is 6181200.0000, 
raw observation next is [30.3, 71.0, 1.0, 2.0, 0.4315830289685867, 1.0, 1.0, 0.4315830289685867, 1.0, 2.0, 0.7479929145064781, 6.911199999999999, 6.9112, 170.5573041426782, 1810142.502957566, 1810142.502957566, 370828.4578590983], 
processed observation next is [1.0, 0.5652173913043478, 0.6350710900473934, 0.71, 1.0, 1.0, 0.31516027586576706, 1.0, 0.5, 0.31516027586576706, 1.0, 1.0, 0.6926742859835099, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5028173619326572, 0.5028173619326572, 0.5534753102374601], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1707044], dtype=float32), 0.18326122]. 
=============================================
[2019-03-26 20:11:44,902] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.3629874e-12 1.0000000e+00 3.0889910e-10 1.4007138e-09 2.1321141e-12], sum to 1.0000
[2019-03-26 20:11:44,909] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4194
[2019-03-26 20:11:44,916] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.75, 77.5, 1.0, 2.0, 0.4875684746969029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104273, 681295.6203202899, 681295.6203202892, 181674.4259616278], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6197400.0000, 
sim time next is 6198000.0000, 
raw observation next is [28.66666666666667, 78.0, 1.0, 2.0, 0.5008950371047298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 699923.4033164144, 699923.4033164139, 183738.8669801877], 
processed observation next is [1.0, 0.7391304347826086, 0.5576619273301741, 0.78, 1.0, 1.0, 0.3986687194032889, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1944231675878929, 0.19442316758789274, 0.27423711489580255], 
reward next is 0.7258, 
noisyNet noise sample is [array([-1.1846392], dtype=float32), 0.21719557]. 
=============================================
[2019-03-26 20:11:44,939] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[44.289204]
 [42.33163 ]
 [40.11151 ]
 [40.29471 ]
 [39.898697]], R is [[46.63495636]
 [46.89744949]
 [46.42847443]
 [45.96419144]
 [45.50455093]].
[2019-03-26 20:11:53,801] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.3473633e-20 1.0000000e+00 1.2718612e-17 1.2285205e-15 3.2540565e-20], sum to 1.0000
[2019-03-26 20:11:53,814] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1753
[2019-03-26 20:11:53,820] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.41666666666666, 82.0, 1.0, 2.0, 0.5203567118000646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 727127.3935614872, 727127.3935614872, 186846.5989268792], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6385800.0000, 
sim time next is 6386400.0000, 
raw observation next is [27.4, 82.0, 1.0, 2.0, 0.5193917096283556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 725778.4742334208, 725778.4742334208, 186689.7429614227], 
processed observation next is [0.0, 0.9565217391304348, 0.4976303317535545, 0.82, 1.0, 1.0, 0.4209538670221151, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20160513173150577, 0.20160513173150577, 0.2786414074051085], 
reward next is 0.7214, 
noisyNet noise sample is [array([-1.9199332], dtype=float32), -0.12138846]. 
=============================================
[2019-03-26 20:11:59,594] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4698175e-10 1.0000000e+00 1.1661289e-09 2.4304549e-08 5.6878967e-11], sum to 1.0000
[2019-03-26 20:11:59,606] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9369
[2019-03-26 20:11:59,614] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2020833.100945427 W.
[2019-03-26 20:11:59,618] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.9, 69.0, 1.0, 2.0, 0.4817695818351497, 1.0, 2.0, 0.4817695818351497, 1.0, 1.0, 0.8278135276129462, 6.9112, 6.9112, 170.5573041426782, 2020833.100945427, 2020833.100945427, 401227.1301765035], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6438000.0000, 
sim time next is 6438600.0000, 
raw observation next is [29.9, 69.0, 1.0, 2.0, 0.6883357170663913, 1.0, 2.0, 0.6883357170663913, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1924778.088590406, 1924778.088590406, 369167.5137877924], 
processed observation next is [1.0, 0.5217391304347826, 0.6161137440758293, 0.69, 1.0, 1.0, 0.6245008639354112, 1.0, 1.0, 0.6245008639354112, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5346605801640018, 0.5346605801640018, 0.550996289235511], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.1963084], dtype=float32), -1.1089855]. 
=============================================
[2019-03-26 20:12:01,793] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3170172e-19 1.0000000e+00 4.8787026e-18 1.4509619e-15 3.1384334e-20], sum to 1.0000
[2019-03-26 20:12:01,798] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9033
[2019-03-26 20:12:01,803] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.86666666666667, 88.33333333333334, 1.0, 2.0, 0.52873246730019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738835.4375962825, 738835.4375962825, 188220.286648948], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6480600.0000, 
sim time next is 6481200.0000, 
raw observation next is [26.83333333333333, 88.66666666666667, 1.0, 2.0, 0.5291646017967019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 739439.5000042234, 739439.5000042241, 188291.7101906741], 
processed observation next is [1.0, 0.0, 0.470774091627172, 0.8866666666666667, 1.0, 1.0, 0.4327284358996408, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20539986111228428, 0.20539986111228448, 0.28103240326966283], 
reward next is 0.7190, 
noisyNet noise sample is [array([-1.1138383], dtype=float32), 0.16539451]. 
=============================================
[2019-03-26 20:12:03,763] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2876742e-16 1.0000000e+00 4.8164479e-15 9.8024833e-13 1.1864782e-16], sum to 1.0000
[2019-03-26 20:12:03,774] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8551
[2019-03-26 20:12:03,780] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1739937.705748593 W.
[2019-03-26 20:12:03,786] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.71666666666667, 74.33333333333334, 1.0, 2.0, 0.414858036644404, 1.0, 2.0, 0.414858036644404, 1.0, 1.0, 0.7091951048548273, 6.911199999999999, 6.9112, 170.5573041426782, 1739937.705748593, 1739937.705748594, 359606.6979878964], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6513000.0000, 
sim time next is 6513600.0000, 
raw observation next is [28.93333333333334, 72.66666666666667, 1.0, 2.0, 0.4187187703878794, 1.0, 2.0, 0.4187187703878794, 1.0, 2.0, 0.7155163311830108, 6.911200000000001, 6.9112, 170.5573041426782, 1756143.106324155, 1756143.106324154, 361757.5465389492], 
processed observation next is [1.0, 0.391304347826087, 0.5703001579778835, 0.7266666666666667, 1.0, 1.0, 0.2996611691420234, 1.0, 1.0, 0.2996611691420234, 1.0, 1.0, 0.6530686965646474, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4878175295344875, 0.4878175295344872, 0.5399366366252973], 
reward next is 0.4601, 
noisyNet noise sample is [array([-0.79547924], dtype=float32), 1.5279053]. 
=============================================
[2019-03-26 20:12:04,244] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.8489757e-11 1.0000000e+00 2.0113257e-10 9.9000967e-09 4.5764221e-12], sum to 1.0000
[2019-03-26 20:12:04,252] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5274
[2019-03-26 20:12:04,260] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2229596.727199761 W.
[2019-03-26 20:12:04,266] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.1, 55.0, 1.0, 2.0, 0.953270072721905, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.973370474585385, 6.9112, 168.9125868754285, 2229596.727199761, 2185490.949303901, 450369.5271016133], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6530400.0000, 
sim time next is 6531000.0000, 
raw observation next is [31.98333333333333, 55.5, 1.0, 2.0, 0.8010044528183244, 1.0, 1.0, 0.8010044528183244, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2240156.514184684, 2240156.514184684, 420351.0116031492], 
processed observation next is [1.0, 0.6086956521739131, 0.7148499210110584, 0.555, 1.0, 1.0, 0.7602463286967764, 1.0, 0.5, 0.7602463286967764, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6222656983846344, 0.6222656983846344, 0.627389569556939], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2532861], dtype=float32), 0.69281995]. 
=============================================
[2019-03-26 20:12:04,280] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[42.212234]
 [41.862553]
 [41.63496 ]
 [41.27103 ]
 [42.384216]], R is [[41.57134628]
 [41.15563202]
 [40.74407578]
 [40.33663559]
 [39.9332695 ]].
[2019-03-26 20:12:04,812] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9207638e-19 1.0000000e+00 7.0177855e-16 2.7842200e-15 2.2459352e-19], sum to 1.0000
[2019-03-26 20:12:04,820] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0635
[2019-03-26 20:12:04,826] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.56666666666667, 88.66666666666667, 1.0, 2.0, 0.5192630779451771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 725598.6677585011, 725598.6677585011, 186669.2128722406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6569400.0000, 
sim time next is 6570000.0000, 
raw observation next is [26.5, 89.0, 1.0, 2.0, 0.5195887127387313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 726053.8530634192, 726053.8530634185, 186722.0346897692], 
processed observation next is [1.0, 0.043478260869565216, 0.4549763033175356, 0.89, 1.0, 1.0, 0.4211912201671461, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20168162585094979, 0.2016816258509496, 0.2786896040145809], 
reward next is 0.7213, 
noisyNet noise sample is [array([1.4354129], dtype=float32), 0.6926384]. 
=============================================
[2019-03-26 20:12:04,843] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[69.53443 ]
 [69.904785]
 [70.35848 ]
 [70.80402 ]
 [71.15054 ]], R is [[69.26029968]
 [69.28908539]
 [69.31764984]
 [69.34593201]
 [69.37388611]].
[2019-03-26 20:12:06,563] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 20:12:06,565] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:12:06,567] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:12:06,567] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:12:06,569] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:12:06,569] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:12:06,570] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:12:06,570] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:12:06,572] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:12:06,571] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:12:06,574] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:12:06,596] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run25
[2019-03-26 20:12:06,614] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run25
[2019-03-26 20:12:06,616] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run25
[2019-03-26 20:12:06,658] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run25
[2019-03-26 20:12:06,676] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run25
[2019-03-26 20:12:39,419] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06580801], dtype=float32), 0.06224388]
[2019-03-26 20:12:39,420] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.94894008, 96.7303224, 1.0, 2.0, 0.5243829160066478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 741169.9461522271, 741169.9461522277, 188582.0579835171]
[2019-03-26 20:12:39,421] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:12:39,424] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.23276236e-18 1.00000000e+00 1.05253776e-16 8.63120475e-15
 2.42325275e-19], sampled 0.912392590909323
[2019-03-26 20:12:43,153] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06580801], dtype=float32), 0.06224388]
[2019-03-26 20:12:43,155] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.23046481, 90.2995831, 1.0, 2.0, 0.4582391813403777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 640300.4736769453, 640300.4736769447, 177312.3303521039]
[2019-03-26 20:12:43,155] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:12:43,157] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.7339312e-16 1.0000000e+00 1.0569688e-14 2.9649658e-13 3.1904528e-17], sampled 0.46100293542597603
[2019-03-26 20:12:43,564] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06580801], dtype=float32), 0.06224388]
[2019-03-26 20:12:43,565] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.38333333333334, 80.5, 1.0, 2.0, 0.525801279665876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 769215.1648607214, 769215.1648607214, 192076.3679853522]
[2019-03-26 20:12:43,568] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:12:43,573] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.3186623e-18 1.0000000e+00 1.8531123e-16 9.1749457e-15 4.0077699e-19], sampled 0.28121813713518296
[2019-03-26 20:12:58,769] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06580801], dtype=float32), 0.06224388]
[2019-03-26 20:12:58,770] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.08333333333333, 57.16666666666667, 1.0, 2.0, 0.5627003985333133, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9543330804285128, 6.911200000000001, 6.9112, 168.9125475912408, 1573220.155546166, 1573220.155546165, 339439.7682615445]
[2019-03-26 20:12:58,771] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:12:58,773] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.5802178e-17 1.0000000e+00 1.4468938e-15 1.7141030e-13 1.8388867e-17], sampled 0.6860574336262031
[2019-03-26 20:13:52,167] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06580801], dtype=float32), 0.06224388]
[2019-03-26 20:13:52,167] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.42643458, 93.18370697, 1.0, 2.0, 0.3767436632137366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 575310.9173908726, 575310.9173908726, 172684.4668431602]
[2019-03-26 20:13:52,168] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:13:52,170] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.6196446e-18 1.0000000e+00 1.2315463e-16 8.6456382e-15 3.3109809e-19], sampled 0.6217899223628002
[2019-03-26 20:14:01,231] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6842 2927317744.9770 1338.0000
[2019-03-26 20:14:01,596] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8724 2842497929.8887 1131.0000
[2019-03-26 20:14:01,648] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 20:14:01,665] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.9141 3164157795.0059 1778.0000
[2019-03-26 20:14:01,670] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5495 3007743997.8566 1766.0000
[2019-03-26 20:14:02,686] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 600000, evaluation results [600000.0, 7881.914089799695, 3164157795.0059204, 1778.0, 8253.684239900658, 2927317744.977035, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7997.5495352406515, 3007743997.8566456, 1766.0, 8496.87235025343, 2842497929.888741, 1131.0]
[2019-03-26 20:14:04,293] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0748366e-18 1.0000000e+00 7.0827349e-16 1.0674838e-14 1.0101895e-18], sum to 1.0000
[2019-03-26 20:14:04,302] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0342
[2019-03-26 20:14:04,306] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.9, 91.5, 1.0, 2.0, 0.754033857688654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1053821.267887807, 1053821.267887807, 232938.8551451454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6586200.0000, 
sim time next is 6586800.0000, 
raw observation next is [25.96666666666667, 91.0, 1.0, 2.0, 0.7025669105951161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 981858.9333790259, 981858.9333790265, 221398.4840133816], 
processed observation next is [1.0, 0.21739130434782608, 0.42969984202211703, 0.91, 1.0, 1.0, 0.6416468802350797, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.272738592605285, 0.27273859260528516, 0.3304454985274352], 
reward next is 0.6696, 
noisyNet noise sample is [array([1.2947495], dtype=float32), -0.8170495]. 
=============================================
[2019-03-26 20:14:19,710] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7978652e-18 1.0000000e+00 1.9953628e-16 2.6386032e-14 1.6496175e-19], sum to 1.0000
[2019-03-26 20:14:19,720] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7711
[2019-03-26 20:14:19,723] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333334, 62.0, 1.0, 2.0, 0.3590494259817629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 551357.4794983586, 551357.4794983593, 170710.9904451374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6860400.0000, 
sim time next is 6861000.0000, 
raw observation next is [27.01666666666667, 60.5, 1.0, 2.0, 0.3552286247109708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 546793.3043005125, 546793.3043005131, 170366.6043472594], 
processed observation next is [0.0, 0.391304347826087, 0.4794628751974725, 0.605, 1.0, 1.0, 0.22316701772406117, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15188702897236458, 0.15188702897236475, 0.25427851395113343], 
reward next is 0.7457, 
noisyNet noise sample is [array([-0.24590859], dtype=float32), -0.27854696]. 
=============================================
[2019-03-26 20:14:19,738] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[72.901794]
 [72.86923 ]
 [72.83323 ]
 [72.786224]
 [72.727104]], R is [[72.94468689]
 [72.96044922]
 [72.97550964]
 [72.98996735]
 [73.00397491]].
[2019-03-26 20:14:29,526] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.7872978e-19 1.0000000e+00 1.2693413e-16 2.4785196e-15 1.0259367e-19], sum to 1.0000
[2019-03-26 20:14:29,539] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1375
[2019-03-26 20:14:29,549] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.65, 76.0, 1.0, 2.0, 0.5917320944556285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 846554.1892061256, 846554.1892061256, 201742.0874032477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7023000.0000, 
sim time next is 7023600.0000, 
raw observation next is [26.8, 75.0, 1.0, 2.0, 0.6364402611088918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 910828.0310405577, 910828.031040557, 210518.0316832197], 
processed observation next is [1.0, 0.30434782608695654, 0.4691943127962086, 0.75, 1.0, 1.0, 0.5619762182034841, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2530077864001549, 0.2530077864001547, 0.31420601743764137], 
reward next is 0.6858, 
noisyNet noise sample is [array([0.9090937], dtype=float32), 1.3957665]. 
=============================================
[2019-03-26 20:14:33,875] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1290778e-18 1.0000000e+00 5.8672675e-17 2.6042028e-15 1.3378950e-19], sum to 1.0000
[2019-03-26 20:14:33,887] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6466
[2019-03-26 20:14:33,891] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 91.0, 1.0, 2.0, 0.4736726639397326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 662746.8627646222, 662746.8627646222, 179686.7581658885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7088400.0000, 
sim time next is 7089000.0000, 
raw observation next is [24.96666666666667, 91.16666666666667, 1.0, 2.0, 0.4740211407467417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 663354.1910249898, 663354.1910249904, 179754.1539608379], 
processed observation next is [1.0, 0.043478260869565216, 0.3823064770932071, 0.9116666666666667, 1.0, 1.0, 0.36629053102017073, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18426505306249719, 0.18426505306249732, 0.2682897820311013], 
reward next is 0.7317, 
noisyNet noise sample is [array([2.6497235], dtype=float32), 0.14228979]. 
=============================================
[2019-03-26 20:14:33,907] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[72.97906 ]
 [73.33361 ]
 [73.765755]
 [74.2861  ]
 [74.803505]], R is [[72.55709839]
 [72.56333923]
 [72.56951904]
 [72.57554626]
 [72.58135223]].
[2019-03-26 20:14:37,336] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5653950e-17 1.0000000e+00 1.5274726e-15 2.0904385e-14 1.5560351e-18], sum to 1.0000
[2019-03-26 20:14:37,344] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1324
[2019-03-26 20:14:37,349] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 75.33333333333333, 1.0, 2.0, 0.4143900331792998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 636312.9102827344, 636312.9102827339, 178298.6179107785], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7353600.0000, 
sim time next is 7354200.0000, 
raw observation next is [24.58333333333334, 76.16666666666667, 1.0, 2.0, 0.4114681303065342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 631072.2264921246, 631072.2264921246, 177794.5795916351], 
processed observation next is [1.0, 0.08695652173913043, 0.3641390205371251, 0.7616666666666667, 1.0, 1.0, 0.2909254582006436, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17529784069225685, 0.17529784069225685, 0.26536504416661955], 
reward next is 0.7346, 
noisyNet noise sample is [array([-1.4727404], dtype=float32), 2.7026975]. 
=============================================
[2019-03-26 20:14:40,890] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.0522799e-13 1.0000000e+00 6.0218731e-12 3.6117409e-10 1.4930952e-13], sum to 1.0000
[2019-03-26 20:14:40,900] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3958
[2019-03-26 20:14:40,910] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1882300.778230643 W.
[2019-03-26 20:14:40,914] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.16666666666667, 77.0, 1.0, 2.0, 0.4487722593087126, 1.0, 1.0, 0.4487722593087126, 1.0, 2.0, 0.776978697993377, 6.9112, 6.9112, 170.5573041426782, 1882300.778230643, 1882300.778230643, 381148.342494908], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7208400.0000, 
sim time next is 7209000.0000, 
raw observation next is [29.25, 76.0, 1.0, 2.0, 0.4348347774656657, 1.0, 2.0, 0.4348347774656657, 1.0, 2.0, 0.7525940783317998, 6.9112, 6.9112, 170.5573041426782, 1823792.570607855, 1823792.570607855, 372614.5055673344], 
processed observation next is [1.0, 0.43478260869565216, 0.5853080568720379, 0.76, 1.0, 1.0, 0.3190780451393562, 1.0, 1.0, 0.3190780451393562, 1.0, 1.0, 0.6982854613802436, 0.0, 0.0, 0.8375144448122397, 0.5066090473910708, 0.5066090473910708, 0.5561410530855737], 
reward next is 0.4439, 
noisyNet noise sample is [array([0.40587184], dtype=float32), 0.7626037]. 
=============================================
[2019-03-26 20:14:40,928] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[49.75273 ]
 [51.46638 ]
 [52.123642]
 [53.292828]
 [54.25434 ]], R is [[48.16830444]
 [48.11774445]
 [47.64454269]
 [47.16809845]
 [46.69641876]].
[2019-03-26 20:14:43,147] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6520177e-18 1.0000000e+00 2.5611780e-16 1.6034400e-14 4.0827024e-19], sum to 1.0000
[2019-03-26 20:14:43,157] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4683
[2019-03-26 20:14:43,162] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.06666666666667, 89.33333333333333, 1.0, 2.0, 0.3354019002724136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 523749.3957909404, 523749.3957909399, 168705.8100013182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7260000.0000, 
sim time next is 7260600.0000, 
raw observation next is [22.03333333333333, 89.16666666666667, 1.0, 2.0, 0.3330708145564837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 520838.4301610519, 520838.4301610525, 168494.8166367773], 
processed observation next is [1.0, 0.0, 0.2432859399684044, 0.8916666666666667, 1.0, 1.0, 0.19647086091142613, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1446773417114033, 0.14467734171140348, 0.25148480095041387], 
reward next is 0.7485, 
noisyNet noise sample is [array([-0.16869467], dtype=float32), -0.3791894]. 
=============================================
[2019-03-26 20:14:46,273] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.9689864e-20 1.0000000e+00 5.2028300e-18 7.0242134e-16 1.4705958e-19], sum to 1.0000
[2019-03-26 20:14:46,283] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0963
[2019-03-26 20:14:46,294] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.73333333333333, 64.33333333333334, 1.0, 2.0, 0.7743874539833375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1179373.118487598, 1179373.118487598, 250502.7218039786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7299600.0000, 
sim time next is 7300200.0000, 
raw observation next is [26.81666666666667, 63.66666666666666, 1.0, 2.0, 0.7866281003577029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1199196.73302138, 1199196.733021379, 253857.3074249674], 
processed observation next is [1.0, 0.4782608695652174, 0.46998420221169057, 0.6366666666666666, 1.0, 1.0, 0.7429254221177144, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33311020361704996, 0.33311020361704974, 0.37889150361935436], 
reward next is 0.6211, 
noisyNet noise sample is [array([-0.2920563], dtype=float32), 0.3678796]. 
=============================================
[2019-03-26 20:14:52,269] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.5154607e-20 1.0000000e+00 4.3402034e-17 2.1914367e-15 3.6263010e-20], sum to 1.0000
[2019-03-26 20:14:52,280] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5191
[2019-03-26 20:14:52,288] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.63333333333333, 82.33333333333334, 1.0, 2.0, 0.2874782655347496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 462706.1998459483, 462706.1998459483, 164457.4963176636], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7415400.0000, 
sim time next is 7416000.0000, 
raw observation next is [21.7, 82.0, 1.0, 2.0, 0.2876649825195954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 462816.0945530452, 462816.0945530459, 164464.6261958088], 
processed observation next is [1.0, 0.8695652173913043, 0.2274881516587678, 0.82, 1.0, 1.0, 0.1417650391802354, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12856002626473478, 0.12856002626473498, 0.2454695913370281], 
reward next is 0.7545, 
noisyNet noise sample is [array([0.45457712], dtype=float32), -0.0007008654]. 
=============================================
[2019-03-26 20:14:52,311] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[75.30899 ]
 [75.400925]
 [75.56678 ]
 [75.67185 ]
 [75.807816]], R is [[75.18486786]
 [75.18756104]
 [75.19021606]
 [75.19284821]
 [75.19549561]].
[2019-03-26 20:14:57,841] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 20:14:57,847] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:14:57,847] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:14:57,848] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:14:57,849] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:14:57,849] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:14:57,850] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:14:57,850] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:14:57,851] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:14:57,850] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:14:57,852] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:14:57,876] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run26
[2019-03-26 20:14:57,895] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run26
[2019-03-26 20:14:57,897] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run26
[2019-03-26 20:14:57,945] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run26
[2019-03-26 20:14:57,946] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run26
[2019-03-26 20:14:59,675] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07052112], dtype=float32), 0.06639808]
[2019-03-26 20:14:59,679] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.9, 61.5, 1.0, 2.0, 0.80055427292565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1118871.43788565, 1118871.43788565, 244043.0491753223]
[2019-03-26 20:14:59,680] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:14:59,683] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.4916035e-21 1.0000000e+00 2.6776038e-19 4.7742056e-17 3.7990948e-22], sampled 0.7470857785693698
[2019-03-26 20:15:04,457] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07052112], dtype=float32), 0.06639808]
[2019-03-26 20:15:04,458] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.11292766, 86.22857749, 1.0, 2.0, 0.48421606102819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 702285.1770190044, 702285.177019005, 184414.5637921969]
[2019-03-26 20:15:04,458] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:15:04,460] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0271629e-18 1.0000000e+00 7.8425616e-17 4.4125940e-15 1.2763313e-19], sampled 0.21359243648884652
[2019-03-26 20:15:06,551] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07052112], dtype=float32), 0.06639808]
[2019-03-26 20:15:06,552] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.25041376666667, 82.12600259999999, 1.0, 2.0, 0.2523990583419493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 415082.5212365488, 415082.5212365495, 161143.4005270808]
[2019-03-26 20:15:06,553] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:15:06,556] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.7338304e-18 1.0000000e+00 3.1846422e-16 1.2082987e-14 4.5832196e-19], sampled 0.22572224484655645
[2019-03-26 20:15:41,976] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07052112], dtype=float32), 0.06639808]
[2019-03-26 20:15:41,976] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.7, 71.5, 1.0, 2.0, 0.5075049163980327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709162.7711583419, 709162.7711583412, 184779.8045073638]
[2019-03-26 20:15:41,977] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:15:41,981] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2396745e-20 1.0000000e+00 9.4285458e-19 2.0354010e-16 2.3644443e-21], sampled 0.5911993101551655
[2019-03-26 20:15:59,187] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07052112], dtype=float32), 0.06639808]
[2019-03-26 20:15:59,187] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.0, 89.0, 1.0, 2.0, 0.8130366652437334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1136326.4258456, 1136326.4258456, 247138.7285865187]
[2019-03-26 20:15:59,188] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:15:59,192] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.9963791e-20 1.0000000e+00 2.1178692e-18 1.7661084e-16 2.9756954e-21], sampled 0.9530677783041036
[2019-03-26 20:16:05,866] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07052112], dtype=float32), 0.06639808]
[2019-03-26 20:16:05,867] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.56960681666667, 85.75651472333334, 1.0, 2.0, 0.8251087923455618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1153207.984675918, 1153207.984675918, 250165.2120784855]
[2019-03-26 20:16:05,869] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:16:05,871] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.4230306e-19 1.0000000e+00 9.5331068e-18 1.2483382e-15 1.4466639e-20], sampled 0.9732364086074051
[2019-03-26 20:16:08,839] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07052112], dtype=float32), 0.06639808]
[2019-03-26 20:16:08,841] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.60704414, 69.47950730666666, 1.0, 2.0, 0.590251714393029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 824834.0297807849, 824834.0297807849, 198943.6028778046]
[2019-03-26 20:16:08,843] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:16:08,846] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.3006478e-22 1.0000000e+00 4.8161418e-20 1.3007665e-17 6.3890122e-23], sampled 0.5973952660908797
[2019-03-26 20:16:13,983] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07052112], dtype=float32), 0.06639808]
[2019-03-26 20:16:13,985] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.3, 63.33333333333333, 1.0, 2.0, 0.5796892209760965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 810068.0814616492, 810068.0814616486, 197022.2440292638]
[2019-03-26 20:16:13,987] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:16:13,988] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.2677833e-21 1.0000000e+00 9.1525891e-19 1.3717892e-16 1.3245433e-21], sampled 0.7367435005385925
[2019-03-26 20:16:33,865] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07052112], dtype=float32), 0.06639808]
[2019-03-26 20:16:33,867] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.88271619333334, 66.00135939333333, 1.0, 2.0, 0.590648496876272, 0.0, 1.0, 0.0, 1.0, 1.0, 1.025761108631343, 6.911200000000001, 6.9112, 168.9128195762093, 1651419.348498884, 1651419.348498883, 361745.7598698962]
[2019-03-26 20:16:33,868] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:16:33,870] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.0235469e-21 1.0000000e+00 8.3526232e-19 2.1323417e-16 2.6533405e-21], sampled 0.31204329336937076
[2019-03-26 20:16:39,087] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07052112], dtype=float32), 0.06639808]
[2019-03-26 20:16:39,089] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.75, 93.50000000000001, 1.0, 2.0, 0.493893140219897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 690136.1562771677, 690136.1562771677, 182643.6412361407]
[2019-03-26 20:16:39,090] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:16:39,094] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.9333038e-20 1.0000000e+00 8.8470044e-18 7.5179923e-16 1.1151651e-20], sampled 0.24626999756969392
[2019-03-26 20:16:52,292] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4308 2779149198.4617 933.0000
[2019-03-26 20:16:52,348] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 20:16:52,479] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 20:16:52,675] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.3850 2927277645.1185 1338.0000
[2019-03-26 20:16:52,826] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 20:16:53,841] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 625000, evaluation results [625000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8254.384998904972, 2927277645.1184874, 1338.0, 8661.430759135581, 2779149198.4616733, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 20:16:57,346] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0373334e-19 1.0000000e+00 2.3245440e-17 9.8121578e-16 8.3562839e-20], sum to 1.0000
[2019-03-26 20:16:57,354] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2457
[2019-03-26 20:16:57,361] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 76.5, 1.0, 2.0, 0.4702476916781942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 657085.2296747924, 657085.2296747918, 179066.041318213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7554600.0000, 
sim time next is 7555200.0000, 
raw observation next is [27.53333333333333, 75.66666666666666, 1.0, 2.0, 0.4717161429883107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 659137.7586540052, 659137.7586540047, 179283.6296646017], 
processed observation next is [0.0, 0.43478260869565216, 0.5039494470774091, 0.7566666666666666, 1.0, 1.0, 0.3635134252871214, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18309382184833478, 0.18309382184833461, 0.2675875069620921], 
reward next is 0.7324, 
noisyNet noise sample is [array([-1.4797963], dtype=float32), 0.03594456]. 
=============================================
[2019-03-26 20:17:01,475] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.7929331e-18 1.0000000e+00 1.5309494e-15 4.9636951e-14 1.1610550e-17], sum to 1.0000
[2019-03-26 20:17:01,484] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2615
[2019-03-26 20:17:01,493] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1743131.546584188 W.
[2019-03-26 20:17:01,496] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.76666666666667, 63.33333333333334, 1.0, 2.0, 0.6234234681813311, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.927581408687901, 6.9112, 168.9128376486929, 1743131.546584188, 1731510.019634331, 370354.8572809302], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7644000.0000, 
sim time next is 7644600.0000, 
raw observation next is [29.85, 63.0, 1.0, 2.0, 0.6344963252518899, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.949688206172116, 6.9112, 168.9127071285998, 1774117.837874399, 1746813.020066764, 372485.0526567554], 
processed observation next is [1.0, 0.4782608695652174, 0.613744075829384, 0.63, 1.0, 1.0, 0.5596341268095059, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.00384882061721159, 0.0, 0.829438720573344, 0.4928105105206664, 0.4852258389074344, 0.5559478397862021], 
reward next is 0.2516, 
noisyNet noise sample is [array([-1.3869427], dtype=float32), 1.0014875]. 
=============================================
[2019-03-26 20:17:01,831] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:01,831] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:01,864] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run4
[2019-03-26 20:17:06,888] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2948065e-11 1.0000000e+00 9.4351506e-11 3.5565482e-09 3.5545896e-12], sum to 1.0000
[2019-03-26 20:17:06,894] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4921
[2019-03-26 20:17:06,899] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.7, 61.66666666666667, 1.0, 2.0, 0.52923817421294, 1.0, 2.0, 0.52923817421294, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1479589.987743812, 1479589.987743812, 309586.2775081244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7735200.0000, 
sim time next is 7735800.0000, 
raw observation next is [31.75, 61.33333333333334, 1.0, 2.0, 0.997817137505666, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1394751.244082569, 1394751.244082569, 298261.6793300555], 
processed observation next is [1.0, 0.5217391304347826, 0.7037914691943128, 0.6133333333333334, 1.0, 1.0, 0.9973700451875495, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.38743090113404693, 0.38743090113404693, 0.445166685567247], 
reward next is 0.5548, 
noisyNet noise sample is [array([-0.89293796], dtype=float32), -0.6649407]. 
=============================================
[2019-03-26 20:17:08,222] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1633809e-16 1.0000000e+00 1.0518364e-14 2.7380894e-13 6.8827771e-18], sum to 1.0000
[2019-03-26 20:17:08,233] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8980
[2019-03-26 20:17:08,242] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.38333333333333, 75.83333333333334, 1.0, 2.0, 0.5038040579441986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 703989.6573216347, 703989.6573216347, 184194.8833086832], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7757400.0000, 
sim time next is 7758000.0000, 
raw observation next is [28.2, 77.0, 1.0, 2.0, 0.5068590382560402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 708259.9514718591, 708259.9514718591, 184678.1952016931], 
processed observation next is [1.0, 0.8260869565217391, 0.5355450236966824, 0.77, 1.0, 1.0, 0.4058542629590845, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19673887540884977, 0.19673887540884977, 0.27563909731595987], 
reward next is 0.7244, 
noisyNet noise sample is [array([0.04522613], dtype=float32), 1.0213277]. 
=============================================
[2019-03-26 20:17:08,254] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[65.647835]
 [64.404015]
 [62.339306]
 [60.671738]
 [59.29328 ]], R is [[67.07920837]
 [67.13349915]
 [67.18795776]
 [67.24259186]
 [67.2972641 ]].
[2019-03-26 20:17:08,965] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:08,965] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:09,003] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run4
[2019-03-26 20:17:12,722] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:12,723] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:12,756] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run4
[2019-03-26 20:17:17,507] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:17,508] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:17,550] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run4
[2019-03-26 20:17:17,682] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9553375e-18 1.0000000e+00 1.2080302e-16 2.4676340e-14 1.8879512e-19], sum to 1.0000
[2019-03-26 20:17:17,692] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0978
[2019-03-26 20:17:17,696] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 81.66666666666667, 1.0, 2.0, 0.5235415690042754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 731579.3287968005, 731579.3287968005, 187367.2348529376], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7935000.0000, 
sim time next is 7935600.0000, 
raw observation next is [27.8, 82.33333333333334, 1.0, 2.0, 0.5236551086158481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 731738.0398667025, 731738.0398667025, 187385.8173370538], 
processed observation next is [1.0, 0.8695652173913043, 0.5165876777251186, 0.8233333333333335, 1.0, 1.0, 0.4260904923082507, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2032605666296396, 0.2032605666296396, 0.27968032438366236], 
reward next is 0.7203, 
noisyNet noise sample is [array([-0.79277825], dtype=float32), -1.0438173]. 
=============================================
[2019-03-26 20:17:18,618] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.8856315e-19 1.0000000e+00 6.8326806e-18 6.3386138e-16 1.1307065e-19], sum to 1.0000
[2019-03-26 20:17:18,619] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9651
[2019-03-26 20:17:18,624] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 78.83333333333334, 1.0, 2.0, 0.3013051075397071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 479424.4883262644, 479424.4883262644, 165574.4798935821], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 319800.0000, 
sim time next is 320400.0000, 
raw observation next is [22.6, 79.0, 1.0, 2.0, 0.2993775856819734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 476788.9494197393, 476788.9494197399, 165393.446471702], 
processed observation next is [0.0, 0.7391304347826086, 0.27014218009478685, 0.79, 1.0, 1.0, 0.15587660925538965, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13244137483881646, 0.13244137483881663, 0.2468558902562716], 
reward next is 0.7531, 
noisyNet noise sample is [array([-1.1350186], dtype=float32), 0.6589391]. 
=============================================
[2019-03-26 20:17:18,698] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:18,699] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:18,717] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run4
[2019-03-26 20:17:19,265] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:19,265] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:19,280] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run4
[2019-03-26 20:17:19,300] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:19,303] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:19,331] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run4
[2019-03-26 20:17:19,399] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:19,400] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:19,418] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run4
[2019-03-26 20:17:19,435] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:19,436] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:19,440] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:19,440] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:19,454] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run4
[2019-03-26 20:17:19,476] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:19,476] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:19,477] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:19,479] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:19,482] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run4
[2019-03-26 20:17:19,520] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run4
[2019-03-26 20:17:19,543] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:19,543] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:19,546] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:19,545] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:19,543] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:19,544] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:17:19,549] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:19,544] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run4
[2019-03-26 20:17:19,549] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:19,570] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run4
[2019-03-26 20:17:19,596] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run4
[2019-03-26 20:17:19,658] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run4
[2019-03-26 20:17:19,692] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run4
[2019-03-26 20:17:23,391] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.4412235e-20 1.0000000e+00 3.7100630e-18 5.4078024e-16 4.0341485e-21], sum to 1.0000
[2019-03-26 20:17:23,400] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9324
[2019-03-26 20:17:23,405] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 66.33333333333334, 1.0, 2.0, 0.9701979298382953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1477756.259014511, 1477756.259014512, 307748.2391642974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 40800.0000, 
sim time next is 41400.0000, 
raw observation next is [26.5, 66.0, 1.0, 2.0, 1.011568122795368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1538833.650648151, 1538833.650648151, 321166.3498221408], 
processed observation next is [1.0, 0.4782608695652174, 0.4549763033175356, 0.66, 1.0, 1.0, 1.0139374973438167, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.4274537918467086, 0.4274537918467086, 0.4793527609285684], 
reward next is 0.5206, 
noisyNet noise sample is [array([0.3138298], dtype=float32), -0.10596244]. 
=============================================
[2019-03-26 20:17:23,461] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2525899e-20 1.0000000e+00 1.1289142e-18 8.8961859e-16 1.6310628e-21], sum to 1.0000
[2019-03-26 20:17:23,471] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9903
[2019-03-26 20:17:23,476] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 65.0, 1.0, 2.0, 0.9816847687986171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1487998.301291125, 1487998.301291124, 310516.4289071359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 43200.0000, 
sim time next is 43800.0000, 
raw observation next is [26.9, 64.66666666666667, 1.0, 2.0, 0.8976294841334724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1359017.294545552, 1359017.294545552, 284035.0235331982], 
processed observation next is [1.0, 0.5217391304347826, 0.4739336492890995, 0.6466666666666667, 1.0, 1.0, 0.8766620290764728, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.37750480404043113, 0.37750480404043113, 0.423932870945072], 
reward next is 0.5761, 
noisyNet noise sample is [array([1.5704489], dtype=float32), 1.1294398]. 
=============================================
[2019-03-26 20:17:28,356] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.9023565e-19 1.0000000e+00 1.3209230e-17 3.1589689e-15 3.3672019e-20], sum to 1.0000
[2019-03-26 20:17:28,367] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6635
[2019-03-26 20:17:28,372] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.85, 94.5, 1.0, 2.0, 0.7611937522887287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1138973.070034778, 1138973.070034778, 244615.5935863852], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 124200.0000, 
sim time next is 124800.0000, 
raw observation next is [22.83333333333333, 94.66666666666666, 1.0, 2.0, 0.6972964845658064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1043212.04975452, 1043212.049754521, 229158.2087723514], 
processed observation next is [1.0, 0.43478260869565216, 0.2812006319115322, 0.9466666666666665, 1.0, 1.0, 0.6352969693563932, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2897811249318111, 0.2897811249318114, 0.3420271772721663], 
reward next is 0.6580, 
noisyNet noise sample is [array([0.5646158], dtype=float32), -1.7455513]. 
=============================================
[2019-03-26 20:17:31,002] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.9041140e-19 1.0000000e+00 5.3875388e-17 2.0193005e-15 1.9488984e-20], sum to 1.0000
[2019-03-26 20:17:31,013] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4736
[2019-03-26 20:17:31,016] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 96.0, 1.0, 2.0, 0.3031448632281573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 483559.4951141838, 483559.4951141845, 165888.6869817479], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 173400.0000, 
sim time next is 174000.0000, 
raw observation next is [20.33333333333334, 96.0, 1.0, 2.0, 0.3022975971265512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 482554.179306344, 482554.179306344, 165820.6858335079], 
processed observation next is [0.0, 0.0, 0.16271721958925783, 0.96, 1.0, 1.0, 0.1593946953331942, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13404282758509556, 0.13404282758509556, 0.24749356094553415], 
reward next is 0.7525, 
noisyNet noise sample is [array([-0.32173446], dtype=float32), 0.05558072]. 
=============================================
[2019-03-26 20:17:31,029] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[75.86554]
 [76.40234]
 [76.68946]
 [76.71491]
 [76.73954]], R is [[75.50925446]
 [75.50656891]
 [75.50374603]
 [75.50061035]
 [75.49686432]].
[2019-03-26 20:17:40,032] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.5352812e-20 1.0000000e+00 3.9147679e-18 7.2798257e-16 6.9012228e-21], sum to 1.0000
[2019-03-26 20:17:40,043] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5158
[2019-03-26 20:17:40,049] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 77.0, 1.0, 2.0, 0.3150392842453921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 496097.0192038848, 496097.0192038848, 166688.1536447444], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 313200.0000, 
sim time next is 313800.0000, 
raw observation next is [23.33333333333333, 77.16666666666667, 1.0, 2.0, 0.3136728975625669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 494428.568492173, 494428.5684921724, 166575.4995984131], 
processed observation next is [0.0, 0.6521739130434783, 0.30489731437598716, 0.7716666666666667, 1.0, 1.0, 0.17309987658140588, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13734126902560362, 0.13734126902560345, 0.2486201486543479], 
reward next is 0.7514, 
noisyNet noise sample is [array([0.292053], dtype=float32), -0.38238794]. 
=============================================
[2019-03-26 20:17:46,258] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.8372772e-20 1.0000000e+00 1.7066582e-17 1.8795465e-16 1.9196573e-20], sum to 1.0000
[2019-03-26 20:17:46,266] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8583
[2019-03-26 20:17:46,271] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.03333333333333, 83.66666666666666, 1.0, 2.0, 0.2483630317335039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 408540.0226770592, 408540.0226770592, 160744.0411312169], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 424200.0000, 
sim time next is 424800.0000, 
raw observation next is [20.0, 84.0, 1.0, 2.0, 0.2484011189761096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 408560.1641764822, 408560.1641764816, 160748.413382857], 
processed observation next is [1.0, 0.9565217391304348, 0.1469194312796209, 0.84, 1.0, 1.0, 0.09445917948928864, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11348893449346727, 0.11348893449346711, 0.2399230050490403], 
reward next is 0.7601, 
noisyNet noise sample is [array([-1.0698035], dtype=float32), 0.102575384]. 
=============================================
[2019-03-26 20:17:48,018] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 20:17:48,019] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:17:48,020] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:48,022] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:17:48,023] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:17:48,023] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:48,024] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:48,024] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:17:48,024] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:17:48,026] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:48,026] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:17:48,052] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run27
[2019-03-26 20:17:48,072] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run27
[2019-03-26 20:17:48,092] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run27
[2019-03-26 20:17:48,111] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run27
[2019-03-26 20:17:48,112] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run27
[2019-03-26 20:17:49,695] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:17:49,695] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.42603517, 71.553314995, 1.0, 2.0, 0.5082230782416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 798660.763632607, 798660.763632607, 195152.6417288291]
[2019-03-26 20:17:49,697] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:17:49,701] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.7489757e-20 1.0000000e+00 5.8072327e-18 6.2940625e-16 7.2622774e-21], sampled 0.8099657392646143
[2019-03-26 20:18:04,727] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:18:04,728] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.37555129166667, 94.64252674333333, 1.0, 2.0, 0.3608155063136064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 547184.7890347684, 547184.7890347678, 170142.9085143887]
[2019-03-26 20:18:04,729] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:18:04,731] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.4506391e-19 1.0000000e+00 2.3707804e-17 1.6060684e-15 2.4407205e-20], sampled 0.27546586261145767
[2019-03-26 20:18:11,420] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:18:11,421] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.1, 86.0, 1.0, 2.0, 0.3561579235170261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 547306.5807380031, 547306.5807380031, 170382.9207291479]
[2019-03-26 20:18:11,425] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:18:11,426] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.34015715e-20 1.00000000e+00 1.25651072e-18 2.36121445e-16
 1.77148826e-21], sampled 0.5348355006957277
[2019-03-26 20:18:25,631] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:18:25,632] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.131631515, 85.727532315, 1.0, 2.0, 0.5649156647033784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 789415.5780497944, 789415.578049795, 194391.3958831663]
[2019-03-26 20:18:25,634] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:18:25,637] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.4009816e-22 1.0000000e+00 2.7881347e-20 8.5117489e-18 3.0258751e-23], sampled 0.009157537262654447
[2019-03-26 20:18:30,117] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:18:30,119] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.66337572, 94.667666405, 1.0, 2.0, 0.2772561794392837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 449425.8213312295, 449425.8213312295, 163547.8873084354]
[2019-03-26 20:18:30,120] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:18:30,127] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.4573528e-19 1.0000000e+00 3.0934728e-17 2.0424489e-15 3.3998047e-20], sampled 0.35136965969281597
[2019-03-26 20:18:47,040] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:18:47,042] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [37.0, 45.83333333333334, 1.0, 2.0, 0.6278979410012889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 877463.6363571997, 877463.6363572004, 206055.7261495886]
[2019-03-26 20:18:47,043] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:18:47,047] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.7246073e-22 1.0000000e+00 7.9485065e-20 2.7436044e-17 1.2893414e-22], sampled 0.6440429730262315
[2019-03-26 20:19:10,246] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:19:10,246] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.827658375, 73.53191422500001, 1.0, 2.0, 0.5730481838406154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 800784.2791345918, 800784.2791345918, 195833.1208620231]
[2019-03-26 20:19:10,249] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:19:10,252] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.5224211e-22 1.0000000e+00 1.0780925e-19 3.0664618e-17 1.3779895e-22], sampled 0.8746839475186486
[2019-03-26 20:19:16,904] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:19:16,906] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.65, 91.5, 1.0, 2.0, 0.5785051141166306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 808412.7596693789, 808412.7596693783, 196806.6259450491]
[2019-03-26 20:19:16,907] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:19:16,910] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2125661e-20 1.0000000e+00 1.3492842e-18 1.4929022e-16 1.1871091e-21], sampled 0.10324505735216172
[2019-03-26 20:19:20,106] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:19:20,109] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.73333333333333, 80.0, 1.0, 2.0, 0.5563239753437872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777405.1208294409, 777405.1208294409, 192890.7876320588]
[2019-03-26 20:19:20,111] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:19:20,113] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1956806e-21 1.0000000e+00 1.2691941e-19 3.7303159e-17 1.5954011e-22], sampled 0.7566704398940585
[2019-03-26 20:19:39,107] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:19:39,107] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.96666666666667, 64.66666666666667, 1.0, 2.0, 0.7150197493143149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 999270.3475010657, 999270.3475010657, 224123.0801190432]
[2019-03-26 20:19:39,108] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:19:39,111] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1111618e-18 1.0000000e+00 7.1038642e-17 4.7261012e-15 6.5157547e-20], sampled 0.3527446698744964
[2019-03-26 20:19:40,017] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:19:40,017] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.51666666666667, 94.16666666666667, 1.0, 2.0, 0.5476631611930595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 767961.4259707705, 767961.4259707705, 191739.8831565204]
[2019-03-26 20:19:40,019] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:19:40,023] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.9267928e-20 1.0000000e+00 3.4679481e-18 3.4674358e-16 3.1140204e-21], sampled 0.0726899358903692
[2019-03-26 20:19:42,235] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:19:42,238] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.76666666666667, 67.66666666666666, 1.0, 2.0, 0.3253391312090933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 513155.9957480194, 513155.9957480188, 167997.6534938914]
[2019-03-26 20:19:42,241] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:19:42,243] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0008185e-19 1.0000000e+00 6.9957535e-18 1.0078546e-15 1.4916866e-20], sampled 0.5673495549182103
[2019-03-26 20:19:43,213] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0730907], dtype=float32), 0.068612464]
[2019-03-26 20:19:43,215] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.1, 65.0, 1.0, 2.0, 0.3394130226934388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 536513.4856379686, 536513.485637968, 169846.4697669005]
[2019-03-26 20:19:43,217] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:19:43,218] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.4043386e-20 1.0000000e+00 2.2344082e-18 3.3866217e-16 3.3958628e-21], sampled 0.5322488525697674
[2019-03-26 20:19:43,367] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 20:19:43,381] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 20:19:43,440] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6842 2927317744.9770 1338.0000
[2019-03-26 20:19:43,442] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1685 3164067279.4129 1778.0000
[2019-03-26 20:19:43,504] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5752 2842451949.6408 1131.0000
[2019-03-26 20:19:44,521] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 650000, evaluation results [650000.0, 7884.168455680242, 3164067279.4128904, 1778.0, 8253.684239900658, 2927317744.977035, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8497.575228127671, 2842451949.640752, 1131.0]
[2019-03-26 20:19:56,242] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0918760e-20 1.0000000e+00 4.7996948e-18 1.1061936e-16 7.5189482e-21], sum to 1.0000
[2019-03-26 20:19:56,252] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3488
[2019-03-26 20:19:56,258] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.96666666666667, 62.66666666666667, 1.0, 2.0, 0.2497542569032178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 411159.580403137, 411159.5804031377, 160874.469992949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 670800.0000, 
sim time next is 671400.0000, 
raw observation next is [22.75, 64.0, 1.0, 2.0, 0.2477770852107169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 407900.3416524674, 407900.341652468, 160680.6588433189], 
processed observation next is [1.0, 0.782608695652174, 0.27725118483412325, 0.64, 1.0, 1.0, 0.09370733157917698, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11330565045901872, 0.1133056504590189, 0.23982187887062523], 
reward next is 0.7602, 
noisyNet noise sample is [array([-0.98197263], dtype=float32), 0.8294206]. 
=============================================
[2019-03-26 20:19:58,366] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7411744e-19 1.0000000e+00 2.1754508e-17 1.0198010e-15 2.8436356e-20], sum to 1.0000
[2019-03-26 20:19:58,373] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1933
[2019-03-26 20:19:58,379] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.26666666666667, 83.66666666666667, 1.0, 2.0, 0.2273105243081364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 377038.4691451734, 377038.4691451727, 158558.7234487081], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 714000.0000, 
sim time next is 714600.0000, 
raw observation next is [19.5, 82.5, 1.0, 2.0, 0.2281350297106171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 378105.1292275349, 378105.1292275355, 158669.3260739864], 
processed observation next is [1.0, 0.2608695652173913, 0.12322274881516594, 0.825, 1.0, 1.0, 0.07004220447062301, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10502920256320415, 0.1050292025632043, 0.23681988966266626], 
reward next is 0.7632, 
noisyNet noise sample is [array([-0.07748201], dtype=float32), 0.3442041]. 
=============================================
[2019-03-26 20:20:14,253] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5070226e-19 1.0000000e+00 3.2954727e-17 1.8180059e-15 6.2743207e-20], sum to 1.0000
[2019-03-26 20:20:14,263] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8170
[2019-03-26 20:20:14,272] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 93.0, 1.0, 2.0, 0.3292132708040946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 510337.8854934814, 510337.8854934814, 167546.445712559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 972600.0000, 
sim time next is 973200.0000, 
raw observation next is [21.9, 93.0, 1.0, 2.0, 0.3282851924684677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 508893.8120397911, 508893.8120397917, 167434.2684789953], 
processed observation next is [1.0, 0.2608695652173913, 0.23696682464454974, 0.93, 1.0, 1.0, 0.19070505116682857, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1413593922332753, 0.14135939223327548, 0.2499018932522318], 
reward next is 0.7501, 
noisyNet noise sample is [array([-0.02413815], dtype=float32), 0.5536521]. 
=============================================
[2019-03-26 20:20:18,588] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.9394270e-20 1.0000000e+00 8.8018914e-19 3.9889677e-17 2.6022769e-22], sum to 1.0000
[2019-03-26 20:20:18,590] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8443
[2019-03-26 20:20:18,598] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666666, 97.16666666666667, 1.0, 2.0, 0.3735297665692196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 565849.4265649362, 565849.4265649356, 171724.4730006552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1036200.0000, 
sim time next is 1036800.0000, 
raw observation next is [22.2, 97.0, 1.0, 2.0, 0.3745609537191627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 567166.5495109085, 567166.5495109091, 171831.886341989], 
processed observation next is [1.0, 0.0, 0.2511848341232228, 0.97, 1.0, 1.0, 0.24645898038453337, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15754626375303016, 0.15754626375303032, 0.2564655020029687], 
reward next is 0.7435, 
noisyNet noise sample is [array([0.5430142], dtype=float32), -0.1781289]. 
=============================================
[2019-03-26 20:20:26,612] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.8569214e-22 1.0000000e+00 9.2799222e-20 6.1568476e-17 3.5243140e-22], sum to 1.0000
[2019-03-26 20:20:26,621] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8043
[2019-03-26 20:20:26,624] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 57.5, 1.0, 2.0, 0.8694337795922499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1338358.83683975, 1338358.836839749, 278471.2090432497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1182600.0000, 
sim time next is 1183200.0000, 
raw observation next is [27.6, 57.33333333333334, 1.0, 2.0, 0.8756463434796307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1349039.152794541, 1349039.152794542, 280439.4418665444], 
processed observation next is [1.0, 0.6956521739130435, 0.5071090047393366, 0.5733333333333335, 1.0, 1.0, 0.8501763174453382, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.37473309799848364, 0.3747330979984839, 0.41856633114409614], 
reward next is 0.5814, 
noisyNet noise sample is [array([0.4341277], dtype=float32), -0.22970654]. 
=============================================
[2019-03-26 20:20:26,765] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7966888e-22 1.0000000e+00 3.4648635e-20 9.8078441e-18 1.1588795e-22], sum to 1.0000
[2019-03-26 20:20:26,775] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1322
[2019-03-26 20:20:26,780] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 57.16666666666666, 1.0, 2.0, 0.8749218469490505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1349022.648056325, 1349022.648056325, 280355.8618688554], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1183800.0000, 
sim time next is 1184400.0000, 
raw observation next is [27.6, 57.0, 1.0, 2.0, 0.8641109400539346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1333435.593337787, 1333435.593337787, 277297.3716745664], 
processed observation next is [1.0, 0.7391304347826086, 0.5071090047393366, 0.57, 1.0, 1.0, 0.8362782410288369, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3703987759271631, 0.3703987759271631, 0.4138766741411439], 
reward next is 0.5861, 
noisyNet noise sample is [array([0.9465154], dtype=float32), 0.702228]. 
=============================================
[2019-03-26 20:20:39,169] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 20:20:39,172] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:20:39,174] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:20:39,178] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:20:39,179] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:20:39,181] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:20:39,183] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:20:39,183] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:20:39,183] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:20:39,185] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:20:39,188] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:20:39,201] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run28
[2019-03-26 20:20:39,221] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run28
[2019-03-26 20:20:39,240] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run28
[2019-03-26 20:20:39,259] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run28
[2019-03-26 20:20:39,260] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run28
[2019-03-26 20:20:44,287] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07195614], dtype=float32), 0.067729115]
[2019-03-26 20:20:44,289] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [20.7, 80.0, 1.0, 2.0, 0.2603187166191264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 427142.9310148385, 427142.9310148379, 161945.1865026677]
[2019-03-26 20:20:44,291] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:20:44,294] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.7520686e-18 1.0000000e+00 1.4148431e-16 8.1209267e-15 2.2168412e-19], sampled 0.48899079902276066
[2019-03-26 20:20:58,856] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07195614], dtype=float32), 0.067729115]
[2019-03-26 20:20:58,857] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.55, 35.5, 1.0, 2.0, 0.3503617765224989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 581611.5942867066, 581611.5942867066, 172337.7319400003]
[2019-03-26 20:20:58,858] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:20:58,860] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.4697394e-19 1.0000000e+00 4.0429227e-17 3.8955121e-15 9.7282799e-20], sampled 0.15063038698433906
[2019-03-26 20:22:10,411] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07195614], dtype=float32), 0.067729115]
[2019-03-26 20:22:10,412] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.50837848, 63.42974886666667, 1.0, 2.0, 0.5812164266060625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 812203.0418758553, 812203.0418758553, 197298.3995771476]
[2019-03-26 20:22:10,414] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:22:10,416] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.7658257e-21 1.0000000e+00 3.9050708e-19 9.7899446e-17 7.0800935e-22], sampled 0.3302080731037086
[2019-03-26 20:22:33,426] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.9845 2842525325.0091 1131.0000
[2019-03-26 20:22:33,428] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 20:22:33,776] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9775 2779206587.5399 933.0000
[2019-03-26 20:22:33,831] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4154 3164065956.6075 1778.0000
[2019-03-26 20:22:33,864] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.8487 2927414887.4755 1338.0000
[2019-03-26 20:22:34,877] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 675000, evaluation results [675000.0, 7883.415429619458, 3164065956.607484, 1778.0, 8252.84871800047, 2927414887.475508, 1338.0, 8659.977453803283, 2779206587.539943, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8495.984537277802, 2842525325.009142, 1131.0]
[2019-03-26 20:22:35,189] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.2852233e-19 1.0000000e+00 1.7613776e-17 3.5876462e-15 9.6375944e-21], sum to 1.0000
[2019-03-26 20:22:35,197] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2467
[2019-03-26 20:22:35,204] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.56666666666667, 98.0, 1.0, 2.0, 0.3146155162227376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 497157.3719752533, 497157.3719752527, 166806.0286991008], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1399200.0000, 
sim time next is 1399800.0000, 
raw observation next is [20.58333333333334, 98.0, 1.0, 2.0, 0.3146256245799867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 496975.2427550306, 496975.2427550299, 166788.3153678298], 
processed observation next is [0.0, 0.17391304347826086, 0.17456556082148533, 0.98, 1.0, 1.0, 0.17424774045781533, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13804867854306405, 0.13804867854306385, 0.24893778413108927], 
reward next is 0.7511, 
noisyNet noise sample is [array([0.7453191], dtype=float32), 1.874499]. 
=============================================
[2019-03-26 20:22:35,764] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3905927e-20 1.0000000e+00 4.9770523e-18 1.0193188e-15 1.1109186e-21], sum to 1.0000
[2019-03-26 20:22:35,774] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4637
[2019-03-26 20:22:35,780] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.46666666666667, 88.33333333333334, 1.0, 2.0, 0.3838733222462882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 576914.3328353864, 576914.3328353864, 172560.3639169473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1420800.0000, 
sim time next is 1421400.0000, 
raw observation next is [23.33333333333333, 88.16666666666667, 1.0, 2.0, 0.3777673281179953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 570617.3028294251, 570617.3028294244, 172091.4384280974], 
processed observation next is [0.0, 0.43478260869565216, 0.30489731437598716, 0.8816666666666667, 1.0, 1.0, 0.25032208206987383, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15850480634150696, 0.15850480634150677, 0.2568528931762648], 
reward next is 0.7431, 
noisyNet noise sample is [array([0.030476], dtype=float32), -1.1855526]. 
=============================================
[2019-03-26 20:22:40,616] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.9226983e-20 1.0000000e+00 1.4287378e-17 6.2615894e-16 1.5989967e-21], sum to 1.0000
[2019-03-26 20:22:40,628] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0170
[2019-03-26 20:22:40,632] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.85, 97.0, 1.0, 2.0, 0.317154963496824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 499638.4752906411, 499638.4752906417, 166958.1857657255], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1488600.0000, 
sim time next is 1489200.0000, 
raw observation next is [21.06666666666667, 96.33333333333334, 1.0, 2.0, 0.3211144020052021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 504130.2420193978, 504130.2420193972, 167255.4211590555], 
processed observation next is [0.0, 0.21739130434782608, 0.19747235387045833, 0.9633333333333334, 1.0, 1.0, 0.18206554458458082, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14003617833872162, 0.14003617833872145, 0.24963495695381416], 
reward next is 0.7504, 
noisyNet noise sample is [array([0.07952274], dtype=float32), 0.091851585]. 
=============================================
[2019-03-26 20:22:41,352] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0011168e-18 1.0000000e+00 1.3498873e-17 1.8699002e-15 4.4643073e-20], sum to 1.0000
[2019-03-26 20:22:41,360] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8005
[2019-03-26 20:22:41,365] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 51.0, 1.0, 2.0, 0.3428707597271431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527662.0149253301, 527662.0149253301, 168795.5129784984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1510800.0000, 
sim time next is 1511400.0000, 
raw observation next is [29.05, 51.0, 1.0, 2.0, 0.3449039851276267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 530137.3790334774, 530137.3790334767, 168974.470872795], 
processed observation next is [0.0, 0.4782608695652174, 0.575829383886256, 0.51, 1.0, 1.0, 0.21072769292485147, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14726038306485484, 0.14726038306485464, 0.25220070279521645], 
reward next is 0.7478, 
noisyNet noise sample is [array([1.0525995], dtype=float32), 0.56776625]. 
=============================================
[2019-03-26 20:22:49,903] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.1682051e-20 1.0000000e+00 5.4564725e-18 1.6585682e-15 1.2083733e-20], sum to 1.0000
[2019-03-26 20:22:49,913] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0134
[2019-03-26 20:22:49,917] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 89.33333333333334, 1.0, 2.0, 0.457008147605568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 650229.9721294543, 650229.9721294548, 178634.0645105311], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1892400.0000, 
sim time next is 1893000.0000, 
raw observation next is [24.76666666666667, 89.66666666666666, 1.0, 2.0, 0.4555482627739102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 648744.9343583201, 648744.9343583207, 178495.5949080214], 
processed observation next is [1.0, 0.9130434782608695, 0.3728278041074251, 0.8966666666666666, 1.0, 1.0, 0.3440340515348316, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18020692621064446, 0.18020692621064463, 0.266411335683614], 
reward next is 0.7336, 
noisyNet noise sample is [array([-1.3719623], dtype=float32), 0.016357591]. 
=============================================
[2019-03-26 20:22:49,935] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[78.01075 ]
 [77.80507 ]
 [77.581375]
 [77.23268 ]
 [76.74812 ]], R is [[78.12641144]
 [78.07852936]
 [78.03111267]
 [77.98397064]
 [77.93676758]].
[2019-03-26 20:22:58,851] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.9833544e-20 1.0000000e+00 1.7051291e-17 1.5504559e-15 6.6134637e-21], sum to 1.0000
[2019-03-26 20:22:58,860] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5297
[2019-03-26 20:22:58,873] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.8, 74.83333333333334, 1.0, 2.0, 0.5460826286472423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 763088.7591808831, 763088.7591808836, 191132.0399709794], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2112600.0000, 
sim time next is 2113200.0000, 
raw observation next is [30.0, 74.0, 1.0, 2.0, 0.5477626437469091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 765437.2362863581, 765437.2362863588, 191418.6536162527], 
processed observation next is [0.0, 0.4782608695652174, 0.6208530805687204, 0.74, 1.0, 1.0, 0.45513571535772174, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21262145452398837, 0.21262145452398856, 0.2856994830093324], 
reward next is 0.7143, 
noisyNet noise sample is [array([0.410632], dtype=float32), 0.55254024]. 
=============================================
[2019-03-26 20:22:59,368] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6666777e-18 1.0000000e+00 1.7830591e-16 5.4696517e-15 4.7453129e-19], sum to 1.0000
[2019-03-26 20:22:59,381] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6417
[2019-03-26 20:22:59,386] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 94.0, 1.0, 2.0, 0.3456426327659531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 535458.5648562041, 535458.5648562048, 169532.0914627482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1818000.0000, 
sim time next is 1818600.0000, 
raw observation next is [21.83333333333334, 93.83333333333334, 1.0, 2.0, 0.3459735753827479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 535856.5860672527, 535856.5860672527, 169561.2748346665], 
processed observation next is [1.0, 0.043478260869565216, 0.23380726698262277, 0.9383333333333335, 1.0, 1.0, 0.21201635588282883, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14884905168534796, 0.14884905168534796, 0.25307652960397986], 
reward next is 0.7469, 
noisyNet noise sample is [array([1.0756241], dtype=float32), -0.40025446]. 
=============================================
[2019-03-26 20:23:00,466] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9433898e-20 1.0000000e+00 2.3671465e-18 3.3045254e-16 2.3064055e-21], sum to 1.0000
[2019-03-26 20:23:00,472] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1707
[2019-03-26 20:23:00,478] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.2, 79.5, 1.0, 2.0, 0.5599434419713749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 782464.8134040869, 782464.8134040869, 193520.9843603424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2140200.0000, 
sim time next is 2140800.0000, 
raw observation next is [29.03333333333333, 80.33333333333333, 1.0, 2.0, 0.5604960811354082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 783237.3559466929, 783237.3559466923, 193617.3095072526], 
processed observation next is [0.0, 0.782608695652174, 0.5750394944707741, 0.8033333333333332, 1.0, 1.0, 0.4704772061872387, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2175659322074147, 0.21756593220741452, 0.28898105896604864], 
reward next is 0.7110, 
noisyNet noise sample is [array([0.34867355], dtype=float32), -0.18458553]. 
=============================================
[2019-03-26 20:23:03,798] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.3021637e-20 1.0000000e+00 4.8640404e-18 2.3469004e-16 3.1776702e-20], sum to 1.0000
[2019-03-26 20:23:03,806] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8243
[2019-03-26 20:23:03,810] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.03333333333333, 88.33333333333334, 1.0, 2.0, 0.4619212663082412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 655440.5529497884, 655440.5529497884, 179131.7906215914], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1890600.0000, 
sim time next is 1891200.0000, 
raw observation next is [24.96666666666667, 88.66666666666667, 1.0, 2.0, 0.4590128919104424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 651900.7031326913, 651900.703132692, 178778.1598062251], 
processed observation next is [1.0, 0.9130434782608695, 0.3823064770932071, 0.8866666666666667, 1.0, 1.0, 0.3482083035065572, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1810835286479698, 0.18108352864797, 0.2668330743376494], 
reward next is 0.7332, 
noisyNet noise sample is [array([0.35430974], dtype=float32), 1.0687618]. 
=============================================
[2019-03-26 20:23:05,050] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1185155e-20 1.0000000e+00 1.1786149e-17 2.5683887e-16 1.1795306e-20], sum to 1.0000
[2019-03-26 20:23:05,060] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4385
[2019-03-26 20:23:05,067] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 94.0, 1.0, 2.0, 0.5033578552556454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 703365.9504080118, 703365.9504080118, 184124.0527852743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2025600.0000, 
sim time next is 2026200.0000, 
raw observation next is [25.5, 94.0, 1.0, 2.0, 0.5029984965547285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 702863.6352198946, 702863.6352198952, 184067.4316723697], 
processed observation next is [0.0, 0.43478260869565216, 0.40758293838862564, 0.94, 1.0, 1.0, 0.4012030078972632, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19523989867219294, 0.1952398986721931, 0.2747275099587608], 
reward next is 0.7253, 
noisyNet noise sample is [array([0.00287518], dtype=float32), -1.1802461]. 
=============================================
[2019-03-26 20:23:06,456] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.3088362e-18 1.0000000e+00 7.7041445e-17 1.7103596e-14 7.6541581e-20], sum to 1.0000
[2019-03-26 20:23:06,468] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8765
[2019-03-26 20:23:06,473] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 82.33333333333334, 1.0, 2.0, 0.944622855265667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1351154.575088492, 1351154.575088492, 287167.0202374759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1932000.0000, 
sim time next is 1932600.0000, 
raw observation next is [25.75, 82.16666666666667, 1.0, 2.0, 0.9591499955711602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1370467.644170956, 1370467.644170956, 291273.3067042731], 
processed observation next is [1.0, 0.34782608695652173, 0.41943127962085314, 0.8216666666666668, 1.0, 1.0, 0.9507831271941689, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.38068545671415444, 0.38068545671415444, 0.43473627866309417], 
reward next is 0.5653, 
noisyNet noise sample is [array([0.61084217], dtype=float32), 0.4642914]. 
=============================================
[2019-03-26 20:23:07,387] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7829776e-15 1.0000000e+00 8.7952513e-14 3.7777186e-12 1.1750875e-15], sum to 1.0000
[2019-03-26 20:23:07,396] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0301
[2019-03-26 20:23:07,403] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 88.0, 1.0, 2.0, 0.5436671798572236, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9226020525646972, 6.911199999999999, 6.9112, 168.9126598470645, 1563383.838635537, 1563383.838635537, 331620.9279000681], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1962000.0000, 
sim time next is 1962600.0000, 
raw observation next is [24.5, 88.33333333333334, 1.0, 2.0, 0.541128356334343, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9129564363528, 782400.6616864445, 782400.6616864452, 193620.2572637955], 
processed observation next is [1.0, 0.7391304347826086, 0.3601895734597157, 0.8833333333333334, 1.0, 1.0, 0.4471425979931843, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399447885448, 0.21733351713512347, 0.21733351713512367, 0.2889854586026799], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7749622], dtype=float32), -1.4737036]. 
=============================================
[2019-03-26 20:23:11,826] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.39257084e-19 1.00000000e+00 1.33089721e-17 1.81294316e-15
 1.21107295e-20], sum to 1.0000
[2019-03-26 20:23:11,836] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4314
[2019-03-26 20:23:11,842] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 85.33333333333334, 1.0, 2.0, 0.7423467209443687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1037479.601694007, 1037479.601694007, 230251.8085865166], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2445600.0000, 
sim time next is 2446200.0000, 
raw observation next is [27.7, 85.5, 1.0, 2.0, 0.7473744893047615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1044509.702720558, 1044509.702720558, 231403.9013687684], 
processed observation next is [1.0, 0.30434782608695654, 0.5118483412322274, 0.855, 1.0, 1.0, 0.6956319148250139, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2901415840890439, 0.2901415840890439, 0.3453789572668185], 
reward next is 0.6546, 
noisyNet noise sample is [array([0.13300699], dtype=float32), 1.0920615]. 
=============================================
[2019-03-26 20:23:15,280] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.477268e-13 1.000000e+00 3.054963e-12 4.972110e-10 5.847146e-14], sum to 1.0000
[2019-03-26 20:23:15,292] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7414
[2019-03-26 20:23:15,301] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2095324.672608743 W.
[2019-03-26 20:23:15,304] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.4, 72.0, 1.0, 2.0, 0.857339056637522, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.001758704607475, 6.9112, 168.9124175138631, 2095324.672608743, 2031079.415775619, 422653.8384390911], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2200800.0000, 
sim time next is 2201400.0000, 
raw observation next is [30.5, 71.5, 1.0, 2.0, 0.7054687864135881, 1.0, 1.0, 0.7054687864135881, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1972731.02294334, 1972731.02294334, 376477.7497993315], 
processed observation next is [1.0, 0.4782608695652174, 0.6445497630331753, 0.715, 1.0, 1.0, 0.6451431161609495, 1.0, 0.5, 0.6451431161609495, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5479808397064834, 0.5479808397064834, 0.5619070892527336], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.53695285], dtype=float32), 0.880138]. 
=============================================
[2019-03-26 20:23:20,875] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1437823e-18 1.0000000e+00 3.5223471e-17 9.5822322e-15 4.0773795e-19], sum to 1.0000
[2019-03-26 20:23:20,884] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1457
[2019-03-26 20:23:20,895] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2058183.014306735 W.
[2019-03-26 20:23:20,904] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.7, 80.0, 1.0, 2.0, 0.8308020888640424, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.992143855976874, 6.9112, 168.9115868268401, 2058183.014306735, 2000759.1226476, 416112.479292169], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2191200.0000, 
sim time next is 2191800.0000, 
raw observation next is [28.8, 79.5, 1.0, 2.0, 0.4613205023119524, 1.0, 1.0, 0.4613205023119524, 1.0, 2.0, 0.7969343309027064, 6.9112, 6.9112, 170.5573041426782, 1934979.828179007, 1934979.828179007, 388732.8074586079], 
processed observation next is [1.0, 0.34782608695652173, 0.5639810426540285, 0.795, 1.0, 1.0, 0.3509885570023523, 1.0, 0.5, 0.3509885570023523, 1.0, 1.0, 0.7523589401252517, 0.0, 0.0, 0.8375144448122397, 0.5374943967163908, 0.5374943967163908, 0.5801982200874745], 
reward next is 0.4198, 
noisyNet noise sample is [array([0.26903498], dtype=float32), 0.170839]. 
=============================================
[2019-03-26 20:23:23,182] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1568187e-16 1.0000000e+00 5.7614338e-15 5.1738583e-13 2.1156023e-16], sum to 1.0000
[2019-03-26 20:23:23,191] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6671
[2019-03-26 20:23:23,197] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.05, 75.33333333333333, 1.0, 2.0, 0.5553783215004101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 776083.1847961639, 776083.1847961632, 192728.4417279382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2227800.0000, 
sim time next is 2228400.0000, 
raw observation next is [29.9, 76.0, 1.0, 2.0, 0.5557608008668448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 776617.8551437154, 776617.8551437147, 192794.5471801717], 
processed observation next is [1.0, 0.8260869565217391, 0.6161137440758293, 0.76, 1.0, 1.0, 0.4647720492371623, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21572718198436538, 0.2157271819843652, 0.2877530554927936], 
reward next is 0.7122, 
noisyNet noise sample is [array([-0.88002706], dtype=float32), 0.79500324]. 
=============================================
[2019-03-26 20:23:23,403] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2730755e-12 1.0000000e+00 1.6854938e-11 1.4877937e-09 1.8159386e-13], sum to 1.0000
[2019-03-26 20:23:23,411] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7411
[2019-03-26 20:23:23,418] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.13333333333333, 70.66666666666667, 1.0, 2.0, 0.5390484969802792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 753255.869906509, 753255.869906509, 189943.1877000899], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2223600.0000, 
sim time next is 2224200.0000, 
raw observation next is [30.96666666666667, 71.33333333333333, 1.0, 2.0, 0.548377951945325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 766297.3710551489, 766297.3710551496, 191525.0280133157], 
processed observation next is [1.0, 0.7391304347826086, 0.6666666666666667, 0.7133333333333333, 1.0, 1.0, 0.45587705053653615, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21286038084865247, 0.21286038084865266, 0.2858582507661428], 
reward next is 0.7141, 
noisyNet noise sample is [array([1.3736261], dtype=float32), -1.5131361]. 
=============================================
[2019-03-26 20:23:29,567] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1073784e-19 1.0000000e+00 3.3699312e-17 1.6831902e-15 2.5765873e-20], sum to 1.0000
[2019-03-26 20:23:29,576] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8924
[2019-03-26 20:23:29,584] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3927254813660197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 586005.8747645393, 586005.87476454, 173252.3685203411], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2742600.0000, 
sim time next is 2743200.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3900876994207442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 582070.2072966028, 582070.2072966034, 172894.7167615541], 
processed observation next is [0.0, 0.782608695652174, 0.28909952606635075, 0.94, 1.0, 1.0, 0.2651659029165593, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16168616869350078, 0.16168616869350094, 0.25805181606202104], 
reward next is 0.7419, 
noisyNet noise sample is [array([-0.13289417], dtype=float32), 0.9987277]. 
=============================================
[2019-03-26 20:23:30,162] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 20:23:30,167] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:23:30,168] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:23:30,169] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:23:30,170] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:23:30,171] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:23:30,174] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:23:30,174] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:23:30,175] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:23:30,175] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:23:30,177] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:23:30,186] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run29
[2019-03-26 20:23:30,205] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run29
[2019-03-26 20:23:30,225] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run29
[2019-03-26 20:23:30,225] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run29
[2019-03-26 20:23:30,261] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run29
[2019-03-26 20:23:31,787] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06860191], dtype=float32), 0.064220235]
[2019-03-26 20:23:31,789] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.4, 57.5, 1.0, 2.0, 0.7799282521055937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1099686.960818262, 1099686.960818262, 240389.2996133573]
[2019-03-26 20:23:31,790] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:23:31,793] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.0213503e-19 1.0000000e+00 1.9432223e-17 2.7615099e-15 3.9685172e-20], sampled 0.3385428521787355
[2019-03-26 20:23:37,402] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06860191], dtype=float32), 0.064220235]
[2019-03-26 20:23:37,404] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [19.6, 85.0, 1.0, 2.0, 0.2386394219171848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 393702.6486954252, 393702.6486954258, 159774.2805548117]
[2019-03-26 20:23:37,407] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:23:37,414] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0956519e-17 1.0000000e+00 4.4185378e-16 3.8675070e-14 1.1942510e-18], sampled 0.3690487953400763
[2019-03-26 20:24:19,324] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06860191], dtype=float32), 0.064220235]
[2019-03-26 20:24:19,325] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.0, 84.0, 1.0, 2.0, 0.480380665497935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 671375.1440546975, 671375.1440546975, 180595.003021988]
[2019-03-26 20:24:19,326] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:24:19,328] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0951249e-18 1.0000000e+00 5.5718257e-17 8.8290479e-15 1.4164988e-19], sampled 0.9769729965679012
[2019-03-26 20:24:28,842] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06860191], dtype=float32), 0.064220235]
[2019-03-26 20:24:28,844] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [37.4, 45.16666666666666, 1.0, 2.0, 0.5999824695197342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 838437.4225132655, 838437.4225132655, 200742.1465859236]
[2019-03-26 20:24:28,845] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:24:28,847] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.3657888e-20 1.0000000e+00 3.2025472e-18 8.4975478e-16 8.7538319e-21], sampled 0.16705815553281023
[2019-03-26 20:24:31,189] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06860191], dtype=float32), 0.064220235]
[2019-03-26 20:24:31,191] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.174585855, 89.05717415000001, 1.0, 2.0, 0.5601533157468664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 782758.1990237217, 782758.1990237217, 193556.0707636568]
[2019-03-26 20:24:31,192] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:24:31,195] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.0431855e-20 1.0000000e+00 1.6933309e-18 4.8611888e-16 3.2809531e-21], sampled 0.20130818228238234
[2019-03-26 20:24:33,515] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06860191], dtype=float32), 0.064220235]
[2019-03-26 20:24:33,517] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.8, 62.0, 1.0, 2.0, 0.9248693100168514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1292722.510134276, 1292722.510134276, 276873.2374894047]
[2019-03-26 20:24:33,519] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:24:33,521] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.6101379e-20 1.0000000e+00 3.4717999e-18 6.7345107e-16 5.1238794e-21], sampled 0.2585339684772603
[2019-03-26 20:24:42,259] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06860191], dtype=float32), 0.064220235]
[2019-03-26 20:24:42,260] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.61135814, 72.69956687999999, 1.0, 2.0, 0.4865130600233059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 682627.5147455498, 682627.5147455498, 181870.9397436483]
[2019-03-26 20:24:42,261] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:24:42,264] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.593868e-20 1.000000e+00 3.563988e-18 9.150753e-16 8.140597e-21], sampled 0.4001000038328857
[2019-03-26 20:25:15,865] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06860191], dtype=float32), 0.064220235]
[2019-03-26 20:25:15,866] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.1, 75.5, 1.0, 2.0, 0.576615634214039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 805771.3672075102, 805771.3672075102, 196469.9242248872]
[2019-03-26 20:25:15,868] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:25:15,871] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.3306510e-20 1.0000000e+00 3.5913924e-18 1.0211596e-15 6.7736298e-21], sampled 0.4598552804849435
[2019-03-26 20:25:25,412] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 20:25:25,463] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4154 3163997799.2143 1778.0000
[2019-03-26 20:25:25,501] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.3130 3007656030.3370 1766.0000
[2019-03-26 20:25:25,688] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.1994 2779305917.2640 933.0000
[2019-03-26 20:25:25,691] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8494.5529 2842640641.5065 1131.0000
[2019-03-26 20:25:26,706] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 700000, evaluation results [700000.0, 7883.415429661524, 3163997799.214286, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8659.199368136167, 2779305917.264039, 933.0, 7998.312951428424, 3007656030.3370423, 1766.0, 8494.552924859718, 2842640641.5064535, 1131.0]
[2019-03-26 20:25:44,593] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.2189750e-19 1.0000000e+00 3.2959756e-17 6.7285820e-15 2.7917640e-20], sum to 1.0000
[2019-03-26 20:25:44,604] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9956
[2019-03-26 20:25:44,609] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 98.0, 1.0, 2.0, 0.3705931676615564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 561826.8458285144, 561826.8458285144, 171388.3369283464], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2758800.0000, 
sim time next is 2759400.0000, 
raw observation next is [22.0, 97.0, 1.0, 2.0, 0.3664723963152283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 557692.7297589987, 557692.7297589987, 171098.6210555367], 
processed observation next is [0.0, 0.9565217391304348, 0.2417061611374408, 0.97, 1.0, 1.0, 0.23671373050027508, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15491464715527742, 0.15491464715527742, 0.2553710762022936], 
reward next is 0.7446, 
noisyNet noise sample is [array([1.5279794], dtype=float32), 0.5820807]. 
=============================================
[2019-03-26 20:25:46,686] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.3143592e-18 1.0000000e+00 1.1904498e-16 7.2412515e-14 2.1303220e-19], sum to 1.0000
[2019-03-26 20:25:46,698] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2352
[2019-03-26 20:25:46,702] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3799617438694608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 585306.2526241723, 585306.2526241723, 173689.40024381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2793000.0000, 
sim time next is 2793600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3661254196985073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 563989.4557530059, 563989.4557530066, 171830.7491793997], 
processed observation next is [1.0, 0.34782608695652173, 0.2417061611374408, 0.94, 1.0, 1.0, 0.23629568638374374, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1566637377091683, 0.1566637377091685, 0.25646380474537267], 
reward next is 0.7435, 
noisyNet noise sample is [array([-0.9823428], dtype=float32), -0.91999]. 
=============================================
[2019-03-26 20:25:46,704] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2731080e-18 1.0000000e+00 7.6393480e-18 3.7912758e-15 1.4292597e-19], sum to 1.0000
[2019-03-26 20:25:46,713] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1705
[2019-03-26 20:25:46,720] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.4404975202183125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 632708.5283133048, 632708.5283133048, 177012.2143808495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2688600.0000, 
sim time next is 2689200.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.4399813768221698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 631967.518960236, 631967.5189602353, 176938.3436916701], 
processed observation next is [0.0, 0.13043478260869565, 0.3364928909952607, 0.94, 1.0, 1.0, 0.3252787672556263, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17554653304450998, 0.1755465330445098, 0.26408708013682103], 
reward next is 0.7359, 
noisyNet noise sample is [array([-1.1764823], dtype=float32), 1.0969821]. 
=============================================
[2019-03-26 20:25:50,333] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.2589583e-19 1.0000000e+00 5.7843086e-17 2.5077738e-15 3.8778586e-20], sum to 1.0000
[2019-03-26 20:25:50,341] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7713
[2019-03-26 20:25:50,348] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.5355604728846093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 841524.837482649, 841524.837482649, 200166.0786956559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2977200.0000, 
sim time next is 2977800.0000, 
raw observation next is [22.0, 88.00000000000001, 1.0, 2.0, 0.532402841094277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 836546.0507181135, 836546.0507181135, 199571.6985395206], 
processed observation next is [1.0, 0.4782608695652174, 0.2417061611374408, 0.8800000000000001, 1.0, 1.0, 0.4366299290292494, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23237390297725377, 0.23237390297725377, 0.2978682067754039], 
reward next is 0.7021, 
noisyNet noise sample is [array([-0.03881132], dtype=float32), -0.66461545]. 
=============================================
[2019-03-26 20:25:51,065] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6670901e-19 1.0000000e+00 2.7152736e-17 2.0331129e-15 2.1828043e-20], sum to 1.0000
[2019-03-26 20:25:51,072] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8540
[2019-03-26 20:25:51,077] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3466114755863642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 533945.5494993416, 533945.5494993416, 169321.0441365112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2763000.0000, 
sim time next is 2763600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.34953729368586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 538453.7168682074, 538453.7168682081, 169689.5798246755], 
processed observation next is [0.0, 1.0, 0.2417061611374408, 0.94, 1.0, 1.0, 0.2163099923926024, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1495704769078354, 0.1495704769078356, 0.2532680295890679], 
reward next is 0.7467, 
noisyNet noise sample is [array([1.6306918], dtype=float32), -0.8496112]. 
=============================================
[2019-03-26 20:25:59,328] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4215166e-18 1.0000000e+00 4.4000837e-17 3.5595641e-15 2.4495643e-19], sum to 1.0000
[2019-03-26 20:25:59,339] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3438
[2019-03-26 20:25:59,346] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.85, 89.5, 1.0, 2.0, 0.7060682241505758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1078598.675680693, 1078598.675680693, 233837.28362028], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2892600.0000, 
sim time next is 2893200.0000, 
raw observation next is [22.9, 89.33333333333333, 1.0, 2.0, 0.7267118807483757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1109168.379321267, 1109168.379321268, 238730.1906129474], 
processed observation next is [1.0, 0.4782608695652174, 0.2843601895734597, 0.8933333333333333, 1.0, 1.0, 0.6707372057209345, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.30810232758924083, 0.3081023275892411, 0.3563137173327573], 
reward next is 0.6437, 
noisyNet noise sample is [array([-0.93066853], dtype=float32), -0.73168826]. 
=============================================
[2019-03-26 20:26:00,728] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.5225853e-19 1.0000000e+00 1.2788377e-17 2.5191260e-15 2.3323302e-20], sum to 1.0000
[2019-03-26 20:26:00,736] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0271
[2019-03-26 20:26:00,739] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333334, 99.5, 1.0, 2.0, 0.3084631333891708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 490992.1554524192, 490992.1554524192, 166413.9369656206], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2923800.0000, 
sim time next is 2924400.0000, 
raw observation next is [20.16666666666667, 99.0, 1.0, 2.0, 0.308800462644727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 491248.2889387395, 491248.2889387395, 166428.6719962212], 
processed observation next is [1.0, 0.8695652173913043, 0.15481832543443946, 0.99, 1.0, 1.0, 0.16722947306593614, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13645785803853874, 0.13645785803853874, 0.24840100297943463], 
reward next is 0.7516, 
noisyNet noise sample is [array([-0.2425077], dtype=float32), -0.11085665]. 
=============================================
[2019-03-26 20:26:00,919] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8984053e-20 1.0000000e+00 8.6882122e-17 4.1834513e-16 1.9419078e-20], sum to 1.0000
[2019-03-26 20:26:00,931] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3613
[2019-03-26 20:26:00,935] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 97.0, 1.0, 2.0, 0.3315803871043239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 519262.2577181674, 519262.2577181674, 168389.7613645521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2917800.0000, 
sim time next is 2918400.0000, 
raw observation next is [21.0, 96.0, 1.0, 2.0, 0.327929369601104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515079.3029153354, 515079.3029153354, 168100.4300197184], 
processed observation next is [1.0, 0.782608695652174, 0.19431279620853087, 0.96, 1.0, 1.0, 0.1902763489169928, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14307758414314872, 0.14307758414314872, 0.2508961642085349], 
reward next is 0.7491, 
noisyNet noise sample is [array([0.7064229], dtype=float32), -1.3375759]. 
=============================================
[2019-03-26 20:26:02,934] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.3447125e-18 1.0000000e+00 1.5140537e-16 5.3120164e-15 2.1815568e-19], sum to 1.0000
[2019-03-26 20:26:02,944] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2925
[2019-03-26 20:26:02,952] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 96.0, 1.0, 2.0, 0.3134351607399103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 493290.6173517926, 493290.6173517926, 166472.5207403959], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2960400.0000, 
sim time next is 2961000.0000, 
raw observation next is [21.0, 97.0, 1.0, 2.0, 0.3152768574074239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 494738.7411713288, 494738.7411713288, 166542.4331262729], 
processed observation next is [1.0, 0.2608695652173913, 0.19431279620853087, 0.97, 1.0, 1.0, 0.17503235832219746, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1374274281031469, 0.1374274281031469, 0.24857079571085508], 
reward next is 0.7514, 
noisyNet noise sample is [array([2.6509068], dtype=float32), -0.3943558]. 
=============================================
[2019-03-26 20:26:02,966] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[69.43087 ]
 [69.396545]
 [69.351814]
 [69.33098 ]
 [69.320435]], R is [[69.51496124]
 [69.57134247]
 [69.6247406 ]
 [69.6807785 ]
 [69.73620605]].
[2019-03-26 20:26:06,976] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3481991e-17 1.0000000e+00 7.4761235e-16 1.6187006e-13 1.2866908e-18], sum to 1.0000
[2019-03-26 20:26:06,983] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8181
[2019-03-26 20:26:06,992] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3011493778918823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 479564.4341337842, 479564.4341337842, 165590.718614072], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3030600.0000, 
sim time next is 3031200.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3013590549690915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 479898.5322266188, 479898.5322266183, 165614.6233730871], 
processed observation next is [1.0, 0.08695652173913043, 0.1469194312796209, 1.0, 1.0, 1.0, 0.1582639216495078, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13330514784072744, 0.1333051478407273, 0.24718600503445834], 
reward next is 0.7528, 
noisyNet noise sample is [array([-0.08152001], dtype=float32), -2.3829494]. 
=============================================
[2019-03-26 20:26:07,604] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.3387991e-17 1.0000000e+00 6.0124611e-16 4.1514223e-14 7.7573375e-19], sum to 1.0000
[2019-03-26 20:26:07,614] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5272
[2019-03-26 20:26:07,619] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3136293636407088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 499421.3290167285, 499421.3290167285, 167037.5342275142], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3033000.0000, 
sim time next is 3033600.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3152831036555155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 502062.4358846961, 502062.4358846961, 167234.1481452631], 
processed observation next is [1.0, 0.08695652173913043, 0.1469194312796209, 1.0, 1.0, 1.0, 0.1750398839223078, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1394617877457489, 0.1394617877457489, 0.24960320618695986], 
reward next is 0.7504, 
noisyNet noise sample is [array([0.6852011], dtype=float32), -0.7510789]. 
=============================================
[2019-03-26 20:26:08,222] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.1725935e-18 1.0000000e+00 6.9159161e-17 4.9767370e-15 1.8521696e-19], sum to 1.0000
[2019-03-26 20:26:08,230] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7141
[2019-03-26 20:26:08,233] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.3408426909329262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 526683.8322111608, 526683.8322111614, 168784.6009892069], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3051600.0000, 
sim time next is 3052200.0000, 
raw observation next is [21.83333333333334, 95.0, 1.0, 2.0, 0.3557463601685748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 548977.406688696, 548977.4066886967, 170587.4430615893], 
processed observation next is [1.0, 0.30434782608695654, 0.23380726698262277, 0.95, 1.0, 1.0, 0.22379079538382507, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15249372408019332, 0.15249372408019352, 0.2546081239725213], 
reward next is 0.7454, 
noisyNet noise sample is [array([0.62117344], dtype=float32), 0.69859904]. 
=============================================
[2019-03-26 20:26:10,239] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.4451790e-19 1.0000000e+00 3.4544164e-17 4.4152352e-16 2.2613989e-21], sum to 1.0000
[2019-03-26 20:26:10,247] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8477
[2019-03-26 20:26:10,260] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 95.0, 1.0, 2.0, 0.5296480638879271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 787887.8744350799, 787887.8744350792, 194310.1199839892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3071400.0000, 
sim time next is 3072000.0000, 
raw observation next is [23.0, 96.0, 1.0, 2.0, 0.7583974758994021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1123210.192958733, 1123210.192958733, 242446.031017916], 
processed observation next is [1.0, 0.5652173913043478, 0.28909952606635075, 0.96, 1.0, 1.0, 0.7089126215655447, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31200283137742585, 0.31200283137742585, 0.3618597477879343], 
reward next is 0.6381, 
noisyNet noise sample is [array([0.09744447], dtype=float32), 0.26920715]. 
=============================================
[2019-03-26 20:26:10,285] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[76.10924 ]
 [76.0722  ]
 [76.043846]
 [75.99599 ]
 [75.92286 ]], R is [[76.07180023]
 [76.02106476]
 [75.98817444]
 [75.93483734]
 [75.88526154]].
[2019-03-26 20:26:12,043] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6480639e-19 1.0000000e+00 4.2747200e-19 1.4559686e-15 5.0162522e-21], sum to 1.0000
[2019-03-26 20:26:12,053] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0399
[2019-03-26 20:26:12,058] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 77.66666666666667, 1.0, 2.0, 0.5886233678286997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 822557.652259809, 822557.652259809, 198645.9138852008], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3343200.0000, 
sim time next is 3343800.0000, 
raw observation next is [30.16666666666666, 78.33333333333334, 1.0, 2.0, 0.5871957103560523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 820561.8358201879, 820561.8358201872, 198385.0043462438], 
processed observation next is [0.0, 0.6956521739130435, 0.6287519747235385, 0.7833333333333334, 1.0, 1.0, 0.5026454341639185, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22793384328338553, 0.22793384328338534, 0.2960970214123042], 
reward next is 0.7039, 
noisyNet noise sample is [array([0.36745527], dtype=float32), -0.7483659]. 
=============================================
[2019-03-26 20:26:16,022] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.2319643e-11 1.0000000e+00 1.1502387e-10 2.0181602e-08 5.3891969e-12], sum to 1.0000
[2019-03-26 20:26:16,031] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1031
[2019-03-26 20:26:16,040] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1876174.280225525 W.
[2019-03-26 20:26:16,044] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.4473128765836142, 1.0, 2.0, 0.4473128765836142, 1.0, 2.0, 0.7768345379969697, 6.9112, 6.9112, 170.5573041426782, 1876174.280225525, 1876174.280225525, 380625.2220435548], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3589200.0000, 
sim time next is 3589800.0000, 
raw observation next is [32.16666666666667, 66.33333333333334, 1.0, 2.0, 0.7506623875287941, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.005978403660233, 6.9112, 168.9123932092714, 1946025.776119699, 1878786.938775121, 396010.8894177899], 
processed observation next is [1.0, 0.5652173913043478, 0.7235387045813588, 0.6633333333333334, 1.0, 1.0, 0.6995932379864989, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.009477840366023305, 0.0, 0.8294371790857287, 0.5405627155888053, 0.5218852607708669, 0.5910610289817759], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3254756], dtype=float32), -0.74191]. 
=============================================
[2019-03-26 20:26:17,900] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7020122e-14 1.0000000e+00 2.5530855e-13 1.4017260e-10 2.0924001e-15], sum to 1.0000
[2019-03-26 20:26:17,908] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8156
[2019-03-26 20:26:17,916] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666667, 70.66666666666667, 1.0, 2.0, 0.5429697960851061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 758737.373915605, 758737.373915605, 190603.7892000405], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3435000.0000, 
sim time next is 3435600.0000, 
raw observation next is [30.33333333333334, 71.33333333333334, 1.0, 2.0, 0.5430648807823452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 758870.2912250569, 758870.2912250574, 190619.353949639], 
processed observation next is [1.0, 0.782608695652174, 0.6366508688783573, 0.7133333333333334, 1.0, 1.0, 0.4494757599787291, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21079730311807135, 0.21079730311807152, 0.284506498432297], 
reward next is 0.7155, 
noisyNet noise sample is [array([0.78341335], dtype=float32), 0.09501623]. 
=============================================
[2019-03-26 20:26:21,998] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 20:26:22,002] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:26:22,003] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:26:22,005] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:26:22,006] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:26:22,008] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:26:22,009] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:26:22,010] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:26:22,011] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:26:22,012] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:26:22,012] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:26:22,033] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run30
[2019-03-26 20:26:22,057] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run30
[2019-03-26 20:26:22,058] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run30
[2019-03-26 20:26:22,058] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run30
[2019-03-26 20:26:22,111] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run30
[2019-03-26 20:26:56,705] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07051379], dtype=float32), 0.06578362]
[2019-03-26 20:26:56,706] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.69305425, 69.67835767, 1.0, 2.0, 0.6782824107484248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 947905.4495306101, 947905.4495306101, 216229.0163539361]
[2019-03-26 20:26:56,707] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:26:56,709] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.9734403e-20 1.0000000e+00 1.6851985e-18 3.1686587e-16 2.5392732e-21], sampled 0.9200012568239189
[2019-03-26 20:26:58,895] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07051379], dtype=float32), 0.06578362]
[2019-03-26 20:26:58,896] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.63333333333333, 79.0, 1.0, 2.0, 0.637691972844985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 931838.3036698964, 931838.3036698964, 213215.6281650336]
[2019-03-26 20:26:58,896] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:26:58,899] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.9753225e-19 1.0000000e+00 1.8427910e-17 1.9796924e-15 2.2789886e-20], sampled 0.8164875630929845
[2019-03-26 20:27:00,414] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07051379], dtype=float32), 0.06578362]
[2019-03-26 20:27:00,416] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.1, 82.0, 1.0, 2.0, 0.8433519886899967, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.987767024817693, 6.9112, 168.9124386241294, 2075747.931680686, 2021428.815584054, 419505.3415509235]
[2019-03-26 20:27:00,417] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:27:00,419] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.1983527e-15 1.0000000e+00 2.3822520e-14 5.7139358e-12 5.3345743e-16], sampled 0.2650629312735697
[2019-03-26 20:27:00,420] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2075747.931680686 W.
[2019-03-26 20:27:34,460] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07051379], dtype=float32), 0.06578362]
[2019-03-26 20:27:34,461] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [37.2, 42.66666666666667, 1.0, 2.0, 1.009586306850093, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.000401068615696, 6.9112, 168.9123537440784, 2308419.881973157, 2245137.799656427, 466480.2283242022]
[2019-03-26 20:27:34,462] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:27:34,467] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.0475910e-13 1.0000000e+00 1.9534131e-12 1.6436390e-10 3.6513253e-14], sampled 0.08205236817114303
[2019-03-26 20:27:34,469] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2308419.881973157 W.
[2019-03-26 20:27:39,754] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07051379], dtype=float32), 0.06578362]
[2019-03-26 20:27:39,756] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.16666666666667, 69.5, 1.0, 2.0, 0.8944623320804566, 1.0, 2.0, 0.8944623320804566, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2501790.324053546, 2501790.324053545, 468480.1379034643]
[2019-03-26 20:27:39,758] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:27:39,760] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.4302056e-12 1.0000000e+00 3.8835293e-12 1.5854981e-09 2.4233987e-13], sampled 0.5227294804163694
[2019-03-26 20:27:39,761] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2501790.324053546 W.
[2019-03-26 20:28:09,588] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07051379], dtype=float32), 0.06578362]
[2019-03-26 20:28:09,589] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.94944702666667, 94.80241878, 1.0, 2.0, 0.3456252917432709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 551576.4898623539, 551576.4898623539, 171098.3832453467]
[2019-03-26 20:28:09,591] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:28:09,596] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.3361347e-18 1.0000000e+00 1.1584896e-16 7.8406545e-15 1.4202431e-19], sampled 0.20300548964559295
[2019-03-26 20:28:12,393] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07051379], dtype=float32), 0.06578362]
[2019-03-26 20:28:12,395] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.298544325, 72.76596982333334, 1.0, 2.0, 0.45453284065036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 648289.3485723737, 648289.3485723737, 178473.2462400253]
[2019-03-26 20:28:12,396] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:28:12,397] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.3656364e-19 1.0000000e+00 5.9557517e-18 1.1243688e-15 1.1341272e-20], sampled 0.004603624518687122
[2019-03-26 20:28:17,118] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.8169 3007629189.2715 1766.0000
[2019-03-26 20:28:17,402] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6703 2927361465.7317 1338.0000
[2019-03-26 20:28:17,444] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8356 2842522561.2823 1131.0000
[2019-03-26 20:28:17,578] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 20:28:17,585] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.2711 2779256177.9474 933.0000
[2019-03-26 20:28:18,600] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 725000, evaluation results [725000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8253.670307618522, 2927361465.731651, 1338.0, 8661.271088261434, 2779256177.947352, 933.0, 7996.81694110405, 3007629189.271529, 1766.0, 8496.835586979434, 2842522561.2823186, 1131.0]
[2019-03-26 20:28:22,953] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6112722e-15 1.0000000e+00 2.8039664e-14 1.2624890e-12 1.5463449e-15], sum to 1.0000
[2019-03-26 20:28:22,963] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4128
[2019-03-26 20:28:22,972] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2181538.103874469 W.
[2019-03-26 20:28:22,979] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.33333333333334, 68.66666666666667, 1.0, 2.0, 0.520042918733616, 1.0, 1.0, 0.520042918733616, 1.0, 2.0, 0.8976620619147561, 6.911200000000001, 6.9112, 170.5573041426782, 2181538.103874469, 2181538.103874468, 428248.2381265859], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3576000.0000, 
sim time next is 3576600.0000, 
raw observation next is [30.5, 68.0, 1.0, 2.0, 0.7755444742638068, 1.0, 2.0, 0.7755444742638068, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2168884.88508394, 2168884.885083939, 408138.5668309193], 
processed observation next is [1.0, 0.391304347826087, 0.6445497630331753, 0.68, 1.0, 1.0, 0.7295716557395262, 1.0, 1.0, 0.7295716557395262, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6024680236344278, 0.6024680236344275, 0.6091620400461482], 
reward next is 0.3908, 
noisyNet noise sample is [array([1.0173818], dtype=float32), -1.8006095]. 
=============================================
[2019-03-26 20:28:27,611] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.59126817e-17 1.00000000e+00 3.85005274e-16 1.06214645e-14
 9.38415932e-19], sum to 1.0000
[2019-03-26 20:28:27,620] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1223
[2019-03-26 20:28:27,623] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.7511585591953072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1073596.744355148, 1073596.744355148, 235529.3833489165], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3723600.0000, 
sim time next is 3724200.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.7120148643517216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1017636.38555769, 1017636.385557691, 226492.0396493571], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.74, 1.0, 1.0, 0.6530299570502669, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.282676773766025, 0.2826767737660253, 0.33804782037217473], 
reward next is 0.6620, 
noisyNet noise sample is [array([-1.337992], dtype=float32), 0.3795308]. 
=============================================
[2019-03-26 20:28:38,124] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9313347e-07 9.9998796e-01 3.6949726e-07 1.1440402e-05 4.0797804e-08], sum to 1.0000
[2019-03-26 20:28:38,134] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4475
[2019-03-26 20:28:38,141] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2995765.788038054 W.
[2019-03-26 20:28:38,146] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.0, 60.0, 1.0, 2.0, 0.7866350280206407, 1.0, 2.0, 0.713907553524583, 1.0, 2.0, 1.03, 7.005104564241957, 6.9112, 170.5573041426782, 2995765.788038054, 2928498.128878089, 550088.7375066765], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4030800.0000, 
sim time next is 4031400.0000, 
raw observation next is [34.0, 60.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.121743801388431, 6.9112, 170.5573041426782, 3060326.510999545, 2909505.421690744, 552549.0375043012], 
processed observation next is [1.0, 0.6521739130434783, 0.8104265402843602, 0.6, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.021054380138843067, 0.0, 0.8375144448122397, 0.8500906974998736, 0.8081959504696511, 0.8247000559765689], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05721994], dtype=float32), -0.3504978]. 
=============================================
[2019-03-26 20:28:43,502] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3248057e-07 9.9994397e-01 5.3816825e-07 5.5176923e-05 7.5134878e-08], sum to 1.0000
[2019-03-26 20:28:43,508] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4856
[2019-03-26 20:28:43,513] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3394976.818134333 W.
[2019-03-26 20:28:43,522] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.16666666666666, 66.5, 1.0, 2.0, 0.9766451445331129, 1.0, 2.0, 0.8089126117808191, 1.0, 2.0, 1.03, 7.005119555514479, 6.9112, 170.5573041426782, 3394976.818134333, 3327698.420116054, 622965.4380759565], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4117800.0000, 
sim time next is 4118400.0000, 
raw observation next is [35.0, 67.0, 1.0, 2.0, 0.9677778073302755, 1.0, 2.0, 0.8044789431794002, 1.0, 2.0, 1.03, 7.005118855692995, 6.9112, 170.5573041426782, 3376343.713939696, 3309065.817232014, 619264.420551235], 
processed observation next is [1.0, 0.6956521739130435, 0.8578199052132701, 0.67, 1.0, 1.0, 0.9611780811208139, 1.0, 1.0, 0.7644324616619279, 1.0, 1.0, 1.0365853658536586, 0.009391885569299508, 0.0, 0.8375144448122397, 0.9378732538721378, 0.919184949231115, 0.9242752545540821], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3864328], dtype=float32), -0.032998506]. 
=============================================
[2019-03-26 20:28:46,317] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.97158564e-20 1.00000000e+00 5.03348967e-19 1.06871325e-16
 2.61696176e-21], sum to 1.0000
[2019-03-26 20:28:46,326] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7412
[2019-03-26 20:28:46,333] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.0, 57.33333333333333, 1.0, 2.0, 0.6093395870336394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 851518.6419786054, 851518.6419786054, 202499.3785488599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3854400.0000, 
sim time next is 3855000.0000, 
raw observation next is [35.0, 56.66666666666667, 1.0, 2.0, 0.6045622374870508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 844839.9029176588, 844839.9029176594, 201599.4660853402], 
processed observation next is [0.0, 0.6086956521739131, 0.8578199052132701, 0.5666666666666668, 1.0, 1.0, 0.523568960827772, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23467775081046077, 0.23467775081046094, 0.3008947255005077], 
reward next is 0.6991, 
noisyNet noise sample is [array([0.7410016], dtype=float32), 0.059025142]. 
=============================================
[2019-03-26 20:28:46,345] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[76.24351 ]
 [76.215485]
 [76.202354]
 [76.16079 ]
 [76.10001 ]], R is [[76.1842804 ]
 [76.12020111]
 [76.05548096]
 [75.98982239]
 [75.92292023]].
[2019-03-26 20:28:48,348] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1902338e-17 1.0000000e+00 1.0328815e-15 4.6191424e-14 3.8803022e-19], sum to 1.0000
[2019-03-26 20:28:48,353] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7939
[2019-03-26 20:28:48,361] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.83333333333333, 75.66666666666667, 1.0, 2.0, 0.5566760394165543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777897.274046499, 777897.274046499, 192952.8135621715], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3787800.0000, 
sim time next is 3788400.0000, 
raw observation next is [29.66666666666667, 76.33333333333334, 1.0, 2.0, 0.5575228775608567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 779081.0768769619, 779081.0768769624, 193099.6265252201], 
processed observation next is [1.0, 0.8695652173913043, 0.6050552922590839, 0.7633333333333334, 1.0, 1.0, 0.46689503320585146, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21641141024360053, 0.21641141024360067, 0.288208397798836], 
reward next is 0.7118, 
noisyNet noise sample is [array([-0.9780326], dtype=float32), 0.5528899]. 
=============================================
[2019-03-26 20:28:52,078] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.3829906e-20 1.0000000e+00 6.3205706e-18 6.4037973e-16 5.2462896e-21], sum to 1.0000
[2019-03-26 20:28:52,085] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7794
[2019-03-26 20:28:52,088] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.66666666666667, 60.66666666666667, 1.0, 2.0, 0.6211640916239537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 868049.490890921, 868049.4908909217, 204755.9348768251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3849600.0000, 
sim time next is 3850200.0000, 
raw observation next is [34.75, 60.5, 1.0, 2.0, 0.6203133274136174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 866860.1001569517, 866860.1001569517, 204592.3819506234], 
processed observation next is [0.0, 0.5652173913043478, 0.8459715639810427, 0.605, 1.0, 1.0, 0.5425461776067679, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2407944722658199, 0.2407944722658199, 0.3053617641054081], 
reward next is 0.6946, 
noisyNet noise sample is [array([-1.2282217], dtype=float32), -0.3765963]. 
=============================================
[2019-03-26 20:28:52,396] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.3261674e-20 1.0000000e+00 2.9310512e-19 4.0657523e-16 1.4392377e-21], sum to 1.0000
[2019-03-26 20:28:52,406] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6234
[2019-03-26 20:28:52,412] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.0, 56.66666666666667, 1.0, 2.0, 0.6045622374870508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 844839.9029176588, 844839.9029176594, 201599.4660853402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3855000.0000, 
sim time next is 3855600.0000, 
raw observation next is [35.0, 56.0, 1.0, 2.0, 0.5995248817101846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 837797.7203946159, 837797.7203946159, 200657.9150921838], 
processed observation next is [0.0, 0.6521739130434783, 0.8578199052132701, 0.56, 1.0, 1.0, 0.5174998574821501, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23272158899850443, 0.23272158899850443, 0.2994894255107221], 
reward next is 0.7005, 
noisyNet noise sample is [array([0.0215157], dtype=float32), 0.3538759]. 
=============================================
[2019-03-26 20:28:53,814] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.6758186e-17 1.0000000e+00 9.6850832e-17 1.4426894e-14 1.9922490e-19], sum to 1.0000
[2019-03-26 20:28:53,826] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1832
[2019-03-26 20:28:53,832] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 89.0, 1.0, 2.0, 0.8809010652799849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1231230.906649581, 1231230.906649581, 264740.7812458202], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4168200.0000, 
sim time next is 4168800.0000, 
raw observation next is [28.0, 89.0, 1.0, 2.0, 0.8841526440840171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1235778.266542298, 1235778.266542298, 265618.3853730501], 
processed observation next is [1.0, 0.2608695652173913, 0.5260663507109005, 0.89, 1.0, 1.0, 0.860424872390382, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3432717407061939, 0.3432717407061939, 0.39644535130305986], 
reward next is 0.6036, 
noisyNet noise sample is [array([-0.9592869], dtype=float32), 1.3765078]. 
=============================================
[2019-03-26 20:29:02,380] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.1251773e-09 9.9999428e-01 1.4660727e-08 5.7422121e-06 1.1528311e-09], sum to 1.0000
[2019-03-26 20:29:02,388] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4539
[2019-03-26 20:29:02,394] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2969376.173182256 W.
[2019-03-26 20:29:02,398] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.0, 60.0, 1.0, 2.0, 0.7740723785544233, 1.0, 2.0, 0.7076262287914743, 1.0, 1.0, 1.03, 7.005103573421169, 6.9112, 170.5573041426782, 2969376.173182256, 2902109.223787526, 545745.3147679911], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4024800.0000, 
sim time next is 4025400.0000, 
raw observation next is [34.0, 60.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.494993859959802, 6.9112, 170.5573041426782, 3328012.156172819, 2909816.867067693, 550462.7165547883], 
processed observation next is [1.0, 0.6086956521739131, 0.8104265402843602, 0.6, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.05837938599598021, 0.0, 0.8375144448122397, 0.9244478211591164, 0.8082824630743591, 0.8215861441116243], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.78086424], dtype=float32), -0.6662792]. 
=============================================
[2019-03-26 20:29:10,732] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.1767402e-18 1.0000000e+00 8.4185554e-18 4.1942234e-15 2.3478001e-20], sum to 1.0000
[2019-03-26 20:29:10,736] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9213
[2019-03-26 20:29:10,746] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 75.0, 1.0, 2.0, 0.632694677132829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 884169.6839489749, 884169.6839489749, 206995.7315317388], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4445400.0000, 
sim time next is 4446000.0000, 
raw observation next is [32.0, 75.0, 1.0, 2.0, 0.633447829405717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 885222.6277207539, 885222.6277207533, 207143.3702792489], 
processed observation next is [0.0, 0.4782608695652174, 0.7156398104265403, 0.75, 1.0, 1.0, 0.5583708788020686, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24589517436687608, 0.2458951743668759, 0.30916920937201325], 
reward next is 0.6908, 
noisyNet noise sample is [array([0.2344977], dtype=float32), 0.042543363]. 
=============================================
[2019-03-26 20:29:10,784] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[71.74695 ]
 [71.69974 ]
 [71.65648 ]
 [71.61592 ]
 [71.567566]], R is [[71.7766571 ]
 [71.74993896]
 [71.72358704]
 [71.69732666]
 [71.67050171]].
[2019-03-26 20:29:11,431] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2923950e-14 1.0000000e+00 3.4186353e-13 9.3375974e-11 5.3662332e-15], sum to 1.0000
[2019-03-26 20:29:11,444] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2093
[2019-03-26 20:29:11,453] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2657684.574548648 W.
[2019-03-26 20:29:11,459] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.33333333333334, 69.16666666666667, 1.0, 2.0, 0.9501398153508931, 1.0, 2.0, 0.9501398153508931, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2657684.574548648, 2657684.574548648, 499597.4950276015], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4180200.0000, 
sim time next is 4180800.0000, 
raw observation next is [33.66666666666667, 67.33333333333334, 1.0, 2.0, 0.6949085594008445, 1.0, 2.0, 0.6680443192146848, 1.0, 1.0, 1.03, 7.005097330704058, 6.9112, 170.5573041426782, 2803094.244581169, 2735831.767098643, 519727.2420213423], 
processed observation next is [1.0, 0.391304347826087, 0.7946287519747238, 0.6733333333333335, 1.0, 1.0, 0.6324199510853548, 1.0, 1.0, 0.6000533966441985, 1.0, 0.5, 1.0365853658536586, 0.009389733070405804, 0.0, 0.8375144448122397, 0.7786372901614358, 0.7599532686385119, 0.7757123015243914], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.35764802], dtype=float32), 0.42265302]. 
=============================================
[2019-03-26 20:29:12,362] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.2777264e-18 1.0000000e+00 1.2442346e-16 2.7238313e-14 1.1994415e-19], sum to 1.0000
[2019-03-26 20:29:12,370] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2446
[2019-03-26 20:29:12,375] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.5, 75.0, 1.0, 2.0, 0.6176027634820951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 863070.6693976154, 863070.6693976154, 204071.4122473456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4224600.0000, 
sim time next is 4225200.0000, 
raw observation next is [31.66666666666666, 73.66666666666666, 1.0, 2.0, 0.6142260544652046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 858349.9713901208, 858349.9713901208, 203426.4550872703], 
processed observation next is [1.0, 0.9130434782608695, 0.6998420221169034, 0.7366666666666666, 1.0, 1.0, 0.5352121138134995, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23843054760836688, 0.23843054760836688, 0.30362157475711987], 
reward next is 0.6964, 
noisyNet noise sample is [array([1.5902917], dtype=float32), -0.85921127]. 
=============================================
[2019-03-26 20:29:13,864] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 20:29:13,866] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:29:13,867] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:29:13,868] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:29:13,870] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:29:13,870] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:29:13,872] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:29:13,873] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:29:13,873] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:29:13,874] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:29:13,877] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:29:13,900] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run31
[2019-03-26 20:29:13,900] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run31
[2019-03-26 20:29:13,940] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run31
[2019-03-26 20:29:13,941] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run31
[2019-03-26 20:29:13,975] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run31
[2019-03-26 20:29:24,997] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06652622], dtype=float32), 0.06053268]
[2019-03-26 20:29:24,999] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.04510238, 91.24776275, 1.0, 2.0, 0.2729342525619293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 444218.2805861628, 444218.2805861628, 163173.5436699264]
[2019-03-26 20:29:25,001] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:29:25,003] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.9135739e-17 1.0000000e+00 1.6300850e-15 8.6782883e-14 1.8172265e-18], sampled 0.9891414129784043
[2019-03-26 20:29:28,991] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06652622], dtype=float32), 0.06053268]
[2019-03-26 20:29:28,992] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.9, 92.16666666666667, 1.0, 2.0, 0.3243463421572204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 504104.9634368094, 504104.9634368094, 167107.9997366096]
[2019-03-26 20:29:28,996] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:29:28,998] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.3194172e-17 1.0000000e+00 3.4762960e-16 1.5730596e-14 1.9593580e-19], sampled 0.2359391285429404
[2019-03-26 20:29:30,040] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06652622], dtype=float32), 0.06053268]
[2019-03-26 20:29:30,041] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.7, 84.33333333333334, 1.0, 2.0, 0.2958247489382581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 472896.2280765323, 472896.2280765329, 165142.5376199511]
[2019-03-26 20:29:30,043] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:29:30,046] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.8084575e-17 1.0000000e+00 1.0882136e-15 6.1896967e-14 9.8196317e-19], sampled 0.9458441127750887
[2019-03-26 20:30:41,946] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06652622], dtype=float32), 0.06053268]
[2019-03-26 20:30:41,947] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.75, 82.66666666666667, 1.0, 2.0, 0.5344110712102559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 746773.3435512764, 746773.3435512757, 189162.8819221621]
[2019-03-26 20:30:41,948] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:30:41,951] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.50621803e-18 1.00000000e+00 1.13882031e-16 1.22893825e-14
 4.70425305e-20], sampled 0.5724848567726205
[2019-03-26 20:31:08,708] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5374 3007679688.9915 1766.0000
[2019-03-26 20:31:09,056] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5144 2842492707.2201 1131.0000
[2019-03-26 20:31:09,069] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6673 3164135639.9928 1778.0000
[2019-03-26 20:31:09,121] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6857 2927400807.7850 1338.0000
[2019-03-26 20:31:09,137] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 20:31:10,154] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 750000, evaluation results [750000.0, 7882.667340294582, 3164135639.9928446, 1778.0, 8253.68573338827, 2927400807.784972, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7997.53741177424, 3007679688.9914675, 1766.0, 8497.514395919725, 2842492707.2200756, 1131.0]
[2019-03-26 20:31:17,792] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.2160114e-12 1.0000000e+00 1.8132097e-11 5.3337184e-09 2.2458520e-13], sum to 1.0000
[2019-03-26 20:31:17,799] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9548
[2019-03-26 20:31:17,806] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.33333333333334, 65.66666666666667, 1.0, 2.0, 0.5435444189643169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 759540.6298902467, 759540.6298902467, 190702.9414364648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4383600.0000, 
sim time next is 4384200.0000, 
raw observation next is [32.16666666666666, 66.33333333333333, 1.0, 2.0, 0.5546009538050467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 774996.4983625632, 774996.4983625638, 192595.2098592759], 
processed observation next is [1.0, 0.7391304347826086, 0.7235387045813582, 0.6633333333333333, 1.0, 1.0, 0.4633746431386105, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.215276805100712, 0.21527680510071215, 0.2874555371033969], 
reward next is 0.7125, 
noisyNet noise sample is [array([-0.36371386], dtype=float32), -0.93974924]. 
=============================================
[2019-03-26 20:31:18,179] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.3466815e-20 1.0000000e+00 5.8771886e-18 8.5743938e-16 2.2655865e-21], sum to 1.0000
[2019-03-26 20:31:18,188] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7183
[2019-03-26 20:31:18,194] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666667, 67.66666666666667, 1.0, 2.0, 0.5409105871556351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 755858.8442419033, 755858.844241904, 190254.3010965207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4461600.0000, 
sim time next is 4462200.0000, 
raw observation next is [31.0, 68.5, 1.0, 2.0, 0.5535190075115133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 773484.0417379951, 773484.0417379951, 192406.5548702447], 
processed observation next is [0.0, 0.6521739130434783, 0.6682464454976303, 0.685, 1.0, 1.0, 0.46207109338736535, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21485667826055418, 0.21485667826055418, 0.28717396249290256], 
reward next is 0.7128, 
noisyNet noise sample is [array([-1.1739607], dtype=float32), -0.62988627]. 
=============================================
[2019-03-26 20:31:19,207] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.6048533e-08 9.9999571e-01 1.0420728e-07 4.1758972e-06 2.5910700e-09], sum to 1.0000
[2019-03-26 20:31:19,214] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5781
[2019-03-26 20:31:19,220] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3159183.322769613 W.
[2019-03-26 20:31:19,226] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.66666666666666, 56.83333333333333, 1.0, 2.0, 0.8644232500053548, 1.0, 2.0, 0.75280166451694, 1.0, 2.0, 1.03, 7.005110700359527, 6.9112, 170.5573041426782, 3159183.322769613, 3091911.268059032, 578293.9996124969], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4377000.0000, 
sim time next is 4377600.0000, 
raw observation next is [36.0, 57.0, 1.0, 2.0, 0.8841450590930557, 1.0, 2.0, 0.7626625690607903, 1.0, 2.0, 1.03, 7.005112256317167, 6.9112, 170.5573041426782, 3200618.307041098, 3133345.137734767, 585803.79679163], 
processed observation next is [1.0, 0.6956521739130435, 0.9052132701421801, 0.57, 1.0, 1.0, 0.860415733847055, 1.0, 1.0, 0.7140512880250486, 1.0, 1.0, 1.0365853658536586, 0.009391225631716705, 0.0, 0.8375144448122397, 0.8890606408447495, 0.8703736493707687, 0.8743340250621343], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.09306791], dtype=float32), 0.071175024]. 
=============================================
[2019-03-26 20:31:26,972] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0400049e-17 1.0000000e+00 1.1901909e-16 2.9823481e-14 1.0979310e-19], sum to 1.0000
[2019-03-26 20:31:26,984] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3712
[2019-03-26 20:31:26,992] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.5085719292308827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 710654.2619121685, 710654.261912169, 184949.4775477625], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4499400.0000, 
sim time next is 4500000.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5079176052521707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709739.6352092845, 709739.6352092845, 184845.3994978373], 
processed observation next is [0.0, 0.08695652173913043, 0.4312796208530806, 0.89, 1.0, 1.0, 0.4071296448821333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1971498986692457, 0.1971498986692457, 0.27588865596692136], 
reward next is 0.7241, 
noisyNet noise sample is [array([0.6830063], dtype=float32), 2.755337]. 
=============================================
[2019-03-26 20:31:27,008] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[66.82414 ]
 [66.967094]
 [67.14329 ]
 [67.3028  ]
 [67.52075 ]], R is [[66.78037262]
 [66.83652496]
 [66.89198303]
 [66.94684601]
 [67.00123596]].
[2019-03-26 20:31:32,014] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.8914994e-17 1.0000000e+00 5.9182785e-15 3.8377851e-13 6.5729554e-18], sum to 1.0000
[2019-03-26 20:31:32,023] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3713
[2019-03-26 20:31:32,028] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 94.0, 1.0, 2.0, 0.9217203584982179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1288318.438848376, 1288318.438848375, 275984.2101772272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4597200.0000, 
sim time next is 4597800.0000, 
raw observation next is [27.16666666666666, 94.00000000000001, 1.0, 2.0, 0.9450630098866242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1320965.517572562, 1320965.517572562, 282636.4787975866], 
processed observation next is [1.0, 0.21739130434782608, 0.4865718799368086, 0.9400000000000002, 1.0, 1.0, 0.9338108552850893, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.36693486599237835, 0.36693486599237835, 0.42184549074266653], 
reward next is 0.5782, 
noisyNet noise sample is [array([-0.8665757], dtype=float32), 0.7400825]. 
=============================================
[2019-03-26 20:31:38,548] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.5577173e-19 1.0000000e+00 7.8494451e-17 7.9870980e-15 1.4340376e-20], sum to 1.0000
[2019-03-26 20:31:38,556] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1870
[2019-03-26 20:31:38,563] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1912115.408060752 W.
[2019-03-26 20:31:38,566] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.5, 77.0, 1.0, 2.0, 0.7264307407134263, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.997361067221316, 6.9112, 168.9117644768777, 1912115.408060752, 1850990.212907785, 390815.1469627995], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4696200.0000, 
sim time next is 4696800.0000, 
raw observation next is [29.66666666666667, 76.33333333333334, 1.0, 2.0, 0.8471060634789535, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.998922709020061, 6.9112, 168.9123650485908, 2081002.218370057, 2018768.927324056, 420079.0224891172], 
processed observation next is [1.0, 0.34782608695652173, 0.6050552922590839, 0.7633333333333334, 1.0, 1.0, 0.8157904379264499, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008772270902006074, 0.0, 0.8294370408038949, 0.5780561717694602, 0.5607691464789044, 0.6269836156553988], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2094524], dtype=float32), 0.30809748]. 
=============================================
[2019-03-26 20:31:43,026] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3633833e-18 1.0000000e+00 7.1129486e-17 4.3758171e-15 3.5201253e-20], sum to 1.0000
[2019-03-26 20:31:43,036] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5582
[2019-03-26 20:31:43,041] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 74.16666666666667, 1.0, 2.0, 1.03242672510641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1443161.494803355, 1443161.494803355, 308963.4938216915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4781400.0000, 
sim time next is 4782000.0000, 
raw observation next is [30.0, 73.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 10.44574732387161, 6.9112, 168.8924281972294, 3962525.200585771, 1455300.424137647, 304721.9599729059], 
processed observation next is [1.0, 0.34782608695652173, 0.6208530805687204, 0.7333333333333334, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.35345473238716096, 0.0, 0.8293391417365804, 1.1007014446071586, 0.40425011781601305, 0.45480889548194914], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41131827], dtype=float32), -1.2705407]. 
=============================================
[2019-03-26 20:31:43,056] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[68.34485 ]
 [68.1806  ]
 [68.07509 ]
 [68.015724]
 [67.95723 ]], R is [[67.49206543]
 [67.35601044]
 [67.29131317]
 [67.24933624]
 [67.20744324]].
[2019-03-26 20:31:48,548] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.5288294e-19 1.0000000e+00 2.9671323e-17 4.0679109e-15 9.5160877e-21], sum to 1.0000
[2019-03-26 20:31:48,557] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8565
[2019-03-26 20:31:48,561] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.7042239497036771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 984175.7697041045, 984175.7697041052, 221757.8984896256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4859400.0000, 
sim time next is 4860000.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.6655394859862604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 930089.3055936471, 930089.3055936464, 213581.1324064603], 
processed observation next is [1.0, 0.2608695652173913, 0.4786729857819906, 0.84, 1.0, 1.0, 0.5970355252846511, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25835814044267974, 0.2583581404426795, 0.31877780956188106], 
reward next is 0.6812, 
noisyNet noise sample is [array([1.0071825], dtype=float32), -1.2610879]. 
=============================================
[2019-03-26 20:31:48,573] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[69.4104  ]
 [69.35226 ]
 [69.093605]
 [69.083694]
 [68.92679 ]], R is [[69.43778229]
 [69.41242981]
 [69.38811493]
 [69.37081909]
 [69.34609222]].
[2019-03-26 20:31:51,596] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.6258823e-17 1.0000000e+00 4.1475400e-16 9.0160389e-15 2.9105597e-20], sum to 1.0000
[2019-03-26 20:31:51,609] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4439
[2019-03-26 20:31:51,620] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2346739.57588912 W.
[2019-03-26 20:31:51,628] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.5, 70.0, 1.0, 2.0, 0.8390792141742882, 1.0, 1.0, 0.8390792141742882, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2346739.57588912, 2346739.57588912, 439336.9133748683], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4955400.0000, 
sim time next is 4956000.0000, 
raw observation next is [29.66666666666667, 68.66666666666667, 1.0, 2.0, 0.4987491295504229, 1.0, 2.0, 0.4987491295504229, 1.0, 1.0, 0.8514470068924643, 6.9112, 6.9112, 170.5573041426782, 2092125.14419389, 2092125.14419389, 411606.0443741106], 
processed observation next is [1.0, 0.34782608695652173, 0.6050552922590839, 0.6866666666666668, 1.0, 1.0, 0.3960832886149674, 1.0, 1.0, 0.3960832886149674, 1.0, 0.5, 0.8188378132834929, 0.0, 0.0, 0.8375144448122397, 0.5811458733871917, 0.5811458733871917, 0.6143373796628516], 
reward next is 0.3857, 
noisyNet noise sample is [array([-1.1292676], dtype=float32), 1.1404394]. 
=============================================
[2019-03-26 20:31:51,641] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[67.17787 ]
 [69.56837 ]
 [69.73377 ]
 [69.634476]
 [69.628555]], R is [[63.15390015]
 [62.86663437]
 [62.23796844]
 [62.16079712]
 [62.1914978 ]].
[2019-03-26 20:31:57,470] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.5100190e-19 1.0000000e+00 1.9469620e-17 1.8698074e-15 5.0874584e-21], sum to 1.0000
[2019-03-26 20:31:57,481] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6476
[2019-03-26 20:31:57,488] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5104633257084197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 713298.0968898302, 713298.0968898295, 185251.679123224], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5006400.0000, 
sim time next is 5007000.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.511770668521239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 715125.5328461556, 715125.5328461563, 185460.7396174659], 
processed observation next is [1.0, 0.9565217391304348, 0.4786729857819906, 0.84, 1.0, 1.0, 0.41177188978462526, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19864598134615433, 0.19864598134615452, 0.27680707405591926], 
reward next is 0.7232, 
noisyNet noise sample is [array([2.0932746], dtype=float32), 1.7701422]. 
=============================================
[2019-03-26 20:31:57,506] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[68.75598]
 [68.73906]
 [68.72165]
 [68.69559]
 [68.57114]], R is [[68.80735779]
 [68.8427887 ]
 [68.87818909]
 [68.91343689]
 [68.94832611]].
[2019-03-26 20:32:02,800] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4107081e-18 1.0000000e+00 1.8860456e-17 3.6091837e-15 5.3559504e-21], sum to 1.0000
[2019-03-26 20:32:02,809] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6553
[2019-03-26 20:32:02,812] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.482364311720772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 674146.5682088706, 674146.5682088699, 180894.5739038551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5111400.0000, 
sim time next is 5112000.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4835689770511917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 675829.8095865631, 675829.8095865624, 181077.0919183193], 
processed observation next is [0.0, 0.17391304347826086, 0.4312796208530806, 0.84, 1.0, 1.0, 0.37779394825444784, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1877305026629342, 0.187730502662934, 0.27026431629599895], 
reward next is 0.7297, 
noisyNet noise sample is [array([0.6976138], dtype=float32), -0.9487579]. 
=============================================
[2019-03-26 20:32:02,836] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[71.59801 ]
 [71.56626 ]
 [71.4053  ]
 [71.234314]
 [71.227295]], R is [[71.73087311]
 [71.74357605]
 [71.75648499]
 [71.76907349]
 [71.78136444]].
[2019-03-26 20:32:05,532] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 20:32:05,534] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:32:05,534] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:32:05,536] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:32:05,536] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:32:05,537] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:32:05,537] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:32:05,538] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:32:05,538] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:32:05,539] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:32:05,540] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:32:05,561] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run32
[2019-03-26 20:32:05,562] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run32
[2019-03-26 20:32:05,562] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run32
[2019-03-26 20:32:05,562] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run32
[2019-03-26 20:32:05,639] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run32
[2019-03-26 20:32:42,689] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07100971], dtype=float32), 0.06264745]
[2019-03-26 20:32:42,691] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.0, 89.0, 1.0, 2.0, 0.6067728303256104, 0.0, 2.0, 0.0, 1.0, 2.0, 1.021511206261907, 6.911200000000001, 6.9112, 168.9129099725272, 1696538.093735963, 1696538.093735962, 364797.6689175738]
[2019-03-26 20:32:42,693] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:32:42,695] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.9914873e-13 1.0000000e+00 1.5022285e-12 1.2030074e-10 5.6039979e-15], sampled 0.880447521820981
[2019-03-26 20:32:42,697] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1696538.093735963 W.
[2019-03-26 20:32:46,406] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07100971], dtype=float32), 0.06264745]
[2019-03-26 20:32:46,407] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.96666666666667, 69.66666666666666, 1.0, 2.0, 0.572594881529774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 800150.5905531935, 800150.5905531929, 195750.9110766879]
[2019-03-26 20:32:46,410] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:32:46,413] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.0628563e-20 1.0000000e+00 6.3807684e-19 1.6515215e-16 2.0580837e-22], sampled 0.3914909045930318
[2019-03-26 20:32:50,294] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07100971], dtype=float32), 0.06264745]
[2019-03-26 20:32:50,294] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.0, 88.0, 1.0, 2.0, 0.5180023575694004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813921.2367332013, 813921.2367332013, 196910.6037159325]
[2019-03-26 20:32:50,297] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:32:50,298] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.0012116e-19 1.0000000e+00 6.0499105e-18 6.3423387e-16 1.5102946e-21], sampled 0.887239460190495
[2019-03-26 20:32:56,725] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07100971], dtype=float32), 0.06264745]
[2019-03-26 20:32:56,726] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.4, 63.66666666666666, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.435112258544394, 6.9112, 168.9099829272536, 1825684.345054911, 1454009.500341239, 311348.5608684314]
[2019-03-26 20:32:56,728] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:32:56,733] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.4096911e-13 1.0000000e+00 4.6645993e-13 4.1738578e-11 1.0889445e-15], sampled 0.6705147389790818
[2019-03-26 20:32:56,736] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1825684.345054911 W.
[2019-03-26 20:33:48,647] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07100971], dtype=float32), 0.06264745]
[2019-03-26 20:33:48,650] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.06908732333333, 91.12243774666666, 1.0, 2.0, 0.4907619074555794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 685759.3502782556, 685759.3502782556, 182160.3525976848]
[2019-03-26 20:33:48,651] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:33:48,654] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.4172297e-19 1.0000000e+00 6.6476961e-18 1.0170272e-15 2.4017706e-21], sampled 0.7366817921817775
[2019-03-26 20:34:00,601] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.2043 2927417036.4532 1338.0000
[2019-03-26 20:34:00,718] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.3448 2842553551.5226 1131.0000
[2019-03-26 20:34:00,825] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.1789 3007672430.4622 1766.0000
[2019-03-26 20:34:00,826] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164071917.9177 1778.0000
[2019-03-26 20:34:00,869] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3694 2779190338.1949 933.0000
[2019-03-26 20:34:01,885] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 775000, evaluation results [775000.0, 7884.168443086554, 3164071917.9176674, 1778.0, 8252.204329082842, 2927417036.4532247, 1338.0, 8661.369356548688, 2779190338.194891, 933.0, 7998.178869716802, 3007672430.462179, 1766.0, 8495.344803432035, 2842553551.5226407, 1131.0]
[2019-03-26 20:34:01,949] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6709541e-14 1.0000000e+00 6.7822382e-14 6.4209697e-12 1.1717527e-15], sum to 1.0000
[2019-03-26 20:34:01,957] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6817
[2019-03-26 20:34:01,964] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.35, 93.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.053606735770643, 6.9112, 168.9119829019505, 1554851.773188323, 1453824.115894347, 311355.8895393038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5374200.0000, 
sim time next is 5374800.0000, 
raw observation next is [28.3, 94.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.068916068689807, 6.9112, 168.9117063731829, 1565719.934579369, 1453831.555382934, 311355.8516056846], 
processed observation next is [1.0, 0.21739130434782608, 0.5402843601895735, 0.94, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.015771606868980735, 0.0, 0.8294338064060992, 0.4349222040498247, 0.40384209871748167, 0.4647102262771412], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1507058], dtype=float32), 1.3223988]. 
=============================================
[2019-03-26 20:34:07,405] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.9131953e-09 9.9999917e-01 7.5491222e-09 8.3319344e-07 4.9818621e-11], sum to 1.0000
[2019-03-26 20:34:07,411] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9182
[2019-03-26 20:34:07,419] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2598129.880892421 W.
[2019-03-26 20:34:07,425] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.928870733185632, 1.0, 2.0, 0.928870733185632, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2598129.880892421, 2598129.880892421, 487489.4395305769], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5238000.0000, 
sim time next is 5238600.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.6387821546088603, 1.0, 2.0, 0.6387821546088603, 1.0, 1.0, 1.03, 7.000410993746838, 6.9112, 170.5573041426782, 2680179.356823115, 2616273.893131044, 502468.5722622339], 
processed observation next is [1.0, 0.6521739130434783, 0.7156398104265403, 0.67, 1.0, 1.0, 0.5647977766371811, 1.0, 1.0, 0.5647977766371811, 1.0, 0.5, 1.0365853658536586, 0.008921099374683817, 0.0, 0.8375144448122397, 0.7444942657841986, 0.7267427480919567, 0.7499530929287073], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04497421], dtype=float32), 0.18842618]. 
=============================================
[2019-03-26 20:34:10,945] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2411802e-07 9.9998462e-01 1.2499656e-07 1.5159923e-05 5.9369509e-09], sum to 1.0000
[2019-03-26 20:34:10,955] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7194
[2019-03-26 20:34:10,961] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2843318.940216053 W.
[2019-03-26 20:34:10,968] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [37.45, 54.0, 1.0, 2.0, 0.7140597758501153, 1.0, 2.0, 0.6776199274393203, 1.0, 1.0, 1.03, 7.005098840782406, 6.9112, 170.5573041426782, 2843318.940216053, 2776055.38100298, 525808.9248121696], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5409000.0000, 
sim time next is 5409600.0000, 
raw observation next is [37.63333333333333, 54.0, 1.0, 2.0, 0.8442336214397562, 1.0, 2.0, 0.7427068502341406, 1.0, 2.0, 1.03, 7.005109107600018, 6.9112, 170.5573041426782, 3116766.886501258, 3049495.972749102, 570758.060268389], 
processed observation next is [1.0, 0.6086956521739131, 0.9826224328593997, 0.54, 1.0, 1.0, 0.8123296643852485, 1.0, 1.0, 0.6900082532941453, 1.0, 1.0, 1.0365853658536586, 0.00939091076000178, 0.0, 0.8375144448122397, 0.8657685795836827, 0.8470822146525283, 0.8518777018931178], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7238651], dtype=float32), 1.0464923]. 
=============================================
[2019-03-26 20:34:17,295] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0632277e-16 1.0000000e+00 2.4294497e-15 1.4692358e-12 1.5824273e-18], sum to 1.0000
[2019-03-26 20:34:17,305] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3839
[2019-03-26 20:34:17,309] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.8, 79.66666666666667, 1.0, 2.0, 0.6116229153945442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 854710.751960657, 854710.751960657, 202932.1652566262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5425800.0000, 
sim time next is 5426400.0000, 
raw observation next is [30.8, 80.33333333333334, 1.0, 2.0, 0.6167525996765194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861882.12361638, 861882.12361638, 203909.3314807037], 
processed observation next is [1.0, 0.8260869565217391, 0.6587677725118484, 0.8033333333333335, 1.0, 1.0, 0.5382561441885776, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23941170100455, 0.23941170100455, 0.30434228579209505], 
reward next is 0.6957, 
noisyNet noise sample is [array([-1.0711074], dtype=float32), -1.0871136]. 
=============================================
[2019-03-26 20:34:30,255] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1459505e-18 1.0000000e+00 1.3268114e-17 8.8552560e-15 1.6148125e-20], sum to 1.0000
[2019-03-26 20:34:30,265] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6682
[2019-03-26 20:34:30,268] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.85, 92.5, 1.0, 2.0, 0.5159975761444457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 721034.0298569204, 721034.0298569197, 186140.2664358656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5621400.0000, 
sim time next is 5622000.0000, 
raw observation next is [25.8, 92.66666666666667, 1.0, 2.0, 0.5148374441949914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 719412.359690964, 719412.3596909647, 185953.2053432669], 
processed observation next is [0.0, 0.043478260869565216, 0.42180094786729866, 0.9266666666666667, 1.0, 1.0, 0.41546680023492943, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19983676658082333, 0.19983676658082353, 0.277542097527264], 
reward next is 0.7225, 
noisyNet noise sample is [array([-0.79679674], dtype=float32), 0.6730464]. 
=============================================
[2019-03-26 20:34:30,280] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[69.75572 ]
 [69.84752 ]
 [69.78987 ]
 [69.929245]
 [69.914536]], R is [[69.77669525]
 [69.80110168]
 [69.82507324]
 [69.84867859]
 [69.87174225]].
[2019-03-26 20:34:30,335] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5380542e-17 1.0000000e+00 3.5870972e-16 9.9956190e-15 1.8666597e-20], sum to 1.0000
[2019-03-26 20:34:30,340] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7643
[2019-03-26 20:34:30,347] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.63333333333333, 91.33333333333334, 1.0, 2.0, 0.5038736434684384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 704086.9247482967, 704086.9247482962, 184204.8727349343], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5629200.0000, 
sim time next is 5629800.0000, 
raw observation next is [25.61666666666667, 91.16666666666667, 1.0, 2.0, 0.5019505234115789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 701398.7692300805, 701398.7692300805, 183901.9238461858], 
processed observation next is [0.0, 0.13043478260869565, 0.41311216429699865, 0.9116666666666667, 1.0, 1.0, 0.3999403896525046, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19483299145280014, 0.19483299145280014, 0.2744804833525161], 
reward next is 0.7255, 
noisyNet noise sample is [array([0.4888514], dtype=float32), 0.23618576]. 
=============================================
[2019-03-26 20:34:33,861] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.4179558e-20 1.0000000e+00 8.0602645e-19 3.7762915e-16 1.0815221e-22], sum to 1.0000
[2019-03-26 20:34:33,871] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8162
[2019-03-26 20:34:33,874] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.43333333333333, 72.83333333333334, 1.0, 2.0, 0.5322740261263339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 743786.0419720585, 743786.0419720579, 188807.3144585471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5683800.0000, 
sim time next is 5684400.0000, 
raw observation next is [29.2, 74.0, 1.0, 2.0, 0.5315173219168408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742728.2732834636, 742728.2732834629, 188681.5681455161], 
processed observation next is [0.0, 0.8260869565217391, 0.5829383886255924, 0.74, 1.0, 1.0, 0.435563038454025, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20631340924540653, 0.20631340924540634, 0.28161428081420314], 
reward next is 0.7184, 
noisyNet noise sample is [array([0.9908239], dtype=float32), -0.15646245]. 
=============================================
[2019-03-26 20:34:35,636] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.7200877e-19 1.0000000e+00 2.7443790e-17 2.0387202e-15 2.6960191e-21], sum to 1.0000
[2019-03-26 20:34:35,645] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9561
[2019-03-26 20:34:35,652] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 80.0, 1.0, 2.0, 0.5186626171841852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 724759.320264166, 724759.3202641654, 186571.6622047571], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5727600.0000, 
sim time next is 5728200.0000, 
raw observation next is [27.96666666666667, 79.16666666666667, 1.0, 2.0, 0.5203001505872328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 727048.329947903, 727048.3299479038, 186837.6735789017], 
processed observation next is [0.0, 0.30434782608695654, 0.524486571879937, 0.7916666666666667, 1.0, 1.0, 0.4220483742014852, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20195786942997307, 0.20195786942997326, 0.2788621993714951], 
reward next is 0.7211, 
noisyNet noise sample is [array([1.2131658], dtype=float32), -0.0058676936]. 
=============================================
[2019-03-26 20:34:40,899] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.5828229e-17 1.0000000e+00 8.7395737e-16 6.1509649e-14 1.5506302e-19], sum to 1.0000
[2019-03-26 20:34:40,910] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9891
[2019-03-26 20:34:40,913] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.25, 92.66666666666666, 1.0, 2.0, 1.02165564932647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9126407906377, 1428095.189700725, 1428095.189700725, 305592.9519679165], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5802600.0000, 
sim time next is 5803200.0000, 
raw observation next is [26.2, 93.0, 1.0, 2.0, 0.9733484047002313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129564758013, 1360526.872468977, 1360526.872468976, 290910.0341345718], 
processed observation next is [1.0, 0.17391304347826086, 0.44075829383886256, 0.93, 1.0, 1.0, 0.9678896442171462, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.829439944982255, 0.3779241312413825, 0.37792413124138224, 0.43419408079786836], 
reward next is 0.5658, 
noisyNet noise sample is [array([0.26230302], dtype=float32), -0.8529768]. 
=============================================
[2019-03-26 20:34:45,823] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.70563557e-18 1.00000000e+00 1.32803186e-17 7.53746191e-16
 1.12671400e-21], sum to 1.0000
[2019-03-26 20:34:45,830] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6134
[2019-03-26 20:34:45,835] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 86.83333333333333, 1.0, 2.0, 0.7572846375360189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1058366.75090455, 1058366.75090455, 233697.3669026125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5899800.0000, 
sim time next is 5900400.0000, 
raw observation next is [28.0, 86.0, 1.0, 2.0, 0.7399295906189444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1034099.854283911, 1034099.85428391, 229701.7055847963], 
processed observation next is [1.0, 0.30434782608695654, 0.5260663507109005, 0.86, 1.0, 1.0, 0.6866621573722221, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2872499595233086, 0.28724995952330834, 0.3428383665444721], 
reward next is 0.6572, 
noisyNet noise sample is [array([-1.443759], dtype=float32), -1.2789633]. 
=============================================
[2019-03-26 20:34:52,175] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1981245e-19 1.0000000e+00 1.2475793e-18 1.2161872e-15 8.5129981e-22], sum to 1.0000
[2019-03-26 20:34:52,185] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0161
[2019-03-26 20:34:52,189] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.4, 78.33333333333334, 1.0, 2.0, 0.5282310838648453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738134.5754765758, 738134.5754765758, 188137.5857425934], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6290400.0000, 
sim time next is 6291000.0000, 
raw observation next is [28.25, 79.5, 1.0, 2.0, 0.5291039197801833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 739354.6751770646, 739354.6751770653, 188281.7942024401], 
processed observation next is [0.0, 0.8260869565217391, 0.537914691943128, 0.795, 1.0, 1.0, 0.43265532503636545, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20537629866029572, 0.20537629866029591, 0.281017603287224], 
reward next is 0.7190, 
noisyNet noise sample is [array([-1.2480351], dtype=float32), 0.044395894]. 
=============================================
[2019-03-26 20:34:52,205] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[73.159256]
 [73.110214]
 [73.05626 ]
 [73.00982 ]
 [72.975975]], R is [[73.19142914]
 [73.17871857]
 [73.16654968]
 [73.15522766]
 [73.14451599]].
[2019-03-26 20:34:56,956] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.4907502e-13 1.0000000e+00 3.4022251e-12 2.6428143e-10 2.8739049e-15], sum to 1.0000
[2019-03-26 20:34:56,961] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4856
[2019-03-26 20:34:56,970] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2027541.01003053 W.
[2019-03-26 20:34:56,976] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.93333333333333, 72.0, 1.0, 2.0, 0.7250508680104412, 1.0, 2.0, 0.7250508680104412, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2027541.01003053, 2027541.01003053, 385032.7230802483], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6082800.0000, 
sim time next is 6083400.0000, 
raw observation next is [30.06666666666667, 71.0, 1.0, 2.0, 0.7332681134794553, 1.0, 2.0, 0.7332681134794553, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2050541.806573811, 2050541.806573811, 388690.8166589456], 
processed observation next is [1.0, 0.391304347826087, 0.6240126382306479, 0.71, 1.0, 1.0, 0.6786362813005485, 1.0, 1.0, 0.6786362813005485, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.569594946270503, 0.569594946270503, 0.5801355472521575], 
reward next is 0.4199, 
noisyNet noise sample is [array([0.9844199], dtype=float32), -0.4541173]. 
=============================================
[2019-03-26 20:34:57,335] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 20:34:57,337] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:34:57,339] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:34:57,339] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:34:57,339] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:34:57,340] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:34:57,341] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:34:57,341] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:34:57,342] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:34:57,342] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:34:57,344] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:34:57,361] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run33
[2019-03-26 20:34:57,379] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run33
[2019-03-26 20:34:57,380] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run33
[2019-03-26 20:34:57,380] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run33
[2019-03-26 20:34:57,380] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run33
[2019-03-26 20:35:00,555] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07167528], dtype=float32), 0.061679263]
[2019-03-26 20:35:00,556] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.69226175333333, 98.5780558, 1.0, 2.0, 0.8039412757324162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1135751.717801432, 1135751.717801432, 246592.269168363]
[2019-03-26 20:35:00,558] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:35:00,560] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.3361856e-19 1.0000000e+00 5.8959614e-18 1.0490429e-15 8.1458428e-22], sampled 0.848483413084535
[2019-03-26 20:35:00,624] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07167528], dtype=float32), 0.061679263]
[2019-03-26 20:35:00,628] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.6, 96.0, 1.0, 2.0, 0.3543341171355828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 547783.4350458741, 547783.4350458735, 170514.375543383]
[2019-03-26 20:35:00,631] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:35:00,635] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.8837388e-19 1.0000000e+00 6.1042728e-18 1.3115100e-15 1.0501288e-21], sampled 0.040605564597344324
[2019-03-26 20:35:51,054] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07167528], dtype=float32), 0.061679263]
[2019-03-26 20:35:51,055] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.96039160333333, 68.18587109, 1.0, 2.0, 0.5064266083740188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 707655.4938998363, 707655.4938998357, 184607.9817728036]
[2019-03-26 20:35:51,056] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:35:51,060] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.6578914e-15 1.0000000e+00 2.4885869e-14 1.1887708e-12 7.6772965e-18], sampled 0.19928555101378131
[2019-03-26 20:36:16,878] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07167528], dtype=float32), 0.061679263]
[2019-03-26 20:36:16,880] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.2, 73.0, 1.0, 2.0, 0.5672390504484937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 792663.4987275783, 792663.4987275783, 194800.7560988428]
[2019-03-26 20:36:16,881] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:36:16,882] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.1391871e-20 1.0000000e+00 1.4863091e-18 5.6737311e-16 2.7465607e-22], sampled 0.8437905982073476
[2019-03-26 20:36:23,161] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07167528], dtype=float32), 0.061679263]
[2019-03-26 20:36:23,162] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.98288499333334, 85.29926642000001, 1.0, 2.0, 0.9056524966738863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9128854655964, 1345737.880678305, 1345737.880678304, 283033.0527345506]
[2019-03-26 20:36:23,163] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:36:23,165] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.1014128e-13 1.0000000e+00 1.2231960e-12 2.4727084e-10 6.2610905e-15], sampled 0.011416082279412265
[2019-03-26 20:36:29,632] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07167528], dtype=float32), 0.061679263]
[2019-03-26 20:36:29,634] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.03333333333333, 68.33333333333333, 1.0, 2.0, 0.5636544596811557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 787652.5112767582, 787652.5112767576, 194169.8309346595]
[2019-03-26 20:36:29,635] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:36:29,637] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.3426294e-19 1.0000000e+00 2.8391945e-18 6.2626164e-16 4.9006468e-22], sampled 0.095200430359621
[2019-03-26 20:36:52,183] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.5883 2927327297.4404 1338.0000
[2019-03-26 20:36:52,355] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 20:36:52,800] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.1099 2779281538.5944 933.0000
[2019-03-26 20:36:52,816] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5565 3007666902.0797 1766.0000
[2019-03-26 20:36:52,861] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.2939 2842588129.6969 1131.0000
[2019-03-26 20:36:53,876] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 800000, evaluation results [800000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8253.588267098503, 2927327297.440425, 1338.0, 8659.109938516645, 2779281538.594428, 933.0, 7997.556496139842, 3007666902.07966, 1766.0, 8495.293851511607, 2842588129.696858, 1131.0]
[2019-03-26 20:36:55,098] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8362119e-14 1.0000000e+00 3.0655323e-13 1.2897028e-11 7.3311549e-17], sum to 1.0000
[2019-03-26 20:36:55,107] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6242
[2019-03-26 20:36:55,113] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.75, 77.0, 1.0, 2.0, 0.5252405013827002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733954.1797674065, 733954.1797674065, 187645.8684115319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6114600.0000, 
sim time next is 6115200.0000, 
raw observation next is [28.56666666666666, 78.0, 1.0, 2.0, 0.5257320437657211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 734641.2827991112, 734641.2827991118, 187726.5116731009], 
processed observation next is [1.0, 0.782608695652174, 0.5529225908372825, 0.78, 1.0, 1.0, 0.42859282381412184, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20406702299975313, 0.20406702299975327, 0.2801888233926879], 
reward next is 0.7198, 
noisyNet noise sample is [array([0.8863452], dtype=float32), 0.5935223]. 
=============================================
[2019-03-26 20:36:56,568] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5836950e-19 1.0000000e+00 3.0414611e-17 1.9621743e-15 5.9020056e-21], sum to 1.0000
[2019-03-26 20:36:56,575] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2950
[2019-03-26 20:36:56,580] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 86.0, 1.0, 2.0, 0.5269159403329983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 736296.1956722644, 736296.1956722644, 187920.8085717417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6123600.0000, 
sim time next is 6124200.0000, 
raw observation next is [27.21666666666667, 86.16666666666667, 1.0, 2.0, 0.5281266562988742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 737988.600777555, 737988.6007775556, 188120.4078167687], 
processed observation next is [1.0, 0.9130434782608695, 0.48894154818325447, 0.8616666666666667, 1.0, 1.0, 0.43147789915527013, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20499683354932083, 0.204996833549321, 0.2807767280847294], 
reward next is 0.7192, 
noisyNet noise sample is [array([-0.3256776], dtype=float32), 1.1264501]. 
=============================================
[2019-03-26 20:37:05,416] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3739521e-20 1.0000000e+00 2.1979299e-18 1.0276387e-15 1.2499252e-22], sum to 1.0000
[2019-03-26 20:37:05,423] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1808
[2019-03-26 20:37:05,431] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.73333333333333, 83.33333333333334, 1.0, 2.0, 0.5343749585673689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 746722.8628641486, 746722.862864148, 189157.0941031561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6294000.0000, 
sim time next is 6294600.0000, 
raw observation next is [27.7, 83.5, 1.0, 2.0, 0.5339543842505919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 746134.9559035427, 746134.9559035427, 189086.947106703], 
processed observation next is [0.0, 0.8695652173913043, 0.5118483412322274, 0.835, 1.0, 1.0, 0.43849925813324325, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2072597099732063, 0.2072597099732063, 0.2822193240398552], 
reward next is 0.7178, 
noisyNet noise sample is [array([-0.8467525], dtype=float32), 0.40189922]. 
=============================================
[2019-03-26 20:37:16,788] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3584051e-09 9.9999940e-01 7.1982873e-09 5.7815771e-07 1.4419239e-10], sum to 1.0000
[2019-03-26 20:37:16,795] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0052
[2019-03-26 20:37:16,801] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2064149.985925456 W.
[2019-03-26 20:37:16,806] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.4, 56.0, 1.0, 2.0, 0.8350654403905928, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.966144482402706, 6.9112, 168.9126294020522, 2064149.985925456, 2025170.554551597, 417979.9620279639], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6523200.0000, 
sim time next is 6523800.0000, 
raw observation next is [31.46666666666667, 56.0, 1.0, 2.0, 0.9851750642965174, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.965588563449253, 6.9112, 168.9125886541575, 2274252.00856118, 2235666.973770525, 460085.4014719563], 
processed observation next is [1.0, 0.5217391304347826, 0.6903633491311217, 0.56, 1.0, 1.0, 0.982138631682551, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.005438856344925291, 0.0, 0.8294381388095945, 0.6317366690447722, 0.6210186038251458, 0.6866946290626214], 
reward next is 0.0414, 
noisyNet noise sample is [array([0.16309828], dtype=float32), -0.1595013]. 
=============================================
[2019-03-26 20:37:20,786] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5194080e-20 1.0000000e+00 6.3017200e-18 6.7674486e-16 4.6941737e-22], sum to 1.0000
[2019-03-26 20:37:20,796] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8692
[2019-03-26 20:37:20,802] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.6, 58.0, 1.0, 2.0, 0.4388025248677382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 633761.5362040659, 633761.5362040659, 177209.9897885411], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6976800.0000, 
sim time next is 6977400.0000, 
raw observation next is [29.51666666666667, 57.83333333333334, 1.0, 2.0, 0.4310396285639245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 625009.0755310854, 625009.075531086, 176413.4769398913], 
processed observation next is [0.0, 0.782608695652174, 0.5979462875197474, 0.5783333333333335, 1.0, 1.0, 0.31450557658304157, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17361363209196815, 0.1736136320919683, 0.2633036969252109], 
reward next is 0.7367, 
noisyNet noise sample is [array([0.7393155], dtype=float32), 0.03084915]. 
=============================================
[2019-03-26 20:37:21,960] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2292999e-18 1.0000000e+00 1.4549297e-16 1.5915659e-14 3.8479011e-20], sum to 1.0000
[2019-03-26 20:37:21,970] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2956
[2019-03-26 20:37:21,978] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 90.0, 1.0, 2.0, 0.5135106425592673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 717557.7162522693, 717557.7162522699, 185739.9079392068], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6573600.0000, 
sim time next is 6574200.0000, 
raw observation next is [26.16666666666666, 90.16666666666667, 1.0, 2.0, 0.8706117203170282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1216841.300810235, 1216841.300810236, 261979.8620683027], 
processed observation next is [1.0, 0.08695652173913043, 0.4391785150078987, 0.9016666666666667, 1.0, 1.0, 0.844110506406058, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3380114724472875, 0.3380114724472878, 0.3910147195049294], 
reward next is 0.6090, 
noisyNet noise sample is [array([0.895941], dtype=float32), 1.0803989]. 
=============================================
[2019-03-26 20:37:27,010] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.11397629e-17 1.00000000e+00 3.19068576e-16 1.24649724e-14
 2.13879745e-20], sum to 1.0000
[2019-03-26 20:37:27,017] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5339
[2019-03-26 20:37:27,022] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.88333333333333, 95.0, 1.0, 2.0, 0.6139510287585741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 857965.4815870208, 857965.4815870208, 203365.0439199614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6664200.0000, 
sim time next is 6664800.0000, 
raw observation next is [24.86666666666667, 95.0, 1.0, 2.0, 0.6050253766004485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 845487.3699859132, 845487.3699859132, 201677.6649269905], 
processed observation next is [1.0, 0.13043478260869565, 0.3775671406003162, 0.95, 1.0, 1.0, 0.5241269597595766, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23485760277386478, 0.23485760277386478, 0.301011440189538], 
reward next is 0.6990, 
noisyNet noise sample is [array([-1.3466836], dtype=float32), 0.66582507]. 
=============================================
[2019-03-26 20:37:29,064] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.9329241e-18 1.0000000e+00 1.6168067e-16 2.5738041e-15 1.2184502e-20], sum to 1.0000
[2019-03-26 20:37:29,073] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3314
[2019-03-26 20:37:29,079] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.03333333333333, 90.66666666666667, 1.0, 2.0, 0.6725707463073679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 939919.8176081327, 939919.8176081327, 215034.3510619343], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6680400.0000, 
sim time next is 6681000.0000, 
raw observation next is [26.11666666666666, 90.33333333333333, 1.0, 2.0, 0.6622723438651841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 925521.4954580624, 925521.4954580631, 212910.9042391225], 
processed observation next is [1.0, 0.30434782608695654, 0.4368088467614531, 0.9033333333333333, 1.0, 1.0, 0.5930992094761254, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2570893042939062, 0.2570893042939064, 0.31777746901361564], 
reward next is 0.6822, 
noisyNet noise sample is [array([0.1295278], dtype=float32), 0.5603151]. 
=============================================
[2019-03-26 20:37:29,097] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[70.29936]
 [70.2086 ]
 [70.22474]
 [70.18105]
 [70.15454]], R is [[70.26368713]
 [70.24010468]
 [70.20031738]
 [70.16518402]
 [70.14056396]].
[2019-03-26 20:37:33,824] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.6206487e-18 1.0000000e+00 1.3334083e-16 3.3487468e-14 4.7788812e-20], sum to 1.0000
[2019-03-26 20:37:33,832] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2147
[2019-03-26 20:37:33,836] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.53333333333333, 77.0, 1.0, 2.0, 0.3747493844665999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 588698.4156158856, 588698.4156158856, 174175.6952414407], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6766800.0000, 
sim time next is 6767400.0000, 
raw observation next is [23.66666666666667, 76.5, 1.0, 2.0, 0.3844108377844545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 603003.0325276207, 603003.0325276207, 175421.6376671486], 
processed observation next is [1.0, 0.30434782608695654, 0.3206951026856243, 0.765, 1.0, 1.0, 0.2583263105836801, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16750084236878351, 0.16750084236878351, 0.26182333980171435], 
reward next is 0.7382, 
noisyNet noise sample is [array([0.93678194], dtype=float32), 2.075052]. 
=============================================
[2019-03-26 20:37:38,157] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.25684213e-17 1.00000000e+00 2.14192901e-16 9.18383953e-15
 1.01779695e-20], sum to 1.0000
[2019-03-26 20:37:38,169] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8228
[2019-03-26 20:37:38,177] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 81.66666666666667, 1.0, 2.0, 0.3362063253829475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 525077.1570925282, 525077.1570925282, 168812.7021562097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6838800.0000, 
sim time next is 6839400.0000, 
raw observation next is [23.1, 81.83333333333334, 1.0, 2.0, 0.3367879131771817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 525679.7773040036, 525679.7773040036, 168852.8277994767], 
processed observation next is [0.0, 0.13043478260869565, 0.2938388625592418, 0.8183333333333335, 1.0, 1.0, 0.20094929298455627, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1460221603622232, 0.1460221603622232, 0.25201914596936825], 
reward next is 0.7480, 
noisyNet noise sample is [array([-2.3604803], dtype=float32), -0.8969886]. 
=============================================
[2019-03-26 20:37:43,174] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.8214390e-20 1.0000000e+00 2.7198855e-18 1.8821079e-16 1.4258867e-22], sum to 1.0000
[2019-03-26 20:37:43,184] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4481
[2019-03-26 20:37:43,193] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.88333333333334, 78.16666666666667, 1.0, 2.0, 0.4264226533309549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 620671.1091066434, 620671.1091066428, 176057.0423806288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6936600.0000, 
sim time next is 6937200.0000, 
raw observation next is [26.1, 77.0, 1.0, 2.0, 0.4275852769461792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 621469.6596054427, 621469.6596054421, 176109.5352132057], 
processed observation next is [0.0, 0.30434782608695654, 0.4360189573459717, 0.77, 1.0, 1.0, 0.3103437071640713, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17263046100151186, 0.1726304610015117, 0.26285005255702343], 
reward next is 0.7371, 
noisyNet noise sample is [array([0.18752012], dtype=float32), 0.90530056]. 
=============================================
[2019-03-26 20:37:46,058] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6530293e-19 1.0000000e+00 1.2331574e-18 2.0858095e-15 5.2062942e-22], sum to 1.0000
[2019-03-26 20:37:46,069] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2752
[2019-03-26 20:37:46,080] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.63333333333333, 52.0, 1.0, 2.0, 0.4580598965596291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 646346.3453054957, 646346.3453054951, 178099.7782756368], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6964800.0000, 
sim time next is 6965400.0000, 
raw observation next is [31.81666666666667, 52.0, 1.0, 2.0, 0.4655127809537518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 652273.3864311778, 652273.3864311778, 178603.0257078125], 
processed observation next is [0.0, 0.6086956521739131, 0.7069510268562403, 0.52, 1.0, 1.0, 0.35603949512500216, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1811870517864383, 0.1811870517864383, 0.2665716801609142], 
reward next is 0.7334, 
noisyNet noise sample is [array([0.12429328], dtype=float32), 0.7176296]. 
=============================================
[2019-03-26 20:37:47,750] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1772004e-19 1.0000000e+00 1.4034734e-17 8.9754046e-16 2.9976942e-22], sum to 1.0000
[2019-03-26 20:37:47,759] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2991
[2019-03-26 20:37:47,765] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 83.5, 1.0, 2.0, 0.3699750097547244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 560805.8883778467, 560805.8883778473, 171297.4943313054], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7235400.0000, 
sim time next is 7236000.0000, 
raw observation next is [23.8, 84.0, 1.0, 2.0, 0.3710920051502805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 563026.1201074978, 563026.1201074984, 171506.0276666304], 
processed observation next is [1.0, 0.782608695652174, 0.3270142180094788, 0.84, 1.0, 1.0, 0.2422795242774464, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15639614447430494, 0.1563961444743051, 0.25597914577109016], 
reward next is 0.7440, 
noisyNet noise sample is [array([-0.26779756], dtype=float32), -0.41508517]. 
=============================================
[2019-03-26 20:37:47,788] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[72.42532 ]
 [72.04588 ]
 [71.71389 ]
 [71.338486]
 [70.639885]], R is [[72.98972321]
 [73.00415802]
 [73.0186615 ]
 [73.03363037]
 [73.04771423]].
[2019-03-26 20:37:47,968] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1731899e-20 1.0000000e+00 7.3360671e-20 1.4142549e-16 2.0835038e-22], sum to 1.0000
[2019-03-26 20:37:47,977] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4769
[2019-03-26 20:37:47,981] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.06666666666667, 71.33333333333334, 1.0, 2.0, 0.430716646286219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 625065.2306058331, 625065.2306058324, 176433.5325010216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6992400.0000, 
sim time next is 6993000.0000, 
raw observation next is [26.95, 72.5, 1.0, 2.0, 0.4346398957204802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 628941.992582633, 628941.9925826325, 176764.8646300449], 
processed observation next is [0.0, 0.9565217391304348, 0.476303317535545, 0.725, 1.0, 1.0, 0.31884324785600027, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1747061090507314, 0.17470610905073125, 0.2638281561642461], 
reward next is 0.7362, 
noisyNet noise sample is [array([-2.7733529], dtype=float32), -1.1139872]. 
=============================================
[2019-03-26 20:37:47,994] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[75.24399 ]
 [75.210556]
 [75.17644 ]
 [75.15309 ]
 [75.14549 ]], R is [[75.26207733]
 [75.24612427]
 [75.23107147]
 [75.21648407]
 [75.2025528 ]].
[2019-03-26 20:37:49,109] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 20:37:49,111] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:37:49,112] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:37:49,113] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:37:49,114] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:37:49,114] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:37:49,116] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:37:49,116] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:37:49,116] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:37:49,115] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:37:49,121] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:37:49,136] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run34
[2019-03-26 20:37:49,137] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run34
[2019-03-26 20:37:49,137] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run34
[2019-03-26 20:37:49,192] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run34
[2019-03-26 20:37:49,192] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run34
[2019-03-26 20:38:13,556] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07537396], dtype=float32), 0.064257495]
[2019-03-26 20:38:13,558] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.53333333333333, 85.0, 1.0, 2.0, 0.7318827464191792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1114832.101468987, 1114832.101468988, 239745.0294733926]
[2019-03-26 20:38:13,560] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:38:13,564] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.6487923e-19 1.0000000e+00 5.8107560e-18 1.0002823e-15 5.8250590e-22], sampled 0.35161581266168007
[2019-03-26 20:38:15,015] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07537396], dtype=float32), 0.064257495]
[2019-03-26 20:38:15,016] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.07922330666667, 87.36184766666668, 1.0, 2.0, 0.7897306619669633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1103736.27028935, 1103736.27028935, 241405.3433691232]
[2019-03-26 20:38:15,017] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:38:15,018] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.9703337e-20 1.0000000e+00 1.5314377e-18 3.7665086e-16 1.3754634e-22], sampled 0.9123432912371211
[2019-03-26 20:39:24,089] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07537396], dtype=float32), 0.064257495]
[2019-03-26 20:39:24,090] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.8, 72.5, 1.0, 2.0, 0.5062973892159814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 707474.8693109483, 707474.8693109483, 184588.7930917196]
[2019-03-26 20:39:24,091] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:39:24,094] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.8379955e-18 1.0000000e+00 9.2323746e-17 2.4426933e-14 9.0137419e-21], sampled 0.9167653817827028
[2019-03-26 20:39:35,638] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07537396], dtype=float32), 0.064257495]
[2019-03-26 20:39:35,639] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.46666666666667, 61.66666666666667, 1.0, 2.0, 0.7309859031985598, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005977218288723, 6.9112, 168.9123160296632, 1918489.92838533, 1851251.962703742, 391509.2980740494]
[2019-03-26 20:39:35,640] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:39:35,642] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2877387e-15 1.0000000e+00 5.3112866e-15 3.8519700e-12 1.6819818e-17], sampled 0.4523704569836857
[2019-03-26 20:39:35,643] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1918489.92838533 W.
[2019-03-26 20:39:37,914] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07537396], dtype=float32), 0.064257495]
[2019-03-26 20:39:37,915] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.65, 65.0, 1.0, 2.0, 0.4598344209285375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 655066.0471925375, 655066.0471925375, 179153.9454233901]
[2019-03-26 20:39:37,916] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:39:37,923] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.4041948e-19 1.0000000e+00 3.2554628e-18 7.6562472e-16 4.5090421e-22], sampled 0.9164209293429427
[2019-03-26 20:39:43,711] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 20:39:44,385] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1249 2927277438.0038 1338.0000
[2019-03-26 20:39:44,579] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5735 3007648438.5815 1766.0000
[2019-03-26 20:39:44,631] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.3549 2842524527.6411 1131.0000
[2019-03-26 20:39:44,649] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 20:39:45,664] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 825000, evaluation results [825000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8255.124881931173, 2927277438.00382, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7997.573465804901, 3007648438.5815053, 1766.0, 8495.354936069756, 2842524527.6411414, 1131.0]
[2019-03-26 20:39:48,930] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.5953001e-17 1.0000000e+00 4.9530438e-15 1.3073388e-12 3.5047855e-19], sum to 1.0000
[2019-03-26 20:39:48,939] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1680
[2019-03-26 20:39:48,945] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.01666666666667, 79.33333333333334, 1.0, 2.0, 0.4817471921539958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 673158.771627048, 673158.771627048, 180785.7260450441], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7066200.0000, 
sim time next is 7066800.0000, 
raw observation next is [26.9, 80.0, 1.0, 2.0, 0.4821338432490095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 673699.2212934479, 673699.2212934486, 180844.1848919697], 
processed observation next is [1.0, 0.8260869565217391, 0.4739336492890995, 0.8, 1.0, 1.0, 0.3760648713843488, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18713867258151332, 0.1871386725815135, 0.2699166938686115], 
reward next is 0.7301, 
noisyNet noise sample is [array([1.1468011], dtype=float32), 0.792023]. 
=============================================
[2019-03-26 20:39:50,636] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.6104168e-19 1.0000000e+00 4.5120965e-18 2.6657258e-15 8.6747113e-22], sum to 1.0000
[2019-03-26 20:39:50,641] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5161
[2019-03-26 20:39:50,647] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 94.33333333333334, 1.0, 2.0, 0.4998698147767043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 710274.5482731145, 710274.5482731145, 185083.5276788748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7100400.0000, 
sim time next is 7101000.0000, 
raw observation next is [24.15, 94.5, 1.0, 2.0, 0.5293945642474459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 753184.2030502071, 753184.2030502065, 190045.4234577006], 
processed observation next is [1.0, 0.17391304347826086, 0.34360189573459715, 0.945, 1.0, 1.0, 0.4330054990933083, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2092178341806131, 0.20921783418061293, 0.2836498857577621], 
reward next is 0.7164, 
noisyNet noise sample is [array([0.91726536], dtype=float32), 0.8732387]. 
=============================================
[2019-03-26 20:39:50,660] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[71.06558 ]
 [70.93988 ]
 [70.825325]
 [70.65802 ]
 [70.62561 ]], R is [[71.12785339]
 [71.14032745]
 [71.12771606]
 [71.14353943]
 [71.15835571]].
[2019-03-26 20:39:52,516] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1338452e-14 1.0000000e+00 9.6741130e-14 2.3290380e-11 1.9481357e-17], sum to 1.0000
[2019-03-26 20:39:52,527] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7224
[2019-03-26 20:39:52,534] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 84.83333333333334, 1.0, 2.0, 0.4774050149871767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 667089.4214282708, 667089.4214282702, 180131.7009389495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7150200.0000, 
sim time next is 7150800.0000, 
raw observation next is [26.1, 84.66666666666667, 1.0, 2.0, 0.4787848660057578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 669018.1273309673, 669018.1273309673, 180338.8082001063], 
processed observation next is [1.0, 0.782608695652174, 0.4360189573459717, 0.8466666666666667, 1.0, 1.0, 0.3720299590430817, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18583836870304649, 0.18583836870304649, 0.2691624002986661], 
reward next is 0.7308, 
noisyNet noise sample is [array([-2.0931468], dtype=float32), 0.681693]. 
=============================================
[2019-03-26 20:39:53,813] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.3961031e-19 1.0000000e+00 6.5927432e-18 3.3907599e-15 4.4075650e-22], sum to 1.0000
[2019-03-26 20:39:53,817] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7966
[2019-03-26 20:39:53,826] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 85.0, 1.0, 2.0, 0.3838705267360344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 574791.6780117674, 574791.6780117681, 172304.2200867445], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7473600.0000, 
sim time next is 7474200.0000, 
raw observation next is [24.21666666666667, 84.50000000000001, 1.0, 2.0, 0.386239480210638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 577380.7410647481, 577380.7410647476, 172505.4138475132], 
processed observation next is [0.0, 0.5217391304347826, 0.34676145339652464, 0.8450000000000002, 1.0, 1.0, 0.2605294942296843, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16038353918465226, 0.1603835391846521, 0.2574707669365869], 
reward next is 0.7425, 
noisyNet noise sample is [array([0.96910715], dtype=float32), 2.2996824]. 
=============================================
[2019-03-26 20:39:56,003] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.570705e-19 1.000000e+00 3.349732e-17 7.099808e-15 7.571737e-21], sum to 1.0000
[2019-03-26 20:39:56,013] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1709
[2019-03-26 20:39:56,023] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 85.33333333333334, 1.0, 2.0, 0.6224901344569533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 869903.3362911043, 869903.3362911043, 205004.9677661726], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7197600.0000, 
sim time next is 7198200.0000, 
raw observation next is [27.8, 85.0, 1.0, 2.0, 0.625845564128584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 874594.3363654815, 874594.3363654815, 205654.0994703549], 
processed observation next is [1.0, 0.30434782608695654, 0.5165876777251186, 0.85, 1.0, 1.0, 0.5492115230464868, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24294287121263375, 0.24294287121263375, 0.3069464171199327], 
reward next is 0.6931, 
noisyNet noise sample is [array([-0.00293698], dtype=float32), 2.5413504]. 
=============================================
[2019-03-26 20:39:59,786] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.5866054e-19 1.0000000e+00 4.8321410e-17 7.0904162e-15 3.3055511e-21], sum to 1.0000
[2019-03-26 20:39:59,795] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2941
[2019-03-26 20:39:59,802] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 91.0, 1.0, 2.0, 0.3259975310288161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 515603.3088994767, 515603.3088994772, 168211.0703710788], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7369200.0000, 
sim time next is 7369800.0000, 
raw observation next is [21.1, 91.16666666666667, 1.0, 2.0, 0.3322420986857388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 527565.2722048846, 527565.2722048839, 169167.5007764274], 
processed observation next is [1.0, 0.30434782608695654, 0.1990521327014219, 0.9116666666666667, 1.0, 1.0, 0.19547240805510696, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14654590894580127, 0.14654590894580108, 0.25248880712899613], 
reward next is 0.7475, 
noisyNet noise sample is [array([-1.0426399], dtype=float32), 1.8951238]. 
=============================================
[2019-03-26 20:40:07,673] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1142216e-19 1.0000000e+00 3.1877384e-18 3.7712406e-15 5.8915202e-22], sum to 1.0000
[2019-03-26 20:40:07,683] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9502
[2019-03-26 20:40:07,687] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 92.83333333333333, 1.0, 2.0, 0.6387313323200511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1008690.98886403, 1008690.988864029, 221827.4207823641], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7387800.0000, 
sim time next is 7388400.0000, 
raw observation next is [21.13333333333333, 92.66666666666667, 1.0, 2.0, 0.4581793355792964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 724441.5512895911, 724441.5512895911, 186999.0418960373], 
processed observation next is [1.0, 0.5217391304347826, 0.20063191153238533, 0.9266666666666667, 1.0, 1.0, 0.34720401877023666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20123376424710865, 0.20123376424710865, 0.27910304760602583], 
reward next is 0.7209, 
noisyNet noise sample is [array([0.85444075], dtype=float32), 0.3277493]. 
=============================================
[2019-03-26 20:40:14,491] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0850901e-19 1.0000000e+00 1.6767095e-17 3.0064772e-15 1.4531621e-21], sum to 1.0000
[2019-03-26 20:40:14,495] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1445
[2019-03-26 20:40:14,504] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 93.0, 1.0, 2.0, 0.4046505640864498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 595742.8224814701, 595742.8224814708, 173904.6966147587], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7522800.0000, 
sim time next is 7523400.0000, 
raw observation next is [23.5, 93.0, 1.0, 2.0, 0.4078350447546752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 600431.5050611332, 600431.5050611338, 174339.1243004749], 
processed observation next is [0.0, 0.043478260869565216, 0.31279620853080575, 0.93, 1.0, 1.0, 0.28654824669237977, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1667865291836481, 0.16678652918364828, 0.260207648209664], 
reward next is 0.7398, 
noisyNet noise sample is [array([-0.3798772], dtype=float32), -1.079493]. 
=============================================
[2019-03-26 20:40:15,276] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2766251e-20 1.0000000e+00 1.9010182e-18 1.4271154e-16 1.0209106e-22], sum to 1.0000
[2019-03-26 20:40:15,284] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9301
[2019-03-26 20:40:15,293] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 90.0, 1.0, 2.0, 0.383760969435442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 575045.0046162286, 575045.004616228, 172340.1760897095], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7540200.0000, 
sim time next is 7540800.0000, 
raw observation next is [23.43333333333333, 90.0, 1.0, 2.0, 0.3853932460323327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 576839.8275490114, 576839.8275490114, 172480.00652421], 
processed observation next is [0.0, 0.2608695652173913, 0.30963665086887826, 0.9, 1.0, 1.0, 0.2595099349787141, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16023328543028095, 0.16023328543028095, 0.2574328455585224], 
reward next is 0.7426, 
noisyNet noise sample is [array([0.43793616], dtype=float32), -1.0533509]. 
=============================================
[2019-03-26 20:40:16,635] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:16,635] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:16,672] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run5
[2019-03-26 20:40:19,496] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4320970e-20 1.0000000e+00 4.8186435e-19 7.5852237e-17 4.8623560e-24], sum to 1.0000
[2019-03-26 20:40:19,506] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8459
[2019-03-26 20:40:19,513] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.13333333333333, 92.0, 1.0, 2.0, 0.4824504968940798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 674141.8307629039, 674141.8307629032, 180891.9996816422], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7598400.0000, 
sim time next is 7599000.0000, 
raw observation next is [25.06666666666667, 92.5, 1.0, 2.0, 0.4824780337637555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 674180.3210257734, 674180.3210257734, 180896.1693598697], 
processed observation next is [0.0, 0.9565217391304348, 0.38704581358609813, 0.925, 1.0, 1.0, 0.3764795587515127, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18727231139604816, 0.18727231139604816, 0.2699942826266712], 
reward next is 0.7300, 
noisyNet noise sample is [array([-1.1305513], dtype=float32), -0.053451143]. 
=============================================
[2019-03-26 20:40:19,526] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[79.7311  ]
 [79.673904]
 [79.61573 ]
 [79.55131 ]
 [79.47395 ]], R is [[79.71952057]
 [79.65233612]
 [79.58592987]
 [79.52018738]
 [79.45497131]].
[2019-03-26 20:40:23,675] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:23,675] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:23,720] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run5
[2019-03-26 20:40:25,294] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.3964493e-12 1.0000000e+00 1.0458670e-10 2.2087070e-09 1.4523727e-13], sum to 1.0000
[2019-03-26 20:40:25,304] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9302
[2019-03-26 20:40:25,308] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 85.0, 1.0, 2.0, 0.2916255677845448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 472958.204721603, 472958.204721603, 165136.8508836607], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 9600.0000, 
sim time next is 10200.0000, 
raw observation next is [20.93333333333333, 85.0, 1.0, 2.0, 0.2887626895459192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 467794.6389357135, 467794.6389357135, 164789.1255658762], 
processed observation next is [1.0, 0.08695652173913043, 0.19115323854660338, 0.85, 1.0, 1.0, 0.14308757776616773, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12994295525992042, 0.12994295525992042, 0.2459539187550391], 
reward next is 0.7540, 
noisyNet noise sample is [array([-0.41226256], dtype=float32), 1.2478776]. 
=============================================
[2019-03-26 20:40:26,808] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:26,809] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:26,841] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run5
[2019-03-26 20:40:28,683] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.9159071e-20 1.0000000e+00 2.1632942e-17 1.3169848e-15 1.3689889e-21], sum to 1.0000
[2019-03-26 20:40:28,691] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1932
[2019-03-26 20:40:28,698] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 87.66666666666667, 1.0, 2.0, 0.5225463123681657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 730188.1127435089, 730188.1127435095, 187204.1012011808], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7766400.0000, 
sim time next is 7767000.0000, 
raw observation next is [26.8, 88.0, 1.0, 2.0, 0.523318483537868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731267.4893892081, 731267.4893892087, 187330.321357835], 
processed observation next is [1.0, 0.9130434782608695, 0.4691943127962086, 0.88, 1.0, 1.0, 0.4256849199251422, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20312985816366894, 0.2031298581636691, 0.27959749456393285], 
reward next is 0.7204, 
noisyNet noise sample is [array([-0.2278975], dtype=float32), -1.073146]. 
=============================================
[2019-03-26 20:40:28,728] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[75.2982  ]
 [74.80735 ]
 [74.5867  ]
 [74.31655 ]
 [74.321915]], R is [[75.43218231]
 [75.39845276]
 [75.36518097]
 [75.33237457]
 [75.30001831]].
[2019-03-26 20:40:34,387] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:34,388] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:34,430] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run5
[2019-03-26 20:40:37,271] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:37,272] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:37,312] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run5
[2019-03-26 20:40:38,894] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:38,894] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:38,935] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run5
[2019-03-26 20:40:39,100] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:39,100] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,125] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run5
[2019-03-26 20:40:39,151] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:39,152] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,177] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run5
[2019-03-26 20:40:39,238] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:39,240] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,254] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:39,254] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,264] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run5
[2019-03-26 20:40:39,290] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run5
[2019-03-26 20:40:39,329] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:39,330] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,344] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run5
[2019-03-26 20:40:39,537] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:39,538] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,541] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:39,541] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,543] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run5
[2019-03-26 20:40:39,564] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:39,564] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,575] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run5
[2019-03-26 20:40:39,596] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:39,596] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,598] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 20:40:39,599] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,599] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run5
[2019-03-26 20:40:39,624] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run5
[2019-03-26 20:40:39,649] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run5
[2019-03-26 20:40:39,796] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 20:40:39,804] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:40:39,804] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,805] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run35
[2019-03-26 20:40:39,822] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:40:39,825] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,827] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run35
[2019-03-26 20:40:39,842] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:40:39,843] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,845] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run35
[2019-03-26 20:40:39,881] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:40:39,882] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,884] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run35
[2019-03-26 20:40:39,899] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:40:39,900] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:40:39,902] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run35
[2019-03-26 20:40:45,036] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07739601], dtype=float32), 0.06564205]
[2019-03-26 20:40:45,040] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.13333333333334, 72.33333333333333, 1.0, 2.0, 0.2444401960508632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 404018.0197313101, 404018.0197313095, 160289.9432297642]
[2019-03-26 20:40:45,041] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:40:45,044] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.3361252e-19 1.0000000e+00 3.0755977e-18 7.8300700e-16 4.0576675e-22], sampled 0.5239719315527005
[2019-03-26 20:40:46,448] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07739601], dtype=float32), 0.06564205]
[2019-03-26 20:40:46,449] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.43333333333333, 75.0, 1.0, 2.0, 0.2601197495710089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 426576.8301072216, 426576.8301072216, 161923.8475619994]
[2019-03-26 20:40:46,449] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:40:46,456] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2837492e-18 1.0000000e+00 3.1445860e-17 2.6750671e-15 3.3042020e-21], sampled 0.9003526681027708
[2019-03-26 20:40:47,061] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07739601], dtype=float32), 0.06564205]
[2019-03-26 20:40:47,063] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.33294102666667, 76.23386122333334, 1.0, 2.0, 0.3998241295713341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 628332.1960632943, 628332.1960632937, 177691.621134284]
[2019-03-26 20:40:47,063] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:40:47,066] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.8118480e-19 1.0000000e+00 6.7534896e-18 9.2756228e-16 6.0448000e-22], sampled 0.09307714278297896
[2019-03-26 20:40:50,235] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07739601], dtype=float32), 0.06564205]
[2019-03-26 20:40:50,235] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.7, 54.0, 1.0, 2.0, 0.6266273055150398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1028773.728638557, 1028773.728638557, 221450.6096715211]
[2019-03-26 20:40:50,237] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:40:50,239] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.0226826e-20 1.0000000e+00 1.5993835e-18 4.8004872e-16 1.8811977e-22], sampled 0.2839210029215714
[2019-03-26 20:41:12,248] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07739601], dtype=float32), 0.06564205]
[2019-03-26 20:41:12,250] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.15, 94.5, 1.0, 2.0, 0.8989701569902202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1256500.92769338, 1256500.92769338, 269651.8516837089]
[2019-03-26 20:41:12,251] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:41:12,253] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.9000222e-20 1.0000000e+00 1.1138567e-18 3.6655428e-16 8.2265937e-23], sampled 0.9722099176528001
[2019-03-26 20:41:25,651] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07739601], dtype=float32), 0.06564205]
[2019-03-26 20:41:25,653] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.05, 88.0, 1.0, 2.0, 0.5095010330825633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 711952.9825849005, 711952.9825848999, 185097.2798474207]
[2019-03-26 20:41:25,656] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:41:25,660] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.4818991e-20 1.0000000e+00 1.2675015e-18 4.2279877e-16 1.4244405e-22], sampled 0.19491789775507484
[2019-03-26 20:41:41,658] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07739601], dtype=float32), 0.06564205]
[2019-03-26 20:41:41,660] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [34.42200827666667, 72.98104162666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 8.083867604595016, 6.9112, 168.9063153848781, 3116343.488856535, 2284445.438950443, 473363.3967720806]
[2019-03-26 20:41:41,661] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:41:41,663] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.3670669e-13 1.0000000e+00 1.8146897e-12 4.8147242e-10 2.6556270e-15], sampled 0.8633711927937291
[2019-03-26 20:41:41,664] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 3116343.488856535 W.
[2019-03-26 20:41:45,291] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07739601], dtype=float32), 0.06564205]
[2019-03-26 20:41:45,293] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.33333333333333, 59.66666666666667, 1.0, 2.0, 0.6132532419454715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 856989.9664401206, 856989.96644012, 203241.0195023037]
[2019-03-26 20:41:45,294] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:41:45,296] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.2117409e-18 1.0000000e+00 1.3318019e-16 8.4063453e-14 3.9175274e-20], sampled 0.198108194317707
[2019-03-26 20:42:35,039] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.4320 2779397896.3857 933.0000
[2019-03-26 20:42:35,112] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164071917.9177 1778.0000
[2019-03-26 20:42:35,180] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 20:42:35,215] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.1321 2842497763.3803 1131.0000
[2019-03-26 20:42:35,332] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.9689 2927381913.5140 1338.0000
[2019-03-26 20:42:36,349] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 850000, evaluation results [850000.0, 7884.168443086554, 3164071917.9176674, 1778.0, 8254.968948333817, 2927381913.5140486, 1338.0, 8660.432005415354, 2779397896.3857465, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8496.132109434688, 2842497763.3802733, 1131.0]
[2019-03-26 20:42:37,582] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.5722375e-18 1.0000000e+00 3.6995924e-17 4.5629927e-15 4.2147401e-21], sum to 1.0000
[2019-03-26 20:42:37,590] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2250
[2019-03-26 20:42:37,597] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 86.0, 1.0, 2.0, 0.3213215530535128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 512655.718011903, 512655.718011903, 168040.2722682601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 21600.0000, 
sim time next is 22200.0000, 
raw observation next is [21.66666666666667, 85.66666666666667, 1.0, 2.0, 0.3690137845416782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 588413.6889443405, 588413.6889443405, 174182.9217423461], 
processed observation next is [1.0, 0.2608695652173913, 0.22590837282780438, 0.8566666666666667, 1.0, 1.0, 0.23977564402611834, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16344824692898346, 0.16344824692898346, 0.25997451006320316], 
reward next is 0.7400, 
noisyNet noise sample is [array([-0.03994741], dtype=float32), 0.69413304]. 
=============================================
[2019-03-26 20:42:41,604] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1796933e-19 1.0000000e+00 1.0075268e-17 1.6034912e-15 1.2104026e-21], sum to 1.0000
[2019-03-26 20:42:41,614] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2453
[2019-03-26 20:42:41,619] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 90.0, 1.0, 2.0, 0.4188307082407541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 645170.0220620681, 645170.0220620674, 179164.0193579936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 97800.0000, 
sim time next is 98400.0000, 
raw observation next is [22.5, 90.0, 1.0, 2.0, 0.3892222281961041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 599538.9229341301, 599538.9229341301, 174958.839227896], 
processed observation next is [1.0, 0.13043478260869565, 0.2654028436018958, 0.9, 1.0, 1.0, 0.2641231665013302, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16653858970392502, 0.16653858970392502, 0.26113259586253135], 
reward next is 0.7389, 
noisyNet noise sample is [array([-1.1280838], dtype=float32), 0.93645203]. 
=============================================
[2019-03-26 20:42:46,361] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0750581e-18 1.0000000e+00 1.6866658e-17 9.3028426e-15 2.7893566e-21], sum to 1.0000
[2019-03-26 20:42:46,372] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9704
[2019-03-26 20:42:46,377] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.1, 96.0, 1.0, 2.0, 0.2958873061110873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 474622.3086687301, 474622.3086687301, 165278.0506669351], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 178200.0000, 
sim time next is 178800.0000, 
raw observation next is [20.06666666666667, 96.0, 1.0, 2.0, 0.2946152574974321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 472899.1159788866, 472899.1159788866, 165158.8503494025], 
processed observation next is [0.0, 0.043478260869565216, 0.1500789889415484, 0.96, 1.0, 1.0, 0.15013886445473748, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13136086554969073, 0.13136086554969073, 0.24650574679015297], 
reward next is 0.7535, 
noisyNet noise sample is [array([0.8106696], dtype=float32), 0.66698897]. 
=============================================
[2019-03-26 20:42:53,692] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.4626270e-20 1.0000000e+00 8.6195394e-19 1.6349791e-16 1.8334467e-22], sum to 1.0000
[2019-03-26 20:42:53,702] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4375
[2019-03-26 20:42:53,709] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 77.0, 1.0, 2.0, 0.3093101533890999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 488096.0379017606, 488096.03790176, 166121.1053605776], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 301200.0000, 
sim time next is 301800.0000, 
raw observation next is [23.36666666666667, 77.0, 1.0, 2.0, 0.3110274341431913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 490434.1831508067, 490434.1831508067, 166284.1622592447], 
processed observation next is [0.0, 0.4782608695652174, 0.30647709320695127, 0.77, 1.0, 1.0, 0.16991257125685696, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13623171754189076, 0.13623171754189076, 0.24818531680484285], 
reward next is 0.7518, 
noisyNet noise sample is [array([1.0555973], dtype=float32), -0.10354662]. 
=============================================
[2019-03-26 20:42:53,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.4050095e-20 1.0000000e+00 4.0826732e-18 4.4626481e-16 1.1691321e-22], sum to 1.0000
[2019-03-26 20:42:53,914] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5154
[2019-03-26 20:42:53,918] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.53333333333333, 76.33333333333333, 1.0, 2.0, 0.3164592760256142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 498106.7996662029, 498106.7996662023, 166832.9639899812], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 304800.0000, 
sim time next is 305400.0000, 
raw observation next is [23.56666666666667, 76.16666666666667, 1.0, 2.0, 0.3167429366759382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 498449.7570176365, 498449.7570176359, 166856.1608256341], 
processed observation next is [0.0, 0.5217391304347826, 0.31595576619273325, 0.7616666666666667, 1.0, 1.0, 0.17679871888667256, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13845826583823237, 0.1384582658382322, 0.24903904600840912], 
reward next is 0.7510, 
noisyNet noise sample is [array([-0.15897831], dtype=float32), -0.38726303]. 
=============================================
[2019-03-26 20:42:54,293] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6141494e-20 1.0000000e+00 2.6397944e-19 5.6071139e-17 3.0097470e-23], sum to 1.0000
[2019-03-26 20:42:54,303] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5403
[2019-03-26 20:42:54,307] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 76.0, 1.0, 2.0, 0.3219655759065918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 504274.8703338532, 504274.8703338532, 167235.4415181305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 309600.0000, 
sim time next is 310200.0000, 
raw observation next is [23.73333333333333, 76.16666666666667, 1.0, 2.0, 0.3217629405699107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 504177.1305989992, 504177.1305989985, 167233.8146102949], 
processed observation next is [0.0, 0.6086956521739131, 0.3238546603475513, 0.7616666666666667, 1.0, 1.0, 0.18284691634929004, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14004920294416645, 0.14004920294416626, 0.24960270837357448], 
reward next is 0.7504, 
noisyNet noise sample is [array([1.1266578], dtype=float32), 0.28135148]. 
=============================================
[2019-03-26 20:42:54,401] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0133113e-19 1.0000000e+00 6.5182194e-19 5.1624620e-17 3.0687926e-23], sum to 1.0000
[2019-03-26 20:42:54,415] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2404
[2019-03-26 20:42:54,419] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.76666666666667, 76.0, 1.0, 2.0, 0.3200186993366982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 501627.4022096229, 501627.4022096229, 167045.3239074733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 309000.0000, 
sim time next is 309600.0000, 
raw observation next is [23.8, 76.0, 1.0, 2.0, 0.3219655759065918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 504274.8703338532, 504274.8703338532, 167235.4415181305], 
processed observation next is [0.0, 0.6086956521739131, 0.3270142180094788, 0.76, 1.0, 1.0, 0.18309105530914674, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14007635287051476, 0.14007635287051476, 0.24960513659422465], 
reward next is 0.7504, 
noisyNet noise sample is [array([-1.1211476], dtype=float32), 1.5633204]. 
=============================================
[2019-03-26 20:43:05,148] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0563907e-20 1.0000000e+00 2.3222740e-18 3.1035922e-16 3.6798920e-22], sum to 1.0000
[2019-03-26 20:43:05,156] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8609
[2019-03-26 20:43:05,162] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 55.66666666666667, 1.0, 2.0, 0.3498141191536414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 573622.1155521977, 573622.1155521977, 172483.1554737045], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 564600.0000, 
sim time next is 565200.0000, 
raw observation next is [24.4, 56.0, 1.0, 2.0, 0.3915364578328762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 642331.2885569048, 642331.2885569048, 178239.6055975177], 
processed observation next is [1.0, 0.5652173913043478, 0.3554502369668246, 0.56, 1.0, 1.0, 0.26691139497936894, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17842535793247355, 0.17842535793247355, 0.2660292620858473], 
reward next is 0.7340, 
noisyNet noise sample is [array([-0.53178525], dtype=float32), 0.67074937]. 
=============================================
[2019-03-26 20:43:09,861] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.25369424e-20 1.00000000e+00 1.48370321e-18 1.45562903e-16
 3.68949046e-23], sum to 1.0000
[2019-03-26 20:43:09,870] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4600
[2019-03-26 20:43:09,875] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.76666666666667, 61.16666666666667, 1.0, 2.0, 0.6206558011641495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1014574.779839985, 1014574.779839985, 220047.3637728094], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 573000.0000, 
sim time next is 573600.0000, 
raw observation next is [23.73333333333333, 61.33333333333334, 1.0, 2.0, 0.5598863370792512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 915356.7541321453, 915356.7541321447, 207204.7569613243], 
processed observation next is [1.0, 0.6521739130434783, 0.3238546603475513, 0.6133333333333334, 1.0, 1.0, 0.4697425747942785, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25426576503670706, 0.2542657650367069, 0.30926083128555865], 
reward next is 0.6907, 
noisyNet noise sample is [array([-1.04374], dtype=float32), 0.74726254]. 
=============================================
[2019-03-26 20:43:10,516] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.04428895e-20 1.00000000e+00 6.17389256e-19 1.81503213e-16
 1.16201302e-23], sum to 1.0000
[2019-03-26 20:43:10,525] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0824
[2019-03-26 20:43:10,533] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.36666666666667, 64.5, 1.0, 2.0, 0.3307820616167551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 539556.480864077, 539556.4808640777, 169936.0921577853], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 580200.0000, 
sim time next is 580800.0000, 
raw observation next is [23.23333333333333, 65.0, 1.0, 2.0, 0.2580634839382641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 421322.9825268023, 421322.982526803, 161681.6681969654], 
processed observation next is [1.0, 0.7391304347826086, 0.3001579778830963, 0.65, 1.0, 1.0, 0.10610058305814953, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11703416181300064, 0.11703416181300083, 0.2413159226820379], 
reward next is 0.7587, 
noisyNet noise sample is [array([0.65229833], dtype=float32), -0.5377509]. 
=============================================
[2019-03-26 20:43:20,902] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0165022e-19 1.0000000e+00 1.3159225e-19 9.4394596e-17 1.1393774e-22], sum to 1.0000
[2019-03-26 20:43:20,909] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2111
[2019-03-26 20:43:20,915] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 60.5, 1.0, 2.0, 0.2436747180262885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 402194.8189099152, 402194.8189099146, 160246.7239985138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 756600.0000, 
sim time next is 757200.0000, 
raw observation next is [22.9, 62.0, 1.0, 2.0, 0.2448529244925271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 403930.1500833399, 403930.1500833393, 160369.7330999935], 
processed observation next is [1.0, 0.782608695652174, 0.2843601895734597, 0.62, 1.0, 1.0, 0.09018424637653867, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11220281946759442, 0.11220281946759425, 0.23935781059700523], 
reward next is 0.7606, 
noisyNet noise sample is [array([-2.0333643], dtype=float32), 1.2210956]. 
=============================================
[2019-03-26 20:43:31,690] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 20:43:31,695] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:43:31,697] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:43:31,698] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:43:31,699] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:43:31,699] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:43:31,700] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:43:31,701] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:43:31,702] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:43:31,704] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:43:31,705] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:43:31,718] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run36
[2019-03-26 20:43:31,740] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run36
[2019-03-26 20:43:31,760] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run36
[2019-03-26 20:43:31,762] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run36
[2019-03-26 20:43:31,781] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run36
[2019-03-26 20:44:14,889] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07985868], dtype=float32), 0.06806123]
[2019-03-26 20:44:14,891] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.17991434833333, 96.27885883833333, 1.0, 2.0, 0.380723813008215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 575531.8401847187, 575531.840184718, 172539.0601669981]
[2019-03-26 20:44:14,892] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:44:14,895] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.1007049e-21 1.0000000e+00 2.0679713e-19 8.8532545e-17 1.9039092e-23], sampled 0.6732101055586269
[2019-03-26 20:44:21,660] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07985868], dtype=float32), 0.06806123]
[2019-03-26 20:44:21,665] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.83907307, 80.40393479, 1.0, 2.0, 0.4940533174504129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 690360.050900892, 690360.050900892, 182668.9854451985]
[2019-03-26 20:44:21,667] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:44:21,671] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.0793452e-21 1.0000000e+00 2.3889165e-19 5.7576052e-17 1.4050922e-23], sampled 0.422328808661377
[2019-03-26 20:44:24,278] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07985868], dtype=float32), 0.06806123]
[2019-03-26 20:44:24,279] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.66666666666667, 68.0, 1.0, 2.0, 0.5494874967450897, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129563846099, 767848.3972653876, 767848.3972653869, 191715.086618775]
[2019-03-26 20:44:24,281] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:44:24,284] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.3407541e-14 1.0000000e+00 2.6631163e-13 2.8277919e-10 4.0209917e-16], sampled 0.4150462403751918
[2019-03-26 20:44:45,186] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07985868], dtype=float32), 0.06806123]
[2019-03-26 20:44:45,188] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.04394837333334, 86.71592153, 1.0, 2.0, 0.5038979210108827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 704120.8601716596, 704120.8601716589, 184208.1681199142]
[2019-03-26 20:44:45,190] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:44:45,193] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5366729e-21 1.0000000e+00 4.5807349e-20 2.7347435e-17 3.2460161e-24], sampled 0.9860643490276415
[2019-03-26 20:45:08,051] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07985868], dtype=float32), 0.06806123]
[2019-03-26 20:45:08,053] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.38333333333333, 66.33333333333333, 1.0, 2.0, 0.8275988900916382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1156690.149362809, 1156690.149362809, 250797.2980358155]
[2019-03-26 20:45:08,056] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:45:08,060] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.3133404e-21 1.0000000e+00 8.2082056e-20 2.8794875e-17 4.4831048e-24], sampled 0.006334615835478008
[2019-03-26 20:45:25,783] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.6797 2779181245.9678 933.0000
[2019-03-26 20:45:25,860] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6842 2927277501.7680 1338.0000
[2019-03-26 20:45:26,087] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4154 3164020870.7600 1778.0000
[2019-03-26 20:45:26,132] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7995.2579 3007753550.6473 1766.0000
[2019-03-26 20:45:26,224] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.7375 2842583214.3812 1131.0000
[2019-03-26 20:45:27,241] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 875000, evaluation results [875000.0, 7883.415427042078, 3164020870.760028, 1778.0, 8253.684237189153, 2927277501.7679873, 1338.0, 8660.67966608941, 2779181245.96776, 933.0, 7995.25786734932, 3007753550.6473494, 1766.0, 8496.737518497717, 2842583214.381195, 1131.0]
[2019-03-26 20:45:29,124] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1506699e-19 1.0000000e+00 6.3089599e-18 1.0312668e-16 5.7359311e-22], sum to 1.0000
[2019-03-26 20:45:29,141] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1339
[2019-03-26 20:45:29,147] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 93.0, 1.0, 2.0, 0.3329765268366439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 516161.5966468404, 516161.5966468398, 168000.7902355249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 978600.0000, 
sim time next is 979200.0000, 
raw observation next is [21.9, 93.0, 1.0, 2.0, 0.3331733487724681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 516468.1102545601, 516468.1102545608, 168024.895854503], 
processed observation next is [1.0, 0.34782608695652173, 0.23696682464454974, 0.93, 1.0, 1.0, 0.1965943961114074, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14346336395960002, 0.14346336395960022, 0.25078342664851194], 
reward next is 0.7492, 
noisyNet noise sample is [array([-0.3033904], dtype=float32), 0.6503565]. 
=============================================
[2019-03-26 20:45:31,781] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.4843799e-20 1.0000000e+00 5.2850046e-18 5.5217871e-16 2.8407813e-22], sum to 1.0000
[2019-03-26 20:45:31,790] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5622
[2019-03-26 20:45:31,793] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.45, 96.16666666666666, 1.0, 2.0, 0.4858714802355741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731001.4755006314, 731001.475500632, 187824.1420854495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1044600.0000, 
sim time next is 1045200.0000, 
raw observation next is [22.3, 96.33333333333333, 1.0, 2.0, 0.397315129270448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 600258.6993975863, 600258.6993975863, 174760.7903989587], 
processed observation next is [1.0, 0.08695652173913043, 0.25592417061611383, 0.9633333333333333, 1.0, 1.0, 0.2738736497234313, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16673852761044064, 0.16673852761044064, 0.2608370005954607], 
reward next is 0.7392, 
noisyNet noise sample is [array([1.1539894], dtype=float32), -0.36162773]. 
=============================================
[2019-03-26 20:45:34,650] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4631871e-19 1.0000000e+00 3.8378488e-18 7.0046263e-16 2.0050012e-22], sum to 1.0000
[2019-03-26 20:45:34,662] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3423
[2019-03-26 20:45:34,666] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 67.16666666666667, 1.0, 2.0, 0.797217510878386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1231854.706438085, 1231854.706438085, 258606.5675795001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1093800.0000, 
sim time next is 1094400.0000, 
raw observation next is [25.7, 67.0, 1.0, 2.0, 0.7950108555506639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1229328.373533733, 1229328.373533734, 258107.6580123094], 
processed observation next is [1.0, 0.6956521739130435, 0.4170616113744076, 0.67, 1.0, 1.0, 0.7530251271694746, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.34148010375937027, 0.34148010375937055, 0.38523531046613346], 
reward next is 0.6148, 
noisyNet noise sample is [array([1.653876], dtype=float32), 2.5684278]. 
=============================================
[2019-03-26 20:45:39,330] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2981373e-20 1.0000000e+00 1.4547283e-18 1.4715858e-16 9.2894708e-23], sum to 1.0000
[2019-03-26 20:45:39,336] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2656
[2019-03-26 20:45:39,341] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 61.0, 1.0, 2.0, 0.9160060260170056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1385697.653478942, 1385697.653478942, 289429.0482113513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1173600.0000, 
sim time next is 1174200.0000, 
raw observation next is [27.6, 60.66666666666667, 1.0, 2.0, 0.9738410104176051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1474473.84463667, 1474473.844636671, 307746.788348244], 
processed observation next is [1.0, 0.6086956521739131, 0.5071090047393366, 0.6066666666666667, 1.0, 1.0, 0.9684831450814518, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.4095760679546306, 0.40957606795463086, 0.4593235646988716], 
reward next is 0.5407, 
noisyNet noise sample is [array([-0.14404657], dtype=float32), 0.8293836]. 
=============================================
[2019-03-26 20:45:40,284] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6166429e-20 1.0000000e+00 1.2464845e-19 8.3802700e-17 1.6392512e-23], sum to 1.0000
[2019-03-26 20:45:40,295] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6960
[2019-03-26 20:45:40,299] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 57.16666666666666, 1.0, 2.0, 0.8749218469490505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1349022.648056325, 1349022.648056325, 280355.8618688554], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1183800.0000, 
sim time next is 1184400.0000, 
raw observation next is [27.6, 57.0, 1.0, 2.0, 0.8641109400539346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1333435.593337787, 1333435.593337787, 277297.3716745664], 
processed observation next is [1.0, 0.7391304347826086, 0.5071090047393366, 0.57, 1.0, 1.0, 0.8362782410288369, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3703987759271631, 0.3703987759271631, 0.4138766741411439], 
reward next is 0.5861, 
noisyNet noise sample is [array([-1.4008183], dtype=float32), 0.58365977]. 
=============================================
[2019-03-26 20:45:45,042] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3885815e-20 1.0000000e+00 6.5767895e-19 9.6117666e-17 1.7557773e-23], sum to 1.0000
[2019-03-26 20:45:45,052] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5550
[2019-03-26 20:45:45,057] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.56666666666667, 98.0, 1.0, 2.0, 0.3146155162227376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 497157.3719752533, 497157.3719752527, 166806.0286991008], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1399200.0000, 
sim time next is 1399800.0000, 
raw observation next is [20.58333333333334, 98.0, 1.0, 2.0, 0.3146256245799867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 496975.2427550306, 496975.2427550299, 166788.3153678298], 
processed observation next is [0.0, 0.17391304347826086, 0.17456556082148533, 0.98, 1.0, 1.0, 0.17424774045781533, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13804867854306405, 0.13804867854306385, 0.24893778413108927], 
reward next is 0.7511, 
noisyNet noise sample is [array([-0.28005072], dtype=float32), -1.0751995]. 
=============================================
[2019-03-26 20:45:49,606] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.9642505e-20 1.0000000e+00 8.6132611e-19 3.4747846e-16 2.7675096e-23], sum to 1.0000
[2019-03-26 20:45:49,617] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3147
[2019-03-26 20:45:49,621] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.65, 94.0, 1.0, 2.0, 0.8230026852319834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1240633.399539506, 1240633.399539506, 261960.4021930824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1337400.0000, 
sim time next is 1338000.0000, 
raw observation next is [22.56666666666667, 93.66666666666667, 1.0, 2.0, 0.7483828928246812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1132725.695171514, 1132725.695171513, 242998.8884753696], 
processed observation next is [1.0, 0.4782608695652174, 0.26856240126382325, 0.9366666666666668, 1.0, 1.0, 0.696846858824917, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31464602643653167, 0.31464602643653133, 0.36268490817219345], 
reward next is 0.6373, 
noisyNet noise sample is [array([-0.21679284], dtype=float32), 0.8420483]. 
=============================================
[2019-03-26 20:45:49,630] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[76.62657 ]
 [76.50909 ]
 [76.38647 ]
 [76.254776]
 [76.17777 ]], R is [[76.57811737]
 [76.4213562 ]
 [76.2677536 ]
 [76.11073303]
 [75.97169495]].
[2019-03-26 20:45:51,901] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.1523303e-20 1.0000000e+00 1.5900160e-17 6.2941345e-16 3.1231432e-22], sum to 1.0000
[2019-03-26 20:45:51,913] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4737
[2019-03-26 20:45:51,918] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 95.0, 1.0, 2.0, 0.3185148446419488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 503382.6962452093, 503382.6962452086, 167273.6079057441], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1375200.0000, 
sim time next is 1375800.0000, 
raw observation next is [20.86666666666667, 95.16666666666667, 1.0, 2.0, 0.3180440035163916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 502811.7905038574, 502811.7905038581, 167233.9838712227], 
processed observation next is [1.0, 0.9565217391304348, 0.18799368088467638, 0.9516666666666667, 1.0, 1.0, 0.17836626929685737, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13966994180662706, 0.13966994180662726, 0.24960296100182494], 
reward next is 0.7504, 
noisyNet noise sample is [array([-0.4876025], dtype=float32), -0.36873803]. 
=============================================
[2019-03-26 20:45:54,786] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2166766e-19 1.0000000e+00 1.0779861e-18 2.0423698e-16 1.2678277e-22], sum to 1.0000
[2019-03-26 20:45:54,793] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2046
[2019-03-26 20:45:54,799] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 88.5, 1.0, 2.0, 0.3851740829385485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 577888.3025299233, 577888.302529924, 172617.3626335623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1423800.0000, 
sim time next is 1424400.0000, 
raw observation next is [23.73333333333333, 88.66666666666666, 1.0, 2.0, 0.3913579781120874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 584088.8963221629, 584088.8963221624, 173081.8393349934], 
processed observation next is [0.0, 0.4782608695652174, 0.3238546603475513, 0.8866666666666666, 1.0, 1.0, 0.2666963591711896, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16224691564504526, 0.1622469156450451, 0.2583311034850648], 
reward next is 0.7417, 
noisyNet noise sample is [array([-0.4332831], dtype=float32), -0.18839097]. 
=============================================
[2019-03-26 20:46:05,392] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6199484e-21 1.0000000e+00 2.0817671e-19 3.8411313e-17 9.9121517e-24], sum to 1.0000
[2019-03-26 20:46:05,404] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5360
[2019-03-26 20:46:05,409] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 91.66666666666666, 1.0, 2.0, 0.4765954530357104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 665957.8466101834, 665957.8466101841, 180009.9954166866], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2065200.0000, 
sim time next is 2065800.0000, 
raw observation next is [24.93333333333333, 91.83333333333333, 1.0, 2.0, 0.476418763859153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 665710.8773785756, 665710.8773785762, 179983.5260085615], 
processed observation next is [0.0, 0.9130434782608695, 0.38072669826224315, 0.9183333333333333, 1.0, 1.0, 0.3691792335652446, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18491968816071544, 0.1849196881607156, 0.26863212837098727], 
reward next is 0.7314, 
noisyNet noise sample is [array([-0.9689098], dtype=float32), 1.400089]. 
=============================================
[2019-03-26 20:46:15,892] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.9823470e-20 1.0000000e+00 1.2978960e-18 8.3954412e-16 4.1371612e-22], sum to 1.0000
[2019-03-26 20:46:15,904] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8662
[2019-03-26 20:46:15,910] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 90.66666666666667, 1.0, 2.0, 0.6036693233599966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 957533.1192305534, 957533.1192305528, 214559.1078550541], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1781400.0000, 
sim time next is 1782000.0000, 
raw observation next is [21.0, 92.0, 1.0, 2.0, 0.6004387425506822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 953896.1516256345, 953896.1516256345, 213998.0517939191], 
processed observation next is [1.0, 0.6521739130434783, 0.19431279620853087, 0.92, 1.0, 1.0, 0.5186008946393761, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.26497115322934295, 0.26497115322934295, 0.3194000773043569], 
reward next is 0.6806, 
noisyNet noise sample is [array([-0.49300402], dtype=float32), 0.28222287]. 
=============================================
[2019-03-26 20:46:15,927] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[73.28987 ]
 [73.37662 ]
 [73.45769 ]
 [73.51367 ]
 [73.562874]], R is [[73.20669556]
 [73.15439606]
 [73.09926605]
 [73.03708649]
 [72.97794342]].
[2019-03-26 20:46:18,999] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.9594033e-19 1.0000000e+00 2.0632298e-17 1.9594142e-15 1.7956344e-21], sum to 1.0000
[2019-03-26 20:46:19,006] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8260
[2019-03-26 20:46:19,010] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.26666666666667, 96.0, 1.0, 2.0, 0.3642284799019063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 552751.6089454736, 552751.6089454743, 170628.0012622536], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1834800.0000, 
sim time next is 1835400.0000, 
raw observation next is [22.38333333333333, 95.5, 1.0, 2.0, 0.3660613538979577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 554535.9567450732, 554535.9567450739, 170747.6339494929], 
processed observation next is [1.0, 0.21739130434782608, 0.25987361769352274, 0.955, 1.0, 1.0, 0.23621849867223818, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15403776576252035, 0.15403776576252054, 0.2548472148499894], 
reward next is 0.7452, 
noisyNet noise sample is [array([0.93626934], dtype=float32), 0.42998084]. 
=============================================
[2019-03-26 20:46:21,329] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.82348523e-14 1.00000000e+00 1.20341413e-13 2.14111333e-11
 1.04068016e-16], sum to 1.0000
[2019-03-26 20:46:21,337] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0856
[2019-03-26 20:46:21,341] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 85.33333333333334, 1.0, 2.0, 0.5619177285137905, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9544510202185322, 6.911200000000001, 6.9112, 168.9129565097814, 1571030.313302474, 1571030.313302474, 339282.871611386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1869600.0000, 
sim time next is 1870200.0000, 
raw observation next is [27.0, 85.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.343322821026133, 6.9112, 168.9110361441731, 1760524.205985298, 1453964.889532816, 311349.2751118926], 
processed observation next is [1.0, 0.6521739130434783, 0.4786729857819906, 0.855, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0432122821026133, 0.0, 0.8294305152748289, 0.4890345016625828, 0.40387913598133773, 0.4647004106147651], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1654463], dtype=float32), 0.4165293]. 
=============================================
[2019-03-26 20:46:21,393] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 20:46:21,393] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:46:21,394] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:46:21,394] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:46:21,395] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:46:21,396] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:46:21,397] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:46:21,398] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:46:21,400] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:46:21,400] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:46:21,403] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:46:21,422] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run37
[2019-03-26 20:46:21,441] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run37
[2019-03-26 20:46:21,441] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run37
[2019-03-26 20:46:21,461] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run37
[2019-03-26 20:46:21,463] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run37
[2019-03-26 20:46:44,501] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07702083], dtype=float32), 0.06536546]
[2019-03-26 20:46:44,503] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.0, 57.0, 1.0, 2.0, 0.3597016180012442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 549558.4744311062, 549558.4744311069, 170475.6977692278]
[2019-03-26 20:46:44,506] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:46:44,509] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.5126543e-19 1.0000000e+00 2.6586536e-18 7.4211987e-16 5.1329349e-22], sampled 0.8880373050512276
[2019-03-26 20:47:20,516] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07702083], dtype=float32), 0.06536546]
[2019-03-26 20:47:20,518] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.66666666666666, 72.33333333333333, 1.0, 2.0, 0.605403271208467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 846015.6657879984, 846015.665787999, 201757.0875099954]
[2019-03-26 20:47:20,518] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:47:20,521] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.2603662e-21 1.0000000e+00 1.3089933e-19 9.0886847e-17 1.9031249e-23], sampled 0.3366450163351785
[2019-03-26 20:48:05,810] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07702083], dtype=float32), 0.06536546]
[2019-03-26 20:48:05,812] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.78333333333333, 84.16666666666667, 1.0, 2.0, 0.4705645336530451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 663273.8861411756, 663273.8861411756, 179853.4742387891]
[2019-03-26 20:48:05,813] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:48:05,816] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.0548400e-20 1.0000000e+00 5.5419105e-19 2.3338301e-16 7.8126474e-23], sampled 0.4058108343143435
[2019-03-26 20:48:16,513] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.2473 2779265161.4241 933.0000
[2019-03-26 20:48:16,742] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.5884 2927466011.8531 1338.0000
[2019-03-26 20:48:16,744] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6674 3164201025.1587 1778.0000
[2019-03-26 20:48:16,785] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 20:48:16,916] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2767 3007680316.3481 1766.0000
[2019-03-26 20:48:17,934] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 900000, evaluation results [900000.0, 7882.66739125975, 3164201025.158725, 1778.0, 8253.588413883566, 2927466011.853124, 1338.0, 8659.247308817945, 2779265161.4241467, 933.0, 7998.276703650782, 3007680316.348062, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 20:48:20,342] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0262046e-19 1.0000000e+00 1.9878935e-17 5.0247879e-16 4.4753859e-22], sum to 1.0000
[2019-03-26 20:48:20,349] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1096
[2019-03-26 20:48:20,354] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.51666666666667, 93.33333333333334, 1.0, 2.0, 0.4608808574322754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 677225.1522928596, 677225.1522928596, 181884.2629197574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1919400.0000, 
sim time next is 1920000.0000, 
raw observation next is [23.63333333333333, 92.66666666666667, 1.0, 2.0, 0.4303234485036004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 631597.265746425, 631597.2657464244, 177259.1514627667], 
processed observation next is [1.0, 0.21739130434782608, 0.3191153238546602, 0.9266666666666667, 1.0, 1.0, 0.31364270904048236, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1754436849295625, 0.17544368492956233, 0.26456589770562194], 
reward next is 0.7354, 
noisyNet noise sample is [array([-1.5420735], dtype=float32), 0.85890603]. 
=============================================
[2019-03-26 20:48:20,380] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[72.05298 ]
 [72.004425]
 [71.999275]
 [72.03529 ]
 [71.962975]], R is [[72.07278442]
 [72.08058929]
 [72.09789276]
 [72.11463928]
 [72.13034821]].
[2019-03-26 20:48:22,790] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5490325e-13 1.0000000e+00 7.9277313e-13 3.6847958e-10 6.9752990e-15], sum to 1.0000
[2019-03-26 20:48:22,796] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9872
[2019-03-26 20:48:22,801] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.43333333333334, 83.83333333333334, 1.0, 2.0, 1.005540251031928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9127213910156, 1438975.589868758, 1438975.589868758, 305848.4243092289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1959000.0000, 
sim time next is 1959600.0000, 
raw observation next is [25.26666666666667, 84.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.093763841999584, 6.9112, 168.9119773570833, 1621476.502378422, 1491960.180284987, 317424.2395773351], 
processed observation next is [1.0, 0.6956521739130435, 0.3965244865718801, 0.8466666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.018256384199958387, 0.0, 0.829435137061107, 0.45041013954956166, 0.41443338341249636, 0.47376752175721654], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.39419955], dtype=float32), 1.8716087]. 
=============================================
[2019-03-26 20:48:30,722] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6460337e-20 1.0000000e+00 1.0969436e-18 2.9331586e-16 9.8552626e-23], sum to 1.0000
[2019-03-26 20:48:30,733] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6648
[2019-03-26 20:48:30,742] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 86.5, 1.0, 2.0, 0.5107083068985722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 713640.5373868372, 713640.5373868379, 185291.4615950815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2104200.0000, 
sim time next is 2104800.0000, 
raw observation next is [27.1, 85.66666666666667, 1.0, 2.0, 0.5132600484130145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 717207.4285421473, 717207.4285421467, 185700.380978169], 
processed observation next is [0.0, 0.34782608695652173, 0.4834123222748816, 0.8566666666666667, 1.0, 1.0, 0.4135663233891741, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19922428570615203, 0.19922428570615186, 0.27716474772861044], 
reward next is 0.7228, 
noisyNet noise sample is [array([1.3066779], dtype=float32), 1.4656998]. 
=============================================
[2019-03-26 20:48:34,490] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2869215e-18 1.0000000e+00 1.5737234e-17 4.1370495e-15 1.5285529e-20], sum to 1.0000
[2019-03-26 20:48:34,500] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8827
[2019-03-26 20:48:34,504] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 95.16666666666667, 1.0, 2.0, 0.7088116804154643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 990590.2621577844, 990590.2621577844, 222755.8968294621], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2171400.0000, 
sim time next is 2172000.0000, 
raw observation next is [24.93333333333333, 95.33333333333334, 1.0, 2.0, 0.6431525871204777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 898790.4477961449, 898790.4477961449, 209050.4975111737], 
processed observation next is [1.0, 0.13043478260869565, 0.38072669826224315, 0.9533333333333335, 1.0, 1.0, 0.5700633579764792, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2496640132767069, 0.2496640132767069, 0.31201566792712493], 
reward next is 0.6880, 
noisyNet noise sample is [array([-0.5980429], dtype=float32), 0.0478461]. 
=============================================
[2019-03-26 20:48:34,518] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.99054 ]
 [69.89104 ]
 [69.713066]
 [69.59409 ]
 [69.55251 ]], R is [[70.08892059]
 [70.05555725]
 [69.99590302]
 [69.93202209]
 [69.85423279]].
[2019-03-26 20:48:38,917] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0671234e-18 1.0000000e+00 7.3399657e-18 2.5663726e-15 1.4659504e-22], sum to 1.0000
[2019-03-26 20:48:38,923] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5396
[2019-03-26 20:48:38,934] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.55, 84.5, 1.0, 2.0, 0.531361632074012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742510.6403696458, 742510.6403696451, 188655.7856488573], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2241000.0000, 
sim time next is 2241600.0000, 
raw observation next is [27.46666666666667, 84.66666666666667, 1.0, 2.0, 0.5300039202080183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740612.7484461255, 740612.7484461262, 188430.6489737317], 
processed observation next is [1.0, 0.9565217391304348, 0.500789889415482, 0.8466666666666667, 1.0, 1.0, 0.4337396629012269, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2057257634572571, 0.2057257634572573, 0.28123977458765925], 
reward next is 0.7188, 
noisyNet noise sample is [array([1.7209266], dtype=float32), -1.3413903]. 
=============================================
[2019-03-26 20:48:56,834] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2944243e-16 1.0000000e+00 2.2556074e-15 6.7323631e-13 8.9766922e-19], sum to 1.0000
[2019-03-26 20:48:56,844] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1738
[2019-03-26 20:48:56,855] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1839698.987399578 W.
[2019-03-26 20:48:56,859] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.1, 89.0, 1.0, 2.0, 0.4386239860499572, 1.0, 1.0, 0.4386239860499572, 1.0, 2.0, 0.7566653310216834, 6.9112, 6.9112, 170.5573041426782, 1839698.987399578, 1839698.987399578, 374508.7242936583], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2538000.0000, 
sim time next is 2538600.0000, 
raw observation next is [27.21666666666667, 88.16666666666667, 1.0, 2.0, 0.4697690768911749, 1.0, 2.0, 0.4697690768911749, 1.0, 2.0, 0.8114871349464242, 6.9112, 6.9112, 170.5573041426782, 1970449.430687979, 1970449.430687979, 394138.8618716993], 
processed observation next is [1.0, 0.391304347826087, 0.48894154818325447, 0.8816666666666667, 1.0, 1.0, 0.3611675625194879, 1.0, 1.0, 0.3611675625194879, 1.0, 1.0, 0.7701062621297855, 0.0, 0.0, 0.8375144448122397, 0.5473470640799942, 0.5473470640799942, 0.5882669580174616], 
reward next is 0.4117, 
noisyNet noise sample is [array([0.74663657], dtype=float32), 1.0054524]. 
=============================================
[2019-03-26 20:49:01,824] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0160911e-18 1.0000000e+00 1.8523047e-18 2.0574070e-16 5.6377054e-22], sum to 1.0000
[2019-03-26 20:49:01,833] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2537
[2019-03-26 20:49:01,837] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666666, 85.66666666666667, 1.0, 2.0, 0.4682794274503636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 657664.9178185721, 657664.9178185728, 179205.7604229623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2619600.0000, 
sim time next is 2620200.0000, 
raw observation next is [25.83333333333334, 84.83333333333333, 1.0, 2.0, 0.4706401665435882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 659581.9644106363, 659581.9644106363, 179375.6299886161], 
processed observation next is [0.0, 0.30434782608695654, 0.42338072669826254, 0.8483333333333333, 1.0, 1.0, 0.36221706812480503, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18321721233628788, 0.18321721233628788, 0.2677248208785315], 
reward next is 0.7323, 
noisyNet noise sample is [array([-1.4587141], dtype=float32), 0.56966823]. 
=============================================
[2019-03-26 20:49:04,269] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.7154580e-18 1.0000000e+00 7.0044357e-17 2.0955953e-15 3.0385092e-21], sum to 1.0000
[2019-03-26 20:49:04,281] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8126
[2019-03-26 20:49:04,288] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 99.0, 1.0, 2.0, 0.3432213617658628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 532063.7906343807, 532063.79063438, 169267.1162802483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3127800.0000, 
sim time next is 3128400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.342328538041652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 531439.1029385976, 531439.1029385976, 169237.7812907807], 
processed observation next is [1.0, 0.21739130434782608, 0.19431279620853087, 1.0, 1.0, 1.0, 0.20762474462849634, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14762197303849933, 0.14762197303849933, 0.25259370341907567], 
reward next is 0.7474, 
noisyNet noise sample is [array([-0.03939802], dtype=float32), -0.4095337]. 
=============================================
[2019-03-26 20:49:10,717] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1833012e-19 1.0000000e+00 2.1153751e-17 2.4388094e-15 2.1448343e-21], sum to 1.0000
[2019-03-26 20:49:10,729] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4776
[2019-03-26 20:49:10,737] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.348595990499932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 537003.0584279208, 537003.0584279202, 169570.6688884929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2769000.0000, 
sim time next is 2769600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3485839557927702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 536984.4613737067, 536984.4613737067, 169569.1448971195], 
processed observation next is [1.0, 0.043478260869565216, 0.2417061611374408, 0.94, 1.0, 1.0, 0.21516139252140987, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1491623503815852, 0.1491623503815852, 0.25308827596585], 
reward next is 0.7469, 
noisyNet noise sample is [array([-2.3312628], dtype=float32), 0.4370496]. 
=============================================
[2019-03-26 20:49:13,309] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 20:49:13,313] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:49:13,314] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:49:13,316] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:49:13,317] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:49:13,319] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:49:13,320] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:49:13,321] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:49:13,322] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:49:13,322] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:49:13,323] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:49:13,337] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run38
[2019-03-26 20:49:13,358] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run38
[2019-03-26 20:49:13,358] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run38
[2019-03-26 20:49:13,398] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run38
[2019-03-26 20:49:13,415] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run38
[2019-03-26 20:49:21,367] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07750741], dtype=float32), 0.06487997]
[2019-03-26 20:49:21,369] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.76666666666667, 71.0, 1.0, 2.0, 0.7370344117010069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1041724.405904566, 1041724.405904567, 230634.8910394287]
[2019-03-26 20:49:21,370] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:49:21,373] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.3215746e-20 1.0000000e+00 9.6531678e-19 2.7009464e-16 1.2106006e-22], sampled 0.6828909828788039
[2019-03-26 20:49:39,220] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07750741], dtype=float32), 0.06487997]
[2019-03-26 20:49:39,222] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.16316816, 89.76867278, 1.0, 2.0, 0.4530122113217309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 657730.9407343311, 657730.9407343304, 179711.8010705198]
[2019-03-26 20:49:39,223] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:49:39,226] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.9217454e-20 1.0000000e+00 2.4739333e-19 1.4137480e-16 3.6315972e-23], sampled 0.1556662040066823
[2019-03-26 20:50:09,662] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07750741], dtype=float32), 0.06487997]
[2019-03-26 20:50:09,663] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [37.51666666666667, 44.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.391137885596201, 6.9112, 168.9101613151846, 1794466.949675181, 1453988.129830425, 311354.5510313082]
[2019-03-26 20:50:09,664] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:50:09,668] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.9246428e-17 1.0000000e+00 1.6689698e-16 7.4380274e-14 1.1124081e-19], sampled 0.7839813464825254
[2019-03-26 20:50:09,671] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1794466.949675181 W.
[2019-03-26 20:50:48,699] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07750741], dtype=float32), 0.06487997]
[2019-03-26 20:50:48,701] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.11666666666667, 92.83333333333333, 1.0, 2.0, 0.6530760839191702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 912664.2571650674, 912664.257165068, 211042.0464341715]
[2019-03-26 20:50:48,705] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:50:48,710] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.1681188e-20 1.0000000e+00 5.7421358e-19 1.5413559e-16 5.3950494e-23], sampled 0.45687123334982715
[2019-03-26 20:51:00,299] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07750741], dtype=float32), 0.06487997]
[2019-03-26 20:51:00,300] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.0, 72.0, 1.0, 2.0, 0.3529430983346466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 544314.467373413, 544314.467373413, 170190.4459524591]
[2019-03-26 20:51:00,301] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:51:00,302] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.5947269e-19 1.0000000e+00 9.4122715e-18 2.3171450e-15 1.9755294e-21], sampled 0.2809951132429245
[2019-03-26 20:51:08,351] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8657.7255 2779296335.4222 933.0000
[2019-03-26 20:51:08,374] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07750741], dtype=float32), 0.06487997]
[2019-03-26 20:51:08,375] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.502026755, 70.34475208666667, 1.0, 2.0, 0.6184365696060591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9128745223207, 864236.3482796514, 864236.3482796521, 204223.9528173999]
[2019-03-26 20:51:08,376] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:51:08,377] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.5834340e-15 1.0000000e+00 6.1626344e-15 3.9337613e-12 1.4335693e-17], sampled 0.8039887497259841
[2019-03-26 20:51:08,655] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.1321 2842451957.6633 1131.0000
[2019-03-26 20:51:08,692] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.8717 2927447046.3306 1338.0000
[2019-03-26 20:51:08,696] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164027848.4855 1778.0000
[2019-03-26 20:51:08,804] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 20:51:09,820] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 925000, evaluation results [925000.0, 7884.16835844559, 3164027848.485504, 1778.0, 8254.871735174753, 2927447046.3306217, 1338.0, 8657.725469675026, 2779296335.422204, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8496.132105234119, 2842451957.6632614, 1131.0]
[2019-03-26 20:51:15,978] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9949565e-19 1.0000000e+00 1.8480770e-18 8.4237358e-16 1.7393399e-21], sum to 1.0000
[2019-03-26 20:51:15,985] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3101
[2019-03-26 20:51:15,991] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 97.0, 1.0, 2.0, 0.31207332160021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 495274.6924825286, 495274.6924825286, 166706.4719911926], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2926800.0000, 
sim time next is 2927400.0000, 
raw observation next is [20.58333333333334, 96.50000000000001, 1.0, 2.0, 0.312656314054623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 495910.2715004249, 495910.2715004249, 166748.6065074436], 
processed observation next is [1.0, 0.9130434782608695, 0.17456556082148533, 0.9650000000000002, 1.0, 1.0, 0.1718750771742446, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13775285319456246, 0.13775285319456246, 0.24887851717528894], 
reward next is 0.7511, 
noisyNet noise sample is [array([0.84037113], dtype=float32), 0.86933744]. 
=============================================
[2019-03-26 20:51:16,784] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3128445e-18 1.0000000e+00 2.9495275e-17 7.3773681e-15 5.3967222e-21], sum to 1.0000
[2019-03-26 20:51:16,796] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7342
[2019-03-26 20:51:16,805] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3028660219808765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 482297.4615000679, 482297.4615000679, 165786.6792181012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2943600.0000, 
sim time next is 2944200.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3029009757181943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 482353.0474773564, 482353.0474773558, 165790.674409861], 
processed observation next is [1.0, 0.043478260869565216, 0.1469194312796209, 1.0, 1.0, 1.0, 0.16012165749180035, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.133986957632599, 0.13398695763259882, 0.24744876777591196], 
reward next is 0.7526, 
noisyNet noise sample is [array([1.323252], dtype=float32), 1.8539208]. 
=============================================
[2019-03-26 20:51:22,957] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.7163659e-18 1.0000000e+00 1.8565855e-17 5.3278051e-15 1.2102041e-21], sum to 1.0000
[2019-03-26 20:51:22,967] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5052
[2019-03-26 20:51:22,973] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 93.33333333333334, 1.0, 2.0, 0.9607025276158709, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.9129564061214, 1342839.539883344, 1342839.539883343, 287180.2992788879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3379200.0000, 
sim time next is 3379800.0000, 
raw observation next is [26.05, 93.66666666666667, 1.0, 2.0, 0.9263271978212507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104049, 1294761.4939872, 1294761.493987201, 277281.5065194667], 
processed observation next is [1.0, 0.08695652173913043, 0.43364928909952616, 0.9366666666666668, 1.0, 1.0, 0.9112375877364467, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451521746, 0.35965597055200005, 0.35965597055200027, 0.4138529948051742], 
reward next is 0.5861, 
noisyNet noise sample is [array([0.6498348], dtype=float32), -0.9050127]. 
=============================================
[2019-03-26 20:51:33,367] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.3008072e-20 1.0000000e+00 1.0600637e-18 5.7676321e-16 6.1702542e-23], sum to 1.0000
[2019-03-26 20:51:33,376] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1780
[2019-03-26 20:51:33,382] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 82.33333333333334, 1.0, 2.0, 0.4725219784565339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 660264.1175018304, 660264.1175018311, 179402.8188057252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3223200.0000, 
sim time next is 3223800.0000, 
raw observation next is [26.5, 81.5, 1.0, 2.0, 0.4734447424415968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 661553.9149877997, 661553.9149877997, 179540.0543227098], 
processed observation next is [0.0, 0.30434782608695654, 0.4549763033175356, 0.815, 1.0, 1.0, 0.36559607523083953, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1837649763854999, 0.1837649763854999, 0.2679702303324027], 
reward next is 0.7320, 
noisyNet noise sample is [array([-0.9497194], dtype=float32), -0.5410768]. 
=============================================
[2019-03-26 20:51:37,146] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.9192600e-19 1.0000000e+00 5.8726582e-19 6.8267732e-16 3.6692387e-22], sum to 1.0000
[2019-03-26 20:51:37,154] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7532
[2019-03-26 20:51:37,158] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.5368056235281804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 750120.615587785, 750120.6155877844, 189563.6615732112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3363000.0000, 
sim time next is 3363600.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.5380746063124562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 751894.4923981369, 751894.4923981369, 189776.4799464616], 
processed observation next is [0.0, 0.9565217391304348, 0.4786729857819906, 0.89, 1.0, 1.0, 0.44346338109934474, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2088595812217047, 0.2088595812217047, 0.28324847753203225], 
reward next is 0.7168, 
noisyNet noise sample is [array([0.20578817], dtype=float32), 1.0580773]. 
=============================================
[2019-03-26 20:51:38,045] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.4769392e-20 1.0000000e+00 1.7248526e-18 7.1326752e-17 4.4227717e-23], sum to 1.0000
[2019-03-26 20:51:38,057] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2673
[2019-03-26 20:51:38,062] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.4232603203675319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 619726.5050434443, 619726.5050434449, 176067.713518332], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3298800.0000, 
sim time next is 3299400.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.4228097815742998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 619072.0669224252, 619072.0669224246, 176004.9039168248], 
processed observation next is [0.0, 0.17391304347826086, 0.38388625592417064, 0.83, 1.0, 1.0, 0.3045900982822889, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.171964463034007, 0.17196446303400684, 0.2626938864430221], 
reward next is 0.7373, 
noisyNet noise sample is [array([-1.3794016], dtype=float32), 0.66576785]. 
=============================================
[2019-03-26 20:51:38,972] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0553960e-13 1.0000000e+00 1.3710884e-12 2.7675440e-10 1.4613429e-16], sum to 1.0000
[2019-03-26 20:51:38,980] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8861
[2019-03-26 20:51:38,986] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666667, 70.66666666666667, 1.0, 2.0, 0.5429697960851061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 758737.373915605, 758737.373915605, 190603.789200118], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3435000.0000, 
sim time next is 3435600.0000, 
raw observation next is [30.33333333333334, 71.33333333333334, 1.0, 2.0, 0.5430648807823452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 758870.2912250569, 758870.2912250574, 190619.3539496436], 
processed observation next is [1.0, 0.782608695652174, 0.6366508688783573, 0.7133333333333334, 1.0, 1.0, 0.4494757599787291, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21079730311807135, 0.21079730311807152, 0.2845064984323039], 
reward next is 0.7155, 
noisyNet noise sample is [array([-1.565319], dtype=float32), 1.5113715]. 
=============================================
[2019-03-26 20:51:43,874] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6908431e-15 1.0000000e+00 8.8695781e-14 2.9184558e-11 5.2808560e-17], sum to 1.0000
[2019-03-26 20:51:43,881] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2928
[2019-03-26 20:51:43,890] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2207631.835587648 W.
[2019-03-26 20:51:43,896] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 75.0, 1.0, 2.0, 0.78938524948167, 1.0, 2.0, 0.78938524948167, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2207631.835587648, 2207631.835587648, 414738.8432795599], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3402000.0000, 
sim time next is 3402600.0000, 
raw observation next is [30.16666666666666, 74.16666666666667, 1.0, 2.0, 0.9678508719757132, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.003065965862143, 6.9112, 168.9124099799762, 2250004.298296398, 2184831.631202963, 453673.2890163329], 
processed observation next is [1.0, 0.391304347826087, 0.6287519747235385, 0.7416666666666667, 1.0, 1.0, 0.9612661108141123, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.009186596586214258, 0.0, 0.8294372614375668, 0.6250011939712217, 0.6068976753341564, 0.6771243119646759], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3063295], dtype=float32), -0.98665607]. 
=============================================
[2019-03-26 20:51:49,429] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8823755e-14 1.0000000e+00 8.4103866e-14 2.3624684e-11 6.0051691e-17], sum to 1.0000
[2019-03-26 20:51:49,438] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9956
[2019-03-26 20:51:49,447] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2049816.466451498 W.
[2019-03-26 20:51:49,455] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 66.0, 1.0, 2.0, 0.7330089817639536, 1.0, 2.0, 0.7330089817639536, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2049816.466451498, 2049816.466451498, 388568.3322343022], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3489600.0000, 
sim time next is 3490200.0000, 
raw observation next is [30.0, 66.0, 1.0, 2.0, 0.9074725078271609, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.975723466243606, 6.9112, 168.9125725399419, 2165495.995462245, 2119720.931838158, 437181.3223207155], 
processed observation next is [1.0, 0.391304347826087, 0.6208530805687204, 0.66, 1.0, 1.0, 0.8885210937676637, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.0064523466243605835, 0.0, 0.8294380596814187, 0.6015266654061792, 0.5888113699550439, 0.6525094362995754], 
reward next is 0.0249, 
noisyNet noise sample is [array([-1.0427207], dtype=float32), -1.2908328]. 
=============================================
[2019-03-26 20:51:51,162] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.5795785e-14 1.0000000e+00 1.5328179e-13 6.1052641e-10 1.6988062e-16], sum to 1.0000
[2019-03-26 20:51:51,173] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7369
[2019-03-26 20:51:51,177] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.5, 72.5, 1.0, 2.0, 0.5586218292961201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780617.3135819572, 780617.3135819572, 193291.0778714404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3522600.0000, 
sim time next is 3523200.0000, 
raw observation next is [30.33333333333334, 73.33333333333334, 1.0, 2.0, 0.5570663515143547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 778442.8947538843, 778442.8947538843, 193020.7645969841], 
processed observation next is [1.0, 0.782608695652174, 0.6366508688783573, 0.7333333333333334, 1.0, 1.0, 0.4663450018245237, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21623413743163453, 0.21623413743163453, 0.2880906934283345], 
reward next is 0.7119, 
noisyNet noise sample is [array([0.7470825], dtype=float32), -0.5202774]. 
=============================================
[2019-03-26 20:52:01,294] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7544903e-06 9.9959761e-01 2.1758676e-06 3.9844695e-04 5.7565330e-08], sum to 1.0000
[2019-03-26 20:52:01,302] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8544
[2019-03-26 20:52:01,309] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2714694.317436214 W.
[2019-03-26 20:52:01,314] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.0, 59.0, 1.0, 2.0, 0.9704990560376204, 1.0, 2.0, 0.9704990560376204, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2714694.317436214, 2714694.317436213, 511410.1232128367], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3684000.0000, 
sim time next is 3684600.0000, 
raw observation next is [33.0, 59.0, 1.0, 2.0, 0.6650100431462004, 1.0, 2.0, 0.6530950610873628, 1.0, 1.0, 1.03, 7.005094973392655, 6.9112, 170.5573041426782, 2740298.801259573, 2673038.012415094, 510503.822679501], 
processed observation next is [1.0, 0.6521739130434783, 0.7630331753554502, 0.59, 1.0, 1.0, 0.5963976423448197, 1.0, 1.0, 0.5820422422739311, 1.0, 0.5, 1.0365853658536586, 0.009389497339265506, 0.0, 0.8375144448122397, 0.7611941114609925, 0.7425105590041927, 0.7619460039992553], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8835611], dtype=float32), -0.44520974]. 
=============================================
[2019-03-26 20:52:03,184] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.5373489e-18 1.0000000e+00 3.1495802e-17 7.1850227e-14 2.1187073e-20], sum to 1.0000
[2019-03-26 20:52:03,186] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0076
[2019-03-26 20:52:03,190] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.4509556509691987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 644644.5115775216, 644644.5115775221, 178136.6356711813], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3721800.0000, 
sim time next is 3722400.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.4506987407720722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 644277.5792512562, 644277.5792512568, 178099.2523405596], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.74, 1.0, 1.0, 0.33819125394225574, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17896599423646006, 0.1789659942364602, 0.2658197796127755], 
reward next is 0.7342, 
noisyNet noise sample is [array([-0.8740636], dtype=float32), 0.9314698]. 
=============================================
[2019-03-26 20:52:05,124] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.1715730e-16 1.0000000e+00 1.8039337e-15 1.9102917e-13 5.1858662e-19], sum to 1.0000
[2019-03-26 20:52:05,135] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8949
[2019-03-26 20:52:05,143] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2088521.55272127 W.
[2019-03-26 20:52:05,149] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 70.0, 1.0, 2.0, 0.8524784363192753, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.969994472172504, 6.9112, 168.912557135727, 2088521.55272127, 2046810.829232838, 422419.6750745567], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3747000.0000, 
sim time next is 3747600.0000, 
raw observation next is [29.0, 70.0, 1.0, 2.0, 0.8089966406410334, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.969935009459197, 6.9112, 168.9125587959448, 2027664.636839348, 1985996.097736989, 411276.2215164255], 
processed observation next is [1.0, 0.391304347826087, 0.5734597156398105, 0.7, 1.0, 1.0, 0.7698754706518475, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.00587350094591974, 0.0, 0.8294379921921009, 0.5632401768998189, 0.5516655827047191, 0.6138451067409335], 
reward next is 0.0925, 
noisyNet noise sample is [array([-0.54153293], dtype=float32), -1.5387342]. 
=============================================
[2019-03-26 20:52:05,254] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 20:52:05,255] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:52:05,257] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:52:05,258] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:52:05,259] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:52:05,260] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:52:05,261] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:52:05,262] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:52:05,262] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:52:05,263] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:52:05,264] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:52:05,286] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run39
[2019-03-26 20:52:05,286] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run39
[2019-03-26 20:52:05,325] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run39
[2019-03-26 20:52:05,325] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run39
[2019-03-26 20:52:05,370] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run39
[2019-03-26 20:52:20,647] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07586104], dtype=float32), 0.06269049]
[2019-03-26 20:52:20,648] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.7672784, 97.72755044499999, 1.0, 2.0, 0.3322431934724575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 522235.5257508077, 522235.5257508077, 168665.8598901371]
[2019-03-26 20:52:20,649] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:52:20,652] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1981708e-18 1.0000000e+00 1.3070138e-17 2.6377466e-15 1.0717847e-21], sampled 0.6415442451778289
[2019-03-26 20:52:21,498] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07586104], dtype=float32), 0.06269049]
[2019-03-26 20:52:21,500] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.64355299, 98.03227709, 1.0, 2.0, 0.3890059809799953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 580346.5626196684, 580346.5626196684, 172735.6094290185]
[2019-03-26 20:52:21,501] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:52:21,504] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.4414982e-18 1.0000000e+00 1.7220527e-17 5.8823787e-15 2.0602056e-21], sampled 0.8686404558511499
[2019-03-26 20:53:21,029] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07586104], dtype=float32), 0.06269049]
[2019-03-26 20:53:21,031] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.6, 61.0, 1.0, 2.0, 0.5730608329366773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 800801.9617936152, 800801.9617936147, 195833.734715194]
[2019-03-26 20:53:21,031] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 20:53:21,035] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2354074e-19 1.0000000e+00 1.2229310e-18 6.6359213e-16 1.2109332e-22], sampled 0.1899056118922039
[2019-03-26 20:53:48,585] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07586104], dtype=float32), 0.06269049]
[2019-03-26 20:53:48,586] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.08333333333333, 79.33333333333334, 1.0, 2.0, 0.8136092363476667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1137127.098295576, 1137127.098295576, 247285.7189269558]
[2019-03-26 20:53:48,586] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:53:48,590] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.7637021e-19 1.0000000e+00 1.9325983e-18 1.0835659e-15 1.6724317e-22], sampled 0.6329532465154235
[2019-03-26 20:53:56,094] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07586104], dtype=float32), 0.06269049]
[2019-03-26 20:53:56,095] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.33333333333334, 54.33333333333333, 1.0, 2.0, 0.5815070450223081, 0.0, 2.0, 0.0, 1.0, 2.0, 1.009885429885332, 6.911199999999999, 6.9112, 168.9129561277913, 1625840.795168864, 1625840.795168864, 355933.0405849325]
[2019-03-26 20:53:56,097] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:53:56,102] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.1681861e-16 1.0000000e+00 1.1913817e-15 1.0548230e-12 1.2411710e-18], sampled 0.8794931465563132
[2019-03-26 20:53:56,814] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07586104], dtype=float32), 0.06269049]
[2019-03-26 20:53:56,815] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.70687542666667, 82.57729515, 1.0, 2.0, 0.5561746476643238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 777196.3745264774, 777196.3745264767, 192863.2818193711]
[2019-03-26 20:53:56,817] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 20:53:56,820] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.851140e-20 1.000000e+00 9.017293e-19 6.787589e-16 7.849601e-23], sampled 0.8312993447198254
[2019-03-26 20:54:00,096] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8724 2842497929.8887 1131.0000
[2019-03-26 20:54:00,127] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 20:54:00,185] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4154 3163997799.2143 1778.0000
[2019-03-26 20:54:00,299] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 20:54:00,318] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.1097 2779315363.5344 933.0000
[2019-03-26 20:54:01,332] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 950000, evaluation results [950000.0, 7883.415429661524, 3163997799.214286, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8659.10971405369, 2779315363.534448, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8496.87235025343, 2842497929.888741, 1131.0]
[2019-03-26 20:54:04,396] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.4745417e-18 1.0000000e+00 1.5025398e-17 2.8769064e-14 5.7025323e-21], sum to 1.0000
[2019-03-26 20:54:04,406] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7158
[2019-03-26 20:54:04,411] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5172292827914047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722755.7521721631, 722755.7521721631, 186339.6530535103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3807600.0000, 
sim time next is 3808200.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5169078942163573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 722306.5037944618, 722306.5037944611, 186287.6925481673], 
processed observation next is [0.0, 0.043478260869565216, 0.5260663507109005, 0.79, 1.0, 1.0, 0.4179613183329606, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2006406954984616, 0.20064069549846142, 0.2780413321614437], 
reward next is 0.7220, 
noisyNet noise sample is [array([-1.0078609], dtype=float32), -0.55364186]. 
=============================================
[2019-03-26 20:54:11,310] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.6849490e-12 1.0000000e+00 2.6648401e-12 1.3737158e-09 7.9239441e-15], sum to 1.0000
[2019-03-26 20:54:11,324] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7099
[2019-03-26 20:54:11,336] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2152205.574575119 W.
[2019-03-26 20:54:11,342] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.66666666666667, 75.66666666666667, 1.0, 2.0, 0.7695863134946676, 1.0, 2.0, 0.7695863134946676, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2152205.574575119, 2152205.574575119, 405330.8848840685], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4009800.0000, 
sim time next is 4010400.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.5201952126951489, 1.0, 2.0, 0.5201952126951489, 1.0, 1.0, 0.8935859335083844, 6.911199999999999, 6.9112, 170.5573041426782, 2182177.615524209, 2182177.61552421, 427530.4201671232], 
processed observation next is [1.0, 0.43478260869565216, 0.5734597156398105, 0.74, 1.0, 1.0, 0.42192194300620345, 1.0, 1.0, 0.42192194300620345, 1.0, 0.5, 0.8702267481809567, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6061604487567247, 0.606160448756725, 0.6381051047270495], 
reward next is 0.3619, 
noisyNet noise sample is [array([0.39157015], dtype=float32), -1.3171666]. 
=============================================
[2019-03-26 20:54:14,059] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.7730954e-13 1.0000000e+00 1.7069849e-12 3.0032696e-10 2.5079748e-15], sum to 1.0000
[2019-03-26 20:54:14,067] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1118
[2019-03-26 20:54:14,075] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1941155.176729104 W.
[2019-03-26 20:54:14,083] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.83333333333333, 79.83333333333334, 1.0, 2.0, 0.4627914408725608, 1.0, 2.0, 0.4627914408725608, 1.0, 2.0, 0.8037156853274392, 6.9112, 6.9112, 170.5573041426782, 1941155.176729104, 1941155.176729104, 390369.9566309965], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3985800.0000, 
sim time next is 3986400.0000, 
raw observation next is [29.66666666666667, 80.66666666666667, 1.0, 2.0, 0.6371745502108916, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.998077467091528, 6.9112, 168.9124356057172, 1781612.722575277, 1719979.047399398, 371629.306917244], 
processed observation next is [1.0, 0.13043478260869565, 0.6050552922590839, 0.8066666666666668, 1.0, 1.0, 0.5628609038685441, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008687746709152755, 0.0, 0.8294373872716867, 0.49489242293757696, 0.4777719576109439, 0.5546706073391702], 
reward next is 0.0109, 
noisyNet noise sample is [array([1.4675952], dtype=float32), -0.47633192]. 
=============================================
[2019-03-26 20:54:24,314] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8357799e-19 1.0000000e+00 5.1455316e-18 2.6862337e-15 2.9631206e-22], sum to 1.0000
[2019-03-26 20:54:24,324] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6841
[2019-03-26 20:54:24,333] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.6253095733433646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 873845.0023829468, 873845.0023829468, 205556.1514635404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4222800.0000, 
sim time next is 4223400.0000, 
raw observation next is [31.16666666666667, 77.66666666666667, 1.0, 2.0, 0.6261640746376792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 875039.6255179587, 875039.6255179587, 205721.643896095], 
processed observation next is [1.0, 0.9130434782608695, 0.6761453396524489, 0.7766666666666667, 1.0, 1.0, 0.5495952706478062, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2430665626438774, 0.2430665626438774, 0.30704722969566417], 
reward next is 0.6930, 
noisyNet noise sample is [array([-0.4589519], dtype=float32), 0.9917569]. 
=============================================
[2019-03-26 20:54:25,229] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.4560431e-18 1.0000000e+00 1.5075742e-18 2.5905296e-15 1.4039731e-22], sum to 1.0000
[2019-03-26 20:54:25,241] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7824
[2019-03-26 20:54:25,246] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666667, 82.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.916186142425426, 6.9112, 168.9128263400949, 1457294.688481161, 1453757.350160787, 311357.4961964511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4173600.0000, 
sim time next is 4174200.0000, 
raw observation next is [31.0, 81.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.263297578968324, 6.9112, 168.9109766956921, 1703713.217283246, 1453926.004269188, 311358.1073930356], 
processed observation next is [1.0, 0.30434782608695654, 0.6682464454976303, 0.815, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.03520975789683236, 0.0, 0.8294302233555716, 0.47325367146756836, 0.4038683345192189, 0.46471359312393373], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.37031186], dtype=float32), 1.4131964]. 
=============================================
[2019-03-26 20:54:25,830] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.2655868e-11 1.0000000e+00 4.8433486e-11 2.5960787e-08 8.0358775e-14], sum to 1.0000
[2019-03-26 20:54:25,839] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1785
[2019-03-26 20:54:25,847] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2765019.118521234 W.
[2019-03-26 20:54:25,850] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.66666666666667, 67.33333333333334, 1.0, 2.0, 0.9884702075183035, 1.0, 2.0, 0.9884702075183035, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2765019.118521234, 2765019.118521235, 522068.2710250695], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4180800.0000, 
sim time next is 4181400.0000, 
raw observation next is [34.0, 65.5, 1.0, 2.0, 0.6824450434438054, 1.0, 2.0, 0.6618125612361652, 1.0, 1.0, 1.03, 7.005096348004823, 6.9112, 170.5573041426782, 2776916.909425229, 2709655.135890138, 515842.9769786153], 
processed observation next is [1.0, 0.391304347826087, 0.8104265402843602, 0.655, 1.0, 1.0, 0.6174036667997655, 1.0, 1.0, 0.5925452545014038, 1.0, 0.5, 1.0365853658536586, 0.009389634800482317, 0.0, 0.8375144448122397, 0.7713658081736747, 0.752681982191705, 0.7699148910128586], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.23936713], dtype=float32), 0.3935637]. 
=============================================
[2019-03-26 20:54:33,122] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.8665447e-11 9.9999952e-01 2.2556723e-10 5.0427627e-07 1.6100104e-13], sum to 1.0000
[2019-03-26 20:54:33,129] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4797
[2019-03-26 20:54:33,136] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [36.16666666666666, 49.66666666666667, 1.0, 2.0, 0.5571315156630094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 778533.9883165538, 778533.9883165538, 193033.9268777779], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4297800.0000, 
sim time next is 4298400.0000, 
raw observation next is [36.0, 50.0, 1.0, 2.0, 0.5650363426496096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 789584.2766094765, 789584.2766094772, 194414.7933898995], 
processed observation next is [1.0, 0.782608695652174, 0.9052132701421801, 0.5, 1.0, 1.0, 0.47594740078266207, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2193289657248546, 0.2193289657248548, 0.29017133341776047], 
reward next is 0.7098, 
noisyNet noise sample is [array([2.7395775], dtype=float32), 1.4584161]. 
=============================================
[2019-03-26 20:54:36,750] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.6764604e-06 9.9717748e-01 5.4728030e-06 2.8132154e-03 9.3442765e-08], sum to 1.0000
[2019-03-26 20:54:36,758] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2155
[2019-03-26 20:54:36,767] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3400074.57651669 W.
[2019-03-26 20:54:36,772] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.16666666666666, 59.0, 1.0, 2.0, 0.9790711017179462, 1.0, 2.0, 0.8101255903732357, 1.0, 2.0, 1.03, 7.005119746977728, 6.9112, 170.5573041426782, 3400074.57651669, 3332796.041345498, 623982.3866349928], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4360200.0000, 
sim time next is 4360800.0000, 
raw observation next is [36.33333333333334, 58.00000000000001, 1.0, 2.0, 0.9995067521537426, 1.0, 2.0, 0.8203434155911338, 1.0, 2.0, 1.03, 7.005121359877788, 6.9112, 170.5573041426782, 3443017.631362226, 3375737.940805112, 632642.1008355919], 
processed observation next is [1.0, 0.4782608695652174, 0.9210110584518172, 0.5800000000000001, 1.0, 1.0, 0.9994057254864369, 1.0, 1.0, 0.7835462838447395, 1.0, 1.0, 1.0365853658536586, 0.009392135987778794, 0.0, 0.8375144448122397, 0.9563937864895072, 0.9377049835569755, 0.9442419415456595], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4189125], dtype=float32), -0.49459237]. 
=============================================
[2019-03-26 20:54:39,848] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.2902471e-19 1.0000000e+00 4.6159801e-18 2.6697252e-15 4.3862969e-22], sum to 1.0000
[2019-03-26 20:54:39,861] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4332
[2019-03-26 20:54:39,866] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 84.0, 1.0, 2.0, 0.6186703196537894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 864563.1358813802, 864563.1358813802, 204275.9750784005], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4409400.0000, 
sim time next is 4410000.0000, 
raw observation next is [30.0, 84.0, 1.0, 2.0, 0.617992481989888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 863615.5040085978, 863615.5040085978, 204146.0588657027], 
processed observation next is [0.0, 0.043478260869565216, 0.6208530805687204, 0.84, 1.0, 1.0, 0.5397499783010699, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23989319555794383, 0.23989319555794383, 0.3046956102473175], 
reward next is 0.6953, 
noisyNet noise sample is [array([1.3637332], dtype=float32), -0.6711551]. 
=============================================
[2019-03-26 20:54:39,874] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[66.88454 ]
 [66.99882 ]
 [67.14727 ]
 [67.33492 ]
 [67.443245]], R is [[67.07459259]
 [67.09896088]
 [67.12314606]
 [67.14749146]
 [67.17181396]].
[2019-03-26 20:54:40,614] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.5605878e-19 1.0000000e+00 4.4142878e-18 4.6225599e-15 2.1152165e-22], sum to 1.0000
[2019-03-26 20:54:40,623] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3319
[2019-03-26 20:54:40,629] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.580097601090425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 810638.9769055882, 810638.9769055882, 197096.7969505157], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4425000.0000, 
sim time next is 4425600.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.5799923344610609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 810491.8192723399, 810491.8192723405, 197077.8147772468], 
processed observation next is [0.0, 0.21739130434782608, 0.5734597156398105, 0.84, 1.0, 1.0, 0.4939666680253746, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22513661646453886, 0.22513661646453903, 0.29414599220484594], 
reward next is 0.7059, 
noisyNet noise sample is [array([1.0821393], dtype=float32), -0.32375768]. 
=============================================
[2019-03-26 20:54:44,839] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4692189e-19 1.0000000e+00 2.5001952e-18 9.2652614e-16 2.1085932e-23], sum to 1.0000
[2019-03-26 20:54:44,853] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5034
[2019-03-26 20:54:44,857] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 81.5, 1.0, 2.0, 0.5315886663888735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742828.0030241485, 742828.0030241485, 188693.4436522572], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4570200.0000, 
sim time next is 4570800.0000, 
raw observation next is [28.0, 82.33333333333334, 1.0, 2.0, 0.5351957552558767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 747870.2284100746, 747870.2284100752, 189294.3949329485], 
processed observation next is [0.0, 0.9130434782608695, 0.5260663507109005, 0.8233333333333335, 1.0, 1.0, 0.4399948858504538, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20774173011390962, 0.20774173011390978, 0.28252894766111714], 
reward next is 0.7175, 
noisyNet noise sample is [array([0.07662498], dtype=float32), -1.1678042]. 
=============================================
[2019-03-26 20:54:48,692] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0938979e-18 1.0000000e+00 1.5225844e-17 1.7297519e-14 2.8262324e-22], sum to 1.0000
[2019-03-26 20:54:48,703] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2788
[2019-03-26 20:54:48,709] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.4921104465037565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 687644.3225295888, 687644.3225295888, 182368.9809710474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4825800.0000, 
sim time next is 4826400.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.4927319954189953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 688513.1175253581, 688513.1175253581, 182464.9332078178], 
processed observation next is [1.0, 0.8695652173913043, 0.5260663507109005, 0.74, 1.0, 1.0, 0.38883372942047634, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19125364375704393, 0.19125364375704393, 0.2723357212056982], 
reward next is 0.7277, 
noisyNet noise sample is [array([0.14391539], dtype=float32), 1.162186]. 
=============================================
[2019-03-26 20:54:51,615] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.9476437e-19 1.0000000e+00 1.8694979e-18 1.5790085e-14 9.4033476e-23], sum to 1.0000
[2019-03-26 20:54:51,622] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4873
[2019-03-26 20:54:51,632] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1657029.516379889 W.
[2019-03-26 20:54:51,636] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.5, 86.5, 1.0, 2.0, 0.5926579280099435, 1.0, 1.0, 0.5926579280099435, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1657029.516379889, 1657029.516379889, 331570.5197829991], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4606200.0000, 
sim time next is 4606800.0000, 
raw observation next is [29.66666666666667, 85.66666666666667, 1.0, 2.0, 0.5417827096919977, 1.0, 2.0, 0.5417827096919977, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1514685.498569606, 1514685.498569606, 313759.3328913067], 
processed observation next is [1.0, 0.30434782608695654, 0.6050552922590839, 0.8566666666666667, 1.0, 1.0, 0.4479309755325273, 1.0, 1.0, 0.4479309755325273, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4207459718248906, 0.4207459718248906, 0.4682975117780697], 
reward next is 0.5317, 
noisyNet noise sample is [array([1.4727695], dtype=float32), -0.98522353]. 
=============================================
[2019-03-26 20:54:56,640] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 20:54:56,642] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:54:56,642] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:54:56,643] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:54:56,644] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:54:56,646] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:54:56,648] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:54:56,651] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:54:56,652] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:54:56,653] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:54:56,650] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:54:56,677] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run40
[2019-03-26 20:54:56,695] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run40
[2019-03-26 20:54:56,715] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run40
[2019-03-26 20:54:56,731] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run40
[2019-03-26 20:54:56,748] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run40
[2019-03-26 20:55:11,536] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07589488], dtype=float32), 0.06134154]
[2019-03-26 20:55:11,537] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [20.6, 94.0, 1.0, 2.0, 0.3063962177478621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 488612.0705346086, 488612.070534608, 166252.2926654936]
[2019-03-26 20:55:11,539] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 20:55:11,541] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.7573775e-19 1.0000000e+00 7.9089236e-18 1.6560900e-15 1.4418583e-22], sampled 0.4616637784461133
[2019-03-26 20:55:49,760] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07589488], dtype=float32), 0.06134154]
[2019-03-26 20:55:49,761] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.02961140833333, 79.76100348000001, 1.0, 2.0, 0.5656710694624358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 790471.5766977441, 790471.5766977447, 194524.2443509772]
[2019-03-26 20:55:49,763] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:55:49,767] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.1480536e-20 1.0000000e+00 3.9429117e-19 4.4375916e-16 8.5998113e-24], sampled 0.8570819346350498
[2019-03-26 20:56:05,827] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07589488], dtype=float32), 0.06134154]
[2019-03-26 20:56:05,828] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 93.16666666666667, 1.0, 2.0, 0.8720731411064225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1218885.079781418, 1218885.079781418, 262372.7935790793]
[2019-03-26 20:56:05,829] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:56:05,833] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.4081589e-19 1.0000000e+00 1.2738610e-18 8.4691346e-16 2.3031414e-23], sampled 0.4009622821775939
[2019-03-26 20:56:15,325] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07589488], dtype=float32), 0.06134154]
[2019-03-26 20:56:15,327] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.6, 80.33333333333334, 1.0, 2.0, 0.6182201795144697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 863933.8300315007, 863933.8300315007, 204189.7184561313]
[2019-03-26 20:56:15,327] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:56:15,329] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.0051255e-20 1.0000000e+00 1.7852956e-19 3.1471798e-16 3.8877152e-24], sampled 0.5181715939648935
[2019-03-26 20:56:51,672] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.8893 2779265366.1414 933.0000
[2019-03-26 20:56:51,845] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.9106 3164254891.7810 1778.0000
[2019-03-26 20:56:51,893] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.0837 3007805556.0190 1766.0000
[2019-03-26 20:56:51,981] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.5590 2927409635.8428 1338.0000
[2019-03-26 20:56:51,991] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.4166 2842558242.3972 1131.0000
[2019-03-26 20:56:53,007] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 975000, evaluation results [975000.0, 7881.910573284552, 3164254891.78102, 1778.0, 8253.559004724644, 2927409635.8427854, 1338.0, 8659.88925272283, 2779265366.141443, 933.0, 7996.083716631031, 3007805556.0189595, 1766.0, 8497.416582222564, 2842558242.397172, 1131.0]
[2019-03-26 20:56:53,377] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5765639e-19 1.0000000e+00 6.4071136e-18 8.2921889e-16 5.3427220e-23], sum to 1.0000
[2019-03-26 20:56:53,391] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6407
[2019-03-26 20:56:53,396] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.00000000000001, 1.0, 2.0, 0.6504004919059506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 908923.556545309, 908923.5565453096, 210500.1410584522], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4770600.0000, 
sim time next is 4771200.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.6452299467925651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 901694.7408924326, 901694.7408924319, 209463.995573637], 
processed observation next is [1.0, 0.21739130434782608, 0.4786729857819906, 0.79, 1.0, 1.0, 0.5725662009548976, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2504707613590091, 0.25047076135900886, 0.31263282921438357], 
reward next is 0.6874, 
noisyNet noise sample is [array([-1.1273773], dtype=float32), -0.7695511]. 
=============================================
[2019-03-26 20:56:53,484] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.9681844e-11 9.9999988e-01 6.2456601e-10 1.2272162e-07 5.6923834e-13], sum to 1.0000
[2019-03-26 20:56:53,492] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7286
[2019-03-26 20:56:53,500] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1916042.581602974 W.
[2019-03-26 20:56:53,506] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.13333333333333, 65.33333333333333, 1.0, 2.0, 0.7292370626344379, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.975399280498166, 6.9112, 168.9125745541166, 1916042.581602974, 1870497.505438412, 392173.4509772705], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4966800.0000, 
sim time next is 4967400.0000, 
raw observation next is [30.16666666666667, 65.16666666666667, 1.0, 2.0, 0.7570342806752752, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.97413158129388, 6.9112, 168.9125296804085, 1954942.941756586, 1910297.224865408, 398597.7540567368], 
processed observation next is [1.0, 0.4782608695652174, 0.6287519747235389, 0.6516666666666667, 1.0, 1.0, 0.7072702176810545, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.006293158129387954, 0.0, 0.8294378492214887, 0.5430397060434962, 0.5306381180181688, 0.5949220209802042], 
reward next is 0.0904, 
noisyNet noise sample is [array([0.12073161], dtype=float32), 0.27293828]. 
=============================================
[2019-03-26 20:56:54,366] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.7387959e-10 9.9999928e-01 2.2533511e-09 7.5916904e-07 1.6432975e-12], sum to 1.0000
[2019-03-26 20:56:54,373] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1237
[2019-03-26 20:56:54,384] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1757499.476522023 W.
[2019-03-26 20:56:54,388] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.6285628589302136, 1.0, 2.0, 0.6285628589302136, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1757499.476522023, 1757499.476522023, 345042.0442080645], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4712400.0000, 
sim time next is 4713000.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.665462205573246, 1.0, 2.0, 0.665462205573246, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1860761.848449361, 1860761.848449361, 359689.5675666216], 
processed observation next is [1.0, 0.5652173913043478, 0.6682464454976303, 0.66, 1.0, 1.0, 0.5969424163533084, 1.0, 1.0, 0.5969424163533084, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5168782912359337, 0.5168782912359337, 0.5368501008457038], 
reward next is 0.4631, 
noisyNet noise sample is [array([-1.2687713], dtype=float32), 1.3870908]. 
=============================================
[2019-03-26 20:56:54,409] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[35.23207 ]
 [33.91602 ]
 [32.89676 ]
 [30.428926]
 [29.495804]], R is [[36.19873047]
 [36.32175446]
 [35.95853806]
 [35.59895325]
 [35.2429657 ]].
[2019-03-26 20:56:57,831] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.4468809e-13 1.0000000e+00 1.0990538e-12 5.6306687e-10 2.6410172e-16], sum to 1.0000
[2019-03-26 20:56:57,837] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3383
[2019-03-26 20:56:57,846] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2141342.025152147 W.
[2019-03-26 20:56:57,852] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.33333333333334, 68.66666666666667, 1.0, 2.0, 0.8902162328121819, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.988975054674748, 6.9112, 168.9124938349144, 2141342.025152147, 2086165.875690461, 431986.6997656179], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4785600.0000, 
sim time next is 4786200.0000, 
raw observation next is [30.5, 68.0, 1.0, 2.0, 0.5099463256797695, 1.0, 1.0, 0.5099463256797695, 1.0, 2.0, 0.8806616194755796, 6.9112, 6.9112, 170.5573041426782, 2139141.418509251, 2139141.418509251, 421178.9847887268], 
processed observation next is [1.0, 0.391304347826087, 0.6445497630331753, 0.68, 1.0, 1.0, 0.40957388636116804, 1.0, 0.5, 0.40957388636116804, 1.0, 1.0, 0.8544653896043655, 0.0, 0.0, 0.8375144448122397, 0.594205949585903, 0.594205949585903, 0.6286253504309355], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2804032], dtype=float32), 0.34808767]. 
=============================================
[2019-03-26 20:56:58,595] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3029884e-08 9.9999690e-01 3.2121259e-09 3.1301902e-06 3.7260282e-11], sum to 1.0000
[2019-03-26 20:56:58,603] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9421
[2019-03-26 20:56:58,613] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2049940.364235335 W.
[2019-03-26 20:56:58,617] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.4887021632903534, 1.0, 2.0, 0.4887021632903534, 1.0, 2.0, 0.8464974143791002, 6.9112, 6.9112, 170.5573041426782, 2049940.364235335, 2049940.364235335, 407031.6238271805], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4791600.0000, 
sim time next is 4792200.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.73148383836194, 1.0, 2.0, 0.73148383836194, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2045547.420800778, 2045547.420800778, 387893.0159902875], 
processed observation next is [1.0, 0.4782608695652174, 0.6682464454976303, 0.66, 1.0, 1.0, 0.6764865522433011, 1.0, 1.0, 0.6764865522433011, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.568207616889105, 0.568207616889105, 0.5789447999855037], 
reward next is 0.4211, 
noisyNet noise sample is [array([-0.4794026], dtype=float32), 1.8639405]. 
=============================================
[2019-03-26 20:57:03,387] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2798465e-19 1.0000000e+00 2.8879662e-19 6.4631388e-16 3.6257975e-23], sum to 1.0000
[2019-03-26 20:57:03,396] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5539
[2019-03-26 20:57:03,400] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.8657238211015147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1210005.662553092, 1210005.662553092, 260680.6476420635], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4945800.0000, 
sim time next is 4946400.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.698444760184059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 976095.4535506312, 976095.4535506305, 220507.5525312316], 
processed observation next is [1.0, 0.2608695652173913, 0.4312796208530806, 0.89, 1.0, 1.0, 0.6366804339566976, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.27113762598628643, 0.27113762598628627, 0.3291157500466143], 
reward next is 0.6709, 
noisyNet noise sample is [array([-0.48957855], dtype=float32), 0.5284404]. 
=============================================
[2019-03-26 20:57:13,493] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1894538e-19 1.0000000e+00 1.8257731e-18 4.9676301e-16 4.3610495e-24], sum to 1.0000
[2019-03-26 20:57:13,504] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0653
[2019-03-26 20:57:13,509] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 65.0, 1.0, 2.0, 0.508066914699337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709948.342770735, 709948.3427707345, 184870.064162707], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5048400.0000, 
sim time next is 5049000.0000, 
raw observation next is [30.5, 64.5, 1.0, 2.0, 0.5102633896284433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 713018.6215941472, 713018.6215941465, 185220.1944383688], 
processed observation next is [0.0, 0.43478260869565216, 0.6445497630331753, 0.645, 1.0, 1.0, 0.40995589111860636, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19806072822059645, 0.19806072822059625, 0.27644805140055045], 
reward next is 0.7236, 
noisyNet noise sample is [array([0.5558546], dtype=float32), -1.687391]. 
=============================================
[2019-03-26 20:57:13,521] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[72.708206]
 [72.73452 ]
 [72.744095]
 [72.75531 ]
 [72.77722 ]], R is [[72.67565155]
 [72.67297363]
 [72.67095947]
 [72.66893005]
 [72.66659546]].
[2019-03-26 20:57:17,677] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7461461e-19 1.0000000e+00 2.5193047e-18 4.3857918e-16 1.2438939e-22], sum to 1.0000
[2019-03-26 20:57:17,686] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3212
[2019-03-26 20:57:17,695] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4814376300807592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 672851.568051295, 672851.5680512957, 180754.442465774], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5115600.0000, 
sim time next is 5116200.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4811471539177737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 672445.3420356801, 672445.3420356801, 180710.5309765235], 
processed observation next is [0.0, 0.21739130434782608, 0.4312796208530806, 0.84, 1.0, 1.0, 0.3748760890575587, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18679037278768892, 0.18679037278768892, 0.2697172104127216], 
reward next is 0.7303, 
noisyNet noise sample is [array([-0.02470719], dtype=float32), -0.016369013]. 
=============================================
[2019-03-26 20:57:21,776] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3664127e-20 1.0000000e+00 4.6539362e-20 9.0203649e-17 7.0802717e-25], sum to 1.0000
[2019-03-26 20:57:21,783] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1838
[2019-03-26 20:57:21,788] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 79.0, 1.0, 2.0, 0.5060471560311154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 707125.0894830591, 707125.0894830597, 184548.2607312716], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5179200.0000, 
sim time next is 5179800.0000, 
raw observation next is [27.16666666666666, 79.0, 1.0, 2.0, 0.5006537658082684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 699586.1529506514, 699586.1529506508, 183697.824478063], 
processed observation next is [0.0, 0.9565217391304348, 0.4865718799368086, 0.79, 1.0, 1.0, 0.3983780310942992, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19432948693073648, 0.19432948693073632, 0.27417585742994477], 
reward next is 0.7258, 
noisyNet noise sample is [array([1.9712077], dtype=float32), 1.6685148]. 
=============================================
[2019-03-26 20:57:22,018] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.4522015e-09 9.9999392e-01 7.8650455e-09 6.0972034e-06 2.2117854e-11], sum to 1.0000
[2019-03-26 20:57:22,031] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5999
[2019-03-26 20:57:22,044] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2832216.513018818 W.
[2019-03-26 20:57:22,050] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.06666666666666, 52.5, 1.0, 2.0, 1.012465488733521, 1.0, 2.0, 1.012465488733521, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2832216.513018818, 2832216.513018818, 536568.9653328168], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5309400.0000, 
sim time next is 5310000.0000, 
raw observation next is [36.4, 51.0, 1.0, 2.0, 1.008226203770889, 1.0, 2.0, 1.008226203770889, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2820344.378254774, 2820344.378254774, 533981.2221668637], 
processed observation next is [1.0, 0.4782608695652174, 0.924170616113744, 0.51, 1.0, 1.0, 1.0099110888805891, 1.0, 1.0, 1.0099110888805891, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7834289939596595, 0.7834289939596595, 0.7969868987565131], 
reward next is 0.2030, 
noisyNet noise sample is [array([0.5724877], dtype=float32), 0.99173814]. 
=============================================
[2019-03-26 20:57:22,062] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[29.811827]
 [30.034449]
 [30.117075]
 [32.757328]
 [33.644188]], R is [[29.99594498]
 [29.89513588]
 [29.59618568]
 [29.3002243 ]
 [29.00722313]].
[2019-03-26 20:57:25,981] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.5300308e-19 1.0000000e+00 5.2814198e-17 3.5756656e-14 3.0403280e-22], sum to 1.0000
[2019-03-26 20:57:25,987] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4911
[2019-03-26 20:57:25,992] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.81666666666667, 78.83333333333334, 1.0, 2.0, 0.5452327300927857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 761900.6960647892, 761900.6960647892, 190986.6117764753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5255400.0000, 
sim time next is 5256000.0000, 
raw observation next is [28.8, 79.0, 1.0, 2.0, 0.5473916124312921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 764918.5746976368, 764918.5746976368, 191354.3720096959], 
processed observation next is [1.0, 0.8695652173913043, 0.5639810426540285, 0.79, 1.0, 1.0, 0.4546886896762555, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21247738186045464, 0.21247738186045464, 0.2856035403129789], 
reward next is 0.7144, 
noisyNet noise sample is [array([1.1411986], dtype=float32), -1.8633897]. 
=============================================
[2019-03-26 20:57:26,006] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[67.05404 ]
 [66.21162 ]
 [65.334984]
 [63.7592  ]
 [61.79158 ]], R is [[67.97387695]
 [68.00907898]
 [68.04467773]
 [68.0796814 ]
 [68.11398315]].
[2019-03-26 20:57:29,407] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.5487611e-10 9.9999952e-01 1.1415379e-09 5.2606936e-07 1.6391439e-12], sum to 1.0000
[2019-03-26 20:57:29,415] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6873
[2019-03-26 20:57:29,426] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2635976.034523997 W.
[2019-03-26 20:57:29,433] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.4, 60.0, 1.0, 2.0, 0.9423870472655778, 1.0, 2.0, 0.9423870472655778, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2635976.034523997, 2635976.034523997, 495152.1615209293], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5306400.0000, 
sim time next is 5307000.0000, 
raw observation next is [34.73333333333333, 58.5, 1.0, 2.0, 0.9367147163285413, 1.0, 2.0, 0.9367147163285413, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2620093.169288582, 2620093.169288582, 491925.8662141053], 
processed observation next is [1.0, 0.43478260869565216, 0.8451816745655606, 0.585, 1.0, 1.0, 0.923752670275351, 1.0, 1.0, 0.923752670275351, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7278036581357172, 0.7278036581357172, 0.7342177107673213], 
reward next is 0.2658, 
noisyNet noise sample is [array([-0.7554696], dtype=float32), -1.528562]. 
=============================================
[2019-03-26 20:57:29,447] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[32.824768]
 [33.48079 ]
 [34.577618]
 [38.071102]
 [39.212082]], R is [[32.69287872]
 [32.62691879]
 [32.30065155]
 [31.97764587]
 [31.89770317]].
[2019-03-26 20:57:33,200] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.4665632e-17 1.0000000e+00 5.3425984e-16 3.3547899e-13 4.6292161e-21], sum to 1.0000
[2019-03-26 20:57:33,209] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1671
[2019-03-26 20:57:33,219] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.68333333333334, 84.83333333333334, 1.0, 2.0, 0.9271896082850597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1295967.652439482, 1295967.652439482, 277531.9163570391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5379000.0000, 
sim time next is 5379600.0000, 
raw observation next is [29.86666666666667, 83.66666666666667, 1.0, 2.0, 1.00421400093909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1403698.707146698, 1403698.707146698, 300218.0830243566], 
processed observation next is [1.0, 0.2608695652173913, 0.6145339652448659, 0.8366666666666667, 1.0, 1.0, 1.0050771095651687, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3899163075407494, 0.3899163075407494, 0.4480866910811292], 
reward next is 0.5519, 
noisyNet noise sample is [array([0.32304898], dtype=float32), 1.2437047]. 
=============================================
[2019-03-26 20:57:35,006] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9446426e-05 9.6833313e-01 1.8082244e-05 3.1629201e-02 6.4193159e-08], sum to 1.0000
[2019-03-26 20:57:35,013] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7710
[2019-03-26 20:57:35,017] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [36.96666666666667, 58.00000000000001, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 8.757578370963664, 6.9112, 170.5573041426782, 4233506.814277962, 2910870.88128653, 541802.2791854424], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5404800.0000, 
sim time next is 5405400.0000, 
raw observation next is [36.95, 57.0, 1.0, 2.0, 1.04, 1.0, 2.0, 0.9323135439794149, 1.0, 1.0, 1.03, 7.363478861723502, 6.9112, 170.5573041426782, 3913697.883497291, 3589712.137316917, 672822.7083202585], 
processed observation next is [1.0, 0.5652173913043478, 0.9502369668246446, 0.57, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 0.9184500529872469, 1.0, 0.5, 1.0365853658536586, 0.045227886172350205, 0.0, 0.8375144448122397, 1.0871383009714697, 0.9971422603658103, 1.0042129974929233], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.522675], dtype=float32), -1.7724282]. 
=============================================
[2019-03-26 20:57:35,833] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2623643e-05 9.6017945e-01 1.3011032e-05 3.9784878e-02 4.4871747e-08], sum to 1.0000
[2019-03-26 20:57:35,841] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9909
[2019-03-26 20:57:35,847] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.5, 53.5, 1.0, 2.0, 0.83932350779629, 1.0, 2.0, 0.7402517934124074, 1.0, 1.0, 1.03, 7.005108720257568, 6.9112, 170.5573041426782, 3106451.435430883, 3039180.79914788, 568946.842622049], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5412600.0000, 
sim time next is 5413200.0000, 
raw observation next is [36.0, 53.33333333333333, 1.0, 2.0, 0.9859595428723203, 1.0, 2.0, 0.9859595428723203, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2757988.356558115, 2757988.356558115, 520565.2754785069], 
processed observation next is [1.0, 0.6521739130434783, 0.9052132701421801, 0.5333333333333333, 1.0, 1.0, 0.9830837865931571, 1.0, 1.0, 0.9830837865931571, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7661078768216987, 0.7661078768216987, 0.7769630977291149], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.75675035], dtype=float32), 0.9424458]. 
=============================================
[2019-03-26 20:57:38,484] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.0326431e-20 1.0000000e+00 4.2383184e-18 2.7788826e-15 1.7140387e-23], sum to 1.0000
[2019-03-26 20:57:38,488] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2056
[2019-03-26 20:57:38,493] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3640588e-19 1.0000000e+00 1.2787540e-18 8.8830622e-16 2.0782468e-24], sum to 1.0000
[2019-03-26 20:57:38,495] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.08333333333334, 80.16666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.961979922733856, 6.9112, 168.9124318028578, 1489804.51202544, 1453779.599035345, 311355.0240488254], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5469000.0000, 
sim time next is 5469600.0000, 
raw observation next is [30.26666666666667, 79.33333333333334, 1.0, 2.0, 0.9433032354491814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129151632572, 1318504.258749772, 1318504.258749772, 282131.7719618179], 
processed observation next is [1.0, 0.30434782608695654, 0.6334913112164299, 0.7933333333333334, 1.0, 1.0, 0.9316906451194956, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294397421187505, 0.3662511829860478, 0.3662511829860478, 0.4210921969579372], 
reward next is 0.5789, 
noisyNet noise sample is [array([-0.69866985], dtype=float32), 0.7515816]. 
=============================================
[2019-03-26 20:57:38,500] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1583
[2019-03-26 20:57:38,503] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.2, 66.5, 1.0, 2.0, 0.5188215423091408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 724981.4719438948, 724981.4719438948, 186597.6618802674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5736600.0000, 
sim time next is 5737200.0000, 
raw observation next is [30.36666666666667, 65.66666666666667, 1.0, 2.0, 0.5187050071485437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 724818.5745895375, 724818.5745895375, 186578.7846418523], 
processed observation next is [0.0, 0.391304347826087, 0.6382306477093209, 0.6566666666666667, 1.0, 1.0, 0.4201265146367996, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2013384929415382, 0.2013384929415382, 0.2784757979729139], 
reward next is 0.7215, 
noisyNet noise sample is [array([1.3217824], dtype=float32), -0.19459242]. 
=============================================
[2019-03-26 20:57:45,336] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.4683973e-09 9.9999642e-01 1.5789436e-09 3.5735914e-06 3.4662468e-12], sum to 1.0000
[2019-03-26 20:57:45,344] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9377
[2019-03-26 20:57:45,355] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2369730.995497529 W.
[2019-03-26 20:57:45,361] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.7, 60.33333333333334, 1.0, 2.0, 0.8472920335410258, 1.0, 2.0, 0.8472920335410258, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2369730.995497529, 2369730.995497529, 443551.818520732], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5570400.0000, 
sim time next is 5571000.0000, 
raw observation next is [32.8, 59.5, 1.0, 2.0, 0.5415839278569684, 1.0, 2.0, 0.5415839278569684, 1.0, 1.0, 0.940552178145734, 6.9112, 6.9112, 170.5573041426782, 2271987.745457427, 2271987.745457427, 445093.1337440636], 
processed observation next is [1.0, 0.4782608695652174, 0.7535545023696681, 0.595, 1.0, 1.0, 0.44769147934574505, 1.0, 1.0, 0.44769147934574505, 1.0, 0.5, 0.9275026562752854, 0.0, 0.0, 0.8375144448122397, 0.6311077070715075, 0.6311077070715075, 0.6643181100657666], 
reward next is 0.3357, 
noisyNet noise sample is [array([0.2438074], dtype=float32), 0.93082124]. 
=============================================
[2019-03-26 20:57:45,371] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[30.329443]
 [30.291403]
 [30.612011]
 [33.40089 ]
 [33.8848  ]], R is [[28.58640099]
 [28.63851929]
 [28.3521347 ]
 [28.06861305]
 [28.14788437]].
[2019-03-26 20:57:47,372] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.8308607e-20 1.0000000e+00 1.5160923e-18 1.6273017e-15 2.1857173e-23], sum to 1.0000
[2019-03-26 20:57:47,381] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7777
[2019-03-26 20:57:47,389] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.85, 90.0, 1.0, 2.0, 0.5414135592833833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 756561.938858219, 756561.9388582197, 190338.7116191654], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5610600.0000, 
sim time next is 5611200.0000, 
raw observation next is [26.76666666666667, 90.0, 1.0, 2.0, 0.5384643945517558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 752439.3674601886, 752439.367460188, 189841.7069438901], 
processed observation next is [1.0, 0.9565217391304348, 0.46761453396524505, 0.9, 1.0, 1.0, 0.4439330054840431, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20901093540560794, 0.20901093540560778, 0.2833458312595375], 
reward next is 0.7167, 
noisyNet noise sample is [array([0.8676477], dtype=float32), 0.51233345]. 
=============================================
[2019-03-26 20:57:47,962] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.11050815e-20 1.00000000e+00 1.34627587e-19 1.86294394e-15
 3.39774767e-25], sum to 1.0000
[2019-03-26 20:57:47,975] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5973
[2019-03-26 20:57:47,983] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.56666666666667, 87.0, 1.0, 2.0, 0.5164692057412986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 721693.2897524032, 721693.2897524037, 186216.2916922576], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5700000.0000, 
sim time next is 5700600.0000, 
raw observation next is [26.55, 87.0, 1.0, 2.0, 0.5155360072540192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 720388.8335553042, 720388.8335553035, 186065.6733481382], 
processed observation next is [0.0, 1.0, 0.4573459715639811, 0.87, 1.0, 1.0, 0.4163084424747219, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20010800932091782, 0.20010800932091763, 0.2777099602211018], 
reward next is 0.7223, 
noisyNet noise sample is [array([0.6415457], dtype=float32), 0.17649907]. 
=============================================
[2019-03-26 20:57:48,489] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 20:57:48,494] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 20:57:48,496] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 20:57:48,497] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 20:57:48,498] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:57:48,498] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 20:57:48,515] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:57:48,504] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:57:48,528] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:57:48,521] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 20:57:48,558] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 20:57:48,913] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run41
[2019-03-26 20:57:49,005] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run41
[2019-03-26 20:57:49,016] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run41
[2019-03-26 20:57:49,274] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run41
[2019-03-26 20:57:49,290] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run41
[2019-03-26 20:58:44,277] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07793801], dtype=float32), 0.06136985]
[2019-03-26 20:58:44,279] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.8430654, 62.22186902, 1.0, 2.0, 1.021662486822666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1428104.75195319, 1428104.751953189, 305596.5243679656]
[2019-03-26 20:58:44,281] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 20:58:44,283] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.3502437e-19 1.0000000e+00 2.4741138e-18 3.8315789e-15 7.0503352e-23], sampled 0.8424791482131408
[2019-03-26 20:59:37,709] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07793801], dtype=float32), 0.06136985]
[2019-03-26 20:59:37,709] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.36666666666667, 90.0, 1.0, 2.0, 0.3821606821028495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 573289.9408775953, 573289.9408775946, 172204.3705864997]
[2019-03-26 20:59:37,710] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 20:59:37,716] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1282851e-19 1.0000000e+00 1.2313148e-18 4.4661390e-16 1.1444036e-23], sampled 0.4817664702008573
[2019-03-26 20:59:42,948] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.5064 2779290623.4488 933.0000
[2019-03-26 20:59:43,348] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6749 3164129388.9823 1778.0000
[2019-03-26 20:59:43,943] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.1321 2842451957.6633 1131.0000
[2019-03-26 20:59:43,977] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.7395 3007855093.9336 1766.0000
[2019-03-26 20:59:44,069] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.8488 2927539683.3633 1338.0000
[2019-03-26 20:59:45,086] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1000000, evaluation results [1000000.0, 7882.674904135256, 3164129388.982254, 1778.0, 8252.848818411621, 2927539683.363314, 1338.0, 8658.506407847246, 2779290623.4488473, 933.0, 7996.739487620537, 3007855093.933641, 1766.0, 8496.132105234119, 2842451957.6632614, 1131.0]
[2019-03-26 20:59:47,960] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.4309854e-20 1.0000000e+00 1.9664790e-19 3.1363335e-16 1.8321934e-24], sum to 1.0000
[2019-03-26 20:59:47,968] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4520
[2019-03-26 20:59:47,972] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666666, 71.66666666666666, 1.0, 2.0, 0.5329130095245321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 744679.2539343757, 744679.2539343757, 188913.6345181573], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5683200.0000, 
sim time next is 5683800.0000, 
raw observation next is [29.43333333333333, 72.83333333333334, 1.0, 2.0, 0.5322740261263339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 743786.0419720585, 743786.0419720579, 188807.3144585471], 
processed observation next is [0.0, 0.782608695652174, 0.5939968404423379, 0.7283333333333334, 1.0, 1.0, 0.4364747302726914, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20660723388112737, 0.2066072338811272, 0.2818019618784285], 
reward next is 0.7182, 
noisyNet noise sample is [array([1.2199154], dtype=float32), -1.4340261]. 
=============================================
[2019-03-26 20:59:51,604] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.5432248e-21 1.0000000e+00 7.6346827e-19 4.8431422e-16 7.8015646e-24], sum to 1.0000
[2019-03-26 20:59:51,614] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4360
[2019-03-26 20:59:51,622] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.0, 53.0, 1.0, 2.0, 0.5359444086305802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 748916.7481963548, 748916.7481963541, 189420.552626323], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5756400.0000, 
sim time next is 5757000.0000, 
raw observation next is [33.81666666666667, 53.83333333333334, 1.0, 2.0, 0.5579740119941156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779711.722389029, 779711.722389029, 193177.2254882831], 
processed observation next is [0.0, 0.6521739130434783, 0.8017377567140602, 0.5383333333333334, 1.0, 1.0, 0.4674385686676091, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21658658955250806, 0.21658658955250806, 0.28832421714669115], 
reward next is 0.7117, 
noisyNet noise sample is [array([0.9185535], dtype=float32), 0.802647]. 
=============================================
[2019-03-26 20:59:51,640] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[71.157646]
 [71.13721 ]
 [71.13244 ]
 [71.12805 ]
 [71.13153 ]], R is [[71.18560791]
 [71.19104004]
 [71.19773865]
 [71.20547485]
 [71.21438599]].
[2019-03-26 20:59:57,097] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2660420e-18 1.0000000e+00 9.2197303e-19 2.1286772e-15 9.8179593e-24], sum to 1.0000
[2019-03-26 20:59:57,105] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0912
[2019-03-26 20:59:57,108] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 92.0, 1.0, 2.0, 0.5585769165991905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780554.5295859132, 780554.5295859132, 193282.6554188319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5958000.0000, 
sim time next is 5958600.0000, 
raw observation next is [27.15, 91.83333333333334, 1.0, 2.0, 0.5562878331980117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777354.5974442194, 777354.5974442194, 192885.0075366251], 
processed observation next is [1.0, 1.0, 0.485781990521327, 0.9183333333333334, 1.0, 1.0, 0.46540702794941163, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21593183262339427, 0.21593183262339427, 0.28788807095018676], 
reward next is 0.7121, 
noisyNet noise sample is [array([1.2558146], dtype=float32), -0.31160393]. 
=============================================
[2019-03-26 20:59:57,150] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4533846e-10 9.9999809e-01 1.6264253e-09 1.9566839e-06 9.0231875e-13], sum to 1.0000
[2019-03-26 20:59:57,156] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3242
[2019-03-26 20:59:57,164] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1955378.578880651 W.
[2019-03-26 20:59:57,169] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.6, 63.0, 1.0, 2.0, 0.6992690327235931, 1.0, 1.0, 0.6992690327235931, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1955378.578880651, 1955378.578880651, 373818.2353881682], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5835600.0000, 
sim time next is 5836200.0000, 
raw observation next is [32.65, 62.66666666666666, 1.0, 2.0, 0.5343426919900258, 1.0, 2.0, 0.5343426919900258, 1.0, 1.0, 0.9279765461581492, 6.9112, 6.9112, 170.5573041426782, 2241582.941045094, 2241582.941045094, 439707.474372201], 
processed observation next is [1.0, 0.5652173913043478, 0.7464454976303317, 0.6266666666666666, 1.0, 1.0, 0.4389670987831636, 1.0, 1.0, 0.4389670987831636, 1.0, 0.5, 0.9121665197050598, 0.0, 0.0, 0.8375144448122397, 0.6226619280680816, 0.6226619280680816, 0.6562798124958225], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2662417], dtype=float32), -1.1899747]. 
=============================================
[2019-03-26 20:59:58,013] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.7831686e-09 9.9987519e-01 3.7210850e-08 1.2476741e-04 5.2334890e-11], sum to 1.0000
[2019-03-26 20:59:58,024] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8735
[2019-03-26 20:59:58,031] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2366198.110659766 W.
[2019-03-26 20:59:58,035] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.95, 76.33333333333334, 1.0, 2.0, 0.5640200354794015, 1.0, 1.0, 0.5640200354794015, 1.0, 2.0, 0.9795162773517294, 6.9112, 6.9112, 170.5573041426782, 2366198.110659766, 2366198.110659766, 462240.0201006327], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5929800.0000, 
sim time next is 5930400.0000, 
raw observation next is [30.0, 76.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.455131074472712, 6.9112, 168.9099559417075, 2669910.247638114, 2284033.677575166, 474891.4102066854], 
processed observation next is [1.0, 0.6521739130434783, 0.6208530805687204, 0.7666666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.054393107447271216, 0.0, 0.8294252109862039, 0.7416417354550316, 0.634453799326435, 0.7087931495622171], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.16121411], dtype=float32), 1.1361517]. 
=============================================
[2019-03-26 21:00:02,717] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.7111790e-15 1.0000000e+00 1.8028657e-13 5.1826043e-11 7.8873770e-19], sum to 1.0000
[2019-03-26 21:00:02,726] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9494
[2019-03-26 21:00:02,730] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.25, 80.5, 1.0, 2.0, 0.5296007756582151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 740049.2092168102, 740049.2092168102, 188364.34514583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6201000.0000, 
sim time next is 6201600.0000, 
raw observation next is [28.16666666666666, 81.0, 1.0, 2.0, 0.5294392445132065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 739823.411539051, 739823.411539051, 188337.6208923114], 
processed observation next is [1.0, 0.782608695652174, 0.5339652448657185, 0.81, 1.0, 1.0, 0.43305933073880293, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20550650320529193, 0.20550650320529193, 0.28110092670494236], 
reward next is 0.7189, 
noisyNet noise sample is [array([-0.45639235], dtype=float32), 2.4901843]. 
=============================================
[2019-03-26 21:00:04,240] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6269205e-18 1.0000000e+00 1.2879634e-17 2.3402023e-14 2.4031153e-23], sum to 1.0000
[2019-03-26 21:00:04,248] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3828
[2019-03-26 21:00:04,252] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 83.0, 1.0, 2.0, 0.5555106039364517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 776268.1032273677, 776268.1032273677, 192750.558847794], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5947200.0000, 
sim time next is 5947800.0000, 
raw observation next is [28.43333333333333, 83.5, 1.0, 2.0, 0.5542947447851586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 774568.4474511578, 774568.4474511571, 192540.3891611593], 
processed observation next is [1.0, 0.8695652173913043, 0.546603475513428, 0.835, 1.0, 1.0, 0.46300571660862483, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21515790206976607, 0.21515790206976587, 0.2873737151659094], 
reward next is 0.7126, 
noisyNet noise sample is [array([1.241351], dtype=float32), 1.9625657]. 
=============================================
[2019-03-26 21:00:05,131] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8510434e-20 1.0000000e+00 1.1967775e-18 1.4920538e-16 3.5496492e-24], sum to 1.0000
[2019-03-26 21:00:05,142] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9070
[2019-03-26 21:00:05,150] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 92.66666666666667, 1.0, 2.0, 0.6213281476404795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 868278.8456684981, 868278.8456684987, 204779.9012124394], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5980800.0000, 
sim time next is 5981400.0000, 
raw observation next is [26.35, 92.0, 1.0, 2.0, 0.6178315982302748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 863390.5851196287, 863390.585119628, 204108.6099141939], 
processed observation next is [1.0, 0.21739130434782608, 0.4478672985781992, 0.92, 1.0, 1.0, 0.5395561424461142, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23983071808878575, 0.23983071808878556, 0.3046397162898416], 
reward next is 0.6954, 
noisyNet noise sample is [array([0.36789906], dtype=float32), -0.05980147]. 
=============================================
[2019-03-26 21:00:09,948] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1349160e-18 1.0000000e+00 1.5032271e-18 5.6211902e-15 7.9749444e-24], sum to 1.0000
[2019-03-26 21:00:09,961] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1949
[2019-03-26 21:00:09,968] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.18333333333333, 93.0, 1.0, 2.0, 0.7186882424336557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1004399.64630749, 1004399.64630749, 224930.2274513614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6059400.0000, 
sim time next is 6060000.0000, 
raw observation next is [26.16666666666667, 93.0, 1.0, 2.0, 0.6952603385547894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 971643.1022969646, 971643.1022969646, 219824.931110276], 
processed observation next is [1.0, 0.13043478260869565, 0.4391785150078992, 0.93, 1.0, 1.0, 0.6328437813913125, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.26990086174915684, 0.26990086174915684, 0.32809691210488956], 
reward next is 0.6719, 
noisyNet noise sample is [array([-0.6648938], dtype=float32), 1.9924638]. 
=============================================
[2019-03-26 21:00:09,980] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[68.728714]
 [68.463715]
 [68.21977 ]
 [68.0018  ]
 [67.94719 ]], R is [[68.90776825]
 [68.88297272]
 [68.84473419]
 [68.80590057]
 [68.75110626]].
[2019-03-26 21:00:14,324] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7348622e-19 1.0000000e+00 1.7388925e-17 4.0934731e-14 1.4944467e-23], sum to 1.0000
[2019-03-26 21:00:14,334] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4226
[2019-03-26 21:00:14,339] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.36666666666667, 85.0, 1.0, 2.0, 0.5255001495933351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 734317.1292335063, 734317.1292335069, 187688.1301361267], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6119400.0000, 
sim time next is 6120000.0000, 
raw observation next is [27.2, 86.0, 1.0, 2.0, 0.5259561978209946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 734954.6169261284, 734954.616926129, 187762.9799009111], 
processed observation next is [1.0, 0.8695652173913043, 0.4881516587677725, 0.86, 1.0, 1.0, 0.42886288894095725, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20415406025725788, 0.20415406025725805, 0.2802432535834494], 
reward next is 0.7198, 
noisyNet noise sample is [array([-0.13250867], dtype=float32), -1.4493442]. 
=============================================
[2019-03-26 21:00:14,359] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[66.3176  ]
 [65.39112 ]
 [63.774216]
 [62.45028 ]
 [60.96023 ]], R is [[67.42297363]
 [67.46861267]
 [67.51383972]
 [67.55853271]
 [67.60275269]].
[2019-03-26 21:00:15,368] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.3074065e-18 1.0000000e+00 6.5257642e-17 2.1798278e-14 6.3718317e-22], sum to 1.0000
[2019-03-26 21:00:15,377] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0312
[2019-03-26 21:00:15,383] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 92.0, 1.0, 2.0, 0.7233181724426507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1010873.264611454, 1010873.264611454, 225959.1443215516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6147000.0000, 
sim time next is 6147600.0000, 
raw observation next is [26.6, 92.0, 1.0, 2.0, 0.7153428128753893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 999722.0550100794, 999722.0550100801, 224192.0248112427], 
processed observation next is [1.0, 0.13043478260869565, 0.4597156398104266, 0.92, 1.0, 1.0, 0.6570395335848063, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.27770057083613314, 0.27770057083613336, 0.33461496240483984], 
reward next is 0.6654, 
noisyNet noise sample is [array([-0.5084024], dtype=float32), 0.8431848]. 
=============================================
[2019-03-26 21:00:33,391] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.3532893e-09 9.9996996e-01 5.0349222e-08 2.9997465e-05 3.3429655e-11], sum to 1.0000
[2019-03-26 21:00:33,397] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8788
[2019-03-26 21:00:33,412] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1810220.773710351 W.
[2019-03-26 21:00:33,417] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.66666666666667, 66.33333333333333, 1.0, 2.0, 0.6474025123708151, 1.0, 2.0, 0.6474025123708151, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1810220.773710351, 1810220.773710351, 352412.4303089677], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6712800.0000, 
sim time next is 6713400.0000, 
raw observation next is [29.63333333333333, 66.66666666666667, 1.0, 2.0, 0.4364545746800534, 1.0, 2.0, 0.4364545746800534, 1.0, 1.0, 0.7419720427454726, 6.9112, 6.9112, 170.5573041426782, 1830592.15937285, 1830592.15937285, 371474.1166860805], 
processed observation next is [1.0, 0.6956521739130435, 0.6034755134281199, 0.6666666666666667, 1.0, 1.0, 0.32102960804825714, 1.0, 1.0, 0.32102960804825714, 1.0, 0.5, 0.6853317594456982, 0.0, 0.0, 0.8375144448122397, 0.5084978220480139, 0.5084978220480139, 0.5544389801284784], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.00631179], dtype=float32), 0.6477578]. 
=============================================
[2019-03-26 21:00:34,337] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6023803e-19 1.0000000e+00 2.9531510e-18 1.1498212e-15 2.7621412e-23], sum to 1.0000
[2019-03-26 21:00:34,346] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3691
[2019-03-26 21:00:34,349] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.96666666666667, 69.66666666666667, 1.0, 2.0, 0.3764670437434964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 570601.8994316269, 570601.8994316269, 172149.2990639542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6730800.0000, 
sim time next is 6731400.0000, 
raw observation next is [25.83333333333334, 69.83333333333333, 1.0, 2.0, 0.3731243859180476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 567287.1956160339, 567287.1956160332, 171911.6274366681], 
processed observation next is [1.0, 0.9130434782608695, 0.42338072669826254, 0.6983333333333333, 1.0, 1.0, 0.2447281758048766, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1575797765600094, 0.1575797765600092, 0.25658451856219117], 
reward next is 0.7434, 
noisyNet noise sample is [array([0.00737164], dtype=float32), 0.13370189]. 
=============================================
[2019-03-26 21:00:40,844] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-26 21:00:40,846] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:00:40,846] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:00:40,848] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:00:40,849] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:00:40,850] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:00:40,851] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:00:40,852] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:00:40,852] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:00:40,853] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:00:40,853] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:00:40,869] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run42
[2019-03-26 21:00:40,891] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run42
[2019-03-26 21:00:40,892] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run42
[2019-03-26 21:00:40,893] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run42
[2019-03-26 21:00:40,966] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run42
[2019-03-26 21:01:09,398] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07977366], dtype=float32), 0.061971568]
[2019-03-26 21:01:09,399] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.21486066, 92.10327534, 1.0, 2.0, 0.7641569495440313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1067976.194540338, 1067976.194540338, 235307.4832399855]
[2019-03-26 21:01:09,399] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:01:09,403] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.6761916e-20 1.0000000e+00 3.5158997e-19 2.0953384e-16 1.5789372e-24], sampled 0.6765357857344115
[2019-03-26 21:01:28,422] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07977366], dtype=float32), 0.061971568]
[2019-03-26 21:01:28,425] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.66666666666666, 60.66666666666666, 1.0, 2.0, 0.5638425186395655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 787915.4029247942, 787915.4029247942, 194203.0972062044]
[2019-03-26 21:01:28,426] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:01:28,427] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.9015105e-20 1.0000000e+00 5.0033958e-19 8.9117088e-16 1.4045823e-24], sampled 0.141079926713367
[2019-03-26 21:01:33,571] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07977366], dtype=float32), 0.061971568]
[2019-03-26 21:01:33,572] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.28333333333333, 72.83333333333334, 1.0, 2.0, 0.5673097258708658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 792762.2978735439, 792762.2978735439, 194813.3942664599]
[2019-03-26 21:01:33,574] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:01:33,576] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2083503e-20 1.0000000e+00 1.7153570e-19 2.0298337e-16 1.0373466e-24], sampled 0.8072893700809717
[2019-03-26 21:02:36,076] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5374 3007672604.7148 1766.0000
[2019-03-26 21:02:36,207] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.9141 3164157795.0059 1778.0000
[2019-03-26 21:02:36,305] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.4067 2927264152.9822 1338.0000
[2019-03-26 21:02:36,306] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8494.6508 2842558823.8127 1131.0000
[2019-03-26 21:02:36,340] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.4941 2779356785.0158 933.0000
[2019-03-26 21:02:37,356] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1025000, evaluation results [1025000.0, 7881.914089799695, 3164157795.0059204, 1778.0, 8254.406660643592, 2927264152.9821725, 1338.0, 8660.494053451539, 2779356785.015815, 933.0, 7997.537410079355, 3007672604.7147675, 1766.0, 8494.650760429256, 2842558823.8126726, 1131.0]
[2019-03-26 21:02:48,775] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7441064e-18 1.0000000e+00 2.0352524e-17 1.4060094e-15 3.2354231e-23], sum to 1.0000
[2019-03-26 21:02:48,784] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5363
[2019-03-26 21:02:48,789] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 86.0, 1.0, 2.0, 0.3128036487553827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 499859.6428419989, 499859.6428419989, 167086.998874023], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6757200.0000, 
sim time next is 6757800.0000, 
raw observation next is [21.63333333333333, 85.5, 1.0, 2.0, 0.377430861065963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 602659.979297497, 602659.979297497, 175405.2198176705], 
processed observation next is [1.0, 0.21739130434782608, 0.2243285939968403, 0.855, 1.0, 1.0, 0.2499167000794735, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16740554980486028, 0.16740554980486028, 0.26179883554876193], 
reward next is 0.7382, 
noisyNet noise sample is [array([-0.23722439], dtype=float32), 0.20180506]. 
=============================================
[2019-03-26 21:02:53,301] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4184309e-20 1.0000000e+00 2.8263459e-18 1.5453189e-15 1.9623759e-23], sum to 1.0000
[2019-03-26 21:02:53,311] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0375
[2019-03-26 21:02:53,317] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.86666666666667, 75.66666666666667, 1.0, 2.0, 0.3368873658917485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 527164.054859657, 527164.0548596563, 169002.6861892093], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6826800.0000, 
sim time next is 6827400.0000, 
raw observation next is [23.8, 76.0, 1.0, 2.0, 0.3365327607482251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 526828.3924248168, 526828.3924248168, 168981.12464931], 
processed observation next is [0.0, 0.0, 0.3270142180094788, 0.76, 1.0, 1.0, 0.20064188041954828, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14634122011800468, 0.14634122011800468, 0.2522106338049403], 
reward next is 0.7478, 
noisyNet noise sample is [array([0.9807702], dtype=float32), -0.07956239]. 
=============================================
[2019-03-26 21:02:56,997] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.4875485e-20 1.0000000e+00 2.6181926e-19 2.9455822e-16 7.3572955e-24], sum to 1.0000
[2019-03-26 21:02:57,007] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7149
[2019-03-26 21:02:57,015] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333334, 63.16666666666666, 1.0, 2.0, 0.3688237051575706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 562188.2769463515, 562188.2769463509, 171512.6995161288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6897000.0000, 
sim time next is 6897600.0000, 
raw observation next is [26.8, 64.0, 1.0, 2.0, 0.3693110611153672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 562659.6548752574, 562659.6548752574, 171545.3113086715], 
processed observation next is [0.0, 0.8695652173913043, 0.4691943127962086, 0.64, 1.0, 1.0, 0.2401338085727316, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15629434857646038, 0.15629434857646038, 0.256037778072644], 
reward next is 0.7440, 
noisyNet noise sample is [array([1.4030846], dtype=float32), -0.24165659]. 
=============================================
[2019-03-26 21:02:57,025] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9299883e-20 1.0000000e+00 3.3759236e-19 2.6524061e-16 1.8853482e-24], sum to 1.0000
[2019-03-26 21:02:57,032] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0819
[2019-03-26 21:02:57,035] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.35, 58.5, 1.0, 2.0, 0.3891835891993862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 584786.8259990885, 584786.8259990878, 173265.0750511373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6985800.0000, 
sim time next is 6986400.0000, 
raw observation next is [28.23333333333333, 59.66666666666666, 1.0, 2.0, 0.3922925721318365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 587481.8435461828, 587481.8435461835, 173451.3244544136], 
processed observation next is [0.0, 0.8695652173913043, 0.537124802527646, 0.5966666666666666, 1.0, 1.0, 0.2678223760624536, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1631894009850508, 0.163189400985051, 0.25888257381255764], 
reward next is 0.7411, 
noisyNet noise sample is [array([0.16923036], dtype=float32), -0.27288884]. 
=============================================
[2019-03-26 21:03:05,155] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8322875e-19 1.0000000e+00 1.2797844e-17 1.9912730e-15 7.6617090e-24], sum to 1.0000
[2019-03-26 21:03:05,163] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1228
[2019-03-26 21:03:05,168] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 68.0, 1.0, 2.0, 0.390849191565308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 584974.975979596, 584974.9759795954, 173212.8141027009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7323600.0000, 
sim time next is 7324200.0000, 
raw observation next is [26.6, 68.5, 1.0, 2.0, 0.3917519939357751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 586588.1526171557, 586588.1526171563, 173367.3444991322], 
processed observation next is [1.0, 0.782608695652174, 0.4597156398104266, 0.685, 1.0, 1.0, 0.2671710770310543, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16294115350476546, 0.16294115350476562, 0.2587572305957197], 
reward next is 0.7412, 
noisyNet noise sample is [array([0.7196776], dtype=float32), -1.3186969]. 
=============================================
[2019-03-26 21:03:11,324] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0948381e-13 1.0000000e+00 5.9800922e-13 1.5376028e-09 7.0461892e-17], sum to 1.0000
[2019-03-26 21:03:11,329] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2026
[2019-03-26 21:03:11,335] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.8504309034423084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1188619.079260518, 1188619.079260517, 256662.4954915921], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7218000.0000, 
sim time next is 7218600.0000, 
raw observation next is [24.15, 98.16666666666667, 1.0, 2.0, 0.8762086344217833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1224668.537556989, 1224668.537556989, 263473.1249735946], 
processed observation next is [1.0, 0.5652173913043478, 0.34360189573459715, 0.9816666666666667, 1.0, 1.0, 0.8508537764117872, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.34018570487694133, 0.34018570487694133, 0.39324347010984273], 
reward next is 0.6068, 
noisyNet noise sample is [array([0.9686585], dtype=float32), -0.74338067]. 
=============================================
[2019-03-26 21:03:19,301] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7004169e-19 1.0000000e+00 7.7006445e-18 4.3485414e-16 6.8728386e-24], sum to 1.0000
[2019-03-26 21:03:19,314] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6677
[2019-03-26 21:03:19,321] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 87.66666666666667, 1.0, 2.0, 0.32384633556991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 510724.8929599915, 510724.8929599921, 167809.770943136], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7281600.0000, 
sim time next is 7282200.0000, 
raw observation next is [21.95, 87.33333333333333, 1.0, 2.0, 0.3237276441616025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 510450.7968378516, 510450.7968378516, 167787.0528761033], 
processed observation next is [1.0, 0.2608695652173913, 0.2393364928909953, 0.8733333333333333, 1.0, 1.0, 0.18521402911036444, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14179188801051432, 0.14179188801051432, 0.25042843712851237], 
reward next is 0.7496, 
noisyNet noise sample is [array([0.25160453], dtype=float32), -0.84819674]. 
=============================================
[2019-03-26 21:03:21,205] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.8891332e-19 1.0000000e+00 4.1327060e-18 9.6293871e-16 3.9705685e-24], sum to 1.0000
[2019-03-26 21:03:21,215] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0880
[2019-03-26 21:03:21,223] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666666, 67.83333333333333, 1.0, 2.0, 0.9211127486650742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1402809.416674592, 1402809.416674592, 292211.7475226044], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7296600.0000, 
sim time next is 7297200.0000, 
raw observation next is [26.4, 67.0, 1.0, 2.0, 0.9418648725348665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1430643.056450117, 1430643.056450116, 298180.3931317443], 
processed observation next is [1.0, 0.4782608695652174, 0.45023696682464454, 0.67, 1.0, 1.0, 0.9299576777528512, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.39740084901392136, 0.3974008490139211, 0.44504536288320046], 
reward next is 0.5550, 
noisyNet noise sample is [array([0.25845233], dtype=float32), -0.95033646]. 
=============================================
[2019-03-26 21:03:29,000] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6130471e-19 1.0000000e+00 4.0946655e-19 2.2662849e-15 7.7571107e-24], sum to 1.0000
[2019-03-26 21:03:29,010] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9158
[2019-03-26 21:03:29,018] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 92.0, 1.0, 2.0, 0.3159488283097837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 498901.1413231689, 498901.1413231689, 166928.5734579208], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7434000.0000, 
sim time next is 7434600.0000, 
raw observation next is [21.31666666666667, 91.83333333333334, 1.0, 2.0, 0.315471054679055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 498204.7504799939, 498204.7504799945, 166877.7633131374], 
processed observation next is [0.0, 0.043478260869565216, 0.20932069510268583, 0.9183333333333334, 1.0, 1.0, 0.17526633093862048, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13839020846666497, 0.13839020846666514, 0.24907128852707075], 
reward next is 0.7509, 
noisyNet noise sample is [array([-2.0107017], dtype=float32), 0.00035211712]. 
=============================================
[2019-03-26 21:03:32,693] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 21:03:32,695] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:03:32,696] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:03:32,697] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:03:32,699] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:03:32,698] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:03:32,700] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:03:32,701] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:03:32,703] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:03:32,702] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:03:32,704] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:03:32,729] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run43
[2019-03-26 21:03:32,730] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run43
[2019-03-26 21:03:32,730] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run43
[2019-03-26 21:03:32,790] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run43
[2019-03-26 21:03:32,816] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run43
[2019-03-26 21:03:34,411] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08290202], dtype=float32), 0.06448355]
[2019-03-26 21:03:34,412] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.88256137, 68.52183625, 1.0, 2.0, 0.4276134407203553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 655866.4450399788, 655866.4450399794, 180162.568699893]
[2019-03-26 21:03:34,412] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:03:34,415] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.0565868e-20 1.0000000e+00 3.5152963e-19 9.1040914e-17 1.4112421e-24], sampled 0.3439375480550202
[2019-03-26 21:03:34,599] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08290202], dtype=float32), 0.06448355]
[2019-03-26 21:03:34,600] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.6, 66.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.085176566325606, 6.9112, 168.911710699916, 1577263.509058596, 1453839.455411623, 311347.6927159446]
[2019-03-26 21:03:34,601] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:03:34,602] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.1919768e-21 1.0000000e+00 6.5636782e-20 5.1076729e-17 2.0986646e-25], sampled 0.38955668753727835
[2019-03-26 21:03:39,156] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08290202], dtype=float32), 0.06448355]
[2019-03-26 21:03:39,157] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.37765947, 86.32927121, 1.0, 2.0, 0.2815516588773362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 456574.4995621733, 456574.4995621739, 164020.9030201123]
[2019-03-26 21:03:39,158] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:03:39,162] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.3563015e-20 1.0000000e+00 6.1980095e-19 1.7052144e-16 2.6412081e-24], sampled 0.24209255342247282
[2019-03-26 21:03:48,212] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08290202], dtype=float32), 0.06448355]
[2019-03-26 21:03:48,214] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.46958, 92.498054105, 1.0, 2.0, 0.3990886911678943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 622772.9343399663, 622772.9343399663, 177160.1283730322]
[2019-03-26 21:03:48,216] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:03:48,219] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.3903147e-20 1.0000000e+00 2.1975516e-19 6.5348321e-17 7.4326958e-25], sampled 0.7113315416443193
[2019-03-26 21:04:13,130] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08290202], dtype=float32), 0.06448355]
[2019-03-26 21:04:13,132] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.46666666666667, 87.33333333333334, 1.0, 2.0, 0.4894697256452026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 685692.8063845931, 685692.8063845931, 182186.0497550252]
[2019-03-26 21:04:13,134] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:04:13,136] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.9726807e-21 1.0000000e+00 5.2157812e-20 4.5499344e-17 2.4743409e-25], sampled 0.22267362294357462
[2019-03-26 21:04:28,409] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08290202], dtype=float32), 0.06448355]
[2019-03-26 21:04:28,411] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.36379884, 81.3343327, 1.0, 2.0, 0.5850208489055833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 817521.4609198094, 817521.4609198101, 197982.9247081685]
[2019-03-26 21:04:28,411] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:04:28,415] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.2866012e-20 1.0000000e+00 2.4552334e-19 6.5515054e-17 8.1206066e-25], sampled 0.7054662135710024
[2019-03-26 21:04:53,411] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08290202], dtype=float32), 0.06448355]
[2019-03-26 21:04:53,413] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.45, 73.5, 1.0, 2.0, 0.7086100181887341, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.003939077342926, 6.9112, 168.912330510543, 1887177.327660647, 1821385.278190404, 386598.1264597398]
[2019-03-26 21:04:53,414] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:04:53,418] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.9012886e-12 1.0000000e+00 1.7190586e-11 1.6275743e-08 1.9063950e-15], sampled 0.07296844902644606
[2019-03-26 21:04:53,419] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1887177.327660647 W.
[2019-03-26 21:04:53,436] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08290202], dtype=float32), 0.06448355]
[2019-03-26 21:04:53,437] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [32.88999861833334, 52.29752701166667, 1.0, 2.0, 0.6771958170424494, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.977291405980583, 6.9112, 168.9124973594479, 1843218.15113702, 1796330.760496675, 380786.5245506929]
[2019-03-26 21:04:53,439] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:04:53,440] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.5274883e-13 1.0000000e+00 4.3844542e-12 1.7380648e-08 5.1043058e-16], sampled 0.7206344153681763
[2019-03-26 21:04:53,441] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1843218.15113702 W.
[2019-03-26 21:05:27,342] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08290202], dtype=float32), 0.06448355]
[2019-03-26 21:05:27,345] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.83641672, 63.53417991, 1.0, 2.0, 0.8331868611146985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1231820.102933269, 1231820.102933269, 261608.0963943004]
[2019-03-26 21:05:27,347] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:05:27,349] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.3507741e-20 1.0000000e+00 1.2287201e-18 5.9813036e-16 3.7630322e-24], sampled 0.433569277019753
[2019-03-26 21:05:27,859] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5144 2842492707.2201 1131.0000
[2019-03-26 21:05:27,889] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164071917.9177 1778.0000
[2019-03-26 21:05:28,112] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1249 2927277438.0038 1338.0000
[2019-03-26 21:05:28,172] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.8169 3007730089.1005 1766.0000
[2019-03-26 21:05:28,296] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8657.7539 2779338961.2007 933.0000
[2019-03-26 21:05:29,311] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1050000, evaluation results [1050000.0, 7884.168443086554, 3164071917.9176674, 1778.0, 8255.124881931173, 2927277438.00382, 1338.0, 8657.75392792439, 2779338961.200734, 933.0, 7996.8169432730165, 3007730089.1004972, 1766.0, 8497.514395919725, 2842492707.2200756, 1131.0]
[2019-03-26 21:05:30,153] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0856065e-21 1.0000000e+00 9.7926934e-20 1.1526219e-17 2.2843008e-25], sum to 1.0000
[2019-03-26 21:05:30,165] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8871
[2019-03-26 21:05:30,169] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.13333333333333, 92.0, 1.0, 2.0, 0.4824504968940798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 674141.8307629039, 674141.8307629032, 180891.9996816422], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7598400.0000, 
sim time next is 7599000.0000, 
raw observation next is [25.06666666666667, 92.5, 1.0, 2.0, 0.4824780337637555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 674180.3210257734, 674180.3210257734, 180896.1693598697], 
processed observation next is [0.0, 0.9565217391304348, 0.38704581358609813, 0.925, 1.0, 1.0, 0.3764795587515127, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18727231139604816, 0.18727231139604816, 0.2699942826266712], 
reward next is 0.7300, 
noisyNet noise sample is [array([-0.32039145], dtype=float32), -0.2470293]. 
=============================================
[2019-03-26 21:05:30,187] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[77.70188]
 [77.6506 ]
 [77.59969]
 [77.54394]
 [77.47622]], R is [[77.70192719]
 [77.65492249]
 [77.60848999]
 [77.56252289]
 [77.51688385]].
[2019-03-26 21:05:30,399] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:30,401] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:30,480] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run6
[2019-03-26 21:05:37,101] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:37,102] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:37,177] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run6
[2019-03-26 21:05:38,827] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.7879417e-20 1.0000000e+00 1.6081504e-18 5.4412863e-15 1.2817390e-24], sum to 1.0000
[2019-03-26 21:05:38,838] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9951
[2019-03-26 21:05:38,846] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.15, 85.33333333333334, 1.0, 2.0, 0.5179917238877224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723821.5202064664, 723821.5202064664, 186463.3624524275], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7762200.0000, 
sim time next is 7762800.0000, 
raw observation next is [27.1, 85.66666666666667, 1.0, 2.0, 0.5195943645146639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726061.7533430048, 726061.7533430048, 186723.2850285625], 
processed observation next is [1.0, 0.8695652173913043, 0.4834123222748816, 0.8566666666666667, 1.0, 1.0, 0.4211980295357396, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2016838203730569, 0.2016838203730569, 0.27869147019188434], 
reward next is 0.7213, 
noisyNet noise sample is [array([0.9368533], dtype=float32), 0.27399448]. 
=============================================
[2019-03-26 21:05:39,187] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:39,188] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:39,268] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run6
[2019-03-26 21:05:39,463] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1055039: loss 0.0559
[2019-03-26 21:05:39,464] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1055041: learning rate 0.0000
[2019-03-26 21:05:43,372] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.1798045e-12 9.9999988e-01 8.8524868e-11 1.3892024e-07 1.1000298e-14], sum to 1.0000
[2019-03-26 21:05:43,382] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4494
[2019-03-26 21:05:43,386] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.63333333333333, 67.66666666666667, 1.0, 2.0, 0.4644769612724171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 649019.2251040917, 649019.2251040917, 178219.793812848], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7753200.0000, 
sim time next is 7753800.0000, 
raw observation next is [29.46666666666667, 68.83333333333333, 1.0, 2.0, 0.4776343206228006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 667409.9363188114, 667409.9363188114, 180167.8236841091], 
processed observation next is [1.0, 0.7391304347826086, 0.5955766192733019, 0.6883333333333332, 1.0, 1.0, 0.37064375978650677, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18539164897744762, 0.18539164897744762, 0.26890719952852105], 
reward next is 0.7311, 
noisyNet noise sample is [array([-1.3849443], dtype=float32), -0.12660354]. 
=============================================
[2019-03-26 21:05:46,755] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1058408: loss 0.0417
[2019-03-26 21:05:46,758] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1058408: learning rate 0.0000
[2019-03-26 21:05:47,630] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:47,630] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:47,727] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run6
[2019-03-26 21:05:48,183] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9050800e-12 9.9999976e-01 1.6734107e-11 2.1552221e-07 2.0569604e-15], sum to 1.0000
[2019-03-26 21:05:48,191] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6640
[2019-03-26 21:05:48,194] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.3, 65.0, 1.0, 2.0, 0.4647916551619754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104279, 649459.0850632364, 649459.0850632364, 178266.1460314929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7925400.0000, 
sim time next is 7926000.0000, 
raw observation next is [30.13333333333333, 66.0, 1.0, 2.0, 0.4748563034256418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 663526.933694607, 663526.933694607, 179752.5839599559], 
processed observation next is [1.0, 0.7391304347826086, 0.6271721958925749, 0.66, 1.0, 1.0, 0.367296751115231, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18431303713739083, 0.18431303713739083, 0.2682874387462028], 
reward next is 0.7317, 
noisyNet noise sample is [array([0.5620112], dtype=float32), 0.26486197]. 
=============================================
[2019-03-26 21:05:48,204] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[42.517624]
 [38.204964]
 [35.048737]
 [33.662376]
 [34.080162]], R is [[45.73371506]
 [46.01031113]
 [45.55020905]
 [45.09470749]
 [44.64376068]].
[2019-03-26 21:05:48,580] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4792792e-20 1.0000000e+00 2.4026813e-18 3.1353766e-16 2.9228371e-24], sum to 1.0000
[2019-03-26 21:05:48,586] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0134
[2019-03-26 21:05:48,590] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.4, 96.0, 1.0, 2.0, 0.3854258006863907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 581924.2250599122, 581924.2250599122, 173088.8438988943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 154800.0000, 
sim time next is 155400.0000, 
raw observation next is [22.4, 96.0, 1.0, 2.0, 0.3849870078901698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 581361.768807654, 581361.7688076535, 173041.3148942467], 
processed observation next is [1.0, 0.8260869565217391, 0.2606635071090047, 0.96, 1.0, 1.0, 0.2590204914339395, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16148938022434833, 0.1614893802243482, 0.25827061924514433], 
reward next is 0.7417, 
noisyNet noise sample is [array([0.9636291], dtype=float32), -1.9269001]. 
=============================================
[2019-03-26 21:05:48,619] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1059312: loss 0.0294
[2019-03-26 21:05:48,621] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1059312: learning rate 0.0000
[2019-03-26 21:05:49,578] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1120687e-19 1.0000000e+00 5.0117054e-19 2.4391060e-16 7.5015466e-24], sum to 1.0000
[2019-03-26 21:05:49,589] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5090
[2019-03-26 21:05:49,595] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.08333333333334, 91.33333333333334, 1.0, 2.0, 0.7600381123005231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1062216.880056028, 1062216.880056028, 234336.6552992772], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7872600.0000, 
sim time next is 7873200.0000, 
raw observation next is [26.1, 91.0, 1.0, 2.0, 0.6892488017322556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 963238.0245145586, 963238.0245145586, 218540.254209167], 
processed observation next is [1.0, 0.13043478260869565, 0.4360189573459717, 0.91, 1.0, 1.0, 0.6256009659424766, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2675661179207107, 0.2675661179207107, 0.3261794838942791], 
reward next is 0.6738, 
noisyNet noise sample is [array([-1.5413265], dtype=float32), 0.5203144]. 
=============================================
[2019-03-26 21:05:50,334] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:50,334] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:50,399] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run6
[2019-03-26 21:05:53,889] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:53,890] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:53,957] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:53,958] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:53,965] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run6
[2019-03-26 21:05:53,985] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:53,989] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:54,023] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:54,024] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:54,048] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run6
[2019-03-26 21:05:54,074] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1061919: loss 0.0760
[2019-03-26 21:05:54,076] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1061919: learning rate 0.0000
[2019-03-26 21:05:54,080] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run6
[2019-03-26 21:05:54,122] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run6
[2019-03-26 21:05:54,177] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:54,177] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:54,214] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run6
[2019-03-26 21:05:54,336] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:54,336] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:54,363] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run6
[2019-03-26 21:05:54,434] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:54,434] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:54,454] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run6
[2019-03-26 21:05:54,492] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1800166e-20 1.0000000e+00 5.2940014e-19 7.5328592e-17 7.4414339e-25], sum to 1.0000
[2019-03-26 21:05:54,498] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5133
[2019-03-26 21:05:54,501] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.75, 96.0, 1.0, 2.0, 0.9123297797886507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1360691.385182906, 1360691.385182906, 285705.5645954492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 138600.0000, 
sim time next is 139200.0000, 
raw observation next is [22.73333333333333, 96.0, 1.0, 2.0, 0.8486763137904157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1266470.075735952, 1266470.075735952, 267414.8147117951], 
processed observation next is [1.0, 0.6086956521739131, 0.27646129541864134, 0.96, 1.0, 1.0, 0.8176823057715852, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3517972432599867, 0.3517972432599867, 0.3991265891220822], 
reward next is 0.6009, 
noisyNet noise sample is [array([-0.72196144], dtype=float32), 0.48471886]. 
=============================================
[2019-03-26 21:05:54,512] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:54,512] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:54,521] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run6
[2019-03-26 21:05:54,703] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:54,703] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:54,708] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run6
[2019-03-26 21:05:54,745] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:54,745] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:54,752] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run6
[2019-03-26 21:05:54,801] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:05:54,801] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:05:54,804] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run6
[2019-03-26 21:05:54,940] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1062232: loss 0.0371
[2019-03-26 21:05:54,948] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1062232: learning rate 0.0000
[2019-03-26 21:05:56,255] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1062953: loss 0.0633
[2019-03-26 21:05:56,256] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1062954: learning rate 0.0000
[2019-03-26 21:05:56,716] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1056234e-19 1.0000000e+00 4.8330418e-18 3.3605233e-16 2.0288666e-23], sum to 1.0000
[2019-03-26 21:05:56,726] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0220
[2019-03-26 21:05:56,736] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.4, 86.0, 1.0, 2.0, 0.2889412922408359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 462967.1389990058, 462967.1389990051, 164463.3166264564], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 18000.0000, 
sim time next is 18600.0000, 
raw observation next is [21.43333333333333, 86.0, 1.0, 2.0, 0.3538382837698558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 566489.6619203629, 566489.6619203629, 172316.7511963779], 
processed observation next is [1.0, 0.21739130434782608, 0.21484992101105835, 0.86, 1.0, 1.0, 0.22149190815645278, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15735823942232302, 0.15735823942232302, 0.2571891808901163], 
reward next is 0.7428, 
noisyNet noise sample is [array([0.69547355], dtype=float32), 0.03333717]. 
=============================================
[2019-03-26 21:05:58,798] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1064107: loss 0.0709
[2019-03-26 21:05:58,802] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1064107: learning rate 0.0000
[2019-03-26 21:06:01,265] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1065202: loss 0.0447
[2019-03-26 21:06:01,266] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1065203: learning rate 0.0000
[2019-03-26 21:06:01,866] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.33309534e-20 1.00000000e+00 6.29227607e-19 3.49725643e-17
 6.06389371e-24], sum to 1.0000
[2019-03-26 21:06:01,876] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1655
[2019-03-26 21:06:01,882] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.58333333333334, 90.83333333333334, 1.0, 2.0, 0.3727829568078108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 571299.4506704927, 571299.4506704921, 172387.3284338278], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 103800.0000, 
sim time next is 104400.0000, 
raw observation next is [22.6, 91.0, 1.0, 2.0, 0.3666308478678393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 561238.6564266729, 561238.6564266729, 171500.5371181019], 
processed observation next is [1.0, 0.21739130434782608, 0.27014218009478685, 0.91, 1.0, 1.0, 0.23690463598534853, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15589962678518693, 0.15589962678518693, 0.25597095092254013], 
reward next is 0.7440, 
noisyNet noise sample is [array([-0.21835263], dtype=float32), 0.7763321]. 
=============================================
[2019-03-26 21:06:03,484] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1066188: loss 0.0828
[2019-03-26 21:06:03,486] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1066188: learning rate 0.0000
[2019-03-26 21:06:03,822] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1066340: loss 0.0846
[2019-03-26 21:06:03,826] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1066342: learning rate 0.0000
[2019-03-26 21:06:03,875] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1066363: loss 0.0765
[2019-03-26 21:06:03,880] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1066365: learning rate 0.0000
[2019-03-26 21:06:03,961] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1066404: loss 0.0851
[2019-03-26 21:06:03,963] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1066404: learning rate 0.0000
[2019-03-26 21:06:04,213] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1066512: loss 0.0872
[2019-03-26 21:06:04,214] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1066512: learning rate 0.0000
[2019-03-26 21:06:04,782] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1066770: loss 0.0802
[2019-03-26 21:06:04,783] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1066770: learning rate 0.0000
[2019-03-26 21:06:04,876] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1066813: loss 0.0924
[2019-03-26 21:06:04,882] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1066816: learning rate 0.0000
[2019-03-26 21:06:05,058] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1066892: loss 0.0793
[2019-03-26 21:06:05,062] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1066892: learning rate 0.0000
[2019-03-26 21:06:05,158] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1066938: loss 0.0859
[2019-03-26 21:06:05,159] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1066938: learning rate 0.0000
[2019-03-26 21:06:05,231] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1066969: loss 0.0780
[2019-03-26 21:06:05,233] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1066969: learning rate 0.0000
[2019-03-26 21:06:05,582] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1067125: loss 0.0626
[2019-03-26 21:06:05,585] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1067126: learning rate 0.0000
[2019-03-26 21:06:08,942] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1068630: loss 0.0235
[2019-03-26 21:06:08,943] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1068630: learning rate 0.0000
[2019-03-26 21:06:09,999] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0723683e-21 1.0000000e+00 1.3823194e-19 4.3611979e-17 9.9105156e-26], sum to 1.0000
[2019-03-26 21:06:10,004] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1213
[2019-03-26 21:06:10,014] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 91.16666666666667, 1.0, 2.0, 0.2831954340292483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 455922.9584193631, 455922.9584193638, 163996.5893461507], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 256200.0000, 
sim time next is 256800.0000, 
raw observation next is [20.5, 91.33333333333334, 1.0, 2.0, 0.2833883711786864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 456068.3070089751, 456068.3070089751, 164005.9628730823], 
processed observation next is [0.0, 1.0, 0.1706161137440759, 0.9133333333333334, 1.0, 1.0, 0.13661249539600773, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12668564083582642, 0.12668564083582642, 0.24478501921355567], 
reward next is 0.7552, 
noisyNet noise sample is [array([1.1177385], dtype=float32), -0.9242308]. 
=============================================
[2019-03-26 21:06:11,183] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1069630: loss 0.0493
[2019-03-26 21:06:11,187] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1069630: learning rate 0.0000
[2019-03-26 21:06:14,151] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1070955: loss 0.0462
[2019-03-26 21:06:14,155] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1070955: learning rate 0.0000
[2019-03-26 21:06:16,557] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1072029: loss 0.0156
[2019-03-26 21:06:16,566] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1072031: learning rate 0.0000
[2019-03-26 21:06:16,827] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5170461e-19 1.0000000e+00 1.0373419e-18 1.9300437e-16 1.5279901e-24], sum to 1.0000
[2019-03-26 21:06:16,836] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1674
[2019-03-26 21:06:16,842] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 69.0, 1.0, 2.0, 0.2408189506974966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 397554.5246586306, 397554.5246586306, 159969.3600277277], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 500400.0000, 
sim time next is 501000.0000, 
raw observation next is [21.46666666666667, 70.5, 1.0, 2.0, 0.2405443348468091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 397198.3745515567, 397198.3745515567, 159938.2199016922], 
processed observation next is [1.0, 0.8260869565217391, 0.21642969984202226, 0.705, 1.0, 1.0, 0.08499317451422782, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11033288181987687, 0.11033288181987687, 0.2387137610473018], 
reward next is 0.7613, 
noisyNet noise sample is [array([0.93566656], dtype=float32), 1.2618648]. 
=============================================
[2019-03-26 21:06:16,869] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.85361 ]
 [72.84328 ]
 [72.81601 ]
 [72.85312 ]
 [72.815704]], R is [[72.87446594]
 [72.90695953]
 [72.93911743]
 [72.97103882]
 [73.00230408]].
[2019-03-26 21:06:17,386] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.0990062e-20 1.0000000e+00 3.3483889e-18 1.2300954e-16 4.2719216e-24], sum to 1.0000
[2019-03-26 21:06:17,395] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0569
[2019-03-26 21:06:17,397] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.13333333333333, 88.66666666666666, 1.0, 2.0, 0.256341999938463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 417466.0831842221, 417466.0831842227, 161473.3418926864], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 358800.0000, 
sim time next is 359400.0000, 
raw observation next is [20.11666666666667, 88.83333333333334, 1.0, 2.0, 0.25656065928945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 417798.8141201269, 417798.8141201264, 161494.3555650893], 
processed observation next is [1.0, 0.13043478260869565, 0.15244865718799394, 0.8883333333333334, 1.0, 1.0, 0.10428995095114456, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11605522614447969, 0.11605522614447956, 0.2410363515896855], 
reward next is 0.7590, 
noisyNet noise sample is [array([1.0149376], dtype=float32), 0.11223032]. 
=============================================
[2019-03-26 21:06:19,213] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1073216: loss 0.0062
[2019-03-26 21:06:19,217] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1073216: learning rate 0.0000
[2019-03-26 21:06:19,712] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.9832592e-20 1.0000000e+00 1.4014716e-18 1.6712953e-16 7.4144058e-24], sum to 1.0000
[2019-03-26 21:06:19,721] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1108
[2019-03-26 21:06:19,729] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 86.0, 1.0, 2.0, 0.245100758040299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 403372.8761155003, 403372.8761155003, 160422.9433864815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 430200.0000, 
sim time next is 430800.0000, 
raw observation next is [19.7, 86.0, 1.0, 2.0, 0.244680711747906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 402682.2676706034, 402682.2676706034, 160382.3105867617], 
processed observation next is [1.0, 1.0, 0.1327014218009479, 0.86, 1.0, 1.0, 0.08997676114205543, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1118561854640565, 0.1118561854640565, 0.239376582965316], 
reward next is 0.7606, 
noisyNet noise sample is [array([0.19533488], dtype=float32), 2.2292967]. 
=============================================
[2019-03-26 21:06:20,648] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.5217976e-20 1.0000000e+00 6.3270114e-18 1.8502808e-15 8.2606146e-24], sum to 1.0000
[2019-03-26 21:06:20,659] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6214
[2019-03-26 21:06:20,662] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 85.0, 1.0, 2.0, 0.2386394219171848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 393702.6486954252, 393702.6486954258, 159774.2805548117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 435600.0000, 
sim time next is 436200.0000, 
raw observation next is [19.6, 85.00000000000001, 1.0, 2.0, 0.2389475910213506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 394263.9203123889, 394263.9203123889, 159801.1288835176], 
processed observation next is [1.0, 0.043478260869565216, 0.127962085308057, 0.8500000000000001, 1.0, 1.0, 0.08306938677271156, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.10951775564233025, 0.10951775564233025, 0.2385091475873397], 
reward next is 0.7615, 
noisyNet noise sample is [array([-0.17485844], dtype=float32), 2.0562756]. 
=============================================
[2019-03-26 21:06:21,213] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1074107: loss 0.0303
[2019-03-26 21:06:21,218] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1074110: learning rate 0.0000
[2019-03-26 21:06:21,836] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1074384: loss 0.0310
[2019-03-26 21:06:21,841] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1074386: learning rate 0.0000
[2019-03-26 21:06:21,914] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1074422: loss 0.0242
[2019-03-26 21:06:21,915] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1074422: learning rate 0.0000
[2019-03-26 21:06:21,958] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1074442: loss 0.0269
[2019-03-26 21:06:21,960] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1074443: learning rate 0.0000
[2019-03-26 21:06:22,042] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1074476: loss 0.0222
[2019-03-26 21:06:22,045] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1074476: learning rate 0.0000
[2019-03-26 21:06:22,556] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1074705: loss 0.0206
[2019-03-26 21:06:22,557] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1074705: learning rate 0.0000
[2019-03-26 21:06:22,811] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1074818: loss 0.0257
[2019-03-26 21:06:22,817] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1074818: learning rate 0.0000
[2019-03-26 21:06:22,958] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6830831e-20 1.0000000e+00 2.8100481e-18 1.0584323e-16 2.9798824e-24], sum to 1.0000
[2019-03-26 21:06:22,972] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8946
[2019-03-26 21:06:22,976] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 82.83333333333334, 1.0, 2.0, 0.2293239952763556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 379049.5574255372, 379049.5574255366, 158867.9655074656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 447000.0000, 
sim time next is 447600.0000, 
raw observation next is [19.7, 82.66666666666667, 1.0, 2.0, 0.2282594086308865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 377369.7702676977, 377369.7702676977, 158765.3333167458], 
processed observation next is [1.0, 0.17391304347826086, 0.1327014218009479, 0.8266666666666667, 1.0, 1.0, 0.07019205859142952, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.10482493618547158, 0.10482493618547158, 0.23696318405484446], 
reward next is 0.7630, 
noisyNet noise sample is [array([0.93257254], dtype=float32), -0.7347588]. 
=============================================
[2019-03-26 21:06:23,061] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1074929: loss 0.0257
[2019-03-26 21:06:23,069] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1074931: learning rate 0.0000
[2019-03-26 21:06:23,070] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1074931: loss 0.0241
[2019-03-26 21:06:23,076] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1074932: learning rate 0.0000
[2019-03-26 21:06:23,206] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1074991: loss 0.0251
[2019-03-26 21:06:23,207] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1074992: learning rate 0.0000
[2019-03-26 21:06:23,228] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 21:06:23,229] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:06:23,230] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:06:23,230] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:06:23,231] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:06:23,232] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:06:23,233] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:06:23,233] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:06:23,234] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:06:23,236] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:06:23,236] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:06:23,254] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run44
[2019-03-26 21:06:23,276] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run44
[2019-03-26 21:06:23,296] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run44
[2019-03-26 21:06:23,325] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run44
[2019-03-26 21:06:23,326] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run44
[2019-03-26 21:06:32,827] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08592572], dtype=float32), 0.06731702]
[2019-03-26 21:06:32,829] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.11432194666667, 62.69695972, 1.0, 2.0, 0.5458816209265307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 873586.0354827372, 873586.0354827372, 203441.4063662263]
[2019-03-26 21:06:32,831] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:06:32,833] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.7898708e-21 1.0000000e+00 1.8844758e-19 5.7367993e-17 5.4709801e-25], sampled 0.35686833500091564
[2019-03-26 21:07:16,799] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08592572], dtype=float32), 0.06731702]
[2019-03-26 21:07:16,800] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.29974491, 80.33729858666668, 1.0, 2.0, 0.7900741351069266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1104216.561726777, 1104216.561726778, 241491.663838896]
[2019-03-26 21:07:16,801] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:07:16,805] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.5174949e-21 1.0000000e+00 4.2468755e-20 1.5076554e-17 7.2626467e-26], sampled 0.6710377301158987
[2019-03-26 21:07:20,212] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08592572], dtype=float32), 0.06731702]
[2019-03-26 21:07:20,213] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.17621086, 86.81932802, 1.0, 2.0, 0.5533737368674007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 773280.9675448239, 773280.9675448239, 192382.0933397757]
[2019-03-26 21:07:20,215] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:07:20,220] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.3916212e-22 1.0000000e+00 9.7677663e-21 1.2388869e-17 2.0747752e-26], sampled 0.32948952106686435
[2019-03-26 21:07:21,398] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08592572], dtype=float32), 0.06731702]
[2019-03-26 21:07:21,399] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.92360589, 73.70483926, 1.0, 2.0, 0.5345958380032326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 747031.6230699618, 747031.6230699618, 189193.0119839574]
[2019-03-26 21:07:21,399] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:07:21,404] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.9387495e-22 1.0000000e+00 6.8217577e-21 8.5359737e-18 1.6199222e-26], sampled 0.4290487672644099
[2019-03-26 21:07:31,724] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08592572], dtype=float32), 0.06731702]
[2019-03-26 21:07:31,725] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.1, 61.0, 1.0, 2.0, 0.515324500574358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 720093.1826354061, 720093.1826354061, 186031.8368039847]
[2019-03-26 21:07:31,726] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:07:31,729] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.2787012e-21 1.0000000e+00 6.4121438e-20 5.3990601e-17 2.6145616e-25], sampled 0.6914442646598028
[2019-03-26 21:07:54,606] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08592572], dtype=float32), 0.06731702]
[2019-03-26 21:07:54,608] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.90889165666667, 81.78798415, 1.0, 2.0, 0.4778755414484228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 681357.3038001166, 681357.3038001161, 181945.2943021762]
[2019-03-26 21:07:54,610] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:07:54,613] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.1298580e-22 1.0000000e+00 6.8610876e-21 7.4431920e-18 1.3653816e-26], sampled 0.6124788334260227
[2019-03-26 21:07:57,822] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08592572], dtype=float32), 0.06731702]
[2019-03-26 21:07:57,823] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.25, 91.5, 1.0, 2.0, 0.7653272860402697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1069612.665953984, 1069612.665953983, 235576.9830237671]
[2019-03-26 21:07:57,824] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:07:57,827] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.2374013e-21 1.0000000e+00 2.3662773e-20 9.5814862e-18 3.6080208e-26], sampled 0.3187663050132671
[2019-03-26 21:08:18,371] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1701 3164000012.1395 1778.0000
[2019-03-26 21:08:18,375] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.4791 3007718786.5045 1766.0000
[2019-03-26 21:08:18,581] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 21:08:18,660] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.6283 2779190527.6999 933.0000
[2019-03-26 21:08:18,694] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.9454 2927351652.0094 1338.0000
[2019-03-26 21:08:19,711] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1075000, evaluation results [1075000.0, 7884.170123390672, 3164000012.13951, 1778.0, 8252.945436711087, 2927351652.0094247, 1338.0, 8660.628342730803, 2779190527.699903, 933.0, 7997.479055512932, 3007718786.504511, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 21:08:19,935] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1075105: loss 0.0159
[2019-03-26 21:08:19,937] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1075105: learning rate 0.0000
[2019-03-26 21:08:22,866] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1076638: loss 0.0054
[2019-03-26 21:08:22,869] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1076638: learning rate 0.0000
[2019-03-26 21:08:25,053] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1077630: loss 0.0012
[2019-03-26 21:08:25,058] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1077632: learning rate 0.0000
[2019-03-26 21:08:26,918] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.3669565e-20 1.0000000e+00 3.2076091e-18 1.9816860e-16 7.1465670e-24], sum to 1.0000
[2019-03-26 21:08:26,927] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3887
[2019-03-26 21:08:26,932] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.96666666666667, 87.66666666666667, 1.0, 2.0, 0.2144727358452151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 357739.3476943186, 357739.3476943193, 156966.718099004], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 606000.0000, 
sim time next is 606600.0000, 
raw observation next is [17.9, 88.0, 1.0, 2.0, 0.2134813270544272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 356140.5977505077, 356140.5977505077, 156860.3708652732], 
processed observation next is [1.0, 0.0, 0.04739336492890995, 0.88, 1.0, 1.0, 0.052387141029430366, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.09892794381958547, 0.09892794381958547, 0.23411995651533313], 
reward next is 0.7659, 
noisyNet noise sample is [array([-0.4704142], dtype=float32), 1.9760585]. 
=============================================
[2019-03-26 21:08:28,107] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1078999: loss 0.0046
[2019-03-26 21:08:28,110] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1078999: learning rate 0.0000
[2019-03-26 21:08:28,539] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.6795247e-19 1.0000000e+00 3.8027275e-18 8.7680917e-16 6.3482674e-24], sum to 1.0000
[2019-03-26 21:08:28,548] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2143
[2019-03-26 21:08:28,553] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.96666666666667, 92.0, 1.0, 2.0, 0.2007718088497139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 335655.8152497928, 335655.8152497928, 155379.4642532544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 620400.0000, 
sim time next is 621000.0000, 
raw observation next is [16.95, 92.0, 1.0, 2.0, 0.2012261717516125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 336434.2421623027, 336434.2421623032, 155399.7682012333], 
processed observation next is [1.0, 0.17391304347826086, 0.002369668246445531, 0.92, 1.0, 1.0, 0.03762189367664156, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.0934539561561952, 0.09345395615619533, 0.23193995253915417], 
reward next is 0.7681, 
noisyNet noise sample is [array([0.4398506], dtype=float32), 1.9967679]. 
=============================================
[2019-03-26 21:08:28,579] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[72.993965]
 [73.002975]
 [73.03532 ]
 [72.95612 ]
 [72.9714  ]], R is [[72.97850037]
 [73.01680756]
 [73.0541153 ]
 [73.0915451 ]
 [73.12854004]].
[2019-03-26 21:08:30,451] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1080042: loss 0.0091
[2019-03-26 21:08:30,452] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1080042: learning rate 0.0000
[2019-03-26 21:08:32,893] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.4374510e-20 1.0000000e+00 2.5398291e-18 1.3869961e-16 7.6140713e-24], sum to 1.0000
[2019-03-26 21:08:32,907] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7400
[2019-03-26 21:08:32,915] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.71666666666667, 91.0, 1.0, 2.0, 0.2173594940760535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 362380.1638334922, 362380.1638334916, 157278.1722491333], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 709800.0000, 
sim time next is 710400.0000, 
raw observation next is [17.93333333333333, 90.0, 1.0, 2.0, 0.2147865918908541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 357865.0006242922, 357865.0006242922, 157127.2389302956], 
processed observation next is [1.0, 0.21739130434782608, 0.04897314375987352, 0.9, 1.0, 1.0, 0.05395974926608928, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.09940694461785894, 0.09940694461785894, 0.2345182670601427], 
reward next is 0.7655, 
noisyNet noise sample is [array([-0.55588794], dtype=float32), -0.5940473]. 
=============================================
[2019-03-26 21:08:32,988] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1081171: loss 0.0074
[2019-03-26 21:08:32,992] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1081172: learning rate 0.0000
[2019-03-26 21:08:35,258] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1082180: loss 0.0057
[2019-03-26 21:08:35,262] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1082181: learning rate 0.0000
[2019-03-26 21:08:35,659] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1082357: loss 0.0025
[2019-03-26 21:08:35,660] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1082357: learning rate 0.0000
[2019-03-26 21:08:35,711] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1082378: loss 0.0056
[2019-03-26 21:08:35,713] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1082379: learning rate 0.0000
[2019-03-26 21:08:35,872] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1082451: loss 0.0044
[2019-03-26 21:08:35,875] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1082451: learning rate 0.0000
[2019-03-26 21:08:35,932] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1082476: loss 0.0025
[2019-03-26 21:08:35,936] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1082476: learning rate 0.0000
[2019-03-26 21:08:36,342] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1082663: loss 0.0020
[2019-03-26 21:08:36,345] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1082663: learning rate 0.0000
[2019-03-26 21:08:36,731] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1082835: loss 0.0037
[2019-03-26 21:08:36,737] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1082836: learning rate 0.0000
[2019-03-26 21:08:36,803] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1082868: loss 0.0022
[2019-03-26 21:08:36,805] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1082868: learning rate 0.0000
[2019-03-26 21:08:36,894] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1082909: loss 0.0051
[2019-03-26 21:08:36,900] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1082910: learning rate 0.0000
[2019-03-26 21:08:37,174] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1083034: loss 0.0029
[2019-03-26 21:08:37,179] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1083034: learning rate 0.0000
[2019-03-26 21:08:37,244] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1083066: loss 0.0026
[2019-03-26 21:08:37,248] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1083067: learning rate 0.0000
[2019-03-26 21:08:41,205] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1084837: loss 0.1303
[2019-03-26 21:08:41,210] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1084837: learning rate 0.0000
[2019-03-26 21:08:42,739] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0533745e-21 1.0000000e+00 3.0979659e-21 4.8842517e-18 2.4567050e-26], sum to 1.0000
[2019-03-26 21:08:42,748] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9019
[2019-03-26 21:08:42,757] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.56666666666667, 89.0, 1.0, 2.0, 0.3091973448710491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 489324.0105647654, 489324.0105647654, 166242.3931793907], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 861000.0000, 
sim time next is 861600.0000, 
raw observation next is [21.53333333333333, 89.0, 1.0, 2.0, 0.3091584772471531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 489622.0235564462, 489622.0235564456, 166271.5381219746], 
processed observation next is [0.0, 1.0, 0.21958925750394942, 0.89, 1.0, 1.0, 0.16766081596042542, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13600611765456838, 0.13600611765456821, 0.2481664748089173], 
reward next is 0.7518, 
noisyNet noise sample is [array([1.1833712], dtype=float32), -0.08605398]. 
=============================================
[2019-03-26 21:08:42,906] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1085588: loss 0.0066
[2019-03-26 21:08:42,913] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1085589: learning rate 0.0000
[2019-03-26 21:08:46,027] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1086980: loss 0.0015
[2019-03-26 21:08:46,032] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1086982: learning rate 0.0000
[2019-03-26 21:08:46,120] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.2135577e-21 1.0000000e+00 9.8598649e-20 5.9249591e-17 3.6889377e-25], sum to 1.0000
[2019-03-26 21:08:46,128] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4273
[2019-03-26 21:08:46,134] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.51666666666667, 91.33333333333334, 1.0, 2.0, 0.4829092636687409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 688431.9385824759, 688431.9385824759, 182708.3712056043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1314600.0000, 
sim time next is 1315200.0000, 
raw observation next is [24.43333333333334, 91.66666666666667, 1.0, 2.0, 0.4445638809425742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 634802.0317618322, 634802.0317618322, 177121.6507836706], 
processed observation next is [1.0, 0.21739130434782608, 0.3570300157977887, 0.9166666666666667, 1.0, 1.0, 0.33079985655731836, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17633389771162006, 0.17633389771162006, 0.26436067281144865], 
reward next is 0.7356, 
noisyNet noise sample is [array([0.49793378], dtype=float32), -1.8702928]. 
=============================================
[2019-03-26 21:08:48,549] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1396350e-20 1.0000000e+00 1.3775035e-18 2.5936615e-17 2.1894546e-24], sum to 1.0000
[2019-03-26 21:08:48,550] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.9927991e-21 1.0000000e+00 4.9303558e-19 1.3318470e-17 2.6212926e-25], sum to 1.0000
[2019-03-26 21:08:48,559] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9587
[2019-03-26 21:08:48,561] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6615
[2019-03-26 21:08:48,565] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 93.0, 1.0, 2.0, 0.3292132708040946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 510337.8854934814, 510337.8854934814, 167546.445712559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 972600.0000, 
sim time next is 973200.0000, 
raw observation next is [21.9, 93.0, 1.0, 2.0, 0.3282851924684677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 508893.8120397911, 508893.8120397917, 167434.2684789953], 
processed observation next is [1.0, 0.2608695652173913, 0.23696682464454974, 0.93, 1.0, 1.0, 0.19070505116682857, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1413593922332753, 0.14135939223327548, 0.2499018932522318], 
reward next is 0.7501, 
noisyNet noise sample is [array([-0.22088192], dtype=float32), 0.5807401]. 
=============================================
[2019-03-26 21:08:48,569] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 92.5, 1.0, 2.0, 0.3266065538592764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 507045.1089431385, 507045.1089431385, 167315.7245968776], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 966600.0000, 
sim time next is 967200.0000, 
raw observation next is [21.9, 92.33333333333333, 1.0, 2.0, 0.3249702401700564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 504792.0294788929, 504792.0294788922, 167151.6441352735], 
processed observation next is [1.0, 0.17391304347826086, 0.23696682464454974, 0.9233333333333333, 1.0, 1.0, 0.18671113273500767, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14022000818858135, 0.14022000818858119, 0.24948006587354254], 
reward next is 0.7505, 
noisyNet noise sample is [array([0.48439136], dtype=float32), 1.1344528]. 
=============================================
[2019-03-26 21:08:48,575] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1088120: loss 0.0847
[2019-03-26 21:08:48,576] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1088120: learning rate 0.0000
[2019-03-26 21:08:51,106] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1089247: loss 0.0783
[2019-03-26 21:08:51,107] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1089248: learning rate 0.0000
[2019-03-26 21:08:53,244] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1090175: loss 0.0013
[2019-03-26 21:08:53,247] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1090175: learning rate 0.0000
[2019-03-26 21:08:53,588] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1090326: loss 0.0011
[2019-03-26 21:08:53,592] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1090328: learning rate 0.0000
[2019-03-26 21:08:53,642] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1090350: loss 0.0016
[2019-03-26 21:08:53,645] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1090351: learning rate 0.0000
[2019-03-26 21:08:53,700] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1090374: loss 0.0010
[2019-03-26 21:08:53,703] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1090374: learning rate 0.0000
[2019-03-26 21:08:53,918] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1090467: loss 0.0012
[2019-03-26 21:08:53,927] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1090469: learning rate 0.0000
[2019-03-26 21:08:54,380] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1090679: loss 0.0012
[2019-03-26 21:08:54,382] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1090679: learning rate 0.0000
[2019-03-26 21:08:54,725] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1090831: loss 0.0011
[2019-03-26 21:08:54,732] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1090831: learning rate 0.0000
[2019-03-26 21:08:54,757] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1090844: loss 0.0011
[2019-03-26 21:08:54,761] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1090844: learning rate 0.0000
[2019-03-26 21:08:54,849] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1090886: loss 0.0026
[2019-03-26 21:08:54,851] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1090886: learning rate 0.0000
[2019-03-26 21:08:55,140] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1091013: loss 0.0017
[2019-03-26 21:08:55,147] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1091014: learning rate 0.0000
[2019-03-26 21:08:55,232] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1091052: loss 0.0012
[2019-03-26 21:08:55,234] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1091053: learning rate 0.0000
[2019-03-26 21:08:57,634] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2427747e-20 1.0000000e+00 2.8062118e-19 9.0971828e-17 4.2474155e-25], sum to 1.0000
[2019-03-26 21:08:57,643] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2021
[2019-03-26 21:08:57,649] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.71666666666667, 67.0, 1.0, 2.0, 0.7495945480135784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1159024.965604882, 1159024.965604882, 246130.2975684384], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1095000.0000, 
sim time next is 1095600.0000, 
raw observation next is [25.73333333333333, 67.0, 1.0, 2.0, 0.7365807830015667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1138469.343710732, 1138469.343710732, 242778.3475346128], 
processed observation next is [1.0, 0.6956521739130435, 0.41864139020537117, 0.67, 1.0, 1.0, 0.682627449399478, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3162414843640922, 0.3162414843640922, 0.36235574258897435], 
reward next is 0.6376, 
noisyNet noise sample is [array([-0.7481846], dtype=float32), -1.279687]. 
=============================================
[2019-03-26 21:08:59,228] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1092834: loss 0.0895
[2019-03-26 21:08:59,230] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1092834: learning rate 0.0000
[2019-03-26 21:09:01,077] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1093656: loss 0.0529
[2019-03-26 21:09:01,079] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1093656: learning rate 0.0000
[2019-03-26 21:09:04,289] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1095085: loss 0.0412
[2019-03-26 21:09:04,294] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1095086: learning rate 0.0000
[2019-03-26 21:09:06,358] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1096045: loss 0.0980
[2019-03-26 21:09:06,360] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1096046: learning rate 0.0000
[2019-03-26 21:09:08,787] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1097130: loss 0.0864
[2019-03-26 21:09:08,790] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1097130: learning rate 0.0000
[2019-03-26 21:09:11,005] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1098125: loss 0.0444
[2019-03-26 21:09:11,008] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1098126: learning rate 0.0000
[2019-03-26 21:09:11,405] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1098302: loss 0.0369
[2019-03-26 21:09:11,407] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1098303: learning rate 0.0000
[2019-03-26 21:09:11,483] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1098336: loss 0.0414
[2019-03-26 21:09:11,486] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1098338: learning rate 0.0000
[2019-03-26 21:09:11,696] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1098435: loss 0.0364
[2019-03-26 21:09:11,699] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1098435: learning rate 0.0000
[2019-03-26 21:09:11,796] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1098476: loss 0.0388
[2019-03-26 21:09:11,800] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1098476: learning rate 0.0000
[2019-03-26 21:09:12,369] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1098729: loss 0.0345
[2019-03-26 21:09:12,370] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1098729: learning rate 0.0000
[2019-03-26 21:09:12,677] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1098854: loss 0.0379
[2019-03-26 21:09:12,681] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1098857: learning rate 0.0000
[2019-03-26 21:09:12,701] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1098866: loss 0.0380
[2019-03-26 21:09:12,703] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1098867: learning rate 0.0000
[2019-03-26 21:09:12,799] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1098906: loss 0.0313
[2019-03-26 21:09:12,804] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1098907: learning rate 0.0000
[2019-03-26 21:09:13,037] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1099017: loss 0.0381
[2019-03-26 21:09:13,042] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1099018: learning rate 0.0000
[2019-03-26 21:09:13,272] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1099121: loss 0.0325
[2019-03-26 21:09:13,274] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1099121: learning rate 0.0000
[2019-03-26 21:09:13,322] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.2859468e-20 1.0000000e+00 1.3803387e-18 2.6146634e-16 2.7506891e-24], sum to 1.0000
[2019-03-26 21:09:13,332] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1014
[2019-03-26 21:09:13,340] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 94.0, 1.0, 2.0, 0.3215548565950076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 507499.2158023393, 507499.2158023393, 167571.6449226296], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1364400.0000, 
sim time next is 1365000.0000, 
raw observation next is [21.11666666666667, 94.00000000000001, 1.0, 2.0, 0.3215166228207157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 507093.7928781672, 507093.7928781665, 167533.7984119957], 
processed observation next is [1.0, 0.8260869565217391, 0.19984202211690388, 0.9400000000000002, 1.0, 1.0, 0.1825501479767659, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14085938691060199, 0.1408593869106018, 0.2500504453910384], 
reward next is 0.7499, 
noisyNet noise sample is [array([-0.7796482], dtype=float32), 0.20254244]. 
=============================================
[2019-03-26 21:09:13,351] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[73.505066]
 [73.48092 ]
 [73.46737 ]
 [73.35415 ]
 [73.31429 ]], R is [[73.52435303]
 [73.53900146]
 [73.55358124]
 [73.56824493]
 [73.58250427]].
[2019-03-26 21:09:15,263] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 21:09:15,267] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:09:15,269] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:09:15,270] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:09:15,271] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:09:15,272] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:09:15,272] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:09:15,273] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:09:15,274] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:09:15,275] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:09:15,275] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:09:15,294] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run45
[2019-03-26 21:09:15,316] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run45
[2019-03-26 21:09:15,335] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run45
[2019-03-26 21:09:15,336] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run45
[2019-03-26 21:09:15,373] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run45
[2019-03-26 21:09:21,627] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08423373], dtype=float32), 0.06565747]
[2019-03-26 21:09:21,629] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.41666666666667, 78.33333333333333, 1.0, 2.0, 0.3726745707419122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 607374.3786738176, 607374.3786738182, 175496.8364599389]
[2019-03-26 21:09:21,631] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:09:21,634] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.2274894e-20 1.0000000e+00 5.9334120e-19 9.1603874e-17 2.2680303e-24], sampled 0.7960226303789947
[2019-03-26 21:09:26,186] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08423373], dtype=float32), 0.06565747]
[2019-03-26 21:09:26,187] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.63333333333334, 51.66666666666666, 1.0, 2.0, 0.3447390701928989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 554538.010472925, 554538.0104729257, 171315.3028047412]
[2019-03-26 21:09:26,188] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:09:26,190] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.4962744e-20 1.0000000e+00 2.4691060e-19 1.2428922e-16 1.3701623e-24], sampled 0.41441701446384727
[2019-03-26 21:09:26,502] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08423373], dtype=float32), 0.06565747]
[2019-03-26 21:09:26,503] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.8, 74.0, 1.0, 2.0, 0.3719148415018976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 586568.7366534609, 586568.7366534609, 174009.972652377]
[2019-03-26 21:09:26,504] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:09:26,507] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.55083466e-20 1.00000000e+00 6.38868397e-19 1.05954326e-16
 2.55800415e-24], sampled 0.5599087528453603
[2019-03-26 21:10:00,479] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08423373], dtype=float32), 0.06565747]
[2019-03-26 21:10:00,482] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.83898773, 100.0, 1.0, 2.0, 0.4214693611456272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 618229.0601706101, 618229.0601706101, 175955.1709221988]
[2019-03-26 21:10:00,483] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:10:00,485] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.9189102e-21 1.0000000e+00 1.1769468e-19 3.8667415e-17 4.1396965e-25], sampled 0.024168910715453573
[2019-03-26 21:10:27,514] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08423373], dtype=float32), 0.06565747]
[2019-03-26 21:10:27,515] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.22181319666667, 64.14957543666668, 1.0, 2.0, 0.6145498448510377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 858802.6350784826, 858802.6350784826, 203482.4973778971]
[2019-03-26 21:10:27,516] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:10:27,517] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.3263420e-21 1.0000000e+00 6.8362458e-20 4.0901110e-17 2.3356453e-25], sampled 0.046613027292070175
[2019-03-26 21:10:33,293] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08423373], dtype=float32), 0.06565747]
[2019-03-26 21:10:33,293] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.76666666666667, 68.5, 1.0, 2.0, 0.3617181194328698, 0.0, 2.0, 0.0, 1.0, 2.0, 0.628184751444867, 6.911200000000001, 6.9112, 168.912879318952, 1011038.347099405, 1011038.347099404, 243868.3470216112]
[2019-03-26 21:10:33,294] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:10:33,297] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2141772e-12 1.0000000e+00 4.8243718e-12 9.3054968e-09 5.2894672e-16], sampled 0.12112701253297309
[2019-03-26 21:10:56,003] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08423373], dtype=float32), 0.06565747]
[2019-03-26 21:10:56,004] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.33333333333333, 81.5, 1.0, 2.0, 0.8221052527498889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1149007.835626726, 1149007.835626726, 249415.0630614681]
[2019-03-26 21:10:56,007] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:10:56,010] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.1753784e-21 1.0000000e+00 5.0705083e-20 2.2537646e-17 1.2017461e-25], sampled 0.5146798500082697
[2019-03-26 21:11:07,203] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6125 2927449872.7600 1338.0000
[2019-03-26 21:11:07,241] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164071917.9177 1778.0000
[2019-03-26 21:11:07,365] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.3918 2842563638.9128 1131.0000
[2019-03-26 21:11:07,397] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.2105 2779239691.3999 933.0000
[2019-03-26 21:11:07,427] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.0936 3007789820.9736 1766.0000
[2019-03-26 21:11:08,442] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1100000, evaluation results [1100000.0, 7884.168443086554, 3164071917.9176674, 1778.0, 8253.612502082276, 2927449872.7599883, 1338.0, 8659.210464896743, 2779239691.399938, 933.0, 7996.093556430663, 3007789820.97356, 1766.0, 8495.391845542033, 2842563638.9127707, 1131.0]
[2019-03-26 21:11:10,376] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1100904: loss -162.4745
[2019-03-26 21:11:10,378] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1100905: learning rate 0.0000
[2019-03-26 21:11:11,599] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1101536: loss 0.0999
[2019-03-26 21:11:11,601] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1101537: learning rate 0.0000
[2019-03-26 21:11:11,690] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5694098e-21 1.0000000e+00 5.6209617e-20 6.6713758e-17 1.9914527e-25], sum to 1.0000
[2019-03-26 21:11:11,697] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4449
[2019-03-26 21:11:11,702] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 94.0, 1.0, 2.0, 0.3812029617447436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 574572.6535373455, 574572.6535373455, 172403.5456470895], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1458000.0000, 
sim time next is 1458600.0000, 
raw observation next is [22.63333333333333, 94.16666666666667, 1.0, 2.0, 0.3798966029423203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 573246.6561010603, 573246.6561010603, 172305.686990211], 
processed observation next is [0.0, 0.9130434782608695, 0.27172195892575024, 0.9416666666666668, 1.0, 1.0, 0.2528874734244823, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15923518225029454, 0.15923518225029454, 0.25717266714956866], 
reward next is 0.7428, 
noisyNet noise sample is [array([3.3215759], dtype=float32), 0.20806572]. 
=============================================
[2019-03-26 21:11:12,284] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.3897983e-20 1.0000000e+00 1.9568780e-19 7.3900918e-17 1.6164732e-24], sum to 1.0000
[2019-03-26 21:11:12,293] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6329
[2019-03-26 21:11:12,299] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.13333333333333, 88.33333333333334, 1.0, 2.0, 0.357434373157981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 544417.1301215849, 544417.1301215843, 169990.0831217124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1495200.0000, 
sim time next is 1495800.0000, 
raw observation next is [23.35, 87.5, 1.0, 2.0, 0.3626450143454151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 550529.1796307543, 550529.1796307543, 170445.1272456773], 
processed observation next is [0.0, 0.30434782608695654, 0.3056872037914693, 0.875, 1.0, 1.0, 0.23210242692218683, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15292477211965397, 0.15292477211965397, 0.25439571230698105], 
reward next is 0.7456, 
noisyNet noise sample is [array([0.2253707], dtype=float32), -0.21132113]. 
=============================================
[2019-03-26 21:11:14,344] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1102917: loss 0.1231
[2019-03-26 21:11:14,348] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1102917: learning rate 0.0000
[2019-03-26 21:11:17,112] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1104150: loss -167.0652
[2019-03-26 21:11:17,116] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1104153: learning rate 0.0000
[2019-03-26 21:11:17,810] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.1342421e-20 1.0000000e+00 4.8375979e-18 7.7292879e-16 2.2282315e-23], sum to 1.0000
[2019-03-26 21:11:17,818] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5838
[2019-03-26 21:11:17,823] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 89.5, 1.0, 2.0, 0.3064054166652293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 483867.5143219733, 483867.5143219727, 165820.8009257269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1571400.0000, 
sim time next is 1572000.0000, 
raw observation next is [21.6, 89.33333333333333, 1.0, 2.0, 0.307159065139851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 485294.8178840481, 485294.8178840481, 165930.2536523599], 
processed observation next is [1.0, 0.17391304347826086, 0.22274881516587688, 0.8933333333333333, 1.0, 1.0, 0.16525188571066382, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13480411607890225, 0.13480411607890225, 0.24765709500352226], 
reward next is 0.7523, 
noisyNet noise sample is [array([0.02624631], dtype=float32), -0.9367428]. 
=============================================
[2019-03-26 21:11:17,845] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[71.51296 ]
 [71.642746]
 [71.66547 ]
 [71.73228 ]
 [71.77767 ]], R is [[71.34281921]
 [71.38189697]
 [71.42062378]
 [71.45822144]
 [71.49391937]].
[2019-03-26 21:11:18,877] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.2927668e-20 1.0000000e+00 1.1412589e-18 1.4720975e-15 8.5141261e-24], sum to 1.0000
[2019-03-26 21:11:18,880] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4847
[2019-03-26 21:11:18,884] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 88.83333333333334, 1.0, 2.0, 0.3336543243877199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527088.794799645, 527088.794799645, 169094.8504072993], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1573800.0000, 
sim time next is 1574400.0000, 
raw observation next is [21.8, 88.66666666666667, 1.0, 2.0, 0.312807323646386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 493251.869358558, 493251.869358558, 166492.7018573178], 
processed observation next is [1.0, 0.21739130434782608, 0.23222748815165886, 0.8866666666666667, 1.0, 1.0, 0.17205701644142893, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.137014408155155, 0.137014408155155, 0.2484965699362952], 
reward next is 0.7515, 
noisyNet noise sample is [array([-0.51172936], dtype=float32), 0.67802435]. 
=============================================
[2019-03-26 21:11:19,735] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1105322: loss -89.0017
[2019-03-26 21:11:19,746] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1105322: learning rate 0.0000
[2019-03-26 21:11:21,596] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1106154: loss 0.0940
[2019-03-26 21:11:21,600] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1106154: learning rate 0.0000
[2019-03-26 21:11:21,729] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1106215: loss 0.1005
[2019-03-26 21:11:21,731] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1106215: learning rate 0.0000
[2019-03-26 21:11:21,799] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1106246: loss 0.0865
[2019-03-26 21:11:21,804] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1106247: learning rate 0.0000
[2019-03-26 21:11:22,191] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1106417: loss 0.1068
[2019-03-26 21:11:22,195] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1106418: learning rate 0.0000
[2019-03-26 21:11:22,228] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1106437: loss 0.0972
[2019-03-26 21:11:22,234] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1106438: learning rate 0.0000
[2019-03-26 21:11:22,807] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1106693: loss 0.0884
[2019-03-26 21:11:22,809] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1106693: learning rate 0.0000
[2019-03-26 21:11:22,994] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1106776: loss 0.0929
[2019-03-26 21:11:22,996] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1106776: learning rate 0.0000
[2019-03-26 21:11:23,115] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1106829: loss 0.0997
[2019-03-26 21:11:23,116] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1106829: learning rate 0.0000
[2019-03-26 21:11:23,386] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1106946: loss 0.0879
[2019-03-26 21:11:23,389] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1106947: learning rate 0.0000
[2019-03-26 21:11:23,484] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1106992: loss 0.0916
[2019-03-26 21:11:23,490] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1106992: learning rate 0.0000
[2019-03-26 21:11:23,716] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1107093: loss 0.0999
[2019-03-26 21:11:23,721] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1107094: learning rate 0.0000
[2019-03-26 21:11:24,942] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.259951e-21 1.000000e+00 1.933261e-19 3.927574e-17 6.014177e-25], sum to 1.0000
[2019-03-26 21:11:24,952] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3328
[2019-03-26 21:11:24,959] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.78333333333333, 88.5, 1.0, 2.0, 0.9213328693092347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1287776.504167697, 1287776.504167696, 275870.1029602659], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1680600.0000, 
sim time next is 1681200.0000, 
raw observation next is [25.9, 88.0, 1.0, 2.0, 0.9123370336778922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1275195.184950111, 1275195.184950111, 273350.8277725301], 
processed observation next is [1.0, 0.4782608695652174, 0.42654028436018954, 0.88, 1.0, 1.0, 0.8943819682866171, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.35422088470836416, 0.35422088470836416, 0.40798631010825387], 
reward next is 0.5920, 
noisyNet noise sample is [array([1.972801], dtype=float32), 1.7551898]. 
=============================================
[2019-03-26 21:11:28,142] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1109019: loss 0.0022
[2019-03-26 21:11:28,150] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1109022: learning rate 0.0000
[2019-03-26 21:11:28,872] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9967375e-20 1.0000000e+00 4.0806939e-19 2.1319430e-16 1.8628716e-24], sum to 1.0000
[2019-03-26 21:11:28,886] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3599
[2019-03-26 21:11:28,890] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.43333333333333, 88.33333333333334, 1.0, 2.0, 0.8651847732561314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1256650.847859527, 1256650.847859528, 267346.7810243415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1762800.0000, 
sim time next is 1763400.0000, 
raw observation next is [24.36666666666667, 88.16666666666667, 1.0, 2.0, 0.8792083519838492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1281363.709296258, 1281363.709296258, 271862.067511845], 
processed observation next is [1.0, 0.391304347826087, 0.3538704581358612, 0.8816666666666667, 1.0, 1.0, 0.8544678939564447, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.355934363693405, 0.355934363693405, 0.40576427986842534], 
reward next is 0.5942, 
noisyNet noise sample is [array([0.5319212], dtype=float32), -0.286507]. 
=============================================
[2019-03-26 21:11:29,465] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1109615: loss -247.1184
[2019-03-26 21:11:29,466] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1109615: learning rate 0.0000
[2019-03-26 21:11:31,940] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.9210948e-19 1.0000000e+00 4.2474306e-18 5.5901168e-16 4.3689752e-24], sum to 1.0000
[2019-03-26 21:11:31,948] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0031
[2019-03-26 21:11:31,952] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 96.0, 1.0, 2.0, 0.3493305945499476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 535988.9577849462, 535988.9577849468, 169420.9558366583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1828800.0000, 
sim time next is 1829400.0000, 
raw observation next is [21.88333333333333, 96.33333333333333, 1.0, 2.0, 0.3623963527946852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 555663.2742153206, 555663.2742153206, 171050.950247655], 
processed observation next is [1.0, 0.17391304347826086, 0.2361769352290678, 0.9633333333333333, 1.0, 1.0, 0.2318028346923918, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15435090950425573, 0.15435090950425573, 0.25529992574276866], 
reward next is 0.7447, 
noisyNet noise sample is [array([-1.2567357], dtype=float32), 1.6041706]. 
=============================================
[2019-03-26 21:11:32,572] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1111007: loss 27.1940
[2019-03-26 21:11:32,574] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1111007: learning rate 0.0000
[2019-03-26 21:11:35,325] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1112230: loss 0.0031
[2019-03-26 21:11:35,328] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1112231: learning rate 0.0000
[2019-03-26 21:11:37,756] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1113312: loss 0.0027
[2019-03-26 21:11:37,758] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1113312: learning rate 0.0000
[2019-03-26 21:11:39,570] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1114126: loss -100.4852
[2019-03-26 21:11:39,573] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1114126: learning rate 0.0000
[2019-03-26 21:11:39,808] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1114231: loss -297.9898
[2019-03-26 21:11:39,813] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1114233: learning rate 0.0000
[2019-03-26 21:11:39,891] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1114267: loss -152.7678
[2019-03-26 21:11:39,894] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1114269: learning rate 0.0000
[2019-03-26 21:11:40,216] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1114410: loss -324.4153
[2019-03-26 21:11:40,218] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1114410: learning rate 0.0000
[2019-03-26 21:11:40,442] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1114511: loss -102.9969
[2019-03-26 21:11:40,447] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1114514: learning rate 0.0000
[2019-03-26 21:11:40,771] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1114658: loss -5.7543
[2019-03-26 21:11:40,777] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1114659: learning rate 0.0000
[2019-03-26 21:11:40,788] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.839641e-15 1.000000e+00 9.189447e-15 2.650798e-12 7.248585e-19], sum to 1.0000
[2019-03-26 21:11:40,793] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6112
[2019-03-26 21:11:40,800] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 75.0, 1.0, 2.0, 0.861726977892549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1213619.04219943, 1213619.042199431, 260964.5536667316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1947600.0000, 
sim time next is 1948200.0000, 
raw observation next is [27.26666666666667, 74.83333333333333, 1.0, 2.0, 0.9468065285326769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1331721.333333103, 1331721.333333103, 284404.573827854], 
processed observation next is [1.0, 0.5652173913043478, 0.4913112164297, 0.7483333333333333, 1.0, 1.0, 0.9359114801598517, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.36992259259252863, 0.36992259259252863, 0.42448443854903584], 
reward next is 0.5755, 
noisyNet noise sample is [array([0.51665246], dtype=float32), 0.4098943]. 
=============================================
[2019-03-26 21:11:40,863] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1114695: loss -200.9751
[2019-03-26 21:11:40,869] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1114695: learning rate 0.0000
[2019-03-26 21:11:41,045] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1114779: loss -268.3929
[2019-03-26 21:11:41,049] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1114779: learning rate 0.0000
[2019-03-26 21:11:41,378] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1114899: loss -66.1485
[2019-03-26 21:11:41,383] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1114899: learning rate 0.0000
[2019-03-26 21:11:41,515] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1114960: loss -28.0619
[2019-03-26 21:11:41,518] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1114961: learning rate 0.0000
[2019-03-26 21:11:41,699] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1115041: loss -103.9128
[2019-03-26 21:11:41,707] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1115041: learning rate 0.0000
[2019-03-26 21:11:42,135] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.9370489e-20 1.0000000e+00 1.4033119e-18 5.3626900e-16 2.1943462e-24], sum to 1.0000
[2019-03-26 21:11:42,142] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5117
[2019-03-26 21:11:42,149] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.93333333333333, 95.33333333333334, 1.0, 2.0, 0.6431525871204777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 898790.4477961449, 898790.4477961449, 209050.4975111737], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2172000.0000, 
sim time next is 2172600.0000, 
raw observation next is [24.9, 95.5, 1.0, 2.0, 0.6251284712388214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 873591.8153861965, 873591.8153861965, 205511.5342816726], 
processed observation next is [1.0, 0.13043478260869565, 0.3791469194312796, 0.955, 1.0, 1.0, 0.5483475557094234, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24266439316283236, 0.24266439316283236, 0.30673363325622777], 
reward next is 0.6933, 
noisyNet noise sample is [array([-0.25209054], dtype=float32), -1.0422577]. 
=============================================
[2019-03-26 21:11:42,609] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0805990e-20 1.0000000e+00 9.1301322e-19 2.7281076e-16 2.4344482e-24], sum to 1.0000
[2019-03-26 21:11:42,618] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6558
[2019-03-26 21:11:42,623] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.56666666666667, 97.83333333333334, 1.0, 2.0, 0.4458249436070488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 639476.8617077165, 639476.8617077158, 177668.092980041], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1984200.0000, 
sim time next is 1984800.0000, 
raw observation next is [23.63333333333333, 97.66666666666667, 1.0, 2.0, 0.4488983664727622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 642619.5072123181, 642619.5072123181, 177953.8439553231], 
processed observation next is [1.0, 1.0, 0.3191153238546602, 0.9766666666666667, 1.0, 1.0, 0.3360221282804364, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17850541867008837, 0.17850541867008837, 0.26560275217212403], 
reward next is 0.7344, 
noisyNet noise sample is [array([-2.1109333], dtype=float32), 1.8200803]. 
=============================================
[2019-03-26 21:11:43,831] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3811829e-07 9.9861002e-01 3.6557703e-06 1.3859917e-03 4.1230463e-09], sum to 1.0000
[2019-03-26 21:11:43,840] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6473
[2019-03-26 21:11:43,851] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2729021.184997265 W.
[2019-03-26 21:11:43,856] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.03333333333333, 61.33333333333333, 1.0, 2.0, 0.6596403224811663, 1.0, 2.0, 0.6504102007548458, 1.0, 2.0, 1.03, 7.005094550048782, 6.9112, 170.5573041426782, 2729021.184997265, 2661760.699411222, 508883.3497826583], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2389200.0000, 
sim time next is 2389800.0000, 
raw observation next is [33.06666666666667, 61.16666666666666, 1.0, 2.0, 0.9574758162862992, 1.0, 2.0, 0.9574758162862992, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2678226.471455253, 2678226.471455253, 503819.1566545708], 
processed observation next is [1.0, 0.6521739130434783, 0.7661927330173778, 0.6116666666666666, 1.0, 1.0, 0.9487660437184328, 1.0, 1.0, 0.9487660437184328, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7439517976264592, 0.7439517976264592, 0.7519688905292101], 
reward next is 0.2480, 
noisyNet noise sample is [array([-0.9882382], dtype=float32), 0.26333082]. 
=============================================
[2019-03-26 21:11:47,007] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1117406: loss -195.9011
[2019-03-26 21:11:47,008] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1117406: learning rate 0.0000
[2019-03-26 21:11:47,474] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1117613: loss 0.0052
[2019-03-26 21:11:47,479] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1117616: learning rate 0.0000
[2019-03-26 21:11:47,627] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2205896e-20 1.0000000e+00 3.8446750e-19 1.8505824e-17 2.5764544e-24], sum to 1.0000
[2019-03-26 21:11:47,633] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8741
[2019-03-26 21:11:47,640] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 97.0, 1.0, 2.0, 0.460795891596776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 651176.1322495863, 651176.1322495863, 178624.0099571674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2088000.0000, 
sim time next is 2088600.0000, 
raw observation next is [23.96666666666667, 97.16666666666667, 1.0, 2.0, 0.4599709408056562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 650217.9598427864, 650217.9598427871, 178529.635563173], 
processed observation next is [0.0, 0.17391304347826086, 0.33491311216429714, 0.9716666666666667, 1.0, 1.0, 0.34936257928392317, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18061609995632957, 0.18061609995632977, 0.2664621426316015], 
reward next is 0.7335, 
noisyNet noise sample is [array([0.18348984], dtype=float32), 1.0461009]. 
=============================================
[2019-03-26 21:11:49,060] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1192991e-20 1.0000000e+00 1.5357895e-19 2.3498925e-16 7.1363202e-25], sum to 1.0000
[2019-03-26 21:11:49,071] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1849
[2019-03-26 21:11:49,075] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 89.0, 1.0, 2.0, 0.5041720142207456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 704503.9908351148, 704503.9908351141, 184252.7491142351], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2102400.0000, 
sim time next is 2103000.0000, 
raw observation next is [26.5, 88.16666666666667, 1.0, 2.0, 0.5059188884544717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 706945.7951191511, 706945.7951191511, 184529.1445501473], 
processed observation next is [0.0, 0.34782608695652173, 0.4549763033175356, 0.8816666666666667, 1.0, 1.0, 0.4047215523547852, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.196373831977542, 0.196373831977542, 0.27541663365693625], 
reward next is 0.7246, 
noisyNet noise sample is [array([0.35280427], dtype=float32), -2.003962]. 
=============================================
[2019-03-26 21:11:49,091] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.797165]
 [73.78884 ]
 [73.78707 ]
 [73.78059 ]
 [73.77668 ]], R is [[73.79646301]
 [73.78350067]
 [73.77094269]
 [73.75894928]
 [73.74784088]].
[2019-03-26 21:11:50,493] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1118956: loss 0.0122
[2019-03-26 21:11:50,495] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1118957: learning rate 0.0000
[2019-03-26 21:11:54,215] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1120625: loss -110.1231
[2019-03-26 21:11:54,221] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1120626: learning rate 0.0000
[2019-03-26 21:11:56,451] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1121620: loss -89.7093
[2019-03-26 21:11:56,452] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1121620: learning rate 0.0000
[2019-03-26 21:11:57,448] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1122049: loss 0.0220
[2019-03-26 21:11:57,451] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1122051: learning rate 0.0000
[2019-03-26 21:11:57,536] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1122088: loss 0.0238
[2019-03-26 21:11:57,538] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1122088: learning rate 0.0000
[2019-03-26 21:11:57,688] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1122156: loss 0.0214
[2019-03-26 21:11:57,692] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1122156: learning rate 0.0000
[2019-03-26 21:11:57,976] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1122282: loss 0.0196
[2019-03-26 21:11:57,978] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1122283: learning rate 0.0000
[2019-03-26 21:11:58,235] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1122399: loss 0.0232
[2019-03-26 21:11:58,237] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1122399: learning rate 0.0000
[2019-03-26 21:11:58,643] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1122579: loss 0.0249
[2019-03-26 21:11:58,644] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1122579: learning rate 0.0000
[2019-03-26 21:11:58,675] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1122592: loss 0.0237
[2019-03-26 21:11:58,679] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1122593: learning rate 0.0000
[2019-03-26 21:11:58,870] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1122683: loss 0.0250
[2019-03-26 21:11:58,871] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1122683: learning rate 0.0000
[2019-03-26 21:11:59,294] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1122866: loss 0.0189
[2019-03-26 21:11:59,296] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1122866: learning rate 0.0000
[2019-03-26 21:11:59,428] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1122926: loss 0.0189
[2019-03-26 21:11:59,432] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1122928: learning rate 0.0000
[2019-03-26 21:11:59,476] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1122944: loss 0.0211
[2019-03-26 21:11:59,477] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1122944: learning rate 0.0000
[2019-03-26 21:12:03,788] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.4804650e-20 1.0000000e+00 5.7871717e-19 1.3582351e-16 1.0035001e-23], sum to 1.0000
[2019-03-26 21:12:03,797] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9531
[2019-03-26 21:12:03,803] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.26666666666667, 96.33333333333333, 1.0, 2.0, 0.6876930569954549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 961062.8585341, 961062.8585341007, 218212.1327088874], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2521200.0000, 
sim time next is 2521800.0000, 
raw observation next is [26.25, 96.5, 1.0, 2.0, 0.6952171063192489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 971582.6565672379, 971582.6565672379, 219817.1580888292], 
processed observation next is [1.0, 0.17391304347826086, 0.4431279620853081, 0.965, 1.0, 1.0, 0.6327916943605408, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2698840712686772, 0.2698840712686772, 0.32808531058034207], 
reward next is 0.6719, 
noisyNet noise sample is [array([0.42683598], dtype=float32), -0.9593077]. 
=============================================
[2019-03-26 21:12:04,097] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 21:12:04,099] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:12:04,100] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:12:04,101] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:12:04,102] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:12:04,103] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:12:04,104] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:12:04,105] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:12:04,107] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:12:04,107] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:12:04,108] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:12:04,130] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run46
[2019-03-26 21:12:04,151] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run46
[2019-03-26 21:12:04,171] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run46
[2019-03-26 21:12:04,188] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run46
[2019-03-26 21:12:04,189] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run46
[2019-03-26 21:12:17,259] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08201215], dtype=float32), 0.06311699]
[2019-03-26 21:12:17,260] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.270594135, 64.15411118, 1.0, 2.0, 0.2840846769133793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 458095.3695167052, 458095.3695167052, 164143.8999177077]
[2019-03-26 21:12:17,261] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:12:17,263] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5697527e-19 1.0000000e+00 2.2090086e-18 4.1309289e-16 1.6227574e-23], sampled 0.11582998648524812
[2019-03-26 21:12:39,772] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08201215], dtype=float32), 0.06311699]
[2019-03-26 21:12:39,773] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.63225233, 70.87513911, 1.0, 2.0, 0.4042144713144424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 594509.865865903, 594509.8658659023, 173770.720325679]
[2019-03-26 21:12:39,774] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:12:39,779] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.6938877e-16 1.0000000e+00 2.1865016e-15 2.1228744e-12 3.2699096e-20], sampled 0.13640703014818167
[2019-03-26 21:12:43,299] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08201215], dtype=float32), 0.06311699]
[2019-03-26 21:12:43,301] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.33133863, 87.37679442, 1.0, 2.0, 0.4408639729878844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 644356.5954360266, 644356.5954360266, 178455.4182700059]
[2019-03-26 21:12:43,302] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:12:43,305] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.7107897e-20 1.0000000e+00 7.8917409e-19 2.7626885e-16 3.3543872e-24], sampled 0.8826415539776241
[2019-03-26 21:13:14,621] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08201215], dtype=float32), 0.06311699]
[2019-03-26 21:13:14,622] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [38.45, 39.33333333333334, 1.0, 2.0, 0.8056385544306505, 1.0, 1.0, 0.8056385544306505, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 169.0403247858759, 2253146.542325126, 2253146.542325127, 422341.0406056926]
[2019-03-26 21:13:14,622] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:13:14,624] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.11266725e-10 9.99999404e-01 3.13836374e-10 6.43024748e-07
 5.47603954e-14], sampled 0.9194603331183135
[2019-03-26 21:13:14,626] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2253146.542325126 W.
[2019-03-26 21:13:43,085] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08201215], dtype=float32), 0.06311699]
[2019-03-26 21:13:43,087] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.16666666666666, 72.0, 1.0, 2.0, 0.5233238836344907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731275.0378983855, 731275.0378983861, 187330.8146423479]
[2019-03-26 21:13:43,088] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:13:43,090] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.8719139e-20 1.0000000e+00 4.3704868e-19 2.9092225e-16 2.6674937e-24], sampled 0.18297139070266433
[2019-03-26 21:13:45,756] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08201215], dtype=float32), 0.06311699]
[2019-03-26 21:13:45,757] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.6, 95.0, 1.0, 2.0, 0.6630818087068466, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.976563347141798, 6.9112, 168.9125143333222, 1823468.435480222, 1777097.548774178, 377878.2414525484]
[2019-03-26 21:13:45,760] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:13:45,763] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.0836569e-18 1.0000000e+00 4.7519478e-17 1.7402156e-14 8.1421462e-22], sampled 0.7327040503288037
[2019-03-26 21:13:45,764] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1823468.435480222 W.
[2019-03-26 21:13:58,985] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.1682 2927441262.2667 1338.0000
[2019-03-26 21:13:59,403] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6750 3164089889.8551 1778.0000
[2019-03-26 21:13:59,629] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5752 2842451949.6408 1131.0000
[2019-03-26 21:13:59,706] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.7903 2779331027.2517 933.0000
[2019-03-26 21:13:59,728] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2222 3007669257.3412 1766.0000
[2019-03-26 21:14:00,745] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1125000, evaluation results [1125000.0, 7882.675018132028, 3164089889.8551016, 1778.0, 8252.16817576188, 2927441262.2666926, 1338.0, 8659.790305226421, 2779331027.2517376, 933.0, 7998.222170733027, 3007669257.3412185, 1766.0, 8497.575228127671, 2842451949.640752, 1131.0]
[2019-03-26 21:14:00,835] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1125052: loss 0.1955
[2019-03-26 21:14:00,838] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1125053: learning rate 0.0000
[2019-03-26 21:14:02,512] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1125829: loss -220.0051
[2019-03-26 21:14:02,513] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1125829: learning rate 0.0000
[2019-03-26 21:14:04,927] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1127124: loss -363.1436
[2019-03-26 21:14:04,934] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1127125: learning rate 0.0000
[2019-03-26 21:14:05,874] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.8151867e-20 1.0000000e+00 1.2349281e-17 8.5932916e-15 8.8395266e-23], sum to 1.0000
[2019-03-26 21:14:05,882] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3975
[2019-03-26 21:14:05,887] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.63333333333333, 80.0, 1.0, 2.0, 0.5447403130070768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 761212.3526648957, 761212.3526648963, 190902.9292745833], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2425800.0000, 
sim time next is 2426400.0000, 
raw observation next is [28.6, 80.0, 1.0, 2.0, 0.5435166482092623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 759501.8095895732, 759501.8095895732, 190695.2003592339], 
processed observation next is [1.0, 0.08695652173913043, 0.5545023696682465, 0.8, 1.0, 1.0, 0.45002005808344847, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21097272488599256, 0.21097272488599256, 0.2846197020287073], 
reward next is 0.7154, 
noisyNet noise sample is [array([0.05705239], dtype=float32), -1.0052617]. 
=============================================
[2019-03-26 21:14:05,962] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.2443713e-20 1.0000000e+00 2.0922533e-18 1.2310249e-16 1.7524577e-24], sum to 1.0000
[2019-03-26 21:14:05,975] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6380
[2019-03-26 21:14:05,982] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4745087563260036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 663170.6458928146, 663170.6458928146, 179714.9691434588], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2622600.0000, 
sim time next is 2623200.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4749715298666664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 663817.185979863, 663817.185979863, 179783.9465901326], 
processed observation next is [0.0, 0.34782608695652173, 0.4312796208530806, 0.84, 1.0, 1.0, 0.3674355781526102, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1843936627721842, 0.1843936627721842, 0.26833424864198896], 
reward next is 0.7317, 
noisyNet noise sample is [array([-1.3148242], dtype=float32), -1.5401071]. 
=============================================
[2019-03-26 21:14:06,879] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.6010795e-12 1.0000000e+00 7.2761103e-11 1.9272264e-08 1.3672499e-15], sum to 1.0000
[2019-03-26 21:14:06,886] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4560
[2019-03-26 21:14:06,895] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1994242.139152862 W.
[2019-03-26 21:14:06,901] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.4, 89.0, 1.0, 2.0, 0.4754361523061441, 1.0, 2.0, 0.4754361523061441, 1.0, 1.0, 0.8127101034304197, 6.9112, 6.9112, 170.5573041426782, 1994242.139152862, 1994242.139152862, 396343.6476665935], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2469600.0000, 
sim time next is 2470200.0000, 
raw observation next is [26.51666666666667, 88.5, 1.0, 2.0, 0.6808141627902243, 1.0, 2.0, 0.6808141627902243, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1903727.045357011, 1903727.045357011, 366013.9674520502], 
processed observation next is [1.0, 0.6086956521739131, 0.45576619273301755, 0.885, 1.0, 1.0, 0.6154387503496679, 1.0, 1.0, 0.6154387503496679, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5288130681547253, 0.5288130681547253, 0.5462895036597764], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9248359], dtype=float32), -0.99838907]. 
=============================================
[2019-03-26 21:14:07,256] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1128170: loss 0.1746
[2019-03-26 21:14:07,257] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1128170: learning rate 0.0000
[2019-03-26 21:14:09,431] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1129133: loss 0.2024
[2019-03-26 21:14:09,433] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1129134: learning rate 0.0000
[2019-03-26 21:14:09,557] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2745114e-15 1.0000000e+00 3.7720844e-14 4.3349217e-11 1.2134875e-19], sum to 1.0000
[2019-03-26 21:14:09,568] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3470
[2019-03-26 21:14:09,572] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.76666666666667, 86.33333333333334, 1.0, 2.0, 0.539127674020312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 753366.5495954424, 753366.5495954424, 189954.4600145585], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2485200.0000, 
sim time next is 2485800.0000, 
raw observation next is [27.7, 87.0, 1.0, 2.0, 0.5415113386926087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 756698.6227808386, 756698.6227808392, 190356.3363476636], 
processed observation next is [1.0, 0.782608695652174, 0.5118483412322274, 0.87, 1.0, 1.0, 0.4476040225212153, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2101940618835663, 0.21019406188356646, 0.2841139348472591], 
reward next is 0.7159, 
noisyNet noise sample is [array([1.3644946], dtype=float32), -0.6022117]. 
=============================================
[2019-03-26 21:14:11,298] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7770820e-17 1.0000000e+00 8.3029147e-17 2.5438973e-14 1.2588789e-21], sum to 1.0000
[2019-03-26 21:14:11,308] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1052
[2019-03-26 21:14:11,316] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1918526.389447049 W.
[2019-03-26 21:14:11,325] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.9, 90.33333333333333, 1.0, 2.0, 0.7310119590452874, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.989612224914922, 6.9112, 168.9124894639532, 1918526.389447049, 1862898.212164945, 392127.7423929257], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2536800.0000, 
sim time next is 2537400.0000, 
raw observation next is [27.0, 89.66666666666667, 1.0, 2.0, 0.7369929846412463, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.988198495477901, 6.9112, 168.9124345354923, 1926896.337112496, 1872271.123140178, 393535.9332281854], 
processed observation next is [1.0, 0.34782608695652173, 0.4786729857819906, 0.8966666666666667, 1.0, 1.0, 0.6831240778810196, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007699849547790105, 0.0, 0.8294373820163925, 0.5352489825312489, 0.5200753119833827, 0.5873670645196797], 
reward next is 0.0276, 
noisyNet noise sample is [array([-0.16886137], dtype=float32), -1.2949921]. 
=============================================
[2019-03-26 21:14:12,062] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1130307: loss -293.4342
[2019-03-26 21:14:12,066] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1130308: learning rate 0.0000
[2019-03-26 21:14:12,086] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1130315: loss -135.6891
[2019-03-26 21:14:12,092] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1130315: learning rate 0.0000
[2019-03-26 21:14:12,204] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1130370: loss -287.0211
[2019-03-26 21:14:12,206] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1130371: learning rate 0.0000
[2019-03-26 21:14:12,554] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1130524: loss 67.5226
[2019-03-26 21:14:12,556] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1130525: learning rate 0.0000
[2019-03-26 21:14:12,633] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1130560: loss -288.5346
[2019-03-26 21:14:12,638] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1130560: learning rate 0.0000
[2019-03-26 21:14:12,811] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1130637: loss -230.8622
[2019-03-26 21:14:12,813] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1130637: learning rate 0.0000
[2019-03-26 21:14:13,106] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1130766: loss -241.5662
[2019-03-26 21:14:13,108] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1130766: learning rate 0.0000
[2019-03-26 21:14:13,187] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1130803: loss -117.2999
[2019-03-26 21:14:13,188] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1130803: learning rate 0.0000
[2019-03-26 21:14:13,724] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1131043: loss -153.0150
[2019-03-26 21:14:13,729] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1131043: learning rate 0.0000
[2019-03-26 21:14:13,820] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1131087: loss -188.8347
[2019-03-26 21:14:13,821] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1131087: learning rate 0.0000
[2019-03-26 21:14:13,871] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1131110: loss -213.1124
[2019-03-26 21:14:13,875] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1131110: learning rate 0.0000
[2019-03-26 21:14:13,963] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.2705778e-20 1.0000000e+00 7.4479601e-19 2.4937222e-15 3.8083191e-24], sum to 1.0000
[2019-03-26 21:14:13,976] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1656
[2019-03-26 21:14:13,984] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 90.0, 1.0, 2.0, 0.5143747832153845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 718765.6378186536, 718765.6378186536, 185878.5886857517], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2586600.0000, 
sim time next is 2587200.0000, 
raw observation next is [26.0, 90.33333333333334, 1.0, 2.0, 0.5116815054405028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 715000.8983977824, 715000.8983977824, 185446.2512504732], 
processed observation next is [1.0, 0.9565217391304348, 0.4312796208530806, 0.9033333333333334, 1.0, 1.0, 0.41166446438614795, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19861136066605065, 0.19861136066605065, 0.27678544962757196], 
reward next is 0.7232, 
noisyNet noise sample is [array([0.8385967], dtype=float32), -0.1423633]. 
=============================================
[2019-03-26 21:14:16,291] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0155746e-20 1.0000000e+00 3.7344982e-19 3.0936986e-16 2.0824845e-24], sum to 1.0000
[2019-03-26 21:14:16,299] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3622
[2019-03-26 21:14:16,307] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4758616036700493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 665060.7513070958, 665060.7513070963, 179916.7981240377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2624400.0000, 
sim time next is 2625000.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4757732070636331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 664937.0254277509, 664937.0254277509, 179903.5648397444], 
processed observation next is [0.0, 0.391304347826087, 0.4312796208530806, 0.84, 1.0, 1.0, 0.3684014542935339, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18470472928548637, 0.18470472928548637, 0.2685127833429021], 
reward next is 0.7315, 
noisyNet noise sample is [array([-0.06488045], dtype=float32), -0.06427762]. 
=============================================
[2019-03-26 21:14:16,322] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[73.516975]
 [73.507   ]
 [73.50525 ]
 [73.500694]
 [73.500275]], R is [[73.52774048]
 [73.52393341]
 [73.52024841]
 [73.516716  ]
 [73.51331329]].
[2019-03-26 21:14:17,251] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1132608: loss 0.0024
[2019-03-26 21:14:17,253] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1132608: learning rate 0.0000
[2019-03-26 21:14:19,308] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1133524: loss 0.2736
[2019-03-26 21:14:19,311] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1133526: learning rate 0.0000
[2019-03-26 21:14:19,675] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9187156e-20 1.0000000e+00 1.7820781e-18 3.1633324e-16 7.5016861e-25], sum to 1.0000
[2019-03-26 21:14:19,682] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5765
[2019-03-26 21:14:19,686] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.540977909640847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 807130.6990653153, 807130.6990653153, 196616.662729004], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3070200.0000, 
sim time next is 3070800.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.4581022426458296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 683473.5253452257, 683473.5253452263, 182696.7856311444], 
processed observation next is [1.0, 0.5652173913043478, 0.28909952606635075, 0.94, 1.0, 1.0, 0.347111135717867, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18985375704034047, 0.18985375704034063, 0.272681769598723], 
reward next is 0.7273, 
noisyNet noise sample is [array([-0.62417924], dtype=float32), 0.42048186]. 
=============================================
[2019-03-26 21:14:22,499] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1134954: loss 0.2475
[2019-03-26 21:14:22,504] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1134955: learning rate 0.0000
[2019-03-26 21:14:24,833] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1135992: loss 0.0029
[2019-03-26 21:14:24,834] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1135992: learning rate 0.0000
[2019-03-26 21:14:26,993] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1136949: loss 0.0028
[2019-03-26 21:14:26,996] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1136949: learning rate 0.0000
[2019-03-26 21:14:30,008] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1138291: loss 0.2521
[2019-03-26 21:14:30,009] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1138291: learning rate 0.0000
[2019-03-26 21:14:30,121] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1138339: loss 0.2598
[2019-03-26 21:14:30,125] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1138340: learning rate 0.0000
[2019-03-26 21:14:30,180] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1138367: loss 0.2494
[2019-03-26 21:14:30,182] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1138367: learning rate 0.0000
[2019-03-26 21:14:30,613] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1138545: loss 0.2599
[2019-03-26 21:14:30,616] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1138546: learning rate 0.0000
[2019-03-26 21:14:30,622] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1138549: loss 0.2551
[2019-03-26 21:14:30,623] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1138549: learning rate 0.0000
[2019-03-26 21:14:30,855] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1138650: loss 0.2601
[2019-03-26 21:14:30,857] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1138651: learning rate 0.0000
[2019-03-26 21:14:31,124] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1138772: loss 0.2516
[2019-03-26 21:14:31,125] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1138772: learning rate 0.0000
[2019-03-26 21:14:31,393] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1138889: loss 0.2461
[2019-03-26 21:14:31,395] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1138889: learning rate 0.0000
[2019-03-26 21:14:31,748] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1139050: loss 0.2772
[2019-03-26 21:14:31,751] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1139050: learning rate 0.0000
[2019-03-26 21:14:31,897] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1139113: loss 0.2681
[2019-03-26 21:14:31,900] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1139114: learning rate 0.0000
[2019-03-26 21:14:32,008] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.7006758e-19 1.0000000e+00 2.7776597e-18 8.6623375e-16 1.2211099e-23], sum to 1.0000
[2019-03-26 21:14:32,019] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2451
[2019-03-26 21:14:32,027] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3481086805393849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 536252.434237533, 536252.4342375337, 169509.2681583941], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2857200.0000, 
sim time next is 2857800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3479205549480015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 535962.7626764473, 535962.7626764467, 169485.5977016161], 
processed observation next is [1.0, 0.043478260869565216, 0.2417061611374408, 0.94, 1.0, 1.0, 0.21436211439518252, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14887854518790203, 0.14887854518790186, 0.2529635786591285], 
reward next is 0.7470, 
noisyNet noise sample is [array([0.744723], dtype=float32), -0.021987408]. 
=============================================
[2019-03-26 21:14:32,060] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1139188: loss 0.2776
[2019-03-26 21:14:32,061] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1139188: learning rate 0.0000
[2019-03-26 21:14:33,994] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2423439e-19 1.0000000e+00 3.6254334e-18 4.3397421e-16 4.8355722e-24], sum to 1.0000
[2019-03-26 21:14:34,005] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0558
[2019-03-26 21:14:34,012] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.6897703147367458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1062221.276120694, 1062221.276120694, 230933.8717244141], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2909400.0000, 
sim time next is 2910000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.6798689586545278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1046995.521519257, 1046995.521519256, 228620.2719340856], 
processed observation next is [1.0, 0.6956521739130435, 0.2417061611374408, 0.94, 1.0, 1.0, 0.614299950186178, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2908320893109047, 0.2908320893109045, 0.3412242864687845], 
reward next is 0.6588, 
noisyNet noise sample is [array([-1.1428281], dtype=float32), -1.0826429]. 
=============================================
[2019-03-26 21:14:34,031] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[71.913925]
 [71.88842 ]
 [71.86121 ]
 [71.895164]
 [71.89322 ]], R is [[71.90898132]
 [71.84521484]
 [71.78936005]
 [71.72806549]
 [71.66543579]].
[2019-03-26 21:14:34,739] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.8885420e-21 1.0000000e+00 2.2430752e-19 5.7102064e-17 2.0200462e-24], sum to 1.0000
[2019-03-26 21:14:34,746] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9108
[2019-03-26 21:14:34,755] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 99.00000000000001, 1.0, 2.0, 0.3431875476310522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 534162.7870504323, 534162.7870504316, 169493.8753872201], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2916600.0000, 
sim time next is 2917200.0000, 
raw observation next is [21.0, 98.0, 1.0, 2.0, 0.3380407253222273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527771.1459022759, 527771.1459022759, 169022.2824738064], 
processed observation next is [1.0, 0.782608695652174, 0.19431279620853087, 0.98, 1.0, 1.0, 0.20245870520750275, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14660309608396555, 0.14660309608396555, 0.2522720633937409], 
reward next is 0.7477, 
noisyNet noise sample is [array([0.08762418], dtype=float32), 0.5569878]. 
=============================================
[2019-03-26 21:14:35,553] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1140743: loss 0.1928
[2019-03-26 21:14:35,558] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1140744: learning rate 0.0000
[2019-03-26 21:14:37,233] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.1507136e-19 1.0000000e+00 1.1269355e-17 2.8132056e-15 1.7861094e-23], sum to 1.0000
[2019-03-26 21:14:37,239] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1141497: loss 0.0022
[2019-03-26 21:14:37,241] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1141497: learning rate 0.0000
[2019-03-26 21:14:37,250] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7306
[2019-03-26 21:14:37,255] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.314803195304462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 497805.83781817, 497805.8378181707, 166861.4792520773], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2954400.0000, 
sim time next is 2955000.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.3160220621309831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 499731.7658908868, 499731.7658908868, 167005.2323440549], 
processed observation next is [1.0, 0.17391304347826086, 0.19431279620853087, 0.94, 1.0, 1.0, 0.17593019533853385, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1388143794141352, 0.1388143794141352, 0.24926154081202226], 
reward next is 0.7507, 
noisyNet noise sample is [array([-0.5861486], dtype=float32), -1.1047441]. 
=============================================
[2019-03-26 21:14:37,264] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[70.17336 ]
 [70.25808 ]
 [70.343796]
 [70.38755 ]
 [70.45644 ]], R is [[70.21414948]
 [70.26296234]
 [70.31189728]
 [70.36051178]
 [70.40692139]].
[2019-03-26 21:14:40,445] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1142917: loss 0.0027
[2019-03-26 21:14:40,449] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1142918: learning rate 0.0000
[2019-03-26 21:14:43,166] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1144135: loss 0.2172
[2019-03-26 21:14:43,167] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1144135: learning rate 0.0000
[2019-03-26 21:14:45,339] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1145106: loss 0.1874
[2019-03-26 21:14:45,342] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1145108: learning rate 0.0000
[2019-03-26 21:14:47,245] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.8770510e-19 1.0000000e+00 3.7260620e-18 2.9712806e-15 1.8757293e-23], sum to 1.0000
[2019-03-26 21:14:47,253] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5517
[2019-03-26 21:14:47,260] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 89.0, 1.0, 2.0, 0.6353656039245327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 959454.6949367183, 959454.6949367183, 216482.4968872991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3144000.0000, 
sim time next is 3144600.0000, 
raw observation next is [23.5, 89.0, 1.0, 2.0, 0.663191505572691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 996052.9649350531, 996052.9649350538, 221913.1927502466], 
processed observation next is [1.0, 0.391304347826087, 0.31279620853080575, 0.89, 1.0, 1.0, 0.5942066332201097, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2766813791486259, 0.27668137914862606, 0.33121372052275616], 
reward next is 0.6688, 
noisyNet noise sample is [array([-0.62046444], dtype=float32), -0.23261677]. 
=============================================
[2019-03-26 21:14:47,871] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1146213: loss 0.0026
[2019-03-26 21:14:47,875] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1146214: learning rate 0.0000
[2019-03-26 21:14:47,924] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1146237: loss 0.0027
[2019-03-26 21:14:47,926] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1146237: learning rate 0.0000
[2019-03-26 21:14:48,086] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1146308: loss 0.0026
[2019-03-26 21:14:48,092] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1146309: learning rate 0.0000
[2019-03-26 21:14:48,242] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1146378: loss 0.0028
[2019-03-26 21:14:48,245] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1146380: learning rate 0.0000
[2019-03-26 21:14:48,476] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1146482: loss 0.0024
[2019-03-26 21:14:48,480] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1146483: learning rate 0.0000
[2019-03-26 21:14:48,736] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1146595: loss 0.0025
[2019-03-26 21:14:48,740] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1146595: learning rate 0.0000
[2019-03-26 21:14:49,058] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1146740: loss 0.0026
[2019-03-26 21:14:49,062] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1146741: learning rate 0.0000
[2019-03-26 21:14:49,142] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1146777: loss 0.0025
[2019-03-26 21:14:49,145] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1146777: learning rate 0.0000
[2019-03-26 21:14:49,468] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1146920: loss 0.0023
[2019-03-26 21:14:49,470] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1146920: learning rate 0.0000
[2019-03-26 21:14:49,637] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1146996: loss 0.0024
[2019-03-26 21:14:49,640] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1146997: learning rate 0.0000
[2019-03-26 21:14:49,902] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1147112: loss 0.0023
[2019-03-26 21:14:49,903] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1147112: learning rate 0.0000
[2019-03-26 21:14:51,234] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.6001440e-18 1.0000000e+00 2.2386667e-17 2.3666500e-14 8.2011198e-23], sum to 1.0000
[2019-03-26 21:14:51,243] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7546
[2019-03-26 21:14:51,250] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 87.33333333333333, 1.0, 2.0, 0.4983102221022667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 696310.3400400049, 696310.3400400049, 183332.0542456736], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3177600.0000, 
sim time next is 3178200.0000, 
raw observation next is [26.16666666666667, 88.16666666666667, 1.0, 2.0, 0.498213576120285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 696175.2481932254, 696175.2481932254, 183316.855880317], 
processed observation next is [1.0, 0.782608695652174, 0.4391785150078992, 0.8816666666666667, 1.0, 1.0, 0.3954380435184157, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19338201338700706, 0.19338201338700706, 0.27360724758256266], 
reward next is 0.7264, 
noisyNet noise sample is [array([-0.39081255], dtype=float32), 1.1973318]. 
=============================================
[2019-03-26 21:14:54,639] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1149232: loss -436.6985
[2019-03-26 21:14:54,643] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1149234: learning rate 0.0000
[2019-03-26 21:14:55,335] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1149544: loss 0.1554
[2019-03-26 21:14:55,339] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1149544: learning rate 0.0000
[2019-03-26 21:14:55,511] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6139379e-20 1.0000000e+00 6.3160571e-20 1.8719832e-16 6.4222867e-25], sum to 1.0000
[2019-03-26 21:14:55,519] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4619
[2019-03-26 21:14:55,526] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5180707140281979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723931.9355733166, 723931.9355733166, 186475.836349417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3274800.0000, 
sim time next is 3275400.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5175730678558684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 723236.3073694353, 723236.3073694347, 186395.2683746903], 
processed observation next is [0.0, 0.9130434782608695, 0.5260663507109005, 0.79, 1.0, 1.0, 0.41876273235646794, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2008989742692876, 0.20089897426928743, 0.2782018930965527], 
reward next is 0.7218, 
noisyNet noise sample is [array([-0.08183684], dtype=float32), -0.45231926]. 
=============================================
[2019-03-26 21:14:55,922] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1365227e-06 9.7251928e-01 1.1242893e-06 2.7478373e-02 4.8523461e-09], sum to 1.0000
[2019-03-26 21:14:55,933] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9499
[2019-03-26 21:14:55,944] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2800618.551845738 W.
[2019-03-26 21:14:55,948] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 63.00000000000001, 1.0, 2.0, 1.001182444703939, 1.0, 2.0, 1.001182444703939, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2800618.551845738, 2800618.551845738, 529701.4728043308], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3774000.0000, 
sim time next is 3774600.0000, 
raw observation next is [33.0, 63.0, 1.0, 2.0, 0.9961382449526914, 1.0, 2.0, 0.9961382449526914, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2786492.620000559, 2786492.620000559, 526657.3601819159], 
processed observation next is [1.0, 0.6956521739130435, 0.7630331753554502, 0.63, 1.0, 1.0, 0.9953472830755319, 1.0, 1.0, 0.9953472830755319, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.774025727777933, 0.774025727777933, 0.7860557614655461], 
reward next is 0.2139, 
noisyNet noise sample is [array([-1.0199122], dtype=float32), 0.31244037]. 
=============================================
[2019-03-26 21:14:56,387] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 21:14:56,390] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:14:56,390] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:14:56,392] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:14:56,392] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:14:56,393] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:14:56,394] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:14:56,395] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:14:56,394] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:14:56,397] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:14:56,402] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:14:56,414] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run47
[2019-03-26 21:14:56,415] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run47
[2019-03-26 21:14:56,434] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run47
[2019-03-26 21:14:56,454] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run47
[2019-03-26 21:14:56,495] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run47
[2019-03-26 21:15:07,693] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08314534], dtype=float32), 0.06380846]
[2019-03-26 21:15:07,694] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [15.98225671833334, 91.21345976166667, 1.0, 2.0, 0.2339363136289077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 391331.8288856575, 391331.8288856575, 136294.9437794629]
[2019-03-26 21:15:07,694] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:15:07,696] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.3702263e-19 1.0000000e+00 3.6321191e-18 6.8414766e-16 2.0393963e-23], sampled 0.585909266968696
[2019-03-26 21:15:56,269] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08314534], dtype=float32), 0.06380846]
[2019-03-26 21:15:56,271] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.66666666666667, 75.66666666666667, 1.0, 2.0, 0.9325697108926609, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.980062429401851, 6.9112, 168.9124916666427, 2200624.679014638, 2151771.435978201, 444169.14330097]
[2019-03-26 21:15:56,272] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:15:56,274] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.0333448e-13 1.0000000e+00 8.4712960e-13 5.7718313e-10 1.6898674e-16], sampled 0.14032722413930354
[2019-03-26 21:15:56,276] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2200624.679014638 W.
[2019-03-26 21:16:10,030] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08314534], dtype=float32), 0.06380846]
[2019-03-26 21:16:10,032] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.0, 68.0, 1.0, 2.0, 0.7210927110861041, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.979425870269182, 6.9112, 168.9124964513644, 1904645.373688675, 1856243.72499579, 390231.4358330076]
[2019-03-26 21:16:10,033] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:16:10,035] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.2241704e-14 1.0000000e+00 3.6190774e-14 2.5845236e-11 5.7651403e-18], sampled 0.207939268167339
[2019-03-26 21:16:10,036] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1904645.373688675 W.
[2019-03-26 21:16:35,733] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08314534], dtype=float32), 0.06380846]
[2019-03-26 21:16:35,735] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.55, 54.0, 1.0, 2.0, 0.6698932672736555, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.005973746065319, 6.9112, 168.9117063779472, 1832999.66323427, 1765764.403529832, 378247.3213527398]
[2019-03-26 21:16:35,736] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:16:35,739] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.7258905e-17 1.0000000e+00 1.9570527e-16 2.4852204e-13 1.1589912e-20], sampled 0.33708938922001475
[2019-03-26 21:16:35,741] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1832999.66323427 W.
[2019-03-26 21:16:51,822] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0954 2842517464.9746 1131.0000
[2019-03-26 21:16:51,842] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6857 2927400807.7850 1338.0000
[2019-03-26 21:16:51,860] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.6544 2779248917.7285 933.0000
[2019-03-26 21:16:51,936] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.1633 3164105803.0955 1778.0000
[2019-03-26 21:16:52,058] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2146 3007648997.1407 1766.0000
[2019-03-26 21:16:53,077] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1150000, evaluation results [1150000.0, 7881.163293656913, 3164105803.0955105, 1778.0, 8253.68573338827, 2927400807.784972, 1338.0, 8660.654361620163, 2779248917.728524, 933.0, 7998.214591785093, 3007648997.140727, 1766.0, 8496.095384209508, 2842517464.974608, 1131.0]
[2019-03-26 21:16:54,157] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7999011e-20 1.0000000e+00 1.1830828e-18 5.6082263e-17 2.6017384e-24], sum to 1.0000
[2019-03-26 21:16:54,166] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7355
[2019-03-26 21:16:54,174] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333334, 70.66666666666667, 1.0, 2.0, 0.495279537346645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 692074.0541447345, 692074.0541447351, 182859.9811153516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3315000.0000, 
sim time next is 3315600.0000, 
raw observation next is [29.0, 70.0, 1.0, 2.0, 0.4972080054590089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 694769.66157284, 694769.6615728405, 183159.9795494174], 
processed observation next is [0.0, 0.391304347826087, 0.5734597156398105, 0.7, 1.0, 1.0, 0.3942265126012155, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1929915726591222, 0.19299157265912237, 0.2733731038051006], 
reward next is 0.7266, 
noisyNet noise sample is [array([1.1357682], dtype=float32), -0.2027638]. 
=============================================
[2019-03-26 21:16:55,182] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1151002: loss 0.1578
[2019-03-26 21:16:55,184] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1151003: learning rate 0.0000
[2019-03-26 21:16:58,225] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1152558: loss -362.8440
[2019-03-26 21:16:58,228] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1152558: learning rate 0.0000
[2019-03-26 21:16:59,664] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7861344e-18 1.0000000e+00 2.6769515e-18 5.3420070e-16 1.3643528e-23], sum to 1.0000
[2019-03-26 21:16:59,673] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2206
[2019-03-26 21:16:59,679] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 89.0, 1.0, 2.0, 0.8402982449068611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1174449.165960978, 1174449.165960978, 254045.2440379111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3394200.0000, 
sim time next is 3394800.0000, 
raw observation next is [28.0, 89.0, 1.0, 2.0, 0.8601459056015435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1202205.102822362, 1202205.102822362, 259212.7197674778], 
processed observation next is [1.0, 0.30434782608695654, 0.5260663507109005, 0.89, 1.0, 1.0, 0.831501091086197, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.33394586189510056, 0.33394586189510056, 0.38688465636936986], 
reward next is 0.6131, 
noisyNet noise sample is [array([1.4518446], dtype=float32), -0.13403946]. 
=============================================
[2019-03-26 21:17:00,482] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1153500: loss -342.4329
[2019-03-26 21:17:00,484] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1153502: learning rate 0.0000
[2019-03-26 21:17:01,969] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1154158: loss 0.1091
[2019-03-26 21:17:01,971] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1154158: learning rate 0.0000
[2019-03-26 21:17:01,989] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1154169: loss 0.1182
[2019-03-26 21:17:01,992] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1154169: learning rate 0.0000
[2019-03-26 21:17:02,114] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1154225: loss 0.1209
[2019-03-26 21:17:02,116] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1154225: learning rate 0.0000
[2019-03-26 21:17:02,240] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1154281: loss 0.1243
[2019-03-26 21:17:02,242] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1154281: learning rate 0.0000
[2019-03-26 21:17:02,530] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1154416: loss 0.1216
[2019-03-26 21:17:02,532] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1154416: learning rate 0.0000
[2019-03-26 21:17:02,736] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1154504: loss 0.1295
[2019-03-26 21:17:02,747] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1154507: learning rate 0.0000
[2019-03-26 21:17:02,945] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1154596: loss 0.1313
[2019-03-26 21:17:02,947] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1154596: learning rate 0.0000
[2019-03-26 21:17:03,247] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1154732: loss 0.1296
[2019-03-26 21:17:03,250] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1154732: learning rate 0.0000
[2019-03-26 21:17:03,333] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8981820e-21 1.0000000e+00 2.8198813e-20 5.6323244e-17 3.5721400e-26], sum to 1.0000
[2019-03-26 21:17:03,343] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5980
[2019-03-26 21:17:03,351] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.5, 75.0, 1.0, 2.0, 0.6145677356389444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 858827.6466668961, 858827.6466668961, 203491.7290027667], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3969000.0000, 
sim time next is 3969600.0000, 
raw observation next is [31.33333333333333, 76.33333333333333, 1.0, 2.0, 0.6164178685432905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 861414.1632499291, 861414.1632499298, 203844.9507847506], 
processed observation next is [0.0, 0.9565217391304348, 0.6840442338072668, 0.7633333333333333, 1.0, 1.0, 0.5378528536666151, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2392817120138692, 0.23928171201386939, 0.3042461952011203], 
reward next is 0.6958, 
noisyNet noise sample is [array([-0.5646816], dtype=float32), -0.29759014]. 
=============================================
[2019-03-26 21:17:03,466] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1154826: loss 0.1286
[2019-03-26 21:17:03,469] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1154827: learning rate 0.0000
[2019-03-26 21:17:03,643] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1154905: loss 0.1141
[2019-03-26 21:17:03,645] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1154905: learning rate 0.0000
[2019-03-26 21:17:03,955] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1155045: loss 0.1101
[2019-03-26 21:17:03,958] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1155045: learning rate 0.0000
[2019-03-26 21:17:08,732] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1157168: loss 0.0307
[2019-03-26 21:17:08,736] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1157170: learning rate 0.0000
[2019-03-26 21:17:10,157] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1157801: loss -81.2947
[2019-03-26 21:17:10,159] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1157802: learning rate 0.0000
[2019-03-26 21:17:12,039] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.3323283e-19 1.0000000e+00 1.6020955e-17 1.7359863e-13 1.8347961e-23], sum to 1.0000
[2019-03-26 21:17:12,051] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6541
[2019-03-26 21:17:12,056] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 72.0, 1.0, 2.0, 0.5456852345414839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 762533.2465050385, 762533.2465050385, 191064.4909884494], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3786000.0000, 
sim time next is 3786600.0000, 
raw observation next is [30.16666666666666, 73.5, 1.0, 2.0, 0.5498634409458047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 768373.927986347, 768373.9279863464, 191778.24675427], 
processed observation next is [1.0, 0.8260869565217391, 0.6287519747235385, 0.735, 1.0, 1.0, 0.45766679632024665, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2134372022184297, 0.21343720221842957, 0.2862361891854776], 
reward next is 0.7138, 
noisyNet noise sample is [array([-0.8814897], dtype=float32), -0.32042375]. 
=============================================
[2019-03-26 21:17:12,365] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.7813583e-21 1.0000000e+00 1.1732800e-19 1.1236571e-15 2.4357567e-25], sum to 1.0000
[2019-03-26 21:17:12,372] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4591
[2019-03-26 21:17:12,376] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666666, 72.33333333333333, 1.0, 2.0, 0.605403271208467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 846015.6657879984, 846015.665787999, 201757.0875099954], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3966000.0000, 
sim time next is 3966600.0000, 
raw observation next is [31.83333333333333, 71.66666666666667, 1.0, 2.0, 0.6070122641293909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 848265.0371713643, 848265.037171365, 202059.8077364328], 
processed observation next is [0.0, 0.9130434782608695, 0.7077409162717218, 0.7166666666666667, 1.0, 1.0, 0.5265208001558926, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23562917699204564, 0.23562917699204583, 0.3015818025916907], 
reward next is 0.6984, 
noisyNet noise sample is [array([-1.6978403], dtype=float32), 0.87026495]. 
=============================================
[2019-03-26 21:17:13,047] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1159085: loss -212.4903
[2019-03-26 21:17:13,049] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1159086: learning rate 0.0000
[2019-03-26 21:17:13,435] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1669818e-19 1.0000000e+00 1.6303624e-18 4.7467167e-15 1.0885912e-23], sum to 1.0000
[2019-03-26 21:17:13,441] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4637
[2019-03-26 21:17:13,450] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.00000000000001, 1.0, 2.0, 1.039523179617277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 169.0622343713466, 1453087.07360302, 1453087.07360302, 311222.9894951631], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3636600.0000, 
sim time next is 3637200.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.973138033165379, 6.9112, 168.9123061405828, 1497725.823755476, 1453785.020472417, 311346.8370194196], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.79, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.006193803316537938, 0.0, 0.8294367515386075, 0.4160349510431878, 0.4038291723534491, 0.4646967716707755], 
reward next is 0.2256, 
noisyNet noise sample is [array([-0.00416555], dtype=float32), -1.0803295]. 
=============================================
[2019-03-26 21:17:15,847] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1160328: loss 0.0255
[2019-03-26 21:17:15,848] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1160328: learning rate 0.0000
[2019-03-26 21:17:16,106] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7898744e-06 9.4895720e-01 2.6284020e-05 5.1012687e-02 2.2346317e-08], sum to 1.0000
[2019-03-26 21:17:16,113] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1307
[2019-03-26 21:17:16,120] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2498680.047028154 W.
[2019-03-26 21:17:16,125] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 59.0, 1.0, 2.0, 0.8933514289166565, 1.0, 2.0, 0.8933514289166565, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2498680.047028154, 2498680.047028154, 467876.2459856867], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3682800.0000, 
sim time next is 3683400.0000, 
raw observation next is [33.0, 59.0, 1.0, 2.0, 0.9622614782816608, 1.0, 2.0, 0.9622614782816608, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2691627.220941617, 2691627.220941617, 506595.0215412601], 
processed observation next is [1.0, 0.6521739130434783, 0.7630331753554502, 0.59, 1.0, 1.0, 0.9545319015441696, 1.0, 1.0, 0.9545319015441696, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7476742280393381, 0.7476742280393381, 0.756111972449642], 
reward next is 0.2439, 
noisyNet noise sample is [array([0.52369756], dtype=float32), 0.7742521]. 
=============================================
[2019-03-26 21:17:16,267] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6121976e-05 8.0225056e-01 6.4277119e-05 1.9766884e-01 2.1634388e-07], sum to 1.0000
[2019-03-26 21:17:16,275] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2541
[2019-03-26 21:17:16,285] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2697879.316262793 W.
[2019-03-26 21:17:16,290] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 59.0, 1.0, 2.0, 0.6448121911419555, 1.0, 2.0, 0.6429961350852402, 1.0, 1.0, 1.03, 7.005093381052125, 6.9112, 170.5573041426782, 2697879.316262793, 2630619.668076609, 504462.2766538461], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3686400.0000, 
sim time next is 3687000.0000, 
raw observation next is [32.83333333333334, 60.33333333333334, 1.0, 2.0, 0.8432702294253719, 1.0, 2.0, 0.8432702294253719, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2358472.082334416, 2358472.082334417, 441487.66080842], 
processed observation next is [1.0, 0.6956521739130435, 0.7551342812006324, 0.6033333333333334, 1.0, 1.0, 0.8111689511149058, 1.0, 1.0, 0.8111689511149058, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6551311339817822, 0.6551311339817825, 0.6589368071767463], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9699948], dtype=float32), 1.0836142]. 
=============================================
[2019-03-26 21:17:16,301] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[17.220102]
 [18.34777 ]
 [17.041965]
 [18.03089 ]
 [19.737537]], R is [[18.620821  ]
 [18.43461227]
 [18.47410774]
 [18.28936768]
 [18.10647392]].
[2019-03-26 21:17:16,790] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7120623e-06 9.2760926e-01 5.8744004e-06 7.2383136e-02 8.9968362e-09], sum to 1.0000
[2019-03-26 21:17:16,796] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2652
[2019-03-26 21:17:16,802] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2805294.833809647 W.
[2019-03-26 21:17:16,806] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.0, 61.0, 1.0, 2.0, 0.6959562889454433, 1.0, 2.0, 0.6685681839869841, 1.0, 1.0, 1.03, 7.005097413315289, 6.9112, 170.5573041426782, 2805294.833809647, 2738032.297149336, 520054.4530666978], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3677400.0000, 
sim time next is 3678000.0000, 
raw observation next is [33.0, 60.33333333333333, 1.0, 2.0, 0.6955951330512271, 1.0, 2.0, 0.6683876060398761, 1.0, 2.0, 1.03, 7.005097384838887, 6.9112, 170.5573041426782, 2804536.282871166, 2737273.766609659, 519940.7953161272], 
processed observation next is [1.0, 0.5652173913043478, 0.7630331753554502, 0.6033333333333333, 1.0, 1.0, 0.6332471482544905, 1.0, 1.0, 0.6004669952287663, 1.0, 1.0, 1.0365853658536586, 0.00938973848388871, 0.0, 0.8375144448122397, 0.7790378563531016, 0.7603538240582386, 0.7760310377852645], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9105157], dtype=float32), 1.1521305]. 
=============================================
[2019-03-26 21:17:16,835] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[21.846184]
 [24.001783]
 [23.075274]
 [24.587591]
 [22.724005]], R is [[20.72406769]
 [20.51682663]
 [20.31165886]
 [20.1085434 ]
 [19.90745735]].
[2019-03-26 21:17:16,946] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5568084e-16 1.0000000e+00 2.6857111e-15 2.1004335e-11 3.3114072e-21], sum to 1.0000
[2019-03-26 21:17:16,955] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7270
[2019-03-26 21:17:16,964] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 79.0, 1.0, 2.0, 0.5508000066866207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 769683.1501883166, 769683.1501883172, 191938.2722912116], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3697200.0000, 
sim time next is 3697800.0000, 
raw observation next is [29.0, 78.16666666666667, 1.0, 2.0, 0.5485338291444588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 766515.270746748, 766515.2707467487, 191549.6587717301], 
processed observation next is [1.0, 0.8260869565217391, 0.5734597156398105, 0.7816666666666667, 1.0, 1.0, 0.4560648543909142, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21292090854076332, 0.2129209085407635, 0.28589501309213444], 
reward next is 0.7141, 
noisyNet noise sample is [array([1.4336455], dtype=float32), -2.0818212]. 
=============================================
[2019-03-26 21:17:17,822] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1161198: loss 0.0315
[2019-03-26 21:17:17,825] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1161199: learning rate 0.0000
[2019-03-26 21:17:20,143] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1162216: loss -412.3802
[2019-03-26 21:17:20,146] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1162216: learning rate 0.0000
[2019-03-26 21:17:20,192] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1162238: loss -296.0158
[2019-03-26 21:17:20,197] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1162238: learning rate 0.0000
[2019-03-26 21:17:20,522] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1162383: loss -467.0630
[2019-03-26 21:17:20,524] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1162383: learning rate 0.0000
[2019-03-26 21:17:20,565] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1162403: loss -398.0273
[2019-03-26 21:17:20,569] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1162403: learning rate 0.0000
[2019-03-26 21:17:20,673] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1162449: loss -120.0203
[2019-03-26 21:17:20,676] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1162449: learning rate 0.0000
[2019-03-26 21:17:20,778] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1162499: loss -553.7234
[2019-03-26 21:17:20,780] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1162499: learning rate 0.0000
[2019-03-26 21:17:21,218] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1162688: loss -327.8951
[2019-03-26 21:17:21,220] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1162688: learning rate 0.0000
[2019-03-26 21:17:21,429] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1162781: loss -550.2480
[2019-03-26 21:17:21,432] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1162781: learning rate 0.0000
[2019-03-26 21:17:21,555] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1162840: loss -341.3045
[2019-03-26 21:17:21,559] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1162840: learning rate 0.0000
[2019-03-26 21:17:21,717] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1162910: loss -415.9772
[2019-03-26 21:17:21,721] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1162910: learning rate 0.0000
[2019-03-26 21:17:22,068] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1163063: loss -145.4347
[2019-03-26 21:17:22,070] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1163063: learning rate 0.0000
[2019-03-26 21:17:26,610] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3917739e-20 1.0000000e+00 2.1866308e-19 1.1930007e-15 3.8451786e-24], sum to 1.0000
[2019-03-26 21:17:26,620] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4045
[2019-03-26 21:17:26,624] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.33333333333334, 54.0, 1.0, 2.0, 0.5662677183640833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 791305.6474213669, 791305.6474213663, 194630.0383783326], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3864000.0000, 
sim time next is 3864600.0000, 
raw observation next is [34.0, 54.5, 1.0, 2.0, 0.5566991877508232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777929.6332983342, 777929.6332983342, 192956.6862147729], 
processed observation next is [0.0, 0.7391304347826086, 0.8104265402843602, 0.545, 1.0, 1.0, 0.46590263584436525, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21609156480509284, 0.21609156480509284, 0.28799505405189985], 
reward next is 0.7120, 
noisyNet noise sample is [array([0.7405603], dtype=float32), -0.27021682]. 
=============================================
[2019-03-26 21:17:27,157] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1165328: loss -419.5912
[2019-03-26 21:17:27,159] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1165329: learning rate 0.0000
[2019-03-26 21:17:27,829] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1165630: loss 0.0248
[2019-03-26 21:17:27,830] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1165630: learning rate 0.0000
[2019-03-26 21:17:30,897] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1166997: loss 0.0272
[2019-03-26 21:17:30,903] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1166997: learning rate 0.0000
[2019-03-26 21:17:34,391] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.5629383e-10 9.9999893e-01 9.5106334e-10 1.0617861e-06 5.0192055e-13], sum to 1.0000
[2019-03-26 21:17:34,401] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2088
[2019-03-26 21:17:34,410] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1720176.957998069 W.
[2019-03-26 21:17:34,415] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.6152205062356659, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.95481197737118, 6.9112, 168.9126122941608, 1720176.957998069, 1689237.183292734, 367408.8123819258], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3991800.0000, 
sim time next is 3992400.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.591859104004734, 1.0, 1.0, 0.591859104004734, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1654794.336752699, 1654794.336752699, 331272.8453299826], 
processed observation next is [1.0, 0.21739130434782608, 0.5734597156398105, 0.84, 1.0, 1.0, 0.5082639807285951, 1.0, 0.5, 0.5082639807285951, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.45966509354241636, 0.45966509354241636, 0.49443708258206354], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.34489375], dtype=float32), 1.1907568]. 
=============================================
[2019-03-26 21:17:34,537] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1168626: loss -229.4070
[2019-03-26 21:17:34,541] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1168627: learning rate 0.0000
[2019-03-26 21:17:36,553] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1169523: loss -189.2306
[2019-03-26 21:17:36,555] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1169524: learning rate 0.0000
[2019-03-26 21:17:38,012] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1170169: loss 0.0392
[2019-03-26 21:17:38,018] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1170170: learning rate 0.0000
[2019-03-26 21:17:38,062] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1170190: loss 0.0462
[2019-03-26 21:17:38,065] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1170190: learning rate 0.0000
[2019-03-26 21:17:38,201] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1170252: loss 0.0295
[2019-03-26 21:17:38,201] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1170252: learning rate 0.0000
[2019-03-26 21:17:38,354] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1170325: loss 0.0444
[2019-03-26 21:17:38,357] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1170325: learning rate 0.0000
[2019-03-26 21:17:38,415] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1170345: loss 0.0290
[2019-03-26 21:17:38,417] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1170346: learning rate 0.0000
[2019-03-26 21:17:38,482] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1170378: loss 0.0223
[2019-03-26 21:17:38,485] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1170379: learning rate 0.0000
[2019-03-26 21:17:39,065] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1170637: loss 0.0450
[2019-03-26 21:17:39,066] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1170637: learning rate 0.0000
[2019-03-26 21:17:39,351] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1170760: loss 0.0424
[2019-03-26 21:17:39,352] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1170761: learning rate 0.0000
[2019-03-26 21:17:39,412] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1170788: loss 0.0285
[2019-03-26 21:17:39,415] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1170790: learning rate 0.0000
[2019-03-26 21:17:39,494] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1170826: loss 0.0342
[2019-03-26 21:17:39,496] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1170827: learning rate 0.0000
[2019-03-26 21:17:39,975] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1171039: loss 0.0272
[2019-03-26 21:17:39,977] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1171039: learning rate 0.0000
[2019-03-26 21:17:40,287] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4176856e-15 1.0000000e+00 3.5221491e-15 4.8436233e-12 3.3180473e-20], sum to 1.0000
[2019-03-26 21:17:40,296] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4179
[2019-03-26 21:17:40,306] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2176614.887170687 W.
[2019-03-26 21:17:40,314] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.66666666666666, 79.83333333333334, 1.0, 2.0, 0.7783057437052899, 1.0, 2.0, 0.7783057437052899, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2176614.887170687, 2176614.887170687, 409453.4675258832], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4092600.0000, 
sim time next is 4093200.0000, 
raw observation next is [30.0, 79.0, 1.0, 2.0, 0.5013982465696953, 1.0, 2.0, 0.5013982465696953, 1.0, 1.0, 0.8707629393576196, 6.9112, 6.9112, 170.5573041426782, 2103248.422233628, 2103248.422233628, 416114.8325798362], 
processed observation next is [1.0, 0.391304347826087, 0.6208530805687204, 0.79, 1.0, 1.0, 0.3992749958671028, 1.0, 1.0, 0.3992749958671028, 1.0, 0.5, 0.8423938284849019, 0.0, 0.0, 0.8375144448122397, 0.5842356728426745, 0.5842356728426745, 0.621066914298263], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2384093], dtype=float32), 0.029048774]. 
=============================================
[2019-03-26 21:17:44,088] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.3766407e-20 1.0000000e+00 8.2349620e-19 9.2700743e-15 1.0661970e-23], sum to 1.0000
[2019-03-26 21:17:44,097] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1616
[2019-03-26 21:17:44,103] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.624745264154756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 873056.0788470854, 873056.0788470854, 205446.8751922994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4318800.0000, 
sim time next is 4319400.0000, 
raw observation next is [31.0, 79.0, 1.0, 2.0, 0.624147732083174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 872220.7092239243, 872220.7092239243, 205331.2684898376], 
processed observation next is [1.0, 1.0, 0.6682464454976303, 0.79, 1.0, 1.0, 0.5471659422688843, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.242283530339979, 0.242283530339979, 0.3064645798355785], 
reward next is 0.6935, 
noisyNet noise sample is [array([1.1886986], dtype=float32), 0.09815001]. 
=============================================
[2019-03-26 21:17:44,898] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1173232: loss 0.0393
[2019-03-26 21:17:44,903] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1173232: learning rate 0.0000
[2019-03-26 21:17:46,540] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1173958: loss -254.8239
[2019-03-26 21:17:46,541] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1173958: learning rate 0.0000
[2019-03-26 21:17:48,876] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 21:17:48,878] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:17:48,879] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:17:48,879] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:17:48,881] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:17:48,882] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:17:48,883] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:17:48,881] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:17:48,883] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:17:48,885] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:17:48,887] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:17:48,912] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run48
[2019-03-26 21:17:48,933] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run48
[2019-03-26 21:17:48,935] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run48
[2019-03-26 21:17:48,954] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run48
[2019-03-26 21:17:49,002] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run48
[2019-03-26 21:18:06,572] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08135712], dtype=float32), 0.06147834]
[2019-03-26 21:18:06,573] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [20.95, 85.5, 1.0, 2.0, 0.2851543967414766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 461129.2041853706, 461129.2041853706, 164343.2593572697]
[2019-03-26 21:18:06,574] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:18:06,577] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.7849619e-19 1.0000000e+00 1.9048075e-18 7.1769483e-16 5.8306331e-24], sampled 0.23371435371162774
[2019-03-26 21:18:56,091] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08135712], dtype=float32), 0.06147834]
[2019-03-26 21:18:56,091] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.66666666666667, 84.0, 1.0, 2.0, 0.5419766475752494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 757349.0692028189, 757349.0692028189, 190433.6967397708]
[2019-03-26 21:18:56,093] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:18:56,097] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0746757e-20 1.0000000e+00 1.1070700e-19 3.5051383e-16 3.0939914e-25], sampled 0.7339798905317283
[2019-03-26 21:19:36,638] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08135712], dtype=float32), 0.06147834]
[2019-03-26 21:19:36,640] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.76666666666667, 64.83333333333334, 1.0, 2.0, 0.8172139290730722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1142167.845330982, 1142167.845330982, 248186.9486041588]
[2019-03-26 21:19:36,640] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:19:36,644] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1549055e-18 1.0000000e+00 1.8070586e-17 7.8173043e-14 1.6376886e-23], sampled 0.2743631948242995
[2019-03-26 21:19:39,334] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08135712], dtype=float32), 0.06147834]
[2019-03-26 21:19:39,334] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.76966357, 91.42620937, 1.0, 2.0, 0.427940346170008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 627325.5793359153, 627325.5793359153, 176822.6645436213]
[2019-03-26 21:19:39,335] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:19:39,340] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.7467106e-20 1.0000000e+00 6.5784454e-19 1.2042808e-15 2.7591806e-24], sampled 0.9915637973527189
[2019-03-26 21:19:41,521] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08135712], dtype=float32), 0.06147834]
[2019-03-26 21:19:41,523] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.1082463, 87.12824193166668, 1.0, 2.0, 0.6009707311001595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 839819.0013384251, 839819.0013384244, 200927.1487270634]
[2019-03-26 21:19:41,525] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:19:41,527] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.5882512e-20 1.0000000e+00 2.5343790e-19 6.8099713e-16 6.9361261e-25], sampled 0.44584938176248834
[2019-03-26 21:19:44,042] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.1279 2779303888.4386 933.0000
[2019-03-26 21:19:44,095] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.9850 2842661141.0203 1131.0000
[2019-03-26 21:19:44,360] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5374 3007672604.7148 1766.0000
[2019-03-26 21:19:44,383] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.4067 2927264152.9822 1338.0000
[2019-03-26 21:19:44,443] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7878.5101 3164366437.3076 1776.0000
[2019-03-26 21:19:45,457] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1175000, evaluation results [1175000.0, 7878.510112814466, 3164366437.307597, 1776.0, 8254.406660643592, 2927264152.9821725, 1338.0, 8659.127917113585, 2779303888.438552, 933.0, 7997.537410079355, 3007672604.7147675, 1766.0, 8495.985009183636, 2842661141.020265, 1131.0]
[2019-03-26 21:19:45,515] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1175034: loss -132.3944
[2019-03-26 21:19:45,518] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1175035: learning rate 0.0000
[2019-03-26 21:19:48,110] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1176420: loss 0.2533
[2019-03-26 21:19:48,113] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1176422: learning rate 0.0000
[2019-03-26 21:19:49,983] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1177257: loss 0.0483
[2019-03-26 21:19:49,986] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1177258: learning rate 0.0000
[2019-03-26 21:19:51,980] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0366701e-13 1.0000000e+00 9.5781120e-13 5.4959770e-10 4.6701625e-17], sum to 1.0000
[2019-03-26 21:19:51,991] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2301
[2019-03-26 21:19:52,001] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1660813.92158735 W.
[2019-03-26 21:19:52,005] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 0.594010421204663, 1.0, 1.0, 0.594010421204663, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1660813.92158735, 1660813.92158735, 332063.9003500919], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4336200.0000, 
sim time next is 4336800.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 0.5071177965672004, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8806959062191979, 6.9112, 6.9112, 168.9129564187548, 1417716.326384359, 1417716.326384359, 312064.2457245051], 
processed observation next is [1.0, 0.17391304347826086, 0.5734597156398105, 0.89, 1.0, 1.0, 0.40616601996048235, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.854507202706339, 0.0, 0.0, 0.8294399447021306, 0.393810090662322, 0.393810090662322, 0.46576753093209716], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.15226136], dtype=float32), -0.12221882]. 
=============================================
[2019-03-26 21:19:52,351] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1178304: loss -327.7415
[2019-03-26 21:19:52,352] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1178305: learning rate 0.0000
[2019-03-26 21:19:52,356] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1178307: loss -170.5114
[2019-03-26 21:19:52,357] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1178307: learning rate 0.0000
[2019-03-26 21:19:52,388] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1178319: loss -111.2752
[2019-03-26 21:19:52,393] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1178321: learning rate 0.0000
[2019-03-26 21:19:52,581] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1178405: loss -137.1037
[2019-03-26 21:19:52,583] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1178406: learning rate 0.0000
[2019-03-26 21:19:52,588] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1178408: loss -150.7440
[2019-03-26 21:19:52,589] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1178408: learning rate 0.0000
[2019-03-26 21:19:52,627] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1178423: loss -276.4549
[2019-03-26 21:19:52,631] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1178424: learning rate 0.0000
[2019-03-26 21:19:53,217] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1178685: loss -299.2583
[2019-03-26 21:19:53,219] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1178685: learning rate 0.0000
[2019-03-26 21:19:53,418] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7102305e-06 9.8985213e-01 1.0527839e-06 1.0144073e-02 2.5393680e-09], sum to 1.0000
[2019-03-26 21:19:53,425] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2914
[2019-03-26 21:19:53,435] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3367833.139217023 W.
[2019-03-26 21:19:53,441] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.83333333333334, 71.66666666666667, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.550518623400177, 6.9112, 170.5573041426782, 3367833.139217023, 2909863.203456585, 550147.9737788067], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4355400.0000, 
sim time next is 4356000.0000, 
raw observation next is [34.0, 71.0, 1.0, 2.0, 0.9330811356586278, 1.0, 2.0, 0.7871306073435763, 1.0, 1.0, 1.03, 7.005116117588326, 6.9112, 170.5573041426782, 3303437.610754651, 3236161.675462722, 605065.5681524237], 
processed observation next is [1.0, 0.43478260869565216, 0.8104265402843602, 0.71, 1.0, 1.0, 0.9193748622393106, 1.0, 1.0, 0.7435308522211763, 1.0, 0.5, 1.0365853658536586, 0.009391611758832585, 0.0, 0.8375144448122397, 0.9176215585429586, 0.898933798739645, 0.9030829375409309], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6928713], dtype=float32), -0.28478438]. 
=============================================
[2019-03-26 21:19:53,453] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[20.669   ]
 [20.330753]
 [19.768883]
 [20.111933]
 [22.595285]], R is [[18.16444588]
 [17.98280144]
 [17.80297279]
 [17.84174347]
 [17.66332626]].
[2019-03-26 21:19:53,454] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1178786: loss -150.8948
[2019-03-26 21:19:53,456] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1178786: learning rate 0.0000
[2019-03-26 21:19:53,606] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1178853: loss -160.7012
[2019-03-26 21:19:53,608] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1178854: learning rate 0.0000
[2019-03-26 21:19:53,632] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1178864: loss -200.6031
[2019-03-26 21:19:53,636] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1178865: learning rate 0.0000
[2019-03-26 21:19:54,076] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1179063: loss -277.0827
[2019-03-26 21:19:54,079] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1179063: learning rate 0.0000
[2019-03-26 21:19:56,749] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0559290e-19 1.0000000e+00 2.5031441e-18 4.9609102e-15 1.3710093e-24], sum to 1.0000
[2019-03-26 21:19:56,754] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9182
[2019-03-26 21:19:56,761] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 84.0, 1.0, 2.0, 0.6167573076257186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 861888.7054186263, 861888.705418627, 203909.6718430076], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4407000.0000, 
sim time next is 4407600.0000, 
raw observation next is [30.0, 84.0, 1.0, 2.0, 0.6162785628958777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861219.4114177788, 861219.4114177788, 203818.1714228774], 
processed observation next is [0.0, 0.0, 0.6208530805687204, 0.84, 1.0, 1.0, 0.537685015537202, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23922761428271633, 0.23922761428271633, 0.30420622600429464], 
reward next is 0.6958, 
noisyNet noise sample is [array([1.2130746], dtype=float32), 0.21703821]. 
=============================================
[2019-03-26 21:19:58,985] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1181250: loss -138.0988
[2019-03-26 21:19:58,988] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1181251: learning rate 0.0000
[2019-03-26 21:20:00,230] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1181806: loss 0.0879
[2019-03-26 21:20:00,234] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1181807: learning rate 0.0000
[2019-03-26 21:20:02,588] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.7133850e-21 1.0000000e+00 2.9677050e-20 1.4653064e-16 2.5959573e-25], sum to 1.0000
[2019-03-26 21:20:02,594] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2573
[2019-03-26 21:20:02,598] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.83333333333334, 1.0, 2.0, 0.498187785142159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 696139.1975420427, 696139.1975420427, 183312.3870787389], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4525800.0000, 
sim time next is 4526400.0000, 
raw observation next is [28.0, 75.66666666666667, 1.0, 2.0, 0.5004519591862049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 699304.0666094151, 699304.0666094158, 183666.8470487834], 
processed observation next is [0.0, 0.391304347826087, 0.5260663507109005, 0.7566666666666667, 1.0, 1.0, 0.398134890585789, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19425112961372643, 0.19425112961372662, 0.27412962246087075], 
reward next is 0.7259, 
noisyNet noise sample is [array([-1.6714308], dtype=float32), 1.6551375]. 
=============================================
[2019-03-26 21:20:02,684] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1182889: loss 0.0308
[2019-03-26 21:20:02,685] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1182889: learning rate 0.0000
[2019-03-26 21:20:03,627] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.0904482e-20 1.0000000e+00 3.7923964e-19 2.4085752e-16 4.2606412e-25], sum to 1.0000
[2019-03-26 21:20:03,636] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1597
[2019-03-26 21:20:03,643] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 89.0, 1.0, 2.0, 0.4888727929782466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 683118.7735822961, 683118.7735822955, 181871.2613208176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5028600.0000, 
sim time next is 5029200.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.4941889482615396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 690549.6347464543, 690549.6347464537, 182690.9289405063], 
processed observation next is [0.0, 0.21739130434782608, 0.4312796208530806, 0.89, 1.0, 1.0, 0.3905890942910115, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1918193429851262, 0.19181934298512604, 0.27267302826941237], 
reward next is 0.7273, 
noisyNet noise sample is [array([2.4007027], dtype=float32), 1.8352677]. 
=============================================
[2019-03-26 21:20:04,498] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.2628326e-07 9.7232902e-01 8.7416134e-07 2.7669556e-02 2.1962552e-09], sum to 1.0000
[2019-03-26 21:20:04,509] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1884
[2019-03-26 21:20:04,516] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2639772.41901484 W.
[2019-03-26 21:20:04,521] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.66666666666667, 68.33333333333333, 1.0, 2.0, 0.6291619061905167, 1.0, 2.0, 0.6291619061905167, 1.0, 1.0, 1.03, 6.981627221812754, 6.9112, 170.5573041426782, 2639772.41901484, 2589322.535234144, 498794.4969622501], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4722600.0000, 
sim time next is 4723200.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.9663251823490009, 1.0, 2.0, 0.9663251823490009, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2703006.465926885, 2703006.465926884, 508969.4170372624], 
processed observation next is [1.0, 0.6956521739130435, 0.7156398104265403, 0.67, 1.0, 1.0, 0.959427930540965, 1.0, 1.0, 0.959427930540965, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7508351294241348, 0.7508351294241346, 0.7596558463242723], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7553476], dtype=float32), -0.7313865]. 
=============================================
[2019-03-26 21:20:06,491] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1184588: loss -129.9301
[2019-03-26 21:20:06,496] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1184588: learning rate 0.0000
[2019-03-26 21:20:08,345] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1185414: loss -125.5257
[2019-03-26 21:20:08,348] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1185414: learning rate 0.0000
[2019-03-26 21:20:08,821] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.9763456e-20 1.0000000e+00 2.4645809e-18 2.1663520e-15 6.4008647e-24], sum to 1.0000
[2019-03-26 21:20:08,831] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0798
[2019-03-26 21:20:08,836] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 78.16666666666667, 1.0, 2.0, 0.4892636336620337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 683665.0844578402, 683665.0844578402, 181930.6123048576], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4755000.0000, 
sim time next is 4755600.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.4879558388627915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 681837.0708440433, 681837.070844044, 181730.1153975545], 
processed observation next is [1.0, 0.043478260869565216, 0.4786729857819906, 0.79, 1.0, 1.0, 0.383079323931074, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18939918634556757, 0.18939918634556777, 0.27123897820530524], 
reward next is 0.7288, 
noisyNet noise sample is [array([0.6234858], dtype=float32), -2.0768561]. 
=============================================
[2019-03-26 21:20:10,066] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1186179: loss 0.1245
[2019-03-26 21:20:10,068] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1186180: learning rate 0.0000
[2019-03-26 21:20:10,136] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1186210: loss 0.0987
[2019-03-26 21:20:10,138] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1186210: learning rate 0.0000
[2019-03-26 21:20:10,204] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1186237: loss 0.1544
[2019-03-26 21:20:10,205] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1186239: learning rate 0.0000
[2019-03-26 21:20:10,305] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1186285: loss 0.1456
[2019-03-26 21:20:10,310] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1186286: learning rate 0.0000
[2019-03-26 21:20:10,342] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1186300: loss 0.0312
[2019-03-26 21:20:10,346] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1186300: learning rate 0.0000
[2019-03-26 21:20:10,425] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1186337: loss 0.0257
[2019-03-26 21:20:10,428] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1186337: learning rate 0.0000
[2019-03-26 21:20:11,259] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1186705: loss 0.1745
[2019-03-26 21:20:11,261] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1186706: learning rate 0.0000
[2019-03-26 21:20:11,329] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1186738: loss 0.0830
[2019-03-26 21:20:11,331] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1186738: learning rate 0.0000
[2019-03-26 21:20:11,544] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1186830: loss 0.3108
[2019-03-26 21:20:11,551] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1186832: learning rate 0.0000
[2019-03-26 21:20:11,649] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1186883: loss 0.1906
[2019-03-26 21:20:11,650] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1186883: learning rate 0.0000
[2019-03-26 21:20:12,217] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1187130: loss 0.0685
[2019-03-26 21:20:12,219] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1187130: learning rate 0.0000
[2019-03-26 21:20:16,820] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1189171: loss 13.1180
[2019-03-26 21:20:16,823] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1189171: learning rate 0.0000
[2019-03-26 21:20:18,577] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1189959: loss -116.6965
[2019-03-26 21:20:18,580] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1189959: learning rate 0.0000
[2019-03-26 21:20:18,590] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.6658716e-20 1.0000000e+00 1.1434677e-19 6.3100736e-16 3.3146500e-24], sum to 1.0000
[2019-03-26 21:20:18,598] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3051
[2019-03-26 21:20:18,603] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333333, 72.66666666666667, 1.0, 2.0, 0.5296395360667537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740103.3907889776, 740103.3907889769, 188370.2028500197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5165400.0000, 
sim time next is 5166000.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.52713651146288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 736604.5218805672, 736604.5218805678, 187956.8702118441], 
processed observation next is [0.0, 0.8260869565217391, 0.5734597156398105, 0.74, 1.0, 1.0, 0.4302849535697349, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20461236718904643, 0.2046123671890466, 0.28053264210723], 
reward next is 0.7195, 
noisyNet noise sample is [array([-0.5371444], dtype=float32), 0.11752178]. 
=============================================
[2019-03-26 21:20:18,616] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[72.07735 ]
 [72.057655]
 [72.017265]
 [71.99903 ]
 [71.97342 ]], R is [[72.11763763]
 [72.11531067]
 [72.11244202]
 [72.10907745]
 [72.10516357]].
[2019-03-26 21:20:20,868] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1190973: loss -159.4863
[2019-03-26 21:20:20,871] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1190973: learning rate 0.0000
[2019-03-26 21:20:23,991] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1192361: loss 18.5482
[2019-03-26 21:20:23,994] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1192362: learning rate 0.0000
[2019-03-26 21:20:25,904] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1193218: loss 19.9943
[2019-03-26 21:20:25,909] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1193219: learning rate 0.0000
[2019-03-26 21:20:28,034] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1194169: loss -159.6589
[2019-03-26 21:20:28,037] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1194169: learning rate 0.0000
[2019-03-26 21:20:28,085] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1194188: loss -144.3388
[2019-03-26 21:20:28,088] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1194189: learning rate 0.0000
[2019-03-26 21:20:28,296] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1194285: loss -125.4435
[2019-03-26 21:20:28,303] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1194285: learning rate 0.0000
[2019-03-26 21:20:28,316] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1194295: loss -125.5099
[2019-03-26 21:20:28,319] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1194295: learning rate 0.0000
[2019-03-26 21:20:28,411] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1194334: loss -159.6824
[2019-03-26 21:20:28,414] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1194334: learning rate 0.0000
[2019-03-26 21:20:28,549] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1194396: loss -125.4485
[2019-03-26 21:20:28,555] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1194400: learning rate 0.0000
[2019-03-26 21:20:29,376] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1194757: loss -139.2274
[2019-03-26 21:20:29,377] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1194757: learning rate 0.0000
[2019-03-26 21:20:29,390] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1194762: loss -117.0544
[2019-03-26 21:20:29,393] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1194763: learning rate 0.0000
[2019-03-26 21:20:29,550] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1194834: loss -139.0094
[2019-03-26 21:20:29,552] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1194836: learning rate 0.0000
[2019-03-26 21:20:29,587] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1194850: loss -159.8603
[2019-03-26 21:20:29,589] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1194850: learning rate 0.0000
[2019-03-26 21:20:30,105] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1195082: loss -116.8063
[2019-03-26 21:20:30,108] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1195082: learning rate 0.0000
[2019-03-26 21:20:31,459] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0388908e-08 9.9671078e-01 1.9181890e-08 3.2891831e-03 2.1154315e-12], sum to 1.0000
[2019-03-26 21:20:31,466] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0518
[2019-03-26 21:20:31,475] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2890690.104573426 W.
[2019-03-26 21:20:31,482] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.08333333333334, 48.16666666666666, 1.0, 2.0, 1.033344567576344, 1.0, 2.0, 1.033344567576344, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2890690.104573426, 2890690.104573425, 549459.897697895], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5497800.0000, 
sim time next is 5498400.0000, 
raw observation next is [35.96666666666667, 48.33333333333333, 1.0, 2.0, 1.014592398994442, 1.0, 2.0, 1.014592398994442, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2838172.976352855, 2838172.976352856, 537864.1206823144], 
processed observation next is [1.0, 0.6521739130434783, 0.9036334913112165, 0.4833333333333333, 1.0, 1.0, 1.0175812036077616, 1.0, 1.0, 1.0175812036077616, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7883813823202376, 0.7883813823202378, 0.8027822696750961], 
reward next is 0.1972, 
noisyNet noise sample is [array([-0.13777916], dtype=float32), -0.64000714]. 
=============================================
[2019-03-26 21:20:35,045] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1197280: loss 0.9694
[2019-03-26 21:20:35,047] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1197281: learning rate 0.0000
[2019-03-26 21:20:36,143] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1197769: loss 15.5488
[2019-03-26 21:20:36,146] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1197769: learning rate 0.0000
[2019-03-26 21:20:38,692] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1198913: loss 17.0749
[2019-03-26 21:20:38,698] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1198914: learning rate 0.0000
[2019-03-26 21:20:41,135] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 21:20:41,135] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:20:41,137] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:20:41,137] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:20:41,137] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:20:41,138] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:20:41,139] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:20:41,139] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:20:41,140] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:20:41,143] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:20:41,142] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:20:41,170] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run49
[2019-03-26 21:20:41,192] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run49
[2019-03-26 21:20:41,213] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run49
[2019-03-26 21:20:41,215] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run49
[2019-03-26 21:20:41,216] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run49
[2019-03-26 21:20:59,147] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08400325], dtype=float32), 0.06296095]
[2019-03-26 21:20:59,148] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.65685572, 72.62631583, 1.0, 2.0, 0.3123150181849904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 503303.7144943915, 503303.7144943908, 167342.9995802796]
[2019-03-26 21:20:59,151] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:20:59,155] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.8313177e-20 1.0000000e+00 2.2786246e-19 2.2279844e-16 4.8163133e-25], sampled 0.4349771983522758
[2019-03-26 21:21:02,171] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08400325], dtype=float32), 0.06296095]
[2019-03-26 21:21:02,172] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [18.22913564666667, 96.21105095833335, 1.0, 2.0, 0.2653197497154077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 438397.9655545844, 438397.9655545838, 162391.7403154108]
[2019-03-26 21:21:02,173] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:21:02,175] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.7277248e-21 1.0000000e+00 9.0940812e-20 1.7532871e-16 1.3891924e-25], sampled 0.2661206663175847
[2019-03-26 21:21:27,013] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08400325], dtype=float32), 0.06296095]
[2019-03-26 21:21:27,014] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.45, 79.16666666666667, 1.0, 2.0, 0.5768738507019132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 806132.3397436545, 806132.3397436551, 196516.13134705]
[2019-03-26 21:21:27,015] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:21:27,018] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2136258e-20 1.0000000e+00 1.1884515e-19 5.5247999e-16 2.7580323e-25], sampled 0.7664337388502234
[2019-03-26 21:21:51,921] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08400325], dtype=float32), 0.06296095]
[2019-03-26 21:21:51,922] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.86666666666667, 80.16666666666667, 1.0, 2.0, 0.6344841977655424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 886671.5231623399, 886671.5231623399, 207346.1734361458]
[2019-03-26 21:21:51,925] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:21:51,929] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.5801171e-21 1.0000000e+00 2.0978215e-20 2.0210103e-16 2.8500451e-26], sampled 0.7852021433449589
[2019-03-26 21:22:11,740] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08400325], dtype=float32), 0.06296095]
[2019-03-26 21:22:11,742] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.25409051, 90.80779371, 1.0, 2.0, 0.5231182068916913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730987.5333064273, 730987.5333064273, 187297.1668072361]
[2019-03-26 21:22:11,744] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:22:11,746] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.7840588e-21 1.0000000e+00 3.8621215e-20 2.3009894e-16 1.0143486e-25], sampled 0.10185884870772388
[2019-03-26 21:22:14,320] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08400325], dtype=float32), 0.06296095]
[2019-03-26 21:22:14,321] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.56224095, 84.84456456, 1.0, 2.0, 0.9877449369121211, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.00599270439908, 6.9112, 168.9123159237597, 2277848.960765061, 2210600.008787616, 459558.8035889899]
[2019-03-26 21:22:14,322] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:22:14,324] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.4254077e-15 1.0000000e+00 3.8686930e-15 1.7411711e-11 1.9896819e-19], sampled 0.7866367760648653
[2019-03-26 21:22:14,325] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2277848.960765061 W.
[2019-03-26 21:22:26,599] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08400325], dtype=float32), 0.06296095]
[2019-03-26 21:22:26,601] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.93333333333334, 66.83333333333333, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.405727072092882, 6.9112, 168.9101628140531, 1804823.94210967, 1453995.219404375, 311353.8089129003]
[2019-03-26 21:22:26,606] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:22:26,607] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.19975665e-20 1.00000000e+00 8.53515071e-20 3.30673245e-16
 1.23924107e-25], sampled 0.7523707144527042
[2019-03-26 21:22:26,609] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1804823.94210967 W.
[2019-03-26 21:22:27,257] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08400325], dtype=float32), 0.06296095]
[2019-03-26 21:22:27,259] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.12352057, 71.91286769333334, 1.0, 2.0, 0.4088502630617925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 609783.7012628864, 609783.7012628864, 175433.9177525747]
[2019-03-26 21:22:27,259] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:22:27,263] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.2003971e-21 1.0000000e+00 9.5391360e-20 3.5989668e-16 1.7316039e-25], sampled 0.1740063115831686
[2019-03-26 21:22:35,534] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08400325], dtype=float32), 0.06296095]
[2019-03-26 21:22:35,535] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.46666666666667, 72.66666666666666, 1.0, 2.0, 0.6657209125970925, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.984891247070262, 6.9112, 168.9124582400168, 1827161.303075747, 1774882.350363423, 378167.4749113382]
[2019-03-26 21:22:35,535] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:22:35,537] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.0540084e-12 1.0000000e+00 5.6243950e-12 3.7128498e-08 1.9344157e-15], sampled 0.8274777776002964
[2019-03-26 21:22:35,538] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1827161.303075747 W.
[2019-03-26 21:22:35,731] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7995.9990 3007799231.0350 1766.0000
[2019-03-26 21:22:35,879] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9767 2779207024.4606 933.0000
[2019-03-26 21:22:35,965] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.7366 2842517435.7223 1131.0000
[2019-03-26 21:22:35,973] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.8487 2927400550.8281 1338.0000
[2019-03-26 21:22:35,993] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.7672 3164102243.7041 1778.0000
[2019-03-26 21:22:37,010] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1200000, evaluation results [1200000.0, 7884.767168054142, 3164102243.704051, 1778.0, 8252.848719883228, 2927400550.8281245, 1338.0, 8659.976662972434, 2779207024.4606214, 933.0, 7995.998988991475, 3007799231.0350223, 1766.0, 8496.73656601701, 2842517435.72233, 1131.0]
[2019-03-26 21:22:38,152] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1200535: loss 0.9178
[2019-03-26 21:22:38,155] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1200535: learning rate 0.0000
[2019-03-26 21:22:39,559] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1201382: loss 0.5818
[2019-03-26 21:22:39,563] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1201383: learning rate 0.0000
[2019-03-26 21:22:39,903] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.76883439e-07 9.84396458e-01 1.40275529e-06 1.56013835e-02
 2.36608177e-09], sum to 1.0000
[2019-03-26 21:22:39,911] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9362
[2019-03-26 21:22:39,918] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2506869.673548613 W.
[2019-03-26 21:22:39,923] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.83333333333333, 67.5, 1.0, 2.0, 0.8962765264066731, 1.0, 2.0, 0.8962765264066731, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2506869.673548613, 2506869.673548613, 469466.7508386465], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5226600.0000, 
sim time next is 5227200.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.6232300997092302, 1.0, 2.0, 0.6232300997092302, 1.0, 1.0, 1.03, 6.970045526054255, 6.9112, 170.5573041426782, 2614858.31498394, 2572704.87098832, 496555.3594501014], 
processed observation next is [1.0, 0.5217391304347826, 0.7156398104265403, 0.67, 1.0, 1.0, 0.546060361095458, 1.0, 1.0, 0.546060361095458, 1.0, 0.5, 1.0365853658536586, 0.005884552605425508, 0.0, 0.8375144448122397, 0.7263495319399834, 0.7146402419412, 0.7411274021643304], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4317969], dtype=float32), -0.21780135]. 
=============================================
[2019-03-26 21:22:41,181] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1202107: loss 8.4912
[2019-03-26 21:22:41,183] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1202107: learning rate 0.0000
[2019-03-26 21:22:41,372] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1202189: loss 13.3774
[2019-03-26 21:22:41,375] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1202189: learning rate 0.0000
[2019-03-26 21:22:41,528] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1202258: loss 18.6006
[2019-03-26 21:22:41,529] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1202258: learning rate 0.0000
[2019-03-26 21:22:41,664] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1202312: loss 13.3687
[2019-03-26 21:22:41,667] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1202314: learning rate 0.0000
[2019-03-26 21:22:41,718] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1202338: loss 11.4199
[2019-03-26 21:22:41,719] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1202338: learning rate 0.0000
[2019-03-26 21:22:41,926] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1202426: loss 17.2092
[2019-03-26 21:22:41,928] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1202426: learning rate 0.0000
[2019-03-26 21:22:42,521] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1202667: loss 7.7152
[2019-03-26 21:22:42,523] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1202667: learning rate 0.0000
[2019-03-26 21:22:42,764] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1202776: loss 18.4249
[2019-03-26 21:22:42,770] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1202777: learning rate 0.0000
[2019-03-26 21:22:42,851] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1202809: loss 15.7913
[2019-03-26 21:22:42,853] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1202811: learning rate 0.0000
[2019-03-26 21:22:42,919] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1202838: loss 16.9189
[2019-03-26 21:22:42,921] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1202839: learning rate 0.0000
[2019-03-26 21:22:43,421] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1203063: loss 13.3802
[2019-03-26 21:22:43,429] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1203065: learning rate 0.0000
[2019-03-26 21:22:45,150] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3023689e-19 1.0000000e+00 2.7725135e-19 2.0552969e-16 7.8424696e-25], sum to 1.0000
[2019-03-26 21:22:45,160] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9374
[2019-03-26 21:22:45,165] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 75.5, 1.0, 2.0, 0.5288519511965191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 739002.459011747, 739002.4590117476, 188240.4328122601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5646600.0000, 
sim time next is 5647200.0000, 
raw observation next is [29.16666666666666, 75.0, 1.0, 2.0, 0.531538149414752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742757.3872545608, 742757.3872545602, 188685.3781932706], 
processed observation next is [0.0, 0.34782608695652173, 0.5813586097946285, 0.75, 1.0, 1.0, 0.43558813182500233, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20632149645960024, 0.20632149645960007, 0.28161996745264267], 
reward next is 0.7184, 
noisyNet noise sample is [array([-0.32740912], dtype=float32), 0.37998736]. 
=============================================
[2019-03-26 21:22:48,344] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1205261: loss 143.0851
[2019-03-26 21:22:48,345] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1205261: learning rate 0.0000
[2019-03-26 21:22:49,807] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1205909: loss 1.0923
[2019-03-26 21:22:49,808] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1205909: learning rate 0.0000
[2019-03-26 21:22:52,176] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1206964: loss 0.4241
[2019-03-26 21:22:52,179] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1206965: learning rate 0.0000
[2019-03-26 21:22:55,416] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1208399: loss 126.6764
[2019-03-26 21:22:55,417] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1208399: learning rate 0.0000
[2019-03-26 21:22:55,672] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2652529e-18 1.0000000e+00 7.9041574e-18 3.7086274e-14 1.2392518e-23], sum to 1.0000
[2019-03-26 21:22:55,677] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7909
[2019-03-26 21:22:55,683] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 76.0, 1.0, 2.0, 0.5537443060477982, 1.0, 1.0, 0.5537443060477982, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1548151.206582437, 1548151.206582437, 317808.9051794496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5472000.0000, 
sim time next is 5472600.0000, 
raw observation next is [31.21666666666667, 75.33333333333334, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.260758089179407, 6.9112, 168.9109370009364, 1701910.344950498, 1453924.770556386, 311355.9368391257], 
processed observation next is [1.0, 0.34782608695652173, 0.6785150078988943, 0.7533333333333334, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0349558089179407, 0.0, 0.8294300284361488, 0.47275287359736057, 0.40386799182121835, 0.4647103534912324], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.28485763], dtype=float32), 1.9117023]. 
=============================================
[2019-03-26 21:22:57,138] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1209161: loss 112.5775
[2019-03-26 21:22:57,141] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1209162: learning rate 0.0000
[2019-03-26 21:22:59,246] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1210092: loss 1.1318
[2019-03-26 21:22:59,248] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1210092: learning rate 0.0000
[2019-03-26 21:22:59,566] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1210238: loss 1.1188
[2019-03-26 21:22:59,569] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1210238: learning rate 0.0000
[2019-03-26 21:22:59,664] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1210277: loss 0.9326
[2019-03-26 21:22:59,666] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1210278: learning rate 0.0000
[2019-03-26 21:22:59,798] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1210338: loss 1.4951
[2019-03-26 21:22:59,804] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1210339: learning rate 0.0000
[2019-03-26 21:22:59,868] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1210367: loss 0.5299
[2019-03-26 21:22:59,871] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1210369: learning rate 0.0000
[2019-03-26 21:23:00,084] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1210462: loss 1.5038
[2019-03-26 21:23:00,085] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1210462: learning rate 0.0000
[2019-03-26 21:23:00,620] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1210706: loss 1.0661
[2019-03-26 21:23:00,623] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1210706: learning rate 0.0000
[2019-03-26 21:23:00,755] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1210764: loss 0.5399
[2019-03-26 21:23:00,756] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1210764: learning rate 0.0000
[2019-03-26 21:23:00,864] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1210810: loss 0.3206
[2019-03-26 21:23:00,865] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1210810: learning rate 0.0000
[2019-03-26 21:23:00,957] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.8921447e-08 9.9915051e-01 1.8937618e-07 8.4926526e-04 2.0558852e-10], sum to 1.0000
[2019-03-26 21:23:00,964] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5324
[2019-03-26 21:23:00,972] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2359491.177658596 W.
[2019-03-26 21:23:00,976] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.5, 62.0, 1.0, 2.0, 0.5624228417723925, 1.0, 1.0, 0.5624228417723925, 1.0, 2.0, 0.976742480082685, 6.911200000000001, 6.9112, 170.5573041426782, 2359491.177658596, 2359491.177658595, 460996.3695691614], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5569200.0000, 
sim time next is 5569800.0000, 
raw observation next is [32.6, 61.16666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 8.70033760879017, 6.9112, 168.902707803954, 3555118.640138035, 2285919.855752121, 471482.0082186539], 
processed observation next is [1.0, 0.4782608695652174, 0.7440758293838864, 0.6116666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.17891376087901695, 0.0, 0.8293896193116225, 0.9875329555938986, 0.6349777377089225, 0.7037044898785879], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.44077024], dtype=float32), 2.135496]. 
=============================================
[2019-03-26 21:23:01,014] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1210878: loss 0.4960
[2019-03-26 21:23:01,016] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1210878: learning rate 0.0000
[2019-03-26 21:23:01,103] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1250194e-06 9.8983216e-01 1.0763641e-06 1.0165555e-02 7.0161982e-10], sum to 1.0000
[2019-03-26 21:23:01,111] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2592
[2019-03-26 21:23:01,117] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2304391.305855505 W.
[2019-03-26 21:23:01,122] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.8, 59.5, 1.0, 2.0, 0.8239514930193955, 1.0, 2.0, 0.8239514930193955, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2304391.305855505, 2304391.305855505, 431700.5394947713], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5571000.0000, 
sim time next is 5571600.0000, 
raw observation next is [32.9, 58.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.360908347315324, 6.9112, 168.910701936003, 2607865.300839887, 2288830.979871539, 475361.4458912244], 
processed observation next is [1.0, 0.4782608695652174, 0.7582938388625592, 0.5866666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.044970834731532426, 0.0, 0.8294288741597126, 0.7244070280110797, 0.6357863832976497, 0.7094946953600364], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.4107122], dtype=float32), 0.13949758]. 
=============================================
[2019-03-26 21:23:01,410] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1211049: loss 1.4815
[2019-03-26 21:23:01,413] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1211049: learning rate 0.0000
[2019-03-26 21:23:01,869] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3684373e-07 8.8899928e-01 1.1498350e-06 1.1099924e-01 1.9205648e-09], sum to 1.0000
[2019-03-26 21:23:01,877] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6198
[2019-03-26 21:23:01,885] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2311349.79058196 W.
[2019-03-26 21:23:01,892] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.26666666666667, 53.66666666666667, 1.0, 2.0, 0.5509581666549442, 1.0, 2.0, 0.5509581666549442, 1.0, 2.0, 0.9510283490028572, 6.911199999999999, 6.9112, 170.5573041426782, 2311349.79058196, 2311349.790581961, 451004.8901730112], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5588400.0000, 
sim time next is 5589000.0000, 
raw observation next is [33.2, 54.0, 1.0, 2.0, 1.015871326527399, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.98826465068702, 6.9112, 168.9124985049229, 2317217.034355832, 2262544.867041226, 468881.2337122891], 
processed observation next is [1.0, 0.6956521739130435, 0.7725118483412324, 0.54, 1.0, 1.0, 1.0191220801534928, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007706465068701984, 0.0, 0.829437696135582, 0.6436713984321755, 0.6284846852892294, 0.6998227368840135], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2130554], dtype=float32), 1.3811812]. 
=============================================
[2019-03-26 21:23:01,913] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[21.988108]
 [23.568264]
 [25.091482]
 [24.132166]
 [25.83234 ]], R is [[23.12935829]
 [23.22492409]
 [22.99267578]
 [23.11175537]
 [23.17653847]].
[2019-03-26 21:23:02,080] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.3113867e-06 7.5855160e-01 2.5556388e-05 2.4141356e-01 1.1978820e-08], sum to 1.0000
[2019-03-26 21:23:02,087] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3742
[2019-03-26 21:23:02,095] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2224503.887600615 W.
[2019-03-26 21:23:02,105] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.26666666666667, 55.33333333333334, 1.0, 2.0, 0.530275051818834, 1.0, 2.0, 0.530275051818834, 1.0, 2.0, 0.9204873526333317, 6.9112, 6.9112, 170.5573041426782, 2224503.887600615, 2224503.887600615, 436631.0912284151], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5574000.0000, 
sim time next is 5574600.0000, 
raw observation next is [33.35, 54.5, 1.0, 2.0, 0.4945558914163316, 1.0, 2.0, 0.4945558914163316, 1.0, 2.0, 0.8561862661451083, 6.911199999999999, 6.9112, 170.5573041426782, 2074518.550053851, 2074518.550053852, 410921.7568213641], 
processed observation next is [1.0, 0.5217391304347826, 0.7796208530805688, 0.545, 1.0, 1.0, 0.39103119447750795, 1.0, 1.0, 0.39103119447750795, 1.0, 1.0, 0.824617397737937, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5762551527927364, 0.5762551527927366, 0.6133160549572598], 
reward next is 0.3867, 
noisyNet noise sample is [array([-0.17364308], dtype=float32), 1.0623822]. 
=============================================
[2019-03-26 21:23:06,517] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1213320: loss 0.6403
[2019-03-26 21:23:06,523] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1213320: learning rate 0.0000
[2019-03-26 21:23:07,528] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1213768: loss 109.0946
[2019-03-26 21:23:07,530] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1213768: learning rate 0.0000
[2019-03-26 21:23:09,132] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.3519380e-20 1.0000000e+00 1.2566395e-19 7.7465557e-16 2.1372668e-25], sum to 1.0000
[2019-03-26 21:23:09,145] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2379
[2019-03-26 21:23:09,151] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 88.0, 1.0, 2.0, 0.5099865169177973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712631.6026108376, 712631.6026108376, 185175.2902713618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5711400.0000, 
sim time next is 5712000.0000, 
raw observation next is [26.26666666666667, 88.33333333333333, 1.0, 2.0, 0.5103670622577988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 713163.5375938589, 713163.5375938582, 185236.0695604134], 
processed observation next is [0.0, 0.08695652173913043, 0.44391785150079005, 0.8833333333333333, 1.0, 1.0, 0.4100807979009624, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19810098266496082, 0.19810098266496062, 0.27647174561255733], 
reward next is 0.7235, 
noisyNet noise sample is [array([-1.353068], dtype=float32), -0.70136374]. 
=============================================
[2019-03-26 21:23:09,167] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[71.74466]
 [71.61865]
 [71.47135]
 [71.31036]
 [71.26924]], R is [[71.83729553]
 [71.84254456]
 [71.84780121]
 [71.85301971]
 [71.85814667]].
[2019-03-26 21:23:09,983] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1214856: loss 121.2501
[2019-03-26 21:23:09,985] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1214856: learning rate 0.0000
[2019-03-26 21:23:10,150] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0301446e-19 1.0000000e+00 1.0751032e-18 2.0099411e-14 5.3286923e-25], sum to 1.0000
[2019-03-26 21:23:10,158] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2422
[2019-03-26 21:23:10,165] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 86.0, 1.0, 2.0, 0.5304955854144774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 741300.0274749437, 741300.0274749431, 188512.1514061113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6210000.0000, 
sim time next is 6210600.0000, 
raw observation next is [27.25, 86.16666666666667, 1.0, 2.0, 0.5296273506821226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740086.3573434277, 740086.3573434271, 188368.3708849643], 
processed observation next is [1.0, 0.9130434782608695, 0.490521327014218, 0.8616666666666667, 1.0, 1.0, 0.43328596467725616, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2055795437065077, 0.20557954370650755, 0.2811468222163646], 
reward next is 0.7189, 
noisyNet noise sample is [array([-0.892524], dtype=float32), -2.1944242]. 
=============================================
[2019-03-26 21:23:11,492] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0444313e-20 1.0000000e+00 5.2203992e-20 6.1002717e-17 1.0740008e-25], sum to 1.0000
[2019-03-26 21:23:11,501] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7021
[2019-03-26 21:23:11,507] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.2, 53.0, 1.0, 2.0, 0.5179315487928451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723737.4052203717, 723737.4052203717, 186453.8137669691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5754000.0000, 
sim time next is 5754600.0000, 
raw observation next is [33.4, 53.0, 1.0, 2.0, 0.5210283406326912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 728066.2247017447, 728066.2247017447, 186957.1641838482], 
processed observation next is [0.0, 0.6086956521739131, 0.7819905213270142, 0.53, 1.0, 1.0, 0.422925711605652, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20224061797270687, 0.20224061797270687, 0.27904054355798236], 
reward next is 0.7210, 
noisyNet noise sample is [array([-0.59298915], dtype=float32), 1.4621902]. 
=============================================
[2019-03-26 21:23:12,712] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.97174915e-22 1.00000000e+00 7.66616451e-21 3.18127708e-17
 1.02666173e-25], sum to 1.0000
[2019-03-26 21:23:12,720] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4105
[2019-03-26 21:23:12,726] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.8, 79.0, 1.0, 2.0, 0.5495153097932858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 767887.2769922784, 767887.276992279, 191717.473560603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5772600.0000, 
sim time next is 5773200.0000, 
raw observation next is [28.6, 80.0, 1.0, 2.0, 0.5487683742202893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 766843.1398199901, 766843.1398199908, 191589.5144488959], 
processed observation next is [0.0, 0.8260869565217391, 0.5545023696682465, 0.8, 1.0, 1.0, 0.4563474388196257, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2130119832833306, 0.2130119832833308, 0.2859544991774566], 
reward next is 0.7140, 
noisyNet noise sample is [array([0.64179224], dtype=float32), 1.2767825]. 
=============================================
[2019-03-26 21:23:13,957] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1216620: loss 0.6366
[2019-03-26 21:23:13,959] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1216620: learning rate 0.0000
[2019-03-26 21:23:15,656] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1217376: loss 0.6375
[2019-03-26 21:23:15,658] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1217376: learning rate 0.0000
[2019-03-26 21:23:17,269] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1218087: loss 111.9658
[2019-03-26 21:23:17,271] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1218088: learning rate 0.0000
[2019-03-26 21:23:17,536] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.8810774e-09 9.9951804e-01 3.4257145e-08 4.8198522e-04 2.2129466e-12], sum to 1.0000
[2019-03-26 21:23:17,547] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3790
[2019-03-26 21:23:17,555] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1989709.042198834 W.
[2019-03-26 21:23:17,559] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.46666666666667, 63.66666666666667, 1.0, 2.0, 0.7115346668552469, 1.0, 2.0, 0.7115346668552469, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1989709.042198834, 1989709.042198834, 379107.7160382325], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5834400.0000, 
sim time next is 5835000.0000, 
raw observation next is [32.53333333333333, 63.33333333333333, 1.0, 2.0, 0.7165476263375696, 1.0, 2.0, 0.7165476263375696, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2003740.204729642, 2003740.204729642, 381294.9995167539], 
processed observation next is [1.0, 0.5217391304347826, 0.7409162717219588, 0.6333333333333333, 1.0, 1.0, 0.658491116069361, 1.0, 1.0, 0.658491116069361, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5565945013137894, 0.5565945013137894, 0.5690970142041103], 
reward next is 0.4309, 
noisyNet noise sample is [array([0.04896273], dtype=float32), 0.19310594]. 
=============================================
[2019-03-26 21:23:17,568] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[30.464855]
 [28.93668 ]
 [26.986986]
 [25.060186]
 [24.030405]], R is [[31.98306084]
 [32.09739685]
 [32.21400833]
 [32.2961235 ]
 [32.25087738]].
[2019-03-26 21:23:17,675] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1218267: loss 147.4028
[2019-03-26 21:23:17,677] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1218268: learning rate 0.0000
[2019-03-26 21:23:17,719] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1218288: loss 123.0587
[2019-03-26 21:23:17,722] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1218288: learning rate 0.0000
[2019-03-26 21:23:17,752] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1218303: loss 116.1303
[2019-03-26 21:23:17,754] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1218304: learning rate 0.0000
[2019-03-26 21:23:17,802] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1218323: loss 141.0331
[2019-03-26 21:23:17,804] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1218324: learning rate 0.0000
[2019-03-26 21:23:18,131] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1218472: loss 128.0348
[2019-03-26 21:23:18,133] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1218472: learning rate 0.0000
[2019-03-26 21:23:18,700] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1218727: loss 159.2183
[2019-03-26 21:23:18,703] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1218727: learning rate 0.0000
[2019-03-26 21:23:18,714] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1218730: loss 125.9853
[2019-03-26 21:23:18,716] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1218731: learning rate 0.0000
[2019-03-26 21:23:18,899] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1218815: loss 139.9880
[2019-03-26 21:23:18,901] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1218816: learning rate 0.0000
[2019-03-26 21:23:18,922] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.5041019e-20 1.0000000e+00 1.8409905e-19 2.3569681e-15 4.8967707e-25], sum to 1.0000
[2019-03-26 21:23:18,926] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1218823: loss 112.3442
[2019-03-26 21:23:18,930] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4001
[2019-03-26 21:23:18,930] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1218826: learning rate 0.0000
[2019-03-26 21:23:18,939] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 91.0, 1.0, 2.0, 0.5317772567758355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 743091.6264425924, 743091.6264425929, 188724.4704651713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5877000.0000, 
sim time next is 5877600.0000, 
raw observation next is [26.43333333333333, 91.33333333333333, 1.0, 2.0, 0.5309379209262786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 741918.3508864839, 741918.3508864839, 188585.1632545386], 
processed observation next is [1.0, 0.0, 0.4518167456556081, 0.9133333333333333, 1.0, 1.0, 0.4348649649714199, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2060884308018011, 0.2060884308018011, 0.2814703929172218], 
reward next is 0.7185, 
noisyNet noise sample is [array([0.44440863], dtype=float32), 0.04966415]. 
=============================================
[2019-03-26 21:23:19,455] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1219062: loss 127.3169
[2019-03-26 21:23:19,457] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1219062: learning rate 0.0000
[2019-03-26 21:23:24,302] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1221222: loss 252.1377
[2019-03-26 21:23:24,304] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1221223: learning rate 0.0000
[2019-03-26 21:23:25,870] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1221916: loss 1.3460
[2019-03-26 21:23:25,872] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1221916: learning rate 0.0000
[2019-03-26 21:23:28,070] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1222898: loss 0.5850
[2019-03-26 21:23:28,072] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1222900: learning rate 0.0000
[2019-03-26 21:23:31,617] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1224472: loss 332.4352
[2019-03-26 21:23:31,619] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1224473: learning rate 0.0000
[2019-03-26 21:23:32,253] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.4637469e-09 9.9876761e-01 5.4549545e-08 1.2322575e-03 3.6584498e-12], sum to 1.0000
[2019-03-26 21:23:32,262] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2357
[2019-03-26 21:23:32,266] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1697054.110399064 W.
[2019-03-26 21:23:32,274] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.08333333333333, 65.0, 1.0, 2.0, 0.6069619131164787, 1.0, 1.0, 0.6069619131164787, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1697054.110399064, 1697054.110399064, 336837.7745841413], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6094200.0000, 
sim time next is 6094800.0000, 
raw observation next is [31.1, 65.0, 1.0, 2.0, 0.5457478470993744, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9347403465894563, 6.9112, 6.9112, 168.9129565046544, 1525789.468863362, 1525789.468863362, 331438.9509610398], 
processed observation next is [1.0, 0.5652173913043478, 0.6729857819905214, 0.65, 1.0, 1.0, 0.45270824951731853, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.9204150568164099, 0.0, 0.0, 0.8294399451239369, 0.4238304080176005, 0.4238304080176005, 0.49468500143438776], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.20971031], dtype=float32), -1.747461]. 
=============================================
[2019-03-26 21:23:32,825] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 21:23:32,828] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:23:32,830] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:23:32,831] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:23:32,831] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:23:32,832] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:23:32,833] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:23:32,833] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:23:32,834] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:23:32,835] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:23:32,836] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:23:32,853] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run50
[2019-03-26 21:23:32,875] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run50
[2019-03-26 21:23:32,898] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run50
[2019-03-26 21:23:32,919] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run50
[2019-03-26 21:23:32,919] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run50
[2019-03-26 21:23:42,219] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08338417], dtype=float32), 0.0616029]
[2019-03-26 21:23:42,220] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.984499755, 62.80984914, 1.0, 2.0, 0.4601476861153906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 720688.1920965135, 720688.192096514, 186698.4621892015]
[2019-03-26 21:23:42,223] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:23:42,226] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.2330417e-20 1.0000000e+00 6.8026646e-19 1.0489549e-15 1.7500859e-24], sampled 0.628101877994584
[2019-03-26 21:23:45,121] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08338417], dtype=float32), 0.0616029]
[2019-03-26 21:23:45,124] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.8, 70.5, 1.0, 2.0, 0.4263707776078601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 626469.144949952, 626469.144949952, 176777.1256369181]
[2019-03-26 21:23:45,125] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:23:45,129] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2369960e-20 1.0000000e+00 1.0714016e-19 5.7396043e-16 2.2542800e-25], sampled 0.3523965877499027
[2019-03-26 21:24:32,875] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08338417], dtype=float32), 0.0616029]
[2019-03-26 21:24:32,877] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.7, 49.33333333333333, 1.0, 2.0, 0.7633736257593431, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.99050286977884, 6.9112, 168.9124203153264, 1963814.634888726, 1907554.628265087, 399574.6142779076]
[2019-03-26 21:24:32,878] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:24:32,881] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0368535e-10 9.9999809e-01 1.8346262e-10 1.8852504e-06 6.4688435e-14], sampled 0.16389060874067363
[2019-03-26 21:24:32,882] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1963814.634888726 W.
[2019-03-26 21:25:27,819] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3694 2779190338.1949 933.0000
[2019-03-26 21:25:27,997] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.1944 3164285246.3636 1778.0000
[2019-03-26 21:25:28,003] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.4067 2927264152.9822 1338.0000
[2019-03-26 21:25:28,110] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7995.9992 3007918481.8735 1766.0000
[2019-03-26 21:25:28,331] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8493.7888 2842644872.5258 1131.0000
[2019-03-26 21:25:29,347] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1225000, evaluation results [1225000.0, 7883.194427732159, 3164285246.363639, 1778.0, 8254.406660643592, 2927264152.9821725, 1338.0, 8661.369356548688, 2779190338.194891, 933.0, 7995.999216807949, 3007918481.873536, 1766.0, 8493.788820576661, 2842644872.5258255, 1131.0]
[2019-03-26 21:25:29,685] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1225159: loss 280.9514
[2019-03-26 21:25:29,686] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1225160: learning rate 0.0000
[2019-03-26 21:25:31,227] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1226051: loss 0.5791
[2019-03-26 21:25:31,228] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1226051: learning rate 0.0000
[2019-03-26 21:25:31,709] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1226302: loss 0.5766
[2019-03-26 21:25:31,711] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1226302: learning rate 0.0000
[2019-03-26 21:25:31,774] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1226329: loss 1.1248
[2019-03-26 21:25:31,776] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1226330: learning rate 0.0000
[2019-03-26 21:25:31,857] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1226368: loss 0.6815
[2019-03-26 21:25:31,861] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1226370: learning rate 0.0000
[2019-03-26 21:25:31,887] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1226383: loss 1.3706
[2019-03-26 21:25:31,889] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1226383: learning rate 0.0000
[2019-03-26 21:25:32,152] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1226497: loss 1.9119
[2019-03-26 21:25:32,153] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1226497: learning rate 0.0000
[2019-03-26 21:25:32,727] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1226754: loss 0.6893
[2019-03-26 21:25:32,731] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1226756: learning rate 0.0000
[2019-03-26 21:25:32,910] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1226832: loss 1.1241
[2019-03-26 21:25:32,912] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1226833: learning rate 0.0000
[2019-03-26 21:25:32,946] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1226850: loss 1.1117
[2019-03-26 21:25:32,949] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1226851: learning rate 0.0000
[2019-03-26 21:25:32,971] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1226863: loss 1.9113
[2019-03-26 21:25:32,973] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1226863: learning rate 0.0000
[2019-03-26 21:25:33,500] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1227096: loss 1.1261
[2019-03-26 21:25:33,503] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1227096: learning rate 0.0000
[2019-03-26 21:25:38,132] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1229160: loss 0.0056
[2019-03-26 21:25:38,135] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1229160: learning rate 0.0000
[2019-03-26 21:25:39,477] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.7914824e-21 1.0000000e+00 2.2397482e-20 3.2363112e-16 9.6626389e-26], sum to 1.0000
[2019-03-26 21:25:39,486] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2659
[2019-03-26 21:25:39,488] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.95, 66.0, 1.0, 2.0, 0.5080061117466547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 709863.3512516905, 709863.3512516911, 184860.0016052689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6283800.0000, 
sim time next is 6284400.0000, 
raw observation next is [29.8, 67.0, 1.0, 2.0, 0.510293733637623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 713061.0371501195, 713061.0371501202, 185224.5668484073], 
processed observation next is [0.0, 0.7391304347826086, 0.6113744075829385, 0.67, 1.0, 1.0, 0.4099924501658108, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19807251031947765, 0.19807251031947784, 0.2764545773856825], 
reward next is 0.7235, 
noisyNet noise sample is [array([0.22553219], dtype=float32), -0.09218661]. 
=============================================
[2019-03-26 21:25:39,538] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1229789: loss 236.0425
[2019-03-26 21:25:39,540] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1229790: learning rate 0.0000
[2019-03-26 21:25:41,816] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1230810: loss 281.7938
[2019-03-26 21:25:41,820] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1230811: learning rate 0.0000
[2019-03-26 21:25:45,907] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1232634: loss 0.0033
[2019-03-26 21:25:45,909] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1232634: learning rate 0.0000
[2019-03-26 21:25:46,421] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.0882897e-20 1.0000000e+00 1.6624162e-19 2.5064349e-15 3.0749063e-25], sum to 1.0000
[2019-03-26 21:25:46,433] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7603
[2019-03-26 21:25:46,438] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333334, 87.33333333333333, 1.0, 2.0, 0.5196885430402731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 726193.3998804901, 726193.3998804907, 186738.5075661945], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6567000.0000, 
sim time next is 6567600.0000, 
raw observation next is [26.76666666666667, 87.66666666666667, 1.0, 2.0, 0.5191735408975247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 725473.5093355966, 725473.5093355973, 186654.8340875067], 
processed observation next is [1.0, 0.0, 0.46761453396524505, 0.8766666666666667, 1.0, 1.0, 0.42069101312954776, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20152041925988795, 0.20152041925988814, 0.27858930460821896], 
reward next is 0.7214, 
noisyNet noise sample is [array([-0.69468707], dtype=float32), -1.3129363]. 
=============================================
[2019-03-26 21:25:47,303] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1233255: loss 0.0039
[2019-03-26 21:25:47,305] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1233255: learning rate 0.0000
[2019-03-26 21:25:49,152] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1234083: loss 348.2409
[2019-03-26 21:25:49,155] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1234083: learning rate 0.0000
[2019-03-26 21:25:49,741] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1234341: loss 491.8209
[2019-03-26 21:25:49,744] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1234343: learning rate 0.0000
[2019-03-26 21:25:49,784] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1234364: loss 322.5502
[2019-03-26 21:25:49,785] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1234364: learning rate 0.0000
[2019-03-26 21:25:49,803] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1234371: loss 192.0043
[2019-03-26 21:25:49,805] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1234371: learning rate 0.0000
[2019-03-26 21:25:49,953] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1234438: loss 249.3784
[2019-03-26 21:25:49,955] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1234438: learning rate 0.0000
[2019-03-26 21:25:50,210] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1234553: loss 233.4978
[2019-03-26 21:25:50,212] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1234554: learning rate 0.0000
[2019-03-26 21:25:50,714] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1234776: loss 314.1367
[2019-03-26 21:25:50,716] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1234776: learning rate 0.0000
[2019-03-26 21:25:50,823] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1234824: loss 353.5132
[2019-03-26 21:25:50,826] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1234825: learning rate 0.0000
[2019-03-26 21:25:50,887] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1234851: loss 331.1444
[2019-03-26 21:25:50,893] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1234853: learning rate 0.0000
[2019-03-26 21:25:51,065] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1234930: loss 379.3386
[2019-03-26 21:25:51,070] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1234931: learning rate 0.0000
[2019-03-26 21:25:51,617] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1235177: loss 430.8165
[2019-03-26 21:25:51,619] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1235178: learning rate 0.0000
[2019-03-26 21:25:54,620] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.0454073e-09 9.9866414e-01 3.6839854e-08 1.3358829e-03 6.8098569e-12], sum to 1.0000
[2019-03-26 21:25:54,629] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8115
[2019-03-26 21:25:54,638] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2111033.085531848 W.
[2019-03-26 21:25:54,645] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.86666666666667, 60.0, 1.0, 2.0, 0.8685621208036136, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.971040544934185, 6.9112, 168.9125999941748, 2111033.085531848, 2068580.233006262, 426658.8791892057], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6536400.0000, 
sim time next is 6537000.0000, 
raw observation next is [30.73333333333333, 60.5, 1.0, 2.0, 0.4968690047573474, 1.0, 1.0, 0.4968690047573474, 1.0, 2.0, 0.8444125819230596, 6.9112, 6.9112, 170.5573041426782, 2084230.828829935, 2084230.828829935, 409626.021599804], 
processed observation next is [1.0, 0.6521739130434783, 0.6556082148499209, 0.605, 1.0, 1.0, 0.39381807802090046, 1.0, 0.5, 0.39381807802090046, 1.0, 1.0, 0.8102592462476335, 0.0, 0.0, 0.8375144448122397, 0.5789530080083153, 0.5789530080083153, 0.6113821217907522], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04710822], dtype=float32), -0.50579023]. 
=============================================
[2019-03-26 21:25:54,659] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[31.506723]
 [31.130287]
 [31.136187]
 [32.86539 ]
 [32.15171 ]], R is [[28.81910896]
 [28.53091812]
 [28.24560928]
 [28.35224724]
 [28.47792244]].
[2019-03-26 21:25:55,707] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1236990: loss -375.3128
[2019-03-26 21:25:55,709] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1236991: learning rate 0.0000
[2019-03-26 21:25:57,890] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1237962: loss 0.0047
[2019-03-26 21:25:57,891] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1237962: learning rate 0.0000
[2019-03-26 21:25:59,964] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1238882: loss 0.0032
[2019-03-26 21:25:59,967] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1238882: learning rate 0.0000
[2019-03-26 21:26:00,663] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.2053568e-19 1.0000000e+00 9.7721050e-18 1.3787931e-12 1.5764044e-23], sum to 1.0000
[2019-03-26 21:26:00,675] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2476
[2019-03-26 21:26:00,682] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666667, 85.00000000000001, 1.0, 2.0, 0.5183179903372933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 724277.5877025435, 724277.587702544, 186516.119772264], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6635400.0000, 
sim time next is 6636000.0000, 
raw observation next is [27.13333333333334, 85.0, 1.0, 2.0, 0.517155402362409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 722652.4794647552, 722652.4794647545, 186327.840041978], 
processed observation next is [1.0, 0.8260869565217391, 0.4849921011058455, 0.85, 1.0, 1.0, 0.418259520918565, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20073679985132087, 0.20073679985132067, 0.278101253793997], 
reward next is 0.7219, 
noisyNet noise sample is [array([0.40124857], dtype=float32), 0.5921064]. 
=============================================
[2019-03-26 21:26:00,691] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[66.69967 ]
 [65.77526 ]
 [64.33292 ]
 [61.990604]
 [59.69206 ]], R is [[68.13013458]
 [68.17045593]
 [68.21005249]
 [68.24874878]
 [68.28705597]].
[2019-03-26 21:26:01,661] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5819328e-21 1.0000000e+00 1.6423332e-20 3.8321764e-16 3.9658417e-26], sum to 1.0000
[2019-03-26 21:26:01,669] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4460
[2019-03-26 21:26:01,678] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.4989342556943306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 697182.6152101486, 697182.6152101492, 183429.3100557103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6652800.0000, 
sim time next is 6653400.0000, 
raw observation next is [25.91666666666667, 89.5, 1.0, 2.0, 0.4981941303632086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 696148.0668973145, 696148.0668973145, 183313.6742048307], 
processed observation next is [1.0, 0.0, 0.4273301737756717, 0.895, 1.0, 1.0, 0.395414614895432, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19337446302703182, 0.19337446302703182, 0.27360249881318016], 
reward next is 0.7264, 
noisyNet noise sample is [array([-0.62111133], dtype=float32), -2.14773]. 
=============================================
[2019-03-26 21:26:03,209] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1240327: loss -263.5240
[2019-03-26 21:26:03,210] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1240328: learning rate 0.0000
[2019-03-26 21:26:04,519] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1240908: loss -263.5440
[2019-03-26 21:26:04,522] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1240909: learning rate 0.0000
[2019-03-26 21:26:06,451] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.1269669e-20 1.0000000e+00 2.7913090e-18 4.7229947e-14 5.5992069e-24], sum to 1.0000
[2019-03-26 21:26:06,459] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5836
[2019-03-26 21:26:06,466] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 82.0, 1.0, 2.0, 0.3709714109903833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 560684.6458244983, 560684.6458244983, 171234.8478279128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7233600.0000, 
sim time next is 7234200.0000, 
raw observation next is [24.1, 82.5, 1.0, 2.0, 0.3666782519916247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 554770.5921117193, 554770.5921117193, 170744.5219319351], 
processed observation next is [1.0, 0.7391304347826086, 0.3412322274881518, 0.825, 1.0, 1.0, 0.23696174938749962, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15410294225325535, 0.15410294225325535, 0.2548425700476643], 
reward next is 0.7452, 
noisyNet noise sample is [array([-0.58195883], dtype=float32), -0.2925236]. 
=============================================
[2019-03-26 21:26:07,142] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1242068: loss 0.0035
[2019-03-26 21:26:07,144] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1242068: learning rate 0.0000
[2019-03-26 21:26:07,861] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1242393: loss 0.0030
[2019-03-26 21:26:07,864] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1242393: learning rate 0.0000
[2019-03-26 21:26:07,895] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1242404: loss 0.0061
[2019-03-26 21:26:07,896] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1242404: learning rate 0.0000
[2019-03-26 21:26:07,941] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1242425: loss 0.0035
[2019-03-26 21:26:07,944] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1242425: learning rate 0.0000
[2019-03-26 21:26:07,957] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7037164e-19 1.0000000e+00 4.7912071e-18 7.6259115e-14 2.2520636e-24], sum to 1.0000
[2019-03-26 21:26:07,967] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5956
[2019-03-26 21:26:07,974] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 67.0, 1.0, 2.0, 0.4229472398859401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 616878.4965556355, 616878.4965556355, 175726.7397801908], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6723000.0000, 
sim time next is 6723600.0000, 
raw observation next is [27.46666666666667, 67.0, 1.0, 2.0, 0.4170665138822869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 611146.1835130262, 611146.1835130256, 175261.3542101542], 
processed observation next is [1.0, 0.8260869565217391, 0.500789889415482, 0.67, 1.0, 1.0, 0.2976704986533577, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1697628287536184, 0.16976282875361823, 0.2615841107614242], 
reward next is 0.7384, 
noisyNet noise sample is [array([-0.81784016], dtype=float32), 0.73919916]. 
=============================================
[2019-03-26 21:26:08,051] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1242474: loss 0.0047
[2019-03-26 21:26:08,052] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1242474: learning rate 0.0000
[2019-03-26 21:26:08,374] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1242619: loss 0.0044
[2019-03-26 21:26:08,378] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1242619: learning rate 0.0000
[2019-03-26 21:26:08,848] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1242829: loss 0.0039
[2019-03-26 21:26:08,851] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1242830: learning rate 0.0000
[2019-03-26 21:26:08,950] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1242876: loss 0.0041
[2019-03-26 21:26:08,952] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1242879: learning rate 0.0000
[2019-03-26 21:26:09,003] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1242900: loss 0.0034
[2019-03-26 21:26:09,009] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1242901: learning rate 0.0000
[2019-03-26 21:26:09,213] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1242993: loss 0.0038
[2019-03-26 21:26:09,215] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1242994: learning rate 0.0000
[2019-03-26 21:26:09,851] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1243276: loss 0.0049
[2019-03-26 21:26:09,856] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1243277: learning rate 0.0000
[2019-03-26 21:26:11,397] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5092421e-19 1.0000000e+00 1.4395529e-18 1.6645399e-14 8.9385642e-25], sum to 1.0000
[2019-03-26 21:26:11,407] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6664
[2019-03-26 21:26:11,414] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.38333333333334, 57.83333333333333, 1.0, 2.0, 0.3161603692651043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 500065.5567217665, 500065.5567217659, 167032.459818853], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6811800.0000, 
sim time next is 6812400.0000, 
raw observation next is [26.26666666666667, 58.66666666666667, 1.0, 2.0, 0.3170777072927994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 501115.3531999768, 501115.3531999774, 167103.2722701032], 
processed observation next is [1.0, 0.8695652173913043, 0.44391785150079005, 0.5866666666666667, 1.0, 1.0, 0.17720205697927635, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13919870922221578, 0.13919870922221594, 0.2494078690598555], 
reward next is 0.7506, 
noisyNet noise sample is [array([0.43568364], dtype=float32), -0.73195624]. 
=============================================
[2019-03-26 21:26:13,709] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1244984: loss 0.3174
[2019-03-26 21:26:13,713] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1244984: learning rate 0.0000
[2019-03-26 21:26:15,411] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1245738: loss -212.3376
[2019-03-26 21:26:15,416] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1245739: learning rate 0.0000
[2019-03-26 21:26:17,458] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4514003e-21 1.0000000e+00 1.7987411e-20 1.0505161e-16 4.3638075e-26], sum to 1.0000
[2019-03-26 21:26:17,465] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7236
[2019-03-26 21:26:17,469] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 65.66666666666667, 1.0, 2.0, 0.3727971163437828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 565719.840333914, 565719.840333914, 171743.2627513431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6898800.0000, 
sim time next is 6899400.0000, 
raw observation next is [26.6, 66.5, 1.0, 2.0, 0.3763526246168568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 569809.6062249024, 569809.606224903, 172061.2672329463], 
processed observation next is [0.0, 0.8695652173913043, 0.4597156398104266, 0.665, 1.0, 1.0, 0.2486176200203094, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.158280446173584, 0.15828044617358417, 0.25680786154171087], 
reward next is 0.7432, 
noisyNet noise sample is [array([1.0585011], dtype=float32), -0.9615205]. 
=============================================
[2019-03-26 21:26:17,851] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1246821: loss -113.8549
[2019-03-26 21:26:17,853] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1246822: learning rate 0.0000
[2019-03-26 21:26:18,545] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8447999e-20 1.0000000e+00 2.2727464e-20 1.0270699e-16 4.3138230e-26], sum to 1.0000
[2019-03-26 21:26:18,552] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4326
[2019-03-26 21:26:18,558] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 85.33333333333333, 1.0, 2.0, 0.4173424736751459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 612707.8473380536, 612707.8473380536, 175442.9996377701], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6933000.0000, 
sim time next is 6933600.0000, 
raw observation next is [24.8, 84.0, 1.0, 2.0, 0.4177037662227866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 612920.5840332492, 612920.5840332485, 175454.1703259616], 
processed observation next is [0.0, 0.2608695652173913, 0.3744075829383887, 0.84, 1.0, 1.0, 0.2984382725575742, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17025571778701365, 0.17025571778701346, 0.26187189600889793], 
reward next is 0.7381, 
noisyNet noise sample is [array([-1.7076232], dtype=float32), -0.41504687]. 
=============================================
[2019-03-26 21:26:19,116] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.4382326e-17 1.0000000e+00 3.6698781e-17 2.8097284e-13 2.7562169e-22], sum to 1.0000
[2019-03-26 21:26:19,127] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9253
[2019-03-26 21:26:19,130] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 62.0, 1.0, 2.0, 0.8260160982199958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1242852.539960537, 1242852.539960537, 262490.9453692936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7315200.0000, 
sim time next is 7315800.0000, 
raw observation next is [27.56666666666667, 62.33333333333334, 1.0, 2.0, 0.8200299170893884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1232831.337199867, 1232831.337199868, 260727.6834157234], 
processed observation next is [1.0, 0.6956521739130435, 0.505529225908373, 0.6233333333333334, 1.0, 1.0, 0.783168574806492, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3424531492221853, 0.34245314922218556, 0.38914579614287076], 
reward next is 0.6109, 
noisyNet noise sample is [array([-0.8937504], dtype=float32), -1.5998232]. 
=============================================
[2019-03-26 21:26:20,737] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.7255750e-20 1.0000000e+00 5.9037871e-20 2.9648594e-16 2.0729251e-25], sum to 1.0000
[2019-03-26 21:26:20,748] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6923
[2019-03-26 21:26:20,756] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.4, 61.0, 1.0, 2.0, 0.4492118888303161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 640416.241973249, 640416.2419732496, 177662.1532866675], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6949200.0000, 
sim time next is 6949800.0000, 
raw observation next is [29.55, 60.5, 1.0, 2.0, 0.4520916020901946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 643256.9570040583, 643256.9570040583, 177918.9500055508], 
processed observation next is [0.0, 0.43478260869565216, 0.5995260663507109, 0.605, 1.0, 1.0, 0.3398694001086682, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17868248805668285, 0.17868248805668285, 0.26555067165007584], 
reward next is 0.7344, 
noisyNet noise sample is [array([-0.02712044], dtype=float32), -0.08348547]. 
=============================================
[2019-03-26 21:26:21,464] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1248436: loss 0.2496
[2019-03-26 21:26:21,466] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1248436: learning rate 0.0000
[2019-03-26 21:26:22,765] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1249019: loss 0.2521
[2019-03-26 21:26:22,767] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1249019: learning rate 0.0000
[2019-03-26 21:26:24,974] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 21:26:24,977] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:26:24,979] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:26:24,979] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:26:24,980] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:26:24,981] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:26:24,980] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:26:24,983] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:26:24,982] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:26:24,985] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:26:24,986] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:26:25,013] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run51
[2019-03-26 21:26:25,034] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run51
[2019-03-26 21:26:25,035] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run51
[2019-03-26 21:26:25,082] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run51
[2019-03-26 21:26:25,103] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run51
[2019-03-26 21:26:26,753] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08648594], dtype=float32), 0.06388707]
[2019-03-26 21:26:26,756] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.26666666666667, 66.66666666666667, 1.0, 2.0, 0.4867018564084808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 680084.278176742, 680084.278176742, 181538.8089606444]
[2019-03-26 21:26:26,758] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:26:26,761] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.0831076e-21 1.0000000e+00 1.3895140e-20 2.0647033e-16 2.3728868e-26], sampled 0.17373490504286326
[2019-03-26 21:26:57,941] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08648594], dtype=float32), 0.06388707]
[2019-03-26 21:26:57,946] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.6, 80.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.002168712470443, 6.9112, 168.9068116577663, 2228224.112181839, 1454281.515446444, 311351.5265186779]
[2019-03-26 21:26:57,947] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:26:57,952] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.3091909e-21 1.0000000e+00 3.7888665e-20 1.5886345e-16 5.0589585e-26], sampled 0.608433638346108
[2019-03-26 21:26:57,953] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2228224.112181839 W.
[2019-03-26 21:27:22,936] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08648594], dtype=float32), 0.06388707]
[2019-03-26 21:27:22,940] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.86666666666667, 72.66666666666667, 1.0, 2.0, 0.522529123667235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730164.085593252, 730164.085593252, 187200.5153881304]
[2019-03-26 21:27:22,940] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:27:22,944] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.0056148e-21 1.0000000e+00 4.2381200e-20 1.1120026e-16 7.6527045e-26], sampled 0.7773929893881799
[2019-03-26 21:27:27,483] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08648594], dtype=float32), 0.06388707]
[2019-03-26 21:27:27,484] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.4, 61.0, 1.0, 2.0, 0.6089570585993511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 850983.8653288301, 850983.8653288301, 202425.2174620699]
[2019-03-26 21:27:27,485] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:27:27,487] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.4052710e-19 1.0000000e+00 5.7999713e-18 1.8615429e-13 5.2362844e-24], sampled 0.9978332908990928
[2019-03-26 21:27:27,843] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08648594], dtype=float32), 0.06388707]
[2019-03-26 21:27:27,845] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.8, 63.0, 1.0, 2.0, 0.5889447034860287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 823006.8690628457, 823006.8690628457, 198704.014391289]
[2019-03-26 21:27:27,846] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:27:27,849] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.3704450e-21 1.0000000e+00 2.2486613e-19 1.1431217e-14 6.3621521e-26], sampled 0.7762801708188957
[2019-03-26 21:27:52,020] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08648594], dtype=float32), 0.06388707]
[2019-03-26 21:27:52,022] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.6, 72.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.118214960345339, 6.9112, 168.9116906292082, 2430675.53121014, 2283813.094072767, 475633.5190509565]
[2019-03-26 21:27:52,023] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:27:52,026] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0464828e-11 9.9999976e-01 2.5037399e-11 2.1575686e-07 6.1031862e-15], sampled 0.7505365524129934
[2019-03-26 21:27:52,029] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2430675.53121014 W.
[2019-03-26 21:28:03,279] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08648594], dtype=float32), 0.06388707]
[2019-03-26 21:28:03,281] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.04457568166667, 92.26723350166668, 1.0, 2.0, 0.7347186287862348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1026813.674416743, 1026813.674416742, 228521.8969302607]
[2019-03-26 21:28:03,285] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:28:03,288] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.3351389e-21 1.0000000e+00 2.4035316e-20 8.4589918e-17 3.2513790e-26], sampled 0.24383679000158198
[2019-03-26 21:28:09,666] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08648594], dtype=float32), 0.06388707]
[2019-03-26 21:28:09,667] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.02918843, 85.682323185, 1.0, 2.0, 0.590287423214074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 824883.9496493955, 824883.9496493955, 198945.2463783477]
[2019-03-26 21:28:09,669] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:28:09,671] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.5636837e-21 1.0000000e+00 1.7851721e-20 1.1299062e-16 2.7303425e-26], sampled 0.29892156153413174
[2019-03-26 21:28:16,924] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08648594], dtype=float32), 0.06388707]
[2019-03-26 21:28:16,925] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.2, 78.0, 1.0, 2.0, 0.6565613067290776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 917536.9088724402, 917536.9088724396, 211752.6326119104]
[2019-03-26 21:28:16,927] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:28:16,930] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.4703408e-21 1.0000000e+00 1.4136919e-19 5.0213985e-15 3.1594693e-26], sampled 0.09278198529576032
[2019-03-26 21:28:20,082] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.4890 2927447532.3156 1338.0000
[2019-03-26 21:28:20,339] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 21:28:20,459] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.2905 3164282758.4253 1776.0000
[2019-03-26 21:28:20,588] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.8679 2779270075.9258 933.0000
[2019-03-26 21:28:20,634] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 21:28:21,652] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1250000, evaluation results [1250000.0, 7882.290494044971, 3164282758.4252844, 1776.0, 8253.48903804385, 2927447532.3155904, 1338.0, 8659.867859783146, 2779270075.9258275, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 21:28:21,795] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1250075: loss -358.9633
[2019-03-26 21:28:21,797] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1250075: learning rate 0.0000
[2019-03-26 21:28:22,495] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1250405: loss 19.5470
[2019-03-26 21:28:22,497] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1250405: learning rate 0.0000
[2019-03-26 21:28:22,510] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1250411: loss -319.0936
[2019-03-26 21:28:22,512] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1250412: learning rate 0.0000
[2019-03-26 21:28:22,624] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1250483: loss -245.7261
[2019-03-26 21:28:22,625] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1250484: loss -173.7180
[2019-03-26 21:28:22,627] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1250485: learning rate 0.0000
[2019-03-26 21:28:22,628] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1250485: learning rate 0.0000
[2019-03-26 21:28:22,847] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1250614: loss -148.0398
[2019-03-26 21:28:22,849] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1250616: learning rate 0.0000
[2019-03-26 21:28:23,204] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1250838: loss -216.5729
[2019-03-26 21:28:23,207] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1250839: learning rate 0.0000
[2019-03-26 21:28:23,239] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1250864: loss -175.3718
[2019-03-26 21:28:23,241] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1250867: learning rate 0.0000
[2019-03-26 21:28:23,249] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1250872: loss -136.3660
[2019-03-26 21:28:23,250] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1250872: learning rate 0.0000
[2019-03-26 21:28:23,333] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1250928: loss -169.2467
[2019-03-26 21:28:23,334] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1250928: learning rate 0.0000
[2019-03-26 21:28:23,913] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1251246: loss -233.3013
[2019-03-26 21:28:23,918] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1251247: learning rate 0.0000
[2019-03-26 21:28:27,441] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1252814: loss -417.9342
[2019-03-26 21:28:27,443] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1252814: learning rate 0.0000
[2019-03-26 21:28:29,578] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1253764: loss 0.2336
[2019-03-26 21:28:29,580] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1253764: learning rate 0.0000
[2019-03-26 21:28:32,142] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1254856: loss 0.2563
[2019-03-26 21:28:32,144] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1254856: learning rate 0.0000
[2019-03-26 21:28:35,037] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1256148: loss -412.1733
[2019-03-26 21:28:35,038] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1256148: learning rate 0.0000
[2019-03-26 21:28:36,273] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1256700: loss -125.0167
[2019-03-26 21:28:36,275] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1256700: learning rate 0.0000
[2019-03-26 21:28:37,647] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.8096254e-21 1.0000000e+00 1.0491889e-19 1.4776956e-15 2.9428394e-25], sum to 1.0000
[2019-03-26 21:28:37,655] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5793
[2019-03-26 21:28:37,659] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.96666666666667, 57.5, 1.0, 2.0, 1.000270505240883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1526743.240083183, 1526743.240083183, 318064.6699848701], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7308600.0000, 
sim time next is 7309200.0000, 
raw observation next is [27.93333333333333, 58.00000000000001, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.964758930878284, 6.9112, 168.9124963630703, 1622594.904888347, 1584598.459476157, 331221.0055080327], 
processed observation next is [1.0, 0.6086956521739131, 0.522906793048973, 0.5800000000000001, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.005355893087828356, 0.0, 0.8294376856181053, 0.45072080691342975, 0.44016623874337696, 0.49435970971348164], 
reward next is 0.2378, 
noisyNet noise sample is [array([1.1988012], dtype=float32), 1.1601605]. 
=============================================
[2019-03-26 21:28:39,242] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1258015: loss 0.2168
[2019-03-26 21:28:39,248] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1258017: learning rate 0.0000
[2019-03-26 21:28:40,147] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1258424: loss 0.2188
[2019-03-26 21:28:40,151] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1258426: learning rate 0.0000
[2019-03-26 21:28:40,170] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1258433: loss 0.1965
[2019-03-26 21:28:40,172] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1258434: learning rate 0.0000
[2019-03-26 21:28:40,182] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1258438: loss 0.2174
[2019-03-26 21:28:40,187] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1258438: learning rate 0.0000
[2019-03-26 21:28:40,323] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1258502: loss 0.2088
[2019-03-26 21:28:40,324] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1258502: learning rate 0.0000
[2019-03-26 21:28:40,442] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1258549: loss 0.2092
[2019-03-26 21:28:40,444] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1258549: learning rate 0.0000
[2019-03-26 21:28:41,204] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1258887: loss 0.2087
[2019-03-26 21:28:41,209] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1258889: learning rate 0.0000
[2019-03-26 21:28:41,212] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1258892: loss 0.2067
[2019-03-26 21:28:41,216] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1258894: learning rate 0.0000
[2019-03-26 21:28:41,330] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1258948: loss 0.1925
[2019-03-26 21:28:41,333] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1258949: learning rate 0.0000
[2019-03-26 21:28:41,373] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1258963: loss 0.2115
[2019-03-26 21:28:41,374] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1258963: learning rate 0.0000
[2019-03-26 21:28:42,140] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1259306: loss 0.1929
[2019-03-26 21:28:42,142] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1259307: learning rate 0.0000
[2019-03-26 21:28:43,378] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.0782621e-21 1.0000000e+00 5.1848941e-20 6.1773181e-16 1.2671489e-25], sum to 1.0000
[2019-03-26 21:28:43,386] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4149
[2019-03-26 21:28:43,392] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.96666666666667, 92.0, 1.0, 2.0, 0.6419716570852705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1021055.069585225, 1021055.069585225, 223176.3890289467], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7392000.0000, 
sim time next is 7392600.0000, 
raw observation next is [20.95, 92.0, 1.0, 2.0, 0.6429167467192056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1022892.708885162, 1022892.708885162, 223417.3396784005], 
processed observation next is [1.0, 0.5652173913043478, 0.19194312796208532, 0.92, 1.0, 1.0, 0.5697792129147056, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2841368635792117, 0.2841368635792117, 0.33345871593791115], 
reward next is 0.6665, 
noisyNet noise sample is [array([0.09412554], dtype=float32), -1.6988257]. 
=============================================
[2019-03-26 21:28:46,868] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.934040e-21 1.000000e+00 8.595270e-20 5.989817e-17 2.941682e-26], sum to 1.0000
[2019-03-26 21:28:46,875] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6176
[2019-03-26 21:28:46,879] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.36666666666667, 95.0, 1.0, 2.0, 0.3275686066064395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 511935.0396896502, 511935.0396896502, 167793.3385526447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7453200.0000, 
sim time next is 7453800.0000, 
raw observation next is [21.4, 95.0, 1.0, 2.0, 0.3283968108683529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 512782.1031462479, 512782.1031462479, 167846.8008654031], 
processed observation next is [0.0, 0.2608695652173913, 0.21327014218009477, 0.95, 1.0, 1.0, 0.1908395311666902, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14243947309617996, 0.14243947309617996, 0.2505176132319449], 
reward next is 0.7495, 
noisyNet noise sample is [array([-0.81154436], dtype=float32), 0.3129102]. 
=============================================
[2019-03-26 21:28:47,190] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:28:47,191] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:28:47,234] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1261557: loss -277.2499
[2019-03-26 21:28:47,238] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1261557: learning rate 0.0000
[2019-03-26 21:28:47,253] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run7
[2019-03-26 21:28:49,485] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1262686: loss -353.7505
[2019-03-26 21:28:49,490] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1262687: learning rate 0.0000
[2019-03-26 21:28:51,053] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.8257199e-21 1.0000000e+00 3.3179458e-20 4.7729857e-17 2.6393422e-26], sum to 1.0000
[2019-03-26 21:28:51,064] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9211
[2019-03-26 21:28:51,073] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.36666666666667, 92.33333333333333, 1.0, 2.0, 0.3984910285097117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 590974.3716383805, 590974.3716383805, 173596.6020012604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7526400.0000, 
sim time next is 7527000.0000, 
raw observation next is [23.33333333333333, 92.16666666666667, 1.0, 2.0, 0.3961341364923872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 588624.7158582052, 588624.7158582046, 173415.9105777418], 
processed observation next is [0.0, 0.08695652173913043, 0.30489731437598716, 0.9216666666666667, 1.0, 1.0, 0.27245076685829783, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1635068655161681, 0.16350686551616794, 0.25882971728021165], 
reward next is 0.7412, 
noisyNet noise sample is [array([-0.6147398], dtype=float32), -0.8609969]. 
=============================================
[2019-03-26 21:28:51,104] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[75.68044 ]
 [75.614136]
 [75.507355]
 [75.37582 ]
 [75.22286 ]], R is [[75.75268555]
 [75.7360611 ]
 [75.71914673]
 [75.70196533]
 [75.68463898]].
[2019-03-26 21:28:54,249] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:28:54,249] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:28:54,310] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run7
[2019-03-26 21:28:54,930] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1981709e-20 1.0000000e+00 2.3049995e-20 1.1563792e-16 2.2035711e-26], sum to 1.0000
[2019-03-26 21:28:54,935] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5944
[2019-03-26 21:28:54,940] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 86.0, 1.0, 2.0, 0.9297888318773552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1306386.105237717, 1306386.105237716, 279286.7140862102], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7633800.0000, 
sim time next is 7634400.0000, 
raw observation next is [25.86666666666667, 84.33333333333334, 1.0, 2.0, 1.020149849039546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1431354.713377931, 1431354.71337793, 305976.8251228392], 
processed observation next is [1.0, 0.34782608695652173, 0.42496050552922615, 0.8433333333333334, 1.0, 1.0, 1.0242769265536698, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3975985314938697, 0.3975985314938694, 0.45668182854155104], 
reward next is 0.5433, 
noisyNet noise sample is [array([-1.7582473], dtype=float32), -1.2566968]. 
=============================================
[2019-03-26 21:28:55,216] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:28:55,217] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:28:55,278] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run7
[2019-03-26 21:28:55,912] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.0542932e-21 1.0000000e+00 5.7057555e-20 1.0089197e-16 1.2849646e-25], sum to 1.0000
[2019-03-26 21:28:55,918] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1265729: loss -466.9236
[2019-03-26 21:28:55,920] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2728
[2019-03-26 21:28:55,921] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1265729: learning rate 0.0000
[2019-03-26 21:28:55,928] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.61666666666667, 94.16666666666667, 1.0, 2.0, 0.4206526883465597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 613550.8751311552, 613550.8751311547, 175408.2829786099], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7624200.0000, 
sim time next is 7624800.0000, 
raw observation next is [23.7, 94.0, 1.0, 2.0, 0.424038380884282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 616986.5242341505, 616986.52423415, 175694.964490759], 
processed observation next is [1.0, 0.2608695652173913, 0.3222748815165877, 0.94, 1.0, 1.0, 0.3060703384147976, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17138514562059737, 0.1713851456205972, 0.2622312902847149], 
reward next is 0.7378, 
noisyNet noise sample is [array([-0.49373084], dtype=float32), 0.70228386]. 
=============================================
[2019-03-26 21:28:56,574] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1266086: loss -317.1784
[2019-03-26 21:28:56,578] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1266086: learning rate 0.0000
[2019-03-26 21:28:56,733] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1266159: loss -297.9633
[2019-03-26 21:28:56,734] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1266159: learning rate 0.0000
[2019-03-26 21:28:56,761] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1266168: loss -93.5624
[2019-03-26 21:28:56,763] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1266168: learning rate 0.0000
[2019-03-26 21:28:56,799] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1266183: loss -264.2244
[2019-03-26 21:28:56,805] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1266186: learning rate 0.0000
[2019-03-26 21:28:56,932] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1266244: loss -433.2254
[2019-03-26 21:28:56,935] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1266244: learning rate 0.0000
[2019-03-26 21:28:57,004] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.2333688e-11 9.9999321e-01 2.6565428e-10 6.8258764e-06 1.1605757e-13], sum to 1.0000
[2019-03-26 21:28:57,013] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0815
[2019-03-26 21:28:57,020] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1886183.747199874 W.
[2019-03-26 21:28:57,024] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.23333333333333, 71.0, 1.0, 2.0, 0.7078999992611321, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.976167691954519, 6.9112, 168.9125174233428, 1886183.747199874, 1840093.550323142, 387408.6972833925], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7662000.0000, 
sim time next is 7662600.0000, 
raw observation next is [29.1, 72.0, 1.0, 2.0, 0.6472231837616804, 1.0, 1.0, 0.6472231837616804, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1809718.924389934, 1809718.924389934, 352344.3597162862], 
processed observation next is [1.0, 0.6956521739130435, 0.5781990521327015, 0.72, 1.0, 1.0, 0.574967691279133, 1.0, 0.5, 0.574967691279133, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5026997012194261, 0.5026997012194261, 0.5258871040541585], 
reward next is 0.4741, 
noisyNet noise sample is [array([0.38587478], dtype=float32), -0.9151017]. 
=============================================
[2019-03-26 21:28:57,626] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1266551: loss -390.9491
[2019-03-26 21:28:57,627] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1266552: loss -361.8381
[2019-03-26 21:28:57,631] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1266552: learning rate 0.0000
[2019-03-26 21:28:57,633] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1266552: learning rate 0.0000
[2019-03-26 21:28:57,857] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1266654: loss -394.3419
[2019-03-26 21:28:57,858] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1266654: learning rate 0.0000
[2019-03-26 21:28:57,917] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1266679: loss -477.2451
[2019-03-26 21:28:57,918] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1266679: learning rate 0.0000
[2019-03-26 21:28:58,494] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1266935: loss -557.6746
[2019-03-26 21:28:58,498] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1266935: learning rate 0.0000
[2019-03-26 21:29:01,636] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.8347101e-22 1.0000000e+00 1.0610898e-21 7.9761246e-18 8.5134963e-27], sum to 1.0000
[2019-03-26 21:29:01,643] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3792
[2019-03-26 21:29:01,652] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 89.0, 1.0, 2.0, 0.2975081561231734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 475638.0772194005, 475638.0772194005, 165336.4330564601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 244800.0000, 
sim time next is 245400.0000, 
raw observation next is [21.06666666666667, 89.16666666666667, 1.0, 2.0, 0.2971860017110175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 475310.4594983634, 475310.4594983628, 165315.2776146498], 
processed observation next is [0.0, 0.8695652173913043, 0.19747235387045833, 0.8916666666666667, 1.0, 1.0, 0.1532361466397801, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13203068319398983, 0.13203068319398967, 0.24673922032037282], 
reward next is 0.7533, 
noisyNet noise sample is [array([1.3380648], dtype=float32), -0.16048622]. 
=============================================
[2019-03-26 21:29:01,924] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.3620730e-20 1.0000000e+00 3.6672853e-19 2.1402382e-16 3.6543966e-26], sum to 1.0000
[2019-03-26 21:29:01,930] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4854
[2019-03-26 21:29:01,935] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.95, 89.5, 1.0, 2.0, 0.5670199560653355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 792357.2206313496, 792357.2206313496, 194757.8761450187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7713000.0000, 
sim time next is 7713600.0000, 
raw observation next is [26.1, 89.0, 1.0, 2.0, 0.5906521114172282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 825393.7730333562, 825393.7730333562, 199011.0620205457], 
processed observation next is [1.0, 0.2608695652173913, 0.4360189573459717, 0.89, 1.0, 1.0, 0.5068097727918411, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22927604806482116, 0.22927604806482116, 0.2970314358515608], 
reward next is 0.7030, 
noisyNet noise sample is [array([0.06119556], dtype=float32), 1.577503]. 
=============================================
[2019-03-26 21:29:04,734] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3661855e-21 1.0000000e+00 9.9163698e-20 9.2972983e-17 1.5442031e-25], sum to 1.0000
[2019-03-26 21:29:04,742] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4041
[2019-03-26 21:29:04,746] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.25, 86.0, 1.0, 2.0, 0.7689883759087291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1074731.952577922, 1074731.952577922, 236438.2149592526], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7785000.0000, 
sim time next is 7785600.0000, 
raw observation next is [26.2, 86.33333333333334, 1.0, 2.0, 0.7306928848008548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1021184.748826417, 1021184.748826418, 227606.9774991266], 
processed observation next is [1.0, 0.08695652173913043, 0.44075829383886256, 0.8633333333333334, 1.0, 1.0, 0.6755335961456082, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2836624302295603, 0.28366243022956056, 0.3397119067151143], 
reward next is 0.6603, 
noisyNet noise sample is [array([0.599056], dtype=float32), -0.30967113]. 
=============================================
[2019-03-26 21:29:05,229] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:05,230] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:05,317] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run7
[2019-03-26 21:29:07,196] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:07,197] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:07,254] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run7
[2019-03-26 21:29:10,529] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.9755187e-21 1.0000000e+00 3.0884449e-20 1.6374687e-17 2.8672530e-26], sum to 1.0000
[2019-03-26 21:29:10,543] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6217
[2019-03-26 21:29:10,547] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.03333333333333, 83.33333333333334, 1.0, 2.0, 0.2963295790978868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 471918.240543293, 471918.2405432923, 165048.3676505503], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 289200.0000, 
sim time next is 289800.0000, 
raw observation next is [22.1, 83.0, 1.0, 2.0, 0.2966076757588989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 472137.6107390649, 472137.6107390655, 165060.0192987906], 
processed observation next is [0.0, 0.34782608695652173, 0.24644549763033188, 0.83, 1.0, 1.0, 0.15253936838421553, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13114933631640693, 0.13114933631640707, 0.24635823775938898], 
reward next is 0.7536, 
noisyNet noise sample is [array([0.09433413], dtype=float32), -1.8061823]. 
=============================================
[2019-03-26 21:29:12,847] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.1302936e-21 1.0000000e+00 9.4644681e-20 8.6958096e-16 1.1435252e-25], sum to 1.0000
[2019-03-26 21:29:12,856] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9455
[2019-03-26 21:29:12,859] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.06666666666666, 87.0, 1.0, 2.0, 0.5281639946045908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738040.7943496994, 738040.7943496994, 188126.4933777913], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7940400.0000, 
sim time next is 7941000.0000, 
raw observation next is [26.98333333333333, 87.5, 1.0, 2.0, 0.5277780746609507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 737501.3339908647, 737501.3339908654, 188062.8238960693], 
processed observation next is [1.0, 0.9130434782608695, 0.4778830963665086, 0.875, 1.0, 1.0, 0.4310579212782539, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20486148166412907, 0.20486148166412926, 0.2806907819344318], 
reward next is 0.7193, 
noisyNet noise sample is [array([-0.38041598], dtype=float32), 0.6992662]. 
=============================================
[2019-03-26 21:29:12,867] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[72.95212 ]
 [72.675316]
 [73.171616]
 [73.38717 ]
 [73.64855 ]], R is [[72.73819733]
 [72.73003387]
 [72.72224426]
 [72.71460724]
 [72.70667267]].
[2019-03-26 21:29:13,426] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1316029e-21 1.0000000e+00 3.0464028e-20 3.0034497e-16 3.3531559e-26], sum to 1.0000
[2019-03-26 21:29:13,434] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6838
[2019-03-26 21:29:13,439] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 89.5, 1.0, 2.0, 0.5296601283048128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740132.1758280952, 740132.1758280959, 188373.6006343171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7943400.0000, 
sim time next is 7944000.0000, 
raw observation next is [26.63333333333333, 90.0, 1.0, 2.0, 0.528340222514659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738287.1356138209, 738287.1356138209, 188155.5502397603], 
processed observation next is [1.0, 0.9565217391304348, 0.46129541864139006, 0.9, 1.0, 1.0, 0.43173520784898667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20507975989272803, 0.20507975989272803, 0.2808291794623288], 
reward next is 0.7192, 
noisyNet noise sample is [array([-1.9409417], dtype=float32), 0.67960477]. 
=============================================
[2019-03-26 21:29:13,446] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[72.85538 ]
 [72.80806 ]
 [72.75723 ]
 [72.442696]
 [72.81244 ]], R is [[72.8993988 ]
 [72.88925171]
 [72.87921906]
 [72.86982727]
 [72.86076355]].
[2019-03-26 21:29:13,542] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:13,543] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:13,602] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run7
[2019-03-26 21:29:14,302] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:14,303] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:14,363] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run7
[2019-03-26 21:29:14,539] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:14,539] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:14,552] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:14,553] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:14,590] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run7
[2019-03-26 21:29:14,628] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run7
[2019-03-26 21:29:14,698] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:14,699] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:14,744] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run7
[2019-03-26 21:29:14,779] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:14,779] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:14,820] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run7
[2019-03-26 21:29:15,011] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:15,011] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:15,036] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run7
[2019-03-26 21:29:15,133] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:15,134] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:15,138] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:15,140] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:15,158] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run7
[2019-03-26 21:29:15,191] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run7
[2019-03-26 21:29:15,208] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:15,209] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:15,214] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run7
[2019-03-26 21:29:15,396] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:29:15,396] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:15,405] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run7
[2019-03-26 21:29:15,800] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 21:29:15,802] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:29:15,802] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:15,803] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:29:15,804] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:15,804] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:29:15,805] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:15,809] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run52
[2019-03-26 21:29:15,833] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run52
[2019-03-26 21:29:15,853] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:29:15,853] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run52
[2019-03-26 21:29:15,887] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:15,891] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run52
[2019-03-26 21:29:15,966] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:29:15,966] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:29:15,982] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run52
[2019-03-26 21:30:18,643] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08788411], dtype=float32), 0.06503229]
[2019-03-26 21:30:18,644] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [36.06126448666667, 45.52305199666667, 1.0, 2.0, 0.5735379794390227, 0.0, 2.0, 0.0, 1.0, 2.0, 0.986730187661172, 6.911200000000001, 6.9112, 168.912887357429, 1603543.181827596, 1603543.181827595, 348953.006932994]
[2019-03-26 21:30:18,645] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:30:18,649] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5890659e-11 9.9999809e-01 6.2966604e-11 1.8751178e-06 4.9839283e-15], sampled 0.5318292385052036
[2019-03-26 21:30:35,069] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08788411], dtype=float32), 0.06503229]
[2019-03-26 21:30:35,072] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.66353907666667, 86.2391336, 1.0, 2.0, 0.9467613730549543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1323340.890862259, 1323340.890862259, 283133.1456735725]
[2019-03-26 21:30:35,073] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:30:35,075] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5329609e-21 1.0000000e+00 9.1659270e-21 8.8604503e-17 7.3921968e-27], sampled 0.6989441226715484
[2019-03-26 21:30:36,384] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08788411], dtype=float32), 0.06503229]
[2019-03-26 21:30:36,385] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.04935265333333, 82.66651133333333, 1.0, 2.0, 0.5207678534935817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 727702.1046817146, 727702.1046817146, 186912.9017703226]
[2019-03-26 21:30:36,386] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:30:36,389] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.0598038e-22 1.0000000e+00 2.2363405e-21 2.5840919e-17 2.1089830e-27], sampled 0.03684434337811837
[2019-03-26 21:30:37,311] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08788411], dtype=float32), 0.06503229]
[2019-03-26 21:30:37,313] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.86905448666667, 59.10317726833333, 1.0, 2.0, 0.8874287573245148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1240359.957744914, 1240359.957744914, 266500.1977003572]
[2019-03-26 21:30:37,315] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:30:37,317] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.4088674e-21 1.0000000e+00 2.0567594e-20 1.2155186e-16 3.3250059e-26], sampled 0.07161568916237437
[2019-03-26 21:31:02,469] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08788411], dtype=float32), 0.06503229]
[2019-03-26 21:31:02,470] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.85683427, 69.569237195, 1.0, 2.0, 0.4222274299614619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 619669.4204588145, 619669.4204588139, 176101.7698827869]
[2019-03-26 21:31:02,472] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:31:02,478] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.8394388e-21 1.0000000e+00 3.5462050e-20 1.1498119e-16 6.8915764e-26], sampled 0.5836861485009444
[2019-03-26 21:31:10,928] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3694 2779190338.1949 933.0000
[2019-03-26 21:31:11,046] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.1321 2842434697.4997 1131.0000
[2019-03-26 21:31:11,121] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5735 3007648438.5815 1766.0000
[2019-03-26 21:31:11,182] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.0192 3164167292.2096 1778.0000
[2019-03-26 21:31:11,240] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1249 2927277438.0038 1338.0000
[2019-03-26 21:31:12,255] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1275000, evaluation results [1275000.0, 7884.019182849356, 3164167292.2095833, 1778.0, 8255.124881931173, 2927277438.00382, 1338.0, 8661.369356548688, 2779190338.194891, 933.0, 7997.573465804901, 3007648438.5815053, 1766.0, 8496.132106361554, 2842434697.4996533, 1131.0]
[2019-03-26 21:31:13,711] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4081905e-20 1.0000000e+00 1.0993728e-19 7.7449563e-17 2.1205050e-25], sum to 1.0000
[2019-03-26 21:31:13,729] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3481
[2019-03-26 21:31:13,733] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.3, 84.0, 1.0, 2.0, 0.3294673707365959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 520693.2050942397, 520693.2050942397, 168598.3714326102], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 28800.0000, 
sim time next is 29400.0000, 
raw observation next is [22.51666666666667, 83.0, 1.0, 2.0, 0.3567915519874122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 562941.8508880638, 562941.8508880638, 171995.7415537664], 
processed observation next is [1.0, 0.34782608695652173, 0.2661927330173777, 0.83, 1.0, 1.0, 0.22505006263543637, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1563727363577955, 0.1563727363577955, 0.25671006202054686], 
reward next is 0.7433, 
noisyNet noise sample is [array([0.7716933], dtype=float32), 1.0136361]. 
=============================================
[2019-03-26 21:31:20,599] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0552839e-21 1.0000000e+00 9.7067011e-21 5.8244520e-17 2.6241726e-26], sum to 1.0000
[2019-03-26 21:31:20,612] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0086
[2019-03-26 21:31:20,619] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.61666666666667, 96.0, 1.0, 2.0, 0.7387576761770659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1107018.206574379, 1107018.206574378, 239246.3671416086], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 143400.0000, 
sim time next is 144000.0000, 
raw observation next is [22.6, 96.0, 1.0, 2.0, 0.7789358315697448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1167888.554337311, 1167888.554337311, 249431.4727295514], 
processed observation next is [1.0, 0.6956521739130435, 0.27014218009478685, 0.96, 1.0, 1.0, 0.7336576283972829, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.32441348731591974, 0.32441348731591974, 0.3722857801933603], 
reward next is 0.6277, 
noisyNet noise sample is [array([0.12963986], dtype=float32), -0.6374442]. 
=============================================
[2019-03-26 21:31:20,632] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[73.56706 ]
 [73.63834 ]
 [73.650024]
 [73.66855 ]
 [73.61947 ]], R is [[73.4826355 ]
 [73.39072418]
 [73.30191803]
 [73.21971893]
 [73.13638306]].
[2019-03-26 21:31:23,240] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4129518e-21 1.0000000e+00 2.8124797e-20 2.9407739e-18 3.3608506e-27], sum to 1.0000
[2019-03-26 21:31:23,248] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4066
[2019-03-26 21:31:23,253] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 96.0, 1.0, 2.0, 0.2860759064107357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 460796.9032282293, 460796.9032282293, 164327.4826521666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 186000.0000, 
sim time next is 186600.0000, 
raw observation next is [19.9, 96.0, 1.0, 2.0, 0.286127378626733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 460879.9610897925, 460879.9610897932, 164333.1420590986], 
processed observation next is [0.0, 0.13043478260869565, 0.14218009478672985, 0.96, 1.0, 1.0, 0.1399125043695578, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12802221141383124, 0.12802221141383144, 0.2452733463568636], 
reward next is 0.7547, 
noisyNet noise sample is [array([2.236741], dtype=float32), 0.22945686]. 
=============================================
[2019-03-26 21:31:28,302] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6550226e-20 1.0000000e+00 4.4152957e-19 9.2640549e-17 2.8241802e-25], sum to 1.0000
[2019-03-26 21:31:28,309] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7340
[2019-03-26 21:31:28,314] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.3, 68.5, 1.0, 2.0, 0.4605003215267129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 755739.554287621, 755739.5542876205, 188959.1340844114], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 469800.0000, 
sim time next is 470400.0000, 
raw observation next is [22.43333333333333, 67.66666666666667, 1.0, 2.0, 0.4671205029577186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 766549.5944158662, 766549.5944158655, 190072.9993363132], 
processed observation next is [1.0, 0.43478260869565216, 0.2622432859399683, 0.6766666666666667, 1.0, 1.0, 0.35797650958761285, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21293044289329616, 0.21293044289329596, 0.2836910437855421], 
reward next is 0.7163, 
noisyNet noise sample is [array([0.8932592], dtype=float32), 0.8757659]. 
=============================================
[2019-03-26 21:31:34,835] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4487017e-20 1.0000000e+00 5.6069132e-20 1.5068801e-16 6.0176393e-26], sum to 1.0000
[2019-03-26 21:31:34,847] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5745
[2019-03-26 21:31:34,855] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 85.66666666666667, 1.0, 2.0, 0.2425464766337609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 399465.4648517597, 399465.4648517604, 160169.9418480094], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 433200.0000, 
sim time next is 433800.0000, 
raw observation next is [19.65, 85.5, 1.0, 2.0, 0.2416396750564468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 398145.4098398074, 398145.4098398067, 160078.15637442], 
processed observation next is [1.0, 0.0, 0.13033175355450236, 0.855, 1.0, 1.0, 0.0863128615137913, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11059594717772428, 0.11059594717772409, 0.23892262145435822], 
reward next is 0.7611, 
noisyNet noise sample is [array([-0.12037892], dtype=float32), 1.4494618]. 
=============================================
[2019-03-26 21:31:37,923] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.4755826e-22 1.0000000e+00 3.8989643e-21 1.3269988e-17 2.2778854e-27], sum to 1.0000
[2019-03-26 21:31:37,931] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4784
[2019-03-26 21:31:37,937] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.56666666666667, 89.0, 1.0, 2.0, 0.3091973448710491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 489324.0105647654, 489324.0105647654, 166242.3931793907], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 861000.0000, 
sim time next is 861600.0000, 
raw observation next is [21.53333333333333, 89.0, 1.0, 2.0, 0.3091584772471531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 489622.0235564462, 489622.0235564456, 166271.5381219746], 
processed observation next is [0.0, 1.0, 0.21958925750394942, 0.89, 1.0, 1.0, 0.16766081596042542, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13600611765456838, 0.13600611765456821, 0.2481664748089173], 
reward next is 0.7518, 
noisyNet noise sample is [array([-1.8895836], dtype=float32), -0.66020215]. 
=============================================
[2019-03-26 21:31:41,065] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.8977864e-21 1.0000000e+00 2.3193411e-20 5.4878289e-17 6.4222836e-26], sum to 1.0000
[2019-03-26 21:31:41,071] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9481
[2019-03-26 21:31:41,082] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.15, 53.0, 1.0, 2.0, 0.5912178189896552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 967586.2510941398, 967586.2510941398, 213693.0376814211], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 485400.0000, 
sim time next is 486000.0000, 
raw observation next is [25.1, 53.0, 1.0, 2.0, 0.580819256691232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 951152.6045233355, 951152.6045233348, 211520.7097591924], 
processed observation next is [1.0, 0.6521739130434783, 0.38862559241706174, 0.53, 1.0, 1.0, 0.4949629598689542, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.26420905681203766, 0.26420905681203743, 0.3157025518793916], 
reward next is 0.6843, 
noisyNet noise sample is [array([-0.69742125], dtype=float32), 0.3306481]. 
=============================================
[2019-03-26 21:31:41,101] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[72.32659 ]
 [72.36243 ]
 [72.374344]
 [72.45465 ]
 [72.477165]], R is [[72.30708313]
 [72.26506805]
 [72.2205658 ]
 [72.16687775]
 [72.11756134]].
[2019-03-26 21:31:52,600] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.1324873e-21 1.0000000e+00 1.8275412e-20 3.1405460e-17 2.3468885e-26], sum to 1.0000
[2019-03-26 21:31:52,610] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4064
[2019-03-26 21:31:52,618] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 78.33333333333333, 1.0, 2.0, 0.2456158105228543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 405761.9823307951, 405761.9823307945, 160415.6371487835], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 679200.0000, 
sim time next is 679800.0000, 
raw observation next is [20.21666666666667, 79.16666666666667, 1.0, 2.0, 0.2448214115971884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 404476.7633929561, 404476.7633929567, 160337.0956815377], 
processed observation next is [1.0, 0.8695652173913043, 0.15718799368088482, 0.7916666666666667, 1.0, 1.0, 0.0901462790327571, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11235465649804337, 0.11235465649804352, 0.2393090980321458], 
reward next is 0.7607, 
noisyNet noise sample is [array([-1.0955143], dtype=float32), -0.8193315]. 
=============================================
[2019-03-26 21:31:59,250] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.7850661e-22 1.0000000e+00 3.7986331e-21 3.9255047e-18 5.4453023e-27], sum to 1.0000
[2019-03-26 21:31:59,262] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8830
[2019-03-26 21:31:59,267] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 93.0, 1.0, 2.0, 0.2614158155734548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 427152.6805199397, 427152.6805199391, 162031.5824299034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 793800.0000, 
sim time next is 794400.0000, 
raw observation next is [19.4, 93.0, 1.0, 2.0, 0.2612251365279191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 426841.1356951171, 426841.1356951177, 162012.107858232], 
processed observation next is [0.0, 0.17391304347826086, 0.11848341232227487, 0.93, 1.0, 1.0, 0.10990980304568568, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11856698213753253, 0.1185669821375327, 0.2418091162063164], 
reward next is 0.7582, 
noisyNet noise sample is [array([-0.5971836], dtype=float32), -0.40077654]. 
=============================================
[2019-03-26 21:32:07,883] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 21:32:07,884] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:32:07,885] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:32:07,886] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:32:07,888] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:32:07,889] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:32:07,891] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:32:07,890] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:32:07,893] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:32:07,894] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:32:07,896] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:32:07,916] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run53
[2019-03-26 21:32:07,937] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run53
[2019-03-26 21:32:07,960] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run53
[2019-03-26 21:32:07,961] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run53
[2019-03-26 21:32:07,997] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run53
[2019-03-26 21:32:16,097] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0901381], dtype=float32), 0.06715797]
[2019-03-26 21:32:16,099] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.68683525, 52.69275473, 1.0, 2.0, 0.4560649435929559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 734442.6030743744, 734442.6030743744, 187665.7028377665]
[2019-03-26 21:32:16,100] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:32:16,103] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.2799961e-21 1.0000000e+00 1.7331878e-20 2.4343176e-17 2.9944081e-26], sampled 0.6602852113815284
[2019-03-26 21:32:56,381] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0901381], dtype=float32), 0.06715797]
[2019-03-26 21:32:56,383] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.0, 84.0, 1.0, 2.0, 0.4776390051154442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 667542.1365439373, 667542.1365439373, 180182.5460899989]
[2019-03-26 21:32:56,385] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:32:56,387] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.5028527e-22 1.0000000e+00 2.3214024e-21 1.1346915e-17 2.8437014e-27], sampled 0.9435369421507791
[2019-03-26 21:33:27,359] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0901381], dtype=float32), 0.06715797]
[2019-03-26 21:33:27,361] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [33.64856362, 63.69352908, 1.0, 2.0, 0.9866511905373005, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9129565059739, 1379133.317707846, 1379133.317707847, 294891.0746613542]
[2019-03-26 21:33:27,364] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:33:27,366] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.3526260e-17 1.0000000e+00 2.7447676e-16 1.5390125e-11 1.0794371e-21], sampled 0.9518028723374465
[2019-03-26 21:33:28,085] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0901381], dtype=float32), 0.06715797]
[2019-03-26 21:33:28,086] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.46666666666667, 75.33333333333334, 1.0, 2.0, 0.5556369824682177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 776444.7685845308, 776444.7685845308, 192771.7029487066]
[2019-03-26 21:33:28,087] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:33:28,092] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.5103643e-23 1.0000000e+00 4.1098855e-22 4.6388752e-18 3.1439807e-28], sampled 0.9376725575340955
[2019-03-26 21:33:47,720] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0901381], dtype=float32), 0.06715797]
[2019-03-26 21:33:47,721] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.58409433, 59.72631165, 1.0, 2.0, 0.4202265238787661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 619858.8363460053, 619858.8363460053, 176204.4519318843]
[2019-03-26 21:33:47,722] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:33:47,724] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.5750715e-22 1.0000000e+00 2.0751128e-21 8.1740615e-18 2.7446790e-27], sampled 0.8413476938778428
[2019-03-26 21:33:47,867] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0901381], dtype=float32), 0.06715797]
[2019-03-26 21:33:47,868] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.0, 52.0, 1.0, 2.0, 0.4749011103075036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 663589.5628702575, 663589.5628702568, 179757.0766193429]
[2019-03-26 21:33:47,870] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:33:47,873] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.9736335e-22 1.0000000e+00 2.9033945e-21 9.4795808e-18 3.9991862e-27], sampled 0.06365252836778468
[2019-03-26 21:33:54,781] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0901381], dtype=float32), 0.06715797]
[2019-03-26 21:33:54,782] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.074196705, 86.28207691, 1.0, 2.0, 0.3661620589985237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 561758.9467176615, 561758.9467176622, 171579.4099537619]
[2019-03-26 21:33:54,783] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:33:54,786] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.531864e-22 1.000000e+00 2.766077e-21 4.539582e-18 2.419991e-27], sampled 0.47827212583512957
[2019-03-26 21:33:59,458] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7885.4542 3163966814.6649 1776.0000
[2019-03-26 21:33:59,914] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.4906 2927457840.3776 1338.0000
[2019-03-26 21:33:59,937] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8656.2704 2779489215.6768 933.0000
[2019-03-26 21:33:59,959] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 21:33:59,970] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0947 2842476605.5833 1131.0000
[2019-03-26 21:34:00,986] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1300000, evaluation results [1300000.0, 7885.45417667598, 3163966814.6649485, 1776.0, 8253.490594747309, 2927457840.3775544, 1338.0, 8656.27039530621, 2779489215.676816, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8496.094724748822, 2842476605.583347, 1131.0]
[2019-03-26 21:34:06,123] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8968574e-21 1.0000000e+00 4.7454735e-20 2.4795761e-17 1.0284565e-26], sum to 1.0000
[2019-03-26 21:34:06,135] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5867
[2019-03-26 21:34:06,142] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 97.0, 1.0, 2.0, 0.3607928405584966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 551556.2841985874, 551556.2841985868, 170654.4179159135], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1029600.0000, 
sim time next is 1030200.0000, 
raw observation next is [21.91666666666667, 97.16666666666667, 1.0, 2.0, 0.3622591237435236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 553264.9287388698, 553264.9287388698, 170782.7768147032], 
processed observation next is [1.0, 0.9565217391304348, 0.23775671406003188, 0.9716666666666667, 1.0, 1.0, 0.231637498486173, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15368470242746385, 0.15368470242746385, 0.2548996668876167], 
reward next is 0.7451, 
noisyNet noise sample is [array([-0.24521168], dtype=float32), 0.97219133]. 
=============================================
[2019-03-26 21:34:14,231] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.2303208e-21 1.0000000e+00 4.5917397e-20 1.4563511e-16 6.8947848e-26], sum to 1.0000
[2019-03-26 21:34:14,241] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1273
[2019-03-26 21:34:14,245] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 85.0, 1.0, 2.0, 0.7575287462398848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1135957.378612038, 1135957.378612038, 244002.6636194027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1603200.0000, 
sim time next is 1603800.0000, 
raw observation next is [24.05, 85.0, 1.0, 2.0, 0.7897740726728175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1183587.757241845, 1183587.757241845, 252176.5898389725], 
processed observation next is [1.0, 0.5652173913043478, 0.3388625592417062, 0.85, 1.0, 1.0, 0.7467157502082139, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3287743770116236, 0.3287743770116236, 0.3763829699089142], 
reward next is 0.6236, 
noisyNet noise sample is [array([1.5236118], dtype=float32), 0.09409756]. 
=============================================
[2019-03-26 21:34:16,388] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.3618015e-22 1.0000000e+00 2.5038567e-21 6.3488436e-18 5.9779856e-27], sum to 1.0000
[2019-03-26 21:34:16,396] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0794
[2019-03-26 21:34:16,404] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 70.0, 1.0, 2.0, 0.4530481645940554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 639946.9700882114, 639946.9700882114, 177459.5854733691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1440000.0000, 
sim time next is 1440600.0000, 
raw observation next is [27.93333333333334, 69.83333333333334, 1.0, 2.0, 0.4519402142382168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 639298.9911641382, 639298.9911641382, 177417.5316918393], 
processed observation next is [0.0, 0.6956521739130435, 0.5229067930489735, 0.6983333333333335, 1.0, 1.0, 0.3396870051062853, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1775830531011495, 0.1775830531011495, 0.26480228610722284], 
reward next is 0.7352, 
noisyNet noise sample is [array([-1.1914445], dtype=float32), 1.689843]. 
=============================================
[2019-03-26 21:34:20,224] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3808695e-13 9.9999988e-01 5.5738803e-12 7.6498551e-08 7.5870177e-17], sum to 1.0000
[2019-03-26 21:34:20,232] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6249
[2019-03-26 21:34:20,239] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1962684.722225581 W.
[2019-03-26 21:34:20,247] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.33333333333334, 73.83333333333334, 1.0, 2.0, 0.7625662410992566, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.971277568012139, 6.9112, 168.9125986740915, 1962684.722225581, 1920063.718058791, 399971.6693565893], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1263000.0000, 
sim time next is 1263600.0000, 
raw observation next is [28.3, 74.0, 1.0, 2.0, 0.7719034677860027, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.969660211857937, 6.9112, 168.9125595342627, 1975751.966340749, 1934278.377474224, 402228.3661260952], 
processed observation next is [1.0, 0.6521739130434783, 0.5402843601895735, 0.74, 1.0, 1.0, 0.7251849009469912, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.00584602118579367, 0.0, 0.8294379958175798, 0.548819990650208, 0.5372995492983955, 0.6003408449643212], 
reward next is 0.1074, 
noisyNet noise sample is [array([-1.6103414], dtype=float32), -1.3092178]. 
=============================================
[2019-03-26 21:34:24,653] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3781318e-20 1.0000000e+00 3.9753961e-20 4.5151488e-16 2.8326933e-25], sum to 1.0000
[2019-03-26 21:34:24,664] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0487
[2019-03-26 21:34:24,673] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 88.0, 1.0, 2.0, 0.6708684931586075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1065116.051333728, 1065116.051333728, 229682.4849613019], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1346400.0000, 
sim time next is 1347000.0000, 
raw observation next is [21.46666666666667, 88.16666666666667, 1.0, 2.0, 0.5704487401589996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 906774.0291150539, 906774.0291150539, 207844.0228276239], 
processed observation next is [1.0, 0.6086956521739131, 0.21642969984202226, 0.8816666666666667, 1.0, 1.0, 0.4824683616373489, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.25188167475418166, 0.25188167475418166, 0.3102149594442148], 
reward next is 0.6898, 
noisyNet noise sample is [array([-0.1260429], dtype=float32), 0.88081944]. 
=============================================
[2019-03-26 21:34:24,700] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[73.678215]
 [73.642845]
 [73.74164 ]
 [73.77269 ]
 [73.85411 ]], R is [[73.65369415]
 [73.57434845]
 [73.49263763]
 [73.41475677]
 [73.35221863]].
[2019-03-26 21:34:30,633] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4525524e-22 1.0000000e+00 6.6206291e-22 7.7431500e-18 3.9947034e-27], sum to 1.0000
[2019-03-26 21:34:30,640] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1140
[2019-03-26 21:34:30,647] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 70.0, 1.0, 2.0, 0.4530481645940554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 639946.9700882114, 639946.9700882114, 177459.5854733691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1440000.0000, 
sim time next is 1440600.0000, 
raw observation next is [27.93333333333334, 69.83333333333334, 1.0, 2.0, 0.4519402142382168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 639298.9911641382, 639298.9911641382, 177417.5316918393], 
processed observation next is [0.0, 0.6956521739130435, 0.5229067930489735, 0.6983333333333335, 1.0, 1.0, 0.3396870051062853, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1775830531011495, 0.1775830531011495, 0.26480228610722284], 
reward next is 0.7352, 
noisyNet noise sample is [array([-0.10301185], dtype=float32), -0.22420616]. 
=============================================
[2019-03-26 21:34:32,172] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3972837e-22 1.0000000e+00 4.4790602e-21 1.1547040e-16 3.6183702e-27], sum to 1.0000
[2019-03-26 21:34:32,183] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4235
[2019-03-26 21:34:32,189] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 92.66666666666667, 1.0, 2.0, 0.4540390997547379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 647804.9490534874, 647804.9490534874, 178428.8729174199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1899600.0000, 
sim time next is 1900200.0000, 
raw observation next is [24.31666666666667, 92.83333333333333, 1.0, 2.0, 0.4532830282060038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 646585.4820240797, 646585.4820240802, 178300.4118952776], 
processed observation next is [1.0, 1.0, 0.3515007898894157, 0.9283333333333332, 1.0, 1.0, 0.34130485326024557, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17960707834002212, 0.1796070783400223, 0.2661200177541457], 
reward next is 0.7339, 
noisyNet noise sample is [array([1.1220037], dtype=float32), -0.33999735]. 
=============================================
[2019-03-26 21:34:32,611] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2125268e-21 1.0000000e+00 3.9316903e-20 1.4111463e-15 2.6431796e-27], sum to 1.0000
[2019-03-26 21:34:32,621] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3588
[2019-03-26 21:34:32,629] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.65, 86.5, 1.0, 2.0, 0.5082943590738291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 710266.2688861516, 710266.2688861516, 184905.9869181053], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1714200.0000, 
sim time next is 1714800.0000, 
raw observation next is [26.6, 87.0, 1.0, 2.0, 0.5097277816118588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712269.9366325306, 712269.9366325306, 185134.3652466727], 
processed observation next is [1.0, 0.8695652173913043, 0.4597156398104266, 0.87, 1.0, 1.0, 0.4093105802552516, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19785276017570297, 0.19785276017570297, 0.2763199481293622], 
reward next is 0.7237, 
noisyNet noise sample is [array([-0.8961941], dtype=float32), 1.1785257]. 
=============================================
[2019-03-26 21:34:37,107] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.8191476e-23 1.0000000e+00 4.9587165e-22 7.1122668e-18 9.4503235e-28], sum to 1.0000
[2019-03-26 21:34:37,121] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7866
[2019-03-26 21:34:37,126] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.26666666666667, 90.0, 1.0, 2.0, 0.3444579342784178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 533972.0111294887, 533972.0111294887, 169421.1715931408], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1550400.0000, 
sim time next is 1551000.0000, 
raw observation next is [22.18333333333333, 90.5, 1.0, 2.0, 0.3435328483465633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 532828.480562943, 532828.480562943, 169336.7082593457], 
processed observation next is [0.0, 0.9565217391304348, 0.2503949447077408, 0.905, 1.0, 1.0, 0.20907572089947382, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14800791126748417, 0.14800791126748417, 0.2527413556109637], 
reward next is 0.7473, 
noisyNet noise sample is [array([-1.2970089], dtype=float32), -0.8595739]. 
=============================================
[2019-03-26 21:34:37,140] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[78.0659 ]
 [78.0096 ]
 [77.95387]
 [77.89461]
 [77.82318]], R is [[78.07931519]
 [78.0456543 ]
 [78.01233673]
 [77.97930145]
 [77.94641876]].
[2019-03-26 21:34:39,171] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.0514061e-21 1.0000000e+00 1.0061585e-19 1.2953994e-16 1.5930755e-25], sum to 1.0000
[2019-03-26 21:34:39,180] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5197
[2019-03-26 21:34:39,187] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.41666666666667, 85.00000000000001, 1.0, 2.0, 0.3914057450573952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 598482.06138325, 598482.0613832506, 174773.1832725219], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1584600.0000, 
sim time next is 1585200.0000, 
raw observation next is [23.43333333333333, 85.0, 1.0, 2.0, 0.4809180021870427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 734962.9368181376, 734962.9368181371, 188286.2661040828], 
processed observation next is [1.0, 0.34782608695652173, 0.30963665086887826, 0.85, 1.0, 1.0, 0.3746000026349912, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20415637133837156, 0.20415637133837142, 0.2810242777672878], 
reward next is 0.7190, 
noisyNet noise sample is [array([0.5409486], dtype=float32), 1.0171347]. 
=============================================
[2019-03-26 21:34:40,135] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2744673e-20 1.0000000e+00 2.2996771e-20 3.1246664e-16 2.0248208e-25], sum to 1.0000
[2019-03-26 21:34:40,147] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7916
[2019-03-26 21:34:40,152] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.93333333333333, 85.0, 1.0, 2.0, 0.6382923479185131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 960205.2470163631, 960205.2470163625, 216681.1652413676], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1599600.0000, 
sim time next is 1600200.0000, 
raw observation next is [23.95, 85.0, 1.0, 2.0, 0.6123591816638826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 920756.4851794781, 920756.4851794788, 211193.4751485365], 
processed observation next is [1.0, 0.5217391304347826, 0.3341232227488152, 0.85, 1.0, 1.0, 0.5329628694745573, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2557656903276328, 0.25576569032763297, 0.31521414201274106], 
reward next is 0.6848, 
noisyNet noise sample is [array([0.5422349], dtype=float32), 0.30081767]. 
=============================================
[2019-03-26 21:34:42,728] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.3774523e-23 1.0000000e+00 8.6200197e-22 1.1059399e-17 9.0244445e-28], sum to 1.0000
[2019-03-26 21:34:42,738] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8211
[2019-03-26 21:34:42,744] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.53333333333333, 94.0, 1.0, 2.0, 0.4687473294656851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 657740.7315000216, 657740.7315000216, 179200.0333773325], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2072400.0000, 
sim time next is 2073000.0000, 
raw observation next is [24.51666666666667, 94.0, 1.0, 2.0, 0.4682872902829175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 657590.738664544, 657590.738664544, 179195.8874800015], 
processed observation next is [0.0, 1.0, 0.36097946287519767, 0.94, 1.0, 1.0, 0.3593822774492981, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18266409407348444, 0.18266409407348444, 0.2674565484776142], 
reward next is 0.7325, 
noisyNet noise sample is [array([0.06600285], dtype=float32), 0.09238917]. 
=============================================
[2019-03-26 21:34:42,761] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[78.48384]
 [78.45159]
 [78.42311]
 [78.38984]
 [78.34655]], R is [[78.45426178]
 [78.40225983]
 [78.35077667]
 [78.29975128]
 [78.24909973]].
[2019-03-26 21:34:53,374] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.5465257e-20 1.0000000e+00 2.1820645e-19 1.5893074e-16 4.3224731e-25], sum to 1.0000
[2019-03-26 21:34:53,383] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0457
[2019-03-26 21:34:53,386] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.96666666666667, 93.16666666666666, 1.0, 2.0, 0.3460372273495639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 535188.9095105969, 535188.9095105969, 169485.4041763998], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1821000.0000, 
sim time next is 1821600.0000, 
raw observation next is [22.0, 93.0, 1.0, 2.0, 0.3453446244914873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 533927.2220454625, 533927.2220454625, 169377.4132252798], 
processed observation next is [1.0, 0.08695652173913043, 0.2417061611374408, 0.93, 1.0, 1.0, 0.21125858372468348, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1483131172348507, 0.1483131172348507, 0.2528021092914624], 
reward next is 0.7472, 
noisyNet noise sample is [array([-0.321376], dtype=float32), 0.37672597]. 
=============================================
[2019-03-26 21:34:56,614] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 21:34:56,615] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:34:56,617] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:34:56,617] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:34:56,618] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:34:56,619] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:34:56,621] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:34:56,622] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:34:56,623] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:34:56,620] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:34:56,626] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:34:56,648] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run54
[2019-03-26 21:34:56,668] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run54
[2019-03-26 21:34:56,669] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run54
[2019-03-26 21:34:56,712] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run54
[2019-03-26 21:34:56,713] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run54
[2019-03-26 21:35:31,702] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0875577], dtype=float32), 0.06456214]
[2019-03-26 21:35:31,705] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.3, 82.0, 1.0, 2.0, 0.670485267407717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 937004.0683421745, 937004.0683421738, 214601.8070888437]
[2019-03-26 21:35:31,705] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:35:31,707] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.9034354e-21 1.0000000e+00 2.8677428e-20 5.2601874e-17 3.5830035e-26], sampled 0.9239168022402716
[2019-03-26 21:36:24,534] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0875577], dtype=float32), 0.06456214]
[2019-03-26 21:36:24,535] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.42037378666667, 84.62601232, 1.0, 2.0, 0.8211244365255366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1147636.266052719, 1147636.266052718, 249159.2234722598]
[2019-03-26 21:36:24,538] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:36:24,540] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.0719103e-18 1.0000000e+00 2.3133009e-17 5.6931982e-13 5.4375501e-23], sampled 0.8855004277214499
[2019-03-26 21:36:51,658] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 21:36:51,668] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.4098 3164190979.9668 1776.0000
[2019-03-26 21:36:51,693] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8494.5146 2842683451.9042 1131.0000
[2019-03-26 21:36:51,832] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9767 2779231803.5959 933.0000
[2019-03-26 21:36:51,852] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.1919 2927406475.0554 1338.0000
[2019-03-26 21:36:52,867] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1325000, evaluation results [1325000.0, 7884.409754350378, 3164190979.9668245, 1776.0, 8254.191907072065, 2927406475.055425, 1338.0, 8659.976680226611, 2779231803.5959473, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8494.514649158495, 2842683451.9041815, 1131.0]
[2019-03-26 21:37:01,861] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1516658e-21 1.0000000e+00 1.2230831e-21 1.8666270e-17 6.5989779e-27], sum to 1.0000
[2019-03-26 21:37:01,868] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2329
[2019-03-26 21:37:01,873] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.08333333333333, 90.66666666666666, 1.0, 2.0, 0.5076028214960224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709299.624672002, 709299.624672002, 184796.0986747059], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2029800.0000, 
sim time next is 2030400.0000, 
raw observation next is [26.2, 90.0, 1.0, 2.0, 0.5083006152379825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 710275.0138739177, 710275.0138739183, 184907.0869315164], 
processed observation next is [0.0, 0.5217391304347826, 0.44075829383886256, 0.9, 1.0, 1.0, 0.40759110269636445, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19729861496497716, 0.1972986149649773, 0.2759807267634573], 
reward next is 0.7240, 
noisyNet noise sample is [array([1.5614467], dtype=float32), 1.9114809]. 
=============================================
[2019-03-26 21:37:05,621] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8818878e-21 1.0000000e+00 4.2881572e-21 6.8487552e-18 4.3978799e-27], sum to 1.0000
[2019-03-26 21:37:05,630] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0684
[2019-03-26 21:37:05,637] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.51666666666667, 82.83333333333334, 1.0, 2.0, 0.555518474074829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 776279.1049432408, 776279.1049432408, 192751.8861035321], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2142600.0000, 
sim time next is 2143200.0000, 
raw observation next is [28.33333333333334, 83.66666666666667, 1.0, 2.0, 0.553274880189025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 773142.7755715012, 773142.7755715012, 192364.2066249187], 
processed observation next is [0.0, 0.8260869565217391, 0.5418641390205374, 0.8366666666666667, 1.0, 1.0, 0.46177696408316266, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21476188210319477, 0.21476188210319477, 0.2871107561565951], 
reward next is 0.7129, 
noisyNet noise sample is [array([0.41693655], dtype=float32), 0.3788306]. 
=============================================
[2019-03-26 21:37:06,522] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6832951e-22 1.0000000e+00 2.3993989e-21 3.7256637e-18 6.6970185e-27], sum to 1.0000
[2019-03-26 21:37:06,532] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3897
[2019-03-26 21:37:06,537] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.95, 93.0, 1.0, 2.0, 0.5198918164369748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726477.5436797593, 726477.5436797593, 186771.2839850073], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2158200.0000, 
sim time next is 2158800.0000, 
raw observation next is [25.9, 93.0, 1.0, 2.0, 0.5191090304567378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 725383.3341017362, 725383.3341017356, 186644.0276892886], 
processed observation next is [0.0, 1.0, 0.42654028436018954, 0.93, 1.0, 1.0, 0.42061328970691303, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20149537058381561, 0.20149537058381545, 0.27857317565565465], 
reward next is 0.7214, 
noisyNet noise sample is [array([2.229203], dtype=float32), 1.3567632]. 
=============================================
[2019-03-26 21:37:07,078] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6461459e-21 1.0000000e+00 3.8862088e-21 7.3203921e-18 1.6707704e-26], sum to 1.0000
[2019-03-26 21:37:07,084] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1918
[2019-03-26 21:37:07,093] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 75.83333333333333, 1.0, 2.0, 0.5619807788988245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 785312.8399107563, 785312.8399107563, 193877.3503473001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2119800.0000, 
sim time next is 2120400.0000, 
raw observation next is [30.0, 76.0, 1.0, 2.0, 0.5622836267046358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 785736.1964479298, 785736.1964479298, 193930.428104229], 
processed observation next is [0.0, 0.5652173913043478, 0.6208530805687204, 0.76, 1.0, 1.0, 0.472630875547754, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2182600545688694, 0.2182600545688694, 0.28944840015556567], 
reward next is 0.7106, 
noisyNet noise sample is [array([1.1753764], dtype=float32), 0.7685897]. 
=============================================
[2019-03-26 21:37:08,538] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1452782e-21 1.0000000e+00 6.2221665e-21 2.1174906e-17 4.3270388e-27], sum to 1.0000
[2019-03-26 21:37:08,546] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9612
[2019-03-26 21:37:08,550] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.03333333333333, 80.33333333333333, 1.0, 2.0, 0.5604960811354082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 783237.3559466929, 783237.3559466923, 193617.3095072526], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2140800.0000, 
sim time next is 2141400.0000, 
raw observation next is [28.86666666666667, 81.16666666666667, 1.0, 2.0, 0.5592848233189696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 781544.1212854272, 781544.1212854272, 193406.0303552382], 
processed observation next is [0.0, 0.782608695652174, 0.567140600315956, 0.8116666666666668, 1.0, 1.0, 0.4690178594204452, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21709558924595201, 0.21709558924595201, 0.2886657169481167], 
reward next is 0.7113, 
noisyNet noise sample is [array([1.5181198], dtype=float32), 0.4241985]. 
=============================================
[2019-03-26 21:37:11,900] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1215077e-17 1.0000000e+00 6.9493170e-17 4.9326472e-13 5.8936553e-22], sum to 1.0000
[2019-03-26 21:37:11,909] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4064
[2019-03-26 21:37:11,914] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.35, 80.83333333333333, 1.0, 2.0, 0.9601684494163023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1342092.55043601, 1342092.550436011, 287024.9714171542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2429400.0000, 
sim time next is 2430000.0000, 
raw observation next is [28.3, 81.0, 1.0, 2.0, 0.8873752454859619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1240285.12051485, 1240285.120514849, 266488.8410854603], 
processed observation next is [1.0, 0.13043478260869565, 0.5402843601895735, 0.81, 1.0, 1.0, 0.8643075246818818, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3445236445874583, 0.34452364458745804, 0.39774453893352285], 
reward next is 0.6023, 
noisyNet noise sample is [array([-1.2960314], dtype=float32), -2.1344721]. 
=============================================
[2019-03-26 21:37:11,923] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[60.555763]
 [59.829803]
 [59.749493]
 [62.352207]
 [68.12783 ]], R is [[61.22146606]
 [61.18085861]
 [61.12465286]
 [60.51340866]
 [60.36859512]].
[2019-03-26 21:37:17,416] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.6947063e-21 1.0000000e+00 1.8763978e-20 2.7618126e-17 3.1979928e-26], sum to 1.0000
[2019-03-26 21:37:17,425] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8663
[2019-03-26 21:37:17,430] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.4787173979121028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 668923.8227857114, 668923.8227857107, 180328.5257766519], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2704800.0000, 
sim time next is 2705400.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.4792667362554635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 669691.6689820278, 669691.6689820278, 180411.1458100419], 
processed observation next is [0.0, 0.30434782608695654, 0.3364928909952607, 1.0, 1.0, 1.0, 0.3726105256089922, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18602546360611882, 0.18602546360611882, 0.26927036688065953], 
reward next is 0.7307, 
noisyNet noise sample is [array([1.6953311], dtype=float32), -0.7962104]. 
=============================================
[2019-03-26 21:37:19,864] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.5177733e-21 1.0000000e+00 8.8098483e-20 5.6242977e-16 2.1448135e-25], sum to 1.0000
[2019-03-26 21:37:19,874] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9075
[2019-03-26 21:37:19,878] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.05, 81.0, 1.0, 2.0, 0.5323853369376412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 743941.6393067535, 743941.6393067541, 188825.6811382481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2337000.0000, 
sim time next is 2337600.0000, 
raw observation next is [28.0, 81.0, 1.0, 2.0, 0.5300839181191508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 740724.5742801601, 740724.5742801601, 188443.8136541813], 
processed observation next is [1.0, 0.043478260869565216, 0.5260663507109005, 0.81, 1.0, 1.0, 0.4338360459266877, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20575682618893337, 0.20575682618893337, 0.2812594233644497], 
reward next is 0.7187, 
noisyNet noise sample is [array([-1.8713219], dtype=float32), -0.3573822]. 
=============================================
[2019-03-26 21:37:25,606] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.1019958e-21 1.0000000e+00 3.9542501e-21 3.9009656e-17 9.0085242e-27], sum to 1.0000
[2019-03-26 21:37:25,615] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6943
[2019-03-26 21:37:25,621] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 89.0, 1.0, 2.0, 0.4329971793528517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 628663.3576408663, 628663.3576408663, 176793.8160702822], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2659200.0000, 
sim time next is 2659800.0000, 
raw observation next is [24.16666666666666, 89.0, 1.0, 2.0, 0.4262090879940847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 622792.4104582334, 622792.4104582329, 176329.4834988362], 
processed observation next is [0.0, 0.782608695652174, 0.34439178515007873, 0.89, 1.0, 1.0, 0.30868564818564426, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17299789179395372, 0.17299789179395358, 0.26317833358035253], 
reward next is 0.7368, 
noisyNet noise sample is [array([0.56903577], dtype=float32), 1.4266963]. 
=============================================
[2019-03-26 21:37:29,450] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.3321696e-15 1.0000000e+00 1.1444619e-13 9.8279074e-09 9.4938714e-19], sum to 1.0000
[2019-03-26 21:37:29,460] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6950
[2019-03-26 21:37:29,466] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 85.0, 1.0, 2.0, 0.5352298734017962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 747917.9211063155, 747917.9211063149, 189300.8957934801], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2484000.0000, 
sim time next is 2484600.0000, 
raw observation next is [27.83333333333333, 85.66666666666667, 1.0, 2.0, 0.5380186720661125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 751816.3033612807, 751816.3033612807, 189768.0132462828], 
processed observation next is [1.0, 0.782608695652174, 0.518167456556082, 0.8566666666666667, 1.0, 1.0, 0.4433959904410994, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2088378620448002, 0.2088378620448002, 0.2832358406660937], 
reward next is 0.7168, 
noisyNet noise sample is [array([-0.21419172], dtype=float32), -0.41168654]. 
=============================================
[2019-03-26 21:37:33,348] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1263456e-19 1.0000000e+00 9.9199314e-19 5.3100711e-15 6.0124794e-25], sum to 1.0000
[2019-03-26 21:37:33,360] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3366
[2019-03-26 21:37:33,366] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.5572093849708507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 880900.4277450659, 880900.4277450665, 204798.8753002407], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2991000.0000, 
sim time next is 2991600.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.5497304460693864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 869077.117597409, 869077.117597409, 203339.2766194669], 
processed observation next is [1.0, 0.6521739130434783, 0.19431279620853087, 0.94, 1.0, 1.0, 0.45750656152938113, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2414103104437247, 0.2414103104437247, 0.3034914576409954], 
reward next is 0.6965, 
noisyNet noise sample is [array([-0.43554452], dtype=float32), -0.14047705]. 
=============================================
[2019-03-26 21:37:38,464] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.79383385e-21 1.00000000e+00 6.11330497e-21 3.61504993e-17
 1.13624135e-26], sum to 1.0000
[2019-03-26 21:37:38,473] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1778
[2019-03-26 21:37:38,476] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 82.33333333333334, 1.0, 2.0, 0.495270425329538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 692061.3174084985, 692061.3174084985, 182858.6997948849], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2637600.0000, 
sim time next is 2638200.0000, 
raw observation next is [27.0, 83.16666666666666, 1.0, 2.0, 0.499595863403963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 698107.4123252076, 698107.4123252076, 183533.1453478362], 
processed observation next is [0.0, 0.5217391304347826, 0.4786729857819906, 0.8316666666666666, 1.0, 1.0, 0.39710344988429275, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.193918725645891, 0.193918725645891, 0.2739300676833376], 
reward next is 0.7261, 
noisyNet noise sample is [array([-0.8078866], dtype=float32), -1.9997584]. 
=============================================
[2019-03-26 21:37:41,372] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8787737e-22 1.0000000e+00 3.4498511e-22 1.3357291e-17 1.5222339e-27], sum to 1.0000
[2019-03-26 21:37:41,381] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1397
[2019-03-26 21:37:41,385] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3953053316863929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 589854.1961933773, 589854.1961933773, 173604.2388289574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2672400.0000, 
sim time next is 2673000.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.395570217914681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 590249.5026353665, 590249.5026353665, 173640.5113558316], 
processed observation next is [0.0, 0.9565217391304348, 0.28909952606635075, 0.94, 1.0, 1.0, 0.2717713468851578, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1639581951764907, 0.1639581951764907, 0.2591649423221367], 
reward next is 0.7408, 
noisyNet noise sample is [array([0.2278064], dtype=float32), -0.5840729]. 
=============================================
[2019-03-26 21:37:41,395] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[77.14997 ]
 [77.130875]
 [77.10249 ]
 [77.08114 ]
 [77.077576]], R is [[77.13703918]
 [77.10655975]
 [77.07635498]
 [77.0464325 ]
 [77.01677704]].
[2019-03-26 21:37:42,766] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2507313e-22 1.0000000e+00 9.5575196e-22 8.7777875e-18 3.3466881e-27], sum to 1.0000
[2019-03-26 21:37:42,776] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0625
[2019-03-26 21:37:42,784] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 100.0, 1.0, 2.0, 0.4157842069799606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 610144.6145788797, 610144.6145788797, 175191.8476672653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2715600.0000, 
sim time next is 2716200.0000, 
raw observation next is [22.5, 100.0, 1.0, 2.0, 0.409181697380103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 604254.4559888901, 604254.4559888901, 174749.847841923], 
processed observation next is [0.0, 0.43478260869565216, 0.2654028436018958, 1.0, 1.0, 1.0, 0.28817071973506386, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16784845999691392, 0.16784845999691392, 0.2608206684207806], 
reward next is 0.7392, 
noisyNet noise sample is [array([0.06267849], dtype=float32), -0.23126113]. 
=============================================
[2019-03-26 21:37:44,511] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.4792029e-20 1.0000000e+00 1.5232393e-19 2.0097396e-16 3.8976476e-25], sum to 1.0000
[2019-03-26 21:37:44,524] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6142
[2019-03-26 21:37:44,528] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3395761230537678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 523113.9895834465, 523113.9895834465, 168447.6071190568], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2786400.0000, 
sim time next is 2787000.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.3540312321264625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 545380.3656194228, 545380.3656194228, 170261.4877199658], 
processed observation next is [1.0, 0.2608695652173913, 0.2417061611374408, 0.9400000000000002, 1.0, 1.0, 0.2217243760559789, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15149454600539522, 0.15149454600539522, 0.25412162346263556], 
reward next is 0.7459, 
noisyNet noise sample is [array([0.49589723], dtype=float32), -1.094522]. 
=============================================
[2019-03-26 21:37:44,544] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[70.25965 ]
 [70.24596 ]
 [70.249626]
 [70.18637 ]
 [70.18753 ]], R is [[70.3234787 ]
 [70.36883545]
 [70.41387939]
 [70.458992  ]
 [70.5037384 ]].
[2019-03-26 21:37:48,913] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 21:37:48,915] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:37:48,916] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:37:48,916] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:37:48,917] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:37:48,917] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:37:48,919] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:37:48,920] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:37:48,921] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:37:48,922] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:37:48,919] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:37:48,948] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run55
[2019-03-26 21:37:48,971] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run55
[2019-03-26 21:37:48,991] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run55
[2019-03-26 21:37:48,992] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run55
[2019-03-26 21:37:48,992] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run55
[2019-03-26 21:38:00,766] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08833862], dtype=float32), 0.06461437]
[2019-03-26 21:38:00,767] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.16666666666667, 63.0, 1.0, 2.0, 0.5394786453902297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 793003.3734057762, 793003.3734057762, 194927.454905237]
[2019-03-26 21:38:00,768] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:38:00,770] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.2293385e-21 1.0000000e+00 2.8924519e-20 8.1829881e-17 7.7698966e-26], sampled 0.6436575233186347
[2019-03-26 21:38:06,547] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08833862], dtype=float32), 0.06461437]
[2019-03-26 21:38:06,548] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [18.97532288, 87.80325855333334, 1.0, 2.0, 0.2478166041198559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 409387.4780435792, 409387.4780435792, 160630.3681051942]
[2019-03-26 21:38:06,555] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:38:06,557] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.6298513e-21 1.0000000e+00 1.7878368e-20 4.7816419e-17 3.6967825e-26], sampled 0.4814984254245177
[2019-03-26 21:38:30,181] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08833862], dtype=float32), 0.06461437]
[2019-03-26 21:38:30,185] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.00552509, 93.07956085500001, 1.0, 2.0, 0.4288647517287349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 622451.8972772129, 622451.8972772129, 176180.8770957744]
[2019-03-26 21:38:30,187] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:38:30,191] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.8767795e-22 1.0000000e+00 3.6429648e-21 1.6955553e-17 6.9137180e-27], sampled 0.45935323145394
[2019-03-26 21:38:52,826] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08833862], dtype=float32), 0.06461437]
[2019-03-26 21:38:52,827] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.9, 48.0, 1.0, 2.0, 0.8215131335627761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1148179.818258198, 1148179.818258198, 249262.5482471369]
[2019-03-26 21:38:52,828] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:38:52,835] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.0820151e-21 1.0000000e+00 4.9415191e-20 2.0392102e-15 3.1672285e-26], sampled 0.7498436453368027
[2019-03-26 21:38:56,433] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08833862], dtype=float32), 0.06461437]
[2019-03-26 21:38:56,435] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.0, 79.0, 1.0, 2.0, 0.5220185791478016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729450.423422317, 729450.423422317, 187117.5868678702]
[2019-03-26 21:38:56,438] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:38:56,440] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.9521669e-22 1.0000000e+00 2.2549727e-21 2.6162783e-17 4.5063306e-27], sampled 0.25074812862739526
[2019-03-26 21:39:19,505] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08833862], dtype=float32), 0.06461437]
[2019-03-26 21:39:19,506] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.7, 83.0, 1.0, 2.0, 0.6477390935359809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 905202.712892234, 905202.712892234, 209968.9129767291]
[2019-03-26 21:39:19,508] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:39:19,512] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.6266632e-21 1.0000000e+00 1.3192038e-20 6.0957123e-17 2.4701241e-26], sampled 0.4693940892498941
[2019-03-26 21:39:24,937] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08833862], dtype=float32), 0.06461437]
[2019-03-26 21:39:24,938] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.7, 67.0, 1.0, 2.0, 1.025993549854838, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.988357202091168, 6.9112, 168.9123390349152, 2331385.263497718, 2276647.488887561, 472060.6787407757]
[2019-03-26 21:39:24,940] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:39:24,942] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.8706812e-11 9.9999869e-01 6.3100088e-11 1.3269488e-06 1.7495118e-14], sampled 0.6014035348137232
[2019-03-26 21:39:24,946] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2331385.263497718 W.
[2019-03-26 21:39:33,498] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08833862], dtype=float32), 0.06461437]
[2019-03-26 21:39:33,500] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.60954662, 96.19937646999999, 1.0, 2.0, 0.3996362001461938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 598735.197610952, 598735.1976109525, 174488.5120262746]
[2019-03-26 21:39:33,502] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:39:33,505] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.9708319e-22 1.0000000e+00 4.3038732e-21 2.6481888e-17 6.6609412e-27], sampled 0.20264204875557068
[2019-03-26 21:39:43,274] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.2429 2842674582.9284 1131.0000
[2019-03-26 21:39:43,429] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.3926 3164442528.8259 1776.0000
[2019-03-26 21:39:43,803] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.2902 2927416332.5773 1338.0000
[2019-03-26 21:39:43,854] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7995.9992 3007752696.8220 1766.0000
[2019-03-26 21:39:43,860] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.7905 2779406902.0110 933.0000
[2019-03-26 21:39:44,878] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1350000, evaluation results [1350000.0, 7881.392586968131, 3164442528.825886, 1776.0, 8254.290164618182, 2927416332.5773025, 1338.0, 8659.79050061645, 2779406902.011044, 933.0, 7995.999162255429, 3007752696.8219523, 1766.0, 8497.242939638712, 2842674582.928353, 1131.0]
[2019-03-26 21:39:47,115] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.0749964e-20 1.0000000e+00 3.2883994e-19 6.9073504e-16 9.0493824e-25], sum to 1.0000
[2019-03-26 21:39:47,127] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5382
[2019-03-26 21:39:47,136] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3479205549480015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 535962.7626764473, 535962.7626764467, 169485.5977016161], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2857800.0000, 
sim time next is 2858400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3477500604550242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 535700.2321383464, 535700.2321383464, 169464.1551222687], 
processed observation next is [1.0, 0.08695652173913043, 0.2417061611374408, 0.94, 1.0, 1.0, 0.21415669934340267, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14880562003842956, 0.14880562003842956, 0.2529315748093563], 
reward next is 0.7471, 
noisyNet noise sample is [array([1.1476845], dtype=float32), -1.0336843]. 
=============================================
[2019-03-26 21:39:47,934] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9601280e-21 1.0000000e+00 1.1019628e-20 4.1165173e-17 6.1244702e-26], sum to 1.0000
[2019-03-26 21:39:47,945] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2854
[2019-03-26 21:39:47,951] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.7874252853470698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1174616.704686965, 1174616.704686964, 250870.7695471696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3065400.0000, 
sim time next is 3066000.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.7852241844331339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1171331.216517576, 1171331.216517575, 250300.4449124924], 
processed observation next is [1.0, 0.4782608695652174, 0.28909952606635075, 0.94, 1.0, 1.0, 0.741233957148354, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.32536978236599334, 0.32536978236599307, 0.37358275360073495], 
reward next is 0.6264, 
noisyNet noise sample is [array([0.8332605], dtype=float32), -0.005760203]. 
=============================================
[2019-03-26 21:39:47,965] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[70.36443 ]
 [70.35556 ]
 [70.327644]
 [70.37346 ]
 [70.35174 ]], R is [[70.28408813]
 [70.20681   ]
 [70.13398743]
 [70.04800415]
 [70.00372314]].
[2019-03-26 21:39:48,391] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.4383455e-20 1.0000000e+00 2.2644744e-19 2.0498160e-16 1.8049983e-25], sum to 1.0000
[2019-03-26 21:39:48,397] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3244
[2019-03-26 21:39:48,404] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3460187749729142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 533033.0938952587, 533033.0938952581, 169246.8263457333], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2868000.0000, 
sim time next is 2868600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3453979577601216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 532077.8387668893, 532077.83876689, 169169.26886832], 
processed observation next is [1.0, 0.17391304347826086, 0.2417061611374408, 0.94, 1.0, 1.0, 0.2113228406748453, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14779939965746924, 0.14779939965746944, 0.25249144607211943], 
reward next is 0.7475, 
noisyNet noise sample is [array([-0.02559144], dtype=float32), 1.5031172]. 
=============================================
[2019-03-26 21:39:48,494] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.6909395e-21 1.0000000e+00 2.1742362e-20 9.2484126e-17 1.0401193e-26], sum to 1.0000
[2019-03-26 21:39:48,509] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3420
[2019-03-26 21:39:48,514] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 97.0, 1.0, 2.0, 0.3158403466178733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 500954.1734709924, 500954.1734709924, 167123.6546730745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2921400.0000, 
sim time next is 2922000.0000, 
raw observation next is [20.33333333333333, 98.0, 1.0, 2.0, 0.3125757397116858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 496358.7754493747, 496358.7754493747, 166791.2369796498], 
processed observation next is [1.0, 0.8260869565217391, 0.16271721958925733, 0.98, 1.0, 1.0, 0.17177799965263346, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1378774376248263, 0.1378774376248263, 0.248942144745746], 
reward next is 0.7511, 
noisyNet noise sample is [array([0.6402647], dtype=float32), 0.8156177]. 
=============================================
[2019-03-26 21:39:48,526] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[72.46383]
 [72.4363 ]
 [72.45232]
 [72.44858]
 [72.40666]], R is [[72.46326447]
 [72.48919678]
 [72.51445007]
 [72.53929138]
 [72.56374359]].
[2019-03-26 21:39:50,404] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.6087266e-20 1.0000000e+00 2.9284123e-20 3.4416727e-16 2.0608460e-25], sum to 1.0000
[2019-03-26 21:39:50,413] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8565
[2019-03-26 21:39:50,420] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.6692399577254918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1027449.271806899, 1027449.271806899, 225822.4052598489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2902800.0000, 
sim time next is 2903400.0000, 
raw observation next is [22.5, 91.5, 1.0, 2.0, 0.6907842199617018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1058590.6258932, 1058590.625893201, 230597.951246472], 
processed observation next is [1.0, 0.6086956521739131, 0.2654028436018958, 0.915, 1.0, 1.0, 0.6274508674237371, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.294052951637, 0.2940529516370003, 0.34417604663652535], 
reward next is 0.6558, 
noisyNet noise sample is [array([-1.5535686], dtype=float32), -1.0803365]. 
=============================================
[2019-03-26 21:39:50,884] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.3095277e-21 1.0000000e+00 8.4197668e-20 5.0554346e-16 6.2887024e-26], sum to 1.0000
[2019-03-26 21:39:50,895] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7701
[2019-03-26 21:39:50,900] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.526962387468613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 787175.6370659193, 787175.6370659193, 194221.3347785668], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2898000.0000, 
sim time next is 2898600.0000, 
raw observation next is [22.83333333333334, 94.00000000000001, 1.0, 2.0, 0.5686072264897417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 851744.2705237466, 851744.2705237466, 202139.1769588858], 
processed observation next is [1.0, 0.5652173913043478, 0.2812006319115327, 0.9400000000000002, 1.0, 1.0, 0.4802496704695683, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23659563070104073, 0.23659563070104073, 0.30170026411774], 
reward next is 0.6983, 
noisyNet noise sample is [array([-0.10503859], dtype=float32), -0.88228166]. 
=============================================
[2019-03-26 21:39:56,531] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.5697336e-22 1.0000000e+00 2.6176706e-21 5.5695308e-17 8.5216191e-27], sum to 1.0000
[2019-03-26 21:39:56,538] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2351
[2019-03-26 21:39:56,545] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.5, 73.0, 1.0, 2.0, 0.5976650794464909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 835197.743714509, 835197.7437145095, 200312.3403662385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3259800.0000, 
sim time next is 3260400.0000, 
raw observation next is [31.33333333333333, 73.66666666666667, 1.0, 2.0, 0.5970997092513171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 834407.3656158712, 834407.3656158712, 200207.3675610389], 
processed observation next is [0.0, 0.7391304347826086, 0.6840442338072668, 0.7366666666666667, 1.0, 1.0, 0.514577962953394, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23177982378218642, 0.23177982378218642, 0.2988169665090133], 
reward next is 0.7012, 
noisyNet noise sample is [array([-1.6769469], dtype=float32), -0.30736753]. 
=============================================
[2019-03-26 21:39:59,340] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.6650460e-20 1.0000000e+00 6.0716601e-20 6.9856501e-17 6.1043407e-26], sum to 1.0000
[2019-03-26 21:39:59,350] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1329
[2019-03-26 21:39:59,355] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 97.0, 1.0, 2.0, 0.3158891045644832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 495703.1224979213, 495703.1224979213, 166614.58172773], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3040200.0000, 
sim time next is 3040800.0000, 
raw observation next is [21.0, 98.0, 1.0, 2.0, 0.3202592044005328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 501052.8149874106, 501052.8149874106, 166975.7383874612], 
processed observation next is [1.0, 0.17391304347826086, 0.19431279620853087, 0.98, 1.0, 1.0, 0.1810351860247383, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13918133749650294, 0.13918133749650294, 0.24921751998128538], 
reward next is 0.7508, 
noisyNet noise sample is [array([-1.5741282], dtype=float32), -1.3306655]. 
=============================================
[2019-03-26 21:40:01,566] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.4453425e-22 1.0000000e+00 3.9607112e-21 5.3883607e-17 7.7353212e-27], sum to 1.0000
[2019-03-26 21:40:01,577] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5619
[2019-03-26 21:40:01,584] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 96.0, 1.0, 2.0, 0.4113425000650328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 607420.662355208, 607420.662355208, 175045.2776978148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3094800.0000, 
sim time next is 3095400.0000, 
raw observation next is [23.0, 95.0, 1.0, 2.0, 0.4068317331916693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 603477.5571900024, 603477.557190003, 174755.8674228257], 
processed observation next is [1.0, 0.8260869565217391, 0.28909952606635075, 0.95, 1.0, 1.0, 0.2853394375803245, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16763265477500067, 0.16763265477500083, 0.2608296528698891], 
reward next is 0.7392, 
noisyNet noise sample is [array([1.1818283], dtype=float32), 0.4087742]. 
=============================================
[2019-03-26 21:40:10,783] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.9275438e-22 1.0000000e+00 3.2857377e-21 2.0756317e-17 7.5857643e-27], sum to 1.0000
[2019-03-26 21:40:10,793] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8575
[2019-03-26 21:40:10,800] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.0, 63.00000000000001, 1.0, 2.0, 0.5817994424674762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813018.0712923688, 813018.0712923688, 197404.7590774237], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3252000.0000, 
sim time next is 3252600.0000, 
raw observation next is [33.0, 63.0, 1.0, 2.0, 0.5804348998496559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 811110.5043199442, 811110.5043199449, 197158.2650330917], 
processed observation next is [0.0, 0.6521739130434783, 0.7630331753554502, 0.63, 1.0, 1.0, 0.4944998793369348, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22530847342220672, 0.22530847342220692, 0.29426606721356974], 
reward next is 0.7057, 
noisyNet noise sample is [array([1.5064458], dtype=float32), 1.5541929]. 
=============================================
[2019-03-26 21:40:11,447] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.9818897e-08 8.2733506e-01 1.0080794e-06 1.7266387e-01 4.5978063e-10], sum to 1.0000
[2019-03-26 21:40:11,460] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3545
[2019-03-26 21:40:11,467] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1782942.533973231 W.
[2019-03-26 21:40:11,470] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.83333333333333, 63.0, 1.0, 2.0, 0.4251032702943192, 1.0, 1.0, 0.4251032702943192, 1.0, 2.0, 0.7382637967014997, 6.911200000000001, 6.9112, 170.5573041426782, 1782942.533973231, 1782942.53397323, 367220.5120167193], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3675000.0000, 
sim time next is 3675600.0000, 
raw observation next is [33.0, 63.0, 1.0, 2.0, 0.9750755925458502, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.005991982593865, 6.9112, 168.9123931190018, 2260116.281991317, 2192867.811351934, 455723.2308837916], 
processed observation next is [1.0, 0.5652173913043478, 0.7630331753554502, 0.63, 1.0, 1.0, 0.9699705934287352, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.009479198259386479, 0.0, 0.8294371786424636, 0.6278100783309214, 0.6091299475977594, 0.6801839266922263], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6420575], dtype=float32), -1.5392275]. 
=============================================
[2019-03-26 21:40:24,627] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1586076e-21 1.0000000e+00 7.2525597e-21 2.1526912e-17 3.7745854e-27], sum to 1.0000
[2019-03-26 21:40:24,634] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3119
[2019-03-26 21:40:24,641] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 92.33333333333334, 1.0, 2.0, 0.5751620359736044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 803739.3186089606, 803739.3186089612, 196209.1342637642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3904800.0000, 
sim time next is 3905400.0000, 
raw observation next is [27.16666666666666, 93.16666666666667, 1.0, 2.0, 0.5728608688741702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 800522.4243562263, 800522.4243562256, 195798.149770918], 
processed observation next is [0.0, 0.17391304347826086, 0.4865718799368086, 0.9316666666666668, 1.0, 1.0, 0.48537454081225323, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22236734009895176, 0.22236734009895157, 0.292236044434206], 
reward next is 0.7078, 
noisyNet noise sample is [array([-0.84954035], dtype=float32), 1.812223]. 
=============================================
[2019-03-26 21:40:30,414] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.3620598e-17 1.0000000e+00 2.4091359e-16 8.3318682e-13 3.0451467e-21], sum to 1.0000
[2019-03-26 21:40:30,422] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3559
[2019-03-26 21:40:30,430] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2017694.678239445 W.
[2019-03-26 21:40:30,439] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.66666666666667, 71.33333333333333, 1.0, 2.0, 0.4810220811758265, 1.0, 2.0, 0.4810220811758265, 1.0, 1.0, 0.8259709581907494, 6.9112, 6.9112, 170.5573041426782, 2017694.678239445, 2017694.678239445, 400636.8523954644], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3573600.0000, 
sim time next is 3574200.0000, 
raw observation next is [29.83333333333333, 70.66666666666667, 1.0, 2.0, 0.4802432234385203, 1.0, 2.0, 0.4802432234385203, 1.0, 2.0, 0.8277669493668788, 6.911200000000001, 6.9112, 170.5573041426782, 2014424.610894525, 2014424.610894524, 400671.1605479777], 
processed observation next is [1.0, 0.34782608695652173, 0.6129541864139019, 0.7066666666666667, 1.0, 1.0, 0.3737870161909883, 1.0, 1.0, 0.3737870161909883, 1.0, 1.0, 0.789959694349852, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5595623919151458, 0.5595623919151456, 0.5980166575342951], 
reward next is 0.4020, 
noisyNet noise sample is [array([2.3840146], dtype=float32), 0.769831]. 
=============================================
[2019-03-26 21:40:32,680] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9232582e-18 1.0000000e+00 5.9094967e-17 4.3526058e-13 3.9122667e-22], sum to 1.0000
[2019-03-26 21:40:32,689] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6860
[2019-03-26 21:40:32,701] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2029067.733308447 W.
[2019-03-26 21:40:32,709] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 79.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.721612155932043, 6.9112, 168.9084636780111, 2029067.733308447, 1454148.750049689, 311359.7393482932], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4176000.0000, 
sim time next is 4176600.0000, 
raw observation next is [32.16666666666667, 77.66666666666667, 1.0, 2.0, 0.4860521657983033, 1.0, 1.0, 0.4860521657983033, 1.0, 1.0, 0.8441118720841736, 6.9112, 6.9112, 170.5573041426782, 2038813.942923142, 2038813.942923142, 405637.4101606821], 
processed observation next is [1.0, 0.34782608695652173, 0.7235387045813588, 0.7766666666666667, 1.0, 1.0, 0.38078574192566667, 1.0, 0.5, 0.38078574192566667, 1.0, 0.5, 0.809892526931919, 0.0, 0.0, 0.8375144448122397, 0.5663372063675395, 0.5663372063675395, 0.6054289703890777], 
reward next is 0.3946, 
noisyNet noise sample is [array([2.019282], dtype=float32), 0.7280932]. 
=============================================
[2019-03-26 21:40:40,497] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.77670350e-19 1.00000000e+00 2.60021827e-18 2.58387892e-14
 1.27036385e-23], sum to 1.0000
[2019-03-26 21:40:40,506] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8035
[2019-03-26 21:40:40,513] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 77.33333333333334, 1.0, 2.0, 0.7423142376266154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1055433.815284891, 1055433.815284892, 232701.0231211197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3738000.0000, 
sim time next is 3738600.0000, 
raw observation next is [27.0, 76.5, 1.0, 2.0, 0.7581051865048776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1068852.72550017, 1068852.72550017, 235174.7294630643], 
processed observation next is [1.0, 0.2608695652173913, 0.4786729857819906, 0.765, 1.0, 1.0, 0.7085604656685272, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2969035348611583, 0.2969035348611583, 0.3510070589000959], 
reward next is 0.6490, 
noisyNet noise sample is [array([0.5454497], dtype=float32), -0.030519783]. 
=============================================
[2019-03-26 21:40:40,857] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 21:40:40,859] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:40:40,859] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:40:40,860] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:40:40,861] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:40:40,861] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:40:40,862] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:40:40,864] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:40:40,865] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:40:40,867] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:40:40,868] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:40:40,894] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run56
[2019-03-26 21:40:40,895] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run56
[2019-03-26 21:40:40,941] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run56
[2019-03-26 21:40:40,959] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run56
[2019-03-26 21:40:40,976] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run56
[2019-03-26 21:40:58,762] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08623674], dtype=float32), 0.06263782]
[2019-03-26 21:40:58,765] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.85, 71.5, 1.0, 2.0, 0.2850245150826354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 461050.5064525169, 461050.5064525163, 164336.7713182959]
[2019-03-26 21:40:58,766] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:40:58,770] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.7484119e-20 1.0000000e+00 1.4728022e-19 4.1408370e-16 6.0360580e-25], sampled 0.0685908624241236
[2019-03-26 21:41:04,045] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08623674], dtype=float32), 0.06263782]
[2019-03-26 21:41:04,049] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.92854687, 58.29713357333333, 1.0, 2.0, 0.4585527560685961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 652317.5938059192, 652317.5938059192, 178847.017060014]
[2019-03-26 21:41:04,049] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:41:04,051] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.3163586e-20 1.0000000e+00 4.8198913e-20 3.6856071e-16 1.9817072e-25], sampled 0.491719894217009
[2019-03-26 21:41:09,446] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08623674], dtype=float32), 0.06263782]
[2019-03-26 21:41:09,448] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.0, 92.0, 1.0, 2.0, 0.3938423498093755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 592707.8376502629, 592707.8376502629, 174012.0430028924]
[2019-03-26 21:41:09,450] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:41:09,454] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.2720583e-21 1.0000000e+00 1.9429526e-20 2.6887544e-16 5.0137907e-26], sampled 0.6631923515660998
[2019-03-26 21:41:25,781] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08623674], dtype=float32), 0.06263782]
[2019-03-26 21:41:25,782] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.9, 85.66666666666667, 1.0, 2.0, 0.5272546475909481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 736769.6589615996, 736769.6589616003, 187975.6571304573]
[2019-03-26 21:41:25,782] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:41:25,784] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.5106785e-21 1.0000000e+00 2.2696967e-20 7.6333836e-16 6.6178127e-26], sampled 0.044383559949372486
[2019-03-26 21:41:30,792] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08623674], dtype=float32), 0.06263782]
[2019-03-26 21:41:30,792] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.9, 57.0, 1.0, 2.0, 0.5225064344145554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730132.3695216742, 730132.3695216742, 187196.8082727306]
[2019-03-26 21:41:30,793] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:41:30,795] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.4863526e-21 1.0000000e+00 2.2778848e-20 5.1842323e-16 9.7242804e-26], sampled 0.6203703046030882
[2019-03-26 21:41:35,223] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08623674], dtype=float32), 0.06263782]
[2019-03-26 21:41:35,224] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.46666666666667, 70.66666666666667, 1.0, 2.0, 0.7155666738942693, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.995791155100795, 6.9112, 168.9123845764277, 1896912.305934782, 1836900.632301754, 388449.9390054462]
[2019-03-26 21:41:35,228] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:41:35,230] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.1757576e-10 9.9985898e-01 1.3282705e-09 1.4105543e-04 3.5990961e-13], sampled 0.40637578812400565
[2019-03-26 21:41:35,231] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1896912.305934782 W.
[2019-03-26 21:42:00,987] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08623674], dtype=float32), 0.06263782]
[2019-03-26 21:42:00,988] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [36.3, 52.0, 1.0, 2.0, 0.8964133751278818, 1.0, 2.0, 0.8964133751278818, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2507252.82103856, 2507252.82103856, 469547.7604301787]
[2019-03-26 21:42:00,990] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:42:00,995] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.3108500e-09 9.4016826e-01 2.7740697e-08 5.9831753e-02 8.6106192e-12], sampled 0.0930854097422682
[2019-03-26 21:42:01,000] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2507252.82103856 W.
[2019-03-26 21:42:08,244] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08623674], dtype=float32), 0.06263782]
[2019-03-26 21:42:08,245] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.02662909333334, 83.004423835, 1.0, 2.0, 0.5806289780837517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 811381.8164353975, 811381.8164353975, 197192.3383919733]
[2019-03-26 21:42:08,247] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:42:08,249] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.8664829e-21 1.0000000e+00 1.5370079e-20 6.8112439e-16 3.0409019e-26], sampled 0.688651871264443
[2019-03-26 21:42:22,594] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08623674], dtype=float32), 0.06263782]
[2019-03-26 21:42:22,595] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.2, 96.0, 1.0, 2.0, 0.9565172646157628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1336985.828242042, 1336985.828242042, 285955.0246124357]
[2019-03-26 21:42:22,598] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:42:22,600] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.10067524e-16 1.00000000e+00 1.48231878e-16 2.39701748e-12
 3.47990926e-21], sampled 0.7400979869388266
[2019-03-26 21:42:35,023] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.7489 3164467322.9939 1774.0000
[2019-03-26 21:42:35,186] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7995.9781 3007694799.5541 1766.0000
[2019-03-26 21:42:35,195] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.8473 2927457511.3295 1338.0000
[2019-03-26 21:42:35,360] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.4953 2779298065.2516 933.0000
[2019-03-26 21:42:35,378] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0344 2842500170.3949 1131.0000
[2019-03-26 21:42:36,394] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1375000, evaluation results [1375000.0, 7883.748880879658, 3164467322.993868, 1774.0, 8252.84734365943, 2927457511.3294744, 1338.0, 8658.49531214752, 2779298065.2516174, 933.0, 7995.978053101541, 3007694799.554066, 1766.0, 8496.034361333246, 2842500170.394918, 1131.0]
[2019-03-26 21:42:48,495] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7065376e-21 1.0000000e+00 7.0919097e-21 2.4178270e-16 1.8802039e-26], sum to 1.0000
[2019-03-26 21:42:48,505] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6027
[2019-03-26 21:42:48,507] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4295640e-20 1.0000000e+00 3.1992961e-20 2.6255779e-16 2.4377367e-25], sum to 1.0000
[2019-03-26 21:42:48,508] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.5, 73.0, 1.0, 2.0, 0.6041539172788504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 844269.0728390906, 844269.0728390906, 201522.530803418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3965400.0000, 
sim time next is 3966000.0000, 
raw observation next is [31.66666666666666, 72.33333333333333, 1.0, 2.0, 0.605403271208467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 846015.6657879984, 846015.665787999, 201757.0875099954], 
processed observation next is [0.0, 0.9130434782608695, 0.6998420221169034, 0.7233333333333333, 1.0, 1.0, 0.5245822544680325, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23500435160777733, 0.23500435160777752, 0.3011299813582021], 
reward next is 0.6989, 
noisyNet noise sample is [array([-0.5417014], dtype=float32), -0.646222]. 
=============================================
[2019-03-26 21:42:48,517] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5251
[2019-03-26 21:42:48,522] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[73.75029]
 [73.74129]
 [73.70403]
 [73.64249]
 [73.56388]], R is [[73.74545288]
 [73.70721436]
 [73.6692276 ]
 [73.62994385]
 [73.59354401]].
[2019-03-26 21:42:48,523] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 87.33333333333334, 1.0, 2.0, 0.5074482523920161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709083.5651957112, 709083.5651957105, 184771.0468655145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4515600.0000, 
sim time next is 4516200.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.5085835229625861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 710670.4678615045, 710670.4678615045, 184951.6564859185], 
processed observation next is [0.0, 0.2608695652173913, 0.4549763033175356, 0.865, 1.0, 1.0, 0.40793195537660976, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19740846329486236, 0.19740846329486236, 0.2760472484864455], 
reward next is 0.7240, 
noisyNet noise sample is [array([1.3058047], dtype=float32), 0.1997451]. 
=============================================
[2019-03-26 21:42:48,865] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3560930e-12 9.9985790e-01 1.5454650e-11 1.4203068e-04 5.3540593e-16], sum to 1.0000
[2019-03-26 21:42:48,874] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5261
[2019-03-26 21:42:48,882] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.33333333333334, 65.66666666666667, 1.0, 2.0, 0.5435444189643169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 759540.6298902467, 759540.6298902467, 190702.9414364648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4383600.0000, 
sim time next is 4384200.0000, 
raw observation next is [32.16666666666666, 66.33333333333333, 1.0, 2.0, 0.5546009538050467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 774996.4983625632, 774996.4983625638, 192595.2098592759], 
processed observation next is [1.0, 0.7391304347826086, 0.7235387045813582, 0.6633333333333333, 1.0, 1.0, 0.4633746431386105, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.215276805100712, 0.21527680510071215, 0.2874555371033969], 
reward next is 0.7125, 
noisyNet noise sample is [array([1.1290386], dtype=float32), -0.48360342]. 
=============================================
[2019-03-26 21:42:49,415] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.4802200e-22 1.0000000e+00 4.4391379e-21 1.0143378e-16 2.2921981e-27], sum to 1.0000
[2019-03-26 21:42:49,423] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2272
[2019-03-26 21:42:49,427] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.16666666666666, 83.16666666666666, 1.0, 2.0, 0.6205568352776938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 867200.5304170754, 867200.5304170754, 204638.3574451312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3973800.0000, 
sim time next is 3974400.0000, 
raw observation next is [30.0, 84.0, 1.0, 2.0, 0.6196818803016998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 865977.3213539168, 865977.3213539174, 204470.1066768142], 
processed observation next is [1.0, 0.0, 0.6208530805687204, 0.84, 1.0, 1.0, 0.5417853979538552, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24054925593164356, 0.24054925593164372, 0.30517926369673765], 
reward next is 0.6948, 
noisyNet noise sample is [array([-1.3217442], dtype=float32), -0.33472845]. 
=============================================
[2019-03-26 21:42:54,568] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2700343e-20 1.0000000e+00 1.3048005e-19 1.5396591e-14 1.3199505e-25], sum to 1.0000
[2019-03-26 21:42:54,574] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0408
[2019-03-26 21:42:54,580] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.6231511112308057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 870827.4017313664, 870827.4017313664, 205138.6838726971], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4320000.0000, 
sim time next is 4320600.0000, 
raw observation next is [30.83333333333334, 79.83333333333334, 1.0, 2.0, 0.6263210589470625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 875259.0952998261, 875259.0952998255, 205752.1866650157], 
processed observation next is [1.0, 0.0, 0.6603475513428123, 0.7983333333333335, 1.0, 1.0, 0.5497844083699548, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24312752647217392, 0.24312752647217376, 0.30709281591793386], 
reward next is 0.6929, 
noisyNet noise sample is [array([1.0020816], dtype=float32), -1.7320025]. 
=============================================
[2019-03-26 21:42:55,942] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.1205532e-09 1.5312723e-02 3.4043392e-08 9.8468727e-01 7.3679240e-12], sum to 1.0000
[2019-03-26 21:42:55,948] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9925
[2019-03-26 21:42:55,953] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.66666666666667, 68.33333333333334, 1.0, 2.0, 0.3083886617554669, 1.0, 2.0, 0.3083886617554669, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 861913.3162742543, 861913.3162742543, 251538.5000548629], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4123200.0000, 
sim time next is 4123800.0000, 
raw observation next is [33.5, 69.0, 1.0, 2.0, 0.3054191406077121, 1.0, 2.0, 0.3054191406077121, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 853610.5194181312, 853610.5194181312, 250952.5416520915], 
processed observation next is [1.0, 0.7391304347826086, 0.7867298578199052, 0.69, 1.0, 1.0, 0.163155591093629, 1.0, 1.0, 0.163155591093629, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.23711403317170313, 0.23711403317170313, 0.37455603231655443], 
reward next is 0.6254, 
noisyNet noise sample is [array([3.8850987], dtype=float32), 0.970674]. 
=============================================
[2019-03-26 21:43:01,548] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.62437552e-21 1.00000000e+00 1.15862865e-20 2.32761530e-16
 1.08289463e-26], sum to 1.0000
[2019-03-26 21:43:01,553] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1866
[2019-03-26 21:43:01,556] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 81.5, 1.0, 2.0, 0.5835800211355796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 815507.2424217336, 815507.2424217336, 197726.8947056104], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4433400.0000, 
sim time next is 4434000.0000, 
raw observation next is [29.66666666666667, 80.66666666666667, 1.0, 2.0, 0.5844406942784548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 816710.4279373143, 816710.4279373143, 197883.1917347989], 
processed observation next is [0.0, 0.30434782608695654, 0.6050552922590839, 0.8066666666666668, 1.0, 1.0, 0.49932613768488526, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22686400776036508, 0.22686400776036508, 0.29534804736537146], 
reward next is 0.7047, 
noisyNet noise sample is [array([-0.00836619], dtype=float32), 0.078427956]. 
=============================================
[2019-03-26 21:43:01,566] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[71.87411]
 [71.87487]
 [71.86579]
 [71.84547]
 [71.82927]], R is [[71.86144257]
 [71.84771729]
 [71.8343811 ]
 [71.82146454]
 [71.80890656]].
[2019-03-26 21:43:11,467] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.9494666e-20 1.0000000e+00 8.3349536e-20 4.3883186e-16 4.9134029e-26], sum to 1.0000
[2019-03-26 21:43:11,475] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9888
[2019-03-26 21:43:11,479] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 85.66666666666667, 1.0, 2.0, 0.4890695399877618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 683393.7833797967, 683393.7833797967, 181900.7411829323], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4508400.0000, 
sim time next is 4509000.0000, 
raw observation next is [26.0, 86.5, 1.0, 2.0, 0.4916380989483277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 686984.0802107382, 686984.0802107382, 182295.9628613867], 
processed observation next is [0.0, 0.17391304347826086, 0.4312796208530806, 0.865, 1.0, 1.0, 0.3875157818654551, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1908289111696495, 0.1908289111696495, 0.27208352665878616], 
reward next is 0.7279, 
noisyNet noise sample is [array([2.279204], dtype=float32), 0.50083464]. 
=============================================
[2019-03-26 21:43:11,494] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[70.94415 ]
 [71.050125]
 [71.19735 ]
 [71.2498  ]
 [71.386604]], R is [[70.84243011]
 [70.86251068]
 [70.88285828]
 [70.9030838 ]
 [70.92211914]].
[2019-03-26 21:43:15,820] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.21535386e-20 1.00000000e+00 9.43879706e-20 9.18499129e-16
 7.20068783e-26], sum to 1.0000
[2019-03-26 21:43:15,830] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8015
[2019-03-26 21:43:15,834] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.0, 51.5, 1.0, 2.0, 0.5282437871637812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738152.332860504, 738152.332860504, 188140.407343605], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4545000.0000, 
sim time next is 4545600.0000, 
raw observation next is [34.0, 52.0, 1.0, 2.0, 0.5316923754061694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 742972.973956, 742972.9739560005, 188711.4153926059], 
processed observation next is [0.0, 0.6086956521739131, 0.8104265402843602, 0.52, 1.0, 1.0, 0.4357739462724933, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20638138165444442, 0.20638138165444458, 0.2816588289441879], 
reward next is 0.7183, 
noisyNet noise sample is [array([1.037641], dtype=float32), 0.9493289]. 
=============================================
[2019-03-26 21:43:16,887] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.19141593e-19 1.00000000e+00 6.53582285e-19 1.16931086e-14
 7.87821137e-25], sum to 1.0000
[2019-03-26 21:43:16,894] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3150
[2019-03-26 21:43:16,898] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6945860471020369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 970700.3330538451, 970700.3330538458, 219677.5756208749], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4765200.0000, 
sim time next is 4765800.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.708105031886024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 989602.2348464536, 989602.2348464536, 222601.007603375], 
processed observation next is [1.0, 0.13043478260869565, 0.4786729857819906, 0.79, 1.0, 1.0, 0.6483193155253302, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.27488950967957043, 0.27488950967957043, 0.3322403098557836], 
reward next is 0.6678, 
noisyNet noise sample is [array([0.8361412], dtype=float32), 0.5570114]. 
=============================================
[2019-03-26 21:43:18,060] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.8339348e-21 1.0000000e+00 6.4021479e-20 2.4108989e-14 7.8659516e-27], sum to 1.0000
[2019-03-26 21:43:18,069] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9387
[2019-03-26 21:43:18,075] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.4916469807593624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 686996.4951066292, 686996.4951066292, 182297.5075026217], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4824600.0000, 
sim time next is 4825200.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.4917798306321272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 687182.1911867269, 687182.1911867263, 182317.988432442], 
processed observation next is [1.0, 0.8695652173913043, 0.5260663507109005, 0.74, 1.0, 1.0, 0.38768654293027377, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19088394199631303, 0.19088394199631287, 0.27211640064543585], 
reward next is 0.7279, 
noisyNet noise sample is [array([-1.1921592], dtype=float32), 0.42496464]. 
=============================================
[2019-03-26 21:43:18,309] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.1674155e-15 1.0000000e+00 4.3666793e-15 5.2173276e-11 5.1658622e-20], sum to 1.0000
[2019-03-26 21:43:18,310] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7877
[2019-03-26 21:43:18,311] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2110689.940516744 W.
[2019-03-26 21:43:18,314] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.83333333333334, 85.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.836591079902609, 6.9112, 168.9080727557776, 2110689.940516744, 1454204.640339447, 311351.6167532798], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4590600.0000, 
sim time next is 4591200.0000, 
raw observation next is [27.66666666666667, 87.33333333333334, 1.0, 2.0, 0.6199977019235015, 1.0, 1.0, 0.6199977019235015, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1733531.411995558, 1733531.411995558, 341758.0542806917], 
processed observation next is [1.0, 0.13043478260869565, 0.5102685624012641, 0.8733333333333334, 1.0, 1.0, 0.5421659059319295, 1.0, 0.5, 0.5421659059319295, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.48153650333209946, 0.48153650333209946, 0.5100866481801369], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.60416156], dtype=float32), -0.46346667]. 
=============================================
[2019-03-26 21:43:22,403] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 21:43:22,405] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:43:22,406] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:43:22,407] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:43:22,408] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:43:22,408] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:43:22,409] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:43:22,409] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:43:22,411] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:43:22,413] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:43:22,412] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:43:22,433] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run57
[2019-03-26 21:43:22,451] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run57
[2019-03-26 21:43:22,469] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run57
[2019-03-26 21:43:22,486] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run57
[2019-03-26 21:43:22,507] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run57
[2019-03-26 21:43:29,457] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0869686], dtype=float32), 0.063423045]
[2019-03-26 21:43:29,457] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [17.55141358833333, 82.54672072833334, 1.0, 2.0, 0.1984260857322282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 331920.9120095365, 331920.9120095359, 144649.2408638663]
[2019-03-26 21:43:29,458] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:43:29,461] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.0157721e-21 1.0000000e+00 1.2195941e-20 1.0625627e-16 3.0213607e-26], sampled 0.6999599876628328
[2019-03-26 21:43:38,519] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0869686], dtype=float32), 0.063423045]
[2019-03-26 21:43:38,521] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.70086586333333, 95.47565069999999, 1.0, 2.0, 0.5144807578823076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 738145.0711114771, 738145.0711114777, 188343.7254724487]
[2019-03-26 21:43:38,522] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:43:38,530] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.7553659e-21 1.0000000e+00 2.8039846e-20 2.1222061e-16 5.8125059e-26], sampled 0.09215349146266527
[2019-03-26 21:43:42,518] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0869686], dtype=float32), 0.063423045]
[2019-03-26 21:43:42,520] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.937147985, 97.97597239999999, 1.0, 2.0, 0.4775756851458438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 671870.740742597, 671870.7407425963, 180742.4242351757]
[2019-03-26 21:43:42,521] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:43:42,523] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.5246723e-21 1.0000000e+00 1.3930062e-20 1.1739130e-16 2.7388967e-26], sampled 0.4185027873404207
[2019-03-26 21:44:04,863] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0869686], dtype=float32), 0.063423045]
[2019-03-26 21:44:04,864] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.53333333333333, 67.83333333333334, 1.0, 2.0, 0.5501857074120904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 768824.4230489734, 768824.4230489734, 191831.8394665512]
[2019-03-26 21:44:04,867] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:44:04,870] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.1263040e-21 1.0000000e+00 1.8713368e-20 4.5290179e-16 6.9336091e-26], sampled 0.6895972211548241
[2019-03-26 21:44:18,232] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0869686], dtype=float32), 0.063423045]
[2019-03-26 21:44:18,235] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [35.0, 56.66666666666667, 1.0, 2.0, 0.9341456396989677, 1.0, 2.0, 0.7876628593637466, 1.0, 1.0, 1.03, 7.005116201589427, 6.9112, 170.5573041426782, 3305674.328041233, 3238398.332575899, 605492.4773824506]
[2019-03-26 21:44:18,236] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:44:18,239] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.3399706e-07 9.2127490e-01 2.1453940e-07 7.8724757e-02 6.3376426e-10], sampled 0.6656214461141287
[2019-03-26 21:44:18,241] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 3305674.328041233 W.
[2019-03-26 21:44:20,636] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0869686], dtype=float32), 0.063423045]
[2019-03-26 21:44:20,636] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.83333333333334, 61.0, 1.0, 2.0, 0.5820174898314836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813322.8916605702, 813322.8916605702, 197442.7890554515]
[2019-03-26 21:44:20,637] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:44:20,640] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.8339012e-22 1.0000000e+00 3.5550478e-21 3.5206159e-16 5.9231436e-27], sampled 0.7648261754932
[2019-03-26 21:44:50,473] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0869686], dtype=float32), 0.063423045]
[2019-03-26 21:44:50,474] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.93333333333333, 83.0, 1.0, 2.0, 0.7029972418040268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 982460.6127035277, 982460.6127035277, 221493.8093798092]
[2019-03-26 21:44:50,474] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:44:50,477] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.5012737e-21 1.0000000e+00 1.5340672e-20 2.5528673e-16 3.0549353e-26], sampled 0.44961730583347315
[2019-03-26 21:44:53,470] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0869686], dtype=float32), 0.063423045]
[2019-03-26 21:44:53,471] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.44008523500001, 76.30308219666667, 1.0, 2.0, 0.4766017010118945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 675312.4995554831, 675312.4995554831, 181211.107939546]
[2019-03-26 21:44:53,473] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:44:53,476] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.2770235e-21 1.0000000e+00 6.7033267e-21 3.1164049e-16 1.4710227e-26], sampled 0.6008111799677385
[2019-03-26 21:45:10,106] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.9447 2927328032.1726 1338.0000
[2019-03-26 21:45:10,136] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4308 2779149198.4617 933.0000
[2019-03-26 21:45:10,143] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0572 2842501283.5234 1131.0000
[2019-03-26 21:45:10,149] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.1786 3007673141.5034 1766.0000
[2019-03-26 21:45:10,315] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7886.1432 3164247243.6115 1774.0000
[2019-03-26 21:45:11,329] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1400000, evaluation results [1400000.0, 7886.143234674578, 3164247243.611454, 1774.0, 8252.944690175233, 2927328032.1725616, 1338.0, 8661.430759135581, 2779149198.4616733, 933.0, 7998.178555504131, 3007673141.5034175, 1766.0, 8496.057156619567, 2842501283.523376, 1131.0]
[2019-03-26 21:45:11,992] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.2536621e-10 9.9991322e-01 6.0184746e-10 8.6736363e-05 4.6464536e-13], sum to 1.0000
[2019-03-26 21:45:12,004] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7012
[2019-03-26 21:45:12,014] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2608439.862430869 W.
[2019-03-26 21:45:12,019] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.33333333333334, 73.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.364504169455659, 6.9112, 168.9107342542745, 2608439.862430869, 2286854.513997095, 475252.0999860935], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4702800.0000, 
sim time next is 4703400.0000, 
raw observation next is [30.5, 72.5, 1.0, 2.0, 0.9141295910176921, 1.0, 1.0, 0.9141295910176921, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2556855.472532397, 2556855.472532398, 479258.3450189958], 
processed observation next is [1.0, 0.43478260869565216, 0.6445497630331753, 0.725, 1.0, 1.0, 0.8965416759249302, 1.0, 0.5, 0.8965416759249302, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7102376312589992, 0.7102376312589994, 0.7153109627149191], 
reward next is 0.2847, 
noisyNet noise sample is [array([-0.33137867], dtype=float32), -0.7775185]. 
=============================================
[2019-03-26 21:45:14,141] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.6637177e-17 1.0000000e+00 3.3886892e-16 3.3059289e-10 1.6973314e-21], sum to 1.0000
[2019-03-26 21:45:14,150] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4747
[2019-03-26 21:45:14,154] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 72.0, 1.0, 2.0, 0.5182711362656339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 724212.0933095437, 724212.0933095431, 186509.159270535], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4732200.0000, 
sim time next is 4732800.0000, 
raw observation next is [29.33333333333334, 72.66666666666666, 1.0, 2.0, 0.5182901086495677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 724238.6136246986, 724238.6136246986, 186512.1054916852], 
processed observation next is [1.0, 0.782608695652174, 0.5892575039494474, 0.7266666666666666, 1.0, 1.0, 0.41962663692719, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20117739267352738, 0.20117739267352738, 0.2783762768532615], 
reward next is 0.7216, 
noisyNet noise sample is [array([0.22083218], dtype=float32), -1.4552605]. 
=============================================
[2019-03-26 21:45:14,350] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2768756e-21 1.0000000e+00 2.5858924e-20 2.2114654e-15 4.8423971e-26], sum to 1.0000
[2019-03-26 21:45:14,360] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2710
[2019-03-26 21:45:14,366] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5156445368819844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 720540.5398331, 720540.5398331007, 186083.7356781453], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4741200.0000, 
sim time next is 4741800.0000, 
raw observation next is [28.0, 79.00000000000001, 1.0, 2.0, 0.5152865481673516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 720040.1315345133, 720040.131534514, 186026.0277832874], 
processed observation next is [1.0, 0.9130434782608695, 0.5260663507109005, 0.7900000000000001, 1.0, 1.0, 0.41600788935825495, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2000111476484759, 0.2000111476484761, 0.27765078773624985], 
reward next is 0.7223, 
noisyNet noise sample is [array([-0.8929174], dtype=float32), 0.12581585]. 
=============================================
[2019-03-26 21:45:15,003] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7889416e-21 1.0000000e+00 5.3489292e-20 2.6414621e-15 1.0567124e-26], sum to 1.0000
[2019-03-26 21:45:15,012] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8065
[2019-03-26 21:45:15,019] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5172390205246137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722769.3639248497, 722769.3639248497, 186341.2278548926], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4738800.0000, 
sim time next is 4739400.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5176297980677346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723315.606932321, 723315.606932321, 186404.4491686033], 
processed observation next is [1.0, 0.8695652173913043, 0.5260663507109005, 0.79, 1.0, 1.0, 0.41883108200931873, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20092100192564472, 0.20092100192564472, 0.2782155957740348], 
reward next is 0.7218, 
noisyNet noise sample is [array([-0.85841066], dtype=float32), 0.6708544]. 
=============================================
[2019-03-26 21:45:20,945] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.6015550e-20 1.0000000e+00 3.8251892e-19 4.6272173e-15 2.0988406e-25], sum to 1.0000
[2019-03-26 21:45:20,954] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4089
[2019-03-26 21:45:20,963] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.83333333333334, 1.0, 2.0, 0.6573587196675788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 918651.7662806674, 918651.7662806674, 211907.3129420844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4849800.0000, 
sim time next is 4850400.0000, 
raw observation next is [27.0, 80.66666666666667, 1.0, 2.0, 0.6177226191331104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 863238.2300704888, 863238.2300704888, 204085.358952211], 
processed observation next is [1.0, 0.13043478260869565, 0.4786729857819906, 0.8066666666666668, 1.0, 1.0, 0.5394248423290487, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23978839724180243, 0.23978839724180243, 0.30460501336150897], 
reward next is 0.6954, 
noisyNet noise sample is [array([-0.7610256], dtype=float32), 0.7225747]. 
=============================================
[2019-03-26 21:45:21,725] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.4341157e-17 1.0000000e+00 2.8440954e-17 6.0475605e-13 8.4653944e-22], sum to 1.0000
[2019-03-26 21:45:21,737] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3427
[2019-03-26 21:45:21,749] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1808603.723828035 W.
[2019-03-26 21:45:21,756] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.83333333333334, 74.83333333333334, 1.0, 2.0, 0.6468246826410453, 1.0, 1.0, 0.6468246826410453, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1808603.723828035, 1808603.723828034, 352187.5675818318], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4870200.0000, 
sim time next is 4870800.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.6767943381885638, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.982147736548567, 6.9112, 168.9125342158584, 1842656.356813855, 1792323.716509205, 380557.8074935816], 
processed observation next is [1.0, 0.391304347826087, 0.5734597156398105, 0.74, 1.0, 1.0, 0.6105955881789925, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.007094773654856734, 0.0, 0.8294378714926238, 0.5118489880038486, 0.49786769903033473, 0.5679967276023606], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.70604765], dtype=float32), 0.21059945]. 
=============================================
[2019-03-26 21:45:22,942] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.2411830e-21 1.0000000e+00 5.7719972e-21 1.5208618e-15 2.9720350e-26], sum to 1.0000
[2019-03-26 21:45:22,950] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0620
[2019-03-26 21:45:22,955] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.6, 81.0, 1.0, 2.0, 0.585524400314107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 818225.4061662189, 818225.4061662189, 198080.1773798122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5439600.0000, 
sim time next is 5440200.0000, 
raw observation next is [29.51666666666667, 81.66666666666667, 1.0, 2.0, 0.5852508628324261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 817843.0113683267, 817843.0113683267, 198030.4800677657], 
processed observation next is [1.0, 1.0, 0.5979462875197474, 0.8166666666666668, 1.0, 1.0, 0.500302244376417, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22717861426897965, 0.22717861426897965, 0.29556788069815776], 
reward next is 0.7044, 
noisyNet noise sample is [array([-1.053817], dtype=float32), -0.17942849]. 
=============================================
[2019-03-26 21:45:24,648] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.8116955e-21 1.0000000e+00 1.8355829e-20 1.5820314e-15 2.6561794e-26], sum to 1.0000
[2019-03-26 21:45:24,660] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2598
[2019-03-26 21:45:24,666] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5093660140353766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 711764.250056138, 711764.2500561386, 185076.5959637272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4924200.0000, 
sim time next is 4924800.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5096187058562838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712117.4681467947, 712117.4681467941, 185116.8829735978], 
processed observation next is [1.0, 0.0, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4091791636822696, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19781040781855408, 0.1978104078185539, 0.2762938551844743], 
reward next is 0.7237, 
noisyNet noise sample is [array([-0.40518558], dtype=float32), 0.293513]. 
=============================================
[2019-03-26 21:45:26,163] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3867423e-12 9.9988115e-01 3.0666563e-11 1.1880904e-04 3.6832857e-16], sum to 1.0000
[2019-03-26 21:45:26,174] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0827
[2019-03-26 21:45:26,177] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.5, 66.5, 1.0, 2.0, 0.4924591315085748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104277, 688131.7109321343, 688131.7109321349, 182425.4557901119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4987800.0000, 
sim time next is 4988400.0000, 
raw observation next is [30.33333333333334, 67.66666666666667, 1.0, 2.0, 0.500553902188531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 699446.5630565452, 699446.5630565452, 183685.0184589372], 
processed observation next is [1.0, 0.7391304347826086, 0.6366508688783573, 0.6766666666666667, 1.0, 1.0, 0.3982577134801578, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19429071196015144, 0.19429071196015144, 0.274156743968563], 
reward next is 0.7258, 
noisyNet noise sample is [array([-1.1588613], dtype=float32), -0.55875224]. 
=============================================
[2019-03-26 21:45:26,383] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.1068896e-20 1.0000000e+00 2.0902258e-19 1.7381779e-15 3.0698199e-25], sum to 1.0000
[2019-03-26 21:45:26,394] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6453
[2019-03-26 21:45:26,402] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.684493244645606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 956589.0518646694, 956589.0518646694, 217531.3911643132], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4939200.0000, 
sim time next is 4939800.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.6460255973272189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 902807.1177020743, 902807.1177020743, 209623.98524625], 
processed observation next is [1.0, 0.17391304347826086, 0.4312796208530806, 0.89, 1.0, 1.0, 0.5735248160568902, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.25077975491724286, 0.25077975491724286, 0.3128716197705224], 
reward next is 0.6871, 
noisyNet noise sample is [array([0.6783683], dtype=float32), 1.4417771]. 
=============================================
[2019-03-26 21:45:33,947] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.6270270e-21 1.0000000e+00 5.5934514e-21 3.0685928e-16 3.2665316e-27], sum to 1.0000
[2019-03-26 21:45:33,954] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6936
[2019-03-26 21:45:33,967] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 70.0, 1.0, 2.0, 0.5292462505008002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 739553.6332888254, 739553.6332888254, 188305.6682446461], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5074200.0000, 
sim time next is 5074800.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.5301177846642534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740771.9149529611, 740771.9149529617, 188449.8289393672], 
processed observation next is [0.0, 0.7391304347826086, 0.6208530805687204, 0.7, 1.0, 1.0, 0.4338768489930764, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20576997637582253, 0.2057699763758227, 0.2812684014020406], 
reward next is 0.7187, 
noisyNet noise sample is [array([-0.883559], dtype=float32), -0.47218546]. 
=============================================
[2019-03-26 21:45:33,985] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.5573249e-21 1.0000000e+00 5.4434288e-21 3.0126521e-16 3.1338524e-27], sum to 1.0000
[2019-03-26 21:45:33,992] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8411
[2019-03-26 21:45:33,998] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 70.0, 1.0, 2.0, 0.5301177846642534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740771.9149529611, 740771.9149529617, 188449.8289393672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5074800.0000, 
sim time next is 5075400.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.5304522940026406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 741239.512132653, 741239.5121326536, 188505.219979638], 
processed observation next is [0.0, 0.7391304347826086, 0.6208530805687204, 0.7, 1.0, 1.0, 0.43427987229233805, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20589986448129252, 0.20589986448129266, 0.2813510745964746], 
reward next is 0.7186, 
noisyNet noise sample is [array([-0.883559], dtype=float32), -0.47218546]. 
=============================================
[2019-03-26 21:45:36,613] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.5953879e-22 1.0000000e+00 1.5314295e-21 4.6097579e-15 1.6032061e-27], sum to 1.0000
[2019-03-26 21:45:36,625] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9169
[2019-03-26 21:45:36,629] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.6238121772107247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 871751.5926885338, 871751.5926885332, 205266.4086801062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5346000.0000, 
sim time next is 5346600.0000, 
raw observation next is [30.9, 79.33333333333334, 1.0, 2.0, 0.6252346842520463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 873740.3048395718, 873740.3048395718, 205541.5433098654], 
processed observation next is [1.0, 0.9130434782608695, 0.6635071090047393, 0.7933333333333334, 1.0, 1.0, 0.5484755231952365, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2427056402332144, 0.2427056402332144, 0.30677842285054535], 
reward next is 0.6932, 
noisyNet noise sample is [array([-1.206114], dtype=float32), 0.32701188]. 
=============================================
[2019-03-26 21:45:37,833] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.1559039e-22 1.0000000e+00 1.0015927e-21 8.2997165e-17 2.2653129e-26], sum to 1.0000
[2019-03-26 21:45:37,842] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1225
[2019-03-26 21:45:37,850] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 70.0, 1.0, 2.0, 0.5205520509824388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 727400.4468327963, 727400.4468327957, 186878.614573153], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5128200.0000, 
sim time next is 5128800.0000, 
raw observation next is [29.66666666666667, 68.66666666666667, 1.0, 2.0, 0.5190657316220347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 725322.8092902369, 725322.8092902362, 186636.9319086387], 
processed observation next is [0.0, 0.34782608695652173, 0.6050552922590839, 0.6866666666666668, 1.0, 1.0, 0.4205611224361864, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20147855813617693, 0.20147855813617674, 0.27856258493826674], 
reward next is 0.7214, 
noisyNet noise sample is [array([1.1779928], dtype=float32), -0.43156844]. 
=============================================
[2019-03-26 21:45:37,973] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.1848610e-21 1.0000000e+00 2.9554246e-20 4.8528699e-16 8.1930083e-26], sum to 1.0000
[2019-03-26 21:45:37,983] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8274
[2019-03-26 21:45:37,991] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.5, 64.5, 1.0, 2.0, 0.5153740946603607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 720162.5068553776, 720162.506855377, 186040.0357613687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5135400.0000, 
sim time next is 5136000.0000, 
raw observation next is [30.66666666666666, 64.0, 1.0, 2.0, 0.5176329147832306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 723319.9635912878, 723319.9635912871, 186405.0226921558], 
processed observation next is [0.0, 0.43478260869565216, 0.6524486571879934, 0.64, 1.0, 1.0, 0.4188348370882296, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20092221210869107, 0.20092221210869088, 0.278216451779337], 
reward next is 0.7218, 
noisyNet noise sample is [array([0.7345555], dtype=float32), -0.18627559]. 
=============================================
[2019-03-26 21:45:38,010] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[72.77322 ]
 [72.77239 ]
 [72.75664 ]
 [72.73601 ]
 [72.716255]], R is [[72.78111267]
 [72.77562714]
 [72.77088928]
 [72.76648712]
 [72.76239014]].
[2019-03-26 21:45:39,829] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2437373e-22 1.0000000e+00 6.3381351e-22 3.1244739e-17 9.4563815e-28], sum to 1.0000
[2019-03-26 21:45:39,842] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5967
[2019-03-26 21:45:39,846] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333334, 74.83333333333334, 1.0, 2.0, 0.5311699439436665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742242.6868791814, 742242.6868791814, 188623.3436413643], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5166600.0000, 
sim time next is 5167200.0000, 
raw observation next is [28.66666666666667, 75.66666666666667, 1.0, 2.0, 0.5249734835066681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733580.9287377773, 733580.9287377767, 187601.2697214166], 
processed observation next is [0.0, 0.8260869565217391, 0.5576619273301741, 0.7566666666666667, 1.0, 1.0, 0.4276788957911663, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20377248020493813, 0.20377248020493796, 0.28000189510659196], 
reward next is 0.7200, 
noisyNet noise sample is [array([-0.63390464], dtype=float32), -0.5592537]. 
=============================================
[2019-03-26 21:45:47,656] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1431717e-18 1.0000000e+00 7.0024553e-18 7.3933311e-14 2.2640810e-23], sum to 1.0000
[2019-03-26 21:45:47,662] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0963
[2019-03-26 21:45:47,666] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666667, 77.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 11.75283424908882, 6.9112, 168.8685647585163, 4889765.386420733, 1455846.114157649, 299196.9234843202], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5300400.0000, 
sim time next is 5301000.0000, 
raw observation next is [31.5, 75.5, 1.0, 2.0, 1.036652154833552, 1.0, 1.0, 0.8389161169310383, 1.0, 1.0, 1.03, 7.005124291892358, 6.9112, 170.5573041426782, 3521077.997828701, 3453796.206950285, 648781.8044736482], 
processed observation next is [1.0, 0.34782608695652173, 0.6919431279620853, 0.755, 1.0, 1.0, 1.0441592226910266, 1.0, 0.5, 0.8059230324470341, 1.0, 0.5, 1.0365853658536586, 0.009392429189235774, 0.0, 0.8375144448122397, 0.9780772216190836, 0.9593878352639681, 0.9683310514532063], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.20753978], dtype=float32), -0.5808916]. 
=============================================
[2019-03-26 21:45:47,683] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[61.035545]
 [62.037846]
 [61.941544]
 [65.14544 ]
 [65.22013 ]], R is [[52.93901825]
 [52.40962982]
 [51.88553238]
 [51.86304092]
 [51.34440994]].
[2019-03-26 21:45:48,303] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.2008596e-09 4.1915843e-01 7.0020931e-08 5.8084154e-01 7.0600800e-12], sum to 1.0000
[2019-03-26 21:45:48,314] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1430
[2019-03-26 21:45:48,324] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2852930.335029153 W.
[2019-03-26 21:45:48,329] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.5, 49.0, 1.0, 2.0, 1.019861854306987, 1.0, 2.0, 1.019861854306987, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2852930.335029153, 2852930.335029153, 541099.8863627198], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5500800.0000, 
sim time next is 5501400.0000, 
raw observation next is [35.36666666666667, 49.33333333333334, 1.0, 2.0, 1.009643713537285, 1.0, 2.0, 1.009643713537285, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2824314.107559268, 2824314.107559269, 534836.5678082221], 
processed observation next is [1.0, 0.6956521739130435, 0.8751974723538705, 0.4933333333333334, 1.0, 1.0, 1.0116189319726328, 1.0, 1.0, 1.0116189319726328, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.784531696544241, 0.7845316965442414, 0.7982635340421226], 
reward next is 0.2017, 
noisyNet noise sample is [array([-0.44268528], dtype=float32), 2.1460423]. 
=============================================
[2019-03-26 21:45:51,249] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8724353e-09 9.8866779e-01 3.7322510e-09 1.1332181e-02 4.5421981e-13], sum to 1.0000
[2019-03-26 21:45:51,258] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6482
[2019-03-26 21:45:51,265] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2415041.406095639 W.
[2019-03-26 21:45:51,270] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.53333333333333, 52.0, 1.0, 2.0, 0.8634770301384399, 1.0, 2.0, 0.8634770301384399, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2415041.406095639, 2415041.406095639, 451950.8522690794], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5586000.0000, 
sim time next is 5586600.0000, 
raw observation next is [33.46666666666666, 52.5, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.529324229199976, 6.9112, 168.9095384319202, 2737104.573157879, 2298594.84451731, 475431.5710872942], 
processed observation next is [1.0, 0.6521739130434783, 0.7851500789889413, 0.525, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.061812422919997626, 0.0, 0.8294231608220115, 0.7603068258771887, 0.6384985679214751, 0.7095993598317824], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8388942], dtype=float32), 0.06861622]. 
=============================================
[2019-03-26 21:45:56,728] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.3742632e-22 1.0000000e+00 5.1090269e-21 1.2911573e-15 1.4105409e-26], sum to 1.0000
[2019-03-26 21:45:56,737] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1261
[2019-03-26 21:45:56,742] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.18333333333334, 84.33333333333334, 1.0, 2.0, 0.5873787972320692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 820817.7848168855, 820817.7848168849, 198418.3753768629], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5442600.0000, 
sim time next is 5443200.0000, 
raw observation next is [29.1, 85.0, 1.0, 2.0, 0.5875141679837166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 821007.0283939315, 821007.0283939309, 198443.1342128485], 
processed observation next is [1.0, 0.0, 0.5781990521327015, 0.85, 1.0, 1.0, 0.5030291180526706, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2280575078872032, 0.22805750788720303, 0.2961837824072366], 
reward next is 0.7038, 
noisyNet noise sample is [array([0.83983153], dtype=float32), -0.17083849]. 
=============================================
[2019-03-26 21:45:57,834] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6831865e-19 1.0000000e+00 5.7707511e-18 9.8279762e-14 4.5107575e-24], sum to 1.0000
[2019-03-26 21:45:57,842] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6315
[2019-03-26 21:45:57,847] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.26666666666667, 79.33333333333334, 1.0, 2.0, 0.9358232013179181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104062, 1308042.582860445, 1308042.582860445, 279986.5684641337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5469600.0000, 
sim time next is 5470200.0000, 
raw observation next is [30.45, 78.5, 1.0, 2.0, 0.9400975065883735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1314020.670704297, 1314020.670704297, 281210.4904184974], 
processed observation next is [1.0, 0.30434782608695654, 0.6421800947867299, 0.785, 1.0, 1.0, 0.9278283211908115, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3650057418623047, 0.3650057418623047, 0.41971714987835435], 
reward next is 0.5803, 
noisyNet noise sample is [array([-0.33410734], dtype=float32), 0.13293505]. 
=============================================
[2019-03-26 21:46:07,282] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 21:46:07,284] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:46:07,284] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:46:07,284] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:46:07,285] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:46:07,286] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:46:07,287] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:46:07,287] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:46:07,285] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:46:07,291] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:46:07,288] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:46:07,318] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run58
[2019-03-26 21:46:07,337] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run58
[2019-03-26 21:46:07,359] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run58
[2019-03-26 21:46:07,359] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run58
[2019-03-26 21:46:07,360] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run58
[2019-03-26 21:46:18,350] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08761801], dtype=float32), 0.06364371]
[2019-03-26 21:46:18,351] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [17.65237719833333, 86.07428733, 1.0, 2.0, 0.2034399489272492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 340175.4968373241, 340175.4968373247, 155543.6978595927]
[2019-03-26 21:46:18,352] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:46:18,354] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.2322481e-21 1.0000000e+00 3.9746513e-21 6.2613708e-17 8.9925929e-27], sampled 0.9859811586572612
[2019-03-26 21:46:27,525] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08761801], dtype=float32), 0.06364371]
[2019-03-26 21:46:27,526] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.99323937, 100.0, 1.0, 2.0, 0.513688999780989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 747531.9927893039, 747531.9927893033, 189521.7590435774]
[2019-03-26 21:46:27,527] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:46:27,530] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.5583008e-21 1.0000000e+00 5.6141015e-21 7.5967202e-17 1.0709320e-26], sampled 0.1724215513920626
[2019-03-26 21:46:33,132] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08761801], dtype=float32), 0.06364371]
[2019-03-26 21:46:33,133] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.08333333333334, 84.33333333333333, 1.0, 2.0, 0.9243969496240806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1292061.873570758, 1292061.873570759, 276735.2945956448]
[2019-03-26 21:46:33,134] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:46:33,136] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.5643795e-20 1.0000000e+00 3.0313908e-20 1.9838956e-15 1.3212805e-25], sampled 0.5173888481566401
[2019-03-26 21:46:39,456] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08761801], dtype=float32), 0.06364371]
[2019-03-26 21:46:39,457] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.36666666666667, 75.33333333333334, 1.0, 2.0, 0.5736805237774774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 801668.2518703135, 801668.251870313, 195945.5078429384]
[2019-03-26 21:46:39,459] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:46:39,465] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.3701126e-22 1.0000000e+00 1.5767908e-21 6.1870549e-17 3.5134185e-27], sampled 0.680753265444246
[2019-03-26 21:46:55,944] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08761801], dtype=float32), 0.06364371]
[2019-03-26 21:46:55,945] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.66666666666667, 65.66666666666667, 1.0, 2.0, 0.5863683956701757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 819405.2798309708, 819405.2798309708, 198234.6409096399]
[2019-03-26 21:46:55,946] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:46:55,949] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.2040338e-22 1.0000000e+00 1.7488741e-21 8.5161381e-17 4.5049215e-27], sampled 0.11154687209334646
[2019-03-26 21:46:56,261] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08761801], dtype=float32), 0.06364371]
[2019-03-26 21:46:56,263] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.22052363833333, 77.36795293166668, 1.0, 2.0, 0.5544159501516707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 774737.8809358594, 774737.8809358594, 192560.8144809414]
[2019-03-26 21:46:56,266] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:46:56,269] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.1776913e-22 1.0000000e+00 6.9819830e-22 4.3471461e-17 1.4286706e-27], sampled 0.9439672910589357
[2019-03-26 21:47:08,723] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08761801], dtype=float32), 0.06364371]
[2019-03-26 21:47:08,724] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.63871918, 87.88542050000001, 1.0, 2.0, 0.6233961145274907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 871169.923924532, 871169.9239245327, 205186.1568314561]
[2019-03-26 21:47:08,726] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:47:08,729] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.72937617e-21 1.00000000e+00 4.07488759e-21 2.32578704e-16
 1.04857294e-26], sampled 0.11483225570873923
[2019-03-26 21:47:14,511] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08761801], dtype=float32), 0.06364371]
[2019-03-26 21:47:14,512] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.91366349, 81.08974592333334, 1.0, 2.0, 0.5346127534275705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 747055.2685972002, 747055.2685972007, 189196.328471801]
[2019-03-26 21:47:14,512] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:47:14,516] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.4443207e-22 1.0000000e+00 1.0842904e-21 6.2105356e-17 2.3644913e-27], sampled 0.33345359998683666
[2019-03-26 21:47:25,976] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08761801], dtype=float32), 0.06364371]
[2019-03-26 21:47:25,976] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.98333333333333, 71.5, 1.0, 2.0, 0.585531005899189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 818234.6405198533, 818234.6405198526, 198080.7393308922]
[2019-03-26 21:47:25,977] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:47:25,979] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.6213506e-19 1.0000000e+00 1.5332732e-18 6.5912640e-13 1.3460311e-24], sampled 0.1016614775721092
[2019-03-26 21:47:57,972] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08761801], dtype=float32), 0.06364371]
[2019-03-26 21:47:57,973] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.63333333333333, 91.33333333333334, 1.0, 2.0, 0.5852324403612141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 831151.5802689774, 831151.5802689774, 199743.1143115084]
[2019-03-26 21:47:57,974] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:47:57,976] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.2370025e-21 1.0000000e+00 8.4910453e-21 9.1046129e-17 1.6802939e-26], sampled 0.7254621359637802
[2019-03-26 21:48:01,236] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2953 3007596012.4260 1766.0000
[2019-03-26 21:48:01,458] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5144 2842492707.2201 1131.0000
[2019-03-26 21:48:01,525] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8656.1801 2779481114.8303 933.0000
[2019-03-26 21:48:01,659] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.1701 3164469851.8135 1776.0000
[2019-03-26 21:48:01,710] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8251.3672 2927466060.9598 1338.0000
[2019-03-26 21:48:02,725] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1425000, evaluation results [1425000.0, 7881.1700524112575, 3164469851.8134804, 1776.0, 8251.367175640993, 2927466060.959789, 1338.0, 8656.18011356307, 2779481114.830308, 933.0, 7998.295259250187, 3007596012.4259605, 1766.0, 8497.514395919725, 2842492707.2200756, 1131.0]
[2019-03-26 21:48:04,524] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7842316e-21 1.0000000e+00 6.1295808e-21 5.7695212e-17 1.3212899e-26], sum to 1.0000
[2019-03-26 21:48:04,534] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6779
[2019-03-26 21:48:04,541] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.46666666666667, 60.0, 1.0, 2.0, 0.551524761842415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 770696.2841701536, 770696.284170153, 192062.6559332326], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5667000.0000, 
sim time next is 5667600.0000, 
raw observation next is [32.43333333333334, 60.00000000000001, 1.0, 2.0, 0.5469084769276154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 764243.2039768497, 764243.2039768504, 191272.2893454655], 
processed observation next is [0.0, 0.6086956521739131, 0.7361769352290681, 0.6000000000000001, 1.0, 1.0, 0.45410659870797027, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21228977888245823, 0.21228977888245842, 0.28548102887382915], 
reward next is 0.7145, 
noisyNet noise sample is [array([0.62220126], dtype=float32), -0.14802285]. 
=============================================
[2019-03-26 21:48:04,555] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.5205534e-21 1.0000000e+00 1.5230991e-20 1.3414597e-15 6.2878119e-27], sum to 1.0000
[2019-03-26 21:48:04,563] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0451
[2019-03-26 21:48:04,568] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 86.33333333333334, 1.0, 2.0, 0.528573020536152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738612.5538424747, 738612.5538424747, 188194.0872299482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6211200.0000, 
sim time next is 6211800.0000, 
raw observation next is [27.15, 86.5, 1.0, 2.0, 0.5278203877085342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 737560.481508499, 737560.4815084997, 188069.856583729], 
processed observation next is [1.0, 0.9130434782608695, 0.485781990521327, 0.865, 1.0, 1.0, 0.43110890085365566, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20487791153013862, 0.20487791153013882, 0.2807012784831776], 
reward next is 0.7193, 
noisyNet noise sample is [array([2.2338402], dtype=float32), 2.270911]. 
=============================================
[2019-03-26 21:48:05,124] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5016147e-21 1.0000000e+00 2.5630102e-20 1.4897797e-15 2.5190640e-26], sum to 1.0000
[2019-03-26 21:48:05,133] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4726
[2019-03-26 21:48:05,138] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.76666666666667, 87.0, 1.0, 2.0, 0.5567330500304989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777976.9696666499, 777976.9696666499, 192961.9888492085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5865600.0000, 
sim time next is 5866200.0000, 
raw observation next is [27.7, 87.0, 1.0, 2.0, 0.5536812715813269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 773710.871128941, 773710.871128941, 192433.9467760243], 
processed observation next is [1.0, 0.9130434782608695, 0.5118483412322274, 0.87, 1.0, 1.0, 0.46226659226665884, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21491968642470582, 0.21491968642470582, 0.28721484593436464], 
reward next is 0.7128, 
noisyNet noise sample is [array([-0.58217955], dtype=float32), 1.4237242]. 
=============================================
[2019-03-26 21:48:09,423] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.0538897e-22 1.0000000e+00 1.7046573e-21 3.8420399e-17 1.5622500e-26], sum to 1.0000
[2019-03-26 21:48:09,432] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1076
[2019-03-26 21:48:09,438] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333333, 88.83333333333334, 1.0, 2.0, 0.5379146463188768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 751670.888473976, 751670.8884739766, 189749.3929585985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5791800.0000, 
sim time next is 5792400.0000, 
raw observation next is [26.9, 89.0, 1.0, 2.0, 0.5372087543229461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 750684.140932508, 750684.1409325086, 189630.9578230292], 
processed observation next is [1.0, 0.043478260869565216, 0.4739336492890995, 0.89, 1.0, 1.0, 0.44242018593126037, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20852337248125224, 0.20852337248125238, 0.2830312803328794], 
reward next is 0.7170, 
noisyNet noise sample is [array([-0.7467367], dtype=float32), 0.30591357]. 
=============================================
[2019-03-26 21:48:10,508] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.7688808e-21 1.0000000e+00 1.5067276e-20 1.0444111e-15 2.0502122e-26], sum to 1.0000
[2019-03-26 21:48:10,516] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5063
[2019-03-26 21:48:10,521] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.93333333333334, 87.0, 1.0, 2.0, 0.5608901216826657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 783788.1914569404, 783788.191456941, 193685.9157795505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5952000.0000, 
sim time next is 5952600.0000, 
raw observation next is [27.85, 87.5, 1.0, 2.0, 0.5594376765184098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 781757.7968147881, 781757.7968147881, 193432.5290155013], 
processed observation next is [1.0, 0.9130434782608695, 0.5189573459715641, 0.875, 1.0, 1.0, 0.4692020199016985, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21715494355966336, 0.21715494355966336, 0.2887052671873154], 
reward next is 0.7113, 
noisyNet noise sample is [array([0.12103814], dtype=float32), -1.2240093]. 
=============================================
[2019-03-26 21:48:12,681] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.2733809e-22 1.0000000e+00 8.4465925e-21 2.3162412e-17 1.2905395e-26], sum to 1.0000
[2019-03-26 21:48:12,687] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6415
[2019-03-26 21:48:12,692] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333334, 63.0, 1.0, 2.0, 0.561503829226798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 784646.1035036643, 784646.1035036643, 193792.5561376019], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6351000.0000, 
sim time next is 6351600.0000, 
raw observation next is [31.66666666666667, 63.00000000000001, 1.0, 2.0, 0.5446081712998979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 761027.6335776714, 761027.633577672, 190880.4809788294], 
processed observation next is [0.0, 0.5217391304347826, 0.6998420221169038, 0.6300000000000001, 1.0, 1.0, 0.4513351461444553, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2113965648826865, 0.21139656488268666, 0.2848962402669096], 
reward next is 0.7151, 
noisyNet noise sample is [array([0.07582276], dtype=float32), 1.5841739]. 
=============================================
[2019-03-26 21:48:16,349] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.7512691e-20 1.0000000e+00 4.7064116e-18 1.5047182e-11 1.1330531e-23], sum to 1.0000
[2019-03-26 21:48:16,360] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8736
[2019-03-26 21:48:16,364] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 75.66666666666667, 1.0, 2.0, 0.5579658161244295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779700.265294291, 779700.265294291, 193177.157757118], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5856000.0000, 
sim time next is 5856600.0000, 
raw observation next is [29.8, 76.83333333333333, 1.0, 2.0, 0.5583851429277124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780286.446919334, 780286.446919334, 193250.050459017], 
processed observation next is [1.0, 0.782608695652174, 0.6113744075829385, 0.7683333333333333, 1.0, 1.0, 0.4679339071418221, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21674623525537057, 0.21674623525537057, 0.2884329111328612], 
reward next is 0.7116, 
noisyNet noise sample is [array([-1.6761053], dtype=float32), -0.96214974]. 
=============================================
[2019-03-26 21:48:24,109] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9747018e-20 1.0000000e+00 8.0659506e-20 2.1020723e-15 2.7270234e-25], sum to 1.0000
[2019-03-26 21:48:24,118] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1063
[2019-03-26 21:48:24,123] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.95, 86.5, 1.0, 2.0, 0.7215532050365911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1008405.463406446, 1008405.463406446, 225567.9730546769], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5987400.0000, 
sim time next is 5988000.0000, 
raw observation next is [28.1, 86.0, 1.0, 2.0, 0.7260829362993917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1014739.006210879, 1014739.00621088, 226577.8577497597], 
processed observation next is [1.0, 0.30434782608695654, 0.5308056872037916, 0.86, 1.0, 1.0, 0.6699794413245683, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2818719461696886, 0.2818719461696889, 0.3381759070891936], 
reward next is 0.6618, 
noisyNet noise sample is [array([-1.514498], dtype=float32), -1.3185301]. 
=============================================
[2019-03-26 21:48:24,135] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[67.33843 ]
 [67.279236]
 [67.247475]
 [67.34944 ]
 [67.46392 ]], R is [[67.32678986]
 [67.31685638]
 [67.30060577]
 [67.27347565]
 [67.25357819]].
[2019-03-26 21:48:27,786] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.9966271e-10 9.9999452e-01 1.9669197e-10 5.4849934e-06 9.2424332e-14], sum to 1.0000
[2019-03-26 21:48:27,795] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1773
[2019-03-26 21:48:27,806] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2019078.728238197 W.
[2019-03-26 21:48:27,814] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.1, 74.0, 1.0, 2.0, 0.8028618742387844, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.985070802802207, 6.9112, 168.9125165924237, 2019078.728238197, 1966672.374781298, 409307.7760137274], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6602400.0000, 
sim time next is 6603000.0000, 
raw observation next is [29.26666666666667, 73.16666666666667, 1.0, 2.0, 0.8516222205635412, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.983003480018635, 6.9112, 168.9124692335083, 2087323.164567308, 2036383.451507381, 421823.3598456293], 
processed observation next is [1.0, 0.43478260869565216, 0.5860979462875199, 0.7316666666666667, 1.0, 1.0, 0.8212315910404111, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007180348001863468, 0.0, 0.8294375523995359, 0.5798119901575856, 0.5656620698631614, 0.6295871042472079], 
reward next is 0.0114, 
noisyNet noise sample is [array([-0.09314965], dtype=float32), 0.32700992]. 
=============================================
[2019-03-26 21:48:27,842] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[34.034393]
 [35.713783]
 [39.444527]
 [43.52005 ]
 [45.10679 ]], R is [[32.55627823]
 [32.25045395]
 [32.3368721 ]
 [32.43333435]
 [32.585392  ]].
[2019-03-26 21:48:33,085] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1093839e-21 1.0000000e+00 1.8774216e-20 6.3723861e-16 3.5745254e-26], sum to 1.0000
[2019-03-26 21:48:33,095] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0543
[2019-03-26 21:48:33,102] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.06666666666667, 89.16666666666667, 1.0, 2.0, 0.537561471824019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 751177.1951789671, 751177.1951789678, 189690.614403418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6135000.0000, 
sim time next is 6135600.0000, 
raw observation next is [27.03333333333333, 89.33333333333334, 1.0, 2.0, 0.5369403903072633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 750309.002293081, 750309.002293081, 189586.4630404996], 
processed observation next is [1.0, 0.0, 0.48025276461295413, 0.8933333333333334, 1.0, 1.0, 0.4420968557918834, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2084191673036336, 0.2084191673036336, 0.2829648702097009], 
reward next is 0.7170, 
noisyNet noise sample is [array([1.1314055], dtype=float32), -0.58069754]. 
=============================================
[2019-03-26 21:48:40,620] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.0921942e-21 1.0000000e+00 9.8805361e-20 2.9371011e-15 1.9373228e-25], sum to 1.0000
[2019-03-26 21:48:40,631] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0626
[2019-03-26 21:48:40,640] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.21666666666667, 66.16666666666667, 1.0, 2.0, 0.3277187477992832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 514768.4370488538, 514768.4370488538, 168076.9358525724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6817800.0000, 
sim time next is 6818400.0000, 
raw observation next is [25.1, 67.0, 1.0, 2.0, 0.3282635290664391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515354.9726420644, 515354.9726420644, 168116.2032777758], 
processed observation next is [1.0, 0.9565217391304348, 0.38862559241706174, 0.67, 1.0, 1.0, 0.19067895068245672, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1431541590672401, 0.1431541590672401, 0.25091970638474004], 
reward next is 0.7491, 
noisyNet noise sample is [array([0.09961744], dtype=float32), -0.40093553]. 
=============================================
[2019-03-26 21:48:41,190] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9938350e-22 1.0000000e+00 2.6178703e-21 6.1320255e-17 1.6738380e-27], sum to 1.0000
[2019-03-26 21:48:41,203] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0152
[2019-03-26 21:48:41,209] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.86666666666667, 62.66666666666666, 1.0, 2.0, 0.5167895115338861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722141.0243194941, 722141.0243194941, 186268.4968835686], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6270000.0000, 
sim time next is 6270600.0000, 
raw observation next is [30.88333333333333, 62.33333333333334, 1.0, 2.0, 0.5146297733259568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 719122.070858105, 719122.0708581056, 185920.072765458], 
processed observation next is [0.0, 0.5652173913043478, 0.6627172195892573, 0.6233333333333334, 1.0, 1.0, 0.4152165943686227, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19975613079391805, 0.1997561307939182, 0.277492645918594], 
reward next is 0.7225, 
noisyNet noise sample is [array([0.22825433], dtype=float32), 0.43001407]. 
=============================================
[2019-03-26 21:48:41,673] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.0645311e-21 1.0000000e+00 2.5836838e-20 2.1621249e-15 3.7902135e-26], sum to 1.0000
[2019-03-26 21:48:41,681] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5601
[2019-03-26 21:48:41,685] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.4, 84.33333333333334, 1.0, 2.0, 0.5257489392812211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 734664.9002209393, 734664.9002209399, 187728.8035180014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6474000.0000, 
sim time next is 6474600.0000, 
raw observation next is [27.35, 85.0, 1.0, 2.0, 0.5270079968073125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 736424.87716059, 736424.8771605907, 187935.9629441486], 
processed observation next is [1.0, 0.9565217391304348, 0.4952606635071091, 0.85, 1.0, 1.0, 0.4301301166353162, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20456246587794166, 0.20456246587794186, 0.28050143723007254], 
reward next is 0.7195, 
noisyNet noise sample is [array([-2.046802], dtype=float32), -1.3756441]. 
=============================================
[2019-03-26 21:48:43,321] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.0174147e-23 1.0000000e+00 8.1720492e-22 6.0824959e-17 8.4174203e-28], sum to 1.0000
[2019-03-26 21:48:43,329] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3594
[2019-03-26 21:48:43,333] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.1, 80.66666666666666, 1.0, 2.0, 0.5301681045499398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740842.2550885848, 740842.2550885843, 188457.8951091644], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6291600.0000, 
sim time next is 6292200.0000, 
raw observation next is [27.95, 81.83333333333334, 1.0, 2.0, 0.5317184949596887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 743009.485499889, 743009.4854998883, 188715.0068130046], 
processed observation next is [0.0, 0.8260869565217391, 0.523696682464455, 0.8183333333333335, 1.0, 1.0, 0.43580541561408276, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20639152374996916, 0.20639152374996897, 0.2816641892731412], 
reward next is 0.7183, 
noisyNet noise sample is [array([0.1483366], dtype=float32), -1.3145583]. 
=============================================
[2019-03-26 21:48:43,691] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9386658e-20 1.0000000e+00 6.5008835e-20 3.4690912e-15 2.3550597e-25], sum to 1.0000
[2019-03-26 21:48:43,702] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0050
[2019-03-26 21:48:43,708] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.41666666666667, 85.16666666666667, 1.0, 2.0, 0.9250014301611457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1292907.291572742, 1292907.291572741, 276907.1900368137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6509400.0000, 
sim time next is 6510000.0000, 
raw observation next is [27.63333333333334, 83.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.631521474754371, 6.9112, 168.9093597728707, 1965114.921603189, 1454104.957251263, 311350.1458003531], 
processed observation next is [1.0, 0.34782608695652173, 0.5086887835703005, 0.8333333333333335, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.07203214747543711, 0.0, 0.8294222835242879, 0.5458652560008859, 0.4039180436809064, 0.46470171014978073], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2389194], dtype=float32), -1.5408614]. 
=============================================
[2019-03-26 21:48:43,726] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.09243 ]
 [68.18045 ]
 [68.19586 ]
 [68.21486 ]
 [68.184784]], R is [[67.06571198]
 [66.98176575]
 [66.9547348 ]
 [66.9683609 ]
 [66.97901917]].
[2019-03-26 21:48:44,584] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0963236e-21 1.0000000e+00 2.6330837e-21 3.4133118e-17 8.3604311e-27], sum to 1.0000
[2019-03-26 21:48:44,588] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8028
[2019-03-26 21:48:44,595] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 80.33333333333333, 1.0, 2.0, 0.522397246669101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 729979.7419275157, 729979.7419275151, 187179.6792625401], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6333000.0000, 
sim time next is 6333600.0000, 
raw observation next is [28.0, 79.66666666666667, 1.0, 2.0, 0.5220100882952503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729438.5545294686, 729438.5545294686, 187116.4846361777], 
processed observation next is [0.0, 0.30434782608695654, 0.5260663507109005, 0.7966666666666667, 1.0, 1.0, 0.4241085401147594, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20262182070263018, 0.20262182070263018, 0.27927833527787715], 
reward next is 0.7207, 
noisyNet noise sample is [array([-0.90982395], dtype=float32), -1.1525056]. 
=============================================
[2019-03-26 21:48:55,399] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6197859e-19 1.0000000e+00 7.4118795e-19 3.2163673e-12 5.1455721e-25], sum to 1.0000
[2019-03-26 21:48:55,409] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2940
[2019-03-26 21:48:55,414] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 83.0, 1.0, 2.0, 0.4855467171598969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 678469.6492092324, 678469.6492092324, 181362.4945765904], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7068600.0000, 
sim time next is 7069200.0000, 
raw observation next is [26.36666666666667, 84.0, 1.0, 2.0, 0.486745643232379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 680145.4825121628, 680145.4825121633, 181545.3833398115], 
processed observation next is [1.0, 0.8260869565217391, 0.4486571879936811, 0.84, 1.0, 1.0, 0.3816212569064807, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.188929300697823, 0.18892930069782315, 0.2709632587161366], 
reward next is 0.7290, 
noisyNet noise sample is [array([0.71243924], dtype=float32), 0.8807921]. 
=============================================
[2019-03-26 21:48:56,639] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.7169139e-21 1.0000000e+00 3.7857168e-20 8.9621983e-16 4.4121822e-26], sum to 1.0000
[2019-03-26 21:48:56,641] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2753
[2019-03-26 21:48:56,647] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.76666666666667, 92.66666666666667, 1.0, 2.0, 0.5516146446212815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 770821.9312190055, 770821.9312190055, 192075.0497460303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6583200.0000, 
sim time next is 6583800.0000, 
raw observation next is [25.73333333333333, 92.83333333333333, 1.0, 2.0, 0.5478756560373194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 765595.215277056, 765595.2152770566, 191434.3419718563], 
processed observation next is [1.0, 0.17391304347826086, 0.41864139020537117, 0.9283333333333332, 1.0, 1.0, 0.45527187474375824, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21266533757696, 0.21266533757696016, 0.2857228984654572], 
reward next is 0.7143, 
noisyNet noise sample is [array([-1.1268461], dtype=float32), 0.036168]. 
=============================================
[2019-03-26 21:48:58,306] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 21:48:58,307] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:48:58,307] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:48:58,308] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:48:58,309] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:48:58,310] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:48:58,310] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:48:58,310] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:48:58,312] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:48:58,312] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:48:58,312] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:48:58,329] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run59
[2019-03-26 21:48:58,329] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run59
[2019-03-26 21:48:58,361] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run59
[2019-03-26 21:48:58,361] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run59
[2019-03-26 21:48:58,405] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run59
[2019-03-26 21:49:12,716] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08882496], dtype=float32), 0.06441227]
[2019-03-26 21:49:12,718] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.0, 60.0, 1.0, 2.0, 0.3514927191106925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 542992.0263282717, 542992.0263282723, 170106.8138504166]
[2019-03-26 21:49:12,721] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:49:12,724] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.7941418e-21 1.0000000e+00 4.2954100e-21 8.9843408e-17 1.2555473e-26], sampled 0.11445313908259791
[2019-03-26 21:49:14,555] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08882496], dtype=float32), 0.06441227]
[2019-03-26 21:49:14,556] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.46105076, 94.64587877, 1.0, 2.0, 0.2823640455096942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 458824.2213309819, 458824.2213309825, 164155.5656110889]
[2019-03-26 21:49:14,556] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:49:14,559] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.9882182e-22 1.0000000e+00 1.4017957e-21 4.6513167e-17 2.3561357e-27], sampled 0.40214660249117395
[2019-03-26 21:49:22,995] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08882496], dtype=float32), 0.06441227]
[2019-03-26 21:49:22,997] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.05330437333333, 85.33775633166667, 1.0, 2.0, 0.5297196215250439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 818430.2381491708, 818430.2381491708, 197711.8972108035]
[2019-03-26 21:49:22,999] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:49:23,001] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.2898685e-21 1.0000000e+00 3.7176938e-21 2.3007874e-16 6.7874987e-27], sampled 0.036477069256265926
[2019-03-26 21:49:30,874] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08882496], dtype=float32), 0.06441227]
[2019-03-26 21:49:30,877] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.90117282333333, 76.38354840000001, 1.0, 2.0, 0.5732708758262935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 801095.5888894582, 801095.5888894582, 195871.6964095819]
[2019-03-26 21:49:30,877] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:49:30,881] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.0431436e-22 1.0000000e+00 1.0767474e-21 7.8367899e-17 2.1880319e-27], sampled 0.19043491952150438
[2019-03-26 21:49:36,041] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08882496], dtype=float32), 0.06441227]
[2019-03-26 21:49:36,043] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.80154252666667, 85.89753927333334, 1.0, 2.0, 0.5647901139934329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 789240.0677667267, 789240.0677667267, 194368.5091417293]
[2019-03-26 21:49:36,045] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:49:36,048] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.8075975e-22 1.0000000e+00 1.4818853e-21 1.2798289e-16 2.5534083e-27], sampled 0.10895696482776052
[2019-03-26 21:49:38,877] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08882496], dtype=float32), 0.06441227]
[2019-03-26 21:49:38,879] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.36666666666667, 67.66666666666667, 1.0, 2.0, 0.5708174584696438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 797665.866744857, 797665.8667448576, 195434.8479281227]
[2019-03-26 21:49:38,881] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:49:38,882] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.2088415e-22 1.0000000e+00 1.0903836e-21 1.0485103e-16 2.4206744e-27], sampled 0.41402115538785145
[2019-03-26 21:49:47,529] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08882496], dtype=float32), 0.06441227]
[2019-03-26 21:49:47,529] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.66666666666666, 77.66666666666667, 1.0, 2.0, 0.5705677971913229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 797316.8567040372, 797316.8567040366, 195390.7187670969]
[2019-03-26 21:49:47,530] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:49:47,533] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.8792166e-22 1.0000000e+00 7.4617411e-22 8.3315650e-17 1.4087657e-27], sampled 0.645081968493586
[2019-03-26 21:49:50,633] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08882496], dtype=float32), 0.06441227]
[2019-03-26 21:49:50,635] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.93354366166667, 89.30145289, 1.0, 2.0, 0.5996976410962112, 0.0, 2.0, 0.0, 1.0, 1.0, 1.020495584276802, 6.911199999999999, 6.9112, 168.9127113360748, 1676740.224308037, 1676740.224308037, 362865.3362645982]
[2019-03-26 21:49:50,636] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:49:50,639] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.6296518e-16 1.0000000e+00 3.6004652e-15 1.9310042e-09 1.9112617e-20], sampled 0.585125108533081
[2019-03-26 21:49:50,640] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1676740.224308037 W.
[2019-03-26 21:50:15,032] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08882496], dtype=float32), 0.06441227]
[2019-03-26 21:50:15,035] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.5, 55.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.269444585988404, 6.9112, 168.9107005147313, 1708076.637452615, 1453928.992757988, 311356.1485807053]
[2019-03-26 21:50:15,036] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:50:15,039] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.6260020e-21 1.0000000e+00 5.1812336e-21 8.4036759e-16 1.3069928e-26], sampled 0.08055204934344995
[2019-03-26 21:50:15,039] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1708076.637452615 W.
[2019-03-26 21:50:21,597] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08882496], dtype=float32), 0.06441227]
[2019-03-26 21:50:21,598] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.98333333333333, 50.5, 1.0, 2.0, 0.5878633385438238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 821495.156782524, 821495.1567825234, 198507.0060561619]
[2019-03-26 21:50:21,600] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:50:21,602] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.6525157e-22 1.0000000e+00 1.7964224e-21 1.5507508e-16 4.7890290e-27], sampled 0.16002282391074152
[2019-03-26 21:50:31,971] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08882496], dtype=float32), 0.06441227]
[2019-03-26 21:50:31,973] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.78314476000001, 81.46394955666668, 1.0, 2.0, 0.6785553547812493, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.005974114754478, 6.9112, 168.9120128953742, 1845120.574728852, 1777884.931455916, 380067.927336273]
[2019-03-26 21:50:31,973] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:50:31,976] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.6625663e-20 1.0000000e+00 1.3988325e-19 5.4205069e-15 6.8408455e-25], sampled 0.00611009861313605
[2019-03-26 21:50:31,982] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1845120.574728852 W.
[2019-03-26 21:50:51,780] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.5030 3007903784.0453 1766.0000
[2019-03-26 21:50:52,433] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8251.2254 2927524189.8324 1338.0000
[2019-03-26 21:50:52,584] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.3232 2842641088.5887 1130.0000
[2019-03-26 21:50:52,593] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7167 2779131942.0695 933.0000
[2019-03-26 21:50:52,657] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.4232 3164594232.0422 1774.0000
[2019-03-26 21:50:53,674] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1450000, evaluation results [1450000.0, 7882.423181277259, 3164594232.04216, 1774.0, 8251.225422135243, 2927524189.8323765, 1338.0, 8660.716715102415, 2779131942.069542, 933.0, 7996.503017589907, 3007903784.0453057, 1766.0, 8496.323156831882, 2842641088.588691, 1130.0]
[2019-03-26 21:51:09,506] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.7775682e-19 1.0000000e+00 1.3312919e-19 2.8161368e-15 3.6760561e-25], sum to 1.0000
[2019-03-26 21:51:09,512] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0125
[2019-03-26 21:51:09,517] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.96666666666667, 88.66666666666667, 1.0, 2.0, 0.3282714456302778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515091.1879423255, 515091.1879423255, 168089.3177428393], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7262400.0000, 
sim time next is 7263000.0000, 
raw observation next is [21.95, 88.5, 1.0, 2.0, 0.3271061895200982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 513743.2461474621, 513743.2461474627, 167996.220911652], 
processed observation next is [1.0, 0.043478260869565216, 0.2393364928909953, 0.885, 1.0, 1.0, 0.18928456568686527, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14270645726318393, 0.1427064572631841, 0.25074062822634624], 
reward next is 0.7493, 
noisyNet noise sample is [array([1.0285292], dtype=float32), 1.8261606]. 
=============================================
[2019-03-26 21:51:09,536] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[68.14917 ]
 [68.214035]
 [68.40346 ]
 [68.56467 ]
 [68.85425 ]], R is [[68.19698334]
 [68.26413727]
 [68.33042908]
 [68.39587402]
 [68.46042633]].
[2019-03-26 21:51:12,364] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.9225517e-21 1.0000000e+00 1.6336479e-20 5.9123383e-17 2.7818582e-26], sum to 1.0000
[2019-03-26 21:51:12,373] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1411
[2019-03-26 21:51:12,379] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.9, 30.0, 1.0, 2.0, 0.2544687688644385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 419707.3587315264, 419707.3587315264, 161319.5096549368], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6876000.0000, 
sim time next is 6876600.0000, 
raw observation next is [29.86666666666667, 31.16666666666666, 1.0, 2.0, 0.2530402991085502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 416885.9759888996, 416885.9759889003, 161192.1970138435], 
processed observation next is [0.0, 0.6086956521739131, 0.6145339652448659, 0.3116666666666666, 1.0, 1.0, 0.10004855314283155, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11580165999691655, 0.11580165999691674, 0.24058536867737837], 
reward next is 0.7594, 
noisyNet noise sample is [array([2.243199], dtype=float32), -0.41110405]. 
=============================================
[2019-03-26 21:51:13,190] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2768921e-22 1.0000000e+00 2.8088098e-22 2.5881070e-17 8.1623039e-28], sum to 1.0000
[2019-03-26 21:51:13,198] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7364
[2019-03-26 21:51:13,205] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.31666666666667, 69.83333333333333, 1.0, 2.0, 0.3881709464628906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 582580.531923671, 582580.5319236703, 173045.1849274878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6901800.0000, 
sim time next is 6902400.0000, 
raw observation next is [26.23333333333333, 70.66666666666667, 1.0, 2.0, 0.3902538720148053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 584690.2530060142, 584690.2530060142, 173205.4094153247], 
processed observation next is [0.0, 0.9130434782608695, 0.44233807266982617, 0.7066666666666667, 1.0, 1.0, 0.26536611086121126, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16241395916833726, 0.16241395916833726, 0.2585155364407832], 
reward next is 0.7415, 
noisyNet noise sample is [array([0.14472067], dtype=float32), 1.3069831]. 
=============================================
[2019-03-26 21:51:25,803] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.3028981e-21 1.0000000e+00 7.0535203e-20 2.8503095e-16 5.6688562e-26], sum to 1.0000
[2019-03-26 21:51:25,810] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5348
[2019-03-26 21:51:25,814] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 85.66666666666667, 1.0, 2.0, 0.5065954625839889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 721175.2415038793, 721175.2415038793, 186333.5788862473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7107600.0000, 
sim time next is 7108200.0000, 
raw observation next is [25.5, 84.5, 1.0, 2.0, 0.5052259938965823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 719182.4200182089, 719182.4200182089, 186106.7225950922], 
processed observation next is [1.0, 0.2608695652173913, 0.40758293838862564, 0.845, 1.0, 1.0, 0.40388673963443644, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19977289444950247, 0.19977289444950247, 0.277771227753869], 
reward next is 0.7222, 
noisyNet noise sample is [array([1.3003877], dtype=float32), 0.9423453]. 
=============================================
[2019-03-26 21:51:26,530] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.3303567e-21 1.0000000e+00 5.5732205e-20 8.1917372e-16 2.9004536e-26], sum to 1.0000
[2019-03-26 21:51:26,543] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4543
[2019-03-26 21:51:26,551] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.15, 94.5, 1.0, 2.0, 0.5293945642474459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 753184.2030502071, 753184.2030502065, 190045.4234577006], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7101000.0000, 
sim time next is 7101600.0000, 
raw observation next is [24.1, 94.66666666666666, 1.0, 2.0, 0.5528481404135185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 787519.6662528536, 787519.6662528529, 194206.4304038058], 
processed observation next is [1.0, 0.17391304347826086, 0.3412322274881518, 0.9466666666666665, 1.0, 1.0, 0.46126281977532346, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2187554628480149, 0.2187554628480147, 0.2898603438862773], 
reward next is 0.7101, 
noisyNet noise sample is [array([0.10051451], dtype=float32), -1.2292086]. 
=============================================
[2019-03-26 21:51:30,018] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.4212174e-21 1.0000000e+00 6.7052189e-21 1.2494530e-15 7.6621936e-27], sum to 1.0000
[2019-03-26 21:51:30,033] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9255
[2019-03-26 21:51:30,041] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.06666666666667, 83.33333333333334, 1.0, 2.0, 0.4754627256011617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 665447.246026144, 665447.2460261446, 179979.2249451161], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7158000.0000, 
sim time next is 7158600.0000, 
raw observation next is [26.05, 83.5, 1.0, 2.0, 0.4759218724960754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 665866.1073400227, 665866.1073400221, 180019.0258235217], 
processed observation next is [1.0, 0.8695652173913043, 0.43364928909952616, 0.835, 1.0, 1.0, 0.36858056927238, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18496280759445075, 0.18496280759445058, 0.2686851131694354], 
reward next is 0.7313, 
noisyNet noise sample is [array([-0.8638498], dtype=float32), 0.36452806]. 
=============================================
[2019-03-26 21:51:32,428] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.3505358e-22 1.0000000e+00 1.1611906e-20 2.5604845e-16 1.6066292e-26], sum to 1.0000
[2019-03-26 21:51:32,436] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9206
[2019-03-26 21:51:32,443] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.05, 85.0, 1.0, 2.0, 0.2848850733011434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 460528.7235308647, 460528.7235308641, 164303.8204612862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7410600.0000, 
sim time next is 7411200.0000, 
raw observation next is [21.13333333333333, 84.66666666666667, 1.0, 2.0, 0.285298648560027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 460868.167480948, 460868.1674809474, 164328.995141241], 
processed observation next is [1.0, 0.782608695652174, 0.20063191153238533, 0.8466666666666667, 1.0, 1.0, 0.1389140344096711, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12801893541137443, 0.12801893541137427, 0.24526715692722537], 
reward next is 0.7547, 
noisyNet noise sample is [array([1.1651394], dtype=float32), -0.8693714]. 
=============================================
[2019-03-26 21:51:35,136] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.1939732e-09 9.0566266e-01 3.3429824e-08 9.4337299e-02 7.4465390e-12], sum to 1.0000
[2019-03-26 21:51:35,144] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7475
[2019-03-26 21:51:35,154] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2101361.400923687 W.
[2019-03-26 21:51:35,165] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.41666666666666, 68.33333333333334, 1.0, 2.0, 0.8616520892023151, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.991724240391225, 6.9112, 168.9124767996909, 2101361.400923687, 2044234.895598726, 424175.2488417211], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7825800.0000, 
sim time next is 7826400.0000, 
raw observation next is [30.3, 68.0, 1.0, 2.0, 0.8603513074204293, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.985901389613797, 6.9112, 168.9124462127793, 2099540.760568653, 2046545.183856979, 424032.9658819204], 
processed observation next is [1.0, 0.6086956521739131, 0.6350710900473934, 0.68, 1.0, 1.0, 0.8317485631571437, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007470138961379736, 0.0, 0.8294374393572175, 0.5832057668246258, 0.5684847732936053, 0.6328850237043588], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.17496946], dtype=float32), 0.3224439]. 
=============================================
[2019-03-26 21:51:38,527] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5973948e-19 1.0000000e+00 2.1124943e-19 2.1914670e-14 3.9685395e-24], sum to 1.0000
[2019-03-26 21:51:38,537] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7677
[2019-03-26 21:51:38,543] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.86666666666667, 59.0, 1.0, 2.0, 0.5462299938157297, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9577077174938966, 6.911199999999999, 6.9112, 168.9127464997505, 1648931.145085078, 1648931.145085079, 344972.0300801019], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7310400.0000, 
sim time next is 7311000.0000, 
raw observation next is [27.83333333333334, 59.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.152911102298452, 6.9112, 168.9114647767598, 1744167.892723305, 1572691.232086751, 329547.399946258], 
processed observation next is [1.0, 0.6086956521739131, 0.5181674565560824, 0.595, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.024171110229845194, 0.0, 0.8294326200570584, 0.48449108131202917, 0.436858675579653, 0.49186179096456417], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5738309], dtype=float32), -1.761799]. 
=============================================
[2019-03-26 21:51:38,558] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[64.87561 ]
 [68.82335 ]
 [68.971275]
 [69.1725  ]
 [69.30222 ]], R is [[63.87117767]
 [63.7175827 ]
 [63.08040619]
 [62.68745041]
 [62.58585358]].
[2019-03-26 21:51:43,187] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9567016e-11 9.9935859e-01 4.2320963e-10 6.4146321e-04 1.6358529e-14], sum to 1.0000
[2019-03-26 21:51:43,195] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1475
[2019-03-26 21:51:43,205] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3912125.662500559 W.
[2019-03-26 21:51:43,215] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.76666666666667, 69.33333333333334, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 10.37473072648459, 6.9112, 168.8928124313932, 3912125.662500559, 1455270.792078736, 304984.0170044823], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7824000.0000, 
sim time next is 7824600.0000, 
raw observation next is [30.65, 69.0, 1.0, 2.0, 0.6693244167562855, 1.0, 1.0, 0.6552522478924053, 1.0, 1.0, 1.03, 7.005095313539464, 6.9112, 170.5573041426782, 2749360.026059572, 2682098.993554097, 511813.6045160216], 
processed observation next is [1.0, 0.5652173913043478, 0.6516587677725119, 0.69, 1.0, 1.0, 0.6015956828388982, 1.0, 0.5, 0.5846412625209703, 1.0, 0.5, 1.0365853658536586, 0.009389531353946356, 0.0, 0.8375144448122397, 0.7637111183498811, 0.7450274982094715, 0.7639009022627188], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.00900511], dtype=float32), -0.6768316]. 
=============================================
[2019-03-26 21:51:43,421] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0425848e-21 1.0000000e+00 1.7753115e-20 3.8420859e-16 1.9880057e-26], sum to 1.0000
[2019-03-26 21:51:43,429] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7607
[2019-03-26 21:51:43,435] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.96666666666667, 92.0, 1.0, 2.0, 0.6419716570852705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1021055.069585225, 1021055.069585225, 223176.3890289467], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7392000.0000, 
sim time next is 7392600.0000, 
raw observation next is [20.95, 92.0, 1.0, 2.0, 0.6429167467192056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1022892.708885162, 1022892.708885162, 223417.3396784005], 
processed observation next is [1.0, 0.5652173913043478, 0.19194312796208532, 0.92, 1.0, 1.0, 0.5697792129147056, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2841368635792117, 0.2841368635792117, 0.33345871593791115], 
reward next is 0.6665, 
noisyNet noise sample is [array([-0.8026573], dtype=float32), -0.540219]. 
=============================================
[2019-03-26 21:51:43,847] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:51:43,848] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:51:43,907] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run8
[2019-03-26 21:51:44,151] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3619777e-21 1.0000000e+00 4.1850367e-21 1.2546440e-16 3.7452970e-27], sum to 1.0000
[2019-03-26 21:51:44,158] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5886
[2019-03-26 21:51:44,161] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 95.0, 1.0, 2.0, 0.5300940610091275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 763228.287883301, 763228.2878833016, 191303.9255806483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7612200.0000, 
sim time next is 7612800.0000, 
raw observation next is [23.76666666666667, 95.0, 1.0, 2.0, 0.5236451941342106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 755012.724271016, 755012.724271016, 190340.6590097879], 
processed observation next is [1.0, 0.08695652173913043, 0.32543443917851517, 0.95, 1.0, 1.0, 0.4260785471496513, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20972575674194888, 0.20972575674194888, 0.2840905358355043], 
reward next is 0.7159, 
noisyNet noise sample is [array([-0.9681556], dtype=float32), -0.5722694]. 
=============================================
[2019-03-26 21:51:45,393] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1449378e-22 1.0000000e+00 7.1033317e-22 2.3410146e-18 1.3601355e-27], sum to 1.0000
[2019-03-26 21:51:45,402] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3875
[2019-03-26 21:51:45,409] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.25, 94.5, 1.0, 2.0, 0.3226904336105356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 506466.2105589872, 506466.2105589872, 167429.6081203992], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7446600.0000, 
sim time next is 7447200.0000, 
raw observation next is [21.23333333333333, 94.66666666666666, 1.0, 2.0, 0.3226336790354542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 506334.9479582717, 506334.9479582717, 167418.5494178582], 
processed observation next is [0.0, 0.17391304347826086, 0.2053712480252764, 0.9466666666666665, 1.0, 1.0, 0.18389599883789662, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14064859665507548, 0.14064859665507548, 0.24987843196695253], 
reward next is 0.7501, 
noisyNet noise sample is [array([-0.2585728], dtype=float32), -1.693592]. 
=============================================
[2019-03-26 21:51:48,890] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 21:51:48,892] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:51:48,892] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:51:48,892] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:51:48,893] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:51:48,894] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:51:48,895] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:51:48,898] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:51:48,897] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:51:48,901] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:51:48,902] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:51:48,929] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run60
[2019-03-26 21:51:48,930] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run60
[2019-03-26 21:51:48,968] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run60
[2019-03-26 21:51:48,995] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run60
[2019-03-26 21:51:48,996] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run60
[2019-03-26 21:52:15,396] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09148752], dtype=float32), 0.06660514]
[2019-03-26 21:52:15,398] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.33333333333333, 94.0, 1.0, 2.0, 0.449903455275776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 636792.6927127681, 636792.6927127681, 177172.4196123565]
[2019-03-26 21:52:15,399] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:52:15,401] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.7333286e-22 1.0000000e+00 8.3753915e-22 1.3301815e-17 8.7850457e-28], sampled 0.39584892491971635
[2019-03-26 21:52:54,388] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09148752], dtype=float32), 0.06660514]
[2019-03-26 21:52:54,389] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [34.12927700666667, 76.04419345333335, 1.0, 2.0, 0.730768641129313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1021290.67350234, 1021290.67350234, 227640.3754899486]
[2019-03-26 21:52:54,390] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:52:54,392] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.9204464e-22 1.0000000e+00 3.9771060e-22 1.4474499e-17 6.0242477e-28], sampled 0.0008643436703376084
[2019-03-26 21:53:09,296] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09148752], dtype=float32), 0.06660514]
[2019-03-26 21:53:09,296] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.96666666666667, 62.66666666666667, 1.0, 2.0, 0.5933256754220378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 829131.3443661353, 829131.3443661353, 199508.6167523538]
[2019-03-26 21:53:09,296] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:53:09,300] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.6238339e-23 1.0000000e+00 1.6225167e-22 1.0429415e-16 7.5720524e-29], sampled 0.5521306074177713
[2019-03-26 21:53:11,745] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09148752], dtype=float32), 0.06660514]
[2019-03-26 21:53:11,746] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.33307558, 81.20319486, 1.0, 2.0, 0.5149940116259626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 719631.2145929715, 719631.2145929721, 185978.1669461099]
[2019-03-26 21:53:11,747] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:53:11,749] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.3637064e-22 1.0000000e+00 6.8601677e-22 9.2520069e-18 1.0129594e-27], sampled 0.03581531362132029
[2019-03-26 21:53:42,443] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09148752], dtype=float32), 0.06660514]
[2019-03-26 21:53:42,443] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.83506432333333, 66.42977848833334, 1.0, 2.0, 0.9271205840502458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1295871.115800336, 1295871.115800336, 277504.8098292876]
[2019-03-26 21:53:42,446] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:53:42,450] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.6203993e-22 1.0000000e+00 1.5009384e-21 5.9627791e-17 2.2634546e-27], sampled 0.8923461503731389
[2019-03-26 21:53:42,921] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.0200 3164452019.3244 1774.0000
[2019-03-26 21:53:43,060] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.1176 2927522445.3238 1338.0000
[2019-03-26 21:53:43,089] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.4166 2842558242.3972 1131.0000
[2019-03-26 21:53:43,196] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.1799 3007672286.0859 1766.0000
[2019-03-26 21:53:43,252] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9878 2779190307.3385 933.0000
[2019-03-26 21:53:44,267] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1475000, evaluation results [1475000.0, 7881.020028330992, 3164452019.324362, 1774.0, 8254.117607123124, 2927522445.323764, 1338.0, 8659.987755389953, 2779190307.3384666, 933.0, 7998.179893286996, 3007672286.085915, 1766.0, 8497.416582222564, 2842558242.397172, 1131.0]
[2019-03-26 21:53:45,038] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.8896663e-22 1.0000000e+00 1.1141986e-22 1.0153399e-17 5.2330588e-28], sum to 1.0000
[2019-03-26 21:53:45,045] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5433
[2019-03-26 21:53:45,048] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 93.0, 1.0, 2.0, 0.4061989509719723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 597897.7361913783, 597897.7361913783, 174100.098180348], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7520400.0000, 
sim time next is 7521000.0000, 
raw observation next is [23.5, 93.0, 1.0, 2.0, 0.4055862931466801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 597113.5328769247, 597113.5328769247, 174031.1522881732], 
processed observation next is [0.0, 0.043478260869565216, 0.31279620853080575, 0.93, 1.0, 1.0, 0.28383890740563866, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1658648702435902, 0.1658648702435902, 0.25974798848981073], 
reward next is 0.7403, 
noisyNet noise sample is [array([1.3870246], dtype=float32), 2.3425672]. 
=============================================
[2019-03-26 21:53:45,057] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[76.158485]
 [76.31316 ]
 [76.59951 ]
 [77.01353 ]
 [77.48538 ]], R is [[75.95607758]
 [75.9366684 ]
 [75.91731262]
 [75.89807892]
 [75.87906647]].
[2019-03-26 21:53:45,094] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.3582686e-23 1.0000000e+00 5.1254997e-22 2.9619075e-17 9.4844163e-28], sum to 1.0000
[2019-03-26 21:53:45,102] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1755
[2019-03-26 21:53:45,108] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.43333333333333, 92.33333333333334, 1.0, 2.0, 0.5314335195758074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742611.1291705581, 742611.1291705575, 188667.7318336927], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7947600.0000, 
sim time next is 7948200.0000, 
raw observation next is [26.41666666666666, 92.66666666666666, 1.0, 2.0, 0.5322698190556402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 743780.161061396, 743780.1610613954, 188806.6799080083], 
processed observation next is [1.0, 1.0, 0.4510268562401261, 0.9266666666666665, 1.0, 1.0, 0.43646966151281946, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20660560029483221, 0.20660560029483208, 0.28180101478807207], 
reward next is 0.7182, 
noisyNet noise sample is [array([-2.4067116], dtype=float32), 0.8136369]. 
=============================================
[2019-03-26 21:53:46,162] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:53:46,162] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:53:46,252] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run8
[2019-03-26 21:53:46,966] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:53:46,967] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:53:47,030] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run8
[2019-03-26 21:53:47,816] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6111782e-21 1.0000000e+00 1.3754431e-21 1.1290790e-16 1.9902812e-27], sum to 1.0000
[2019-03-26 21:53:47,822] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0453
[2019-03-26 21:53:47,826] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.73333333333333, 96.0, 1.0, 2.0, 0.8486763137904157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1266470.075735952, 1266470.075735952, 267414.8147117951], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 139200.0000, 
sim time next is 139800.0000, 
raw observation next is [22.71666666666667, 96.0, 1.0, 2.0, 0.824526832537876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1231179.706479469, 1231179.706479469, 260869.5958023983], 
processed observation next is [1.0, 0.6086956521739131, 0.2756714060031597, 0.96, 1.0, 1.0, 0.7885865452263565, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.34199436291096363, 0.34199436291096363, 0.3893576056752214], 
reward next is 0.6106, 
noisyNet noise sample is [array([1.0180827], dtype=float32), -1.8780453]. 
=============================================
[2019-03-26 21:53:55,271] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.3496742e-21 1.0000000e+00 6.8809027e-21 1.5941658e-15 2.8018589e-26], sum to 1.0000
[2019-03-26 21:53:55,279] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0228
[2019-03-26 21:53:55,284] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.56666666666667, 96.0, 1.0, 2.0, 0.7684594695932436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1153431.100435433, 1153431.100435433, 246902.4024887146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 145200.0000, 
sim time next is 145800.0000, 
raw observation next is [22.55, 96.0, 1.0, 2.0, 0.7553360354431568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1134393.075448903, 1134393.075448903, 243666.2669851979], 
processed observation next is [1.0, 0.6956521739130435, 0.26777251184834133, 0.96, 1.0, 1.0, 0.7052241390881406, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3151091876246953, 0.3151091876246953, 0.36368099550029537], 
reward next is 0.6363, 
noisyNet noise sample is [array([-1.2349662], dtype=float32), -0.31378305]. 
=============================================
[2019-03-26 21:53:57,062] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:53:57,063] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:53:57,125] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run8
[2019-03-26 21:53:59,318] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1587259e-20 1.0000000e+00 1.5663544e-20 3.6483281e-16 9.5305175e-27], sum to 1.0000
[2019-03-26 21:53:59,326] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0506
[2019-03-26 21:53:59,333] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 87.33333333333333, 1.0, 2.0, 0.5068338878458176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 708224.7958070813, 708224.7958070813, 184673.6865660661], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7779000.0000, 
sim time next is 7779600.0000, 
raw observation next is [26.4, 87.0, 1.0, 2.0, 0.5053899978036402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 706206.5040660381, 706206.5040660386, 184444.8221595999], 
processed observation next is [1.0, 0.043478260869565216, 0.45023696682464454, 0.87, 1.0, 1.0, 0.404084334703181, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19616847335167725, 0.1961684733516774, 0.2752907793426864], 
reward next is 0.7247, 
noisyNet noise sample is [array([-0.33625075], dtype=float32), -0.69593245]. 
=============================================
[2019-03-26 21:53:59,534] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:53:59,535] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:53:59,613] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run8
[2019-03-26 21:54:00,282] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.5533278e-20 1.0000000e+00 1.9487730e-19 1.2275467e-14 1.2930583e-25], sum to 1.0000
[2019-03-26 21:54:00,288] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3128
[2019-03-26 21:54:00,293] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.25, 86.0, 1.0, 2.0, 0.7689883759087291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1074731.952577922, 1074731.952577922, 236438.2149592526], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7785000.0000, 
sim time next is 7785600.0000, 
raw observation next is [26.2, 86.33333333333334, 1.0, 2.0, 0.7306928848008548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1021184.748826417, 1021184.748826418, 227606.9774991266], 
processed observation next is [1.0, 0.08695652173913043, 0.44075829383886256, 0.8633333333333334, 1.0, 1.0, 0.6755335961456082, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2836624302295603, 0.28366243022956056, 0.3397119067151143], 
reward next is 0.6603, 
noisyNet noise sample is [array([-1.3298386], dtype=float32), 0.2605468]. 
=============================================
[2019-03-26 21:54:02,201] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4671888e-08 4.0517950e-01 1.4861928e-07 5.9482032e-01 2.2671004e-11], sum to 1.0000
[2019-03-26 21:54:02,210] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3715
[2019-03-26 21:54:02,219] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2204536.868909821 W.
[2019-03-26 21:54:02,226] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.81666666666667, 64.16666666666667, 1.0, 2.0, 0.7882797166684661, 1.0, 2.0, 0.7882797166684661, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2204536.868909821, 2204536.86890982, 414200.4413109841], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7834200.0000, 
sim time next is 7834800.0000, 
raw observation next is [30.63333333333333, 65.33333333333334, 1.0, 2.0, 0.494185590427905, 1.0, 2.0, 0.494185590427905, 1.0, 1.0, 0.8497381937859185, 6.9112, 6.9112, 170.5573041426782, 2072963.741885376, 2072963.741885376, 409628.2705885232], 
processed observation next is [1.0, 0.6956521739130435, 0.6508688783570299, 0.6533333333333334, 1.0, 1.0, 0.3905850487083192, 1.0, 1.0, 0.3905850487083192, 1.0, 0.5, 0.8167538948608762, 0.0, 0.0, 0.8375144448122397, 0.5758232616348267, 0.5758232616348267, 0.6113854784903331], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.49148723], dtype=float32), 0.5430883]. 
=============================================
[2019-03-26 21:54:07,059] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:54:07,060] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:54:07,139] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run8
[2019-03-26 21:54:09,135] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:54:09,136] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:54:09,212] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run8
[2019-03-26 21:54:09,240] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:54:09,244] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:54:09,324] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run8
[2019-03-26 21:54:09,343] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:54:09,346] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:54:09,399] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run8
[2019-03-26 21:54:09,480] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:54:09,480] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:54:09,524] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run8
[2019-03-26 21:54:09,541] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:54:09,546] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:54:09,569] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:54:09,569] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:54:09,583] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:54:09,584] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:54:09,592] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run8
[2019-03-26 21:54:09,632] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run8
[2019-03-26 21:54:09,675] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run8
[2019-03-26 21:54:09,825] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:54:09,825] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:54:09,831] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run8
[2019-03-26 21:54:09,982] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:54:09,983] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:54:09,998] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run8
[2019-03-26 21:54:10,197] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 21:54:10,198] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:54:10,203] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run8
[2019-03-26 21:54:11,390] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6262298e-21 1.0000000e+00 7.9363230e-21 6.4236610e-17 8.4639198e-27], sum to 1.0000
[2019-03-26 21:54:11,396] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6559
[2019-03-26 21:54:11,401] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.15, 84.0, 1.0, 2.0, 0.3163609366508008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 501683.0202661069, 501683.0202661069, 167176.6671443254], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 27000.0000, 
sim time next is 27600.0000, 
raw observation next is [22.2, 84.0, 1.0, 2.0, 0.3279442786595308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 519472.6537201722, 519472.6537201722, 168521.9721615786], 
processed observation next is [1.0, 0.30434782608695654, 0.2511848341232228, 0.84, 1.0, 1.0, 0.1902943116379889, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1442979593667145, 0.1442979593667145, 0.2515253315844457], 
reward next is 0.7485, 
noisyNet noise sample is [array([-0.68015033], dtype=float32), -0.31526017]. 
=============================================
[2019-03-26 21:54:11,460] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.3668182e-08 9.9999535e-01 5.0357990e-08 4.4840745e-06 2.1917791e-10], sum to 1.0000
[2019-03-26 21:54:11,469] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1423
[2019-03-26 21:54:11,472] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.53333333333333, 84.83333333333334, 1.0, 2.0, 0.2679605943001746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 437087.9319102297, 437087.9319102297, 162685.9714468173], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6600.0000, 
sim time next is 7200.0000, 
raw observation next is [20.6, 85.0, 1.0, 2.0, 0.2698905340208645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 439649.4341560845, 439649.4341560845, 162867.4799364278], 
processed observation next is [1.0, 0.08695652173913043, 0.17535545023696694, 0.85, 1.0, 1.0, 0.12035004098899335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12212484282113457, 0.12212484282113457, 0.24308579094989222], 
reward next is 0.7569, 
noisyNet noise sample is [array([-0.36527324], dtype=float32), -0.36498347]. 
=============================================
[2019-03-26 21:54:15,513] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0579008e-21 1.0000000e+00 4.9140716e-21 1.4721241e-17 3.6456644e-27], sum to 1.0000
[2019-03-26 21:54:15,523] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1019
[2019-03-26 21:54:15,529] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.93333333333333, 95.33333333333333, 1.0, 2.0, 0.2837356703576741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 457444.3041101692, 457444.3041101685, 164099.8781361738], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 193200.0000, 
sim time next is 193800.0000, 
raw observation next is [19.96666666666667, 95.16666666666667, 1.0, 2.0, 0.2839274654622069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 457631.5982186428, 457631.5982186428, 164112.6145293539], 
processed observation next is [0.0, 0.21739130434782608, 0.14533965244865735, 0.9516666666666667, 1.0, 1.0, 0.13726200658097212, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12711988839406746, 0.12711988839406746, 0.24494420079008042], 
reward next is 0.7551, 
noisyNet noise sample is [array([-0.2525779], dtype=float32), -0.86704105]. 
=============================================
[2019-03-26 21:54:15,698] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3975843e-22 1.0000000e+00 6.9002227e-21 6.8783185e-17 1.1531086e-27], sum to 1.0000
[2019-03-26 21:54:15,710] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0357
[2019-03-26 21:54:15,715] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.25, 89.0, 1.0, 2.0, 0.3419217873529487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 532283.6402900005, 532283.6402900012, 169344.8744007905], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 84600.0000, 
sim time next is 85200.0000, 
raw observation next is [22.26666666666667, 89.0, 1.0, 2.0, 0.3422482490954631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 532557.1297186621, 532557.1297186614, 169360.8597203503], 
processed observation next is [1.0, 1.0, 0.2543443917851502, 0.89, 1.0, 1.0, 0.20752801095838927, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1479325360329617, 0.1479325360329615, 0.252777402567687], 
reward next is 0.7472, 
noisyNet noise sample is [array([-0.19009675], dtype=float32), -0.9131752]. 
=============================================
[2019-03-26 21:54:18,341] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.50929225e-21 1.00000000e+00 1.78850423e-21 1.02179424e-16
 5.17920233e-27], sum to 1.0000
[2019-03-26 21:54:18,354] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1189
[2019-03-26 21:54:18,358] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 96.0, 1.0, 2.0, 0.3757333794794568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 565510.5378395348, 565510.5378395341, 171578.450878132], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 149400.0000, 
sim time next is 150000.0000, 
raw observation next is [22.5, 96.0, 1.0, 2.0, 0.3819982060870853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 574951.4300596942, 574951.4300596935, 172412.015864021], 
processed observation next is [1.0, 0.7391304347826086, 0.2654028436018958, 0.96, 1.0, 1.0, 0.25541952540612683, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15970873057213728, 0.15970873057213708, 0.2573313669612254], 
reward next is 0.7427, 
noisyNet noise sample is [array([-0.520309], dtype=float32), -1.3922008]. 
=============================================
[2019-03-26 21:54:18,381] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[74.27148 ]
 [74.176155]
 [73.93016 ]
 [73.64509 ]
 [73.54418 ]], R is [[74.47112274]
 [74.47032166]
 [74.46881866]
 [74.45157623]
 [74.34409332]].
[2019-03-26 21:54:23,096] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.7577967e-21 1.0000000e+00 1.3613446e-20 6.9175785e-17 2.6108030e-26], sum to 1.0000
[2019-03-26 21:54:23,104] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3540
[2019-03-26 21:54:23,111] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.73333333333333, 82.00000000000001, 1.0, 2.0, 0.2358597049553621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 390202.8409977127, 390202.8409977127, 159447.260738842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 450600.0000, 
sim time next is 451200.0000, 
raw observation next is [19.76666666666667, 82.0, 1.0, 2.0, 0.228648518716553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 378149.2841175299, 378149.2841175292, 158790.7606445757], 
processed observation next is [1.0, 0.21739130434782608, 0.13586097946287537, 0.82, 1.0, 1.0, 0.07066086592355783, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10504146781042498, 0.10504146781042478, 0.2370011352904115], 
reward next is 0.7630, 
noisyNet noise sample is [array([-1.2473596], dtype=float32), 0.064239256]. 
=============================================
[2019-03-26 21:54:26,760] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.1215355e-22 1.0000000e+00 2.6208267e-22 1.1160945e-17 5.5827090e-28], sum to 1.0000
[2019-03-26 21:54:26,772] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2980
[2019-03-26 21:54:26,777] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.85, 88.66666666666667, 1.0, 2.0, 0.2812510604852813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 452555.221064153, 452555.221064153, 163769.1885237974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 283800.0000, 
sim time next is 284400.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.282696241791992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 454294.7908719257, 454294.7908719263, 163883.2565483385], 
processed observation next is [0.0, 0.30434782608695654, 0.19431279620853087, 0.88, 1.0, 1.0, 0.13577860456866503, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1261929974644238, 0.12619299746442397, 0.24460187544528136], 
reward next is 0.7554, 
noisyNet noise sample is [array([-0.19534147], dtype=float32), -0.47352085]. 
=============================================
[2019-03-26 21:54:30,204] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.3039161e-23 1.0000000e+00 4.1548274e-22 5.0032648e-18 4.9676164e-29], sum to 1.0000
[2019-03-26 21:54:30,218] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8092
[2019-03-26 21:54:30,223] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 86.0, 1.0, 2.0, 0.284091025076415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 456391.554335087, 456391.554335087, 164024.0112794014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 332400.0000, 
sim time next is 333000.0000, 
raw observation next is [21.2, 86.0, 1.0, 2.0, 0.2830604192682807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 455026.1301090805, 455026.1301090805, 163933.381175378], 
processed observation next is [0.0, 0.8695652173913043, 0.20379146919431282, 0.86, 1.0, 1.0, 0.13621737261238637, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12639614725252238, 0.12639614725252238, 0.2446766883214597], 
reward next is 0.7553, 
noisyNet noise sample is [array([-0.2533415], dtype=float32), 0.25257316]. 
=============================================
[2019-03-26 21:54:30,248] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[80.10922 ]
 [80.06434 ]
 [80.00855 ]
 [79.955894]
 [79.91955 ]], R is [[80.10248566]
 [80.05664825]
 [80.01113892]
 [79.96595764]
 [79.92111206]].
[2019-03-26 21:54:31,248] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.1797711e-21 1.0000000e+00 6.0333339e-20 1.6395822e-16 8.4517282e-26], sum to 1.0000
[2019-03-26 21:54:31,257] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3092
[2019-03-26 21:54:31,263] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 80.5, 1.0, 2.0, 0.2435427851892651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 401270.2285228275, 401270.2285228275, 160261.07886859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 459000.0000, 
sim time next is 459600.0000, 
raw observation next is [20.33333333333333, 80.33333333333333, 1.0, 2.0, 0.2443283175102852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 402511.2493185347, 402511.249318534, 160338.3618880211], 
processed observation next is [1.0, 0.30434782608695654, 0.16271721958925733, 0.8033333333333332, 1.0, 1.0, 0.08955218977142793, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11180868036625963, 0.11180868036625945, 0.23931098789256883], 
reward next is 0.7607, 
noisyNet noise sample is [array([1.261732], dtype=float32), 0.263964]. 
=============================================
[2019-03-26 21:54:34,528] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1766096e-20 1.0000000e+00 2.7511252e-20 9.6540294e-16 2.2852322e-26], sum to 1.0000
[2019-03-26 21:54:34,536] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8394
[2019-03-26 21:54:34,539] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 80.0, 1.0, 2.0, 0.5961380829508031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 954474.4791067817, 954474.479106781, 213665.3531353726], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 404400.0000, 
sim time next is 405000.0000, 
raw observation next is [22.15, 80.5, 1.0, 2.0, 0.5874190559732858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 940185.5759398754, 940185.5759398754, 211811.7673065752], 
processed observation next is [1.0, 0.6956521739130435, 0.24881516587677724, 0.805, 1.0, 1.0, 0.502914525269019, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.26116265998329874, 0.26116265998329874, 0.3161369661292167], 
reward next is 0.6839, 
noisyNet noise sample is [array([-0.85916173], dtype=float32), -0.08988137]. 
=============================================
[2019-03-26 21:54:34,561] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[72.891464]
 [72.84247 ]
 [72.8345  ]
 [72.78099 ]
 [72.73695 ]], R is [[72.92066193]
 [72.87255859]
 [72.80696106]
 [72.78262329]
 [72.76033783]].
[2019-03-26 21:54:35,557] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.02178029e-23 1.00000000e+00 6.59531767e-23 1.02291686e-17
 1.20259267e-28], sum to 1.0000
[2019-03-26 21:54:35,567] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0166
[2019-03-26 21:54:35,574] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 86.0, 1.0, 2.0, 0.2442807504006924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 402025.3453116264, 402025.3453116264, 160343.6647814425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 432000.0000, 
sim time next is 432600.0000, 
raw observation next is [19.68333333333333, 85.83333333333334, 1.0, 2.0, 0.2435470947532007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 400939.6576215969, 400939.6576215975, 160270.3409328334], 
processed observation next is [1.0, 0.0, 0.13191153238546593, 0.8583333333333334, 1.0, 1.0, 0.08861095753397673, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11137212711711024, 0.11137212711711042, 0.23920946407885582], 
reward next is 0.7608, 
noisyNet noise sample is [array([-0.88461375], dtype=float32), -0.6539813]. 
=============================================
[2019-03-26 21:54:38,393] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 21:54:38,395] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:54:38,395] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:54:38,398] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:54:38,399] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:54:38,400] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:54:38,402] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:54:38,403] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:54:38,405] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:54:38,406] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:54:38,418] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:54:39,320] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run61
[2019-03-26 21:54:39,340] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run61
[2019-03-26 21:54:39,358] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run61
[2019-03-26 21:54:39,360] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run61
[2019-03-26 21:54:39,399] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run61
[2019-03-26 21:54:46,245] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09360334], dtype=float32), 0.06866072]
[2019-03-26 21:54:46,246] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [19.65, 82.0, 1.0, 2.0, 0.3134634717944985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 519031.5619823493, 519031.5619823487, 167746.7283659216]
[2019-03-26 21:54:46,248] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:54:46,252] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.8739494e-22 1.0000000e+00 6.4743958e-22 6.9282440e-18 6.1659326e-28], sampled 0.6180739292907234
[2019-03-26 21:55:00,798] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09360334], dtype=float32), 0.06866072]
[2019-03-26 21:55:00,799] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.53449122333333, 92.089107625, 1.0, 2.0, 0.2742741676997724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 446380.8742384757, 446380.8742384763, 163314.4020826447]
[2019-03-26 21:55:00,800] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:55:00,804] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0114754e-22 1.0000000e+00 3.7264663e-22 2.9703923e-18 3.0794445e-28], sampled 0.596787790988354
[2019-03-26 21:55:18,556] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09360334], dtype=float32), 0.06866072]
[2019-03-26 21:55:18,557] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.58333333333334, 94.00000000000001, 1.0, 2.0, 0.4808156022034412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 674083.5362081722, 674083.5362081722, 180931.7918670275]
[2019-03-26 21:55:18,559] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:55:18,562] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.02611126e-22 1.00000000e+00 2.92635438e-22 3.68192153e-18
 2.31446176e-28], sampled 0.09237076209188744
[2019-03-26 21:55:43,756] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09360334], dtype=float32), 0.06866072]
[2019-03-26 21:55:43,759] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [33.66666666666667, 59.16666666666667, 1.0, 2.0, 0.9946929300405004, 1.0, 2.0, 0.9946929300405004, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2782445.145188771, 2782445.145188772, 525786.9663828945]
[2019-03-26 21:55:43,761] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 21:55:43,764] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.8006022e-12 9.7310662e-01 2.6793226e-10 2.6893405e-02 2.2302350e-15], sampled 0.830000192326506
[2019-03-26 21:55:43,767] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2782445.145188771 W.
[2019-03-26 21:56:03,594] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09360334], dtype=float32), 0.06866072]
[2019-03-26 21:56:03,595] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.53333333333333, 81.33333333333334, 1.0, 2.0, 0.5975529323626769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 835040.9639159498, 835040.9639159505, 200290.1082179762]
[2019-03-26 21:56:03,597] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:56:03,600] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.8142513e-24 1.0000000e+00 1.4288915e-23 2.5263302e-18 8.2039380e-30], sampled 0.5982781488883891
[2019-03-26 21:56:09,652] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09360334], dtype=float32), 0.06866072]
[2019-03-26 21:56:09,654] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.81515552, 78.26179840500001, 1.0, 2.0, 0.8506942838654117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1188987.403456736, 1188987.403456736, 256740.6030990674]
[2019-03-26 21:56:09,655] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:56:09,657] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.9129066e-22 1.0000000e+00 6.7323871e-21 3.4254199e-15 1.3523647e-27], sampled 0.7522242896120949
[2019-03-26 21:56:14,629] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09360334], dtype=float32), 0.06866072]
[2019-03-26 21:56:14,630] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.74024576, 82.54936926333335, 1.0, 2.0, 0.511345824934202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 714531.6756803464, 714531.6756803464, 185391.6727078446]
[2019-03-26 21:56:14,630] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:56:14,633] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.9695785e-23 1.0000000e+00 2.2247844e-22 1.4464343e-17 2.3077790e-28], sampled 0.3995408852317117
[2019-03-26 21:56:16,643] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09360334], dtype=float32), 0.06866072]
[2019-03-26 21:56:16,644] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.86059196666667, 63.39372060666666, 1.0, 2.0, 0.8951068005028914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1283986.178054121, 1283986.178054121, 273429.4934493403]
[2019-03-26 21:56:16,645] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:56:16,649] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.6159218e-21 1.0000000e+00 1.3672412e-20 3.7208120e-15 4.0616547e-26], sampled 0.6925578854055879
[2019-03-26 21:56:32,559] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09360334], dtype=float32), 0.06866072]
[2019-03-26 21:56:32,561] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.32537327, 71.21407122000001, 1.0, 2.0, 0.5031659671927754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 703097.7273240221, 703097.7273240221, 184092.4710290805]
[2019-03-26 21:56:32,563] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:56:32,567] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.6472821e-22 1.0000000e+00 4.4826136e-22 1.8440428e-17 3.3147951e-28], sampled 0.12060675098200035
[2019-03-26 21:56:33,160] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.5400 3164334694.9388 1775.0000
[2019-03-26 21:56:33,384] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.8112 2927481116.5181 1338.0000
[2019-03-26 21:56:33,518] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 21:56:33,582] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8493.8728 2842654543.2783 1131.0000
[2019-03-26 21:56:33,726] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7167 2779131942.0695 933.0000
[2019-03-26 21:56:34,743] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1500000, evaluation results [1500000.0, 7882.539970075675, 3164334694.938758, 1775.0, 8252.811166630017, 2927481116.518129, 1338.0, 8660.716715102415, 2779131942.069542, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8493.872780083646, 2842654543.278335, 1131.0]
[2019-03-26 21:56:38,533] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3014927e-21 1.0000000e+00 4.9721701e-20 2.3613755e-17 6.6967119e-27], sum to 1.0000
[2019-03-26 21:56:38,543] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9475
[2019-03-26 21:56:38,548] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.6, 91.0, 1.0, 2.0, 0.2087180698239279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 348117.7751241152, 348117.7751241145, 156486.8581512556], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 536400.0000, 
sim time next is 537000.0000, 
raw observation next is [17.8, 90.16666666666667, 1.0, 2.0, 0.2141013815277968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 356970.2964023377, 356970.2964023383, 156989.1358950659], 
processed observation next is [1.0, 0.21739130434782608, 0.04265402843601906, 0.9016666666666667, 1.0, 1.0, 0.053134194611803374, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.09915841566731604, 0.0991584156673162, 0.23431214312696405], 
reward next is 0.7657, 
noisyNet noise sample is [array([0.6227143], dtype=float32), 0.11061411]. 
=============================================
[2019-03-26 21:56:38,567] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[72.568954]
 [72.51672 ]
 [72.49276 ]
 [72.64217 ]
 [72.78288 ]], R is [[72.65892792]
 [72.69877625]
 [72.73808289]
 [72.77684021]
 [72.81508636]].
[2019-03-26 21:56:39,145] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7199945e-21 1.0000000e+00 9.3394023e-21 3.2725601e-17 9.1232711e-27], sum to 1.0000
[2019-03-26 21:56:39,154] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9631
[2019-03-26 21:56:39,159] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 69.0, 1.0, 2.0, 0.4610482251419944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 758572.5729980959, 758572.5729980959, 189053.0230014907], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 553200.0000, 
sim time next is 553800.0000, 
raw observation next is [22.2, 67.5, 1.0, 2.0, 0.4726403767214698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777850.2612768414, 777850.2612768414, 191015.0072088683], 
processed observation next is [1.0, 0.391304347826087, 0.2511848341232228, 0.675, 1.0, 1.0, 0.36462695990538535, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21606951702134483, 0.21606951702134483, 0.28509702568487805], 
reward next is 0.7149, 
noisyNet noise sample is [array([1.281828], dtype=float32), -0.44032377]. 
=============================================
[2019-03-26 21:56:40,153] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4152767e-21 1.0000000e+00 3.7108078e-21 3.7752258e-16 4.5694968e-27], sum to 1.0000
[2019-03-26 21:56:40,166] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1430
[2019-03-26 21:56:40,170] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 65.5, 1.0, 2.0, 0.2548724681904998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 416457.5175737196, 416457.5175737189, 161370.4445274106], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 581400.0000, 
sim time next is 582000.0000, 
raw observation next is [22.96666666666667, 66.0, 1.0, 2.0, 0.2559756984143901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 418568.5634198869, 418568.5634198862, 161487.9069930623], 
processed observation next is [1.0, 0.7391304347826086, 0.2875197472353872, 0.66, 1.0, 1.0, 0.10358517881251819, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11626904539441303, 0.11626904539441284, 0.24102672685531687], 
reward next is 0.7590, 
noisyNet noise sample is [array([-0.6820305], dtype=float32), 0.49257973]. 
=============================================
[2019-03-26 21:56:40,187] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[74.4084  ]
 [74.247   ]
 [73.98582 ]
 [73.682205]
 [73.56173 ]], R is [[74.66164398]
 [74.67417908]
 [74.68611908]
 [74.68562317]
 [74.61173248]].
[2019-03-26 21:56:56,083] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5684274e-22 1.0000000e+00 6.2879717e-22 6.6301707e-18 1.8111004e-27], sum to 1.0000
[2019-03-26 21:56:56,091] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7980
[2019-03-26 21:56:56,097] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.06666666666666, 61.66666666666666, 1.0, 2.0, 0.2895305742930316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 463387.3086991419, 463387.3086991413, 164486.7115358807], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 819600.0000, 
sim time next is 820200.0000, 
raw observation next is [25.03333333333333, 61.83333333333334, 1.0, 2.0, 0.2895031986759039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 463378.7550511046, 463378.7550511046, 164486.5213511981], 
processed observation next is [0.0, 0.4782608695652174, 0.38546603475513425, 0.6183333333333334, 1.0, 1.0, 0.14397975744084807, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12871632084752904, 0.12871632084752904, 0.24550227067343003], 
reward next is 0.7545, 
noisyNet noise sample is [array([0.27712092], dtype=float32), 1.2873912]. 
=============================================
[2019-03-26 21:56:58,082] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8738975e-24 1.0000000e+00 4.3485424e-23 5.0797647e-19 3.8696228e-30], sum to 1.0000
[2019-03-26 21:56:58,092] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5503
[2019-03-26 21:56:58,098] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 81.5, 1.0, 2.0, 0.2964162520959962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 473174.0456684512, 473174.0456684512, 165153.8038416617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 850200.0000, 
sim time next is 850800.0000, 
raw observation next is [22.13333333333333, 82.0, 1.0, 2.0, 0.2974824761847182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 474551.9814762044, 474551.9814762044, 165246.6110955798], 
processed observation next is [0.0, 0.8695652173913043, 0.24802527646129527, 0.82, 1.0, 1.0, 0.15359334480086528, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13181999485450122, 0.13181999485450122, 0.24663673297847732], 
reward next is 0.7534, 
noisyNet noise sample is [array([1.3844734], dtype=float32), -0.017498503]. 
=============================================
[2019-03-26 21:57:00,502] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.9908787e-22 1.0000000e+00 6.9301064e-22 6.8974960e-18 1.1988602e-27], sum to 1.0000
[2019-03-26 21:57:00,513] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6499
[2019-03-26 21:57:00,518] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 79.0, 1.0, 2.0, 0.292241266409421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 466670.2044195034, 466670.204419504, 164700.6656892739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 892800.0000, 
sim time next is 893400.0000, 
raw observation next is [22.5, 79.00000000000001, 1.0, 2.0, 0.2925385832152782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 466982.5633899804, 466982.5633899804, 164720.0440739929], 
processed observation next is [0.0, 0.34782608695652173, 0.2654028436018958, 0.7900000000000001, 1.0, 1.0, 0.14763684724732312, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.129717378719439, 0.129717378719439, 0.24585081205073567], 
reward next is 0.7541, 
noisyNet noise sample is [array([0.99845487], dtype=float32), -0.009408679]. 
=============================================
[2019-03-26 21:57:02,348] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.4208161e-23 1.0000000e+00 4.1748476e-21 3.1095635e-17 1.3258384e-27], sum to 1.0000
[2019-03-26 21:57:02,356] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7979
[2019-03-26 21:57:02,362] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.56666666666667, 96.83333333333334, 1.0, 2.0, 0.3545090253303371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 546747.7960604882, 546747.7960604876, 170392.7842107117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1048200.0000, 
sim time next is 1048800.0000, 
raw observation next is [21.43333333333333, 96.66666666666667, 1.0, 2.0, 0.3371600872445006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 522255.1675875294, 522255.1675875288, 168469.7412859084], 
processed observation next is [1.0, 0.13043478260869565, 0.21484992101105835, 0.9666666666666667, 1.0, 1.0, 0.2013976954753019, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14507087988542483, 0.14507087988542466, 0.25144737505359466], 
reward next is 0.7486, 
noisyNet noise sample is [array([1.322764], dtype=float32), -0.32292888]. 
=============================================
[2019-03-26 21:57:07,598] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3425284e-22 1.0000000e+00 3.1172991e-22 7.4547287e-18 2.0795749e-28], sum to 1.0000
[2019-03-26 21:57:07,609] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9420
[2019-03-26 21:57:07,612] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.1, 59.0, 1.0, 2.0, 0.3437258197622903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 531896.1454583206, 531896.14545832, 169226.5476227], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1530000.0000, 
sim time next is 1530600.0000, 
raw observation next is [26.9, 60.16666666666667, 1.0, 2.0, 0.3436552026726148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 531968.7533513719, 531968.7533513724, 169237.7290554589], 
processed observation next is [0.0, 0.7391304347826086, 0.4739336492890995, 0.6016666666666667, 1.0, 1.0, 0.2092231357501383, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14776909815315883, 0.147769098153159, 0.2525936254559088], 
reward next is 0.7474, 
noisyNet noise sample is [array([0.6561044], dtype=float32), 1.0382835]. 
=============================================
[2019-03-26 21:57:09,452] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0808380e-21 1.0000000e+00 1.7249364e-20 6.2733759e-16 3.3487184e-27], sum to 1.0000
[2019-03-26 21:57:09,460] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2148
[2019-03-26 21:57:09,465] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.73333333333333, 94.33333333333334, 1.0, 2.0, 0.8214807975876162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1233206.93885798, 1233206.93885798, 260891.7385488646], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1336800.0000, 
sim time next is 1337400.0000, 
raw observation next is [22.65, 94.0, 1.0, 2.0, 0.8230026852319834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1240633.399539506, 1240633.399539506, 261960.4021930824], 
processed observation next is [1.0, 0.4782608695652174, 0.2725118483412322, 0.94, 1.0, 1.0, 0.7867502231710644, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3446203887609739, 0.3446203887609739, 0.3909856749150484], 
reward next is 0.6090, 
noisyNet noise sample is [array([1.0318568], dtype=float32), -0.42578802]. 
=============================================
[2019-03-26 21:57:11,993] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.9313181e-22 1.0000000e+00 2.9916982e-21 3.1956416e-17 6.2663093e-27], sum to 1.0000
[2019-03-26 21:57:12,004] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0786
[2019-03-26 21:57:12,008] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.93333333333334, 71.0, 1.0, 2.0, 0.597826819227571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 928211.6839156456, 928211.6839156456, 211449.8592102245], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1084800.0000, 
sim time next is 1085400.0000, 
raw observation next is [25.1, 70.5, 1.0, 2.0, 0.6693726472986706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1036894.003653821, 1036894.003653821, 226848.2525376893], 
processed observation next is [1.0, 0.5652173913043478, 0.38862559241706174, 0.705, 1.0, 1.0, 0.6016537919261091, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2880261121260614, 0.2880261121260614, 0.33857948139953625], 
reward next is 0.6614, 
noisyNet noise sample is [array([-0.5093273], dtype=float32), -1.9613757]. 
=============================================
[2019-03-26 21:57:12,776] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.8301393e-21 1.0000000e+00 4.6601184e-20 5.8827543e-17 9.9599321e-27], sum to 1.0000
[2019-03-26 21:57:12,786] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5464
[2019-03-26 21:57:12,791] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.35, 92.0, 1.0, 2.0, 0.2849804203682356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 459130.1705108368, 459130.1705108368, 164214.1599275443], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1132200.0000, 
sim time next is 1132800.0000, 
raw observation next is [20.3, 92.33333333333334, 1.0, 2.0, 0.2818650904555028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 454208.1355815878, 454208.1355815872, 163881.7139531384], 
processed observation next is [1.0, 0.08695652173913043, 0.16113744075829392, 0.9233333333333335, 1.0, 1.0, 0.1347772174162684, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12616892655044104, 0.1261689265504409, 0.24459957306438565], 
reward next is 0.7554, 
noisyNet noise sample is [array([-0.2012465], dtype=float32), -1.5008935]. 
=============================================
[2019-03-26 21:57:15,545] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0612050e-20 1.0000000e+00 3.6930302e-20 1.3176934e-15 7.1433980e-26], sum to 1.0000
[2019-03-26 21:57:15,553] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7591
[2019-03-26 21:57:15,560] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.56666666666667, 98.33333333333334, 1.0, 2.0, 0.4781503930941028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 683549.6838074777, 683549.6838074777, 182215.226587118], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1665600.0000, 
sim time next is 1666200.0000, 
raw observation next is [23.58333333333333, 98.16666666666667, 1.0, 2.0, 0.4773386055273855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 682501.2686907761, 682501.2686907767, 182104.4983785113], 
processed observation next is [1.0, 0.2608695652173913, 0.31674565560821466, 0.9816666666666667, 1.0, 1.0, 0.3702874765390186, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1895836857474378, 0.18958368574743797, 0.2717977587738975], 
reward next is 0.7282, 
noisyNet noise sample is [array([-1.2019069], dtype=float32), 1.1146513]. 
=============================================
[2019-03-26 21:57:22,894] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.2181618e-23 1.0000000e+00 1.8887406e-22 7.4199213e-17 2.3641474e-28], sum to 1.0000
[2019-03-26 21:57:22,902] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4589
[2019-03-26 21:57:22,906] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 93.5, 1.0, 2.0, 0.467535477633353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 659008.1809202835, 659008.1809202841, 179403.0730438775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1290600.0000, 
sim time next is 1291200.0000, 
raw observation next is [24.46666666666667, 93.66666666666667, 1.0, 2.0, 0.4662428858995772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 657526.4807556029, 657526.4807556029, 179255.2230179445], 
processed observation next is [1.0, 0.9565217391304348, 0.3586097946287521, 0.9366666666666668, 1.0, 1.0, 0.3569191396380448, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18264624465433416, 0.18264624465433416, 0.2675451089820067], 
reward next is 0.7325, 
noisyNet noise sample is [array([1.5337907], dtype=float32), -0.8079019]. 
=============================================
[2019-03-26 21:57:30,356] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 21:57:30,361] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 21:57:30,361] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 21:57:30,362] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:57:30,363] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 21:57:30,362] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:57:30,365] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:57:30,365] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 21:57:30,366] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:57:30,366] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 21:57:30,369] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 21:57:30,400] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run62
[2019-03-26 21:57:30,422] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run62
[2019-03-26 21:57:30,446] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run62
[2019-03-26 21:57:30,447] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run62
[2019-03-26 21:57:30,488] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run62
[2019-03-26 21:58:04,967] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09260739], dtype=float32), 0.06764449]
[2019-03-26 21:58:04,968] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.830332985, 67.30345794499999, 1.0, 2.0, 0.6475291565055148, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005971984562885, 6.9112, 168.9123568015877, 1801706.054396823, 1734471.785457445, 373680.2237869828]
[2019-03-26 21:58:04,971] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:58:04,975] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.6425253e-18 1.0000000e+00 1.2723804e-17 3.4224256e-13 2.2487006e-22], sampled 0.7718596034166996
[2019-03-26 21:58:04,976] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1801706.054396823 W.
[2019-03-26 21:58:45,359] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09260739], dtype=float32), 0.06764449]
[2019-03-26 21:58:45,359] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.65273368833333, 83.17273285, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.017993908063464, 6.9112, 168.9122012750493, 1529569.748023872, 1453806.812830059, 311352.5432654117]
[2019-03-26 21:58:45,361] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:58:45,363] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.0204241e-16 1.0000000e+00 1.4541036e-15 3.1536790e-10 1.7803571e-20], sampled 0.21706005231125303
[2019-03-26 21:58:47,027] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09260739], dtype=float32), 0.06764449]
[2019-03-26 21:58:47,028] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [34.92902227166666, 55.62490953, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.125002167716886, 6.9112, 168.9114806710002, 2435494.830533845, 2283817.539510985, 475618.5867182605]
[2019-03-26 21:58:47,029] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 21:58:47,031] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.5057820e-12 9.9991071e-01 3.4126792e-11 8.9232250e-05 8.3558736e-16], sampled 0.09612882666124123
[2019-03-26 21:58:47,032] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2435494.830533845 W.
[2019-03-26 21:58:49,223] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09260739], dtype=float32), 0.06764449]
[2019-03-26 21:58:49,225] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.711531195, 80.02777791166666, 1.0, 2.0, 0.483814909194927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 681159.822655538, 681159.822655538, 181757.2443947399]
[2019-03-26 21:58:49,228] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 21:58:49,231] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.5567384e-22 1.0000000e+00 4.0248620e-22 4.7716724e-18 4.7818159e-28], sampled 0.7302355784943021
[2019-03-26 21:58:53,015] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09260739], dtype=float32), 0.06764449]
[2019-03-26 21:58:53,016] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.3, 84.66666666666667, 1.0, 2.0, 0.5377400009287416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 751426.7562687976, 751426.7562687976, 189719.4331469509]
[2019-03-26 21:58:53,019] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:58:53,023] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.7711122e-23 1.0000000e+00 9.9727644e-23 6.7900680e-18 7.2893090e-29], sampled 0.9255198101626666
[2019-03-26 21:58:55,561] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09260739], dtype=float32), 0.06764449]
[2019-03-26 21:58:55,562] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.16666666666667, 63.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.937785078680928, 6.9112, 168.9123770576083, 1472628.150558249, 1453767.845454361, 311352.2933329373]
[2019-03-26 21:58:55,563] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 21:58:55,566] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.1677930e-20 1.0000000e+00 7.0443774e-20 1.1520302e-14 1.9618125e-25], sampled 0.19168850458045417
[2019-03-26 21:59:05,654] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09260739], dtype=float32), 0.06764449]
[2019-03-26 21:59:05,655] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.7, 65.0, 1.0, 2.0, 0.6016473903849375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 840764.964616303, 840764.964616303, 201052.7677046941]
[2019-03-26 21:59:05,655] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 21:59:05,660] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.5429791e-23 1.0000000e+00 2.5009248e-22 6.2436461e-18 2.8303883e-28], sampled 0.2103832958801306
[2019-03-26 21:59:20,325] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.0887 2927493807.1716 1338.0000
[2019-03-26 21:59:20,738] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.7903 2779331027.2517 933.0000
[2019-03-26 21:59:20,812] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.1862 3007878685.4681 1766.0000
[2019-03-26 21:59:20,898] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5752 2842451949.6408 1131.0000
[2019-03-26 21:59:21,004] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.5759 3164359114.1062 1776.0000
[2019-03-26 21:59:22,021] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1525000, evaluation results [1525000.0, 7883.575942386175, 3164359114.1062307, 1776.0, 8252.088691121107, 2927493807.1715503, 1338.0, 8659.790305226421, 2779331027.2517376, 933.0, 7997.186154960317, 3007878685.468129, 1766.0, 8497.575228127671, 2842451949.640752, 1131.0]
[2019-03-26 21:59:24,855] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.2558644e-21 1.0000000e+00 1.8893695e-20 7.5668146e-17 9.5022387e-27], sum to 1.0000
[2019-03-26 21:59:24,863] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5535
[2019-03-26 21:59:24,870] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 87.0, 1.0, 2.0, 0.4274254435734332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 617571.7663213384, 617571.7663213384, 175626.4153832308], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1926000.0000, 
sim time next is 1926600.0000, 
raw observation next is [24.91666666666667, 86.33333333333333, 1.0, 2.0, 0.482797476369263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 696694.9731691432, 696694.9731691432, 183750.4049189779], 
processed observation next is [1.0, 0.30434782608695654, 0.37993680884676173, 0.8633333333333333, 1.0, 1.0, 0.37686442936055786, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1935263814358731, 0.1935263814358731, 0.27425433569996704], 
reward next is 0.7257, 
noisyNet noise sample is [array([0.9720897], dtype=float32), 0.6257131]. 
=============================================
[2019-03-26 21:59:29,227] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.7285620e-22 1.0000000e+00 4.7312616e-22 5.3030010e-17 2.7836296e-27], sum to 1.0000
[2019-03-26 21:59:29,237] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7803
[2019-03-26 21:59:29,242] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.13333333333333, 98.33333333333334, 1.0, 2.0, 0.4232027237499308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 616241.6862204515, 616241.6862204521, 175636.7641358162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1642800.0000, 
sim time next is 1643400.0000, 
raw observation next is [23.15, 98.5, 1.0, 2.0, 0.4246064280177466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 617380.0500797402, 617380.0500797395, 175720.4870394862], 
processed observation next is [1.0, 0.0, 0.2962085308056872, 0.985, 1.0, 1.0, 0.30675473255150193, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1714944583554834, 0.17149445835548321, 0.2622693836410242], 
reward next is 0.7377, 
noisyNet noise sample is [array([0.51188517], dtype=float32), 0.9002569]. 
=============================================
[2019-03-26 21:59:38,509] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2242877e-13 1.0000000e+00 3.0477273e-13 8.8231999e-09 5.9583879e-18], sum to 1.0000
[2019-03-26 21:59:38,518] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9913
[2019-03-26 21:59:38,527] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1974079.297417222 W.
[2019-03-26 21:59:38,532] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.13333333333333, 79.5, 1.0, 2.0, 0.7059504993446503, 1.0, 1.0, 0.7059504993446503, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1974079.297417222, 1974079.297417222, 376678.7232358592], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1695000.0000, 
sim time next is 1695600.0000, 
raw observation next is [28.2, 79.0, 1.0, 2.0, 0.5805050111567376, 1.0, 2.0, 0.5805050111567376, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1623025.093186015, 1623025.093186015, 327160.3704353867], 
processed observation next is [1.0, 0.6521739130434783, 0.5355450236966824, 0.79, 1.0, 1.0, 0.49458435079125007, 1.0, 1.0, 0.49458435079125007, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.45084030366278194, 0.45084030366278194, 0.4882990603513235], 
reward next is 0.5117, 
noisyNet noise sample is [array([-0.3181847], dtype=float32), -1.720641]. 
=============================================
[2019-03-26 21:59:42,135] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.0700404e-21 1.0000000e+00 5.6248193e-21 2.4902986e-16 1.4265583e-26], sum to 1.0000
[2019-03-26 21:59:42,143] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5400
[2019-03-26 21:59:42,150] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 86.0, 1.0, 2.0, 0.5131924413484565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 717112.9254612556, 717112.9254612562, 185688.8828023507], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2250000.0000, 
sim time next is 2250600.0000, 
raw observation next is [26.75, 86.0, 1.0, 2.0, 0.5111831138728875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 714304.2341105256, 714304.2341105263, 185366.8151638563], 
processed observation next is [1.0, 0.043478260869565216, 0.4668246445497631, 0.86, 1.0, 1.0, 0.41106399261793675, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19841784280847932, 0.19841784280847952, 0.27666688830426317], 
reward next is 0.7233, 
noisyNet noise sample is [array([0.00544886], dtype=float32), -0.54389656]. 
=============================================
[2019-03-26 21:59:47,466] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6305962e-21 1.0000000e+00 3.2843844e-21 4.0519105e-16 1.1558529e-26], sum to 1.0000
[2019-03-26 21:59:47,475] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7605
[2019-03-26 21:59:47,480] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.88333333333333, 96.33333333333333, 1.0, 2.0, 0.3623963527946852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 555663.2742153206, 555663.2742153206, 171050.950247655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1829400.0000, 
sim time next is 1830000.0000, 
raw observation next is [21.86666666666667, 96.66666666666666, 1.0, 2.0, 0.350525081400969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 537080.5314178695, 537080.5314178695, 169486.7710504025], 
processed observation next is [1.0, 0.17391304347826086, 0.23538704581358633, 0.9666666666666666, 1.0, 1.0, 0.2175000980734566, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14918903650496376, 0.14918903650496376, 0.25296532992597387], 
reward next is 0.7470, 
noisyNet noise sample is [array([0.40667623], dtype=float32), -0.72050124]. 
=============================================
[2019-03-26 21:59:47,497] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.084335]
 [70.20719 ]
 [70.23263 ]
 [70.37814 ]
 [70.36412 ]], R is [[70.05657959]
 [70.10071564]
 [70.14684296]
 [70.19259644]
 [70.23801422]].
[2019-03-26 21:59:50,748] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.3215752e-21 1.0000000e+00 1.5003782e-20 7.7005936e-16 7.1532144e-26], sum to 1.0000
[2019-03-26 21:59:50,760] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4598
[2019-03-26 21:59:50,764] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 80.5, 1.0, 2.0, 0.7381116248727769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1031557.89457807, 1031557.89457807, 229284.8295948375], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2352600.0000, 
sim time next is 2353200.0000, 
raw observation next is [27.63333333333333, 80.0, 1.0, 2.0, 0.7301873107500682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1020477.840927375, 1020477.840927375, 227494.3686723046], 
processed observation next is [1.0, 0.21739130434782608, 0.5086887835703, 0.8, 1.0, 1.0, 0.6749244707832146, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.28346606692427084, 0.28346606692427084, 0.3395438338392606], 
reward next is 0.6605, 
noisyNet noise sample is [array([-0.3595243], dtype=float32), -1.7889872]. 
=============================================
[2019-03-26 21:59:52,356] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.2916041e-09 7.8704727e-01 7.8433203e-08 2.1295263e-01 1.2378522e-11], sum to 1.0000
[2019-03-26 21:59:52,371] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6344
[2019-03-26 21:59:52,378] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1736877.006967963 W.
[2019-03-26 21:59:52,385] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.46666666666667, 63.66666666666667, 1.0, 2.0, 0.6211932854019859, 1.0, 2.0, 0.6211932854019859, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1736877.006967963, 1736877.006967963, 342218.8455789382], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2377200.0000, 
sim time next is 2377800.0000, 
raw observation next is [32.5, 63.5, 1.0, 2.0, 0.5953459050262085, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.915646741146617, 6.9112, 168.9128778224467, 1664563.331520532, 1661408.661775705, 363709.5616166595], 
processed observation next is [1.0, 0.5217391304347826, 0.7393364928909952, 0.635, 1.0, 1.0, 0.512464945814709, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.00044467411466166953, 0.0, 0.8294395587582762, 0.4623787032001478, 0.46150240604880693, 0.5428500919651634], 
reward next is 0.4349, 
noisyNet noise sample is [array([0.07867777], dtype=float32), -0.4270403]. 
=============================================
[2019-03-26 21:59:56,507] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.8797719e-22 1.0000000e+00 1.3763083e-22 2.2936256e-18 4.8173348e-28], sum to 1.0000
[2019-03-26 21:59:56,513] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4251
[2019-03-26 21:59:56,521] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333333, 95.33333333333333, 1.0, 2.0, 0.4835651054196176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 675699.8003626856, 675699.8003626862, 181061.2809112976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2011200.0000, 
sim time next is 2011800.0000, 
raw observation next is [24.91666666666667, 95.16666666666667, 1.0, 2.0, 0.4854643778384652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 678354.5571582321, 678354.5571582327, 181350.1802974536], 
processed observation next is [0.0, 0.2608695652173913, 0.37993680884676173, 0.9516666666666667, 1.0, 1.0, 0.3800775636608014, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18843182143284223, 0.1884318214328424, 0.27067191089172177], 
reward next is 0.7293, 
noisyNet noise sample is [array([-0.30615956], dtype=float32), 0.26418293]. 
=============================================
[2019-03-26 22:00:00,596] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1273030e-21 1.0000000e+00 5.3268945e-21 1.1107053e-16 2.2893330e-26], sum to 1.0000
[2019-03-26 22:00:00,603] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3217
[2019-03-26 22:00:00,608] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.46666666666667, 95.0, 1.0, 2.0, 0.5472357266830534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 764700.6633828653, 764700.6633828653, 191327.8186946378], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2510400.0000, 
sim time next is 2511000.0000, 
raw observation next is [26.45, 95.0, 1.0, 2.0, 0.5464744912966144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 763636.5397815894, 763636.53978159, 191197.9855881855], 
processed observation next is [1.0, 0.043478260869565216, 0.45260663507109006, 0.95, 1.0, 1.0, 0.4535837244537523, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2121212610504415, 0.21212126105044166, 0.2853701277435604], 
reward next is 0.7146, 
noisyNet noise sample is [array([1.470609], dtype=float32), 1.589302]. 
=============================================
[2019-03-26 22:00:00,619] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[70.45428 ]
 [70.51267 ]
 [70.696556]
 [70.8569  ]
 [71.154854]], R is [[70.44923401]
 [70.45918274]
 [70.46894836]
 [70.47845459]
 [70.48763275]].
[2019-03-26 22:00:02,690] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4395265e-22 1.0000000e+00 3.1109096e-21 2.6850924e-18 1.2911790e-27], sum to 1.0000
[2019-03-26 22:00:02,701] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3759
[2019-03-26 22:00:02,706] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 94.0, 1.0, 2.0, 0.4797412250532267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 670354.8935108938, 670354.8935108938, 180482.9102815486], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2096400.0000, 
sim time next is 2097000.0000, 
raw observation next is [25.05, 93.5, 1.0, 2.0, 0.4820010316194018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 673513.5810254433, 673513.5810254439, 180824.2370530177], 
processed observation next is [0.0, 0.2608695652173913, 0.3862559241706162, 0.935, 1.0, 1.0, 0.3759048573727732, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18708710584040092, 0.18708710584040106, 0.2698869209746533], 
reward next is 0.7301, 
noisyNet noise sample is [array([0.8091673], dtype=float32), -1.0990458]. 
=============================================
[2019-03-26 22:00:02,719] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[74.12126 ]
 [74.1     ]
 [74.069534]
 [74.04334 ]
 [74.03623 ]], R is [[74.12511444]
 [74.11448669]
 [74.10430145]
 [74.09425354]
 [74.08421326]].
[2019-03-26 22:00:07,944] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.2234891e-20 1.0000000e+00 3.6700404e-20 8.7503824e-16 1.6849740e-25], sum to 1.0000
[2019-03-26 22:00:07,954] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2574
[2019-03-26 22:00:07,963] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.86666666666667, 83.66666666666667, 1.0, 2.0, 0.7490072873415591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1046792.78035397, 1046792.780353971, 231779.3596278974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2187600.0000, 
sim time next is 2188200.0000, 
raw observation next is [28.08333333333334, 82.83333333333334, 1.0, 2.0, 0.7613905261090055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1064107.938572987, 1064107.938572987, 234654.9142125692], 
processed observation next is [1.0, 0.30434782608695654, 0.53001579778831, 0.8283333333333335, 1.0, 1.0, 0.7125187061554282, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.29558553849249636, 0.29558553849249636, 0.35023121524264056], 
reward next is 0.6498, 
noisyNet noise sample is [array([1.2385796], dtype=float32), -0.52681375]. 
=============================================
[2019-03-26 22:00:08,318] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.3082523e-21 1.0000000e+00 4.0671870e-20 1.5102761e-15 1.7319928e-26], sum to 1.0000
[2019-03-26 22:00:08,328] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3384
[2019-03-26 22:00:08,332] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.15, 94.5, 1.0, 2.0, 0.8989701569902202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1256500.92769338, 1256500.92769338, 269651.8516837089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2169000.0000, 
sim time next is 2169600.0000, 
raw observation next is [25.1, 94.66666666666666, 1.0, 2.0, 0.8384846329673163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1171912.958737343, 1171912.958737343, 253573.8587463729], 
processed observation next is [1.0, 0.08695652173913043, 0.38862559241706174, 0.9466666666666665, 1.0, 1.0, 0.8054031722497788, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.32553137742703975, 0.32553137742703975, 0.3784684458901088], 
reward next is 0.6215, 
noisyNet noise sample is [array([-0.21045707], dtype=float32), -1.0967739]. 
=============================================
[2019-03-26 22:00:09,041] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4572007e-09 6.8990856e-01 3.9454260e-08 3.1009135e-01 1.1992686e-11], sum to 1.0000
[2019-03-26 22:00:09,049] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2513
[2019-03-26 22:00:09,060] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1726296.808552725 W.
[2019-03-26 22:00:09,067] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.5, 67.0, 1.0, 2.0, 0.6174123276861581, 1.0, 1.0, 0.6174123276861581, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1726296.808552725, 1726296.808552725, 340777.5724200695], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2206800.0000, 
sim time next is 2207400.0000, 
raw observation next is [31.6, 66.66666666666667, 1.0, 2.0, 0.4522078646940165, 1.0, 2.0, 0.4522078646940165, 1.0, 1.0, 0.7853355135474336, 6.9112, 6.9112, 170.5573041426782, 1896723.6099005, 1896723.6099005, 383670.6441229486], 
processed observation next is [1.0, 0.5652173913043478, 0.6966824644549764, 0.6666666666666667, 1.0, 1.0, 0.34000947553495964, 1.0, 1.0, 0.34000947553495964, 1.0, 0.5, 0.7382140409115044, 0.0, 0.0, 0.8375144448122397, 0.5268676694168055, 0.5268676694168055, 0.5726427524223113], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9558767], dtype=float32), 0.33638692]. 
=============================================
[2019-03-26 22:00:15,122] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2988004e-21 1.0000000e+00 5.9841383e-22 7.4822010e-16 5.7819626e-27], sum to 1.0000
[2019-03-26 22:00:15,130] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7075
[2019-03-26 22:00:15,135] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.8, 78.0, 1.0, 2.0, 0.5741745914193467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 802358.9288674291, 802358.9288674291, 196033.3951373182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2412000.0000, 
sim time next is 2412600.0000, 
raw observation next is [29.71666666666667, 78.33333333333333, 1.0, 2.0, 0.5741466427085284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 802319.8582302403, 802319.8582302403, 196028.3315380805], 
processed observation next is [1.0, 0.9565217391304348, 0.6074249605055293, 0.7833333333333333, 1.0, 1.0, 0.4869236659138897, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22286662728617787, 0.22286662728617787, 0.29257959931056793], 
reward next is 0.7074, 
noisyNet noise sample is [array([-0.45215845], dtype=float32), 0.6030475]. 
=============================================
[2019-03-26 22:00:17,753] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4713003e-20 1.0000000e+00 7.0050126e-20 5.8986023e-15 2.7901172e-25], sum to 1.0000
[2019-03-26 22:00:17,764] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4275
[2019-03-26 22:00:17,767] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666667, 82.0, 1.0, 2.0, 0.6655486001863871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 930102.0482365907, 930102.0482365907, 213582.6950682274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2349600.0000, 
sim time next is 2350200.0000, 
raw observation next is [27.13333333333333, 82.0, 1.0, 2.0, 0.6682611215593884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 933894.4548958407, 933894.4548958407, 214141.528037051], 
processed observation next is [1.0, 0.17391304347826086, 0.484992101105845, 0.82, 1.0, 1.0, 0.6003146042884198, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2594151263599558, 0.2594151263599558, 0.31961422095082237], 
reward next is 0.6804, 
noisyNet noise sample is [array([0.40406963], dtype=float32), -1.1298914]. 
=============================================
[2019-03-26 22:00:17,775] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-26 22:00:17,781] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 22:00:17,781] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:00:17,782] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 22:00:17,783] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 22:00:17,784] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:00:17,785] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:00:17,785] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 22:00:17,786] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 22:00:17,788] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:00:17,788] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:00:17,819] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run63
[2019-03-26 22:00:17,844] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run63
[2019-03-26 22:00:17,868] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run63
[2019-03-26 22:00:17,869] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run63
[2019-03-26 22:00:17,908] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run63
[2019-03-26 22:00:24,602] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09019256], dtype=float32), 0.06526652]
[2019-03-26 22:00:24,603] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.53333333333333, 72.66666666666667, 1.0, 2.0, 0.5027148553256369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 815320.8419876557, 815320.8419876557, 196029.2655666828]
[2019-03-26 22:00:24,604] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 22:00:24,607] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.1817275e-21 1.0000000e+00 1.3159117e-20 1.0994373e-16 3.0034113e-26], sampled 0.8669791791427643
[2019-03-26 22:00:46,744] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09019256], dtype=float32), 0.06526652]
[2019-03-26 22:00:46,745] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.26666666666667, 95.33333333333334, 1.0, 2.0, 0.4635317561565127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 653402.7227129347, 653402.7227129353, 178816.2047037553]
[2019-03-26 22:00:46,746] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 22:00:46,749] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1949145e-21 1.0000000e+00 4.4357019e-21 1.1767781e-16 8.8323625e-27], sampled 0.5966301580502658
[2019-03-26 22:00:58,048] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09019256], dtype=float32), 0.06526652]
[2019-03-26 22:00:58,050] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.28944515666667, 97.44649388666667, 1.0, 2.0, 0.3595129956970979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 557575.7196026894, 557575.7196026887, 171377.8840038526]
[2019-03-26 22:00:58,051] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:00:58,054] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.8822224e-22 1.0000000e+00 2.5354982e-21 3.6657505e-17 4.7670838e-27], sampled 0.5555133877656847
[2019-03-26 22:01:04,246] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09019256], dtype=float32), 0.06526652]
[2019-03-26 22:01:04,247] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.31142186666667, 95.22585998, 1.0, 2.0, 0.5043802498146042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 704795.0650524873, 704795.0650524867, 184285.286145757]
[2019-03-26 22:01:04,247] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:01:04,250] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.4993239e-22 1.0000000e+00 4.9681834e-22 2.1848902e-17 5.9930520e-28], sampled 0.9576627950888738
[2019-03-26 22:01:13,788] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09019256], dtype=float32), 0.06526652]
[2019-03-26 22:01:13,789] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 63.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.172171991241453, 6.9112, 168.911640615452, 2485991.760209801, 2300850.689989645, 476334.3314687381]
[2019-03-26 22:01:13,791] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 22:01:13,796] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.9287102e-12 9.9999940e-01 8.0367848e-12 5.7456839e-07 2.6592343e-15], sampled 0.8341550770171161
[2019-03-26 22:01:13,797] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2485991.760209801 W.
[2019-03-26 22:01:32,787] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09019256], dtype=float32), 0.06526652]
[2019-03-26 22:01:32,788] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 84.0, 1.0, 2.0, 0.5156883475053693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 720601.7797672314, 720601.7797672321, 186090.2565777657]
[2019-03-26 22:01:32,791] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 22:01:32,796] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.3803103e-23 1.0000000e+00 3.2118266e-22 2.3125333e-17 4.3058449e-28], sampled 0.11830107355021369
[2019-03-26 22:01:45,889] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09019256], dtype=float32), 0.06526652]
[2019-03-26 22:01:45,891] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.25, 88.0, 1.0, 2.0, 0.5482636191396113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 766137.5460209971, 766137.5460209965, 191502.8268794776]
[2019-03-26 22:01:45,892] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:01:45,895] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.4332978e-22 1.0000000e+00 5.0176087e-22 4.1853645e-17 6.3957018e-28], sampled 0.5858595712969676
[2019-03-26 22:02:12,027] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.9499 2779472094.2563 933.0000
[2019-03-26 22:02:12,083] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7886.7369 3164631936.3948 1770.0000
[2019-03-26 22:02:12,256] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.1369 3007626102.8964 1767.0000
[2019-03-26 22:02:12,287] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.4991 2842533404.6502 1128.0000
[2019-03-26 22:02:12,292] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.9384 2927343210.6248 1336.0000
[2019-03-26 22:02:13,308] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1550000, evaluation results [1550000.0, 7886.736892921741, 3164631936.3947973, 1770.0, 8252.9384417281, 2927343210.624767, 1336.0, 8658.949866745435, 2779472094.2562866, 933.0, 7998.136919159496, 3007626102.896424, 1767.0, 8496.499145911639, 2842533404.650237, 1128.0]
[2019-03-26 22:02:13,541] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.9718042e-21 1.0000000e+00 4.1478459e-21 4.3658609e-16 5.3452387e-27], sum to 1.0000
[2019-03-26 22:02:13,549] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1296
[2019-03-26 22:02:13,556] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.352172829773883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 542171.901748241, 542171.9017482405, 169985.6101424381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2851200.0000, 
sim time next is 2851800.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.3512009365583582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 540994.8831060061, 540994.8831060055, 169897.9269692278], 
processed observation next is [1.0, 0.0, 0.2417061611374408, 0.9400000000000002, 1.0, 1.0, 0.2183143813956123, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15027635641833503, 0.15027635641833487, 0.2535789954764594], 
reward next is 0.7464, 
noisyNet noise sample is [array([1.2506542], dtype=float32), -2.4546402]. 
=============================================
[2019-03-26 22:02:15,199] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.9527464e-22 1.0000000e+00 1.8786538e-20 9.0767013e-16 3.9329083e-26], sum to 1.0000
[2019-03-26 22:02:15,209] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4030
[2019-03-26 22:02:15,220] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.4088732034614336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 602438.2678458676, 602438.267845867, 174540.3591821208], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2835600.0000, 
sim time next is 2836200.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.4098329272822472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 603852.4830929274, 603852.4830929274, 174672.3354776844], 
processed observation next is [1.0, 0.8260869565217391, 0.3364928909952607, 0.89, 1.0, 1.0, 0.28895533407499663, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1677368008591465, 0.1677368008591465, 0.2607049783249021], 
reward next is 0.7393, 
noisyNet noise sample is [array([-1.3853227], dtype=float32), 0.7644868]. 
=============================================
[2019-03-26 22:02:16,203] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.3307015e-21 1.0000000e+00 8.6688940e-21 1.9831239e-15 9.2934925e-27], sum to 1.0000
[2019-03-26 22:02:16,212] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2015
[2019-03-26 22:02:16,218] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.1, 77.0, 1.0, 2.0, 0.5793113965352257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 809539.9016293401, 809539.9016293401, 196955.0082168444], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2410200.0000, 
sim time next is 2410800.0000, 
raw observation next is [30.0, 77.33333333333334, 1.0, 2.0, 0.5780193806038082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 807733.7294120664, 807733.729412067, 196722.4401446359], 
processed observation next is [1.0, 0.9130434782608695, 0.6208530805687204, 0.7733333333333334, 1.0, 1.0, 0.4915896151853111, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22437048039224067, 0.22437048039224083, 0.2936155823054267], 
reward next is 0.7064, 
noisyNet noise sample is [array([-1.9886549], dtype=float32), -0.2152622]. 
=============================================
[2019-03-26 22:02:17,128] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5734216e-19 1.0000000e+00 5.9742711e-19 1.0260670e-13 5.9901616e-24], sum to 1.0000
[2019-03-26 22:02:17,141] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7108
[2019-03-26 22:02:17,145] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 96.0, 1.0, 2.0, 0.691170751088145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 965925.2059823722, 965925.2059823722, 218951.8724616951], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2517600.0000, 
sim time next is 2518200.0000, 
raw observation next is [26.3, 96.0, 1.0, 2.0, 0.6858248433928761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 958450.8197995113, 958450.8197995106, 217816.1786139738], 
processed observation next is [1.0, 0.13043478260869565, 0.4454976303317536, 0.96, 1.0, 1.0, 0.621475714931176, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2662363388331976, 0.2662363388331974, 0.3250987740507072], 
reward next is 0.6749, 
noisyNet noise sample is [array([0.72171456], dtype=float32), -1.9826329]. 
=============================================
[2019-03-26 22:02:20,747] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2683304e-15 1.0000000e+00 3.7396949e-15 9.0488596e-11 4.2096007e-20], sum to 1.0000
[2019-03-26 22:02:20,757] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1132
[2019-03-26 22:02:20,764] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1874762.636721917 W.
[2019-03-26 22:02:20,769] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 87.0, 1.0, 2.0, 0.6704649152848614, 1.0, 2.0, 0.6704649152848614, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1874762.636721917, 1874762.636721917, 361733.6070374351], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2451600.0000, 
sim time next is 2452200.0000, 
raw observation next is [26.9, 87.16666666666667, 1.0, 2.0, 0.8047130608737253, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.982118917927154, 6.9112, 168.9125391757458, 2021669.547940025, 1971357.351028803, 409862.0981722372], 
processed observation next is [1.0, 0.391304347826087, 0.4739336492890995, 0.8716666666666667, 1.0, 1.0, 0.764714531173163, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.007091891792715366, 0.0, 0.8294378958479417, 0.5615748744277848, 0.5475992641746675, 0.6117344748839362], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4476086], dtype=float32), 0.8541733]. 
=============================================
[2019-03-26 22:02:26,042] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.6115874e-10 9.9995482e-01 1.6452906e-09 4.5141951e-05 2.5742304e-13], sum to 1.0000
[2019-03-26 22:02:26,049] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2847
[2019-03-26 22:02:26,061] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2006885.467406774 W.
[2019-03-26 22:02:26,065] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 82.66666666666667, 1.0, 2.0, 0.4784475570983374, 1.0, 2.0, 0.4784475570983374, 1.0, 1.0, 0.8257692863811685, 6.9112, 6.9112, 170.5573041426782, 2006885.467406774, 2006885.467406774, 399678.988606001], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2542800.0000, 
sim time next is 2543400.0000, 
raw observation next is [28.1, 82.0, 1.0, 2.0, 0.8339316624180726, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.990350046795347, 6.9112, 168.9124852997497, 2062563.149469076, 2006411.538782743, 416976.3908025181], 
processed observation next is [1.0, 0.43478260869565216, 0.5308056872037916, 0.82, 1.0, 1.0, 0.7999176655639428, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007915004679534743, 0.0, 0.8294376312921363, 0.5729342081858544, 0.5573365385507619, 0.6223528220933107], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2968701], dtype=float32), -0.9793875]. 
=============================================
[2019-03-26 22:02:26,114] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.9257224e-09 2.5835136e-01 9.1637133e-08 7.4164855e-01 5.9351638e-12], sum to 1.0000
[2019-03-26 22:02:26,122] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8243
[2019-03-26 22:02:26,126] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 70.0, 1.0, 2.0, 0.76466177005656, 1.0, 2.0, 0.76466177005656, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2138419.974577714, 2138419.974577715, 403030.926999445], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2559600.0000, 
sim time next is 2560200.0000, 
raw observation next is [29.93333333333333, 70.5, 1.0, 2.0, 0.8479503697612004, 1.0, 2.0, 0.8479503697612004, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2371573.9965434, 2371573.9965434, 443885.4692351456], 
processed observation next is [1.0, 0.6521739130434783, 0.6176935229067929, 0.705, 1.0, 1.0, 0.8168076744110848, 1.0, 1.0, 0.8168076744110848, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6587705545953889, 0.6587705545953889, 0.662515625724098], 
reward next is 0.3375, 
noisyNet noise sample is [array([2.1359606], dtype=float32), -0.27971676]. 
=============================================
[2019-03-26 22:02:34,711] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.4901876e-17 1.0000000e+00 2.0209266e-15 4.1960263e-10 1.2477161e-20], sum to 1.0000
[2019-03-26 22:02:34,717] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1457
[2019-03-26 22:02:34,721] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1728910.946540501 W.
[2019-03-26 22:02:34,730] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.6183416697000481, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.92847260025738, 6.9112, 168.9122252322503, 1728910.946540501, 1716657.222491412, 369121.608312563], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3171000.0000, 
sim time next is 3171600.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5919099587813285, 0.0, 2.0, 0.0, 1.0, 2.0, 1.000487008243488, 6.911200000000001, 6.9112, 168.9129422920402, 1654949.072635481, 1654949.07263548, 356420.3998950304], 
processed observation next is [1.0, 0.7391304347826086, 0.4786729857819906, 0.84, 1.0, 1.0, 0.5083252515437692, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0005939124920586, 8.881784197001253e-17, 0.0, 0.8294398753334947, 0.459708075732078, 0.4597080757320778, 0.5319707461119857], 
reward next is 0.4680, 
noisyNet noise sample is [array([-0.32080343], dtype=float32), -1.0259279]. 
=============================================
[2019-03-26 22:02:39,255] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.9121915e-22 1.0000000e+00 1.4126230e-21 3.1414090e-17 2.6344823e-27], sum to 1.0000
[2019-03-26 22:02:39,268] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1997
[2019-03-26 22:02:39,272] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3051706029095784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 485966.2386615312, 485966.2386615312, 166051.3320179218], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3016200.0000, 
sim time next is 3016800.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3058261297994068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 487009.8538300132, 487009.8538300132, 166126.951115905], 
processed observation next is [1.0, 0.9565217391304348, 0.1469194312796209, 1.0, 1.0, 1.0, 0.16364593951735762, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13528051495278146, 0.13528051495278146, 0.24795067330732087], 
reward next is 0.7520, 
noisyNet noise sample is [array([1.3040422], dtype=float32), -0.14535455]. 
=============================================
[2019-03-26 22:02:40,240] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.7597560e-08 9.6932822e-01 7.9546879e-08 3.0671688e-02 9.3357697e-11], sum to 1.0000
[2019-03-26 22:02:40,249] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0672
[2019-03-26 22:02:40,258] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2249483.436430078 W.
[2019-03-26 22:02:40,268] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.16666666666667, 70.16666666666667, 1.0, 2.0, 0.5362242980959033, 1.0, 1.0, 0.5362242980959033, 1.0, 2.0, 0.9312442737074106, 6.9112, 6.9112, 170.5573041426782, 2249483.436430078, 2249483.436430078, 441100.1103733872], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3406200.0000, 
sim time next is 3406800.0000, 
raw observation next is [31.33333333333334, 70.33333333333334, 1.0, 2.0, 0.5696178781874615, 1.0, 2.0, 0.5696178781874615, 1.0, 2.0, 0.9892378789007573, 6.9112, 6.9112, 170.5573041426782, 2389704.846068078, 2389704.846068078, 466626.3453260587], 
processed observation next is [1.0, 0.43478260869565216, 0.6840442338072673, 0.7033333333333335, 1.0, 1.0, 0.4814673231174234, 1.0, 1.0, 0.4814673231174234, 1.0, 1.0, 0.9868754620740942, 0.0, 0.0, 0.8375144448122397, 0.6638069016855773, 0.6638069016855773, 0.6964572318299384], 
reward next is 0.3035, 
noisyNet noise sample is [array([0.0719911], dtype=float32), 0.58920395]. 
=============================================
[2019-03-26 22:02:44,658] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.1264801e-21 1.0000000e+00 3.4563487e-20 3.9462132e-16 5.2592204e-26], sum to 1.0000
[2019-03-26 22:02:44,666] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4331
[2019-03-26 22:02:44,671] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.350244189542749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 539528.9942654476, 539528.9942654483, 169777.4929953436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2866800.0000, 
sim time next is 2867400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3471312974556843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 534742.613052091, 534742.613052091, 169385.8744875454], 
processed observation next is [1.0, 0.17391304347826086, 0.2417061611374408, 0.94, 1.0, 1.0, 0.21341120175383646, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14853961473669194, 0.14853961473669194, 0.25281473804111254], 
reward next is 0.7472, 
noisyNet noise sample is [array([-0.63916266], dtype=float32), -0.35699505]. 
=============================================
[2019-03-26 22:02:48,639] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.4739558e-21 1.0000000e+00 2.1843119e-20 1.2603531e-15 1.8886720e-26], sum to 1.0000
[2019-03-26 22:02:48,647] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1615
[2019-03-26 22:02:48,657] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.3506173231261482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 541231.9532297719, 541231.9532297712, 169950.2820241835], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2913600.0000, 
sim time next is 2914200.0000, 
raw observation next is [21.5, 97.0, 1.0, 2.0, 0.34609121974117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 535014.3067448857, 535014.3067448852, 169463.7440266319], 
processed observation next is [1.0, 0.7391304347826086, 0.21800947867298584, 0.97, 1.0, 1.0, 0.21215809607369882, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14861508520691272, 0.14861508520691255, 0.25293096123377895], 
reward next is 0.7471, 
noisyNet noise sample is [array([-1.4803507], dtype=float32), -1.7314641]. 
=============================================
[2019-03-26 22:02:52,626] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.61600793e-21 1.00000000e+00 1.32847565e-20 4.15354067e-16
 8.39248009e-27], sum to 1.0000
[2019-03-26 22:02:52,639] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4627
[2019-03-26 22:02:52,645] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 95.0, 1.0, 2.0, 0.5252021543128828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 831588.4355212437, 831588.4355212437, 198793.9828026842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2987400.0000, 
sim time next is 2988000.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4980774811396024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 787742.9821215227, 787742.9821215227, 193798.0889225037], 
processed observation next is [1.0, 0.6086956521739131, 0.19431279620853087, 0.94, 1.0, 1.0, 0.3952740736621715, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2188174950337563, 0.2188174950337563, 0.28925087898881147], 
reward next is 0.7107, 
noisyNet noise sample is [array([-0.52596056], dtype=float32), 2.2473745]. 
=============================================
[2019-03-26 22:02:52,672] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[71.41874 ]
 [71.44466 ]
 [71.369934]
 [71.38615 ]
 [71.29977 ]], R is [[71.48405457]
 [71.47251129]
 [71.46514893]
 [71.46435547]
 [71.46718597]].
[2019-03-26 22:02:52,958] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.3559247e-22 1.0000000e+00 1.8501843e-20 7.4540540e-16 3.2587779e-27], sum to 1.0000
[2019-03-26 22:02:52,969] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6694
[2019-03-26 22:02:52,974] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 97.0, 1.0, 2.0, 0.3120817245335519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 494987.5331758604, 494987.5331758604, 166680.0862831681], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3000600.0000, 
sim time next is 3001200.0000, 
raw observation next is [20.33333333333333, 98.0, 1.0, 2.0, 0.3118763279392696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 495249.3745411828, 495249.3745411834, 166709.224319104], 
processed observation next is [1.0, 0.7391304347826086, 0.16271721958925733, 0.98, 1.0, 1.0, 0.1709353348665899, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13756927070588412, 0.1375692707058843, 0.24881973778970745], 
reward next is 0.7512, 
noisyNet noise sample is [array([-0.3742181], dtype=float32), -0.64078575]. 
=============================================
[2019-03-26 22:03:00,338] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.9553987e-20 1.0000000e+00 1.5311323e-20 2.2109245e-16 1.6831551e-26], sum to 1.0000
[2019-03-26 22:03:00,345] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9976
[2019-03-26 22:03:00,349] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3438449554861333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 529919.3263179462, 529919.3263179462, 169001.789415034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3132000.0000, 
sim time next is 3132600.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.3795182821487804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 584652.979167145, 584652.9791671443, 173632.1348740715], 
processed observation next is [1.0, 0.2608695652173913, 0.2417061611374408, 0.9400000000000002, 1.0, 1.0, 0.25243166523949445, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16240360532420695, 0.16240360532420675, 0.25915244011055444], 
reward next is 0.7408, 
noisyNet noise sample is [array([-1.083071], dtype=float32), -1.0960914]. 
=============================================
[2019-03-26 22:03:00,378] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.5818512e-21 1.0000000e+00 3.6151408e-20 5.8175933e-16 3.9333434e-26], sum to 1.0000
[2019-03-26 22:03:00,387] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5911
[2019-03-26 22:03:00,393] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.7332911583064474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1073819.927410601, 1073819.927410601, 234747.6309682543], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3150000.0000, 
sim time next is 3150600.0000, 
raw observation next is [25.16666666666667, 82.33333333333334, 1.0, 2.0, 0.7645639183483103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1117259.567119488, 1117259.567119488, 242017.6803069109], 
processed observation next is [1.0, 0.4782608695652174, 0.39178515007898923, 0.8233333333333335, 1.0, 1.0, 0.716342070299169, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.31034987975541334, 0.31034987975541334, 0.3612204183685237], 
reward next is 0.6388, 
noisyNet noise sample is [array([0.25562632], dtype=float32), 0.9957124]. 
=============================================
[2019-03-26 22:03:02,722] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0464768e-19 1.0000000e+00 7.1579351e-19 9.0223272e-13 3.6919523e-24], sum to 1.0000
[2019-03-26 22:03:02,734] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7243
[2019-03-26 22:03:02,737] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.504063230437664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 704351.9315865864, 704351.9315865864, 184235.3274688482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3176400.0000, 
sim time next is 3177000.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.5018772838525735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 701296.3944119347, 701296.394411934, 183890.9359768336], 
processed observation next is [1.0, 0.782608695652174, 0.4549763033175356, 0.865, 1.0, 1.0, 0.399852149219968, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19480455400331517, 0.19480455400331498, 0.27446408354751284], 
reward next is 0.7255, 
noisyNet noise sample is [array([0.19810896], dtype=float32), 1.6029804]. 
=============================================
[2019-03-26 22:03:02,758] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[64.52744 ]
 [63.25889 ]
 [61.84736 ]
 [60.220554]
 [58.385525]], R is [[66.2166214 ]
 [66.27947998]
 [66.34213257]
 [66.40528107]
 [66.46899414]].
[2019-03-26 22:03:06,481] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0695915e-21 1.0000000e+00 1.4092806e-21 3.9245634e-17 4.3628043e-28], sum to 1.0000
[2019-03-26 22:03:06,493] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5225
[2019-03-26 22:03:06,497] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333333, 69.5, 1.0, 2.0, 0.5342622896260973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 746565.3666367391, 746565.3666367391, 189139.0601715926], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3237000.0000, 
sim time next is 3237600.0000, 
raw observation next is [30.66666666666667, 69.0, 1.0, 2.0, 0.5398229483269797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 754338.4574006329, 754338.4574006336, 190071.577557585], 
processed observation next is [0.0, 0.4782608695652174, 0.6524486571879939, 0.69, 1.0, 1.0, 0.44556981726142136, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2095384603890647, 0.2095384603890649, 0.2836889217277388], 
reward next is 0.7163, 
noisyNet noise sample is [array([-1.157308], dtype=float32), -0.20144399]. 
=============================================
[2019-03-26 22:03:09,345] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 22:03:09,346] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 22:03:09,347] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 22:03:09,348] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:03:09,348] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:03:09,349] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 22:03:09,348] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 22:03:09,351] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 22:03:09,352] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:03:09,354] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:03:09,353] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:03:09,378] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run64
[2019-03-26 22:03:09,403] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run64
[2019-03-26 22:03:09,404] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run64
[2019-03-26 22:03:09,405] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run64
[2019-03-26 22:03:09,423] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run64
[2019-03-26 22:04:32,743] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09143677], dtype=float32), 0.06645192]
[2019-03-26 22:04:32,744] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.26666666666667, 88.33333333333333, 1.0, 2.0, 0.5103670622577988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 713163.5375938589, 713163.5375938582, 185236.0695604134]
[2019-03-26 22:04:32,745] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 22:04:32,748] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.4834404e-22 1.0000000e+00 9.8500429e-22 4.0907039e-17 1.7640584e-27], sampled 0.051598922648450896
[2019-03-26 22:05:03,286] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.1919 2927472788.5469 1338.0000
[2019-03-26 22:05:03,791] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.2406 3164431564.8027 1768.0000
[2019-03-26 22:05:03,842] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5489 3007680329.7847 1767.0000
[2019-03-26 22:05:03,935] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.7906 2779397886.1708 933.0000
[2019-03-26 22:05:04,023] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.2603 2842652844.3644 1130.0000
[2019-03-26 22:05:05,041] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1575000, evaluation results [1575000.0, 7883.240621651382, 3164431564.8026543, 1768.0, 8254.191905559404, 2927472788.546885, 1338.0, 8659.790560713385, 2779397886.170806, 933.0, 7997.54889818731, 3007680329.784734, 1767.0, 8496.260335321147, 2842652844.3644032, 1130.0]
[2019-03-26 22:05:08,099] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6948591e-22 1.0000000e+00 1.2170798e-20 3.1501738e-14 5.5720288e-28], sum to 1.0000
[2019-03-26 22:05:08,109] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3332
[2019-03-26 22:05:08,119] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333333, 72.66666666666667, 1.0, 2.0, 0.5276683472450144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 737347.9509567774, 737347.9509567774, 188044.7479910673], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3613800.0000, 
sim time next is 3614400.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.525114077381621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733777.4579177726, 733777.457917772, 187624.4689086815], 
processed observation next is [1.0, 0.8695652173913043, 0.5734597156398105, 0.74, 1.0, 1.0, 0.42784828600195296, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2038270716438257, 0.20382707164382555, 0.28003652075922614], 
reward next is 0.7200, 
noisyNet noise sample is [array([0.07816402], dtype=float32), 0.16176967]. 
=============================================
[2019-03-26 22:05:09,780] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4135610e-21 1.0000000e+00 7.4272127e-21 8.0629829e-16 1.0024923e-26], sum to 1.0000
[2019-03-26 22:05:09,792] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7433
[2019-03-26 22:05:09,796] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.63333333333333, 91.16666666666667, 1.0, 2.0, 0.5365081392880334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 749704.770820098, 749704.7708200986, 189513.6730314307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3373800.0000, 
sim time next is 3374400.0000, 
raw observation next is [26.56666666666667, 91.33333333333334, 1.0, 2.0, 0.5361456551267951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 749198.064729427, 749198.064729427, 189452.8833895708], 
processed observation next is [1.0, 0.043478260869565216, 0.45813586097946307, 0.9133333333333334, 1.0, 1.0, 0.44113934352625916, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20811057353595194, 0.20811057353595194, 0.2827654975963743], 
reward next is 0.7172, 
noisyNet noise sample is [array([0.71740586], dtype=float32), 0.65316176]. 
=============================================
[2019-03-26 22:05:16,541] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.26065928e-19 1.00000000e+00 1.88657616e-19 1.90256373e-14
 1.46121445e-24], sum to 1.0000
[2019-03-26 22:05:16,551] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1349
[2019-03-26 22:05:16,556] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.26666666666667, 87.66666666666667, 1.0, 2.0, 0.7948406715529139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1110881.811720385, 1110881.811720385, 242648.6013289087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4074000.0000, 
sim time next is 4074600.0000, 
raw observation next is [27.23333333333333, 87.83333333333334, 1.0, 2.0, 0.7821619180971322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1093152.665600299, 1093152.665600299, 239579.602343137], 
processed observation next is [1.0, 0.13043478260869565, 0.4897314375987361, 0.8783333333333334, 1.0, 1.0, 0.7375444796350991, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.30365351822230524, 0.30365351822230524, 0.3575814960345328], 
reward next is 0.6424, 
noisyNet noise sample is [array([2.1975713], dtype=float32), -0.8803147]. 
=============================================
[2019-03-26 22:05:17,518] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.9093367e-07 6.4926267e-01 3.8798717e-07 3.5073629e-01 1.5602225e-09], sum to 1.0000
[2019-03-26 22:05:17,525] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8119
[2019-03-26 22:05:17,529] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.83333333333334, 66.0, 1.0, 2.0, 0.5369967479663094, 1.0, 2.0, 0.5369967479663094, 1.0, 2.0, 0.928023206279464, 6.9112, 6.9112, 170.5573041426782, 2252726.816553889, 2252726.816553889, 440780.9639300724], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3495000.0000, 
sim time next is 3495600.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.81814763343737, 1.0, 2.0, 0.81814763343737, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2288144.466802415, 2288144.466802415, 428800.157841103], 
processed observation next is [1.0, 0.4782608695652174, 0.6682464454976303, 0.66, 1.0, 1.0, 0.7809007631775542, 1.0, 1.0, 0.7809007631775542, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.635595685222893, 0.635595685222893, 0.6400002355837358], 
reward next is 0.3600, 
noisyNet noise sample is [array([-1.0541705], dtype=float32), 0.7150893]. 
=============================================
[2019-03-26 22:05:19,118] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7805132e-10 5.8310270e-01 5.3453006e-09 4.1689721e-01 4.1865491e-13], sum to 1.0000
[2019-03-26 22:05:19,131] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8346
[2019-03-26 22:05:19,141] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 3 has been changed to 4 for the demand 3450653.533496872 W.
[2019-03-26 22:05:19,144] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.0, 61.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 8.5547142527857, 6.9112, 168.9034037720284, 3450653.533496872, 2284753.897434816, 471896.8575374009], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3511800.0000, 
sim time next is 3512400.0000, 
raw observation next is [33.0, 60.33333333333333, 1.0, 2.0, 0.71131738643042, 1.0, 1.0, 0.6762487327294726, 1.0, 2.0, 1.03, 7.005098624538331, 6.9112, 170.5573041426782, 2837558.820395223, 2770295.416086578, 524926.9320346264], 
processed observation next is [1.0, 0.6521739130434783, 0.7630331753554502, 0.6033333333333333, 1.0, 1.0, 0.6521896222053253, 1.0, 0.5, 0.6099382322041839, 1.0, 1.0, 1.0365853658536586, 0.009389862453833064, 0.0, 0.8375144448122397, 0.7882107834431175, 0.7695265044684938, 0.783473032887502], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9599532], dtype=float32), -1.4677705]. 
=============================================
[2019-03-26 22:05:21,398] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.9507546e-19 1.0000000e+00 1.6572503e-18 5.1242815e-13 2.1347105e-23], sum to 1.0000
[2019-03-26 22:05:21,404] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8778
[2019-03-26 22:05:21,411] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1923309.877128724 W.
[2019-03-26 22:05:21,416] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.4585407525016811, 1.0, 1.0, 0.4585407525016811, 1.0, 1.0, 0.796333645351346, 6.9112, 6.9112, 170.5573041426782, 1923309.877128724, 1923309.877128724, 387660.8308080292], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4155600.0000, 
sim time next is 4156200.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.355396677847009, 1.0, 2.0, 0.355396677847009, 1.0, 2.0, 0.6172064979429044, 6.9112, 6.9112, 170.5573041426782, 1490380.050495132, 1490380.050495132, 329572.6112795441], 
processed observation next is [1.0, 0.08695652173913043, 0.5734597156398105, 0.84, 1.0, 1.0, 0.22336949138193857, 1.0, 1.0, 0.22336949138193857, 1.0, 1.0, 0.5331786560279321, 0.0, 0.0, 0.8375144448122397, 0.41399445847087, 0.41399445847087, 0.491899419820215], 
reward next is 0.5081, 
noisyNet noise sample is [array([0.50398386], dtype=float32), 0.15640058]. 
=============================================
[2019-03-26 22:05:22,623] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.6809506e-19 1.0000000e+00 4.2596141e-19 2.6446191e-14 1.2664004e-24], sum to 1.0000
[2019-03-26 22:05:22,631] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0080
[2019-03-26 22:05:22,636] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666666, 83.0, 1.0, 2.0, 0.6581222760653266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 919719.2901947432, 919719.2901947432, 212061.7720320993], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3559200.0000, 
sim time next is 3559800.0000, 
raw observation next is [26.08333333333334, 83.5, 1.0, 2.0, 0.6458875547944924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 902614.1242056534, 902614.1242056529, 209594.8043431386], 
processed observation next is [1.0, 0.17391304347826086, 0.43522906793049004, 0.835, 1.0, 1.0, 0.5733584997524005, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25072614561268153, 0.25072614561268136, 0.31282806618378894], 
reward next is 0.6872, 
noisyNet noise sample is [array([0.308569], dtype=float32), 1.1544986]. 
=============================================
[2019-03-26 22:05:26,625] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.7837702e-20 1.0000000e+00 3.0240467e-19 2.1493876e-14 7.3469988e-25], sum to 1.0000
[2019-03-26 22:05:26,632] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7233
[2019-03-26 22:05:26,637] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 73.33333333333334, 1.0, 2.0, 0.7167963663609491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1001754.416041167, 1001754.416041167, 224509.6117563216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3654600.0000, 
sim time next is 3655200.0000, 
raw observation next is [28.33333333333334, 72.66666666666667, 1.0, 2.0, 0.8337723696138105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1165323.222125652, 1165323.222125652, 252366.6801738021], 
processed observation next is [1.0, 0.30434782608695654, 0.5418641390205374, 0.7266666666666667, 1.0, 1.0, 0.7997257465226633, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.32370089503490335, 0.32370089503490335, 0.3766666868265703], 
reward next is 0.6233, 
noisyNet noise sample is [array([-0.9377486], dtype=float32), -0.103215]. 
=============================================
[2019-03-26 22:05:35,012] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2661537e-22 1.0000000e+00 1.8210186e-22 6.2787833e-17 4.5202246e-27], sum to 1.0000
[2019-03-26 22:05:35,020] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9486
[2019-03-26 22:05:35,025] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.25, 93.0, 1.0, 2.0, 0.5736046835603705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 801562.2318250238, 801562.2318250238, 195930.9415085911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3897000.0000, 
sim time next is 3897600.0000, 
raw observation next is [27.16666666666667, 93.33333333333334, 1.0, 2.0, 0.5725396724857381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 800073.4117516486, 800073.4117516486, 195740.9913087986], 
processed observation next is [0.0, 0.08695652173913043, 0.4865718799368091, 0.9333333333333335, 1.0, 1.0, 0.48498755721173264, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22224261437545795, 0.22224261437545795, 0.2921507332967143], 
reward next is 0.7078, 
noisyNet noise sample is [array([0.8701214], dtype=float32), -0.14699751]. 
=============================================
[2019-03-26 22:05:37,000] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.7761109e-21 1.0000000e+00 8.5097555e-21 1.2598957e-16 8.2346147e-27], sum to 1.0000
[2019-03-26 22:05:37,009] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1844
[2019-03-26 22:05:37,016] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.5426236123804976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 758253.4496400048, 758253.4496400041, 190543.3025044145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3817200.0000, 
sim time next is 3817800.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.5418825655360843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 757217.5536805951, 757217.5536805957, 190417.9670020627], 
processed observation next is [0.0, 0.17391304347826086, 0.4786729857819906, 0.89, 1.0, 1.0, 0.44805128377841474, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21033820935572087, 0.21033820935572103, 0.2842059208986011], 
reward next is 0.7158, 
noisyNet noise sample is [array([1.6705464], dtype=float32), -0.5641864]. 
=============================================
[2019-03-26 22:05:37,622] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2565095e-20 1.0000000e+00 9.5916390e-21 7.7564025e-16 4.0930578e-26], sum to 1.0000
[2019-03-26 22:05:37,632] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1905
[2019-03-26 22:05:37,637] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 88.16666666666667, 1.0, 2.0, 0.5411499810021114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 756193.4880246483, 756193.4880246476, 190294.3499238946], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4056600.0000, 
sim time next is 4057200.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.5411218965421045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 756154.2293244835, 756154.2293244842, 190289.4820549435], 
processed observation next is [1.0, 1.0, 0.4786729857819906, 0.89, 1.0, 1.0, 0.44713481511096925, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21004284147902322, 0.2100428414790234, 0.28401415232081123], 
reward next is 0.7160, 
noisyNet noise sample is [array([2.4689074], dtype=float32), -1.9107126]. 
=============================================
[2019-03-26 22:05:42,575] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1806833e-10 1.1915461e-02 5.1523745e-09 9.8808461e-01 1.6119914e-13], sum to 1.0000
[2019-03-26 22:05:42,581] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3491
[2019-03-26 22:05:42,586] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.0, 53.0, 1.0, 2.0, 0.8855075664266336, 1.0, 2.0, 0.8855075664266336, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2476719.23051769, 2476719.23051769, 463655.6752587686], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4191600.0000, 
sim time next is 4192200.0000, 
raw observation next is [36.0, 53.0, 1.0, 2.0, 0.8370367721561057, 1.0, 2.0, 0.8370367721561057, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2341021.916706339, 2341021.916706339, 438315.2351665387], 
processed observation next is [1.0, 0.5217391304347826, 0.9052132701421801, 0.53, 1.0, 1.0, 0.8036587616338623, 1.0, 1.0, 0.8036587616338623, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6502838657517608, 0.6502838657517608, 0.6542018435321473], 
reward next is 0.3458, 
noisyNet noise sample is [array([-0.2101972], dtype=float32), 0.12069669]. 
=============================================
[2019-03-26 22:06:01,053] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 22:06:01,055] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 22:06:01,056] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:06:01,057] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 22:06:01,059] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 22:06:01,058] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 22:06:01,061] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 22:06:01,060] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:06:01,061] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:06:01,063] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:06:01,064] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:06:01,082] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run65
[2019-03-26 22:06:01,102] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run65
[2019-03-26 22:06:01,104] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run65
[2019-03-26 22:06:01,145] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run65
[2019-03-26 22:06:01,167] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run65
[2019-03-26 22:07:07,078] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08901061], dtype=float32), 0.06460558]
[2019-03-26 22:07:07,081] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.5, 81.5, 1.0, 2.0, 0.5577636451529746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 779417.6483492494, 779417.64834925, 193140.5940172905]
[2019-03-26 22:07:07,083] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 22:07:07,085] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.5012469e-22 1.0000000e+00 2.4135438e-22 2.8048553e-17 6.1668734e-28], sampled 0.921647343832271
[2019-03-26 22:07:17,588] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08901061], dtype=float32), 0.06460558]
[2019-03-26 22:07:17,590] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.45, 69.5, 1.0, 2.0, 0.7050854716539551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 985380.3331016707, 985380.3331016714, 221952.7513829592]
[2019-03-26 22:07:17,593] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:07:17,596] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.8674571e-21 1.0000000e+00 2.2382876e-20 2.7629654e-14 1.8096787e-26], sampled 0.2762485618939885
[2019-03-26 22:07:25,712] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08901061], dtype=float32), 0.06460558]
[2019-03-26 22:07:25,713] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.54239331333333, 87.83017569666667, 1.0, 2.0, 0.5293061335768229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 739637.3413264538, 739637.3413264538, 188314.0400221328]
[2019-03-26 22:07:25,714] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:07:25,717] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5096602e-22 1.0000000e+00 2.3445398e-22 1.8862830e-17 5.6297152e-28], sampled 0.021299424684813495
[2019-03-26 22:07:37,366] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08901061], dtype=float32), 0.06460558]
[2019-03-26 22:07:37,367] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.65, 79.5, 1.0, 2.0, 0.9689531250798037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1354379.319834808, 1354379.319834808, 289609.6203846156]
[2019-03-26 22:07:37,368] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:07:37,371] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.0709454e-21 1.0000000e+00 2.6377081e-21 4.2355104e-16 7.2266885e-27], sampled 0.0630120207125835
[2019-03-26 22:07:39,859] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08901061], dtype=float32), 0.06460558]
[2019-03-26 22:07:39,860] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.13333333333333, 80.66666666666667, 1.0, 2.0, 0.3321118661138523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 519975.3937631316, 519975.3937631322, 168442.7892429112]
[2019-03-26 22:07:39,860] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 22:07:39,864] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.7599166e-21 1.0000000e+00 2.8787129e-21 4.4106541e-17 1.0364555e-26], sampled 0.752188599870117
[2019-03-26 22:07:45,933] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08901061], dtype=float32), 0.06460558]
[2019-03-26 22:07:45,935] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.1, 68.0, 1.0, 2.0, 0.5894892426514151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 823768.1175480718, 823768.1175480718, 198804.4405053689]
[2019-03-26 22:07:45,935] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:07:45,940] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.5899841e-19 1.0000000e+00 7.2470364e-19 4.3402120e-13 3.4710744e-24], sampled 0.8365100230363297
[2019-03-26 22:07:55,054] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.0938 3007676130.0199 1765.0000
[2019-03-26 22:07:55,121] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7886.2965 3164472412.3671 1775.0000
[2019-03-26 22:07:55,305] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1249 2927277438.0038 1338.0000
[2019-03-26 22:07:55,395] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8498.0680 2842512724.6902 1126.0000
[2019-03-26 22:07:55,591] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 22:07:56,612] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1600000, evaluation results [1600000.0, 7886.29645879592, 3164472412.36712, 1775.0, 8255.124881931173, 2927277438.00382, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7996.0937721765595, 3007676130.0198836, 1765.0, 8498.067950332214, 2842512724.6901565, 1126.0]
[2019-03-26 22:08:07,150] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.5065409e-22 1.0000000e+00 4.4636219e-22 6.4381868e-16 1.7079588e-27], sum to 1.0000
[2019-03-26 22:08:07,159] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1780
[2019-03-26 22:08:07,167] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.6172120494033209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 862524.4432381731, 862524.4432381738, 203997.1329587804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4396800.0000, 
sim time next is 4397400.0000, 
raw observation next is [31.0, 79.0, 1.0, 2.0, 0.616364673260863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 861339.7952720759, 861339.7952720753, 203835.1097823063], 
processed observation next is [1.0, 0.9130434782608695, 0.6682464454976303, 0.79, 1.0, 1.0, 0.5377887629648951, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2392610542422433, 0.23926105424224314, 0.3042315071377706], 
reward next is 0.6958, 
noisyNet noise sample is [array([1.1016282], dtype=float32), 0.8580498]. 
=============================================
[2019-03-26 22:08:09,364] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.4575715e-22 1.0000000e+00 7.6617165e-22 3.8598295e-17 1.3416979e-26], sum to 1.0000
[2019-03-26 22:08:09,375] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2967
[2019-03-26 22:08:09,379] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 80.66666666666667, 1.0, 2.0, 0.5844406942784548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 816710.4279373143, 816710.4279373143, 197883.1917347989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4434000.0000, 
sim time next is 4434600.0000, 
raw observation next is [29.83333333333333, 79.83333333333334, 1.0, 2.0, 0.5856148241911059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 818351.8152719805, 818351.8152719805, 198096.7304769898], 
processed observation next is [0.0, 0.30434782608695654, 0.6129541864139019, 0.7983333333333335, 1.0, 1.0, 0.5007407520374769, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22731994868666125, 0.22731994868666125, 0.2956667619059549], 
reward next is 0.7043, 
noisyNet noise sample is [array([1.6147249], dtype=float32), 0.0060796184]. 
=============================================
[2019-03-26 22:08:15,115] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7297324e-21 1.0000000e+00 1.4677361e-21 2.4014274e-17 4.1864290e-27], sum to 1.0000
[2019-03-26 22:08:15,126] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5242
[2019-03-26 22:08:15,133] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.16666666666667, 72.66666666666667, 1.0, 2.0, 0.5234998566177778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 731521.0212447378, 731521.0212447371, 187359.871395574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5127000.0000, 
sim time next is 5127600.0000, 
raw observation next is [29.33333333333334, 71.33333333333334, 1.0, 2.0, 0.5221001399677294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 729564.4327851983, 729564.4327851989, 187131.0297538437], 
processed observation next is [0.0, 0.34782608695652173, 0.5892575039494474, 0.7133333333333334, 1.0, 1.0, 0.42421703610569805, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2026567868847773, 0.20265678688477748, 0.2793000444087219], 
reward next is 0.7207, 
noisyNet noise sample is [array([-0.4303079], dtype=float32), 2.1484337]. 
=============================================
[2019-03-26 22:08:16,206] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.1690220e-23 1.0000000e+00 1.2005520e-22 2.1019821e-17 4.2832865e-28], sum to 1.0000
[2019-03-26 22:08:16,217] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2797
[2019-03-26 22:08:16,224] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.5498011070409204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 768286.7916807865, 768286.791680786, 191766.3772246501], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4575600.0000, 
sim time next is 4576200.0000, 
raw observation next is [28.0, 84.0, 1.0, 2.0, 0.5507766209849794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 769650.4593724336, 769650.4593724343, 191933.6903364013], 
processed observation next is [0.0, 1.0, 0.5260663507109005, 0.84, 1.0, 1.0, 0.45876701323491487, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21379179427012043, 0.21379179427012063, 0.2864681945319423], 
reward next is 0.7135, 
noisyNet noise sample is [array([0.34059146], dtype=float32), -0.18673518]. 
=============================================
[2019-03-26 22:08:17,216] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8413740e-22 1.0000000e+00 2.8424070e-22 9.0245292e-17 1.6787553e-27], sum to 1.0000
[2019-03-26 22:08:17,228] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9175
[2019-03-26 22:08:17,232] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.0, 53.0, 1.0, 2.0, 0.5403888823392552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 755129.5640688089, 755129.5640688089, 190166.8481492438], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4550400.0000, 
sim time next is 4551000.0000, 
raw observation next is [33.66666666666667, 54.0, 1.0, 2.0, 0.5553036881267428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 775978.8543581415, 775978.8543581415, 192713.9165766592], 
processed observation next is [0.0, 0.6956521739130435, 0.7946287519747238, 0.54, 1.0, 1.0, 0.46422131099607566, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21554968176615044, 0.21554968176615044, 0.28763271130844653], 
reward next is 0.7124, 
noisyNet noise sample is [array([-0.34101596], dtype=float32), -0.32135513]. 
=============================================
[2019-03-26 22:08:17,256] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.32325 ]
 [73.280914]
 [73.262   ]
 [73.23018 ]
 [73.21137 ]], R is [[73.3376236 ]
 [73.32041931]
 [73.30347443]
 [73.28676605]
 [73.270401  ]].
[2019-03-26 22:08:17,942] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3367451e-22 1.0000000e+00 1.8154221e-21 1.1637688e-17 1.3696996e-28], sum to 1.0000
[2019-03-26 22:08:17,947] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1844
[2019-03-26 22:08:17,951] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 70.0, 1.0, 2.0, 0.5292462505008002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 739553.6332888254, 739553.6332888254, 188305.6682446461], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5074200.0000, 
sim time next is 5074800.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.5301177846642534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740771.9149529611, 740771.9149529617, 188449.8289393672], 
processed observation next is [0.0, 0.7391304347826086, 0.6208530805687204, 0.7, 1.0, 1.0, 0.4338768489930764, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20576997637582253, 0.2057699763758227, 0.2812684014020406], 
reward next is 0.7187, 
noisyNet noise sample is [array([0.15966408], dtype=float32), 1.8544059]. 
=============================================
[2019-03-26 22:08:26,520] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.2751081e-23 1.0000000e+00 1.6054930e-22 4.6991307e-17 1.2237001e-27], sum to 1.0000
[2019-03-26 22:08:26,527] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8342
[2019-03-26 22:08:26,537] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5228320007704005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 730587.4611039674, 730587.4611039667, 187250.3871592841], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5173200.0000, 
sim time next is 5173800.0000, 
raw observation next is [28.0, 79.00000000000001, 1.0, 2.0, 0.5234912123965862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731508.9379428031, 731508.9379428037, 187358.1546805001], 
processed observation next is [0.0, 0.9130434782608695, 0.5260663507109005, 0.7900000000000001, 1.0, 1.0, 0.42589302698383885, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2031969272063342, 0.20319692720633437, 0.2796390368365673], 
reward next is 0.7204, 
noisyNet noise sample is [array([-1.2093832], dtype=float32), -1.4474411]. 
=============================================
[2019-03-26 22:08:32,633] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.6956197e-22 1.0000000e+00 4.2654984e-20 5.0945068e-14 2.3109517e-27], sum to 1.0000
[2019-03-26 22:08:32,640] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9646
[2019-03-26 22:08:32,645] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 73.33333333333334, 1.0, 2.0, 0.4918672512375458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 687304.3867580179, 687304.3867580179, 182331.589188614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4823400.0000, 
sim time next is 4824000.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.4914015331781712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 686653.4112827313, 686653.4112827313, 182259.6817495035], 
processed observation next is [1.0, 0.8695652173913043, 0.5260663507109005, 0.74, 1.0, 1.0, 0.38723076286526653, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1907370586896476, 0.1907370586896476, 0.2720293757455276], 
reward next is 0.7280, 
noisyNet noise sample is [array([-0.6737226], dtype=float32), -1.6357411]. 
=============================================
[2019-03-26 22:08:32,672] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[73.225494]
 [73.292946]
 [72.77581 ]
 [72.3154  ]
 [71.5645  ]], R is [[73.21509552]
 [73.21081543]
 [73.20638275]
 [73.20135498]
 [73.19587708]].
[2019-03-26 22:08:39,247] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.0300377e-11 9.9997175e-01 2.8829265e-11 2.8209181e-05 1.1200696e-14], sum to 1.0000
[2019-03-26 22:08:39,255] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2114
[2019-03-26 22:08:39,260] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2805301.260083485 W.
[2019-03-26 22:08:39,264] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.53333333333333, 69.66666666666666, 1.0, 2.0, 1.002854570703724, 1.0, 2.0, 1.002854570703724, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2805301.260083485, 2805301.260083486, 530719.4329716593], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5388000.0000, 
sim time next is 5388600.0000, 
raw observation next is [32.71666666666667, 68.83333333333334, 1.0, 2.0, 1.024343692547008, 1.0, 2.0, 1.024343692547008, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2865482.072066886, 2865482.072066887, 543876.5536472631], 
processed observation next is [1.0, 0.34782608695652173, 0.7496050552922592, 0.6883333333333335, 1.0, 1.0, 1.029329750056636, 1.0, 1.0, 1.029329750056636, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7959672422408016, 0.7959672422408018, 0.8117560502197957], 
reward next is 0.1882, 
noisyNet noise sample is [array([-0.33263102], dtype=float32), 0.63589716]. 
=============================================
[2019-03-26 22:08:40,678] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.5096142e-20 1.0000000e+00 3.8313061e-20 7.3983635e-15 1.2334730e-25], sum to 1.0000
[2019-03-26 22:08:40,685] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3702
[2019-03-26 22:08:40,691] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.8, 82.0, 1.0, 2.0, 1.007630450325946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1408477.416688641, 1408477.416688641, 301261.517850252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5558400.0000, 
sim time next is 5559000.0000, 
raw observation next is [29.0, 80.83333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.981440663791823, 6.9112, 168.9124306376941, 1503620.042500017, 1453789.053247153, 311352.4929811025], 
processed observation next is [1.0, 0.34782608695652173, 0.5734597156398105, 0.8083333333333335, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.007024066379182336, 0.0, 0.8294373628764189, 0.4176722340277825, 0.4038302925686536, 0.4647052134046306], 
reward next is 0.1841, 
noisyNet noise sample is [array([-0.643085], dtype=float32), 0.47504544]. 
=============================================
[2019-03-26 22:08:40,725] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[65.924774]
 [66.03586 ]
 [66.093895]
 [66.126755]
 [66.14202 ]], R is [[65.35121918]
 [65.24806213]
 [65.20662689]
 [65.16161346]
 [65.08488464]].
[2019-03-26 22:08:46,075] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.4870105e-22 1.0000000e+00 5.2308198e-22 1.7560975e-17 1.5078318e-27], sum to 1.0000
[2019-03-26 22:08:46,083] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0065
[2019-03-26 22:08:46,089] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 75.5, 1.0, 2.0, 0.5288519511965191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 739002.459011747, 739002.4590117476, 188240.4328122601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5646600.0000, 
sim time next is 5647200.0000, 
raw observation next is [29.16666666666666, 75.0, 1.0, 2.0, 0.531538149414752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742757.3872545608, 742757.3872545602, 188685.3781932706], 
processed observation next is [0.0, 0.34782608695652173, 0.5813586097946285, 0.75, 1.0, 1.0, 0.43558813182500233, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20632149645960024, 0.20632149645960007, 0.28161996745264267], 
reward next is 0.7184, 
noisyNet noise sample is [array([-1.6689032], dtype=float32), -1.5173689]. 
=============================================
[2019-03-26 22:08:46,119] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6484261e-22 1.0000000e+00 2.1415140e-22 9.9216394e-18 2.2695068e-27], sum to 1.0000
[2019-03-26 22:08:46,129] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7111
[2019-03-26 22:08:46,136] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666666, 60.33333333333333, 1.0, 2.0, 0.5212675674919582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 728400.6263068545, 728400.6263068538, 186995.8504322216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5064000.0000, 
sim time next is 5064600.0000, 
raw observation next is [31.83333333333333, 59.66666666666667, 1.0, 2.0, 0.5220691881744673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 729521.1669824453, 729521.1669824459, 187126.6090841035], 
processed observation next is [0.0, 0.6086956521739131, 0.7077409162717218, 0.5966666666666667, 1.0, 1.0, 0.42417974478851483, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2026447686062348, 0.20264476860623495, 0.2792934463941843], 
reward next is 0.7207, 
noisyNet noise sample is [array([1.2415886], dtype=float32), -0.42427495]. 
=============================================
[2019-03-26 22:08:47,684] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.9152854e-22 1.0000000e+00 8.0236232e-22 2.8229009e-16 2.4742062e-27], sum to 1.0000
[2019-03-26 22:08:47,694] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0235
[2019-03-26 22:08:47,702] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.11666666666667, 90.33333333333333, 1.0, 2.0, 0.5486145661652951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 766628.1325044517, 766628.1325044523, 191563.3728262976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5530200.0000, 
sim time next is 5530800.0000, 
raw observation next is [27.03333333333333, 90.66666666666667, 1.0, 2.0, 0.5475336966681766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 765117.1930401626, 765117.193040162, 191378.6003513641], 
processed observation next is [1.0, 0.0, 0.48025276461295413, 0.9066666666666667, 1.0, 1.0, 0.4548598755038272, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2125325536222674, 0.21253255362226722, 0.2856397020169613], 
reward next is 0.7144, 
noisyNet noise sample is [array([-0.6963138], dtype=float32), -0.42651963]. 
=============================================
[2019-03-26 22:08:52,657] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 22:08:52,659] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 22:08:52,660] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 22:08:52,662] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:08:52,662] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 22:08:52,664] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 22:08:52,664] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:08:52,662] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 22:08:52,665] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:08:52,667] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:08:52,668] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:08:52,692] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run66
[2019-03-26 22:08:52,716] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run66
[2019-03-26 22:08:52,718] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run66
[2019-03-26 22:08:52,718] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run66
[2019-03-26 22:08:52,738] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run66
[2019-03-26 22:09:32,550] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09091467], dtype=float32), 0.06634165]
[2019-03-26 22:09:32,551] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.0, 68.0, 1.0, 2.0, 0.5590806478481877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 781258.7017344341, 781258.7017344341, 193370.1139798342]
[2019-03-26 22:09:32,553] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 22:09:32,555] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.3270677e-23 1.0000000e+00 7.6908486e-23 7.9614116e-18 1.7830686e-28], sampled 0.31863849574990066
[2019-03-26 22:09:34,824] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09091467], dtype=float32), 0.06634165]
[2019-03-26 22:09:34,826] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.58697861666667, 80.51552135333334, 1.0, 2.0, 0.45327612621681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 661189.0193546199, 661189.0193546199, 180132.4135765114]
[2019-03-26 22:09:34,829] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:09:34,832] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.2809798e-22 1.0000000e+00 4.3189031e-22 7.2875150e-18 1.0640779e-27], sampled 0.48210119014019315
[2019-03-26 22:09:40,887] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09091467], dtype=float32), 0.06634165]
[2019-03-26 22:09:40,888] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.311575175, 72.65234576333333, 1.0, 2.0, 0.4097672168148239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 605920.8245244825, 605920.8245244825, 174928.7989281304]
[2019-03-26 22:09:40,890] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:09:40,894] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.8367635e-22 1.0000000e+00 3.0221506e-22 5.5834617e-18 7.7995256e-28], sampled 0.2018901611436077
[2019-03-26 22:09:53,869] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09091467], dtype=float32), 0.06634165]
[2019-03-26 22:09:53,871] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [32.44786243999999, 75.00744239000001, 1.0, 2.0, 0.6378976342344534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 891443.6941551028, 891443.6941551028, 208020.2470436619]
[2019-03-26 22:09:53,874] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:09:53,877] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.7027327e-22 1.0000000e+00 2.5908676e-21 2.2857269e-13 1.8496342e-27], sampled 0.3622869781253786
[2019-03-26 22:10:05,924] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09091467], dtype=float32), 0.06634165]
[2019-03-26 22:10:05,925] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.10000000000001, 58.33333333333334, 1.0, 2.0, 0.8992851925360754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1256941.517148185, 1256941.517148185, 269745.3981997525]
[2019-03-26 22:10:05,926] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:10:05,930] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.5122216e-19 1.0000000e+00 8.7156557e-19 3.2286541e-12 7.5883479e-25], sampled 0.6074299465859895
[2019-03-26 22:10:07,809] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09091467], dtype=float32), 0.06634165]
[2019-03-26 22:10:07,810] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.16666666666667, 77.16666666666667, 1.0, 2.0, 0.5851202331719446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 817660.3962143612, 817660.3962143612, 198006.4818612483]
[2019-03-26 22:10:07,813] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:10:07,817] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.5246895e-23 1.0000000e+00 2.0941163e-23 5.3829548e-18 3.7614438e-29], sampled 0.8658671818954615
[2019-03-26 22:10:23,397] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09091467], dtype=float32), 0.06634165]
[2019-03-26 22:10:23,397] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.46666666666667, 58.66666666666667, 1.0, 2.0, 0.5176820273673558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 723388.614960856, 723388.6149608567, 186412.3542216883]
[2019-03-26 22:10:23,402] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:10:23,405] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.9144256e-23 1.0000000e+00 2.2029788e-22 1.9778117e-16 2.8003173e-28], sampled 0.803036586242637
[2019-03-26 22:10:28,787] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09091467], dtype=float32), 0.06634165]
[2019-03-26 22:10:28,788] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.85, 66.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.033726190220959, 6.9112, 168.9120319132295, 2382560.167556999, 2295636.346995201, 476392.8093580543]
[2019-03-26 22:10:28,790] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 22:10:28,792] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.4332641e-12 9.9996269e-01 1.8975634e-11 3.7272483e-05 3.3486522e-15], sampled 0.8430614208789543
[2019-03-26 22:10:28,793] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2382560.167556999 W.
[2019-03-26 22:10:46,765] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.1893 2779508971.0566 933.0000
[2019-03-26 22:10:46,984] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.4057 2842523843.6666 1130.0000
[2019-03-26 22:10:47,084] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.3176 3164294096.2264 1776.0000
[2019-03-26 22:10:47,251] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.2902 2927416332.5773 1338.0000
[2019-03-26 22:10:47,276] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.4791 3007672152.8903 1766.0000
[2019-03-26 22:10:48,292] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1625000, evaluation results [1625000.0, 7882.317580435685, 3164294096.2264004, 1776.0, 8254.290164618182, 2927416332.5773025, 1338.0, 8658.18931172424, 2779508971.0565677, 933.0, 7997.479051450769, 3007672152.8903465, 1766.0, 8496.405674805714, 2842523843.6665945, 1130.0]
[2019-03-26 22:10:49,614] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2146151e-23 1.0000000e+00 1.6996307e-22 1.0694141e-17 1.5847511e-28], sum to 1.0000
[2019-03-26 22:10:49,625] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6157
[2019-03-26 22:10:49,637] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5120795447716742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 715557.288129317, 715557.288129317, 185510.2060561532], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5184000.0000, 
sim time next is 5184600.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5138403410743984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 718018.5785019178, 718018.5785019178, 185792.7409535479], 
processed observation next is [1.0, 0.0, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4142654711739739, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19944960513942162, 0.19944960513942162, 0.2773025984381312], 
reward next is 0.7227, 
noisyNet noise sample is [array([-0.07768157], dtype=float32), -0.8485374]. 
=============================================
[2019-03-26 22:10:54,464] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.6778990e-10 1.7924417e-03 1.8966723e-08 9.9820757e-01 5.7903213e-12], sum to 1.0000
[2019-03-26 22:10:54,473] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8400
[2019-03-26 22:10:54,480] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.7, 58.0, 1.0, 2.0, 0.8406110043070684, 1.0, 2.0, 0.7408955416677968, 1.0, 1.0, 1.03, 7.005108821823244, 6.9112, 170.5573041426782, 3109156.274413909, 3041885.565375281, 569420.8566808725], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5486400.0000, 
sim time next is 5487000.0000, 
raw observation next is [35.8, 57.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.382097917473943, 6.9112, 170.5573041426782, 3247045.991168674, 2909722.657979494, 551123.8552648118], 
processed observation next is [1.0, 0.5217391304347826, 0.895734597156398, 0.57, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.04708979174739429, 0.0, 0.8375144448122397, 0.9019572197690762, 0.8082562938831928, 0.8225729183056892], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7916728], dtype=float32), 0.27812266]. 
=============================================
[2019-03-26 22:10:54,498] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[23.481752]
 [24.439949]
 [23.258911]
 [21.173061]
 [19.573795]], R is [[24.68929291]
 [24.44239998]
 [24.19797707]
 [23.95599747]
 [23.91948509]].
[2019-03-26 22:10:59,099] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9580050e-10 1.3555263e-03 3.0004361e-09 9.9864453e-01 2.2190442e-12], sum to 1.0000
[2019-03-26 22:10:59,107] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8663
[2019-03-26 22:10:59,116] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 3 has been changed to 4 for the demand 3351538.536988149 W.
[2019-03-26 22:10:59,122] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.05, 53.0, 1.0, 2.0, 0.9559730274019669, 1.0, 2.0, 0.7985765532152462, 1.0, 1.0, 1.03, 7.005117924077202, 6.9112, 170.5573041426782, 3351538.536988149, 3284261.307634756, 614381.0412433387], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5326200.0000, 
sim time next is 5326800.0000, 
raw observation next is [36.03333333333333, 53.0, 1.0, 2.0, 0.8808225304337793, 1.0, 2.0, 0.7610013047311522, 1.0, 2.0, 1.03, 7.005111994178113, 6.9112, 170.5573041426782, 3193637.668437528, 3126364.686912064, 584527.655780931], 
processed observation next is [1.0, 0.6521739130434783, 0.9067930489731437, 0.53, 1.0, 1.0, 0.8564126872696136, 1.0, 1.0, 0.712049764736328, 1.0, 1.0, 1.0365853658536586, 0.009391199417811257, 0.0, 0.8375144448122397, 0.88712157456598, 0.8684346352533511, 0.8724293369864642], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.0798342], dtype=float32), -0.7362054]. 
=============================================
[2019-03-26 22:10:59,213] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6964948e-23 1.0000000e+00 7.6437921e-22 2.6876686e-15 2.1608161e-28], sum to 1.0000
[2019-03-26 22:10:59,220] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1314
[2019-03-26 22:10:59,224] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.25, 78.5, 1.0, 2.0, 0.6276846513960663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 877165.4491132319, 877165.4491132324, 206017.5566451002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5344200.0000, 
sim time next is 5344800.0000, 
raw observation next is [31.16666666666666, 78.66666666666667, 1.0, 2.0, 0.6261678895408834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 875044.9588910389, 875044.9588910383, 205722.8452377084], 
processed observation next is [1.0, 0.8695652173913043, 0.6761453396524484, 0.7866666666666667, 1.0, 1.0, 0.549599866916727, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2430680441363997, 0.24306804413639954, 0.30704902274284834], 
reward next is 0.6930, 
noisyNet noise sample is [array([-0.32590744], dtype=float32), 0.8641157]. 
=============================================
[2019-03-26 22:10:59,483] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.1127578e-21 1.0000000e+00 4.8925984e-21 2.2835021e-15 1.6074384e-26], sum to 1.0000
[2019-03-26 22:10:59,493] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0893
[2019-03-26 22:10:59,496] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.53333333333333, 84.83333333333334, 1.0, 2.0, 0.6028952230599088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 842509.425098895, 842509.4250988944, 201286.8559738267], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5359800.0000, 
sim time next is 5360400.0000, 
raw observation next is [29.5, 85.0, 1.0, 2.0, 0.6026620106718366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 842183.3957562943, 842183.3957562943, 201243.2119418286], 
processed observation next is [1.0, 0.043478260869565216, 0.5971563981042655, 0.85, 1.0, 1.0, 0.5212795309299235, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23393983215452618, 0.23393983215452618, 0.30036300289825163], 
reward next is 0.6996, 
noisyNet noise sample is [array([0.10174075], dtype=float32), 1.2398587]. 
=============================================
[2019-03-26 22:11:00,615] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.5820383e-18 1.0000000e+00 2.0572804e-17 9.0586982e-12 1.7627166e-23], sum to 1.0000
[2019-03-26 22:11:00,623] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0581
[2019-03-26 22:11:00,630] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 86.0, 1.0, 2.0, 0.8926081449586144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1247603.445734231, 1247603.445734231, 267918.0238272003], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5378400.0000, 
sim time next is 5379000.0000, 
raw observation next is [29.68333333333334, 84.83333333333334, 1.0, 2.0, 0.9271896082850597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1295967.652439482, 1295967.652439482, 277531.9163570407], 
processed observation next is [1.0, 0.2608695652173913, 0.6058451816745659, 0.8483333333333334, 1.0, 1.0, 0.9122766364880237, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.35999101456652277, 0.35999101456652277, 0.41422674083140404], 
reward next is 0.5858, 
noisyNet noise sample is [array([0.944642], dtype=float32), 0.018585015]. 
=============================================
[2019-03-26 22:11:00,647] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[62.82228 ]
 [61.212475]
 [58.792366]
 [56.413162]
 [53.56177 ]], R is [[64.63372803]
 [64.58751678]
 [64.54575348]
 [64.50798798]
 [64.47263336]].
[2019-03-26 22:11:01,759] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.8553417e-11 9.9999511e-01 1.2591769e-11 4.8686506e-06 5.7610323e-15], sum to 1.0000
[2019-03-26 22:11:01,772] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0971
[2019-03-26 22:11:01,778] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1759297.523155276 W.
[2019-03-26 22:11:01,782] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.55, 92.33333333333334, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.341594873577435, 6.9112, 168.9110407426702, 1759297.523155276, 1453964.049844924, 311356.1010274628], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5371800.0000, 
sim time next is 5372400.0000, 
raw observation next is [28.5, 92.66666666666667, 1.0, 2.0, 0.5677367672126873, 1.0, 1.0, 0.5677367672126873, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1587300.118582292, 1587300.118582292, 322655.1571357525], 
processed observation next is [1.0, 0.17391304347826086, 0.5497630331753555, 0.9266666666666667, 1.0, 1.0, 0.4792009243526353, 1.0, 0.5, 0.4792009243526353, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.44091669960619223, 0.44091669960619223, 0.4815748613966455], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.50951034], dtype=float32), -0.01563577]. 
=============================================
[2019-03-26 22:11:02,608] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6039690e-19 1.0000000e+00 2.2253733e-19 6.2628017e-14 6.0171145e-25], sum to 1.0000
[2019-03-26 22:11:02,616] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5464
[2019-03-26 22:11:02,619] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.36666666666667, 80.5, 1.0, 2.0, 0.9795041304955399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1369136.770955952, 1369136.770955951, 292746.1710573962], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5904600.0000, 
sim time next is 5905200.0000, 
raw observation next is [29.53333333333333, 80.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 9.987940680208649, 6.9112, 168.8954401013694, 3637628.799626759, 1455109.420327928, 306342.9021688374], 
processed observation next is [1.0, 0.34782608695652173, 0.598736176935229, 0.8, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.30767406802086483, 0.0, 0.8293539315647634, 1.0104524443407663, 0.4041970612022022, 0.4572282121922946], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5732992], dtype=float32), -1.2306409]. 
=============================================
[2019-03-26 22:11:03,791] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8062594e-23 1.0000000e+00 5.9319065e-23 1.0225117e-16 2.8135090e-28], sum to 1.0000
[2019-03-26 22:11:03,802] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3956
[2019-03-26 22:11:03,808] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.06666666666667, 82.0, 1.0, 2.0, 0.6108429708254568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 853620.3825900599, 853620.3825900605, 202783.394811058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5435400.0000, 
sim time next is 5436000.0000, 
raw observation next is [30.0, 82.0, 1.0, 2.0, 0.6084672922804134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 850299.169977118, 850299.1699771174, 202333.9938318708], 
processed observation next is [1.0, 0.9565217391304348, 0.6208530805687204, 0.82, 1.0, 1.0, 0.5282738461209799, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23619421388253278, 0.23619421388253262, 0.3019910355699564], 
reward next is 0.6980, 
noisyNet noise sample is [array([0.7063476], dtype=float32), 0.19444802]. 
=============================================
[2019-03-26 22:11:03,818] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[71.8344 ]
 [72.0589 ]
 [72.0886 ]
 [72.52646]
 [72.88435]], R is [[71.47103882]
 [71.45367432]
 [71.43595886]
 [71.41803741]
 [71.3997879 ]].
[2019-03-26 22:11:05,980] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.17549700e-20 1.00000000e+00 2.94380138e-20 1.34049876e-14
 1.51169138e-26], sum to 1.0000
[2019-03-26 22:11:05,990] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3679
[2019-03-26 22:11:05,994] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 82.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.151427281635259, 6.9112, 168.9114775842434, 1624295.654549244, 1453871.645141601, 311354.6066453936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5467200.0000, 
sim time next is 5467800.0000, 
raw observation next is [29.7, 81.83333333333333, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.398970201970895, 6.9112, 168.9098758912226, 1800026.595570599, 1453991.937601569, 311354.7977091381], 
processed observation next is [1.0, 0.2608695652173913, 0.6066350710900474, 0.8183333333333332, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.048777020197089536, 0.0, 0.8294248179016759, 0.5000073876584997, 0.4038866493337692, 0.464708653297221], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5520005], dtype=float32), 0.5540465]. 
=============================================
[2019-03-26 22:11:09,258] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.8357681e-11 9.7440469e-01 2.0799548e-10 2.5595283e-02 6.6872851e-14], sum to 1.0000
[2019-03-26 22:11:09,267] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1050
[2019-03-26 22:11:09,278] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2350783.128013104 W.
[2019-03-26 22:11:09,284] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.55, 67.33333333333334, 1.0, 2.0, 0.8405236319407589, 1.0, 2.0, 0.8405236319407589, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2350783.128013104, 2350783.128013104, 440077.4112446233], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6106200.0000, 
sim time next is 6106800.0000, 
raw observation next is [30.5, 67.66666666666667, 1.0, 2.0, 0.8436808580976434, 1.0, 2.0, 0.8436808580976434, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2359621.619639097, 2359621.619639097, 441692.5752808101], 
processed observation next is [1.0, 0.6956521739130435, 0.6445497630331753, 0.6766666666666667, 1.0, 1.0, 0.811663684454992, 1.0, 1.0, 0.811663684454992, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6554504498997491, 0.6554504498997491, 0.659242649672851], 
reward next is 0.3408, 
noisyNet noise sample is [array([0.32603252], dtype=float32), 1.3523861]. 
=============================================
[2019-03-26 22:11:12,665] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8859744e-12 9.9999988e-01 1.4354827e-12 1.3617638e-07 2.0088656e-16], sum to 1.0000
[2019-03-26 22:11:12,671] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6411
[2019-03-26 22:11:12,680] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2396932.287686975 W.
[2019-03-26 22:11:12,685] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.43333333333334, 72.66666666666667, 1.0, 2.0, 0.5713389842083196, 1.0, 1.0, 0.5713389842083196, 1.0, 2.0, 0.9922268708805294, 6.9112, 6.9112, 170.5573041426782, 2396932.287686975, 2396932.287686975, 467983.1171183062], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5563200.0000, 
sim time next is 5563800.0000, 
raw observation next is [30.65, 71.5, 1.0, 2.0, 0.5800839953926907, 1.0, 2.0, 0.5800839953926907, 1.0, 2.0, 1.007414063288391, 6.9112, 6.9112, 170.5573041426782, 2433655.864580902, 2433655.864580902, 474941.9809182647], 
processed observation next is [1.0, 0.391304347826087, 0.6516587677725119, 0.715, 1.0, 1.0, 0.4940771028827599, 1.0, 1.0, 0.4940771028827599, 1.0, 1.0, 1.0090415405955988, 0.0, 0.0, 0.8375144448122397, 0.6760155179391394, 0.6760155179391394, 0.708868628236216], 
reward next is 0.2911, 
noisyNet noise sample is [array([-0.31680956], dtype=float32), -1.382309]. 
=============================================
[2019-03-26 22:11:23,780] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4475394e-23 1.0000000e+00 1.6369017e-23 7.8506992e-18 1.0381244e-28], sum to 1.0000
[2019-03-26 22:11:23,789] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7089
[2019-03-26 22:11:23,795] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.56666666666667, 85.66666666666667, 1.0, 2.0, 0.5461227528156555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 763144.8483131959, 763144.8483131966, 191137.5523005457], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5781000.0000, 
sim time next is 5781600.0000, 
raw observation next is [27.5, 86.0, 1.0, 2.0, 0.5443056818944126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 760604.7878911024, 760604.7878911024, 190828.5858248018], 
processed observation next is [0.0, 0.9565217391304348, 0.5023696682464456, 0.86, 1.0, 1.0, 0.45097070107760556, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21127910774752845, 0.21127910774752845, 0.284818784813137], 
reward next is 0.7152, 
noisyNet noise sample is [array([-0.04899305], dtype=float32), -0.70703375]. 
=============================================
[2019-03-26 22:11:24,293] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1682048e-22 1.0000000e+00 6.6757089e-23 1.3002258e-17 4.6085669e-28], sum to 1.0000
[2019-03-26 22:11:24,305] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3741
[2019-03-26 22:11:24,311] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.63333333333333, 68.33333333333334, 1.0, 2.0, 0.5423444730103086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 757863.2456525544, 757863.2456525537, 190496.8040392407], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6261600.0000, 
sim time next is 6262200.0000, 
raw observation next is [30.65, 68.0, 1.0, 2.0, 0.5401834855089805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 754842.4443038256, 754842.444303825, 190131.8280194779], 
processed observation next is [0.0, 0.4782608695652174, 0.6516587677725119, 0.68, 1.0, 1.0, 0.44600419940841024, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20967845675106267, 0.2096784567510625, 0.2837788477902655], 
reward next is 0.7162, 
noisyNet noise sample is [array([-0.20155725], dtype=float32), -3.3312826]. 
=============================================
[2019-03-26 22:11:27,421] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.5560018e-10 7.6060134e-01 5.1052855e-09 2.3939864e-01 3.2294146e-13], sum to 1.0000
[2019-03-26 22:11:27,430] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3996
[2019-03-26 22:11:27,439] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2822173.14433741 W.
[2019-03-26 22:11:27,444] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.8, 61.33333333333334, 1.0, 2.0, 1.008879219582594, 1.0, 2.0, 1.008879219582594, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2822173.14433741, 2822173.144337409, 534371.8340842676], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5840400.0000, 
sim time next is 5841000.0000, 
raw observation next is [32.75, 61.5, 1.0, 2.0, 1.013839105825705, 1.0, 2.0, 1.013839105825705, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2836063.357470196, 2836063.357470196, 537401.9716163296], 
processed observation next is [1.0, 0.6086956521739131, 0.7511848341232228, 0.615, 1.0, 1.0, 1.016673621476753, 1.0, 1.0, 1.016673621476753, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7877953770750545, 0.7877953770750545, 0.8020924949497457], 
reward next is 0.1979, 
noisyNet noise sample is [array([-0.74679303], dtype=float32), 0.37520266]. 
=============================================
[2019-03-26 22:11:27,464] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[33.68851 ]
 [33.318764]
 [32.542526]
 [32.62756 ]
 [32.478203]], R is [[33.6191597 ]
 [33.48539734]
 [33.38203812]
 [33.04821777]
 [32.71773529]].
[2019-03-26 22:11:37,416] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.527509e-08 6.885882e-01 4.108519e-08 3.114117e-01 2.444990e-11], sum to 1.0000
[2019-03-26 22:11:37,423] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6372
[2019-03-26 22:11:37,431] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2530551.252034515 W.
[2019-03-26 22:11:37,437] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.06666666666667, 69.66666666666667, 1.0, 2.0, 0.9047347927479609, 1.0, 2.0, 0.9047347927479609, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2530551.252034515, 2530551.252034515, 474087.8185331955], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6002400.0000, 
sim time next is 6003000.0000, 
raw observation next is [32.3, 69.0, 1.0, 2.0, 0.9394663536776535, 1.0, 2.0, 0.9394663536776535, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2627797.892909547, 2627797.892909547, 493486.9063186105], 
processed observation next is [1.0, 0.4782608695652174, 0.7298578199052131, 0.69, 1.0, 1.0, 0.9270678959971729, 1.0, 1.0, 0.9270678959971729, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7299438591415408, 0.7299438591415408, 0.7365476213710604], 
reward next is 0.2635, 
noisyNet noise sample is [array([-2.438217], dtype=float32), 0.31099164]. 
=============================================
[2019-03-26 22:11:37,455] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[26.976778]
 [25.379103]
 [24.173538]
 [22.691938]
 [25.001606]], R is [[27.9852047 ]
 [27.99775887]
 [28.08623886]
 [28.19629478]
 [27.91433144]].
[2019-03-26 22:11:44,294] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 22:11:44,294] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 22:11:44,296] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:11:44,296] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 22:11:44,297] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:11:44,299] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 22:11:44,300] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:11:44,301] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 22:11:44,302] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 22:11:44,302] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:11:44,303] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:11:44,331] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run67
[2019-03-26 22:11:44,353] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run67
[2019-03-26 22:11:44,374] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run67
[2019-03-26 22:11:44,403] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run67
[2019-03-26 22:11:44,428] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run67
[2019-03-26 22:12:50,646] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08991908], dtype=float32), 0.065549254]
[2019-03-26 22:12:50,648] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [36.1, 49.0, 1.0, 2.0, 0.5825562974461744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 814076.1207493512, 814076.1207493518, 197541.3078331102]
[2019-03-26 22:12:50,649] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 22:12:50,652] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.9396987e-23 1.0000000e+00 1.0660267e-22 3.0580391e-17 3.3389205e-28], sampled 0.7620441368752682
[2019-03-26 22:13:38,102] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.5326 2927353024.3788 1338.0000
[2019-03-26 22:13:38,143] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.1242 2779271698.6099 933.0000
[2019-03-26 22:13:38,390] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7887.0961 3164613816.1288 1770.0000
[2019-03-26 22:13:38,501] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.4055 2842571954.9454 1130.0000
[2019-03-26 22:13:38,543] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.7844 3007681903.5972 1767.0000
[2019-03-26 22:13:39,558] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1650000, evaluation results [1650000.0, 7887.096052419623, 3164613816.1288023, 1770.0, 8253.532636977654, 2927353024.3787804, 1338.0, 8659.124182574536, 2779271698.6098742, 933.0, 7997.784391182439, 3007681903.597193, 1767.0, 8496.405526303377, 2842571954.945362, 1130.0]
[2019-03-26 22:13:41,006] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.7871624e-21 1.0000000e+00 4.9754335e-20 1.2968141e-15 2.2064141e-26], sum to 1.0000
[2019-03-26 22:13:41,014] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7224
[2019-03-26 22:13:41,020] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.98333333333333, 91.16666666666667, 1.0, 2.0, 0.7469134029996835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1043864.984662786, 1043864.984662787, 231295.574925382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6577800.0000, 
sim time next is 6578400.0000, 
raw observation next is [25.96666666666667, 91.33333333333334, 1.0, 2.0, 0.667947790105773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 933456.3819723948, 933456.3819723953, 214077.2668831671], 
processed observation next is [1.0, 0.13043478260869565, 0.42969984202211703, 0.9133333333333334, 1.0, 1.0, 0.5999370965129794, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25929343943677635, 0.25929343943677646, 0.3195183087808464], 
reward next is 0.6805, 
noisyNet noise sample is [array([2.2416048], dtype=float32), -0.22990257]. 
=============================================
[2019-03-26 22:13:49,101] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0459818e-22 1.0000000e+00 2.9360600e-22 4.1264360e-18 1.9650901e-28], sum to 1.0000
[2019-03-26 22:13:49,113] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5854
[2019-03-26 22:13:49,119] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.5298350651994064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 740376.7129195761, 740376.7129195761, 188403.1556072866], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6242400.0000, 
sim time next is 6243000.0000, 
raw observation next is [27.08333333333333, 88.66666666666667, 1.0, 2.0, 0.5321569294369884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 743622.3567934886, 743622.3567934886, 188788.2156474468], 
processed observation next is [0.0, 0.2608695652173913, 0.4826224328593995, 0.8866666666666667, 1.0, 1.0, 0.4363336499240824, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20656176577596905, 0.20656176577596905, 0.2817734561902191], 
reward next is 0.7182, 
noisyNet noise sample is [array([-0.3526878], dtype=float32), -0.12067712]. 
=============================================
[2019-03-26 22:13:49,132] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[73.0023  ]
 [72.96651 ]
 [72.94968 ]
 [72.92309 ]
 [72.899605]], R is [[73.02594757]
 [73.01449585]
 [73.00344086]
 [72.99269104]
 [72.98219299]].
[2019-03-26 22:13:56,684] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6339906e-20 1.0000000e+00 2.3383346e-20 2.0920649e-15 3.0516742e-26], sum to 1.0000
[2019-03-26 22:13:56,692] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3569
[2019-03-26 22:13:56,703] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1705302.974156371 W.
[2019-03-26 22:13:56,709] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.98333333333333, 83.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.265501844356185, 6.9112, 168.9277914762471, 1705302.974156371, 1453926.976207555, 311351.4192143306], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6401400.0000, 
sim time next is 6402000.0000, 
raw observation next is [26.96666666666667, 83.66666666666667, 1.0, 2.0, 0.5918914654421555, 1.0, 1.0, 0.5918914654421555, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1654884.886802249, 1654884.886802249, 331270.2683983257], 
processed observation next is [1.0, 0.08695652173913043, 0.47709320695102697, 0.8366666666666667, 1.0, 1.0, 0.5083029704122356, 1.0, 0.5, 0.5083029704122356, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.45969024633395805, 0.45969024633395805, 0.49443323641541154], 
reward next is 0.5056, 
noisyNet noise sample is [array([1.406347], dtype=float32), -0.20183721]. 
=============================================
[2019-03-26 22:13:56,722] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.94477]
 [69.63604]
 [69.89603]
 [70.12337]
 [70.39735]], R is [[65.0982132 ]
 [64.44723511]
 [64.52655029]
 [64.60487366]
 [64.68218994]].
[2019-03-26 22:14:03,048] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7498825e-20 1.0000000e+00 2.3074100e-20 4.0792234e-15 1.5117202e-26], sum to 1.0000
[2019-03-26 22:14:03,057] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8008
[2019-03-26 22:14:03,061] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 91.0, 1.0, 2.0, 0.6832307646945794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 954823.9250331098, 954823.9250331093, 217266.3017586991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6490800.0000, 
sim time next is 6491400.0000, 
raw observation next is [26.28333333333333, 91.16666666666667, 1.0, 2.0, 0.8330963961850133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1164377.92881062, 1164377.928810619, 252195.8502293417], 
processed observation next is [1.0, 0.13043478260869565, 0.4447077409162717, 0.9116666666666667, 1.0, 1.0, 0.7989113207048353, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.32343831355850555, 0.3234383135585053, 0.3764117167602115], 
reward next is 0.6236, 
noisyNet noise sample is [array([0.14566112], dtype=float32), -0.08126633]. 
=============================================
[2019-03-26 22:14:04,644] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.8607390e-11 9.9996114e-01 4.6072854e-11 3.8815779e-05 7.6267456e-15], sum to 1.0000
[2019-03-26 22:14:04,653] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7176
[2019-03-26 22:14:04,666] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1912926.065828003 W.
[2019-03-26 22:14:04,672] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.45, 61.5, 1.0, 2.0, 0.6841009982070816, 1.0, 2.0, 0.6841009982070816, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1912926.065828003, 1912926.065828003, 367383.3198827493], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6517800.0000, 
sim time next is 6518400.0000, 
raw observation next is [30.66666666666667, 60.0, 1.0, 2.0, 0.4638192348590555, 1.0, 2.0, 0.4638192348590555, 1.0, 1.0, 0.7865401503653565, 6.9112, 6.9112, 170.5573041426782, 1945470.120498616, 1945470.120498616, 387830.339570378], 
processed observation next is [1.0, 0.43478260869565216, 0.6524486571879939, 0.6, 1.0, 1.0, 0.35399907814344034, 1.0, 1.0, 0.35399907814344034, 1.0, 0.5, 0.7396831102016542, 0.0, 0.0, 0.8375144448122397, 0.5404083668051711, 0.5404083668051711, 0.5788512530901164], 
reward next is 0.4211, 
noisyNet noise sample is [array([1.2017313], dtype=float32), -0.633249]. 
=============================================
[2019-03-26 22:14:04,811] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6321649e-11 9.9999321e-01 3.0224528e-11 6.8234554e-06 8.6827281e-15], sum to 1.0000
[2019-03-26 22:14:04,820] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1657
[2019-03-26 22:14:04,829] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1844289.498541535 W.
[2019-03-26 22:14:04,836] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.36666666666667, 69.33333333333334, 1.0, 2.0, 0.4397175219531138, 1.0, 2.0, 0.4397175219531138, 1.0, 1.0, 0.7497949093688752, 6.911200000000001, 6.9112, 170.5573041426782, 1844289.498541535, 1844289.498541534, 373778.3284548083], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6514800.0000, 
sim time next is 6515400.0000, 
raw observation next is [29.58333333333334, 67.66666666666666, 1.0, 2.0, 0.7202738553216872, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.975086047516159, 6.9112, 168.9125758176708, 1903499.472585294, 1858176.613837283, 390170.9320646249], 
processed observation next is [1.0, 0.391304347826087, 0.6011058451816749, 0.6766666666666665, 1.0, 1.0, 0.662980548580346, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.006388604751615912, 0.0, 0.8294380757765683, 0.528749853495915, 0.5161601705103565, 0.5823446747233207], 
reward next is 0.0982, 
noisyNet noise sample is [array([0.29196125], dtype=float32), 1.3274767]. 
=============================================
[2019-03-26 22:14:10,912] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1289942e-22 1.0000000e+00 2.7209693e-22 4.6939861e-18 1.2189200e-27], sum to 1.0000
[2019-03-26 22:14:10,923] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0819
[2019-03-26 22:14:10,930] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 83.33333333333334, 1.0, 2.0, 0.3474344319468126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 538128.9982267176, 538128.9982267176, 169746.7032450415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6844800.0000, 
sim time next is 6845400.0000, 
raw observation next is [23.3, 83.0, 1.0, 2.0, 0.3493246992825027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 540260.4933673695, 540260.4933673688, 169899.2951815642], 
processed observation next is [0.0, 0.21739130434782608, 0.3033175355450238, 0.83, 1.0, 1.0, 0.21605385455723217, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15007235926871376, 0.15007235926871357, 0.2535810375844242], 
reward next is 0.7464, 
noisyNet noise sample is [array([0.1581994], dtype=float32), -1.7833438]. 
=============================================
[2019-03-26 22:14:15,943] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1712276e-20 1.0000000e+00 1.7949642e-20 6.9065110e-15 4.4273564e-26], sum to 1.0000
[2019-03-26 22:14:15,951] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1387
[2019-03-26 22:14:15,956] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1730548.414733676 W.
[2019-03-26 22:14:15,961] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.86666666666667, 86.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.301098715168418, 6.9112, 168.910803126166, 1730548.414733676, 1453944.373242454, 311349.028635154], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6684000.0000, 
sim time next is 6684600.0000, 
raw observation next is [27.03333333333333, 85.0, 1.0, 2.0, 0.3858068085302862, 1.0, 1.0, 0.3858068085302862, 1.0, 1.0, 0.6586689604086107, 6.9112, 6.9112, 170.5573041426782, 1618003.255834149, 1618003.255834149, 343636.0908204885], 
processed observation next is [1.0, 0.34782608695652173, 0.48025276461295413, 0.85, 1.0, 1.0, 0.2600082030485376, 1.0, 0.5, 0.2600082030485376, 1.0, 0.5, 0.5837426346446472, 0.0, 0.0, 0.8375144448122397, 0.44944534884281917, 0.44944534884281917, 0.5128896877917739], 
reward next is 0.4871, 
noisyNet noise sample is [array([0.24363582], dtype=float32), -0.4263143]. 
=============================================
[2019-03-26 22:14:16,350] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3765027e-22 1.0000000e+00 2.3757368e-21 3.6146674e-15 9.0332268e-28], sum to 1.0000
[2019-03-26 22:14:16,357] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2287
[2019-03-26 22:14:16,361] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.08333333333334, 67.33333333333334, 1.0, 2.0, 0.4045694827339936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 599843.3394211539, 599843.3394211545, 174411.3904310869], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6725400.0000, 
sim time next is 6726000.0000, 
raw observation next is [26.96666666666667, 67.66666666666667, 1.0, 2.0, 0.4013037451231862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 596171.6056717106, 596171.60567171, 174108.487279308], 
processed observation next is [1.0, 0.8695652173913043, 0.47709320695102697, 0.6766666666666667, 1.0, 1.0, 0.27867921099179055, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16560322379769737, 0.1656032237976972, 0.25986341384971345], 
reward next is 0.7401, 
noisyNet noise sample is [array([-0.99067044], dtype=float32), 0.25822315]. 
=============================================
[2019-03-26 22:14:16,371] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[74.55602]
 [74.50627]
 [74.13147]
 [74.36526]
 [74.22109]], R is [[73.87830353]
 [73.8792038 ]
 [73.87970734]
 [73.87979889]
 [73.87941742]].
[2019-03-26 22:14:20,337] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.99776209e-21 1.00000000e+00 1.11101665e-20 2.95536307e-16
 1.82854661e-26], sum to 1.0000
[2019-03-26 22:14:20,339] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7200
[2019-03-26 22:14:20,347] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.75, 83.16666666666667, 1.0, 2.0, 0.9417134402916928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1336893.568229379, 1336893.568229379, 284793.4860074467], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7006200.0000, 
sim time next is 7006800.0000, 
raw observation next is [25.7, 83.33333333333334, 1.0, 2.0, 0.9265981529351496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1316476.975238259, 1316476.97523826, 280564.3551477921], 
processed observation next is [1.0, 0.08695652173913043, 0.4170616113744076, 0.8333333333333335, 1.0, 1.0, 0.911564039680903, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.36568804867729415, 0.3656880486772945, 0.4187527688773016], 
reward next is 0.5812, 
noisyNet noise sample is [array([0.03832646], dtype=float32), -1.0356058]. 
=============================================
[2019-03-26 22:14:28,940] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5006755e-23 1.0000000e+00 1.7199205e-23 1.9101048e-18 6.9510507e-29], sum to 1.0000
[2019-03-26 22:14:28,949] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3812
[2019-03-26 22:14:28,955] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.35, 87.66666666666667, 1.0, 2.0, 0.4255335402604308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 622937.6104078983, 622937.6104078983, 176374.3481268774], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6922200.0000, 
sim time next is 6922800.0000, 
raw observation next is [24.3, 88.0, 1.0, 2.0, 0.4264785720800399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 624433.0313499692, 624433.0313499692, 176522.1464796], 
processed observation next is [0.0, 0.13043478260869565, 0.3507109004739337, 0.88, 1.0, 1.0, 0.309010327807277, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17345361981943588, 0.17345361981943588, 0.26346589026805967], 
reward next is 0.7365, 
noisyNet noise sample is [array([1.4803578], dtype=float32), -0.024935244]. 
=============================================
[2019-03-26 22:14:32,580] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2079659e-23 1.0000000e+00 4.8402781e-24 1.4232593e-18 3.4224305e-29], sum to 1.0000
[2019-03-26 22:14:32,588] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7249
[2019-03-26 22:14:32,593] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.96666666666667, 56.33333333333334, 1.0, 2.0, 0.3965311551739365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 591149.2877517611, 591149.2877517617, 173707.0568044419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6981600.0000, 
sim time next is 6982200.0000, 
raw observation next is [28.9, 56.0, 1.0, 2.0, 0.3939389622078006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 589670.6571792588, 589670.6571792588, 173642.7863888592], 
processed observation next is [0.0, 0.8260869565217391, 0.5687203791469194, 0.56, 1.0, 1.0, 0.2698059785636152, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16379740477201632, 0.16379740477201632, 0.2591683378938197], 
reward next is 0.7408, 
noisyNet noise sample is [array([0.39717358], dtype=float32), 1.1103117]. 
=============================================
[2019-03-26 22:14:34,097] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.63261820e-22 1.00000000e+00 1.17148424e-23 3.02220156e-19
 6.78645652e-29], sum to 1.0000
[2019-03-26 22:14:34,107] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5404
[2019-03-26 22:14:34,112] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 87.5, 1.0, 2.0, 0.3702539983969875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 560811.1609256746, 560811.1609256753, 171284.7669868701], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7469400.0000, 
sim time next is 7470000.0000, 
raw observation next is [23.5, 87.0, 1.0, 2.0, 0.3709798392562047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 561317.5032886798, 561317.5032886798, 171309.6733639968], 
processed observation next is [0.0, 0.4782608695652174, 0.31279620853080575, 0.87, 1.0, 1.0, 0.24214438464602975, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15592152869129994, 0.15592152869129994, 0.2556860796477564], 
reward next is 0.7443, 
noisyNet noise sample is [array([0.8932763], dtype=float32), -2.3899508]. 
=============================================
[2019-03-26 22:14:34,124] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[76.12986 ]
 [76.119125]
 [76.098564]
 [76.07961 ]
 [76.05484 ]], R is [[76.14241028]
 [76.12534332]
 [76.10865021]
 [76.09254456]
 [76.07693481]].
[2019-03-26 22:14:35,615] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 22:14:35,616] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 22:14:35,617] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:14:35,618] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 22:14:35,619] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:14:35,619] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 22:14:35,620] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 22:14:35,620] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:14:35,621] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 22:14:35,622] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:14:35,622] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:14:35,653] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run68
[2019-03-26 22:14:35,678] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run68
[2019-03-26 22:14:35,679] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run68
[2019-03-26 22:14:35,728] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run68
[2019-03-26 22:14:35,728] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run68
[2019-03-26 22:14:45,504] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09273755], dtype=float32), 0.06801161]
[2019-03-26 22:14:45,506] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [17.2502648, 83.85968898, 1.0, 2.0, 0.214414226960698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 358667.3259652355, 358667.3259652362, 143243.4424613777]
[2019-03-26 22:14:45,506] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:14:45,513] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.3711055e-21 1.0000000e+00 1.7143544e-21 4.7054963e-18 3.6634115e-27], sampled 0.9140788446169352
[2019-03-26 22:14:48,346] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09273755], dtype=float32), 0.06801161]
[2019-03-26 22:14:48,347] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.7, 95.0, 1.0, 2.0, 0.4476615701874979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 647203.3836629156, 647203.3836629156, 178575.5845857306]
[2019-03-26 22:14:48,349] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:14:48,351] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.3157118e-23 1.0000000e+00 8.7763262e-23 2.0536725e-18 1.2581159e-28], sampled 0.4713061277593319
[2019-03-26 22:14:57,861] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09273755], dtype=float32), 0.06801161]
[2019-03-26 22:14:57,861] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.07499696333333, 89.08467346666667, 1.0, 2.0, 0.5987593433017417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 836727.5079952191, 836727.5079952191, 200516.0932558676]
[2019-03-26 22:14:57,861] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:14:57,864] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.2010002e-23 1.0000000e+00 7.1434902e-23 2.3754323e-18 9.7807395e-29], sampled 0.04729022360526314
[2019-03-26 22:15:10,658] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09273755], dtype=float32), 0.06801161]
[2019-03-26 22:15:10,660] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.5, 82.0, 1.0, 2.0, 0.7319434201240673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1022933.284611925, 1022933.284611925, 227889.9815868014]
[2019-03-26 22:15:10,660] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 22:15:10,663] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.3043377e-22 1.0000000e+00 2.9188846e-22 2.0633479e-17 4.3299758e-28], sampled 0.2588857157291168
[2019-03-26 22:15:20,975] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09273755], dtype=float32), 0.06801161]
[2019-03-26 22:15:20,976] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.03333333333333, 89.0, 1.0, 2.0, 0.7617248266697525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1064575.386199375, 1064575.386199375, 234730.2795973564]
[2019-03-26 22:15:20,976] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:15:20,979] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.5740993e-22 1.0000000e+00 3.0791251e-22 1.7720867e-17 4.3607243e-28], sampled 0.44203032119118
[2019-03-26 22:15:38,497] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09273755], dtype=float32), 0.06801161]
[2019-03-26 22:15:38,498] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.3, 52.0, 1.0, 2.0, 0.6144727393754541, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.953338381558265, 6.9112, 168.9125983321593, 1718084.484733325, 1688190.129955547, 367268.7876229808]
[2019-03-26 22:15:38,499] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 22:15:38,502] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.1875004e-18 1.0000000e+00 9.9025017e-19 2.3822261e-13 2.4687430e-23], sampled 0.5580634250465798
[2019-03-26 22:15:38,502] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1718084.484733325 W.
[2019-03-26 22:16:19,964] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09273755], dtype=float32), 0.06801161]
[2019-03-26 22:16:19,965] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.33333333333334, 82.66666666666667, 1.0, 2.0, 0.8681887734308952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1301619.070462619, 1301619.070462619, 273715.6453515966]
[2019-03-26 22:16:19,966] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 22:16:19,969] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.1118455e-22 1.0000000e+00 1.4199979e-21 1.5460972e-15 1.3033178e-27], sampled 0.9834132476809574
[2019-03-26 22:16:21,552] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09273755], dtype=float32), 0.06801161]
[2019-03-26 22:16:21,553] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.91601996666667, 55.14084800333333, 1.0, 2.0, 0.785065403494147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1181802.102680295, 1181802.102680295, 251610.7480461321]
[2019-03-26 22:16:21,555] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:16:21,558] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.7524969e-22 1.0000000e+00 6.0274153e-22 3.4126087e-17 1.5288274e-27], sampled 0.5548725392730939
[2019-03-26 22:16:27,792] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09273755], dtype=float32), 0.06801161]
[2019-03-26 22:16:27,793] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.18180538, 88.79869817666668, 1.0, 2.0, 0.6183631467419766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 864133.7013306, 864133.7013306, 204208.9198499556]
[2019-03-26 22:16:27,795] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:16:27,800] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.02807029e-22 1.00000000e+00 1.60914725e-22 1.17979795e-17
 2.39717635e-28], sampled 0.7844717878297891
[2019-03-26 22:16:29,587] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.3866 3164623742.8994 1774.0000
[2019-03-26 22:16:29,626] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.0126 2779406083.8403 933.0000
[2019-03-26 22:16:29,762] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5749 3007726976.5989 1766.0000
[2019-03-26 22:16:29,865] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.9539 2842422930.9718 1129.0000
[2019-03-26 22:16:29,873] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.9689 2927381913.5140 1338.0000
[2019-03-26 22:16:30,890] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1675000, evaluation results [1675000.0, 7881.3865632717925, 3164623742.8994055, 1774.0, 8254.968948333817, 2927381913.5140486, 1338.0, 8659.012586091692, 2779406083.8403068, 933.0, 7997.574940102971, 3007726976.5988917, 1766.0, 8497.9538964201, 2842422930.9718328, 1129.0]
[2019-03-26 22:16:32,656] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.9869082e-23 1.0000000e+00 2.1625048e-22 8.6008261e-17 4.0705363e-29], sum to 1.0000
[2019-03-26 22:16:32,665] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7913
[2019-03-26 22:16:32,672] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 85.16666666666667, 1.0, 2.0, 0.4700283661630038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 660954.2044177856, 660954.2044177856, 179572.3700062473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7168200.0000, 
sim time next is 7168800.0000, 
raw observation next is [25.7, 85.33333333333334, 1.0, 2.0, 0.47042891901864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 660837.6376088744, 660837.637608875, 179544.4242401823], 
processed observation next is [1.0, 1.0, 0.4170616113744076, 0.8533333333333334, 1.0, 1.0, 0.36196255303450603, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18356601044690954, 0.18356601044690973, 0.26797675259728704], 
reward next is 0.7320, 
noisyNet noise sample is [array([-0.98758006], dtype=float32), 0.7146812]. 
=============================================
[2019-03-26 22:16:34,403] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0544124e-20 1.0000000e+00 1.7633985e-20 1.7867358e-16 6.1765794e-26], sum to 1.0000
[2019-03-26 22:16:34,410] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0243
[2019-03-26 22:16:34,416] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 88.0, 1.0, 2.0, 0.5245874467852158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 747102.4655124333, 747102.4655124326, 189334.376211013], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7106400.0000, 
sim time next is 7107000.0000, 
raw observation next is [25.16666666666667, 86.83333333333334, 1.0, 2.0, 0.5273177890111737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 750799.7312878647, 750799.7312878647, 189768.2273237901], 
processed observation next is [1.0, 0.2608695652173913, 0.39178515007898923, 0.8683333333333334, 1.0, 1.0, 0.43050336025442604, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20855548091329576, 0.20855548091329576, 0.28323616018476133], 
reward next is 0.7168, 
noisyNet noise sample is [array([0.1495852], dtype=float32), -1.7246063]. 
=============================================
[2019-03-26 22:16:34,435] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[70.024765]
 [70.059845]
 [70.12462 ]
 [70.011375]
 [70.0836  ]], R is [[70.02655792]
 [70.0437088 ]
 [70.06082153]
 [70.07680511]
 [70.0920105 ]].
[2019-03-26 22:16:37,012] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8950410e-22 1.0000000e+00 4.6524406e-22 5.2179813e-16 4.4195561e-28], sum to 1.0000
[2019-03-26 22:16:37,020] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1418
[2019-03-26 22:16:37,026] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.47720091044263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 666986.696240317, 666986.696240317, 180124.2261184937], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7160400.0000, 
sim time next is 7161000.0000, 
raw observation next is [25.96666666666667, 84.0, 1.0, 2.0, 0.4793260540578593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 670566.7363261781, 670566.7363261781, 180522.1158581421], 
processed observation next is [1.0, 0.9130434782608695, 0.42969984202211703, 0.84, 1.0, 1.0, 0.37268199284079434, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1862685378683828, 0.1862685378683828, 0.2694359938181225], 
reward next is 0.7306, 
noisyNet noise sample is [array([-0.47273433], dtype=float32), 0.050800942]. 
=============================================
[2019-03-26 22:16:37,040] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[73.84017 ]
 [74.02708 ]
 [74.40924 ]
 [75.02358 ]
 [75.175476]], R is [[73.75583649]
 [73.74943542]
 [73.74334717]
 [73.73729706]
 [73.73123932]].
[2019-03-26 22:16:39,920] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.52536296e-21 1.00000000e+00 1.00910235e-20 4.54178643e-16
 5.49364468e-27], sum to 1.0000
[2019-03-26 22:16:39,932] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6064
[2019-03-26 22:16:39,937] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 86.5, 1.0, 2.0, 0.4774513151191754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 667154.1380232745, 667154.1380232745, 180138.4992762489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7176600.0000, 
sim time next is 7177200.0000, 
raw observation next is [25.8, 86.66666666666667, 1.0, 2.0, 0.4781715024161082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 668160.789432546, 668160.7894325453, 180246.6167092501], 
processed observation next is [1.0, 0.043478260869565216, 0.42180094786729866, 0.8666666666666667, 1.0, 1.0, 0.37129096676639534, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18560021928681833, 0.18560021928681814, 0.26902480105858223], 
reward next is 0.7310, 
noisyNet noise sample is [array([1.1204498], dtype=float32), 0.8149353]. 
=============================================
[2019-03-26 22:16:41,963] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1856744e-21 1.0000000e+00 2.7344563e-21 1.9104418e-16 2.0486398e-27], sum to 1.0000
[2019-03-26 22:16:41,970] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8466
[2019-03-26 22:16:41,977] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.05, 71.5, 1.0, 2.0, 0.391417254083236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 587086.5493565543, 587086.549356555, 173442.4740356298], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7327800.0000, 
sim time next is 7328400.0000, 
raw observation next is [25.96666666666667, 72.0, 1.0, 2.0, 0.3904936106291216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 585732.4335577345, 585732.4335577345, 173320.3874318259], 
processed observation next is [1.0, 0.8260869565217391, 0.42969984202211703, 0.72, 1.0, 1.0, 0.2656549525652067, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16270345376603734, 0.16270345376603734, 0.25868714542063564], 
reward next is 0.7413, 
noisyNet noise sample is [array([1.1099235], dtype=float32), -0.68504244]. 
=============================================
[2019-03-26 22:16:44,400] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5818878e-21 1.0000000e+00 3.7629516e-21 2.1385071e-17 4.6458665e-27], sum to 1.0000
[2019-03-26 22:16:44,408] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5072
[2019-03-26 22:16:44,412] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.53333333333333, 90.33333333333334, 1.0, 2.0, 0.3292589459520169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 519536.0258597115, 519536.0258597108, 168494.1916162801], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7273200.0000, 
sim time next is 7273800.0000, 
raw observation next is [21.5, 90.5, 1.0, 2.0, 0.335819451357793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 530053.8533534574, 530053.8533534574, 169321.492985033], 
processed observation next is [1.0, 0.17391304347826086, 0.21800947867298584, 0.905, 1.0, 1.0, 0.19978247151541326, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1472371814870715, 0.1472371814870715, 0.2527186462463179], 
reward next is 0.7473, 
noisyNet noise sample is [array([0.10534642], dtype=float32), 0.115621164]. 
=============================================
[2019-03-26 22:16:44,774] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8521297e-21 1.0000000e+00 2.3795007e-21 7.6464946e-17 1.6338299e-26], sum to 1.0000
[2019-03-26 22:16:44,785] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5334
[2019-03-26 22:16:44,794] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.93333333333333, 88.33333333333334, 1.0, 2.0, 0.3261194198805615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 512668.71813455, 512668.71813455, 167924.1603654595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7263600.0000, 
sim time next is 7264200.0000, 
raw observation next is [21.91666666666666, 88.16666666666667, 1.0, 2.0, 0.325042031924003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 511445.2175434159, 511445.2175434153, 167840.525070873], 
processed observation next is [1.0, 0.043478260869565216, 0.23775671406003138, 0.8816666666666667, 1.0, 1.0, 0.18679762882409998, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1420681159842822, 0.14206811598428204, 0.2505082463744373], 
reward next is 0.7495, 
noisyNet noise sample is [array([-0.74072814], dtype=float32), 1.9783618]. 
=============================================
[2019-03-26 22:16:48,410] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4737103e-22 1.0000000e+00 1.6599613e-22 9.3024020e-18 1.0612276e-28], sum to 1.0000
[2019-03-26 22:16:48,421] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5560
[2019-03-26 22:16:48,425] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.36666666666667, 91.33333333333334, 1.0, 2.0, 0.3131527610906916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 494711.8894483713, 494711.8894483713, 166621.4210507116], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7438800.0000, 
sim time next is 7439400.0000, 
raw observation next is [21.35, 91.5, 1.0, 2.0, 0.3133050122001033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 494907.9830848176, 494907.983084817, 166635.0146898113], 
processed observation next is [0.0, 0.08695652173913043, 0.2109004739336494, 0.915, 1.0, 1.0, 0.17265664120494376, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13747443974578266, 0.1374744397457825, 0.24870897714897208], 
reward next is 0.7513, 
noisyNet noise sample is [array([1.6497004], dtype=float32), -1.6359241]. 
=============================================
[2019-03-26 22:16:50,782] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:16:50,783] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:16:50,876] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run9
[2019-03-26 22:16:56,156] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:16:56,157] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:16:56,237] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run9
[2019-03-26 22:16:58,598] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:16:58,600] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:16:58,676] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run9
[2019-03-26 22:17:09,052] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:17:09,052] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:17:09,133] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run9
[2019-03-26 22:17:11,868] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:17:11,870] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:17:11,943] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run9
[2019-03-26 22:17:18,193] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:17:18,193] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:17:18,274] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run9
[2019-03-26 22:17:20,764] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.0954863e-13 9.9734700e-01 4.6698912e-12 2.6529331e-03 1.4186404e-16], sum to 1.0000
[2019-03-26 22:17:20,770] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4098
[2019-03-26 22:17:20,773] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.46666666666667, 64.0, 1.0, 2.0, 0.4709581770231792, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129564979474, 658078.3106320441, 658078.3106320435, 179173.2280101282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7924800.0000, 
sim time next is 7925400.0000, 
raw observation next is [30.3, 65.0, 1.0, 2.0, 0.4647916601146905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104279, 649459.0919858422, 649459.0919858416, 178266.1467571481], 
processed observation next is [1.0, 0.7391304347826086, 0.6350710900473934, 0.65, 1.0, 1.0, 0.3551706748369765, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451522875, 0.1804053033294006, 0.18040530332940044, 0.26606887575693744], 
reward next is 0.7339, 
noisyNet noise sample is [array([-0.9951188], dtype=float32), 0.5309573]. 
=============================================
[2019-03-26 22:17:22,379] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:17:22,379] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:17:22,441] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run9
[2019-03-26 22:17:23,008] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:17:23,010] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:17:23,064] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run9
[2019-03-26 22:17:23,108] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:17:23,109] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:17:23,184] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run9
[2019-03-26 22:17:23,211] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:17:23,211] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:17:23,256] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run9
[2019-03-26 22:17:23,884] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:17:23,885] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:17:23,887] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:17:23,887] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:17:23,896] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:17:23,896] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:17:23,926] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run9
[2019-03-26 22:17:23,947] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run9
[2019-03-26 22:17:23,998] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run9
[2019-03-26 22:17:24,117] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:17:24,117] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:17:24,129] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run9
[2019-03-26 22:17:24,212] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:17:24,213] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:17:24,222] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run9
[2019-03-26 22:17:24,313] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:17:24,314] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:17:24,318] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run9
[2019-03-26 22:17:24,415] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6117784e-20 1.0000000e+00 5.0266754e-20 1.4015969e-15 4.4667298e-26], sum to 1.0000
[2019-03-26 22:17:24,418] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4905
[2019-03-26 22:17:24,420] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 64.66666666666667, 1.0, 2.0, 0.8976294841334724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1359017.294545552, 1359017.294545552, 284035.0235331982], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 43800.0000, 
sim time next is 44400.0000, 
raw observation next is [27.0, 64.33333333333334, 1.0, 2.0, 0.8970109981965372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1356564.801339249, 1356564.80133925, 283653.159163759], 
processed observation next is [1.0, 0.5217391304347826, 0.4786729857819906, 0.6433333333333334, 1.0, 1.0, 0.8759168652970327, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.37682355592756916, 0.37682355592756944, 0.4233629241250134], 
reward next is 0.5766, 
noisyNet noise sample is [array([0.3864015], dtype=float32), -2.6615074]. 
=============================================
[2019-03-26 22:17:24,685] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 22:17:24,686] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 22:17:24,687] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:17:24,688] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 22:17:24,690] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 22:17:24,692] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:17:24,690] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 22:17:24,692] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 22:17:24,691] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:17:24,693] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:17:24,693] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:17:24,704] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run69
[2019-03-26 22:17:24,727] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run69
[2019-03-26 22:17:24,754] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run69
[2019-03-26 22:17:24,773] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run69
[2019-03-26 22:17:24,795] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run69
[2019-03-26 22:17:26,687] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09390739], dtype=float32), 0.06943532]
[2019-03-26 22:17:26,691] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.61410956333334, 95.92950079333335, 1.0, 2.0, 0.4016404904233566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 602354.8417218444, 602354.8417218444, 174836.5488905287]
[2019-03-26 22:17:26,693] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:17:26,696] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.8373273e-24 1.0000000e+00 1.7301597e-23 2.1155758e-18 1.2273641e-29], sampled 0.8819247601427409
[2019-03-26 22:17:45,684] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09390739], dtype=float32), 0.06943532]
[2019-03-26 22:17:45,685] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.67210744833334, 92.19572924333332, 1.0, 2.0, 0.610184660427146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 894737.9137649698, 894737.9137649698, 208014.555978471]
[2019-03-26 22:17:45,686] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:17:45,691] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.8164584e-23 1.0000000e+00 1.5192213e-22 8.2108446e-18 1.2683510e-28], sampled 0.778171195434938
[2019-03-26 22:17:53,975] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09390739], dtype=float32), 0.06943532]
[2019-03-26 22:17:53,977] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.39994987666667, 82.63028185666667, 1.0, 2.0, 0.7656792728122052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1070104.846510122, 1070104.846510122, 235664.7168045272]
[2019-03-26 22:17:53,978] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:17:53,981] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.02750565e-22 1.00000000e+00 1.94994501e-22 1.10513861e-17
 2.10559778e-28], sampled 0.5832403304043907
[2019-03-26 22:17:59,901] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09390739], dtype=float32), 0.06943532]
[2019-03-26 22:17:59,901] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.0, 91.0, 1.0, 2.0, 0.3857049050178095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 582749.4328306179, 582749.4328306186, 173174.5009412983]
[2019-03-26 22:17:59,902] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:17:59,905] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9289214e-23 1.0000000e+00 2.2009545e-22 6.0738905e-18 2.2563413e-28], sampled 0.8543344844006271
[2019-03-26 22:18:04,615] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09390739], dtype=float32), 0.06943532]
[2019-03-26 22:18:04,615] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.05065925, 90.12126113333333, 1.0, 2.0, 0.3862905440248603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 585183.1422095428, 585183.1422095422, 173436.5695994786]
[2019-03-26 22:18:04,616] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:18:04,618] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.2986324e-24 1.0000000e+00 1.0106032e-23 1.1264364e-18 7.3550287e-30], sampled 0.15010828736125936
[2019-03-26 22:18:10,398] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09390739], dtype=float32), 0.06943532]
[2019-03-26 22:18:10,400] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.38532758, 83.83300265, 1.0, 2.0, 0.4744434852354214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 682609.0964100312, 682609.0964100305, 182195.5404471035]
[2019-03-26 22:18:10,400] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:18:10,403] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.5180618e-23 1.0000000e+00 1.0101412e-22 2.8712159e-18 9.4319873e-29], sampled 0.3877052276834714
[2019-03-26 22:18:26,547] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09390739], dtype=float32), 0.06943532]
[2019-03-26 22:18:26,547] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [35.29107268333333, 48.42760082333334, 1.0, 2.0, 0.8291514586838207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1158861.274543062, 1158861.274543062, 251193.6119589263]
[2019-03-26 22:18:26,550] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:18:26,553] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.9277053e-22 1.0000000e+00 4.9168254e-22 4.5033317e-16 4.8845247e-28], sampled 0.17935697294774766
[2019-03-26 22:18:27,474] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09390739], dtype=float32), 0.06943532]
[2019-03-26 22:18:27,476] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 75.0, 1.0, 2.0, 0.5980822105192695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 835780.8863707257, 835780.8863707257, 200389.3920534862]
[2019-03-26 22:18:27,478] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 22:18:27,481] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.2267677e-23 1.0000000e+00 1.2683114e-22 2.8929530e-17 1.5524283e-28], sampled 0.7347779671865867
[2019-03-26 22:19:18,841] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3694 2779190338.1949 933.0000
[2019-03-26 22:19:18,941] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.8598 3164259763.8168 1770.0000
[2019-03-26 22:19:19,079] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8251.0289 2927698692.6496 1338.0000
[2019-03-26 22:19:19,119] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8498.0006 2842470179.5226 1128.0000
[2019-03-26 22:19:19,228] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7995.9835 3007874557.2984 1767.0000
[2019-03-26 22:19:20,248] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1700000, evaluation results [1700000.0, 7884.859767623915, 3164259763.816764, 1770.0, 8251.028904966946, 2927698692.649572, 1338.0, 8661.369356548688, 2779190338.194891, 933.0, 7995.98349968604, 3007874557.2983603, 1767.0, 8498.000642656503, 2842470179.5225863, 1128.0]
[2019-03-26 22:19:20,712] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.69036165e-11 1.00000000e+00 1.05825793e-10 4.12437160e-08
 1.05359386e-13], sum to 1.0000
[2019-03-26 22:19:20,722] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2301
[2019-03-26 22:19:20,731] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.73333333333333, 85.0, 1.0, 2.0, 0.3190807445669293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 518586.0455341383, 518586.0455341383, 168404.7934584605], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 8400.0000, 
sim time next is 9000.0000, 
raw observation next is [20.8, 85.0, 1.0, 2.0, 0.2933257951861842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 476224.7608408195, 476224.7608408201, 165353.8095583324], 
processed observation next is [1.0, 0.08695652173913043, 0.1848341232227489, 0.85, 1.0, 1.0, 0.14858529540504117, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13228465578911652, 0.1322846557891167, 0.2467967306840782], 
reward next is 0.7532, 
noisyNet noise sample is [array([0.80195767], dtype=float32), -0.38037127]. 
=============================================
[2019-03-26 22:19:20,753] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[36.532074]
 [33.31102 ]
 [30.354412]
 [27.14977 ]
 [24.006731]], R is [[40.66527557]
 [41.00727463]
 [41.33476257]
 [41.67833328]
 [42.01873779]].
[2019-03-26 22:19:37,726] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5255625e-23 1.0000000e+00 1.6765380e-23 1.0592673e-18 2.5437033e-29], sum to 1.0000
[2019-03-26 22:19:37,732] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5909
[2019-03-26 22:19:37,738] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.23333333333333, 82.33333333333334, 1.0, 2.0, 0.2981145243526388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 474091.621026023, 474091.6210260236, 165190.2972076315], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 291000.0000, 
sim time next is 291600.0000, 
raw observation next is [22.3, 82.0, 1.0, 2.0, 0.2994262534653076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 475955.9677280707, 475955.9677280707, 165318.6499212074], 
processed observation next is [0.0, 0.391304347826087, 0.25592417061611383, 0.82, 1.0, 1.0, 0.15593524513892482, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13220999103557518, 0.13220999103557518, 0.2467442536137424], 
reward next is 0.7533, 
noisyNet noise sample is [array([0.3882202], dtype=float32), -0.9545531]. 
=============================================
[2019-03-26 22:19:41,975] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.4073042e-23 1.0000000e+00 1.2788100e-22 9.8374837e-18 1.8254643e-28], sum to 1.0000
[2019-03-26 22:19:41,983] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0269
[2019-03-26 22:19:41,988] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.26666666666667, 85.33333333333334, 1.0, 2.0, 0.2412295990922571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 399198.2861125637, 399198.2861125631, 159946.3948381975], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 685200.0000, 
sim time next is 685800.0000, 
raw observation next is [19.15, 86.0, 1.0, 2.0, 0.2397723131639538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 396925.4472254777, 396925.4472254771, 159795.9672190154], 
processed observation next is [1.0, 0.9565217391304348, 0.10663507109004738, 0.86, 1.0, 1.0, 0.08406302790837808, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11025706867374381, 0.11025706867374363, 0.23850144361047076], 
reward next is 0.7615, 
noisyNet noise sample is [array([-1.6397448], dtype=float32), -1.2510031]. 
=============================================
[2019-03-26 22:19:51,847] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.64752922e-21 1.00000000e+00 3.68360167e-21 1.50561513e-17
 1.55690665e-27], sum to 1.0000
[2019-03-26 22:19:51,857] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4316
[2019-03-26 22:19:51,867] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.03333333333333, 89.66666666666667, 1.0, 2.0, 0.2186143000393094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 363966.4045390229, 363966.4045390223, 157534.2777165281], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 531600.0000, 
sim time next is 532200.0000, 
raw observation next is [17.96666666666667, 89.83333333333333, 1.0, 2.0, 0.2167860746051304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 361039.2437686982, 361039.2437686975, 157344.371889368], 
processed observation next is [1.0, 0.13043478260869565, 0.050552922590837435, 0.8983333333333333, 1.0, 1.0, 0.05636876458449446, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10028867882463839, 0.1002886788246382, 0.23484234610353433], 
reward next is 0.7652, 
noisyNet noise sample is [array([0.2500158], dtype=float32), -0.25753692]. 
=============================================
[2019-03-26 22:20:07,389] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.3093838e-22 1.0000000e+00 2.7272668e-22 2.4897559e-17 2.8633152e-28], sum to 1.0000
[2019-03-26 22:20:07,399] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5067
[2019-03-26 22:20:07,404] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.3, 96.33333333333333, 1.0, 2.0, 0.397315129270448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 600258.6993975863, 600258.6993975863, 174760.7903989587], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1045200.0000, 
sim time next is 1045800.0000, 
raw observation next is [22.15, 96.5, 1.0, 2.0, 0.3606971938124785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 547255.1984593577, 547255.1984593577, 170157.3581204329], 
processed observation next is [1.0, 0.08695652173913043, 0.24881516587677724, 0.965, 1.0, 1.0, 0.22975565519575722, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15201533290537714, 0.15201533290537714, 0.25396620614989984], 
reward next is 0.7460, 
noisyNet noise sample is [array([-0.6913031], dtype=float32), -0.55322826]. 
=============================================
[2019-03-26 22:20:16,157] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-26 22:20:16,158] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 22:20:16,159] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:20:16,159] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 22:20:16,160] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:20:16,161] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 22:20:16,161] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:20:16,162] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 22:20:16,163] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 22:20:16,163] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:20:16,164] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:20:16,192] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run70
[2019-03-26 22:20:16,215] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run70
[2019-03-26 22:20:16,238] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run70
[2019-03-26 22:20:16,239] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run70
[2019-03-26 22:20:16,258] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run70
[2019-03-26 22:20:22,889] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09566963], dtype=float32), 0.07116183]
[2019-03-26 22:20:22,891] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [19.25, 90.83333333333334, 1.0, 2.0, 0.2716057200672557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 446133.4845504289, 446133.4845504289, 163119.1214777974]
[2019-03-26 22:20:22,893] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:20:22,896] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.23657426e-23 1.00000000e+00 2.63885285e-23 5.61843458e-19
 1.83031640e-29], sampled 0.8339850539379701
[2019-03-26 22:20:30,417] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09566963], dtype=float32), 0.07116183]
[2019-03-26 22:20:30,418] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.73333333333333, 61.33333333333333, 1.0, 2.0, 0.3513243236264468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 542989.8915561023, 542989.8915561023, 170113.7572102077]
[2019-03-26 22:20:30,420] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:20:30,423] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.3906886e-24 1.0000000e+00 1.9323574e-23 6.6489605e-19 1.7163824e-29], sampled 0.6070282963210109
[2019-03-26 22:21:19,930] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09566963], dtype=float32), 0.07116183]
[2019-03-26 22:21:19,932] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [39.42456641, 52.43538419, 1.0, 2.0, 0.9785007131966523, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005992239661269, 6.9112, 168.9122619932886, 2264910.23676405, 2197661.635957551, 456820.9466408312]
[2019-03-26 22:21:19,933] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:21:19,935] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.5648319e-14 9.9999928e-01 1.9514483e-13 7.5631533e-07 2.8209582e-18], sampled 0.5233073975161645
[2019-03-26 22:21:19,936] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2264910.23676405 W.
[2019-03-26 22:22:05,967] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8492.9671 2842730205.6672 1131.0000
[2019-03-26 22:22:06,267] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.6426 3164444746.0886 1774.0000
[2019-03-26 22:22:06,302] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.2899 2927407109.7953 1338.0000
[2019-03-26 22:22:06,328] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.2711 2779256177.9474 933.0000
[2019-03-26 22:22:06,436] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.8607 3007667373.4616 1765.0000
[2019-03-26 22:22:07,454] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1725000, evaluation results [1725000.0, 7881.642642843324, 3164444746.0885677, 1774.0, 8254.289933546808, 2927407109.795325, 1338.0, 8661.271088261434, 2779256177.947352, 933.0, 7998.860733221719, 3007667373.4616113, 1765.0, 8492.96705217117, 2842730205.667166, 1131.0]
[2019-03-26 22:22:21,730] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.4379671e-23 1.0000000e+00 8.7478520e-22 3.3488522e-16 2.9063872e-28], sum to 1.0000
[2019-03-26 22:22:21,739] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0752
[2019-03-26 22:22:21,743] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 58.66666666666667, 1.0, 2.0, 0.3293212876343562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 508207.406258325, 508207.4062583257, 167303.9016481442], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1185600.0000, 
sim time next is 1186200.0000, 
raw observation next is [27.15, 59.5, 1.0, 2.0, 0.3250169273635997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 501528.1998844551, 501528.1998844551, 166786.9665317235], 
processed observation next is [1.0, 0.7391304347826086, 0.485781990521327, 0.595, 1.0, 1.0, 0.18676738236578277, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1393133888567931, 0.1393133888567931, 0.2489357709428709], 
reward next is 0.7511, 
noisyNet noise sample is [array([1.280828], dtype=float32), -0.59774894]. 
=============================================
[2019-03-26 22:22:24,633] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1252696e-23 1.0000000e+00 1.3463861e-23 2.9200489e-18 3.3287701e-29], sum to 1.0000
[2019-03-26 22:22:24,641] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5359
[2019-03-26 22:22:24,649] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 96.33333333333333, 1.0, 2.0, 0.3344182530572016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 521447.604229324, 521447.6042293247, 168504.2985355485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1477200.0000, 
sim time next is 1477800.0000, 
raw observation next is [21.2, 96.5, 1.0, 2.0, 0.333327726455469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 520395.3048499784, 520395.3048499784, 168438.5593902614], 
processed observation next is [0.0, 0.08695652173913043, 0.20379146919431282, 0.965, 1.0, 1.0, 0.19678039331984215, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14455425134721622, 0.14455425134721622, 0.2514008349108379], 
reward next is 0.7486, 
noisyNet noise sample is [array([0.4499201], dtype=float32), -0.028216109]. 
=============================================
[2019-03-26 22:22:25,317] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.6725149e-25 1.0000000e+00 6.2610143e-24 1.7915721e-19 4.3451278e-30], sum to 1.0000
[2019-03-26 22:22:25,327] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3586
[2019-03-26 22:22:25,331] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 91.0, 1.0, 2.0, 0.330860947632158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 517485.2521073253, 517485.2521073253, 168234.9311779943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1557000.0000, 
sim time next is 1557600.0000, 
raw observation next is [21.76666666666667, 91.0, 1.0, 2.0, 0.3298331534031852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 516317.0468404786, 516317.0468404786, 168154.9518577245], 
processed observation next is [1.0, 0.0, 0.23064770932069528, 0.91, 1.0, 1.0, 0.19257006434118698, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14342140190013294, 0.14342140190013294, 0.25097754008615597], 
reward next is 0.7490, 
noisyNet noise sample is [array([0.9814307], dtype=float32), -0.0637938]. 
=============================================
[2019-03-26 22:22:27,786] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0565621e-22 1.0000000e+00 2.6875272e-21 1.8824598e-16 8.3408357e-28], sum to 1.0000
[2019-03-26 22:22:27,795] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9204
[2019-03-26 22:22:27,800] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 94.0, 1.0, 2.0, 0.4596510825608306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 651891.214867351, 651891.2148673504, 178755.0599349044], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1298400.0000, 
sim time next is 1299000.0000, 
raw observation next is [24.3, 94.0, 1.0, 2.0, 0.4597026772879609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 651966.8511016708, 651966.8511016708, 178762.9624516959], 
processed observation next is [1.0, 0.0, 0.3507109004739337, 0.94, 1.0, 1.0, 0.34903937022645887, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18110190308379742, 0.18110190308379742, 0.2668103917189491], 
reward next is 0.7332, 
noisyNet noise sample is [array([-0.45618188], dtype=float32), 0.590045]. 
=============================================
[2019-03-26 22:22:27,812] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[73.714294]
 [74.192444]
 [74.74636 ]
 [75.26391 ]
 [75.993095]], R is [[73.37789917]
 [73.37731934]
 [73.37679291]
 [73.37636566]
 [73.37606049]].
[2019-03-26 22:22:40,065] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6514962e-23 1.0000000e+00 1.2472437e-22 4.5941074e-19 1.1301968e-28], sum to 1.0000
[2019-03-26 22:22:40,074] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8612
[2019-03-26 22:22:40,084] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.93333333333333, 97.16666666666667, 1.0, 2.0, 0.3254563981357907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 510594.4042223032, 510594.4042223032, 167740.3976730386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1480200.0000, 
sim time next is 1480800.0000, 
raw observation next is [20.86666666666667, 97.33333333333334, 1.0, 2.0, 0.323469055500303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 508083.6761096269, 508083.6761096276, 167562.6779779367], 
processed observation next is [0.0, 0.13043478260869565, 0.18799368088467638, 0.9733333333333334, 1.0, 1.0, 0.1849024765063892, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14113435447489636, 0.14113435447489656, 0.250093549220801], 
reward next is 0.7499, 
noisyNet noise sample is [array([-1.3443973], dtype=float32), 0.347403]. 
=============================================
[2019-03-26 22:22:41,139] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.4944314e-23 1.0000000e+00 1.2976607e-22 8.4052386e-18 7.1172784e-28], sum to 1.0000
[2019-03-26 22:22:41,150] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0500
[2019-03-26 22:22:41,156] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.05, 51.0, 1.0, 2.0, 0.3449039851276267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 530137.3790334774, 530137.3790334767, 168974.470872795], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1511400.0000, 
sim time next is 1512000.0000, 
raw observation next is [29.1, 51.0, 1.0, 2.0, 0.3480171406727051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 534257.5264887547, 534257.5264887554, 169288.3780549595], 
processed observation next is [0.0, 0.5217391304347826, 0.5781990521327015, 0.51, 1.0, 1.0, 0.21447848273819894, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1484048684690985, 0.1484048684690987, 0.2526692209775515], 
reward next is 0.7473, 
noisyNet noise sample is [array([-0.00946083], dtype=float32), 0.941931]. 
=============================================
[2019-03-26 22:22:41,176] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[75.85443 ]
 [75.86051 ]
 [75.859024]
 [75.86417 ]
 [75.871216]], R is [[75.86323547]
 [75.85240936]
 [75.84195709]
 [75.83157349]
 [75.82131958]].
[2019-03-26 22:22:56,206] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.2904188e-22 1.0000000e+00 8.1431747e-21 9.1882104e-17 2.4388703e-26], sum to 1.0000
[2019-03-26 22:22:56,212] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6182
[2019-03-26 22:22:56,222] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.15, 89.33333333333333, 1.0, 2.0, 0.4664865109814356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 654881.2491352783, 654881.2491352777, 178906.5591946662], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1756200.0000, 
sim time next is 1756800.0000, 
raw observation next is [25.2, 89.0, 1.0, 2.0, 0.5579299271410525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 783100.424087762, 783100.424087762, 193610.5593701128], 
processed observation next is [1.0, 0.34782608695652173, 0.3933649289099526, 0.89, 1.0, 1.0, 0.46738545438681023, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2175278955799339, 0.2175278955799339, 0.28897098413449673], 
reward next is 0.7110, 
noisyNet noise sample is [array([-0.3429237], dtype=float32), 1.6637009]. 
=============================================
[2019-03-26 22:23:01,732] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.6242741e-21 1.0000000e+00 2.6423206e-21 5.1313256e-16 4.4702047e-27], sum to 1.0000
[2019-03-26 22:23:01,738] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9449
[2019-03-26 22:23:01,748] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.48333333333333, 90.33333333333333, 1.0, 2.0, 0.8876414164202816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1275697.956631741, 1275697.956631741, 271685.1948351348], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1849800.0000, 
sim time next is 1850400.0000, 
raw observation next is [24.6, 90.0, 1.0, 2.0, 0.8642812292572144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1238442.543499014, 1238442.543499014, 264706.07610416], 
processed observation next is [1.0, 0.43478260869565216, 0.36492890995260674, 0.9, 1.0, 1.0, 0.8364834087436318, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.34401181763861505, 0.34401181763861505, 0.39508369567785073], 
reward next is 0.6049, 
noisyNet noise sample is [array([1.0047956], dtype=float32), -0.46337238]. 
=============================================
[2019-03-26 22:23:02,694] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6863894e-21 1.0000000e+00 6.6551236e-20 9.5133542e-16 4.9881129e-26], sum to 1.0000
[2019-03-26 22:23:02,702] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6779
[2019-03-26 22:23:02,707] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.43333333333334, 85.33333333333334, 1.0, 2.0, 0.7321125345210029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1023169.74562647, 1023169.745626471, 227929.24923643], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2186400.0000, 
sim time next is 2187000.0000, 
raw observation next is [27.65, 84.5, 1.0, 2.0, 0.7342333500924266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1026135.140452633, 1026135.140452633, 228408.1018651827], 
processed observation next is [1.0, 0.30434782608695654, 0.509478672985782, 0.845, 1.0, 1.0, 0.6797992169788273, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2850375390146203, 0.2850375390146203, 0.34090761472415326], 
reward next is 0.6591, 
noisyNet noise sample is [array([0.53334194], dtype=float32), -0.01179908]. 
=============================================
[2019-03-26 22:23:02,717] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[69.616104]
 [69.60897 ]
 [69.67162 ]
 [69.699066]
 [69.832466]], R is [[69.54862213]
 [69.51293945]
 [69.46427155]
 [69.44147491]
 [69.43499756]].
[2019-03-26 22:23:03,580] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 22:23:03,581] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 22:23:03,582] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 22:23:03,582] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:23:03,584] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 22:23:03,584] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:23:03,587] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:23:03,586] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 22:23:03,591] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 22:23:03,594] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:23:03,595] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:23:03,611] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run71
[2019-03-26 22:23:03,637] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run71
[2019-03-26 22:23:03,659] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run71
[2019-03-26 22:23:03,662] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run71
[2019-03-26 22:23:03,700] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run71
[2019-03-26 22:23:06,453] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0933323], dtype=float32), 0.06894399]
[2019-03-26 22:23:06,455] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.6, 58.66666666666666, 1.0, 2.0, 0.453410909873917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 724768.6053898413, 724768.6053898406, 186859.0960760836]
[2019-03-26 22:23:06,455] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:23:06,457] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.3832025e-22 1.0000000e+00 6.2811872e-22 8.5068148e-18 9.0005158e-28], sampled 0.391519927367579
[2019-03-26 22:23:39,543] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0933323], dtype=float32), 0.06894399]
[2019-03-26 22:23:39,544] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.51666666666667, 72.5, 1.0, 2.0, 0.5596997369005743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 821766.7164015353, 821766.7164015353, 198471.1920072279]
[2019-03-26 22:23:39,545] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:23:39,548] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.7913780e-22 1.0000000e+00 3.3672112e-22 9.1934996e-18 4.1936836e-28], sampled 0.07650288952473261
[2019-03-26 22:24:22,965] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0933323], dtype=float32), 0.06894399]
[2019-03-26 22:24:22,967] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [34.04574491333334, 53.51373092999999, 1.0, 2.0, 0.9831247782262378, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9129565103898, 1374200.935803919, 1374200.935803919, 293827.8746399017]
[2019-03-26 22:24:22,968] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:24:22,972] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.7878809e-19 1.0000000e+00 9.5403052e-19 9.4041669e-13 3.6953337e-24], sampled 0.04282316070177361
[2019-03-26 22:24:44,628] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0933323], dtype=float32), 0.06894399]
[2019-03-26 22:24:44,629] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.43333333333333, 94.33333333333334, 1.0, 2.0, 0.4835889755826049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 681070.5732223535, 681070.5732223535, 181751.4326697218]
[2019-03-26 22:24:44,632] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:24:44,635] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0700236e-22 1.0000000e+00 1.8833518e-22 2.5358020e-18 1.9187196e-28], sampled 0.9333651170028169
[2019-03-26 22:24:48,268] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0933323], dtype=float32), 0.06894399]
[2019-03-26 22:24:48,269] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.82927253, 98.96420074, 1.0, 2.0, 0.5055257999641293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 706396.3302543431, 706396.3302543431, 184466.3762182705]
[2019-03-26 22:24:48,269] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:24:48,271] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0288510e-22 1.0000000e+00 2.1199987e-22 6.6182940e-18 1.9399748e-28], sampled 0.396855121297609
[2019-03-26 22:24:57,850] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.7831 3164437843.4653 1771.0000
[2019-03-26 22:24:58,249] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8657.7542 2779421310.5350 933.0000
[2019-03-26 22:24:58,319] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.1682 2927441262.2667 1338.0000
[2019-03-26 22:24:58,371] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.0394 3007722810.6536 1766.0000
[2019-03-26 22:24:58,394] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.2245 2842701587.6268 1129.0000
[2019-03-26 22:24:59,411] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1750000, evaluation results [1750000.0, 7884.783074356129, 3164437843.465289, 1771.0, 8252.16817576188, 2927441262.2666926, 1338.0, 8657.75418547552, 2779421310.5350494, 933.0, 7997.039407411129, 3007722810.6535916, 1766.0, 8496.224494879702, 2842701587.6268277, 1129.0]
[2019-03-26 22:25:06,900] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5026162e-22 1.0000000e+00 2.6165812e-22 1.4352430e-18 2.1744264e-28], sum to 1.0000
[2019-03-26 22:25:06,907] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9982
[2019-03-26 22:25:06,917] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 94.16666666666667, 1.0, 2.0, 0.5021788138397962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 701717.8754074966, 701717.8754074973, 183938.4756841463], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2015400.0000, 
sim time next is 2016000.0000, 
raw observation next is [25.6, 94.0, 1.0, 2.0, 0.5037625457317685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 703931.6310894974, 703931.6310894967, 184188.0953561375], 
processed observation next is [0.0, 0.34782608695652173, 0.4123222748815167, 0.94, 1.0, 1.0, 0.40212354907441983, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19553656419152704, 0.19553656419152685, 0.27490760500916045], 
reward next is 0.7251, 
noisyNet noise sample is [array([-0.47158343], dtype=float32), 0.55244976]. 
=============================================
[2019-03-26 22:25:06,935] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[75.82357 ]
 [75.808105]
 [75.78523 ]
 [75.76562 ]
 [75.74207 ]], R is [[75.82591248]
 [75.79312134]
 [75.76112366]
 [75.73014832]
 [75.70026398]].
[2019-03-26 22:25:12,102] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.9431294e-23 1.0000000e+00 1.5943364e-22 8.6057731e-19 3.1863969e-28], sum to 1.0000
[2019-03-26 22:25:12,112] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7904
[2019-03-26 22:25:12,117] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 96.5, 1.0, 2.0, 0.470418714713117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 661346.4960762226, 661346.4960762219, 179610.3312836227], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2093400.0000, 
sim time next is 2094000.0000, 
raw observation next is [24.33333333333333, 96.0, 1.0, 2.0, 0.4764538974751408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 667692.2994593258, 667692.2994593258, 180238.4013870275], 
processed observation next is [0.0, 0.21739130434782608, 0.35229067930489716, 0.96, 1.0, 1.0, 0.36922156322306116, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18547008318314606, 0.18547008318314606, 0.26901253938362313], 
reward next is 0.7310, 
noisyNet noise sample is [array([1.8443681], dtype=float32), -2.0864248]. 
=============================================
[2019-03-26 22:25:12,133] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[74.220474]
 [74.20527 ]
 [74.17718 ]
 [74.13017 ]
 [74.07943 ]], R is [[74.22386932]
 [74.21355438]
 [74.20454407]
 [74.19669342]
 [74.18910217]].
[2019-03-26 22:25:13,618] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.7673639e-18 1.0000000e+00 1.1528153e-17 9.6107779e-13 1.5349789e-22], sum to 1.0000
[2019-03-26 22:25:13,628] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7501
[2019-03-26 22:25:13,638] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2006140.924365637 W.
[2019-03-26 22:25:13,641] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.95, 70.5, 1.0, 2.0, 0.4782702218282451, 1.0, 1.0, 0.4782702218282451, 1.0, 1.0, 0.82685768473388, 6.9112, 6.9112, 170.5573041426782, 2006140.924365637, 2006140.924365637, 399802.6133672573], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2363400.0000, 
sim time next is 2364000.0000, 
raw observation next is [30.1, 70.0, 1.0, 2.0, 0.7656893553521148, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.989999375403258, 6.9112, 168.9124328772767, 1967055.43591164, 1911152.620235628, 400136.4974644193], 
processed observation next is [1.0, 0.34782608695652173, 0.6255924170616115, 0.7, 1.0, 1.0, 0.7176980184965238, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007879937540325788, 0.0, 0.8294373738737948, 0.5464042877532334, 0.53087572784323, 0.5972186529319691], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.1483066], dtype=float32), -1.68732]. 
=============================================
[2019-03-26 22:25:13,651] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[60.65549]
 [67.6215 ]
 [68.10545]
 [68.04357]
 [68.07057]], R is [[56.14309311]
 [55.98493958]
 [55.42509079]
 [55.50337982]
 [55.56342316]].
[2019-03-26 22:25:14,472] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.0461409e-23 1.0000000e+00 3.1483350e-22 1.1194801e-17 1.5536488e-28], sum to 1.0000
[2019-03-26 22:25:14,480] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7961
[2019-03-26 22:25:14,486] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.4, 75.0, 1.0, 2.0, 0.572840619621864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 800494.1171533844, 800494.1171533844, 195795.676688901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2129400.0000, 
sim time next is 2130000.0000, 
raw observation next is [30.43333333333333, 74.66666666666666, 1.0, 2.0, 0.5726233780259352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 800190.4268804025, 800190.4268804025, 195756.90941491], 
processed observation next is [0.0, 0.6521739130434783, 0.6413902053712479, 0.7466666666666666, 1.0, 1.0, 0.4850884072601629, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2222751185778896, 0.2222751185778896, 0.2921744916640448], 
reward next is 0.7078, 
noisyNet noise sample is [array([0.20942767], dtype=float32), -0.6324988]. 
=============================================
[2019-03-26 22:25:14,501] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[76.09911 ]
 [76.06292 ]
 [76.02262 ]
 [75.973145]
 [75.91894 ]], R is [[76.08202362]
 [76.02897644]
 [75.97622681]
 [75.92297363]
 [75.87098694]].
[2019-03-26 22:25:18,494] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2735251e-08 9.0371782e-01 1.0608641e-08 9.6282169e-02 1.6363313e-11], sum to 1.0000
[2019-03-26 22:25:18,503] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0209
[2019-03-26 22:25:18,510] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2222652.975227057 W.
[2019-03-26 22:25:18,515] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.2, 73.0, 1.0, 2.0, 0.7947513376981712, 1.0, 1.0, 0.7947513376981712, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2222652.975227057, 2222652.975227057, 417325.2934804766], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2199600.0000, 
sim time next is 2200200.0000, 
raw observation next is [30.3, 72.5, 1.0, 2.0, 0.4986117933545699, 1.0, 2.0, 0.4986117933545699, 1.0, 1.0, 0.8659237916171061, 6.911200000000001, 6.9112, 170.5573041426782, 2091548.491544016, 2091548.491544015, 414187.0677796171], 
processed observation next is [1.0, 0.4782608695652174, 0.6350710900473934, 0.725, 1.0, 1.0, 0.39591782331875897, 1.0, 1.0, 0.39591782331875897, 1.0, 0.5, 0.8364924288013489, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.58098569209556, 0.5809856920955597, 0.6181896534024136], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.15414324], dtype=float32), 1.0617881]. 
=============================================
[2019-03-26 22:25:24,934] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.2180588e-11 6.3133043e-01 2.1478497e-09 3.6866957e-01 3.9214898e-14], sum to 1.0000
[2019-03-26 22:25:24,947] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3724
[2019-03-26 22:25:24,958] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2321600.072552725 W.
[2019-03-26 22:25:24,961] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.13333333333334, 64.33333333333333, 1.0, 2.0, 0.8300988998031312, 1.0, 2.0, 0.8300988998031312, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2321600.072552725, 2321600.072552725, 434792.628561079], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2302800.0000, 
sim time next is 2303400.0000, 
raw observation next is [32.16666666666667, 64.16666666666667, 1.0, 2.0, 0.8367450121644304, 1.0, 2.0, 0.8367450121644304, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2340205.159207548, 2340205.159207549, 438158.5006232937], 
processed observation next is [1.0, 0.6521739130434783, 0.7235387045813588, 0.6416666666666667, 1.0, 1.0, 0.8033072435716029, 1.0, 1.0, 0.8033072435716029, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6500569886687634, 0.6500569886687636, 0.6539679113780503], 
reward next is 0.3460, 
noisyNet noise sample is [array([-1.5906771], dtype=float32), -0.082371846]. 
=============================================
[2019-03-26 22:25:53,579] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.8294358e-23 1.0000000e+00 1.4730359e-22 3.9761588e-18 1.1881327e-29], sum to 1.0000
[2019-03-26 22:25:53,588] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3705
[2019-03-26 22:25:53,596] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 79.0, 1.0, 2.0, 0.5774209010486471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 806897.086632314, 806897.0866323146, 196614.797051636], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3349200.0000, 
sim time next is 3349800.0000, 
raw observation next is [29.5, 79.0, 1.0, 2.0, 0.5724389695867909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 799932.6353917036, 799932.6353917036, 195723.5432065242], 
processed observation next is [0.0, 0.782608695652174, 0.5971563981042655, 0.79, 1.0, 1.0, 0.4848662284178203, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22220350983102877, 0.22220350983102877, 0.29212469135302116], 
reward next is 0.7079, 
noisyNet noise sample is [array([-0.18314028], dtype=float32), -0.06482629]. 
=============================================
[2019-03-26 22:25:55,459] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 22:25:55,460] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 22:25:55,462] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:25:55,462] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 22:25:55,464] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 22:25:55,465] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 22:25:55,466] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:25:55,468] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:25:55,469] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:25:55,468] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 22:25:55,472] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:25:55,494] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run72
[2019-03-26 22:25:55,519] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run72
[2019-03-26 22:25:55,519] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run72
[2019-03-26 22:25:55,564] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run72
[2019-03-26 22:25:55,565] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run72
[2019-03-26 22:26:39,079] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0933561], dtype=float32), 0.06905428]
[2019-03-26 22:26:39,081] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.79236014, 85.19203813333334, 1.0, 2.0, 0.3995070744144205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 599806.6843437413, 599806.6843437419, 174620.6023780394]
[2019-03-26 22:26:39,082] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:26:39,086] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.1158450e-23 1.0000000e+00 2.3127125e-22 9.9516222e-18 2.3548495e-28], sampled 0.8995054586021555
[2019-03-26 22:26:47,161] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0933561], dtype=float32), 0.06905428]
[2019-03-26 22:26:47,163] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.50328127333333, 77.74691101333333, 1.0, 2.0, 0.5323449673210711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 743885.2080853801, 743885.2080853801, 188818.8147019089]
[2019-03-26 22:26:47,165] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:26:47,167] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.3319886e-23 1.0000000e+00 7.4589481e-23 1.7746167e-17 6.6118728e-29], sampled 0.5499481283385631
[2019-03-26 22:27:14,481] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0933561], dtype=float32), 0.06905428]
[2019-03-26 22:27:14,484] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.08725909, 96.84311019166665, 1.0, 2.0, 0.7195280927858597, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.00597650281927, 6.9112, 168.9123160377501, 1902455.86207267, 1835218.403964592, 388929.2786609698]
[2019-03-26 22:27:14,487] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:27:14,489] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.2882714e-11 9.9997795e-01 4.0827067e-11 2.2079170e-05 6.8459507e-15], sampled 0.573813733253137
[2019-03-26 22:27:14,490] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1902455.86207267 W.
[2019-03-26 22:27:22,710] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0933561], dtype=float32), 0.06905428]
[2019-03-26 22:27:22,711] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.849797885, 89.952002685, 1.0, 2.0, 0.5440626636663014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 760265.0762490887, 760265.076249088, 190787.122843581]
[2019-03-26 22:27:22,712] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:27:22,714] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.584060e-23 1.000000e+00 5.298819e-23 1.431815e-17 4.004464e-29], sampled 0.9142126260809613
[2019-03-26 22:27:34,802] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0933561], dtype=float32), 0.06905428]
[2019-03-26 22:27:34,804] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.4, 78.0, 1.0, 2.0, 0.53206028184895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 743487.2566845964, 743487.2566845964, 188771.366068988]
[2019-03-26 22:27:34,804] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 22:27:34,808] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.7629632e-23 1.0000000e+00 9.1847833e-23 2.2445069e-17 9.2964614e-29], sampled 0.6178430493072232
[2019-03-26 22:27:43,054] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0933561], dtype=float32), 0.06905428]
[2019-03-26 22:27:43,054] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.3925354, 88.5304063, 1.0, 2.0, 0.5259256861170708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 765180.2479935116, 765180.2479935109, 191580.8078838556]
[2019-03-26 22:27:43,057] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:27:43,062] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.6265263e-22 1.0000000e+00 3.4695950e-22 9.5364892e-18 3.9830152e-28], sampled 0.4324907741598647
[2019-03-26 22:27:50,159] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8000.2813 3007623292.1946 1764.0000
[2019-03-26 22:27:50,553] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.1357 2779264097.1931 933.0000
[2019-03-26 22:27:50,588] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.5689 2927215755.2822 1337.0000
[2019-03-26 22:27:50,635] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8498.0169 2842400214.9914 1124.0000
[2019-03-26 22:27:50,701] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.2780 3164835853.8293 1767.0000
[2019-03-26 22:27:51,718] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1775000, evaluation results [1775000.0, 7884.278024103775, 3164835853.8293414, 1767.0, 8255.568928071556, 2927215755.2822227, 1337.0, 8659.135684527335, 2779264097.1930614, 933.0, 8000.28134080942, 3007623292.194597, 1764.0, 8498.01685334296, 2842400214.9914303, 1124.0]
[2019-03-26 22:27:52,625] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0049333e-21 1.0000000e+00 9.3469584e-21 4.0244444e-16 1.0018424e-26], sum to 1.0000
[2019-03-26 22:27:52,633] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0758
[2019-03-26 22:27:52,637] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.00000000000001, 1.0, 2.0, 0.532402841094277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 836546.0507181135, 836546.0507181135, 199571.6985395206], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2977800.0000, 
sim time next is 2978400.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.5230612596804076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 821864.6246631006, 821864.6246631006, 197837.1363894793], 
processed observation next is [1.0, 0.4782608695652174, 0.2417061611374408, 0.88, 1.0, 1.0, 0.4253750116631417, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2282957290730835, 0.2282957290730835, 0.29527930804399893], 
reward next is 0.7047, 
noisyNet noise sample is [array([-1.0108306], dtype=float32), 0.6246015]. 
=============================================
[2019-03-26 22:28:00,265] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4894849e-21 1.0000000e+00 2.5106486e-20 1.3222698e-16 1.2725882e-26], sum to 1.0000
[2019-03-26 22:28:00,272] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8106
[2019-03-26 22:28:00,276] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.00000000000001, 1.0, 2.0, 0.3333950727343722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527203.1610932067, 527203.1610932067, 169111.7180486134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2956200.0000, 
sim time next is 2956800.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.3112955111629772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 492250.5029396613, 492250.5029396607, 166449.4174983875], 
processed observation next is [1.0, 0.21739130434782608, 0.19431279620853087, 0.94, 1.0, 1.0, 0.17023555561804482, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1367362508165726, 0.13673625081657242, 0.24843196641550375], 
reward next is 0.7516, 
noisyNet noise sample is [array([-0.18804826], dtype=float32), 0.37011665]. 
=============================================
[2019-03-26 22:28:04,497] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1854205e-22 1.0000000e+00 1.6761625e-21 2.4110378e-17 1.7734700e-28], sum to 1.0000
[2019-03-26 22:28:04,505] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5413
[2019-03-26 22:28:04,511] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3028285612138949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 482237.5283235412, 482237.5283235412, 165782.3666037986], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3023400.0000, 
sim time next is 3024000.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3029701378635925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 482463.1465890807, 482463.14658908, 165798.5906176273], 
processed observation next is [1.0, 0.0, 0.1469194312796209, 1.0, 1.0, 1.0, 0.1602049853778223, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1340175407191891, 0.1340175407191889, 0.24746058301138404], 
reward next is 0.7525, 
noisyNet noise sample is [array([-0.6860782], dtype=float32), 0.674235]. 
=============================================
[2019-03-26 22:28:04,530] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[74.55585 ]
 [74.52863 ]
 [74.49232 ]
 [74.4602  ]
 [74.423065]], R is [[73.87106323]
 [73.88491821]
 [73.89860535]
 [73.91201019]
 [73.92507172]].
[2019-03-26 22:28:09,866] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9127717e-21 1.0000000e+00 3.9468073e-20 2.3616030e-15 4.0862403e-26], sum to 1.0000
[2019-03-26 22:28:09,875] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2093
[2019-03-26 22:28:09,881] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3909356051978644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 583336.3860204469, 583336.3860204476, 173009.5673319568], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3114000.0000, 
sim time next is 3114600.0000, 
raw observation next is [23.0, 94.00000000000001, 1.0, 2.0, 0.3906318431671744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 582883.0890230265, 582883.0890230272, 172968.4333349663], 
processed observation next is [1.0, 0.043478260869565216, 0.28909952606635075, 0.9400000000000002, 1.0, 1.0, 0.2658214977917764, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16191196917306291, 0.1619119691730631, 0.25816184079845717], 
reward next is 0.7418, 
noisyNet noise sample is [array([0.49557245], dtype=float32), -0.09944358]. 
=============================================
[2019-03-26 22:28:10,056] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.4871380e-17 1.0000000e+00 1.4178479e-15 1.2385021e-09 1.9494039e-20], sum to 1.0000
[2019-03-26 22:28:10,068] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4891
[2019-03-26 22:28:10,074] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.4806062416865125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 671563.9858168777, 671563.9858168783, 180614.9348517487], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3172800.0000, 
sim time next is 3173400.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.4777586849911444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 667583.7682487294, 667583.7682487294, 180186.5019095809], 
processed observation next is [1.0, 0.7391304347826086, 0.4786729857819906, 0.84, 1.0, 1.0, 0.3707935963748727, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18543993562464706, 0.18543993562464706, 0.2689350774769864], 
reward next is 0.7311, 
noisyNet noise sample is [array([-0.85583127], dtype=float32), 1.1600667]. 
=============================================
[2019-03-26 22:28:14,848] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6349429e-22 1.0000000e+00 2.2432089e-22 5.4116765e-18 3.3067247e-28], sum to 1.0000
[2019-03-26 22:28:14,855] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8788
[2019-03-26 22:28:14,861] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.0, 63.0, 1.0, 2.0, 0.6240732084916257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 872116.5228211972, 872116.5228211966, 205316.8012722254], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3841800.0000, 
sim time next is 3842400.0000, 
raw observation next is [34.0, 63.00000000000001, 1.0, 2.0, 0.6183279808014628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 864084.53857606, 864084.5385760607, 204210.7737611511], 
processed observation next is [0.0, 0.4782608695652174, 0.8104265402843602, 0.6300000000000001, 1.0, 1.0, 0.5401541937367021, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24002348293779444, 0.24002348293779463, 0.3047921996435091], 
reward next is 0.6952, 
noisyNet noise sample is [array([-0.8872123], dtype=float32), 0.032329522]. 
=============================================
[2019-03-26 22:28:15,008] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.6990903e-23 1.0000000e+00 5.0501739e-23 1.0046944e-17 9.8887860e-29], sum to 1.0000
[2019-03-26 22:28:15,018] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7558
[2019-03-26 22:28:15,025] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.0, 63.0, 1.0, 2.0, 0.616474343870628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861493.1167962622, 861493.1167962622, 203856.0112491574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3844200.0000, 
sim time next is 3844800.0000, 
raw observation next is [34.0, 63.0, 1.0, 2.0, 0.6167753717940899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861913.9594688974, 861913.9594688974, 203913.5549506455], 
processed observation next is [0.0, 0.5217391304347826, 0.8104265402843602, 0.63, 1.0, 1.0, 0.5382835804748071, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23942054429691595, 0.23942054429691595, 0.3043485894785754], 
reward next is 0.6957, 
noisyNet noise sample is [array([-1.3342056], dtype=float32), 0.44161952]. 
=============================================
[2019-03-26 22:28:18,464] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.4832014e-23 1.0000000e+00 3.2106384e-22 2.6818385e-17 1.2860176e-27], sum to 1.0000
[2019-03-26 22:28:18,470] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0377
[2019-03-26 22:28:18,475] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.5, 73.0, 1.0, 2.0, 0.5976650794464909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 835197.743714509, 835197.7437145095, 200312.3403662385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3259800.0000, 
sim time next is 3260400.0000, 
raw observation next is [31.33333333333333, 73.66666666666667, 1.0, 2.0, 0.5970997092513171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 834407.3656158712, 834407.3656158712, 200207.3675610389], 
processed observation next is [0.0, 0.7391304347826086, 0.6840442338072668, 0.7366666666666667, 1.0, 1.0, 0.514577962953394, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23177982378218642, 0.23177982378218642, 0.2988169665090133], 
reward next is 0.7012, 
noisyNet noise sample is [array([1.1017246], dtype=float32), 1.5968896]. 
=============================================
[2019-03-26 22:28:22,729] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9513449e-21 1.0000000e+00 8.4093944e-21 1.1149042e-15 6.9982877e-26], sum to 1.0000
[2019-03-26 22:28:22,736] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6534
[2019-03-26 22:28:22,742] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 81.5, 1.0, 2.0, 0.6021872497444052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 841519.6834971653, 841519.6834971659, 201145.5087828452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3648600.0000, 
sim time next is 3649200.0000, 
raw observation next is [26.66666666666667, 80.66666666666667, 1.0, 2.0, 0.6136135355518414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 857493.6615310544, 857493.6615310544, 203300.2973600092], 
processed observation next is [1.0, 0.21739130434782608, 0.4628751974723541, 0.8066666666666668, 1.0, 1.0, 0.534474139219086, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23819268375862623, 0.23819268375862623, 0.3034332796418048], 
reward next is 0.6966, 
noisyNet noise sample is [array([0.7514137], dtype=float32), 1.4476337]. 
=============================================
[2019-03-26 22:28:25,020] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5284690e-23 1.0000000e+00 2.2034819e-23 8.6679479e-18 2.0584768e-29], sum to 1.0000
[2019-03-26 22:28:25,028] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1861
[2019-03-26 22:28:25,034] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.5377674587055347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 751465.138770296, 751465.138770296, 189724.9251875314], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3364800.0000, 
sim time next is 3365400.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.5373605047599435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 750896.2687323533, 750896.2687323539, 189656.6609110289], 
processed observation next is [0.0, 0.9565217391304348, 0.4786729857819906, 0.89, 1.0, 1.0, 0.4426030177830644, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20858229687009816, 0.20858229687009833, 0.2830696431507894], 
reward next is 0.7169, 
noisyNet noise sample is [array([0.32651654], dtype=float32), -0.32059327]. 
=============================================
[2019-03-26 22:28:25,149] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.7757752e-24 1.0000000e+00 1.5246845e-22 1.9640370e-17 5.6735856e-29], sum to 1.0000
[2019-03-26 22:28:25,157] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0615
[2019-03-26 22:28:25,163] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.33333333333334, 63.33333333333333, 1.0, 2.0, 0.5572060011874463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 778638.1123257191, 778638.1123257191, 193045.2620676647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3868800.0000, 
sim time next is 3869400.0000, 
raw observation next is [32.16666666666666, 65.16666666666667, 1.0, 2.0, 0.5640217650058872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 788165.9753220618, 788165.9753220612, 194235.5952034292], 
processed observation next is [0.0, 0.782608695652174, 0.7235387045813582, 0.6516666666666667, 1.0, 1.0, 0.4747250180793821, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21893499314501716, 0.218934993145017, 0.28990387343795404], 
reward next is 0.7101, 
noisyNet noise sample is [array([1.2239211], dtype=float32), -0.13841456]. 
=============================================
[2019-03-26 22:28:26,505] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.2460618e-21 1.0000000e+00 3.9483434e-20 2.4729758e-15 3.9495665e-26], sum to 1.0000
[2019-03-26 22:28:26,515] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8119
[2019-03-26 22:28:26,522] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 89.0, 1.0, 2.0, 0.765910022265203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1070427.501924285, 1070427.501924285, 235716.0615192117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3392400.0000, 
sim time next is 3393000.0000, 
raw observation next is [27.5, 89.0, 1.0, 2.0, 0.7733679151593492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1080855.876382472, 1080855.876382473, 237480.0817162002], 
processed observation next is [1.0, 0.2608695652173913, 0.5023696682464456, 0.89, 1.0, 1.0, 0.7269492953727099, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.30023774343957554, 0.3002377434395758, 0.3544478831585077], 
reward next is 0.6456, 
noisyNet noise sample is [array([-0.81923527], dtype=float32), -0.4885964]. 
=============================================
[2019-03-26 22:28:26,542] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[68.29815 ]
 [68.42945 ]
 [68.427795]
 [68.58366 ]
 [68.42719 ]], R is [[68.18909454]
 [68.15538788]
 [68.12043762]
 [68.07352448]
 [68.0254364 ]].
[2019-03-26 22:28:30,297] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.7004553e-12 2.7569818e-01 5.0279131e-10 7.2430182e-01 2.5731348e-14], sum to 1.0000
[2019-03-26 22:28:30,307] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8872
[2019-03-26 22:28:30,315] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 63.0, 1.0, 2.0, 0.8902130785713809, 1.0, 2.0, 0.8902130785713809, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2489893.419331062, 2489893.419331062, 466184.6406531913], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3509400.0000, 
sim time next is 3510000.0000, 
raw observation next is [33.0, 63.0, 1.0, 2.0, 0.8444077657219283, 1.0, 2.0, 0.8444077657219283, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2361656.568857902, 2361656.568857902, 442075.3196570034], 
processed observation next is [1.0, 0.6521739130434783, 0.7630331753554502, 0.63, 1.0, 1.0, 0.8125394767734077, 1.0, 1.0, 0.8125394767734077, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6560157135716395, 0.6560157135716395, 0.659813909935826], 
reward next is 0.3402, 
noisyNet noise sample is [array([0.20050465], dtype=float32), 2.631712]. 
=============================================
[2019-03-26 22:28:30,325] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[38.519985]
 [37.921852]
 [37.3093  ]
 [36.66119 ]
 [36.512123]], R is [[39.08817673]
 [39.00149918]
 [38.920578  ]
 [38.84512329]
 [38.45667267]].
[2019-03-26 22:28:30,667] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2674639e-20 1.0000000e+00 2.6493265e-20 2.5556263e-15 1.0730548e-25], sum to 1.0000
[2019-03-26 22:28:30,675] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3232
[2019-03-26 22:28:30,683] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6215309164514117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 868562.3220550605, 868562.3220550605, 204816.1581560592], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3475200.0000, 
sim time next is 3475800.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.6402951639551456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 894795.5847353708, 894795.5847353701, 208482.4780421715], 
processed observation next is [1.0, 0.21739130434782608, 0.4786729857819906, 0.79, 1.0, 1.0, 0.5666206794640308, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24855432909315855, 0.24855432909315836, 0.31116787767488285], 
reward next is 0.6888, 
noisyNet noise sample is [array([-1.6697413], dtype=float32), -0.69753206]. 
=============================================
[2019-03-26 22:28:34,640] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8872745e-11 7.4175090e-02 4.2964774e-09 9.2582494e-01 1.2515892e-13], sum to 1.0000
[2019-03-26 22:28:34,647] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4654
[2019-03-26 22:28:34,652] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 63.0, 1.0, 2.0, 0.8309095407360023, 1.0, 2.0, 0.8309095407360023, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2323869.361034028, 2323869.361034028, 435199.2781948699], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3672000.0000, 
sim time next is 3672600.0000, 
raw observation next is [32.16666666666667, 63.0, 1.0, 2.0, 0.9077781388666701, 1.0, 2.0, 0.9077781388666701, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2539072.167053817, 2539072.167053817, 475751.4470372468], 
processed observation next is [1.0, 0.5217391304347826, 0.7235387045813588, 0.63, 1.0, 1.0, 0.8888893239357472, 1.0, 1.0, 0.8888893239357472, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7052978241816158, 0.7052978241816158, 0.7100767866227564], 
reward next is 0.2899, 
noisyNet noise sample is [array([0.48389465], dtype=float32), -0.570148]. 
=============================================
[2019-03-26 22:28:41,451] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2694696e-20 1.0000000e+00 5.7437981e-20 6.1159362e-15 9.7324821e-26], sum to 1.0000
[2019-03-26 22:28:41,460] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9248
[2019-03-26 22:28:41,465] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 76.5, 1.0, 2.0, 0.6871586021818643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 960315.611057312, 960315.6110573113, 218094.6857934499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3652200.0000, 
sim time next is 3652800.0000, 
raw observation next is [27.66666666666666, 75.66666666666666, 1.0, 2.0, 0.76585292453172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1070347.662536968, 1070347.662536968, 235698.4606344045], 
processed observation next is [1.0, 0.2608695652173913, 0.5102685624012636, 0.7566666666666666, 1.0, 1.0, 0.717895089797253, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.29731879514915777, 0.29731879514915777, 0.3517887472155291], 
reward next is 0.6482, 
noisyNet noise sample is [array([-1.5426353], dtype=float32), -0.29302305]. 
=============================================
[2019-03-26 22:28:43,231] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.1006820e-11 3.8893577e-01 3.3219809e-09 6.1106426e-01 3.0397390e-14], sum to 1.0000
[2019-03-26 22:28:43,241] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9488
[2019-03-26 22:28:43,246] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 61.0, 1.0, 2.0, 0.9841959376095687, 1.0, 2.0, 0.9841959376095687, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2753049.65261057, 2753049.652610571, 519507.2728511732], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3677400.0000, 
sim time next is 3678000.0000, 
raw observation next is [33.0, 60.33333333333333, 1.0, 2.0, 0.9788749469595208, 1.0, 2.0, 0.9788749469595208, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2738149.159046959, 2738149.159046959, 516348.7741848059], 
processed observation next is [1.0, 0.5652173913043478, 0.7630331753554502, 0.6033333333333333, 1.0, 1.0, 0.9745481288668926, 1.0, 1.0, 0.9745481288668926, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7605969886241554, 0.7605969886241554, 0.7706698122161283], 
reward next is 0.2293, 
noisyNet noise sample is [array([0.34422565], dtype=float32), -0.015931474]. 
=============================================
[2019-03-26 22:28:43,259] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[38.303642]
 [38.21302 ]
 [38.27751 ]
 [37.837368]
 [37.070133]], R is [[38.28510666]
 [38.12687302]
 [37.99263382]
 [37.95165634]
 [37.95226669]].
[2019-03-26 22:28:43,371] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.4434674e-22 1.0000000e+00 6.4410415e-22 1.7876767e-16 1.2629973e-27], sum to 1.0000
[2019-03-26 22:28:43,383] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8621
[2019-03-26 22:28:43,391] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 67.66666666666667, 1.0, 2.0, 0.5874176855503325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 820872.1493224866, 820872.1493224866, 198425.2997707888], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3923400.0000, 
sim time next is 3924000.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.5831125585352475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 814853.7495796885, 814853.7495796885, 197641.9999554863], 
processed observation next is [0.0, 0.43478260869565216, 0.7156398104265403, 0.67, 1.0, 1.0, 0.49772597413885233, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2263482637721357, 0.2263482637721357, 0.2949880596350542], 
reward next is 0.7050, 
noisyNet noise sample is [array([0.00920217], dtype=float32), -0.8161529]. 
=============================================
[2019-03-26 22:28:43,418] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.4048 ]
 [72.37171]
 [72.3468 ]
 [72.32316]
 [72.30591]], R is [[72.43939209]
 [72.4188385 ]
 [72.39738464]
 [72.37507629]
 [72.3507843 ]].
[2019-03-26 22:28:47,237] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.43705178e-11 9.99976993e-01 9.95431446e-11 2.29866382e-05
 1.15696705e-14], sum to 1.0000
[2019-03-26 22:28:47,244] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9768
[2019-03-26 22:28:47,254] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1662958.667597724 W.
[2019-03-26 22:28:47,259] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.16666666666667, 83.16666666666666, 1.0, 2.0, 0.3965179474288019, 1.0, 1.0, 0.3965179474288019, 1.0, 1.0, 0.6886205441948228, 6.911199999999999, 6.9112, 170.5573041426782, 1662958.667597724, 1662958.667597725, 350969.889889459], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3988200.0000, 
sim time next is 3988800.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.3691005075402916, 1.0, 2.0, 0.3691005075402916, 1.0, 2.0, 0.6410055181944047, 6.9112, 6.9112, 170.5573041426782, 1547889.48655222, 1547889.48655222, 336443.6537903991], 
processed observation next is [1.0, 0.17391304347826086, 0.5734597156398105, 0.84, 1.0, 1.0, 0.2398801295666164, 1.0, 1.0, 0.2398801295666164, 1.0, 1.0, 0.562201851456591, 0.0, 0.0, 0.8375144448122397, 0.42996930182006116, 0.42996930182006116, 0.5021547071498493], 
reward next is 0.4978, 
noisyNet noise sample is [array([0.30003303], dtype=float32), -2.158999]. 
=============================================
[2019-03-26 22:28:48,138] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 22:28:48,140] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 22:28:48,142] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:28:48,143] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 22:28:48,145] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 22:28:48,145] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 22:28:48,147] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 22:28:48,146] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:28:48,147] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:28:48,148] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:28:48,149] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:28:48,177] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run73
[2019-03-26 22:28:48,202] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run73
[2019-03-26 22:28:48,203] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run73
[2019-03-26 22:28:48,247] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run73
[2019-03-26 22:28:48,247] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run73
[2019-03-26 22:28:54,821] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09104144], dtype=float32), 0.06731439]
[2019-03-26 22:28:54,823] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.25, 79.50000000000001, 1.0, 2.0, 0.6505882583214113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1042132.917662223, 1042132.917662223, 225708.4408434813]
[2019-03-26 22:28:54,824] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 22:28:54,829] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.3831777e-21 1.0000000e+00 3.1217514e-21 1.3098045e-16 4.9738408e-27], sampled 0.9757948020645557
[2019-03-26 22:29:06,317] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09104144], dtype=float32), 0.06731439]
[2019-03-26 22:29:06,318] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.25, 61.0, 1.0, 2.0, 0.3216959382037267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 522625.7543883991, 522625.7543883998, 168715.4177273568]
[2019-03-26 22:29:06,319] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:29:06,322] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0128350e-21 1.0000000e+00 2.3651210e-21 5.5215947e-17 4.5183110e-27], sampled 0.766649455697252
[2019-03-26 22:29:31,750] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09104144], dtype=float32), 0.06731439]
[2019-03-26 22:29:31,751] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.0, 88.0, 1.0, 2.0, 0.5230612596804076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 821864.6246631006, 821864.6246631006, 197837.1363894793]
[2019-03-26 22:29:31,751] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 22:29:31,754] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0969293e-21 1.0000000e+00 2.3109411e-21 6.6495508e-17 3.4817844e-27], sampled 0.9462504549902688
[2019-03-26 22:29:38,780] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09104144], dtype=float32), 0.06731439]
[2019-03-26 22:29:38,782] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.696033955, 66.18056304833334, 1.0, 2.0, 0.9483283888300362, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9129565104262, 1325532.563110211, 1325532.563110211, 283575.0649945689]
[2019-03-26 22:29:38,783] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:29:38,785] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.65070282e-14 9.99700904e-01 8.81356349e-13 2.99069245e-04
 1.07416334e-17], sampled 0.05404805069330432
[2019-03-26 22:29:47,598] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09104144], dtype=float32), 0.06731439]
[2019-03-26 22:29:47,601] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.55804299833333, 81.76195691666666, 1.0, 2.0, 0.5729027563823507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 800580.980505419, 800580.980505419, 195804.8540109018]
[2019-03-26 22:29:47,603] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:29:47,607] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.6927557e-23 1.0000000e+00 2.3153784e-22 6.8287234e-17 2.3861006e-28], sampled 0.3674344051007724
[2019-03-26 22:30:10,557] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09104144], dtype=float32), 0.06731439]
[2019-03-26 22:30:10,558] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.3, 93.0, 1.0, 2.0, 0.6141118452536968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 858190.3052904297, 858190.3052904297, 203403.9447068287]
[2019-03-26 22:30:10,559] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 22:30:10,563] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.3913365e-22 1.0000000e+00 1.0148306e-21 4.7358237e-17 1.1148123e-27], sampled 0.7674085810030769
[2019-03-26 22:30:18,300] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09104144], dtype=float32), 0.06731439]
[2019-03-26 22:30:18,302] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.73333333333333, 62.0, 1.0, 2.0, 0.5066521727252193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 707970.7914016352, 707970.7914016346, 184645.0240866598]
[2019-03-26 22:30:18,302] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 22:30:18,308] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.3928166e-22 1.0000000e+00 5.8075087e-22 5.1477723e-17 9.4667045e-28], sampled 0.15677272399302866
[2019-03-26 22:30:19,384] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09104144], dtype=float32), 0.06731439]
[2019-03-26 22:30:19,385] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.33333333333334, 87.83333333333334, 1.0, 2.0, 0.5885208642243188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 822414.355593018, 822414.3555930173, 198626.1266813872]
[2019-03-26 22:30:19,386] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:30:19,389] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.9314912e-22 1.0000000e+00 1.1011890e-21 1.6846347e-16 1.8546507e-27], sampled 0.3213270672650326
[2019-03-26 22:30:41,443] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7896.2627 3163476900.4664 1744.0000
[2019-03-26 22:30:41,473] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.0497 2779423092.4578 933.0000
[2019-03-26 22:30:41,550] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8000.5586 3007134580.3178 1756.0000
[2019-03-26 22:30:41,629] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8500.5231 2842130846.0771 1119.0000
[2019-03-26 22:30:41,682] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8256.4953 2927321643.7773 1337.0000
[2019-03-26 22:30:42,817] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1800000, evaluation results [1800000.0, 7896.262673826279, 3163476900.4664245, 1744.0, 8256.495291832582, 2927321643.7772956, 1337.0, 8659.049655051982, 2779423092.457772, 933.0, 8000.558628253752, 3007134580.317751, 1756.0, 8500.523144888528, 2842130846.0770903, 1119.0]
[2019-03-26 22:30:42,890] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.7739111e-13 3.8772080e-02 4.7753190e-11 9.6122789e-01 4.1318585e-15], sum to 1.0000
[2019-03-26 22:30:42,892] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9919
[2019-03-26 22:30:42,901] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 63.0, 1.0, 2.0, 1.018884787524294, 1.0, 2.0, 1.018884787524294, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2850194.000154648, 2850194.000154647, 540502.8457550862], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3772800.0000, 
sim time next is 3773400.0000, 
raw observation next is [33.0, 63.0, 1.0, 2.0, 1.012954679236881, 1.0, 2.0, 1.012954679236881, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2833586.500272607, 2833586.500272607, 536863.9947136585], 
processed observation next is [1.0, 0.6956521739130435, 0.7630331753554502, 0.63, 1.0, 1.0, 1.0156080472733506, 1.0, 1.0, 1.0156080472733506, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7871073611868352, 0.7871073611868352, 0.801289544348744], 
reward next is 0.1987, 
noisyNet noise sample is [array([-0.61653197], dtype=float32), -0.10118634]. 
=============================================
[2019-03-26 22:30:46,284] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.4714471e-13 6.8228566e-08 1.6905291e-11 9.9999988e-01 2.1717713e-15], sum to 1.0000
[2019-03-26 22:30:46,285] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3518
[2019-03-26 22:30:46,289] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [37.0, 54.00000000000001, 1.0, 2.0, 0.9422885544530144, 1.0, 2.0, 0.9422885544530144, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2635700.247046721, 2635700.247046721, 495103.181274304], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4364400.0000, 
sim time next is 4365000.0000, 
raw observation next is [37.0, 54.0, 1.0, 2.0, 0.8808890015560283, 1.0, 2.0, 0.8808890015560283, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2463788.606134657, 2463788.606134657, 461189.2330863352], 
processed observation next is [1.0, 0.5217391304347826, 0.95260663507109, 0.54, 1.0, 1.0, 0.8564927729590703, 1.0, 1.0, 0.8564927729590703, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6843857239262936, 0.6843857239262936, 0.6883421389348287], 
reward next is 0.3117, 
noisyNet noise sample is [array([-3.3865988], dtype=float32), 0.2161407]. 
=============================================
[2019-03-26 22:30:46,326] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[23.433702]
 [20.815365]
 [21.536932]
 [22.702553]
 [23.819038]], R is [[26.19165802]
 [26.19078064]
 [25.92887306]
 [25.66958427]
 [25.41288948]].
[2019-03-26 22:31:02,795] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5197597e-17 9.9999309e-01 1.8940591e-15 6.9488437e-06 1.2192734e-21], sum to 1.0000
[2019-03-26 22:31:02,802] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3902
[2019-03-26 22:31:02,807] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.536276857337197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 749381.4684642986, 749381.4684642986, 189477.5372022543], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4643400.0000, 
sim time next is 4644000.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.5436324995674325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 759663.7563861004, 759663.7563861004, 190716.6130718746], 
processed observation next is [1.0, 0.782608695652174, 0.6682464454976303, 0.7, 1.0, 1.0, 0.4501596380330512, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21101771010725012, 0.21101771010725012, 0.28465166130130537], 
reward next is 0.7153, 
noisyNet noise sample is [array([-0.95084536], dtype=float32), 0.60367346]. 
=============================================
[2019-03-26 22:31:02,824] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[59.605988]
 [55.506973]
 [50.85207 ]
 [46.388065]
 [43.140804]], R is [[62.95621109]
 [63.04384613]
 [63.1322403 ]
 [63.22275543]
 [63.22777176]].
[2019-03-26 22:31:09,366] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.4659468e-24 1.0000000e+00 2.0920734e-22 2.4472354e-14 5.9321375e-29], sum to 1.0000
[2019-03-26 22:31:09,370] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1055
[2019-03-26 22:31:09,376] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.33333333333334, 67.33333333333333, 1.0, 2.0, 0.616656230138146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861747.397183462, 861747.397183462, 203891.3357227084], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4218000.0000, 
sim time next is 4218600.0000, 
raw observation next is [33.16666666666666, 69.16666666666667, 1.0, 2.0, 0.6245771916449745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 872821.1078463277, 872821.1078463277, 205415.340563011], 
processed observation next is [1.0, 0.8260869565217391, 0.7709320695102682, 0.6916666666666668, 1.0, 1.0, 0.5476833634276801, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24245030773509102, 0.24245030773509102, 0.3065900605418075], 
reward next is 0.6934, 
noisyNet noise sample is [array([2.1775157], dtype=float32), -0.72986525]. 
=============================================
[2019-03-26 22:31:11,405] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7057640e-20 1.0000000e+00 1.0376693e-20 6.5996729e-15 4.8637426e-26], sum to 1.0000
[2019-03-26 22:31:11,412] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7790
[2019-03-26 22:31:11,416] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.83333333333334, 75.66666666666667, 1.0, 2.0, 0.598659206729781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 836587.5184940917, 836587.5184940911, 200496.4403018882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4237800.0000, 
sim time next is 4238400.0000, 
raw observation next is [30.66666666666667, 76.33333333333334, 1.0, 2.0, 0.5952278981837773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 831790.6091750228, 831790.6091750228, 199860.3863433832], 
processed observation next is [1.0, 0.043478260869565216, 0.6524486571879939, 0.7633333333333334, 1.0, 1.0, 0.5123227688961172, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2310529469930619, 0.2310529469930619, 0.2982990840946018], 
reward next is 0.7017, 
noisyNet noise sample is [array([-1.4564749], dtype=float32), 0.36780372]. 
=============================================
[2019-03-26 22:31:19,335] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3142811e-13 4.7076112e-03 6.7088099e-11 9.9529243e-01 5.3686261e-16], sum to 1.0000
[2019-03-26 22:31:19,344] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7532
[2019-03-26 22:31:19,353] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.33333333333333, 62.33333333333333, 1.0, 2.0, 0.9893942871250022, 1.0, 2.0, 0.9893942871250022, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2767606.882988957, 2767606.882988958, 522612.0438883472], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4372800.0000, 
sim time next is 4373400.0000, 
raw observation next is [33.66666666666667, 59.16666666666667, 1.0, 2.0, 0.9946929300405004, 1.0, 2.0, 0.9946929300405004, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2782445.145188771, 2782445.145188772, 525786.9663828945], 
processed observation next is [1.0, 0.6086956521739131, 0.7946287519747238, 0.5916666666666667, 1.0, 1.0, 0.9936059398078319, 1.0, 1.0, 0.9936059398078319, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7729014292191031, 0.7729014292191033, 0.7847566662431262], 
reward next is 0.2152, 
noisyNet noise sample is [array([-0.12855716], dtype=float32), 0.2868449]. 
=============================================
[2019-03-26 22:31:21,149] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.2991455e-22 1.0000000e+00 1.4254623e-22 1.4128537e-15 1.5910455e-27], sum to 1.0000
[2019-03-26 22:31:21,159] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8891
[2019-03-26 22:31:21,164] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.6182813646164776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 864019.3681326366, 864019.3681326366, 204201.8957118532], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4399200.0000, 
sim time next is 4399800.0000, 
raw observation next is [30.83333333333334, 79.83333333333334, 1.0, 2.0, 0.6225070610073073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 869927.0001083423, 869927.0001083417, 205014.3152212159], 
processed observation next is [1.0, 0.9565217391304348, 0.6603475513428123, 0.7983333333333335, 1.0, 1.0, 0.545189230129286, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24164638891898396, 0.2416463889189838, 0.3059915152555461], 
reward next is 0.6940, 
noisyNet noise sample is [array([-0.68392617], dtype=float32), -1.5917077]. 
=============================================
[2019-03-26 22:31:26,459] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6371951e-23 1.0000000e+00 5.2929607e-23 5.1885003e-18 6.3869212e-29], sum to 1.0000
[2019-03-26 22:31:26,466] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8122
[2019-03-26 22:31:26,473] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 84.0, 1.0, 2.0, 0.5266037821918546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 735859.8443584514, 735859.844358452, 187868.5678555646], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4488600.0000, 
sim time next is 4489200.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.521256030414582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 728384.499280889, 728384.4992808898, 186992.7269796804], 
processed observation next is [0.0, 1.0, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4232000366440747, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20232902757802473, 0.20232902757802493, 0.27909362235773194], 
reward next is 0.7209, 
noisyNet noise sample is [array([-1.0754234], dtype=float32), 0.19804113]. 
=============================================
[2019-03-26 22:31:27,276] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9258311e-22 1.0000000e+00 8.8389913e-22 1.2796038e-17 7.2424706e-28], sum to 1.0000
[2019-03-26 22:31:27,282] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2855
[2019-03-26 22:31:27,288] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 66.0, 1.0, 2.0, 0.5104630775478667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 713297.7500051999, 713297.7500052005, 185251.6245727143], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5131800.0000, 
sim time next is 5132400.0000, 
raw observation next is [30.0, 66.0, 1.0, 2.0, 0.5103689724725529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 713166.2077364186, 713166.2077364192, 185236.5954961804], 
processed observation next is [0.0, 0.391304347826087, 0.6208530805687204, 0.66, 1.0, 1.0, 0.4100830993645215, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1981017243712274, 0.19810172437122756, 0.27647253059131405], 
reward next is 0.7235, 
noisyNet noise sample is [array([1.1656686], dtype=float32), -0.7748574]. 
=============================================
[2019-03-26 22:31:31,629] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.458912e-23 1.000000e+00 4.791451e-23 8.253994e-18 3.815522e-29], sum to 1.0000
[2019-03-26 22:31:31,638] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8349
[2019-03-26 22:31:31,646] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.5498011070409204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 768286.7916807865, 768286.791680786, 191766.3772246501], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4575600.0000, 
sim time next is 4576200.0000, 
raw observation next is [28.0, 84.0, 1.0, 2.0, 0.5507766209849794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 769650.4593724336, 769650.4593724343, 191933.6903364013], 
processed observation next is [0.0, 1.0, 0.5260663507109005, 0.84, 1.0, 1.0, 0.45876701323491487, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21379179427012043, 0.21379179427012063, 0.2864681945319423], 
reward next is 0.7135, 
noisyNet noise sample is [array([0.9982719], dtype=float32), -0.04488661]. 
=============================================
[2019-03-26 22:31:38,750] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 22:31:38,751] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 22:31:38,751] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 22:31:38,752] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:31:38,752] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:31:38,753] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 22:31:38,753] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 22:31:38,752] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 22:31:38,757] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:31:38,757] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:31:38,762] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:31:38,789] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run74
[2019-03-26 22:31:38,791] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run74
[2019-03-26 22:31:38,812] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run74
[2019-03-26 22:31:38,834] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run74
[2019-03-26 22:31:38,858] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run74
[2019-03-26 22:31:46,627] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09102932], dtype=float32), 0.06782177]
[2019-03-26 22:31:46,628] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.43333333333334, 73.33333333333334, 1.0, 2.0, 0.474871704910924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 718428.5283338411, 718428.5283338417, 186480.9559939143]
[2019-03-26 22:31:46,629] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:31:46,630] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.4338007e-22 1.0000000e+00 5.1995259e-22 2.5717012e-17 6.6685907e-28], sampled 0.4528503126119091
[2019-03-26 22:31:46,929] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09102932], dtype=float32), 0.06782177]
[2019-03-26 22:31:46,930] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.62810009333333, 64.75835274333335, 1.0, 2.0, 0.2768392228676117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 449310.3602034324, 449310.3602034324, 163532.1530095127]
[2019-03-26 22:31:46,931] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:31:46,934] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.7192805e-22 1.0000000e+00 7.8534387e-22 1.5554542e-17 1.3235795e-27], sampled 0.7784733027386861
[2019-03-26 22:31:48,891] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09102932], dtype=float32), 0.06782177]
[2019-03-26 22:31:48,894] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [15.91225574333333, 89.52317588333334, 1.0, 2.0, 0.1872500240598542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 313223.1927340518, 313223.1927340511, 125464.2417320148]
[2019-03-26 22:31:48,894] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:31:48,897] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.3380519e-21 1.0000000e+00 2.3286396e-21 5.9427253e-18 3.9355778e-27], sampled 0.7370261736641365
[2019-03-26 22:31:55,682] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09102932], dtype=float32), 0.06782177]
[2019-03-26 22:31:55,684] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.1, 92.0, 1.0, 2.0, 0.309179572014055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 490600.9813541404, 490600.981354141, 166361.1022286511]
[2019-03-26 22:31:55,686] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 22:31:55,689] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.8533363e-22 1.0000000e+00 8.5368351e-22 5.8511051e-18 1.1231488e-27], sampled 0.6419974464202594
[2019-03-26 22:32:05,048] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09102932], dtype=float32), 0.06782177]
[2019-03-26 22:32:05,050] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.0, 83.16666666666667, 1.0, 2.0, 0.4341436593234454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 634470.0543569291, 634470.0543569291, 177472.6534624292]
[2019-03-26 22:32:05,051] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 22:32:05,054] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.8159307e-23 1.0000000e+00 1.7989656e-22 3.0428070e-17 1.6237254e-28], sampled 0.9847250528898542
[2019-03-26 22:32:20,976] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09102932], dtype=float32), 0.06782177]
[2019-03-26 22:32:20,977] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.25, 66.0, 1.0, 2.0, 0.9442718994423178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1319859.05249365, 1319859.05249365, 282404.7435578063]
[2019-03-26 22:32:20,979] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 22:32:20,983] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2770995e-21 1.0000000e+00 2.1421849e-21 1.4045506e-16 3.1062161e-27], sampled 0.5872877103849828
[2019-03-26 22:32:23,856] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09102932], dtype=float32), 0.06782177]
[2019-03-26 22:32:23,858] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.88333333333334, 66.16666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.058798175625334, 6.9112, 168.9122060554613, 1558537.397279702, 1453826.636770228, 311350.8204417638]
[2019-03-26 22:32:23,859] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 22:32:23,864] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2139437e-14 9.9999571e-01 1.8370281e-13 4.2617776e-06 1.5884745e-18], sampled 0.08956801199333886
[2019-03-26 22:32:38,012] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09102932], dtype=float32), 0.06782177]
[2019-03-26 22:32:38,014] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.23333333333333, 69.66666666666667, 1.0, 2.0, 0.5774782434817908, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9885084954888738, 6.911199999999999, 6.9112, 168.9129565012996, 1614568.064806269, 1614568.06480627, 350302.145035057]
[2019-03-26 22:32:38,016] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 22:32:38,020] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.1214309e-14 1.0000000e+00 1.2813202e-14 1.9873443e-09 1.1980885e-18], sampled 0.4089309672720236
[2019-03-26 22:32:39,941] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09102932], dtype=float32), 0.06782177]
[2019-03-26 22:32:39,942] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.5545143, 62.99977732, 1.0, 2.0, 0.517134279210192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722622.9527685543, 722622.9527685543, 186326.0444222898]
[2019-03-26 22:32:39,943] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:32:39,946] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.9622242e-20 1.0000000e+00 1.6348901e-18 4.1313175e-11 9.2180842e-25], sampled 0.04045639331001416
[2019-03-26 22:33:09,615] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09102932], dtype=float32), 0.06782177]
[2019-03-26 22:33:09,615] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.05, 84.00000000000001, 1.0, 2.0, 0.5419119864910849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 757258.6806813597, 757258.680681359, 190423.7908543491]
[2019-03-26 22:33:09,618] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 22:33:09,623] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.9260955e-22 1.0000000e+00 3.2444471e-22 7.8674281e-18 3.9387598e-28], sampled 0.9174641080034054
[2019-03-26 22:33:29,657] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09102932], dtype=float32), 0.06782177]
[2019-03-26 22:33:29,658] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.6, 95.0, 1.0, 2.0, 0.7894754521107419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1103379.400868978, 1103379.400868978, 241340.0167837304]
[2019-03-26 22:33:29,661] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 22:33:29,663] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.3907528e-22 1.0000000e+00 1.1487568e-21 4.3066083e-17 1.5352854e-27], sampled 0.38157728651703804
[2019-03-26 22:33:30,194] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09102932], dtype=float32), 0.06782177]
[2019-03-26 22:33:30,194] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.65, 62.0, 1.0, 2.0, 0.7195166827186833, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.988018144785315, 6.9112, 168.9124348330544, 1902439.893739562, 1847942.626264371, 389604.5545733401]
[2019-03-26 22:33:30,195] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 22:33:30,198] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.1377845e-12 9.9868375e-01 4.9502343e-11 1.3162581e-03 1.5322624e-15], sampled 0.5041896573718735
[2019-03-26 22:33:30,199] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1902439.893739562 W.
[2019-03-26 22:33:32,277] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.1578 2842672823.9195 1126.0000
[2019-03-26 22:33:32,808] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.5762 2927398498.1281 1338.0000
[2019-03-26 22:33:33,000] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7889.2223 3164165552.1866 1762.0000
[2019-03-26 22:33:33,007] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.4066 2779337753.0413 933.0000
[2019-03-26 22:33:33,064] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.7875 3007760724.4232 1766.0000
[2019-03-26 22:33:34,082] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1825000, evaluation results [1825000.0, 7889.222301747263, 3164165552.1865683, 1762.0, 8253.576203935669, 2927398498.128107, 1338.0, 8658.406570527091, 2779337753.041312, 933.0, 7998.787469803482, 3007760724.4231625, 1766.0, 8495.15778314259, 2842672823.919491, 1126.0]
[2019-03-26 22:33:36,533] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5544755e-17 1.0000000e+00 3.0190819e-17 6.9100398e-12 2.0443902e-22], sum to 1.0000
[2019-03-26 22:33:36,541] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3312
[2019-03-26 22:33:36,551] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2772518.10512884 W.
[2019-03-26 22:33:36,559] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.2, 87.0, 1.0, 2.0, 0.6803506653049258, 1.0, 1.0, 0.6607653721667255, 1.0, 1.0, 1.03, 7.005096182875381, 6.9112, 170.5573041426782, 2772518.10512884, 2705256.449882685, 515194.8643187703], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5365200.0000, 
sim time next is 5365800.0000, 
raw observation next is [29.15, 87.5, 1.0, 2.0, 0.4301713016966485, 1.0, 2.0, 0.4301713016966485, 1.0, 2.0, 0.7470652912237499, 6.9112, 6.9112, 170.5573041426782, 1804216.461397768, 1804216.461397768, 370220.0762030437], 
processed observation next is [1.0, 0.08695652173913043, 0.5805687203791469, 0.875, 1.0, 1.0, 0.31345939963451624, 1.0, 1.0, 0.31345939963451624, 1.0, 1.0, 0.6915430380777438, 0.0, 0.0, 0.8375144448122397, 0.5011712392771578, 0.5011712392771578, 0.5525672779149906], 
reward next is 0.4474, 
noisyNet noise sample is [array([-0.48431364], dtype=float32), -0.0032945704]. 
=============================================
[2019-03-26 22:33:39,687] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.7169726e-09 8.1953126e-01 1.5794583e-08 1.8046874e-01 2.8304765e-11], sum to 1.0000
[2019-03-26 22:33:39,698] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3432
[2019-03-26 22:33:39,706] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2090837.922007837 W.
[2019-03-26 22:33:39,710] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.8541334142817109, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.991900039678725, 6.9112, 168.9124767030845, 2090837.922007837, 2033586.69900472, 422181.9928017646], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4791600.0000, 
sim time next is 4792200.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.736572823082003, 1.0, 1.0, 0.736572823082003, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2059792.120158099, 2059792.120158099, 390173.4170780159], 
processed observation next is [1.0, 0.4782608695652174, 0.6682464454976303, 0.66, 1.0, 1.0, 0.6826178591349433, 1.0, 0.5, 0.6826178591349433, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5721644778216942, 0.5721644778216942, 0.5823483836985313], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.81122965], dtype=float32), -0.7018468]. 
=============================================
[2019-03-26 22:33:39,968] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.3081193e-11 6.3979650e-01 1.8621336e-09 3.6020350e-01 5.8950993e-14], sum to 1.0000
[2019-03-26 22:33:39,977] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3158
[2019-03-26 22:33:39,988] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2509751.108742757 W.
[2019-03-26 22:33:39,993] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.75, 64.0, 1.0, 2.0, 0.5982037913842672, 1.0, 2.0, 0.5982037913842672, 1.0, 1.0, 1.03, 6.921184858770861, 6.9112, 170.5573041426782, 2509751.108742757, 2502598.548247102, 487327.1604566993], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4800600.0000, 
sim time next is 4801200.0000, 
raw observation next is [31.66666666666667, 64.33333333333333, 1.0, 2.0, 0.5908290691401255, 1.0, 2.0, 0.5908290691401255, 1.0, 2.0, 1.026074702937497, 6.9112, 6.9112, 170.5573041426782, 2478779.930974386, 2478779.930974386, 483636.0822821695], 
processed observation next is [1.0, 0.5652173913043478, 0.6998420221169038, 0.6433333333333333, 1.0, 1.0, 0.507022974867621, 1.0, 1.0, 0.507022974867621, 1.0, 1.0, 1.03179841821646, 0.0, 0.0, 0.8375144448122397, 0.6885499808262184, 0.6885499808262184, 0.7218448989286111], 
reward next is 0.2782, 
noisyNet noise sample is [array([-2.5197163], dtype=float32), -1.0485563]. 
=============================================
[2019-03-26 22:33:50,010] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.4698121e-12 9.9999642e-01 1.2131272e-11 3.6042547e-06 6.7434066e-16], sum to 1.0000
[2019-03-26 22:33:50,020] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8628
[2019-03-26 22:33:50,028] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2033513.99583333 W.
[2019-03-26 22:33:50,032] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 68.66666666666667, 1.0, 2.0, 0.8131760705110691, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.982939826383292, 6.9112, 168.9125300874012, 2033513.99583333, 1982619.422387112, 411950.4944838729], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4959600.0000, 
sim time next is 4960200.0000, 
raw observation next is [30.0, 69.33333333333333, 1.0, 2.0, 0.4924350292006684, 1.0, 1.0, 0.4924350292006684, 1.0, 2.0, 0.846931004251154, 6.9112, 6.9112, 170.5573041426782, 2065613.570895166, 2065613.570895166, 408481.7962239166], 
processed observation next is [1.0, 0.391304347826087, 0.6208530805687204, 0.6933333333333332, 1.0, 1.0, 0.38847593879598596, 1.0, 0.5, 0.38847593879598596, 1.0, 1.0, 0.8133304929892122, 0.0, 0.0, 0.8375144448122397, 0.5737815474708794, 0.5737815474708794, 0.6096743227222635], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.9587107], dtype=float32), 1.4668815]. 
=============================================
[2019-03-26 22:33:53,687] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.6657551e-22 1.0000000e+00 4.7874522e-22 9.5927553e-17 1.4733525e-27], sum to 1.0000
[2019-03-26 22:33:53,697] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3952
[2019-03-26 22:33:53,703] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333334, 59.66666666666667, 1.0, 2.0, 0.5228005374421864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 730543.4802124075, 730543.4802124068, 187246.0124310103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5065800.0000, 
sim time next is 5066400.0000, 
raw observation next is [31.66666666666667, 60.33333333333334, 1.0, 2.0, 0.5228746782548913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 730647.1176633828, 730647.1176633834, 187258.0611909356], 
processed observation next is [0.0, 0.6521739130434783, 0.6998420221169038, 0.6033333333333334, 1.0, 1.0, 0.42515021476492926, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.202957532684273, 0.20295753268427316, 0.2794896435685606], 
reward next is 0.7205, 
noisyNet noise sample is [array([0.04816826], dtype=float32), -0.38274455]. 
=============================================
[2019-03-26 22:33:53,709] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2030459e-22 1.0000000e+00 3.7785713e-22 5.1383627e-14 6.2592314e-29], sum to 1.0000
[2019-03-26 22:33:53,719] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4884
[2019-03-26 22:33:53,722] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.96666666666667, 78.5, 1.0, 2.0, 0.5822848562401479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813696.6579454262, 813696.6579454262, 197492.1938883586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5515800.0000, 
sim time next is 5516400.0000, 
raw observation next is [29.83333333333334, 79.0, 1.0, 2.0, 0.5815143960302137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 812619.5893772576, 812619.589377257, 197352.7054057249], 
processed observation next is [1.0, 0.8695652173913043, 0.6129541864139023, 0.79, 1.0, 1.0, 0.49580047714483577, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22572766371590489, 0.22572766371590475, 0.29455627672496254], 
reward next is 0.7054, 
noisyNet noise sample is [array([-0.22440188], dtype=float32), 0.4367355]. 
=============================================
[2019-03-26 22:33:58,220] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.6888394e-12 7.8617585e-01 2.6559857e-10 2.1382409e-01 3.1232349e-15], sum to 1.0000
[2019-03-26 22:33:58,228] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7073
[2019-03-26 22:33:58,235] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2311349.79058196 W.
[2019-03-26 22:33:58,238] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.26666666666667, 53.66666666666667, 1.0, 2.0, 0.8264372499824164, 1.0, 2.0, 0.8264372499824164, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2311349.79058196, 2311349.79058196, 432942.2089740636], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5588400.0000, 
sim time next is 5589000.0000, 
raw observation next is [33.2, 54.0, 1.0, 2.0, 1.015348595718289, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.986928283891902, 6.9112, 168.9125064213364, 2316485.364543148, 2262761.256738644, 468764.4876162245], 
processed observation next is [1.0, 0.6956521739130435, 0.7725118483412324, 0.54, 1.0, 1.0, 1.0184922839979387, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.0075728283891901785, 0.0, 0.8294377350087965, 0.6434681568175411, 0.6285447935385122, 0.6996484889794395], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7078815], dtype=float32), 3.3277771]. 
=============================================
[2019-03-26 22:33:58,247] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[40.80963 ]
 [40.052105]
 [39.05099 ]
 [38.762875]
 [41.417995]], R is [[40.31079865]
 [40.26150894]
 [40.2004776 ]
 [39.79847336]
 [39.69661713]].
[2019-03-26 22:34:07,034] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2275918e-13 8.9408511e-01 1.7729127e-11 1.0591487e-01 1.6966875e-16], sum to 1.0000
[2019-03-26 22:34:07,042] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1288
[2019-03-26 22:34:07,048] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666667, 71.66666666666667, 1.0, 2.0, 0.2695515923118303, 1.0, 2.0, 0.2695515923118303, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 753329.7410114136, 753329.7410114136, 244272.3113792974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5246400.0000, 
sim time next is 5247000.0000, 
raw observation next is [30.5, 72.5, 1.0, 2.0, 0.5305780264447282, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 741415.2685208113, 741415.2685208119, 188528.4508027906], 
processed observation next is [1.0, 0.7391304347826086, 0.6445497630331753, 0.725, 1.0, 1.0, 0.43443135716232306, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20594868570022537, 0.20594868570022554, 0.28138574746685163], 
reward next is 0.7186, 
noisyNet noise sample is [array([-0.18710482], dtype=float32), 0.46903437]. 
=============================================
[2019-03-26 22:34:07,077] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[45.391407]
 [41.59294 ]
 [38.646427]
 [38.187492]
 [40.417053]], R is [[50.0605278 ]
 [50.19533539]
 [50.28066635]
 [49.77785873]
 [49.50294876]].
[2019-03-26 22:34:07,914] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.04070986e-20 1.00000000e+00 1.49519600e-20 2.04861424e-14
 1.02970877e-26], sum to 1.0000
[2019-03-26 22:34:07,923] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2741
[2019-03-26 22:34:07,928] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.1, 83.0, 1.0, 2.0, 0.8977171774923044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1254748.588977918, 1254748.588977918, 269311.1353555602], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5814000.0000, 
sim time next is 5814600.0000, 
raw observation next is [28.28333333333333, 82.16666666666667, 1.0, 2.0, 0.8528473451741722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1191998.355556287, 1191998.355556287, 257297.132162842], 
processed observation next is [1.0, 0.30434782608695654, 0.5394944707740915, 0.8216666666666668, 1.0, 1.0, 0.8227076447881592, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33111065432119086, 0.33111065432119086, 0.3840255703923015], 
reward next is 0.6160, 
noisyNet noise sample is [array([-0.02021446], dtype=float32), 0.4932207]. 
=============================================
[2019-03-26 22:34:09,320] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8234413e-18 1.0000000e+00 1.6856808e-18 5.9642363e-13 1.8410700e-24], sum to 1.0000
[2019-03-26 22:34:09,333] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9001
[2019-03-26 22:34:09,344] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1696244.454574997 W.
[2019-03-26 22:34:09,348] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.23333333333333, 82.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.252776829312349, 6.9112, 168.9110073288307, 1696244.454574997, 1453920.892033781, 311356.3008243894], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5298000.0000, 
sim time next is 5298600.0000, 
raw observation next is [30.36666666666667, 81.5, 1.0, 2.0, 0.568882382530602, 0.0, 2.0, 0.0, 1.0, 1.0, 0.987960566176923, 6.9112, 6.9112, 168.9126783838104, 1590516.941572226, 1590516.941572226, 348065.8869583656], 
processed observation next is [1.0, 0.30434782608695654, 0.6382306477093209, 0.815, 1.0, 1.0, 0.4805811837718096, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.9853177636303937, 0.0, 0.0, 0.8294385794232686, 0.44181026154784053, 0.44181026154784053, 0.5195013238184562], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.90901613], dtype=float32), -0.82990974]. 
=============================================
[2019-03-26 22:34:11,102] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4338981e-11 2.0720011e-02 1.1753950e-09 9.7927994e-01 2.0166481e-14], sum to 1.0000
[2019-03-26 22:34:11,112] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3925
[2019-03-26 22:34:11,118] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.3, 52.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.410926849895674, 6.9112, 170.5573041426782, 3267721.384654039, 2909746.71448518, 550954.3052406273], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5313600.0000, 
sim time next is 5314200.0000, 
raw observation next is [36.28333333333333, 52.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.106010382476932, 6.9112, 170.5573041426782, 3049042.896306989, 2909492.294959056, 552634.734270543], 
processed observation next is [1.0, 0.5217391304347826, 0.9186413902053712, 0.52, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.2195121951219512, 0.019481038247693226, 0.0, 0.8375144448122397, 0.8469563600852746, 0.8081923041552934, 0.8248279615978253], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.88769925], dtype=float32), -1.4047465]. 
=============================================
[2019-03-26 22:34:13,686] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.80507242e-21 1.00000000e+00 1.34533568e-20 1.50612792e-15
 1.22455525e-26], sum to 1.0000
[2019-03-26 22:34:13,695] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0887
[2019-03-26 22:34:13,701] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 90.0, 1.0, 2.0, 0.7027348165219205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 982093.6955925846, 982093.6955925851, 221436.6562364791], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5983200.0000, 
sim time next is 5983800.0000, 
raw observation next is [26.96666666666667, 89.5, 1.0, 2.0, 0.8160636344712391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1140559.288397876, 1140559.288397877, 247892.1964490755], 
processed observation next is [1.0, 0.2608695652173913, 0.47709320695102697, 0.895, 1.0, 1.0, 0.7783899210496856, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31682202455496555, 0.31682202455496583, 0.3699883529090679], 
reward next is 0.6300, 
noisyNet noise sample is [array([1.4042066], dtype=float32), -0.32769993]. 
=============================================
[2019-03-26 22:34:30,302] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-26 22:34:30,304] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 22:34:30,305] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:34:30,305] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 22:34:30,306] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 22:34:30,306] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:34:30,307] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 22:34:30,308] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:34:30,308] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 22:34:30,309] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:34:30,312] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:34:30,334] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run75
[2019-03-26 22:34:30,360] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run75
[2019-03-26 22:34:30,383] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run75
[2019-03-26 22:34:30,401] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run75
[2019-03-26 22:34:30,430] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run75
[2019-03-26 22:34:39,127] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09143076], dtype=float32), 0.068318285]
[2019-03-26 22:34:39,129] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.01836010666667, 79.516743, 1.0, 2.0, 0.2820081273979004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 454676.7654609582, 454676.7654609582, 163913.438563133]
[2019-03-26 22:34:39,129] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:34:39,132] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.9324066e-22 1.0000000e+00 8.7012585e-22 3.3501009e-18 1.2263357e-27], sampled 0.08267354620307543
[2019-03-26 22:34:54,132] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09143076], dtype=float32), 0.068318285]
[2019-03-26 22:34:54,134] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.2, 81.0, 1.0, 2.0, 0.3406727090459362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 532067.1254495085, 532067.1254495085, 169370.0794028605]
[2019-03-26 22:34:54,135] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:34:54,139] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.1947911e-23 1.0000000e+00 5.7615643e-23 2.6004069e-18 6.0628606e-29], sampled 0.5688996635470146
[2019-03-26 22:35:15,550] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09143076], dtype=float32), 0.068318285]
[2019-03-26 22:35:15,552] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.9, 85.66666666666667, 1.0, 2.0, 0.5272546475909481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 736769.6589615996, 736769.6589616003, 187975.6571304573]
[2019-03-26 22:35:15,555] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:35:15,558] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.1901510e-23 1.0000000e+00 7.9616342e-23 1.6818342e-17 5.6979209e-29], sampled 0.07947987737757334
[2019-03-26 22:35:24,601] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09143076], dtype=float32), 0.068318285]
[2019-03-26 22:35:24,602] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.6, 58.0, 1.0, 2.0, 0.7528948960262044, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.005476484210245, 6.9112, 168.9116470954813, 1949150.066953473, 1882267.602786114, 396545.8711249892]
[2019-03-26 22:35:24,603] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 22:35:24,606] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.1722050e-20 1.0000000e+00 3.3394945e-20 3.9747995e-15 1.1261745e-25], sampled 0.5038052940522558
[2019-03-26 22:35:24,607] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1949150.066953473 W.
[2019-03-26 22:35:45,553] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09143076], dtype=float32), 0.068318285]
[2019-03-26 22:35:45,557] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.838360605, 81.09328178999999, 1.0, 2.0, 0.5300833671011647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740723.8040344352, 740723.8040344346, 188443.3479838145]
[2019-03-26 22:35:45,558] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:35:45,561] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.2664919e-23 1.0000000e+00 3.9846664e-23 3.7897375e-18 3.4718200e-29], sampled 0.5759449613460155
[2019-03-26 22:35:46,583] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09143076], dtype=float32), 0.068318285]
[2019-03-26 22:35:46,584] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.84803041666667, 70.92732455333334, 1.0, 2.0, 0.603228034384763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 842974.6932553961, 842974.6932553961, 201349.0052610825]
[2019-03-26 22:35:46,585] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:35:46,587] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.4586647e-23 1.0000000e+00 6.5245991e-23 7.1002305e-18 6.0090736e-29], sampled 0.5395836729248038
[2019-03-26 22:36:12,603] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09143076], dtype=float32), 0.068318285]
[2019-03-26 22:36:12,605] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.73333333333333, 87.33333333333334, 1.0, 2.0, 0.5583977185706083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 780304.0265560901, 780304.0265560894, 193251.1263209496]
[2019-03-26 22:36:12,606] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 22:36:12,611] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.4808158e-23 1.0000000e+00 3.1425978e-23 6.7386922e-18 2.1315630e-29], sampled 0.7666539445841891
[2019-03-26 22:36:24,538] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.4473 3007671692.2141 1766.0000
[2019-03-26 22:36:24,581] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7886.2590 3164161369.4427 1770.0000
[2019-03-26 22:36:24,799] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.4320 2779397896.3857 933.0000
[2019-03-26 22:36:24,830] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8250.6859 2927496244.0118 1338.0000
[2019-03-26 22:36:24,944] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8858 2842480929.4909 1131.0000
[2019-03-26 22:36:25,963] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1850000, evaluation results [1850000.0, 7886.258958834942, 3164161369.4427423, 1770.0, 8250.685938230474, 2927496244.0117564, 1338.0, 8660.432005415354, 2779397896.3857465, 933.0, 7997.447328726946, 3007671692.2141175, 1766.0, 8496.885825785039, 2842480929.4909215, 1131.0]
[2019-03-26 22:36:30,670] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.5501636e-23 1.0000000e+00 8.4275304e-23 1.1815539e-18 3.7466364e-29], sum to 1.0000
[2019-03-26 22:36:30,680] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0851
[2019-03-26 22:36:30,687] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.43333333333333, 82.0, 1.0, 2.0, 0.517413712202767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723013.5542468562, 723013.5542468562, 186369.2482448309], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5726400.0000, 
sim time next is 5727000.0000, 
raw observation next is [27.61666666666667, 81.0, 1.0, 2.0, 0.5182035140574606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 724117.5684371626, 724117.5684371626, 186497.1799061705], 
processed observation next is [0.0, 0.2608695652173913, 0.5078988941548186, 0.81, 1.0, 1.0, 0.41952230609332597, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20114376901032294, 0.20114376901032294, 0.27835399985995596], 
reward next is 0.7216, 
noisyNet noise sample is [array([0.8835027], dtype=float32), 0.582278]. 
=============================================
[2019-03-26 22:36:30,701] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[73.386086]
 [73.38446 ]
 [73.383995]
 [73.37502 ]
 [73.35358 ]], R is [[73.36218262]
 [73.35040283]
 [73.33905029]
 [73.32814026]
 [73.31764984]].
[2019-03-26 22:36:31,922] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8436995e-23 1.0000000e+00 6.9098561e-23 1.6968291e-18 9.3132152e-29], sum to 1.0000
[2019-03-26 22:36:31,935] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6350
[2019-03-26 22:36:31,942] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.96666666666667, 79.16666666666667, 1.0, 2.0, 0.5203001505872328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 727048.329947903, 727048.3299479038, 186837.6735789017], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5728200.0000, 
sim time next is 5728800.0000, 
raw observation next is [28.13333333333333, 78.33333333333334, 1.0, 2.0, 0.5211864883841889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 728287.2904269149, 728287.2904269149, 186982.0259376628], 
processed observation next is [0.0, 0.30434782608695654, 0.532385466034755, 0.7833333333333334, 1.0, 1.0, 0.42311625106528783, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20230202511858747, 0.20230202511858747, 0.2790776506532281], 
reward next is 0.7209, 
noisyNet noise sample is [array([-0.37620106], dtype=float32), 0.49404493]. 
=============================================
[2019-03-26 22:36:32,193] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.9482599e-24 1.0000000e+00 5.2628811e-23 8.4822855e-18 4.9996690e-29], sum to 1.0000
[2019-03-26 22:36:32,202] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2742
[2019-03-26 22:36:32,208] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.0, 53.0, 1.0, 2.0, 0.5180462406040486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 723897.725706286, 723897.7257062853, 186471.9257191476], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5752200.0000, 
sim time next is 5752800.0000, 
raw observation next is [32.8, 53.0, 1.0, 2.0, 0.5123013271457002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 715867.3014275094, 715867.3014275087, 185545.9111822582], 
processed observation next is [0.0, 0.6086956521739131, 0.7535545023696681, 0.53, 1.0, 1.0, 0.41241123752493997, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19885202817430817, 0.19885202817430797, 0.2769341957944152], 
reward next is 0.7231, 
noisyNet noise sample is [array([0.94749564], dtype=float32), 0.65474993]. 
=============================================
[2019-03-26 22:36:43,200] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.4418369e-11 2.4917471e-01 1.1072961e-09 7.5082535e-01 2.0404033e-14], sum to 1.0000
[2019-03-26 22:36:43,208] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8276
[2019-03-26 22:36:43,215] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.33333333333334, 78.66666666666667, 1.0, 2.0, 0.8051819965904577, 1.0, 2.0, 0.8051819965904577, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2251850.310460521, 2251850.310460521, 422410.137033268], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5935200.0000, 
sim time next is 5935800.0000, 
raw observation next is [30.36666666666666, 78.83333333333334, 1.0, 2.0, 0.8022919910658877, 1.0, 2.0, 0.8022919910658877, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2243760.584436621, 2243760.584436621, 420997.3373637049], 
processed observation next is [1.0, 0.6956521739130435, 0.6382306477093204, 0.7883333333333334, 1.0, 1.0, 0.761797579597455, 1.0, 1.0, 0.761797579597455, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6232668290101725, 0.6232668290101725, 0.6283542348712013], 
reward next is 0.3716, 
noisyNet noise sample is [array([0.49435452], dtype=float32), -1.3705292]. 
=============================================
[2019-03-26 22:36:43,606] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6053461e-22 1.0000000e+00 1.2984727e-22 7.7281599e-18 1.6945823e-28], sum to 1.0000
[2019-03-26 22:36:43,615] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0635
[2019-03-26 22:36:43,620] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.25, 88.0, 1.0, 2.0, 0.5356992737036375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 748574.0814228959, 748574.0814228959, 189378.8006929159], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6244200.0000, 
sim time next is 6244800.0000, 
raw observation next is [27.33333333333334, 87.66666666666667, 1.0, 2.0, 0.535774913296884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 748679.8157333675, 748679.8157333675, 189391.5421148086], 
processed observation next is [0.0, 0.2608695652173913, 0.4944707740916275, 0.8766666666666667, 1.0, 1.0, 0.44069266662275175, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20796661548149095, 0.20796661548149095, 0.28267394345493824], 
reward next is 0.7173, 
noisyNet noise sample is [array([-0.9240014], dtype=float32), 0.1816842]. 
=============================================
[2019-03-26 22:36:51,986] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.6033280e-20 1.0000000e+00 1.4339884e-20 2.3691374e-15 9.9365174e-27], sum to 1.0000
[2019-03-26 22:36:51,995] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8030
[2019-03-26 22:36:52,000] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 93.0, 1.0, 2.0, 0.7593145975373807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1061205.202360641, 1061205.202360641, 234168.3392034768], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6063000.0000, 
sim time next is 6063600.0000, 
raw observation next is [26.1, 93.0, 1.0, 2.0, 0.6839299149466307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 955801.4363278971, 955801.4363278977, 217414.0147875368], 
processed observation next is [1.0, 0.17391304347826086, 0.4360189573459717, 0.93, 1.0, 1.0, 0.6191926686103985, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2655003989799714, 0.2655003989799716, 0.32449852953363706], 
reward next is 0.6755, 
noisyNet noise sample is [array([1.7127603], dtype=float32), 3.0892477]. 
=============================================
[2019-03-26 22:36:54,235] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0964672e-11 8.0644655e-01 5.1465476e-10 1.9355345e-01 7.2408120e-15], sum to 1.0000
[2019-03-26 22:36:54,241] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7634
[2019-03-26 22:36:54,250] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2184061.709483602 W.
[2019-03-26 22:36:54,256] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.63333333333334, 66.83333333333333, 1.0, 2.0, 0.7809658383577261, 1.0, 2.0, 0.7809658383577261, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2184061.709483602, 2184061.709483601, 410708.050467802], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6105000.0000, 
sim time next is 6105600.0000, 
raw observation next is [30.6, 67.0, 1.0, 2.0, 0.7826461532052678, 1.0, 2.0, 0.7826461532052678, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2188765.706411435, 2188765.706411435, 411508.0869808395], 
processed observation next is [1.0, 0.6956521739130435, 0.6492890995260664, 0.67, 1.0, 1.0, 0.7381278954280335, 1.0, 1.0, 0.7381278954280335, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6079904740031763, 0.6079904740031763, 0.6141911745982679], 
reward next is 0.3858, 
noisyNet noise sample is [array([0.82167554], dtype=float32), 0.7142531]. 
=============================================
[2019-03-26 22:36:56,708] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1152910e-23 1.0000000e+00 6.1067957e-23 6.5620609e-17 2.6313860e-29], sum to 1.0000
[2019-03-26 22:36:56,716] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5910
[2019-03-26 22:36:56,723] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.26666666666667, 82.0, 1.0, 2.0, 0.5148026147087661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 719363.6739407566, 719363.6739407566, 185947.4626036887], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6388800.0000, 
sim time next is 6389400.0000, 
raw observation next is [27.23333333333333, 82.0, 1.0, 2.0, 0.5136162823872085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 717705.3826788549, 717705.3826788554, 185756.5918737479], 
processed observation next is [0.0, 0.9565217391304348, 0.4897314375987361, 0.82, 1.0, 1.0, 0.4139955209484439, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19936260629968192, 0.19936260629968205, 0.27724864458768345], 
reward next is 0.7228, 
noisyNet noise sample is [array([1.0476865], dtype=float32), -0.69297314]. 
=============================================
[2019-03-26 22:36:58,334] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3220208e-22 1.0000000e+00 1.1175712e-20 9.8347916e-16 4.2385739e-27], sum to 1.0000
[2019-03-26 22:36:58,340] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0941
[2019-03-26 22:36:58,345] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 89.5, 1.0, 2.0, 0.5209585752752517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 727968.7037008121, 727968.7037008121, 186945.2724549527], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6222600.0000, 
sim time next is 6223200.0000, 
raw observation next is [26.56666666666666, 89.66666666666667, 1.0, 2.0, 0.5205903980642519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 727454.0499943167, 727454.0499943167, 186885.3165544713], 
processed observation next is [0.0, 0.0, 0.4581358609794626, 0.8966666666666667, 1.0, 1.0, 0.42239806995692997, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20207056944286575, 0.20207056944286575, 0.27893330829025564], 
reward next is 0.7211, 
noisyNet noise sample is [array([0.11912715], dtype=float32), 0.65840083]. 
=============================================
[2019-03-26 22:37:00,190] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.4694890e-22 1.0000000e+00 5.8424170e-22 5.7582172e-18 2.3684530e-28], sum to 1.0000
[2019-03-26 22:37:00,201] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7710
[2019-03-26 22:37:00,206] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666666, 64.0, 1.0, 2.0, 0.5462490005464246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 763321.3286423986, 763321.3286423986, 191160.036054712], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6349200.0000, 
sim time next is 6349800.0000, 
raw observation next is [31.83333333333333, 63.5, 1.0, 2.0, 0.547774198161312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 765453.388110173, 765453.388110173, 191420.3098841449], 
processed observation next is [0.0, 0.4782608695652174, 0.7077409162717218, 0.635, 1.0, 1.0, 0.45514963633893013, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21262594114171474, 0.21262594114171474, 0.2857019550509625], 
reward next is 0.7143, 
noisyNet noise sample is [array([0.3175931], dtype=float32), -0.65390754]. 
=============================================
[2019-03-26 22:37:02,560] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7881086e-21 1.0000000e+00 1.7038195e-20 2.4472436e-15 1.0337705e-26], sum to 1.0000
[2019-03-26 22:37:02,568] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9436
[2019-03-26 22:37:02,574] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 90.0, 1.0, 2.0, 0.5309965257489656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742000.2722897487, 742000.2722897487, 188595.0932419482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6483600.0000, 
sim time next is 6484200.0000, 
raw observation next is [26.65, 90.16666666666667, 1.0, 2.0, 0.5302752517282425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 740992.0318166435, 740992.0318166435, 188475.511562155], 
processed observation next is [1.0, 0.043478260869565216, 0.462085308056872, 0.9016666666666667, 1.0, 1.0, 0.43406656834728014, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20583111994906766, 0.20583111994906766, 0.2813067336748582], 
reward next is 0.7187, 
noisyNet noise sample is [array([-0.0210133], dtype=float32), 1.2198205]. 
=============================================
[2019-03-26 22:37:10,512] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.64133563e-24 1.00000000e+00 1.23722065e-23 5.49599375e-19
 2.83526999e-30], sum to 1.0000
[2019-03-26 22:37:10,520] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5613
[2019-03-26 22:37:10,527] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.53333333333333, 82.0, 1.0, 2.0, 0.5247844716849677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733316.7185772388, 733316.7185772388, 187569.9571318318], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6382200.0000, 
sim time next is 6382800.0000, 
raw observation next is [27.5, 82.0, 1.0, 2.0, 0.5246813269307252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 733172.5377181085, 733172.5377181091, 187552.9600008283], 
processed observation next is [0.0, 0.9130434782608695, 0.5023696682464456, 0.82, 1.0, 1.0, 0.4273268999165364, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20365903825503015, 0.2036590382550303, 0.27992979104601234], 
reward next is 0.7201, 
noisyNet noise sample is [array([0.5160949], dtype=float32), -0.35075787]. 
=============================================
[2019-03-26 22:37:18,172] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.3089962e-21 1.0000000e+00 2.5534077e-20 1.2758180e-15 1.1381674e-26], sum to 1.0000
[2019-03-26 22:37:18,185] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5086
[2019-03-26 22:37:18,192] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 89.0, 1.0, 2.0, 0.721828431112643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1008790.287836454, 1008790.287836454, 225627.0331261216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6505200.0000, 
sim time next is 6505800.0000, 
raw observation next is [26.86666666666667, 88.66666666666667, 1.0, 2.0, 0.6540641099500806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 914045.6032298539, 914045.6032298539, 211242.1877923063], 
processed observation next is [1.0, 0.30434782608695654, 0.4723538704581361, 0.8866666666666667, 1.0, 1.0, 0.5832097710241935, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2539015564527372, 0.2539015564527372, 0.31528684745120344], 
reward next is 0.6847, 
noisyNet noise sample is [array([-0.04188065], dtype=float32), 0.62959194]. 
=============================================
[2019-03-26 22:37:21,299] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3577422e-22 1.0000000e+00 2.6478287e-22 1.6604413e-16 1.1706369e-28], sum to 1.0000
[2019-03-26 22:37:21,307] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1650
[2019-03-26 22:37:21,314] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 81.0, 1.0, 2.0, 0.5070527216805558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 708530.6854465901, 708530.6854465901, 184708.7648661657], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6559200.0000, 
sim time next is 6559800.0000, 
raw observation next is [27.45, 81.66666666666667, 1.0, 2.0, 0.5095254918336827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 711987.1715569719, 711987.1715569724, 185102.2386850603], 
processed observation next is [1.0, 0.9565217391304348, 0.5, 0.8166666666666668, 1.0, 1.0, 0.40906685763094297, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19777421432138106, 0.19777421432138123, 0.27627199803740343], 
reward next is 0.7237, 
noisyNet noise sample is [array([-0.38066196], dtype=float32), 0.3060694]. 
=============================================
[2019-03-26 22:37:22,066] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 22:37:22,069] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 22:37:22,070] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:37:22,071] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 22:37:22,071] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 22:37:22,073] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:37:22,075] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:37:22,073] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 22:37:22,076] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 22:37:22,080] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:37:22,081] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:37:22,101] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run76
[2019-03-26 22:37:22,124] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run76
[2019-03-26 22:37:22,145] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run76
[2019-03-26 22:37:22,165] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run76
[2019-03-26 22:37:22,166] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run76
[2019-03-26 22:37:58,910] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09209881], dtype=float32), 0.06909022]
[2019-03-26 22:37:58,912] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.51666666666667, 93.5, 1.0, 2.0, 0.3767836268852253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 572734.7354950438, 572734.7354950444, 172385.0668147149]
[2019-03-26 22:37:58,913] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 22:37:58,916] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.4889727e-22 1.0000000e+00 9.3510900e-22 3.3819336e-17 9.0731840e-28], sampled 0.8344546534907695
[2019-03-26 22:38:35,573] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09209881], dtype=float32), 0.06909022]
[2019-03-26 22:38:35,577] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.5, 79.0, 1.0, 2.0, 0.5055472138692355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 706426.262918072, 706426.2629180714, 184469.471636405]
[2019-03-26 22:38:35,578] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 22:38:35,580] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.1229639e-23 1.0000000e+00 2.1462573e-22 3.1534650e-16 2.3808349e-29], sampled 0.805202874132635
[2019-03-26 22:38:53,778] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09209881], dtype=float32), 0.06909022]
[2019-03-26 22:38:53,779] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.97238573, 73.23585674, 1.0, 2.0, 0.3929338750710243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 593604.9992587368, 593604.9992587368, 174156.8385117655]
[2019-03-26 22:38:53,781] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:38:53,783] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.7089332e-23 1.0000000e+00 4.8826000e-23 7.9319466e-18 3.0337483e-29], sampled 0.23670377389514774
[2019-03-26 22:39:03,401] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09209881], dtype=float32), 0.06909022]
[2019-03-26 22:39:03,403] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.51666666666667, 57.83333333333334, 1.0, 2.0, 0.4310396285639245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 625009.0755310854, 625009.075531086, 176413.4769398913]
[2019-03-26 22:39:03,405] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 22:39:03,408] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.7123895e-23 1.0000000e+00 9.2229124e-23 9.0425474e-18 7.2509258e-29], sampled 0.14139887936052942
[2019-03-26 22:39:16,441] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09209881], dtype=float32), 0.06909022]
[2019-03-26 22:39:16,443] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.71025166, 66.84788160333333, 1.0, 2.0, 0.8692632456209313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1214955.479048955, 1214955.479048955, 261622.9264297304]
[2019-03-26 22:39:16,443] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:39:16,446] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.4337371e-22 1.0000000e+00 8.5437094e-22 2.2892050e-16 6.3278003e-28], sampled 0.3304261239273846
[2019-03-26 22:39:16,723] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.7357 2927284574.6276 1336.0000
[2019-03-26 22:39:16,803] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 22:39:16,868] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7887.9849 3163999894.5087 1767.0000
[2019-03-26 22:39:16,905] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5232 3007466293.1397 1760.0000
[2019-03-26 22:39:16,967] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.3804 2842455440.5841 1125.0000
[2019-03-26 22:39:17,986] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1875000, evaluation results [1875000.0, 7887.984901109404, 3163999894.508747, 1767.0, 8255.735685227946, 2927284574.6275697, 1336.0, 8661.467580702742, 2779124528.011676, 933.0, 7997.523203016594, 3007466293.139725, 1760.0, 8497.380379819886, 2842455440.584143, 1125.0]
[2019-03-26 22:39:18,407] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.3993880e-21 1.0000000e+00 4.2697797e-20 7.0822796e-15 1.7070606e-26], sum to 1.0000
[2019-03-26 22:39:18,416] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7316
[2019-03-26 22:39:18,429] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 90.5, 1.0, 2.0, 0.6800205814721221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 950335.64476138, 950335.6447613795, 216590.1856917202], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6575400.0000, 
sim time next is 6576000.0000, 
raw observation next is [26.06666666666667, 90.66666666666667, 1.0, 2.0, 0.6568285128143575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 917910.487686318, 917910.487686318, 211801.0630103037], 
processed observation next is [1.0, 0.08695652173913043, 0.4344391785150081, 0.9066666666666667, 1.0, 1.0, 0.586540376884768, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.25497513546842165, 0.25497513546842165, 0.31612098956761747], 
reward next is 0.6839, 
noisyNet noise sample is [array([-0.28738043], dtype=float32), 0.54799086]. 
=============================================
[2019-03-26 22:39:18,442] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[67.63215 ]
 [67.537056]
 [67.593094]
 [67.8326  ]
 [67.790054]], R is [[67.59780121]
 [67.59854889]
 [67.56638336]
 [67.49970245]
 [67.54748535]].
[2019-03-26 22:39:19,317] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.7054790e-21 1.0000000e+00 6.4953311e-20 9.3951743e-15 9.8199717e-26], sum to 1.0000
[2019-03-26 22:39:19,327] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4709
[2019-03-26 22:39:19,331] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 86.5, 1.0, 2.0, 0.663437006082933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 927149.8141302812, 927149.8141302812, 213149.8031518069], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6593400.0000, 
sim time next is 6594000.0000, 
raw observation next is [26.86666666666667, 86.0, 1.0, 2.0, 0.6336157989283716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 885457.457484027, 885457.4574840264, 207167.517779636], 
processed observation next is [1.0, 0.30434782608695654, 0.4723538704581361, 0.86, 1.0, 1.0, 0.5585732517209296, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24596040485667417, 0.245960404856674, 0.30920525041736713], 
reward next is 0.6908, 
noisyNet noise sample is [array([1.0117434], dtype=float32), -0.38241377]. 
=============================================
[2019-03-26 22:39:19,347] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[67.61643 ]
 [67.58611 ]
 [67.519165]
 [67.396935]
 [67.28111 ]], R is [[67.69855499]
 [67.70343781]
 [67.71055603]
 [67.71683502]
 [67.71469879]].
[2019-03-26 22:39:19,363] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1715468e-23 1.0000000e+00 3.6401273e-23 3.0717286e-18 1.7823604e-29], sum to 1.0000
[2019-03-26 22:39:19,372] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1175
[2019-03-26 22:39:19,380] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 81.0, 1.0, 2.0, 0.4173682019448138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 613015.4431024941, 613015.4431024941, 175479.8766840029], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6912000.0000, 
sim time next is 6912600.0000, 
raw observation next is [25.15, 81.5, 1.0, 2.0, 0.4182182325400535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 613923.9468327624, 613923.9468327624, 175556.6733004142], 
processed observation next is [0.0, 0.0, 0.3909952606635071, 0.815, 1.0, 1.0, 0.2990581114940404, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17053442967576735, 0.17053442967576735, 0.2620248855230063], 
reward next is 0.7380, 
noisyNet noise sample is [array([1.1830151], dtype=float32), -0.0897663]. 
=============================================
[2019-03-26 22:39:21,216] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3006833e-11 8.7189424e-01 7.2875977e-10 1.2810571e-01 7.2389121e-15], sum to 1.0000
[2019-03-26 22:39:21,229] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9361
[2019-03-26 22:39:21,234] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.25, 61.5, 1.0, 2.0, 0.8258025240052862, 1.0, 2.0, 0.8258025240052862, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2309572.97159297, 2309572.971592971, 432621.4313720808], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6618600.0000, 
sim time next is 6619200.0000, 
raw observation next is [31.16666666666666, 62.0, 1.0, 2.0, 0.8131171174649983, 1.0, 2.0, 0.8131171174649983, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2274062.632035894, 2274062.632035894, 426301.135895781], 
processed observation next is [1.0, 0.6086956521739131, 0.6761453396524484, 0.62, 1.0, 1.0, 0.7748399005602389, 1.0, 1.0, 0.7748399005602389, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6316840644544149, 0.6316840644544149, 0.6362703520832552], 
reward next is 0.3637, 
noisyNet noise sample is [array([-0.42370585], dtype=float32), 1.1414746]. 
=============================================
[2019-03-26 22:39:42,874] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6660059e-23 1.0000000e+00 8.3889725e-24 2.9404823e-18 5.8796896e-29], sum to 1.0000
[2019-03-26 22:39:42,883] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0447
[2019-03-26 22:39:42,886] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 78.0, 1.0, 2.0, 0.4147308461261768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 606051.9174150872, 606051.9174150872, 174729.5287385545], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7484400.0000, 
sim time next is 7485000.0000, 
raw observation next is [25.86666666666667, 77.66666666666667, 1.0, 2.0, 0.4154238338477537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 606714.721921772, 606714.7219217714, 174781.5986146753], 
processed observation next is [0.0, 0.6521739130434783, 0.42496050552922615, 0.7766666666666667, 1.0, 1.0, 0.295691366081631, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1685318672004922, 0.16853186720049207, 0.26086805763384374], 
reward next is 0.7391, 
noisyNet noise sample is [array([-0.35016596], dtype=float32), -0.51214993]. 
=============================================
[2019-03-26 22:39:42,896] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[77.17068]
 [77.12853]
 [77.10871]
 [77.07961]
 [77.05325]], R is [[77.18043518]
 [77.14784241]
 [77.11578369]
 [77.08427429]
 [77.05325317]].
[2019-03-26 22:39:43,097] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.575676e-24 1.000000e+00 3.896343e-23 6.629918e-18 7.858231e-30], sum to 1.0000
[2019-03-26 22:39:43,105] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7557
[2019-03-26 22:39:43,111] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.23333333333333, 59.66666666666666, 1.0, 2.0, 0.3922925721318365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 587481.8435461828, 587481.8435461835, 173451.3244544136], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6986400.0000, 
sim time next is 6987000.0000, 
raw observation next is [28.11666666666667, 60.83333333333334, 1.0, 2.0, 0.3956676475549482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 590568.7387648047, 590568.7387648054, 173675.1042919391], 
processed observation next is [0.0, 0.8695652173913043, 0.5315955766192735, 0.6083333333333334, 1.0, 1.0, 0.2718887319939135, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1640468718791124, 0.1640468718791126, 0.25921657357005834], 
reward next is 0.7408, 
noisyNet noise sample is [array([-1.788612], dtype=float32), 2.7079558]. 
=============================================
[2019-03-26 22:39:43,130] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[78.033325]
 [78.021996]
 [78.015114]
 [78.00865 ]
 [77.99108 ]], R is [[78.00120544]
 [77.96231079]
 [77.9240799 ]
 [77.88668823]
 [77.85061646]].
[2019-03-26 22:39:46,481] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.6667874e-15 9.9997282e-01 8.4428542e-13 2.7151438e-05 1.1121785e-19], sum to 1.0000
[2019-03-26 22:39:46,494] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6498
[2019-03-26 22:39:46,504] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1889768.758401218 W.
[2019-03-26 22:39:46,509] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.95, 45.5, 1.0, 2.0, 0.6582792964246731, 1.0, 1.0, 0.6582792964246731, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1889768.758401218, 1889768.758401217, 362786.9039298721], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7047000.0000, 
sim time next is 7047600.0000, 
raw observation next is [32.03333333333334, 45.0, 1.0, 2.0, 0.6478102847116266, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.940491472377167, 6.9112, 168.9127810094653, 1837733.918703442, 1816953.561655267, 379826.1147598844], 
processed observation next is [1.0, 0.5652173913043478, 0.7172195892575042, 0.45, 1.0, 1.0, 0.5756750418212369, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.002929147237716734, 0.0, 0.8294390833622164, 0.5104816440842894, 0.5047093226820186, 0.5669046488953499], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3578774], dtype=float32), -0.25745454]. 
=============================================
[2019-03-26 22:39:50,749] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.7586557e-18 1.0000000e+00 1.8656171e-16 8.5093532e-09 2.2785342e-22], sum to 1.0000
[2019-03-26 22:39:50,759] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2174
[2019-03-26 22:39:50,769] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1929684.742844356 W.
[2019-03-26 22:39:50,777] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.5, 81.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.581613495143984, 6.9112, 168.909274999687, 1929684.742844356, 1454080.701702295, 311346.6008001132], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7135200.0000, 
sim time next is 7135800.0000, 
raw observation next is [26.48333333333333, 81.33333333333333, 1.0, 2.0, 0.7506928718799565, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.959021134797373, 6.9112, 168.912130260619, 1946068.440146346, 1912142.647195907, 397475.3659072684], 
processed observation next is [1.0, 0.6086956521739131, 0.4541864139020536, 0.8133333333333332, 1.0, 1.0, 0.6996299661204295, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.004782113479737315, 0.0, 0.8294358878874669, 0.5405745667073184, 0.5311507353321964, 0.5932468147869678], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5821972], dtype=float32), -0.35702258]. 
=============================================
[2019-03-26 22:39:59,640] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9948680e-24 1.0000000e+00 1.1471615e-23 5.2056864e-19 5.0721848e-30], sum to 1.0000
[2019-03-26 22:39:59,649] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1424
[2019-03-26 22:39:59,654] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 90.66666666666667, 1.0, 2.0, 0.4049397626363604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 596156.6687155137, 596156.6687155131, 173942.5359921775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7510800.0000, 
sim time next is 7511400.0000, 
raw observation next is [23.75, 91.0, 1.0, 2.0, 0.4047130699651731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 595962.373732491, 595962.373732491, 173928.9426337174], 
processed observation next is [0.0, 0.9565217391304348, 0.3246445497630332, 0.91, 1.0, 1.0, 0.2827868312833411, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16554510381458085, 0.16554510381458085, 0.2595954367667424], 
reward next is 0.7404, 
noisyNet noise sample is [array([-1.1017148], dtype=float32), 1.4253724]. 
=============================================
[2019-03-26 22:40:04,156] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0319925e-22 1.0000000e+00 1.4352143e-20 3.3710000e-16 1.8439138e-27], sum to 1.0000
[2019-03-26 22:40:04,167] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9634
[2019-03-26 22:40:04,172] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 91.83333333333334, 1.0, 2.0, 0.5525854446070985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 880894.8556144383, 880894.8556144377, 204494.5465874934], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7395000.0000, 
sim time next is 7395600.0000, 
raw observation next is [20.83333333333333, 91.66666666666667, 1.0, 2.0, 0.4926362209958013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 786271.4478508017, 786271.4478508023, 193419.6816024164], 
processed observation next is [1.0, 0.6086956521739131, 0.1864139020537123, 0.9166666666666667, 1.0, 1.0, 0.38871833854915816, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2184087355141116, 0.21840873551411175, 0.2886860919439051], 
reward next is 0.7113, 
noisyNet noise sample is [array([1.354841], dtype=float32), 1.5679756]. 
=============================================
[2019-03-26 22:40:04,299] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:40:04,300] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:40:04,380] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run10
[2019-03-26 22:40:07,681] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:40:07,688] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:40:07,755] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run10
[2019-03-26 22:40:11,192] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:40:11,192] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:40:11,272] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run10
[2019-03-26 22:40:13,240] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 22:40:13,242] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 22:40:13,243] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 22:40:13,245] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:40:13,246] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:40:13,248] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 22:40:13,245] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 22:40:13,246] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 22:40:13,253] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:40:13,254] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:40:13,256] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:40:13,280] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run77
[2019-03-26 22:40:13,309] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run77
[2019-03-26 22:40:13,328] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run77
[2019-03-26 22:40:13,329] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run77
[2019-03-26 22:40:13,346] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run77
[2019-03-26 22:41:15,228] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09450968], dtype=float32), 0.071634464]
[2019-03-26 22:41:15,230] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.1, 78.0, 1.0, 2.0, 0.5588908692320319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 780993.4078028862, 780993.4078028856, 193336.7239945735]
[2019-03-26 22:41:15,234] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 22:41:15,237] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.0303450e-23 1.0000000e+00 1.9827537e-22 2.8866033e-17 7.5718790e-29], sampled 0.23768021748786872
[2019-03-26 22:41:25,054] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09450968], dtype=float32), 0.071634464]
[2019-03-26 22:41:25,056] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.74885915, 93.12517114, 1.0, 2.0, 0.8870320158544943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1239805.108075023, 1239805.108075023, 266404.5247725067]
[2019-03-26 22:41:25,058] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:41:25,062] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.1657504e-23 1.0000000e+00 2.4088068e-22 1.8726893e-17 7.6880680e-29], sampled 0.9619665592598923
[2019-03-26 22:41:34,154] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09450968], dtype=float32), 0.071634464]
[2019-03-26 22:41:34,154] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [36.25, 52.5, 1.0, 2.0, 0.5949930837193137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104262, 831462.3434536114, 831462.3434536108, 199818.5179081051]
[2019-03-26 22:41:34,155] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 22:41:34,158] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.03933735e-16 9.99994397e-01 8.97221005e-15 5.64109178e-06
 1.44175254e-20], sampled 0.987916741789133
[2019-03-26 22:42:07,648] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7888.2949 3164222177.7480 1764.0000
[2019-03-26 22:42:07,681] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8657.6665 2779440364.3322 933.0000
[2019-03-26 22:42:08,001] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.3023 3007750650.6898 1762.0000
[2019-03-26 22:42:08,097] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8498.0594 2842687401.8032 1125.0000
[2019-03-26 22:42:08,106] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.3858 2927256977.4673 1337.0000
[2019-03-26 22:42:09,126] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1900000, evaluation results [1900000.0, 7888.2948741788505, 3164222177.7479515, 1764.0, 8254.38579363631, 2927256977.4673, 1337.0, 8657.666463367112, 2779440364.3321996, 933.0, 7997.302340464782, 3007750650.689842, 1762.0, 8498.059382540563, 2842687401.803198, 1125.0]
[2019-03-26 22:42:15,418] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6295702e-21 1.0000000e+00 9.3019626e-21 4.6289276e-16 3.8449527e-27], sum to 1.0000
[2019-03-26 22:42:15,425] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0981
[2019-03-26 22:42:15,430] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 94.0, 1.0, 2.0, 0.7523565089805304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1126767.662118722, 1126767.662118722, 242529.6785571532], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 122400.0000, 
sim time next is 123000.0000, 
raw observation next is [22.88333333333333, 94.16666666666667, 1.0, 2.0, 0.7717516638050138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1155141.158100615, 1155141.158100615, 247338.3886303107], 
processed observation next is [1.0, 0.43478260869565216, 0.28357030015797774, 0.9416666666666668, 1.0, 1.0, 0.7250020045843539, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3208725439168375, 0.3208725439168375, 0.3691617740750906], 
reward next is 0.6308, 
noisyNet noise sample is [array([0.47585112], dtype=float32), -0.596187]. 
=============================================
[2019-03-26 22:42:15,445] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[69.56652 ]
 [69.53557 ]
 [69.45745 ]
 [69.395386]
 [69.399666]], R is [[69.57453156]
 [69.51679993]
 [69.4859848 ]
 [69.44934082]
 [69.38359833]].
[2019-03-26 22:42:17,227] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:42:17,228] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:42:17,316] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run10
[2019-03-26 22:42:21,609] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:42:21,611] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:42:21,703] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run10
[2019-03-26 22:42:24,918] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.6868211e-21 1.0000000e+00 7.2681013e-20 5.2790486e-15 1.4539520e-25], sum to 1.0000
[2019-03-26 22:42:24,927] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0534
[2019-03-26 22:42:24,934] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.55, 69.5, 1.0, 2.0, 0.7432295329360913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1142410.468538642, 1142410.468538642, 243752.7884550088], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 37800.0000, 
sim time next is 38400.0000, 
raw observation next is [25.76666666666667, 68.66666666666667, 1.0, 2.0, 0.8336674078865801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1278676.334116864, 1278676.334116864, 267608.4755021951], 
processed observation next is [1.0, 0.43478260869565216, 0.42022116903633505, 0.6866666666666668, 1.0, 1.0, 0.7995992866103375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.35518787058801776, 0.35518787058801776, 0.3994156350779032], 
reward next is 0.6006, 
noisyNet noise sample is [array([0.28869432], dtype=float32), 1.5169649]. 
=============================================
[2019-03-26 22:42:26,699] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:42:26,699] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:42:26,771] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run10
[2019-03-26 22:42:26,946] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6934086e-13 9.8850560e-01 2.5695356e-11 1.1494423e-02 6.0875874e-17], sum to 1.0000
[2019-03-26 22:42:26,954] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5519
[2019-03-26 22:42:26,960] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1898296.590572053 W.
[2019-03-26 22:42:26,965] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.7165558780637322, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.002700785807933, 6.9112, 168.9115333222086, 1898296.590572053, 1833383.330841832, 388400.906965509], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7822800.0000, 
sim time next is 7823400.0000, 
raw observation next is [30.88333333333334, 69.66666666666667, 1.0, 2.0, 0.5906726004529893, 0.0, 2.0, 0.0, 1.0, 2.0, 1.021133972640581, 6.9112, 6.9112, 168.9128794068437, 1651486.792696656, 1651486.792696656, 360726.1828766453], 
processed observation next is [1.0, 0.5652173913043478, 0.6627172195892579, 0.6966666666666668, 1.0, 1.0, 0.5068344583770955, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0257731373665622, 0.0, 0.0, 0.8294395665383909, 0.45874633130462666, 0.45874633130462666, 0.53839728787559], 
reward next is 0.4616, 
noisyNet noise sample is [array([0.50686383], dtype=float32), -1.3060517]. 
=============================================
[2019-03-26 22:42:30,275] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1668117e-13 9.9999952e-01 4.2434394e-13 4.4982977e-07 8.9630057e-18], sum to 1.0000
[2019-03-26 22:42:30,286] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7885
[2019-03-26 22:42:30,294] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1972778.385498827 W.
[2019-03-26 22:42:30,301] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.33333333333334, 78.0, 1.0, 2.0, 0.7697786988037709, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.980939650389695, 6.9112, 168.9124829673932, 1972778.385498827, 1923302.815962702, 401406.8997315054], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7896000.0000, 
sim time next is 7896600.0000, 
raw observation next is [28.45, 77.5, 1.0, 2.0, 0.6991290901772181, 1.0, 1.0, 0.6991290901772181, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1954986.897981706, 1954986.897981706, 373748.4792293618], 
processed observation next is [1.0, 0.391304347826087, 0.54739336492891, 0.775, 1.0, 1.0, 0.6375049279243592, 1.0, 0.5, 0.6375049279243592, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5430519161060294, 0.5430519161060294, 0.5578335510885997], 
reward next is 0.4422, 
noisyNet noise sample is [array([0.8338393], dtype=float32), -1.3193853]. 
=============================================
[2019-03-26 22:42:31,857] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:42:31,858] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:42:31,939] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run10
[2019-03-26 22:42:33,593] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:42:33,595] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:42:33,661] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run10
[2019-03-26 22:42:34,104] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:42:34,105] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:42:34,171] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run10
[2019-03-26 22:42:34,314] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:42:34,315] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:42:34,372] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run10
[2019-03-26 22:42:34,395] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:42:34,396] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:42:34,429] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:42:34,430] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:42:34,453] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run10
[2019-03-26 22:42:34,502] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run10
[2019-03-26 22:42:34,569] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:42:34,569] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:42:34,581] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:42:34,582] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:42:34,615] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run10
[2019-03-26 22:42:34,636] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run10
[2019-03-26 22:42:34,713] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:42:34,713] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:42:34,720] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run10
[2019-03-26 22:42:34,741] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 22:42:34,745] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:42:34,767] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run10
[2019-03-26 22:42:36,949] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5813508e-21 1.0000000e+00 4.2700873e-21 2.5952747e-17 2.7581135e-27], sum to 1.0000
[2019-03-26 22:42:36,955] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2759
[2019-03-26 22:42:36,960] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.63333333333333, 77.33333333333334, 1.0, 2.0, 0.2388806219487062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 394101.6041391643, 394101.6041391649, 159797.1353427625], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 717600.0000, 
sim time next is 718200.0000, 
raw observation next is [20.85, 76.5, 1.0, 2.0, 0.2425875134384144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 399756.4703239303, 399756.4703239303, 160167.4752617245], 
processed observation next is [1.0, 0.30434782608695654, 0.18720379146919444, 0.765, 1.0, 1.0, 0.08745483546796914, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11104346397886954, 0.11104346397886954, 0.23905593322645446], 
reward next is 0.7609, 
noisyNet noise sample is [array([-1.5729638], dtype=float32), 0.9301296]. 
=============================================
[2019-03-26 22:42:42,888] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.2168910e-22 1.0000000e+00 3.0061470e-21 7.9295605e-17 4.2694039e-28], sum to 1.0000
[2019-03-26 22:42:42,897] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0920
[2019-03-26 22:42:42,903] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.1, 80.0, 1.0, 2.0, 0.2428836359520094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 401307.3486973058, 401307.3486973058, 160148.350047122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 680400.0000, 
sim time next is 681000.0000, 
raw observation next is [20.0, 80.66666666666667, 1.0, 2.0, 0.2415022161778914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 399074.9289187366, 399074.9289187372, 160012.917123301], 
processed observation next is [1.0, 0.9130434782608695, 0.1469194312796209, 0.8066666666666668, 1.0, 1.0, 0.08614724840709805, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11085414692187127, 0.11085414692187145, 0.2388252494377627], 
reward next is 0.7612, 
noisyNet noise sample is [array([0.98894346], dtype=float32), -0.3463543]. 
=============================================
[2019-03-26 22:42:42,925] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[73.471725]
 [73.39135 ]
 [73.39376 ]
 [73.46903 ]
 [73.45543 ]], R is [[73.60523224]
 [73.63014984]
 [73.65454102]
 [73.67857361]
 [73.7025528 ]].
[2019-03-26 22:42:42,934] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5327613e-22 1.0000000e+00 8.6582808e-22 1.3308522e-16 4.9305968e-28], sum to 1.0000
[2019-03-26 22:42:42,944] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0841
[2019-03-26 22:42:42,952] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.2, 82.0, 1.0, 2.0, 0.2491420668945658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 410017.1736102046, 410017.173610204, 160817.0308902212], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 421200.0000, 
sim time next is 421800.0000, 
raw observation next is [20.16666666666666, 82.33333333333334, 1.0, 2.0, 0.2488522682366911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 409520.4595377098, 409520.4595377104, 160788.9736322133], 
processed observation next is [1.0, 0.9130434782608695, 0.15481832543443896, 0.8233333333333335, 1.0, 1.0, 0.09500273281529047, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11375568320491938, 0.11375568320491956, 0.23998354273464673], 
reward next is 0.7600, 
noisyNet noise sample is [array([0.70032525], dtype=float32), 0.21551518]. 
=============================================
[2019-03-26 22:42:47,012] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.0076237e-23 1.0000000e+00 4.7616774e-23 1.9674469e-19 7.3812243e-30], sum to 1.0000
[2019-03-26 22:42:47,023] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2195
[2019-03-26 22:42:47,031] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.88333333333333, 96.0, 1.0, 2.0, 0.2862261540114023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 461138.5560566716, 461138.5560566716, 164350.7811383822], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 187800.0000, 
sim time next is 188400.0000, 
raw observation next is [19.86666666666667, 96.0, 1.0, 2.0, 0.2856944411826112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 460424.7653101006, 460424.7653101006, 164302.1342669122], 
processed observation next is [0.0, 0.17391304347826086, 0.14060031595576644, 0.96, 1.0, 1.0, 0.13939089299109786, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12789576814169462, 0.12789576814169462, 0.24522706607001823], 
reward next is 0.7548, 
noisyNet noise sample is [array([0.47293136], dtype=float32), 1.5051017]. 
=============================================
[2019-03-26 22:42:47,559] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2219999e-23 1.0000000e+00 5.7344407e-23 4.5810519e-19 1.4606924e-29], sum to 1.0000
[2019-03-26 22:42:47,573] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3657
[2019-03-26 22:42:47,579] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.71666666666667, 92.83333333333333, 1.0, 2.0, 0.2994093633381976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 477946.181177679, 477946.1811776797, 165491.5623803194], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 209400.0000, 
sim time next is 210000.0000, 
raw observation next is [20.73333333333333, 92.66666666666667, 1.0, 2.0, 0.3048412396151696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 486642.5017893348, 486642.5017893342, 166115.4785106497], 
processed observation next is [0.0, 0.43478260869565216, 0.18167456556082143, 0.9266666666666667, 1.0, 1.0, 0.16245932483755376, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13517847271925967, 0.13517847271925948, 0.24793355001589507], 
reward next is 0.7521, 
noisyNet noise sample is [array([0.18120882], dtype=float32), 0.34999433]. 
=============================================
[2019-03-26 22:42:47,605] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[78.4623  ]
 [78.41594 ]
 [78.366104]
 [78.34048 ]
 [78.30687 ]], R is [[78.45887756]
 [78.42728424]
 [78.39646149]
 [78.36580658]
 [78.33556366]].
[2019-03-26 22:43:03,363] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.1789052e-21 1.0000000e+00 2.3117359e-20 3.7037477e-15 9.5045583e-27], sum to 1.0000
[2019-03-26 22:43:03,371] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1941
[2019-03-26 22:43:03,378] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 53.0, 1.0, 2.0, 0.6254314834511268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1028968.569599063, 1028968.569599063, 221185.3912306551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 658200.0000, 
sim time next is 658800.0000, 
raw observation next is [24.7, 53.0, 1.0, 2.0, 0.5580138440180895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 918045.2608241915, 918045.2608241915, 206890.4954765062], 
processed observation next is [1.0, 0.6521739130434783, 0.3696682464454976, 0.53, 1.0, 1.0, 0.4674865590579391, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2550125724511643, 0.2550125724511643, 0.30879178429329285], 
reward next is 0.6912, 
noisyNet noise sample is [array([-0.45457917], dtype=float32), 2.4440987]. 
=============================================
[2019-03-26 22:43:03,386] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3170674e-21 1.0000000e+00 1.6852868e-20 7.5611878e-17 2.2320382e-27], sum to 1.0000
[2019-03-26 22:43:03,396] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2763
[2019-03-26 22:43:03,402] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.93333333333333, 76.66666666666667, 1.0, 2.0, 0.3979314826951001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 654638.7772868029, 654638.7772868029, 179169.1155806829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 463200.0000, 
sim time next is 463800.0000, 
raw observation next is [21.06666666666667, 75.83333333333333, 1.0, 2.0, 0.4052513659093974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 666519.4414477205, 666519.4414477205, 180246.454953312], 
processed observation next is [1.0, 0.34782608695652173, 0.19747235387045833, 0.7583333333333333, 1.0, 1.0, 0.28343538061373186, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18514428929103346, 0.18514428929103346, 0.26902455963180893], 
reward next is 0.7310, 
noisyNet noise sample is [array([0.3900677], dtype=float32), -0.68937397]. 
=============================================
[2019-03-26 22:43:03,466] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4898444e-22 1.0000000e+00 2.2473556e-21 8.8590316e-17 2.6653029e-27], sum to 1.0000
[2019-03-26 22:43:03,477] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4531
[2019-03-26 22:43:03,484] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 22:43:03,486] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 22:43:03,487] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:43:03,490] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.53333333333333, 79.16666666666667, 1.0, 2.0, 0.2655559406353868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 437259.9974286218, 437259.9974286218, 162471.7820859479], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 461400.0000, 
sim time next is 462000.0000, 
raw observation next is [20.66666666666667, 78.33333333333334, 1.0, 2.0, 0.3552044323731192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 584708.8758904886, 584708.8758904886, 173216.9636957057], 
processed observation next is [1.0, 0.34782608695652173, 0.17851500789889443, 0.7833333333333334, 1.0, 1.0, 0.2231378703290593, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1624191321918024, 0.1624191321918024, 0.2585327816353816], 
reward next is 0.7415, 
noisyNet noise sample is [array([0.44714296], dtype=float32), -2.2618968]. 
=============================================
[2019-03-26 22:43:03,490] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 22:43:03,494] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 22:43:03,495] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 22:43:03,498] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:43:03,493] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 22:43:03,501] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:43:03,499] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:43:03,503] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:43:03,528] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run78
[2019-03-26 22:43:03,553] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run78
[2019-03-26 22:43:03,586] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run78
[2019-03-26 22:43:03,608] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run78
[2019-03-26 22:43:03,609] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run78
[2019-03-26 22:43:35,733] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09641094], dtype=float32), 0.073696814]
[2019-03-26 22:43:35,734] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.0, 76.0, 1.0, 2.0, 0.5622836267046358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 785736.1964479298, 785736.1964479298, 193930.428104229]
[2019-03-26 22:43:35,736] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 22:43:35,738] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.6847204e-24 1.0000000e+00 1.4592990e-23 1.5334486e-18 3.2689576e-30], sampled 0.49776601990490066
[2019-03-26 22:44:01,706] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09641094], dtype=float32), 0.073696814]
[2019-03-26 22:44:01,707] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.35752870666667, 85.23846803166667, 1.0, 2.0, 0.535857550101533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 748795.3312470567, 748795.3312470574, 189402.0649628919]
[2019-03-26 22:44:01,709] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:44:01,713] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.7418894e-24 1.0000000e+00 3.3075530e-23 1.3588971e-18 7.0367680e-30], sampled 0.47866077049307776
[2019-03-26 22:44:04,874] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09641094], dtype=float32), 0.073696814]
[2019-03-26 22:44:04,875] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.62585822666667, 70.39066882333333, 1.0, 2.0, 0.6491804056764534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 907217.7786876482, 907217.7786876488, 210262.681352602]
[2019-03-26 22:44:04,876] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:44:04,879] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.4281653e-25 1.0000000e+00 1.1954878e-23 9.2720098e-17 3.2703153e-31], sampled 0.661428886442659
[2019-03-26 22:44:15,724] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09641094], dtype=float32), 0.073696814]
[2019-03-26 22:44:15,725] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.310272785, 60.72429766833334, 1.0, 2.0, 0.4892283663501862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 702327.4792508996, 702327.4792509003, 184309.9504223091]
[2019-03-26 22:44:15,727] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:44:15,730] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.183945e-24 1.000000e+00 2.715431e-23 9.866610e-18 5.299043e-30], sampled 0.8140289549144678
[2019-03-26 22:44:20,178] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09641094], dtype=float32), 0.073696814]
[2019-03-26 22:44:20,179] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.7, 74.66666666666667, 1.0, 2.0, 0.5624334617700291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 785945.6537136283, 785945.6537136283, 193955.3011570903]
[2019-03-26 22:44:20,180] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 22:44:20,183] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.1416397e-25 1.0000000e+00 5.9291208e-24 3.2338891e-18 8.5311644e-31], sampled 0.5217298688837881
[2019-03-26 22:44:20,323] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09641094], dtype=float32), 0.073696814]
[2019-03-26 22:44:20,324] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.23962836666666, 72.55570200666666, 1.0, 2.0, 0.8176931443580506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1142837.974439642, 1142837.974439642, 248306.9811307288]
[2019-03-26 22:44:20,325] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:44:20,329] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.8315727e-23 1.0000000e+00 1.0635977e-22 1.5750687e-17 2.6903165e-29], sampled 0.10739667394506447
[2019-03-26 22:44:33,539] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09641094], dtype=float32), 0.073696814]
[2019-03-26 22:44:33,539] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.94179846333333, 76.48563455166666, 1.0, 2.0, 0.8836568229260802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1246000.048770056, 1246000.048770055, 267087.2523743111]
[2019-03-26 22:44:33,543] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:44:33,545] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.9007411e-22 1.0000000e+00 2.8154317e-20 2.0612517e-13 4.4373468e-27], sampled 0.958067844777452
[2019-03-26 22:44:50,692] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09641094], dtype=float32), 0.073696814]
[2019-03-26 22:44:50,695] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [18.49468526666667, 86.58743159666668, 1.0, 2.0, 0.2224234933002988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 370534.6062763954, 370534.6062763948, 157810.7390142956]
[2019-03-26 22:44:50,695] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:44:50,697] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.2047925e-24 1.0000000e+00 1.1748407e-23 7.2391890e-19 2.3480120e-30], sampled 0.4043547995212221
[2019-03-26 22:44:57,620] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2688 3007688205.7619 1764.0000
[2019-03-26 22:44:57,944] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.9430 2842428555.9615 1130.0000
[2019-03-26 22:44:58,129] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7886.9690 3164297908.0511 1767.0000
[2019-03-26 22:44:58,143] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.5293 2779256595.0998 933.0000
[2019-03-26 22:44:58,336] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.3521 2927623010.5821 1338.0000
[2019-03-26 22:44:59,352] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1925000, evaluation results [1925000.0, 7886.968984396944, 3164297908.0511456, 1767.0, 8253.352052147957, 2927623010.582074, 1338.0, 8660.529287309864, 2779256595.0998096, 933.0, 7998.268755866765, 3007688205.761928, 1764.0, 8496.943015121336, 2842428555.96149, 1130.0]
[2019-03-26 22:44:59,374] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[72.14534 ]
 [72.12757 ]
 [72.089226]
 [72.06665 ]
 [72.04538 ]], R is [[72.07322693]
 [72.11000061]
 [72.14886475]
 [72.18798065]
 [72.22679138]].
[2019-03-26 22:44:59,650] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0122739e-23 1.0000000e+00 9.4303607e-23 1.4834381e-17 7.8755172e-30], sum to 1.0000
[2019-03-26 22:44:59,666] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0761
[2019-03-26 22:44:59,671] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.53333333333333, 83.0, 1.0, 2.0, 0.2377349738012051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 393541.1061144191, 393541.1061144196, 159604.1388105924], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 510000.0000, 
sim time next is 510600.0000, 
raw observation next is [19.46666666666667, 83.5, 1.0, 2.0, 0.2371244943561485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 392546.6935223611, 392546.6935223617, 159545.2269239772], 
processed observation next is [1.0, 0.9130434782608695, 0.12164296998420236, 0.835, 1.0, 1.0, 0.08087288476644396, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10904074820065586, 0.10904074820065603, 0.23812720436414508], 
reward next is 0.7619, 
noisyNet noise sample is [array([0.43148568], dtype=float32), -0.50210524]. 
=============================================
[2019-03-26 22:45:00,035] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.3290739e-25 1.0000000e+00 9.1871914e-25 1.3796168e-19 2.1429586e-31], sum to 1.0000
[2019-03-26 22:45:00,045] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5832
[2019-03-26 22:45:00,050] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.03333333333333, 83.5, 1.0, 2.0, 0.3008289006429775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 478878.6753059169, 478878.6753059163, 165538.9578176553], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 852600.0000, 
sim time next is 853200.0000, 
raw observation next is [22.0, 84.0, 1.0, 2.0, 0.3029436973056214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 481905.6715583483, 481905.6715583489, 165750.4613694883], 
processed observation next is [0.0, 0.9130434782608695, 0.2417061611374408, 0.84, 1.0, 1.0, 0.16017312928388117, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13386268654398564, 0.1338626865439858, 0.2473887483126691], 
reward next is 0.7526, 
noisyNet noise sample is [array([1.0062734], dtype=float32), 0.3075086]. 
=============================================
[2019-03-26 22:45:05,440] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.3887204e-23 1.0000000e+00 3.0267540e-22 4.4508637e-17 1.6661670e-28], sum to 1.0000
[2019-03-26 22:45:05,448] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8252
[2019-03-26 22:45:05,456] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.9, 88.0, 1.0, 2.0, 0.2134813270544272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 356140.5977505077, 356140.5977505077, 156860.3708652732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 606600.0000, 
sim time next is 607200.0000, 
raw observation next is [17.83333333333333, 88.33333333333333, 1.0, 2.0, 0.2123993107496134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 354389.3453061864, 354389.3453061858, 156746.184946145], 
processed observation next is [1.0, 0.0, 0.044233807266982464, 0.8833333333333333, 1.0, 1.0, 0.05108350692724506, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.09844148480727401, 0.09844148480727383, 0.23394952977036565], 
reward next is 0.7661, 
noisyNet noise sample is [array([0.13849354], dtype=float32), 0.86950547]. 
=============================================
[2019-03-26 22:45:05,660] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8287549e-23 1.0000000e+00 4.0943156e-22 1.8612879e-16 2.0225712e-28], sum to 1.0000
[2019-03-26 22:45:05,671] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7815
[2019-03-26 22:45:05,678] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333333, 66.5, 1.0, 2.0, 0.2553916522124396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 417912.0570407765, 417912.0570407765, 161435.166928166], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 582600.0000, 
sim time next is 583200.0000, 
raw observation next is [22.7, 67.0, 1.0, 2.0, 0.255544752789682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 418460.2671677591, 418460.2671677597, 161455.1958298487], 
processed observation next is [1.0, 0.782608695652174, 0.27488151658767773, 0.67, 1.0, 1.0, 0.1030659672164843, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11623896310215531, 0.11623896310215548, 0.24097790422365478], 
reward next is 0.7590, 
noisyNet noise sample is [array([2.047279], dtype=float32), -1.7440547]. 
=============================================
[2019-03-26 22:45:12,410] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.07706264e-23 1.00000000e+00 4.69277481e-23 1.11077561e-19
 1.07276615e-29], sum to 1.0000
[2019-03-26 22:45:12,420] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2900
[2019-03-26 22:45:12,423] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 89.66666666666667, 1.0, 2.0, 0.266010431261114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 433403.7071040743, 433403.7071040743, 162465.6624087682], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 798000.0000, 
sim time next is 798600.0000, 
raw observation next is [20.15, 88.83333333333334, 1.0, 2.0, 0.2669562477402215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 434605.4772025349, 434605.4772025342, 162550.7975552343], 
processed observation next is [0.0, 0.21739130434782608, 0.15402843601895733, 0.8883333333333334, 1.0, 1.0, 0.11681475631351984, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1207237436673708, 0.12072374366737061, 0.2426131306794542], 
reward next is 0.7574, 
noisyNet noise sample is [array([-0.70873857], dtype=float32), -0.18683675]. 
=============================================
[2019-03-26 22:45:14,086] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.3403552e-24 1.0000000e+00 4.6711638e-23 1.1342798e-18 1.6139552e-29], sum to 1.0000
[2019-03-26 22:45:14,097] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9850
[2019-03-26 22:45:14,106] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 74.0, 1.0, 2.0, 0.2965594300636533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 472648.2819308657, 472648.2819308657, 165105.7264027745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 907200.0000, 
sim time next is 907800.0000, 
raw observation next is [23.45, 73.33333333333334, 1.0, 2.0, 0.2975666348156158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 473890.9216368221, 473890.9216368227, 165187.7114412063], 
processed observation next is [0.0, 0.5217391304347826, 0.3104265402843602, 0.7333333333333334, 1.0, 1.0, 0.15369474074170578, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13163636712133947, 0.13163636712133964, 0.24654882304657658], 
reward next is 0.7535, 
noisyNet noise sample is [array([-0.48755613], dtype=float32), 0.8280318]. 
=============================================
[2019-03-26 22:45:15,573] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.9531443e-24 1.0000000e+00 5.4475752e-24 1.5687657e-18 1.0339069e-29], sum to 1.0000
[2019-03-26 22:45:15,585] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1387
[2019-03-26 22:45:15,589] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 79.0, 1.0, 2.0, 0.4261282500735583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 614974.7235593331, 614974.7235593325, 175353.5020542791], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1429200.0000, 
sim time next is 1429800.0000, 
raw observation next is [26.2, 77.66666666666667, 1.0, 2.0, 0.4281866728004608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 617379.7461963954, 617379.7461963954, 175569.9693124505], 
processed observation next is [0.0, 0.5652173913043478, 0.44075829383886256, 0.7766666666666667, 1.0, 1.0, 0.3110682804824829, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17149437394344316, 0.17149437394344316, 0.2620447303170903], 
reward next is 0.7380, 
noisyNet noise sample is [array([0.8060968], dtype=float32), -1.154868]. 
=============================================
[2019-03-26 22:45:20,179] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9570607e-23 1.0000000e+00 2.9373580e-23 4.9254304e-19 5.6438151e-30], sum to 1.0000
[2019-03-26 22:45:20,191] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4534
[2019-03-26 22:45:20,196] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.13333333333333, 61.33333333333334, 1.0, 2.0, 0.2899116500588187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 463928.3928886835, 463928.3928886829, 164523.2570659499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 818400.0000, 
sim time next is 819000.0000, 
raw observation next is [25.1, 61.5, 1.0, 2.0, 0.2897228075243004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 463660.3177618643, 463660.3177618649, 164505.1470210628], 
processed observation next is [0.0, 0.4782608695652174, 0.38862559241706174, 0.615, 1.0, 1.0, 0.14424434641481976, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12879453271162897, 0.12879453271162913, 0.24553007018069073], 
reward next is 0.7545, 
noisyNet noise sample is [array([-0.19585311], dtype=float32), 0.83524036]. 
=============================================
[2019-03-26 22:45:20,211] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[78.71687 ]
 [78.696205]
 [78.66939 ]
 [78.646835]
 [78.646866]], R is [[78.70635986]
 [78.67373657]
 [78.64141083]
 [78.60934448]
 [78.57749939]].
[2019-03-26 22:45:27,409] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7798236e-23 1.0000000e+00 1.1076675e-23 2.3694852e-19 8.6549102e-30], sum to 1.0000
[2019-03-26 22:45:27,421] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5126
[2019-03-26 22:45:27,426] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 82.0, 1.0, 2.0, 0.3290152649457214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 513191.5550425368, 513191.5550425375, 167863.1858485076], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 932400.0000, 
sim time next is 933000.0000, 
raw observation next is [23.03333333333334, 82.83333333333334, 1.0, 2.0, 0.3303007847433387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 514730.1321471648, 514730.1321471654, 167969.7924274406], 
processed observation next is [0.0, 0.8260869565217391, 0.2906793048973147, 0.8283333333333335, 1.0, 1.0, 0.19313347559438396, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14298059226310134, 0.1429805922631015, 0.2507011827275233], 
reward next is 0.7493, 
noisyNet noise sample is [array([2.1702452], dtype=float32), -0.06970259]. 
=============================================
[2019-03-26 22:45:27,437] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[80.36043 ]
 [80.29066 ]
 [80.2459  ]
 [80.191185]
 [80.13668 ]], R is [[80.37620544]
 [80.32189941]
 [80.26811981]
 [80.21500397]
 [80.16273499]].
[2019-03-26 22:45:33,589] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6552133e-21 1.0000000e+00 5.6415378e-21 5.8824204e-16 3.3098185e-27], sum to 1.0000
[2019-03-26 22:45:33,598] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3784
[2019-03-26 22:45:33,604] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.76666666666667, 75.33333333333334, 1.0, 2.0, 0.6293684352386377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 988845.7697850259, 988845.7697850252, 219286.1492592628], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1080600.0000, 
sim time next is 1081200.0000, 
raw observation next is [23.93333333333334, 74.66666666666667, 1.0, 2.0, 0.5078247384887102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 796602.1151457683, 796602.1151457677, 194948.9142936372], 
processed observation next is [1.0, 0.5217391304347826, 0.3333333333333337, 0.7466666666666667, 1.0, 1.0, 0.4070177572153135, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22127836531826897, 0.2212783653182688, 0.29096852879647345], 
reward next is 0.7090, 
noisyNet noise sample is [array([0.797481], dtype=float32), -1.8813653]. 
=============================================
[2019-03-26 22:45:41,615] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.4719799e-23 1.0000000e+00 4.7820519e-21 2.6950019e-13 3.5838863e-29], sum to 1.0000
[2019-03-26 22:45:41,625] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7950
[2019-03-26 22:45:41,630] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 88.16666666666667, 1.0, 2.0, 0.4689321822145334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 659733.1560217439, 659733.1560217432, 179450.6952276578], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1281000.0000, 
sim time next is 1281600.0000, 
raw observation next is [25.1, 89.0, 1.0, 2.0, 0.4696356892183538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 661743.2575447279, 661743.2575447272, 179686.4477921503], 
processed observation next is [1.0, 0.8695652173913043, 0.38862559241706174, 0.89, 1.0, 1.0, 0.36100685447994435, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1838175715402022, 0.183817571540202, 0.26818872804798555], 
reward next is 0.7318, 
noisyNet noise sample is [array([1.0305086], dtype=float32), 1.8430216]. 
=============================================
[2019-03-26 22:45:55,443] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 22:45:55,448] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 22:45:55,449] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:45:55,450] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 22:45:55,451] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 22:45:55,452] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:45:55,452] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 22:45:55,453] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:45:55,454] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:45:55,453] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 22:45:55,457] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:45:55,482] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run79
[2019-03-26 22:45:55,507] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run79
[2019-03-26 22:45:55,534] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run79
[2019-03-26 22:45:55,535] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run79
[2019-03-26 22:45:55,554] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run79
[2019-03-26 22:46:03,650] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09569362], dtype=float32), 0.072894]
[2019-03-26 22:46:03,651] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.236658955, 46.65524139999999, 1.0, 2.0, 0.2910110408899097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 483259.7872953769, 483259.7872953775, 164982.312273893]
[2019-03-26 22:46:03,654] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:46:03,659] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.9485388e-23 1.0000000e+00 2.0153225e-22 2.4294923e-18 1.0646417e-28], sampled 0.30218551358654167
[2019-03-26 22:46:37,678] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09569362], dtype=float32), 0.072894]
[2019-03-26 22:46:37,679] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.16666666666667, 87.16666666666667, 1.0, 2.0, 0.5352413794238481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 840160.105262556, 840160.105262556, 200026.4735460519]
[2019-03-26 22:46:37,680] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 22:46:37,683] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.6277618e-23 1.0000000e+00 1.1087419e-22 2.3814023e-18 3.2851731e-29], sampled 0.7823061702690849
[2019-03-26 22:47:21,586] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09569362], dtype=float32), 0.072894]
[2019-03-26 22:47:21,588] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.73887220666666, 77.46842552333334, 1.0, 2.0, 0.8236545624917726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1163770.146708482, 1163770.146708482, 251593.6892325387]
[2019-03-26 22:47:21,589] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:47:21,592] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.4391379e-21 1.0000000e+00 1.1299821e-19 5.8235860e-13 3.7901269e-26], sampled 0.6215781250058816
[2019-03-26 22:47:43,399] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09569362], dtype=float32), 0.072894]
[2019-03-26 22:47:43,400] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.45, 61.5, 1.0, 2.0, 0.3161183597037128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 502266.734760174, 502266.7347601734, 167235.0030914994]
[2019-03-26 22:47:43,402] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 22:47:43,405] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.2652385e-23 1.0000000e+00 8.1303476e-23 5.5187704e-18 5.0612669e-29], sampled 0.009585252531616129
[2019-03-26 22:47:45,902] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.5093 3007432004.3466 1764.0000
[2019-03-26 22:47:46,120] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.3070 2842357231.1232 1127.0000
[2019-03-26 22:47:46,160] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7886.7264 3163889986.6644 1763.0000
[2019-03-26 22:47:46,266] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.0735 2779388539.9568 933.0000
[2019-03-26 22:47:46,363] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.0001 2927602680.1411 1338.0000
[2019-03-26 22:47:47,381] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1950000, evaluation results [1950000.0, 7886.726395288472, 3163889986.6644087, 1763.0, 8252.00009824165, 2927602680.1411176, 1338.0, 8661.07353302349, 2779388539.9567747, 933.0, 7999.509279398653, 3007432004.3465824, 1764.0, 8497.307043626686, 2842357231.1231694, 1127.0]
[2019-03-26 22:48:15,527] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6840769e-12 9.9920696e-01 1.8382544e-11 7.9301355e-04 1.5603053e-15], sum to 1.0000
[2019-03-26 22:48:15,535] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7980
[2019-03-26 22:48:15,545] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1668748.581749756 W.
[2019-03-26 22:48:15,550] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.91666666666667, 87.66666666666667, 1.0, 2.0, 0.5968461416432358, 1.0, 1.0, 0.5968461416432358, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1668748.581749756, 1668748.581749756, 333087.5078759771], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1875000.0000, 
sim time next is 1875600.0000, 
raw observation next is [26.9, 88.0, 1.0, 2.0, 0.5928425781907783, 0.0, 1.0, 0.0, 1.0, 1.0, 1.009956489617758, 6.9112, 6.9112, 168.912956510431, 1657558.663524359, 1657558.663524359, 358790.5439761319], 
processed observation next is [1.0, 0.7391304347826086, 0.4739336492890995, 0.88, 1.0, 1.0, 0.5094488893864799, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0121420605094609, 0.0, 0.0, 0.8294399451523027, 0.4604329620900997, 0.4604329620900997, 0.5355082745912416], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1028804], dtype=float32), -0.94219714]. 
=============================================
[2019-03-26 22:48:16,105] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.0252439e-23 1.0000000e+00 1.7368271e-21 2.1486417e-14 6.0249571e-29], sum to 1.0000
[2019-03-26 22:48:16,114] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6269
[2019-03-26 22:48:16,122] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 87.0, 1.0, 2.0, 0.4800667094387691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 670809.8449088709, 670809.8449088709, 180531.682876214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1884000.0000, 
sim time next is 1884600.0000, 
raw observation next is [25.65, 87.0, 1.0, 2.0, 0.4778135396085758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 667660.4420200373, 667660.442020038, 180192.6529677618], 
processed observation next is [1.0, 0.8260869565217391, 0.41469194312796204, 0.87, 1.0, 1.0, 0.37085968627539256, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18546123389445482, 0.185461233894455, 0.2689442581608385], 
reward next is 0.7311, 
noisyNet noise sample is [array([0.5246459], dtype=float32), 0.95263106]. 
=============================================
[2019-03-26 22:48:19,963] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.9978397e-13 9.9999785e-01 2.0043494e-12 2.1003102e-06 4.6587471e-17], sum to 1.0000
[2019-03-26 22:48:19,973] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0170
[2019-03-26 22:48:19,984] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1770498.14459108 W.
[2019-03-26 22:48:19,990] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.8, 77.0, 1.0, 2.0, 0.4221386297169405, 1.0, 1.0, 0.4221386297169405, 1.0, 2.0, 0.7075324474200222, 6.911200000000001, 6.9112, 170.5573041426782, 1770498.14459108, 1770498.14459108, 361557.2377204805], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1944000.0000, 
sim time next is 1944600.0000, 
raw observation next is [26.86666666666667, 76.66666666666667, 1.0, 2.0, 0.3790243836172773, 1.0, 2.0, 0.3790243836172773, 1.0, 2.0, 0.6356530781206958, 6.9112, 6.9112, 170.5573041426782, 1589537.911174007, 1589537.911174007, 338526.8148949855], 
processed observation next is [1.0, 0.5217391304347826, 0.4723538704581361, 0.7666666666666667, 1.0, 1.0, 0.251836606767804, 1.0, 1.0, 0.251836606767804, 1.0, 1.0, 0.5556744855130437, 0.0, 0.0, 0.8375144448122397, 0.4415383086594464, 0.4415383086594464, 0.5052639028283366], 
reward next is 0.4947, 
noisyNet noise sample is [array([0.5101846], dtype=float32), 0.2858827]. 
=============================================
[2019-03-26 22:48:23,316] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.5664369e-24 1.0000000e+00 8.7562898e-24 1.5357786e-18 1.1559299e-30], sum to 1.0000
[2019-03-26 22:48:23,325] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2233
[2019-03-26 22:48:23,332] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3949073917860469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 589260.5812168231, 589260.5812168224, 173549.8204274147], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2676600.0000, 
sim time next is 2677200.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3950110177672582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 589415.3091307866, 589415.3091307866, 173564.0042775566], 
processed observation next is [0.0, 1.0, 0.28909952606635075, 0.94, 1.0, 1.0, 0.27109761176778097, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16372647475855182, 0.16372647475855182, 0.2590507526530696], 
reward next is 0.7409, 
noisyNet noise sample is [array([-0.25895882], dtype=float32), -1.3443853]. 
=============================================
[2019-03-26 22:48:23,919] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.8768438e-23 1.0000000e+00 3.2941683e-23 1.2075221e-18 6.8208419e-30], sum to 1.0000
[2019-03-26 22:48:23,930] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3075
[2019-03-26 22:48:23,937] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.51666666666667, 94.0, 1.0, 2.0, 0.5055154156173153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 706381.8148657124, 706381.8148657124, 184464.8443222244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2022600.0000, 
sim time next is 2023200.0000, 
raw observation next is [25.5, 94.0, 1.0, 2.0, 0.5047153747862756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 705263.5069356282, 705263.5069356275, 184338.2908602052], 
processed observation next is [0.0, 0.43478260869565216, 0.40758293838862564, 0.94, 1.0, 1.0, 0.403271535887079, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1959065297043412, 0.195906529704341, 0.2751317774032913], 
reward next is 0.7249, 
noisyNet noise sample is [array([1.5329365], dtype=float32), 0.36448333]. 
=============================================
[2019-03-26 22:48:24,726] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5307388e-23 1.0000000e+00 2.1082876e-23 1.0626752e-18 1.9208205e-29], sum to 1.0000
[2019-03-26 22:48:24,735] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7733
[2019-03-26 22:48:24,741] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.85, 92.0, 1.0, 2.0, 0.5068470436227975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 708243.1851724104, 708243.1851724099, 184675.9932806488], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2028600.0000, 
sim time next is 2029200.0000, 
raw observation next is [25.96666666666667, 91.33333333333334, 1.0, 2.0, 0.5071619266429156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 708683.3340249904, 708683.3340249899, 184726.0234999185], 
processed observation next is [0.0, 0.4782608695652174, 0.42969984202211703, 0.9133333333333334, 1.0, 1.0, 0.4062191887264043, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19685648167360845, 0.1968564816736083, 0.27571048283569927], 
reward next is 0.7243, 
noisyNet noise sample is [array([-0.7922136], dtype=float32), -1.1611371]. 
=============================================
[2019-03-26 22:48:28,925] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7345683e-23 1.0000000e+00 1.5936744e-21 2.0550909e-18 9.5721174e-29], sum to 1.0000
[2019-03-26 22:48:28,930] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6838
[2019-03-26 22:48:28,935] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.93333333333334, 82.33333333333334, 1.0, 2.0, 0.5247232997634513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733231.209425492, 733231.209425492, 187561.110487983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2107200.0000, 
sim time next is 2107800.0000, 
raw observation next is [28.15, 81.5, 1.0, 2.0, 0.5281077366108463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 737962.1537803897, 737962.1537803903, 188117.8881391904], 
processed observation next is [0.0, 0.391304347826087, 0.533175355450237, 0.815, 1.0, 1.0, 0.43145510435041723, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20498948716121937, 0.2049894871612195, 0.280772967371926], 
reward next is 0.7192, 
noisyNet noise sample is [array([-0.18087804], dtype=float32), -1.7861093]. 
=============================================
[2019-03-26 22:48:39,630] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.2153866e-23 1.0000000e+00 2.1470363e-21 8.9903103e-16 5.4286447e-28], sum to 1.0000
[2019-03-26 22:48:39,637] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8977
[2019-03-26 22:48:39,643] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.1, 80.0, 1.0, 2.0, 0.5613385714576048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 784415.086834244, 784415.086834244, 193764.4831830124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2325600.0000, 
sim time next is 2326200.0000, 
raw observation next is [29.01666666666667, 80.16666666666667, 1.0, 2.0, 0.5599498469338116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 782473.7669935346, 782473.7669935353, 193521.8926222118], 
processed observation next is [1.0, 0.9565217391304348, 0.5742496050552924, 0.8016666666666667, 1.0, 1.0, 0.4698190926913392, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21735382416487073, 0.21735382416487092, 0.28883864570479373], 
reward next is 0.7112, 
noisyNet noise sample is [array([-2.326561], dtype=float32), -1.365099]. 
=============================================
[2019-03-26 22:48:41,343] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.2210406e-12 7.5841941e-02 2.1053491e-10 9.2415810e-01 1.3538603e-15], sum to 1.0000
[2019-03-26 22:48:41,349] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1479
[2019-03-26 22:48:41,354] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.16666666666667, 64.16666666666667, 1.0, 2.0, 0.8367450121644304, 1.0, 2.0, 0.8367450121644304, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2340205.159207548, 2340205.159207549, 438158.500630752], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2303400.0000, 
sim time next is 2304000.0000, 
raw observation next is [32.2, 64.0, 1.0, 2.0, 0.8549220479953572, 1.0, 2.0, 0.8549220479953572, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2391091.257931932, 2391091.257931932, 447496.591853213], 
processed observation next is [1.0, 0.6956521739130435, 0.7251184834123224, 0.64, 1.0, 1.0, 0.8252072867413942, 1.0, 1.0, 0.8252072867413942, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6641920160922034, 0.6641920160922034, 0.6679053609749447], 
reward next is 0.3321, 
noisyNet noise sample is [array([-1.4015766], dtype=float32), -1.0377063]. 
=============================================
[2019-03-26 22:48:41,387] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[41.174957]
 [40.668255]
 [40.00071 ]
 [39.03103 ]
 [38.33484 ]], R is [[41.59316635]
 [41.52326584]
 [41.45908737]
 [41.41134262]
 [40.99723053]].
[2019-03-26 22:48:42,907] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.1734917e-21 1.0000000e+00 1.1346125e-19 1.4954743e-14 2.2953669e-26], sum to 1.0000
[2019-03-26 22:48:42,918] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1668
[2019-03-26 22:48:42,922] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 81.0, 1.0, 2.0, 0.5220923383277316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729553.5273032588, 729553.5273032588, 187129.9057731547], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2340000.0000, 
sim time next is 2340600.0000, 
raw observation next is [27.76666666666667, 81.16666666666667, 1.0, 2.0, 1.036008902548683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1448172.200901085, 1448172.200901085, 310088.4172271824], 
processed observation next is [1.0, 0.08695652173913043, 0.515007898894155, 0.8116666666666668, 1.0, 1.0, 1.0433842199381722, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.40227005580585695, 0.40227005580585695, 0.4628185331748991], 
reward next is 0.5372, 
noisyNet noise sample is [array([0.44438377], dtype=float32), 0.9010318]. 
=============================================
[2019-03-26 22:48:43,590] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 22:48:43,593] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 22:48:43,594] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 22:48:43,595] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:48:43,596] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 22:48:43,597] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 22:48:43,596] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:48:43,597] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 22:48:43,601] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:48:43,603] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:48:43,600] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:48:43,627] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run80
[2019-03-26 22:48:43,665] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run80
[2019-03-26 22:48:43,666] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run80
[2019-03-26 22:48:43,666] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run80
[2019-03-26 22:48:43,734] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run80
[2019-03-26 22:49:02,317] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09337664], dtype=float32), 0.07064761]
[2019-03-26 22:49:02,319] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [19.7, 83.0, 1.0, 2.0, 0.2498543682224275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 412823.2203445097, 412823.2203445103, 160826.7850597729]
[2019-03-26 22:49:02,323] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:49:02,325] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.9816249e-23 1.0000000e+00 2.7478709e-22 1.2660765e-17 1.5146972e-28], sampled 0.30223644113778947
[2019-03-26 22:49:20,129] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09337664], dtype=float32), 0.07064761]
[2019-03-26 22:49:20,132] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.5, 94.0, 1.0, 2.0, 0.3831985600623073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 581368.32670013, 581368.32670013, 173118.7266358]
[2019-03-26 22:49:20,133] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:49:20,136] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.2337986e-22 1.0000000e+00 8.9325449e-22 1.4425716e-17 4.5771006e-28], sampled 0.2143164659880099
[2019-03-26 22:49:37,398] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09337664], dtype=float32), 0.07064761]
[2019-03-26 22:49:37,399] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.33333333333334, 52.66666666666667, 1.0, 2.0, 0.9247173561668341, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005989318858018, 6.9112, 168.9123159571764, 2189634.525496966, 2122387.975316459, 440994.7954728294]
[2019-03-26 22:49:37,400] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 22:49:37,404] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.652884e-15 1.000000e+00 7.771867e-15 5.015087e-09 2.921128e-19], sampled 0.3027575044829858
[2019-03-26 22:49:37,405] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2189634.525496966 W.
[2019-03-26 22:49:41,924] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09337664], dtype=float32), 0.07064761]
[2019-03-26 22:49:41,925] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.5, 70.0, 1.0, 2.0, 0.531093107478223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 742135.2801480719, 742135.2801480726, 188610.1863670394]
[2019-03-26 22:49:41,926] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 22:49:41,928] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.62995488e-22 1.00000000e+00 8.70185624e-22 1.09983165e-16
 6.05867901e-28], sampled 0.26042084503841023
[2019-03-26 22:49:48,279] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09337664], dtype=float32), 0.07064761]
[2019-03-26 22:49:48,283] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [35.07849724, 70.01149256666667, 1.0, 2.0, 0.9896279027178684, 1.0, 1.0, 0.9896279027178684, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 171.5212843490159, 2768243.856117049, 2768243.856117048, 522969.1783741953]
[2019-03-26 22:49:48,284] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:49:48,287] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.8495115e-13 9.6824169e-01 4.9379459e-11 3.1758323e-02 3.5966843e-16], sampled 0.7871105825890303
[2019-03-26 22:49:48,291] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2768243.856117049 W.
[2019-03-26 22:50:12,916] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09337664], dtype=float32), 0.07064761]
[2019-03-26 22:50:12,917] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.440587505, 70.50143918, 1.0, 2.0, 0.6171041602272925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 862373.6120443915, 862373.6120443909, 203966.5294826992]
[2019-03-26 22:50:12,919] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:50:12,921] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.3170102e-22 1.0000000e+00 7.0255584e-22 9.4858439e-17 2.9918816e-28], sampled 0.37394680426567906
[2019-03-26 22:50:33,484] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09337664], dtype=float32), 0.07064761]
[2019-03-26 22:50:33,486] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.3, 84.0, 1.0, 2.0, 0.933783644145616, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.998907457243856, 6.9112, 168.9124344030436, 2202323.671555597, 2140101.175058483, 443863.8906227455]
[2019-03-26 22:50:33,488] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:50:33,491] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.5381606e-16 1.0000000e+00 5.7556535e-16 1.0183497e-10 6.4147832e-21], sampled 0.1935922968448931
[2019-03-26 22:50:33,492] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2202323.671555597 W.
[2019-03-26 22:50:37,561] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.1104 2779424595.2847 931.0000
[2019-03-26 22:50:38,043] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7900.7204 3162634621.9972 1713.0000
[2019-03-26 22:50:38,108] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8501.2081 2841726055.1296 1109.0000
[2019-03-26 22:50:38,156] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8256.4142 2927222616.2943 1330.0000
[2019-03-26 22:50:38,187] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8002.3131 3006696330.2681 1738.0000
[2019-03-26 22:50:39,201] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1975000, evaluation results [1975000.0, 7900.720445603276, 3162634621.997242, 1713.0, 8256.414156361112, 2927222616.2942877, 1330.0, 8658.110397652137, 2779424595.284685, 931.0, 8002.3131186595165, 3006696330.26814, 1738.0, 8501.20806971267, 2841726055.129649, 1109.0]
[2019-03-26 22:50:51,373] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0402144e-22 1.0000000e+00 1.0579821e-20 8.3964661e-16 2.3960791e-28], sum to 1.0000
[2019-03-26 22:50:51,381] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2043
[2019-03-26 22:50:51,389] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3941880045486493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 587763.2868035784, 587763.2868035778, 173399.7780090811], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2840400.0000, 
sim time next is 2841000.0000, 
raw observation next is [23.0, 94.00000000000001, 1.0, 2.0, 0.3946661942987021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 588878.1191612653, 588878.1191612646, 173514.0968981321], 
processed observation next is [1.0, 0.9130434782608695, 0.28909952606635075, 0.9400000000000002, 1.0, 1.0, 0.2706821618056652, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1635772553225737, 0.1635772553225735, 0.2589762640270628], 
reward next is 0.7410, 
noisyNet noise sample is [array([0.16421567], dtype=float32), -0.06387558]. 
=============================================
[2019-03-26 22:50:51,405] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.16009 ]
 [72.03868 ]
 [71.98597 ]
 [72.032585]
 [71.96641 ]], R is [[72.29360199]
 [72.31185913]
 [72.32942963]
 [72.34671783]
 [72.36338806]].
[2019-03-26 22:50:51,914] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9401550e-13 9.5328385e-01 2.8962119e-11 4.6716210e-02 9.6549957e-17], sum to 1.0000
[2019-03-26 22:50:51,924] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7341
[2019-03-26 22:50:51,929] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.8, 71.0, 1.0, 2.0, 0.576945082877522, 1.0, 2.0, 0.576945082877522, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1613064.453598357, 1613064.453598357, 325891.6272801299], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2552400.0000, 
sim time next is 2553000.0000, 
raw observation next is [29.91666666666667, 70.5, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 9.44439842228638, 6.9112, 168.8983127111867, 3251865.06003271, 1454882.715028109, 308050.214633805], 
processed observation next is [1.0, 0.5652173913043478, 0.6169036334913115, 0.705, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.25331984222863796, 0.0, 0.8293680373940528, 0.9032958500090861, 0.40413408750780805, 0.4597764397519477], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.11947763], dtype=float32), 0.2790966]. 
=============================================
[2019-03-26 22:50:51,944] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[47.40869 ]
 [46.186764]
 [45.503662]
 [44.81548 ]
 [44.641384]], R is [[49.70526886]
 [49.7218132 ]
 [49.71111679]
 [49.27869415]
 [48.83037949]].
[2019-03-26 22:50:52,089] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.5427599e-14 9.7548068e-01 3.2705019e-11 2.4519347e-02 3.0555122e-17], sum to 1.0000
[2019-03-26 22:50:52,099] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4858
[2019-03-26 22:50:52,107] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2510101.531915534 W.
[2019-03-26 22:50:52,112] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.26666666666667, 69.0, 1.0, 2.0, 0.8974308473720467, 1.0, 1.0, 0.8974308473720467, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2510101.531915534, 2510101.531915534, 470086.148609618], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2554800.0000, 
sim time next is 2555400.0000, 
raw observation next is [30.38333333333333, 68.5, 1.0, 2.0, 0.9071617219433049, 1.0, 2.0, 0.9071617219433049, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2537346.286954171, 2537346.286954171, 475407.9396331598], 
processed observation next is [1.0, 0.5652173913043478, 0.6390205371248023, 0.685, 1.0, 1.0, 0.8881466529437408, 1.0, 1.0, 0.8881466529437408, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7048184130428253, 0.7048184130428253, 0.7095640890047161], 
reward next is 0.2904, 
noisyNet noise sample is [array([0.2709301], dtype=float32), 0.17007194]. 
=============================================
[2019-03-26 22:50:53,728] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0558522e-22 1.0000000e+00 3.0359008e-22 1.3944172e-17 1.4479831e-28], sum to 1.0000
[2019-03-26 22:50:53,735] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2713
[2019-03-26 22:50:53,740] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 83.16666666666667, 1.0, 2.0, 0.4756558446764272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 664644.4993947353, 664644.4993947353, 179869.5014180462], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2632200.0000, 
sim time next is 2632800.0000, 
raw observation next is [26.33333333333334, 82.33333333333334, 1.0, 2.0, 0.4763915593832231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 665672.8520295065, 665672.8520295065, 179979.603333494], 
processed observation next is [0.0, 0.4782608695652174, 0.44707740916271754, 0.8233333333333335, 1.0, 1.0, 0.3691464570882206, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1849091255637518, 0.1849091255637518, 0.2686262736320806], 
reward next is 0.7314, 
noisyNet noise sample is [array([-0.71797675], dtype=float32), 1.385647]. 
=============================================
[2019-03-26 22:50:58,618] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3737533e-23 1.0000000e+00 7.5032966e-23 1.7936938e-17 2.6894546e-29], sum to 1.0000
[2019-03-26 22:50:58,625] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2294
[2019-03-26 22:50:58,634] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.4196727544789652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 617079.4322294805, 617079.4322294812, 175885.7840774528], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2660400.0000, 
sim time next is 2661000.0000, 
raw observation next is [23.83333333333333, 89.83333333333334, 1.0, 2.0, 0.4151983863922045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 612542.7685328014, 612542.768532802, 175511.5393493354], 
processed observation next is [0.0, 0.8260869565217391, 0.32859399684044216, 0.8983333333333334, 1.0, 1.0, 0.2954197426412103, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17015076903688928, 0.17015076903688944, 0.26195752141691847], 
reward next is 0.7380, 
noisyNet noise sample is [array([1.1217834], dtype=float32), -0.05367427]. 
=============================================
[2019-03-26 22:50:58,651] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[77.96765]
 [77.91409]
 [77.87728]
 [77.83034]
 [77.77901]], R is [[77.97550201]
 [77.93322754]
 [77.89071655]
 [77.84793854]
 [77.80472565]].
[2019-03-26 22:51:05,884] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9731423e-13 9.0306951e-03 5.3527283e-11 9.9096936e-01 1.6848399e-16], sum to 1.0000
[2019-03-26 22:51:05,894] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8346
[2019-03-26 22:51:05,902] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 67.0, 1.0, 2.0, 0.8614397383995828, 1.0, 2.0, 0.8614397383995828, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2409337.852958913, 2409337.852958913, 450901.2894900601], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3414600.0000, 
sim time next is 3415200.0000, 
raw observation next is [33.0, 67.0, 1.0, 2.0, 0.8008811887319947, 1.0, 2.0, 0.8008811887319947, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2239811.474551394, 2239811.474551394, 420312.4225896373], 
processed observation next is [1.0, 0.5217391304347826, 0.7630331753554502, 0.67, 1.0, 1.0, 0.7600978177493911, 1.0, 1.0, 0.7600978177493911, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6221698540420539, 0.6221698540420539, 0.627331974014384], 
reward next is 0.3727, 
noisyNet noise sample is [array([1.232777], dtype=float32), -0.32894507]. 
=============================================
[2019-03-26 22:51:09,348] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9094160e-22 1.0000000e+00 2.5219549e-21 3.3004062e-16 6.8827681e-28], sum to 1.0000
[2019-03-26 22:51:09,357] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4143
[2019-03-26 22:51:09,362] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666666, 90.66666666666667, 1.0, 2.0, 0.4064164472869222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 600874.1257394182, 600874.1257394182, 174456.3596540048], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2838000.0000, 
sim time next is 2838600.0000, 
raw observation next is [23.5, 91.5, 1.0, 2.0, 0.402772868211731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 596731.3529397737, 596731.3529397737, 174111.2858917953], 
processed observation next is [1.0, 0.8695652173913043, 0.31279620853080575, 0.915, 1.0, 1.0, 0.2804492388093145, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16575870914993715, 0.16575870914993715, 0.25986759088327654], 
reward next is 0.7401, 
noisyNet noise sample is [array([1.55537], dtype=float32), -1.2334032]. 
=============================================
[2019-03-26 22:51:10,344] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4898092e-21 1.0000000e+00 2.4190122e-20 1.2074273e-15 4.1327814e-27], sum to 1.0000
[2019-03-26 22:51:10,353] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0091
[2019-03-26 22:51:10,358] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3477500604550242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 535700.2321383464, 535700.2321383464, 169464.1551222687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2858400.0000, 
sim time next is 2859000.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.463536188504447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 714057.5529147636, 714057.552914763, 186056.7008064638], 
processed observation next is [1.0, 0.08695652173913043, 0.2417061611374408, 0.9400000000000002, 1.0, 1.0, 0.35365805843909276, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19834932025410099, 0.19834932025410082, 0.27769656836785644], 
reward next is 0.7223, 
noisyNet noise sample is [array([-0.5870493], dtype=float32), 0.5940369]. 
=============================================
[2019-03-26 22:51:10,374] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[70.14801 ]
 [70.11455 ]
 [70.13143 ]
 [70.1487  ]
 [70.144585]], R is [[70.17534637]
 [70.22066498]
 [70.2654953 ]
 [70.30984497]
 [70.35371399]].
[2019-03-26 22:51:10,562] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.9143313e-22 1.0000000e+00 3.3652482e-21 1.5799258e-16 2.4641653e-27], sum to 1.0000
[2019-03-26 22:51:10,575] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3152
[2019-03-26 22:51:10,582] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.3450129291095888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 531487.0762492359, 531487.0762492366, 169121.4220597318], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2873400.0000, 
sim time next is 2874000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3445782197527655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 530816.2143129116, 530816.2143129123, 169067.0264720253], 
processed observation next is [1.0, 0.2608695652173913, 0.2417061611374408, 0.94, 1.0, 1.0, 0.2103352045214042, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14744894842025322, 0.1474489484202534, 0.25233884548063473], 
reward next is 0.7477, 
noisyNet noise sample is [array([-1.0666602], dtype=float32), -0.109318376]. 
=============================================
[2019-03-26 22:51:10,598] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[70.260826]
 [70.21508 ]
 [70.1776  ]
 [70.16593 ]
 [70.09206 ]], R is [[70.33261108]
 [70.3768692 ]
 [70.42136383]
 [70.46517181]
 [70.5072403 ]].
[2019-03-26 22:51:10,944] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0738392e-21 1.0000000e+00 7.9552674e-21 8.0086595e-17 3.7744991e-27], sum to 1.0000
[2019-03-26 22:51:10,957] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4839
[2019-03-26 22:51:10,963] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.3835916465584336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 590912.58056965, 590912.5805696495, 174189.2145948113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2869800.0000, 
sim time next is 2870400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3648769842953998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 562068.2695467542, 562068.2695467548, 171666.4570487527], 
processed observation next is [1.0, 0.21739130434782608, 0.2417061611374408, 0.94, 1.0, 1.0, 0.23479154734385516, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15613007487409838, 0.15613007487409855, 0.2562185926100786], 
reward next is 0.7438, 
noisyNet noise sample is [array([-0.0420425], dtype=float32), 0.30299437]. 
=============================================
[2019-03-26 22:51:14,155] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2499682e-22 1.0000000e+00 3.8787589e-21 9.8900917e-17 1.7218066e-28], sum to 1.0000
[2019-03-26 22:51:14,164] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1171
[2019-03-26 22:51:14,170] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 95.0, 1.0, 2.0, 0.3245970395610622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 511336.1056912722, 511336.1056912722, 167844.7569561113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2919000.0000, 
sim time next is 2919600.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.3214245079321091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 507786.9718983622, 507786.9718983629, 167602.9986496499], 
processed observation next is [1.0, 0.8260869565217391, 0.19431279620853087, 0.94, 1.0, 1.0, 0.18243916618326395, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14105193663843396, 0.14105193663843416, 0.2501537293278357], 
reward next is 0.7498, 
noisyNet noise sample is [array([-0.1993001], dtype=float32), 0.4065318]. 
=============================================
[2019-03-26 22:51:15,441] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0005884e-21 1.0000000e+00 5.6029547e-21 2.2898776e-16 9.3442510e-28], sum to 1.0000
[2019-03-26 22:51:15,449] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9889
[2019-03-26 22:51:15,455] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.5710010803508623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 859872.9306723499, 859872.9306723499, 203122.4649665443], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3057600.0000, 
sim time next is 3058200.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.5764305647285458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 868067.4489496684, 868067.4489496684, 204174.1835280488], 
processed observation next is [1.0, 0.391304347826087, 0.2417061611374408, 1.0, 1.0, 1.0, 0.489675379191019, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24112984693046347, 0.24112984693046347, 0.3047375873552967], 
reward next is 0.6953, 
noisyNet noise sample is [array([-0.20148979], dtype=float32), -0.1617442]. 
=============================================
[2019-03-26 22:51:27,440] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.3048068e-14 1.3026227e-04 7.4133720e-12 9.9986970e-01 5.6896990e-17], sum to 1.0000
[2019-03-26 22:51:27,448] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4769
[2019-03-26 22:51:27,454] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.83333333333334, 60.5, 1.0, 2.0, 0.8986701324061196, 1.0, 2.0, 0.8986701324061196, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2513571.281289639, 2513571.281289639, 470772.6374310266], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3769800.0000, 
sim time next is 3770400.0000, 
raw observation next is [33.66666666666667, 61.00000000000001, 1.0, 2.0, 0.9770631992543581, 1.0, 2.0, 0.9770631992543581, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2733075.720474157, 2733075.720474157, 515282.4155214336], 
processed observation next is [1.0, 0.6521739130434783, 0.7946287519747238, 0.6100000000000001, 1.0, 1.0, 0.9723653003064556, 1.0, 1.0, 0.9723653003064556, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7591877001317103, 0.7591877001317103, 0.7690782321215427], 
reward next is 0.2309, 
noisyNet noise sample is [array([0.8057628], dtype=float32), -0.9352008]. 
=============================================
[2019-03-26 22:51:29,760] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5605198e-22 1.0000000e+00 1.2941663e-21 8.4376615e-16 1.0149198e-28], sum to 1.0000
[2019-03-26 22:51:29,770] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2627
[2019-03-26 22:51:29,774] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5169078942163573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 722306.5037944618, 722306.5037944611, 186287.6925481673], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3808200.0000, 
sim time next is 3808800.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5166814000258863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 721989.9022757778, 721989.9022757784, 186251.0924673056], 
processed observation next is [0.0, 0.08695652173913043, 0.5260663507109005, 0.79, 1.0, 1.0, 0.41768843376612796, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2005527506321605, 0.20055275063216066, 0.277986705175083], 
reward next is 0.7220, 
noisyNet noise sample is [array([0.95344776], dtype=float32), 0.19340579]. 
=============================================
[2019-03-26 22:51:30,103] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.1241180e-16 1.0000000e+00 2.9333725e-15 3.0344491e-10 4.1069881e-21], sum to 1.0000
[2019-03-26 22:51:30,110] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7526
[2019-03-26 22:51:30,121] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2049085.34007399 W.
[2019-03-26 22:51:30,128] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 70.0, 1.0, 2.0, 0.7327477826996587, 1.0, 2.0, 0.7327477826996587, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2049085.34007399, 2049085.34007399, 388449.765087457], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3747000.0000, 
sim time next is 3747600.0000, 
raw observation next is [29.0, 70.0, 1.0, 2.0, 0.4734924412688309, 1.0, 2.0, 0.4734924412688309, 1.0, 1.0, 0.8031906992062788, 6.9112, 6.9112, 170.5573041426782, 1986081.582946533, 1986081.582946533, 394001.7464126885], 
processed observation next is [1.0, 0.391304347826087, 0.5734597156398105, 0.7, 1.0, 1.0, 0.3656535436973867, 1.0, 1.0, 0.3656535436973867, 1.0, 0.5, 0.7599886575686327, 0.0, 0.0, 0.8375144448122397, 0.5516893285962592, 0.5516893285962592, 0.5880623080786396], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.06756863], dtype=float32), 0.30917796]. 
=============================================
[2019-03-26 22:51:31,610] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.9286798e-14 7.5055705e-04 5.7290756e-12 9.9924940e-01 4.0361911e-17], sum to 1.0000
[2019-03-26 22:51:31,619] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3397
[2019-03-26 22:51:31,629] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.5, 61.5, 1.0, 2.0, 0.9983997071252936, 1.0, 2.0, 0.9983997071252936, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2792825.668344412, 2792825.668344412, 528021.4233530221], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3771000.0000, 
sim time next is 3771600.0000, 
raw observation next is [33.33333333333334, 62.0, 1.0, 2.0, 1.007174547610221, 1.0, 2.0, 1.007174547610221, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2817399.228370426, 2817399.228370425, 533337.8214101889], 
processed observation next is [1.0, 0.6521739130434783, 0.7788309636650873, 0.62, 1.0, 1.0, 1.0086440332653264, 1.0, 1.0, 1.0086440332653264, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7826108967695629, 0.7826108967695624, 0.796026599119685], 
reward next is 0.2040, 
noisyNet noise sample is [array([-1.0265012], dtype=float32), 0.3591694]. 
=============================================
[2019-03-26 22:51:34,631] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2180691e-20 1.0000000e+00 7.0394350e-20 7.5208936e-15 1.2289166e-26], sum to 1.0000
[2019-03-26 22:51:34,645] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5131
[2019-03-26 22:51:34,651] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 80.66666666666667, 1.0, 2.0, 0.7387330742704793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1032426.831788324, 1032426.831788325, 229424.6209387329], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3466200.0000, 
sim time next is 3466800.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.7239280371469882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1011725.986990375, 1011725.986990374, 226091.4214379836], 
processed observation next is [1.0, 0.13043478260869565, 0.4786729857819906, 0.79, 1.0, 1.0, 0.6673831772855279, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.28103499638621526, 0.281034996386215, 0.3374498827432591], 
reward next is 0.6626, 
noisyNet noise sample is [array([1.8995665], dtype=float32), -1.2218404]. 
=============================================
[2019-03-26 22:51:34,990] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 22:51:34,994] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 22:51:34,995] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:51:34,995] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 22:51:34,996] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 22:51:34,997] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 22:51:34,998] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:51:34,998] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:51:34,998] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 22:51:34,999] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:51:35,006] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:51:35,850] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run81
[2019-03-26 22:51:36,014] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run81
[2019-03-26 22:51:36,030] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run81
[2019-03-26 22:51:36,059] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run81
[2019-03-26 22:51:36,121] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run81
[2019-03-26 22:51:47,614] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09402432], dtype=float32), 0.07149237]
[2019-03-26 22:51:47,617] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.3, 73.5, 1.0, 2.0, 0.3377220262139391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 527489.9817065167, 527489.9817065161, 169005.3557129481]
[2019-03-26 22:51:47,618] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:51:47,625] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.3591545e-22 1.0000000e+00 9.1428398e-22 1.3172597e-17 4.9861103e-28], sampled 0.7264201617522434
[2019-03-26 22:51:51,581] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09402432], dtype=float32), 0.07149237]
[2019-03-26 22:51:51,583] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.88635248, 91.026128355, 1.0, 2.0, 0.3394172245162997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 544079.0104037722, 544079.0104037717, 170490.156734425]
[2019-03-26 22:51:51,583] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:51:51,585] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.1005327e-23 1.0000000e+00 2.6013141e-22 7.5193902e-18 1.0565179e-28], sampled 0.2943394382738582
[2019-03-26 22:51:55,776] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09402432], dtype=float32), 0.07149237]
[2019-03-26 22:51:55,777] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.86666666666667, 44.66666666666666, 1.0, 2.0, 0.2330871548183633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 388175.979437235, 388175.9794372356, 158809.0790782647]
[2019-03-26 22:51:55,780] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:51:55,785] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0988721e-22 1.0000000e+00 5.7526070e-22 2.0796816e-17 3.8456695e-28], sampled 0.1042901934092364
[2019-03-26 22:52:14,547] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09402432], dtype=float32), 0.07149237]
[2019-03-26 22:52:14,549] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.58333333333334, 66.16666666666667, 1.0, 2.0, 0.9891276204738475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1382597.106236042, 1382597.106236043, 295628.0875350274]
[2019-03-26 22:52:14,551] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 22:52:14,554] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.3445212e-22 1.0000000e+00 6.2179191e-21 9.9497394e-15 3.0879509e-27], sampled 0.9838458646963908
[2019-03-26 22:52:58,419] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09402432], dtype=float32), 0.07149237]
[2019-03-26 22:52:58,420] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.66666666666667, 78.16666666666666, 1.0, 2.0, 0.6483896913125208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 906112.2984059945, 906112.2984059945, 210107.6921439337]
[2019-03-26 22:52:58,423] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:52:58,428] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.97918385e-23 1.00000000e+00 2.49400811e-22 2.60935117e-17
 1.00163506e-28], sampled 0.46205626361726504
[2019-03-26 22:53:07,054] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09402432], dtype=float32), 0.07149237]
[2019-03-26 22:53:07,055] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.2, 76.66666666666666, 1.0, 2.0, 0.5872449610693765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 820630.6865746818, 820630.6865746812, 198393.3562043537]
[2019-03-26 22:53:07,056] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:53:07,060] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.4512745e-23 1.0000000e+00 2.0222457e-22 2.0942506e-17 8.1028904e-29], sampled 0.31499107997799836
[2019-03-26 22:53:21,775] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09402432], dtype=float32), 0.07149237]
[2019-03-26 22:53:21,776] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.35, 75.0, 1.0, 2.0, 0.6882301421210009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1067253.913742923, 1067253.913742923, 231366.6282060146]
[2019-03-26 22:53:21,776] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 22:53:21,778] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.8150898e-22 1.0000000e+00 1.6367597e-21 3.6199902e-17 8.9575291e-28], sampled 0.33181219657710725
[2019-03-26 22:53:30,612] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8256.1544 2927392711.6677 1335.0000
[2019-03-26 22:53:30,633] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.5991 2779381701.3046 932.0000
[2019-03-26 22:53:30,712] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8002.1149 3006555482.5708 1737.0000
[2019-03-26 22:53:30,816] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7896.1355 3162937243.6189 1729.0000
[2019-03-26 22:53:30,943] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8503.9225 2841630395.1471 1112.0000
[2019-03-26 22:53:31,961] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2000000, evaluation results [2000000.0, 7896.135537429392, 3162937243.618873, 1729.0, 8256.154416702902, 2927392711.6677475, 1335.0, 8660.599073120611, 2779381701.304638, 932.0, 8002.114885901719, 3006555482.570803, 1737.0, 8503.922513109035, 2841630395.1471453, 1112.0]
[2019-03-26 22:53:36,480] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1710527e-20 1.0000000e+00 2.1281128e-19 7.9043810e-15 4.1880924e-26], sum to 1.0000
[2019-03-26 22:53:36,489] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4051
[2019-03-26 22:53:36,494] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.7964846343115369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1138471.644683996, 1138471.644683996, 246585.3304880439], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3726600.0000, 
sim time next is 3727200.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.6683239317910767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 955188.7983335488, 955188.7983335488, 216955.5882730162], 
processed observation next is [1.0, 0.13043478260869565, 0.4786729857819906, 0.74, 1.0, 1.0, 0.6003902792663575, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.26533022175931914, 0.26533022175931914, 0.3238143108552481], 
reward next is 0.6762, 
noisyNet noise sample is [array([-0.46319103], dtype=float32), -0.53712]. 
=============================================
[2019-03-26 22:53:40,827] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.2096819e-14 8.1852697e-02 3.6089787e-11 9.1814733e-01 7.5340865e-16], sum to 1.0000
[2019-03-26 22:53:40,836] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2544
[2019-03-26 22:53:40,841] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.16666666666666, 62.5, 1.0, 2.0, 0.9471127638056895, 1.0, 2.0, 0.9471127638056895, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2649208.477121676, 2649208.477121677, 497849.9378434704], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3426600.0000, 
sim time next is 3427200.0000, 
raw observation next is [33.0, 63.0, 1.0, 2.0, 0.9507941424564362, 1.0, 2.0, 0.9507941424564362, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2659516.774328906, 2659516.774328906, 499963.7320374476], 
processed observation next is [1.0, 0.6956521739130435, 0.7630331753554502, 0.63, 1.0, 1.0, 0.9407158342848629, 1.0, 1.0, 0.9407158342848629, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7387546595358072, 0.7387546595358072, 0.7462145254290263], 
reward next is 0.2538, 
noisyNet noise sample is [array([0.14053065], dtype=float32), 0.0038880222]. 
=============================================
[2019-03-26 22:53:45,314] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.9867318e-23 1.0000000e+00 4.7417797e-21 5.7253959e-14 4.9159263e-29], sum to 1.0000
[2019-03-26 22:53:45,324] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1049
[2019-03-26 22:53:45,329] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.525114077381621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733777.4579177726, 733777.457917772, 187624.4689086815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3614400.0000, 
sim time next is 3615000.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.5239995308192782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 732219.4897511872, 732219.4897511872, 187441.802578741], 
processed observation next is [1.0, 0.8695652173913043, 0.5734597156398105, 0.74, 1.0, 1.0, 0.42650545881840746, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2033943027086631, 0.2033943027086631, 0.27976388444588207], 
reward next is 0.7202, 
noisyNet noise sample is [array([1.0044878], dtype=float32), 1.2725145]. 
=============================================
[2019-03-26 22:53:45,349] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[77.704796]
 [78.20884 ]
 [78.82349 ]
 [79.105415]
 [78.858765]], R is [[76.77626801]
 [76.72846985]
 [76.68052673]
 [76.63243866]
 [76.58415985]].
[2019-03-26 22:53:47,173] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.0794438e-21 1.0000000e+00 3.5964204e-20 2.5974279e-14 2.0483907e-26], sum to 1.0000
[2019-03-26 22:53:47,181] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3490
[2019-03-26 22:53:47,188] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.4846324784678872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 677191.7476338005, 677191.7476338011, 181223.0983454054], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3549600.0000, 
sim time next is 3550200.0000, 
raw observation next is [27.0, 79.00000000000001, 1.0, 2.0, 0.9667862791232862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1351348.627106486, 1351348.627106486, 288965.8720934038], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.7900000000000001, 1.0, 1.0, 0.9599834688232364, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.37537461864069055, 0.37537461864069055, 0.4312923464080654], 
reward next is 0.5687, 
noisyNet noise sample is [array([-0.60543716], dtype=float32), -0.5911194]. 
=============================================
[2019-03-26 22:53:56,984] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0239745e-22 1.0000000e+00 3.4473140e-21 3.3161938e-16 2.6345023e-27], sum to 1.0000
[2019-03-26 22:53:56,993] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3516
[2019-03-26 22:53:56,998] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5169078942163573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 722306.5037944618, 722306.5037944611, 186287.6925481673], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3808200.0000, 
sim time next is 3808800.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5166814000258863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 721989.9022757778, 721989.9022757784, 186251.0924673056], 
processed observation next is [0.0, 0.08695652173913043, 0.5260663507109005, 0.79, 1.0, 1.0, 0.41768843376612796, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2005527506321605, 0.20055275063216066, 0.277986705175083], 
reward next is 0.7220, 
noisyNet noise sample is [array([-1.1442994], dtype=float32), 0.22691917]. 
=============================================
[2019-03-26 22:54:03,215] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5694421e-18 1.0000000e+00 3.6264329e-16 1.5634328e-08 1.1321550e-22], sum to 1.0000
[2019-03-26 22:54:03,228] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2661
[2019-03-26 22:54:03,232] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.8993734095448372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1257064.892096279, 1257064.89209628, 269768.7844799876], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3996000.0000, 
sim time next is 3996600.0000, 
raw observation next is [29.16666666666667, 84.0, 1.0, 2.0, 0.9836277700152309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1374904.467449562, 1374904.467449563, 293981.0077861331], 
processed observation next is [1.0, 0.2608695652173913, 0.581358609794629, 0.84, 1.0, 1.0, 0.9802744217050975, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3819179076248783, 0.38191790762487865, 0.43877762356139266], 
reward next is 0.5612, 
noisyNet noise sample is [array([0.15878068], dtype=float32), -0.01598317]. 
=============================================
[2019-03-26 22:54:06,347] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.8940427e-23 1.0000000e+00 1.3631621e-22 3.3405825e-17 5.3088584e-29], sum to 1.0000
[2019-03-26 22:54:06,356] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7720
[2019-03-26 22:54:06,360] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.0, 55.16666666666667, 1.0, 2.0, 0.5886267292396848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 822562.3514021109, 822562.3514021116, 198646.955114458], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3858600.0000, 
sim time next is 3859200.0000, 
raw observation next is [35.0, 55.0, 1.0, 2.0, 0.5874360757035686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 820897.8581129654, 820897.8581129654, 198429.3402831675], 
processed observation next is [0.0, 0.6956521739130435, 0.8578199052132701, 0.55, 1.0, 1.0, 0.502935030968155, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22802718280915704, 0.22802718280915704, 0.2961631944524888], 
reward next is 0.7038, 
noisyNet noise sample is [array([0.47614232], dtype=float32), -0.7330898]. 
=============================================
[2019-03-26 22:54:14,888] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0841633e-19 1.0000000e+00 8.3259327e-19 9.1289806e-12 8.0845319e-26], sum to 1.0000
[2019-03-26 22:54:14,897] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0474
[2019-03-26 22:54:14,907] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2163191.024890704 W.
[2019-03-26 22:54:14,913] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.83333333333333, 84.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.91055101858602, 6.9112, 168.9073387059962, 2163191.024890704, 1454240.596764241, 311356.2146085633], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4000200.0000, 
sim time next is 4000800.0000, 
raw observation next is [29.66666666666667, 84.0, 1.0, 2.0, 0.4268786946449732, 1.0, 1.0, 0.4268786946449732, 1.0, 1.0, 0.7413471216567808, 6.9112, 6.9112, 170.5573041426782, 1790395.132860543, 1790395.132860543, 368267.6971229135], 
processed observation next is [1.0, 0.30434782608695654, 0.6050552922590839, 0.84, 1.0, 1.0, 0.30949240318671467, 1.0, 0.5, 0.30949240318671467, 1.0, 0.5, 0.6845696605570498, 0.0, 0.0, 0.8375144448122397, 0.49733198135015083, 0.49733198135015083, 0.5496532792879306], 
reward next is 0.4503, 
noisyNet noise sample is [array([-0.9204682], dtype=float32), 0.2151315]. 
=============================================
[2019-03-26 22:54:16,814] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.85690040e-14 8.38023479e-05 1.05486999e-11 9.99916196e-01
 1.05683077e-16], sum to 1.0000
[2019-03-26 22:54:16,822] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5028
[2019-03-26 22:54:16,828] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.0, 60.0, 1.0, 2.0, 0.822175588500539, 1.0, 2.0, 0.7316778337645321, 1.0, 1.0, 1.03, 7.005107367565701, 6.9112, 170.5573041426782, 3070426.7619368, 3003157.094642005, 562695.0626738388], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4031400.0000, 
sim time next is 4032000.0000, 
raw observation next is [34.0, 60.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 6.95596369871359, 6.9112, 170.5573041426782, 2941433.17198281, 2909367.113723422, 553405.6458130722], 
processed observation next is [1.0, 0.6956521739130435, 0.8104265402843602, 0.6, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.004476369871358976, 0.0, 0.8375144448122397, 0.8170647699952249, 0.8081575315898394, 0.8259785758404063], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.38660002], dtype=float32), 1.0816182]. 
=============================================
[2019-03-26 22:54:16,846] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[37.27092 ]
 [39.81722 ]
 [39.16468 ]
 [38.592247]
 [37.699665]], R is [[37.53988647]
 [37.16448975]
 [36.79284668]
 [36.42491913]
 [36.06066895]].
[2019-03-26 22:54:18,335] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.8073952e-23 1.0000000e+00 1.1242153e-21 7.4013487e-17 3.9477098e-28], sum to 1.0000
[2019-03-26 22:54:18,345] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8169
[2019-03-26 22:54:18,353] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.5856808067897477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 818444.0564191804, 818444.0564191804, 198108.2894874195], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4421400.0000, 
sim time next is 4422000.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.5853686592339303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 818007.6861553146, 818007.6861553151, 198051.4949600791], 
processed observation next is [0.0, 0.17391304347826086, 0.5734597156398105, 0.84, 1.0, 1.0, 0.5004441677517233, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22722435726536516, 0.22722435726536533, 0.29559924620907324], 
reward next is 0.7044, 
noisyNet noise sample is [array([0.97330785], dtype=float32), 0.928407]. 
=============================================
[2019-03-26 22:54:18,381] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[71.57678]
 [71.65134]
 [71.57552]
 [71.75559]
 [71.75592]], R is [[71.51785278]
 [71.50698853]
 [71.49607086]
 [71.48406219]
 [71.47097778]].
[2019-03-26 22:54:20,408] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6604236e-13 1.4063244e-01 4.2977011e-10 8.5936755e-01 3.9379700e-16], sum to 1.0000
[2019-03-26 22:54:20,416] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7820
[2019-03-26 22:54:20,424] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.5, 71.0, 1.0, 2.0, 0.5000324760727848, 1.0, 2.0, 0.5000324760727848, 1.0, 1.0, 0.868391047671691, 6.9112, 6.9112, 170.5573041426782, 2097513.725323216, 2097513.725323216, 415171.2226586124], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4105800.0000, 
sim time next is 4106400.0000, 
raw observation next is [33.66666666666666, 71.0, 1.0, 2.0, 0.7907902417049827, 1.0, 2.0, 0.7907902417049827, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2211565.15925595, 2211565.15925595, 415434.1575664577], 
processed observation next is [1.0, 0.5217391304347826, 0.7946287519747232, 0.71, 1.0, 1.0, 0.7479400502469671, 1.0, 1.0, 0.7479400502469671, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6143236553488749, 0.6143236553488749, 0.6200509814424742], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.51021767], dtype=float32), 1.3052994]. 
=============================================
[2019-03-26 22:54:25,123] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1724651e-20 1.0000000e+00 3.2993184e-19 1.0726603e-13 7.0144876e-25], sum to 1.0000
[2019-03-26 22:54:25,143] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8375
[2019-03-26 22:54:25,146] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 89.0, 1.0, 2.0, 0.9006624569647119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510424, 1258867.677126204, 1258867.677126204, 270122.7089204718], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4167600.0000, 
sim time next is 4168200.0000, 
raw observation next is [28.0, 89.0, 1.0, 2.0, 0.8809010652799849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1231230.906649581, 1231230.906649581, 264740.7812458202], 
processed observation next is [1.0, 0.21739130434782608, 0.5260663507109005, 0.89, 1.0, 1.0, 0.8565073075662468, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.34200858518043914, 0.34200858518043914, 0.3951354943967466], 
reward next is 0.6049, 
noisyNet noise sample is [array([-0.4250845], dtype=float32), 0.4265079]. 
=============================================
[2019-03-26 22:54:28,035] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 22:54:28,038] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 22:54:28,040] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:54:28,041] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 22:54:28,043] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 22:54:28,042] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 22:54:28,045] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 22:54:28,044] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:54:28,045] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:54:28,046] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:54:28,046] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:54:28,076] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run82
[2019-03-26 22:54:28,100] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run82
[2019-03-26 22:54:28,126] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run82
[2019-03-26 22:54:28,127] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run82
[2019-03-26 22:54:28,184] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run82
[2019-03-26 22:54:52,477] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09123825], dtype=float32), 0.06929558]
[2019-03-26 22:54:52,478] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.35803026, 78.20914605, 1.0, 2.0, 0.3072202366890245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 492541.7730657942, 492541.7730657948, 166558.7997948996]
[2019-03-26 22:54:52,479] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 22:54:52,483] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.8391202e-22 1.0000000e+00 1.5205323e-21 1.6504060e-17 1.1075851e-27], sampled 0.05253295969964655
[2019-03-26 22:54:53,932] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09123825], dtype=float32), 0.06929558]
[2019-03-26 22:54:53,933] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.48885960833333, 90.37069882166666, 1.0, 2.0, 0.5328477478267323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 744588.0269145094, 744588.0269145101, 188902.1037002147]
[2019-03-26 22:54:53,935] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:54:53,936] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.3626838e-22 1.0000000e+00 6.1230106e-22 1.1378780e-16 2.5803243e-28], sampled 0.7027298504125162
[2019-03-26 22:54:55,883] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09123825], dtype=float32), 0.06929558]
[2019-03-26 22:54:55,884] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.7, 87.0, 1.0, 2.0, 0.3942770632765921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 592280.4391646076, 592280.4391646076, 173942.5526787878]
[2019-03-26 22:54:55,885] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 22:54:55,887] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.2125510e-22 1.0000000e+00 2.7766171e-21 1.4348285e-16 2.5380646e-27], sampled 0.522886520254815
[2019-03-26 22:55:02,672] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09123825], dtype=float32), 0.06929558]
[2019-03-26 22:55:02,673] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.75, 83.66666666666667, 1.0, 2.0, 0.4580447000456556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 649352.843051395, 649352.843051395, 178486.0109766931]
[2019-03-26 22:55:02,674] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:55:02,678] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.8359793e-22 1.0000000e+00 1.6228642e-21 2.3552400e-17 1.1390834e-27], sampled 0.5216328943398703
[2019-03-26 22:55:15,524] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09123825], dtype=float32), 0.06929558]
[2019-03-26 22:55:15,526] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.0, 63.0, 1.0, 2.0, 0.9100709841871512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1272025.976252002, 1272025.976252002, 272727.0228898615]
[2019-03-26 22:55:15,527] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:55:15,532] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.8997738e-22 1.0000000e+00 1.8185837e-20 9.2167823e-14 9.5047715e-28], sampled 0.665678876058277
[2019-03-26 22:55:39,917] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09123825], dtype=float32), 0.06929558]
[2019-03-26 22:55:39,919] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.0, 80.0, 1.0, 2.0, 0.8556109090440929, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.998484432499867, 6.9112, 168.9123649306433, 2092905.883909946, 2030983.520266184, 422328.4324263356]
[2019-03-26 22:55:39,920] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:55:39,922] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1847651e-10 9.9882346e-01 3.8191469e-10 1.1765430e-03 5.4417957e-14], sampled 0.947830358961352
[2019-03-26 22:55:39,923] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2092905.883909946 W.
[2019-03-26 22:56:20,615] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09123825], dtype=float32), 0.06929558]
[2019-03-26 22:56:20,616] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.42419705, 96.650889275, 1.0, 2.0, 0.6654661712792524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 929986.8036658576, 929986.8036658576, 213569.2157153962]
[2019-03-26 22:56:20,617] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:56:20,619] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.3835103e-22 1.0000000e+00 3.3961088e-21 1.9602730e-16 2.1245756e-27], sampled 0.8922883977462062
[2019-03-26 22:56:21,767] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8502.4041 2841971504.5155 1111.0000
[2019-03-26 22:56:21,903] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7903.7707 3162737271.4514 1715.0000
[2019-03-26 22:56:22,218] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.4375 2779110677.0335 933.0000
[2019-03-26 22:56:22,265] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8005.1729 3006246030.9339 1728.0000
[2019-03-26 22:56:22,332] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1239 2927268517.8611 1333.0000
[2019-03-26 22:56:23,352] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2025000, evaluation results [2025000.0, 7903.770743724995, 3162737271.451387, 1715.0, 8255.123941333066, 2927268517.861138, 1333.0, 8660.437504872592, 2779110677.033492, 933.0, 8005.172947789393, 3006246030.9338927, 1728.0, 8502.40410352521, 2841971504.515527, 1111.0]
[2019-03-26 22:56:25,087] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.6473495e-22 1.0000000e+00 3.9709383e-21 2.3583070e-16 1.4899184e-27], sum to 1.0000
[2019-03-26 22:56:25,096] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9145
[2019-03-26 22:56:25,102] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 82.33333333333334, 1.0, 2.0, 0.5826276356725464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 814175.8484580095, 814175.8484580095, 197554.2035287762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4432800.0000, 
sim time next is 4433400.0000, 
raw observation next is [29.5, 81.5, 1.0, 2.0, 0.5835800211355796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 815507.2424217336, 815507.2424217336, 197726.8947056104], 
processed observation next is [0.0, 0.30434782608695654, 0.5971563981042655, 0.815, 1.0, 1.0, 0.49828918209105977, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22652978956159267, 0.22652978956159267, 0.29511476821732896], 
reward next is 0.7049, 
noisyNet noise sample is [array([0.11361448], dtype=float32), -0.3001277]. 
=============================================
[2019-03-26 22:56:29,501] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.1499041e-23 1.0000000e+00 3.1573207e-21 2.4658273e-14 1.1128530e-28], sum to 1.0000
[2019-03-26 22:56:29,510] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9271
[2019-03-26 22:56:29,515] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333333, 77.33333333333333, 1.0, 2.0, 0.5206245008709525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 727501.7203321003, 727501.7203320996, 186890.6140350714], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4995600.0000, 
sim time next is 4996200.0000, 
raw observation next is [28.16666666666667, 78.16666666666667, 1.0, 2.0, 0.5190113034278284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 725246.7274278646, 725246.7274278653, 186628.4037743669], 
processed observation next is [1.0, 0.8260869565217391, 0.5339652448657191, 0.7816666666666667, 1.0, 1.0, 0.42049554629858843, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20145742428551794, 0.20145742428551813, 0.27854985637965207], 
reward next is 0.7215, 
noisyNet noise sample is [array([-0.5315183], dtype=float32), -0.5803098]. 
=============================================
[2019-03-26 22:56:30,361] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.7286357e-17 1.0000000e+00 8.9810598e-15 3.4825550e-08 2.2363662e-21], sum to 1.0000
[2019-03-26 22:56:30,368] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2194
[2019-03-26 22:56:30,374] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 87.33333333333334, 1.0, 2.0, 0.9635833083264508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104117, 1346868.758135521, 1346868.75813552, 288032.1628147765], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4342800.0000, 
sim time next is 4343400.0000, 
raw observation next is [29.5, 86.5, 1.0, 2.0, 0.9740883626934729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1361561.834175812, 1361561.834175812, 291136.0962604904], 
processed observation next is [1.0, 0.2608695652173913, 0.5971563981042655, 0.865, 1.0, 1.0, 0.968781159871654, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.37821162060439223, 0.37821162060439223, 0.43453148695595584], 
reward next is 0.5655, 
noisyNet noise sample is [array([-0.96882486], dtype=float32), 0.82203877]. 
=============================================
[2019-03-26 22:56:43,856] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.7584728e-13 2.9066065e-01 1.1506455e-10 7.0933932e-01 5.7977907e-16], sum to 1.0000
[2019-03-26 22:56:43,866] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7533
[2019-03-26 22:56:43,873] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.7771272063442596, 1.0, 2.0, 0.7771272063442596, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2173315.638294393, 2173315.638294393, 408895.5700087291], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5236200.0000, 
sim time next is 5236800.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.8923176418600224, 1.0, 2.0, 0.8923176418600224, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2495785.68457573, 2495785.684575729, 467320.6622360242], 
processed observation next is [1.0, 0.6086956521739131, 0.7156398104265403, 0.67, 1.0, 1.0, 0.8702622191084607, 1.0, 1.0, 0.8702622191084607, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6932738012710361, 0.6932738012710359, 0.6974935257254092], 
reward next is 0.3025, 
noisyNet noise sample is [array([1.5378402], dtype=float32), -0.5230337]. 
=============================================
[2019-03-26 22:56:44,449] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4139277e-21 1.0000000e+00 1.1195516e-19 7.2268946e-16 2.8027997e-26], sum to 1.0000
[2019-03-26 22:56:44,457] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8063
[2019-03-26 22:56:44,463] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.6908605370632511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 965491.4784959515, 965491.4784959509, 218882.5216439698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4938600.0000, 
sim time next is 4939200.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.684493244645606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 956589.0518646694, 956589.0518646694, 217531.3911643132], 
processed observation next is [1.0, 0.17391304347826086, 0.4312796208530806, 0.89, 1.0, 1.0, 0.6198713790910916, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2657191810735193, 0.2657191810735193, 0.32467371815569135], 
reward next is 0.6753, 
noisyNet noise sample is [array([-1.0218856], dtype=float32), 1.3601657]. 
=============================================
[2019-03-26 22:56:45,347] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.13121545e-17 1.00000000e+00 2.25852402e-17 1.01691485e-11
 1.73203600e-22], sum to 1.0000
[2019-03-26 22:56:45,359] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7856
[2019-03-26 22:56:45,368] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1805307.184545545 W.
[2019-03-26 22:56:45,374] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.6456467086087625, 1.0, 2.0, 0.6456467086087625, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1805307.184545545, 1805307.184545545, 351720.5318473864], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4870800.0000, 
sim time next is 4871400.0000, 
raw observation next is [29.16666666666667, 73.33333333333334, 1.0, 2.0, 0.7633125216373295, 1.0, 2.0, 0.7633125216373295, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2134642.965245233, 2134642.965245233, 402400.9676931592], 
processed observation next is [1.0, 0.391304347826087, 0.581358609794629, 0.7333333333333334, 1.0, 1.0, 0.7148343634184693, 1.0, 1.0, 0.7148343634184693, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.592956379234787, 0.592956379234787, 0.6005984592435212], 
reward next is 0.3994, 
noisyNet noise sample is [array([0.71964896], dtype=float32), 1.937878]. 
=============================================
[2019-03-26 22:56:45,562] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6574446e-20 1.0000000e+00 2.6304059e-19 3.0006467e-14 1.0947283e-25], sum to 1.0000
[2019-03-26 22:56:45,574] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3169
[2019-03-26 22:56:45,580] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 78.16666666666667, 1.0, 2.0, 0.8172105210352213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1142163.079571807, 1142163.079571807, 248178.0196909949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5209800.0000, 
sim time next is 5210400.0000, 
raw observation next is [28.33333333333334, 77.33333333333334, 1.0, 2.0, 0.7609240291581376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1063455.642995191, 1063455.642995192, 234544.1589199607], 
processed observation next is [1.0, 0.30434782608695654, 0.5418641390205374, 0.7733333333333334, 1.0, 1.0, 0.7119566616363103, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.29540434527644194, 0.2954043452764422, 0.3500659088357622], 
reward next is 0.6499, 
noisyNet noise sample is [array([-0.00378344], dtype=float32), 0.7499237]. 
=============================================
[2019-03-26 22:56:53,032] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0224271e-21 1.0000000e+00 5.5533538e-21 2.6716914e-15 1.2952982e-27], sum to 1.0000
[2019-03-26 22:56:53,041] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6057
[2019-03-26 22:56:53,046] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 80.0, 1.0, 2.0, 0.5469442937905147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 764293.2720285837, 764293.2720285837, 191277.961218172], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5259600.0000, 
sim time next is 5260200.0000, 
raw observation next is [28.58333333333334, 80.16666666666667, 1.0, 2.0, 0.5460183157576335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 762998.8569082768, 762998.8569082768, 191120.2139459411], 
processed observation next is [1.0, 0.9130434782608695, 0.5537124802527649, 0.8016666666666667, 1.0, 1.0, 0.45303411537064275, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21194412691896578, 0.21194412691896578, 0.28525405066558374], 
reward next is 0.7147, 
noisyNet noise sample is [array([-0.5633856], dtype=float32), 0.60651135]. 
=============================================
[2019-03-26 22:56:53,775] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1164574e-12 2.2556485e-01 6.3419203e-10 7.7443516e-01 3.5258380e-15], sum to 1.0000
[2019-03-26 22:56:53,783] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9357
[2019-03-26 22:56:53,788] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.33333333333333, 69.0, 1.0, 2.0, 0.871608592261993, 1.0, 2.0, 0.871608592261993, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2437806.591897653, 2437806.591897653, 456240.6004622815], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4725600.0000, 
sim time next is 4726200.0000, 
raw observation next is [31.16666666666667, 69.5, 1.0, 2.0, 0.8572188899078252, 1.0, 2.0, 0.8572188899078252, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2397521.349493352, 2397521.349493352, 448690.6768983711], 
processed observation next is [1.0, 0.6956521739130435, 0.6761453396524489, 0.695, 1.0, 1.0, 0.8279745661540063, 1.0, 1.0, 0.8279745661540063, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6659781526370423, 0.6659781526370423, 0.6696875774602553], 
reward next is 0.3303, 
noisyNet noise sample is [array([0.6623365], dtype=float32), 0.5757934]. 
=============================================
[2019-03-26 22:56:54,943] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.0938400e-21 1.0000000e+00 1.8211593e-20 2.2213407e-15 1.5306022e-26], sum to 1.0000
[2019-03-26 22:56:54,951] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2176
[2019-03-26 22:56:54,956] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.9555799819787751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9373764001279, 1335674.782295708, 1335674.782295708, 285685.7156987255], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4932600.0000, 
sim time next is 4933200.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.8788845734593429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1228410.83591861, 1228410.83591861, 264192.907482719], 
processed observation next is [1.0, 0.08695652173913043, 0.4312796208530806, 0.89, 1.0, 1.0, 0.854077799348606, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.34122523219961387, 0.34122523219961387, 0.39431777236226717], 
reward next is 0.6057, 
noisyNet noise sample is [array([-0.5941784], dtype=float32), 0.77372456]. 
=============================================
[2019-03-26 22:56:55,907] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4706174e-09 1.1977585e-01 2.5727285e-08 8.8022411e-01 5.5074489e-13], sum to 1.0000
[2019-03-26 22:56:55,918] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4797
[2019-03-26 22:56:55,926] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.73333333333333, 58.5, 1.0, 2.0, 0.9367145534014678, 1.0, 2.0, 0.9367145534014678, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2620092.71308595, 2620092.71308595, 491925.7735965457], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5307000.0000, 
sim time next is 5307600.0000, 
raw observation next is [35.06666666666666, 57.00000000000001, 1.0, 2.0, 0.9456550524379305, 1.0, 2.0, 0.9456550524379305, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2645126.735766004, 2645126.735766003, 497019.3736627605], 
processed observation next is [1.0, 0.43478260869565216, 0.8609794628751973, 0.5700000000000001, 1.0, 1.0, 0.9345241595637717, 1.0, 1.0, 0.9345241595637717, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7347574266016678, 0.7347574266016674, 0.7418199606906872], 
reward next is 0.2582, 
noisyNet noise sample is [array([0.359614], dtype=float32), -0.4592834]. 
=============================================
[2019-03-26 22:56:56,208] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6653223e-20 1.0000000e+00 2.0616700e-19 1.1971864e-14 1.2126324e-25], sum to 1.0000
[2019-03-26 22:56:56,215] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7171
[2019-03-26 22:56:56,219] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666666, 82.33333333333334, 1.0, 2.0, 0.5907231758236592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 825493.1190123106, 825493.11901231, 199025.5331287441], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4776000.0000, 
sim time next is 4776600.0000, 
raw observation next is [27.83333333333334, 83.16666666666666, 1.0, 2.0, 0.611175533119672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 854085.3074668181, 854085.3074668181, 202840.9835129082], 
processed observation next is [1.0, 0.2608695652173913, 0.5181674565560824, 0.8316666666666666, 1.0, 1.0, 0.531536786891171, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23724591874078282, 0.23724591874078282, 0.3027477365864301], 
reward next is 0.6973, 
noisyNet noise sample is [array([0.52138156], dtype=float32), -1.5087854]. 
=============================================
[2019-03-26 22:57:07,495] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2248147e-22 1.0000000e+00 2.0588935e-21 1.3218015e-15 4.1924202e-28], sum to 1.0000
[2019-03-26 22:57:07,501] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8202
[2019-03-26 22:57:07,506] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5091015903215216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 711394.6329976249, 711394.6329976243, 185034.4587508654], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5005800.0000, 
sim time next is 5006400.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5104633257084197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 713298.0968898302, 713298.0968898295, 185251.679123224], 
processed observation next is [1.0, 0.9565217391304348, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4101967779619514, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19813836024717504, 0.19813836024717485, 0.2764950434674985], 
reward next is 0.7235, 
noisyNet noise sample is [array([0.42300367], dtype=float32), -0.38844028]. 
=============================================
[2019-03-26 22:57:19,480] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 22:57:19,482] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 22:57:19,482] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:57:19,483] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 22:57:19,484] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 22:57:19,484] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:57:19,485] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:57:19,486] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 22:57:19,488] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 22:57:19,489] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:57:19,490] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 22:57:19,514] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run83
[2019-03-26 22:57:19,540] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run83
[2019-03-26 22:57:19,540] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run83
[2019-03-26 22:57:19,589] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run83
[2019-03-26 22:57:19,612] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run83
[2019-03-26 22:58:10,794] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09313957], dtype=float32), 0.07139633]
[2019-03-26 22:58:10,795] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.573159165, 88.25413365666665, 1.0, 2.0, 0.9062378436252045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1266665.116456664, 1266665.116456665, 271665.997770595]
[2019-03-26 22:58:10,797] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 22:58:10,800] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.7012988e-22 1.0000000e+00 8.1835915e-22 9.4430972e-17 3.2382302e-28], sampled 0.90760187567571
[2019-03-26 22:58:15,280] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09313957], dtype=float32), 0.07139633]
[2019-03-26 22:58:15,282] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.93333333333334, 59.83333333333334, 1.0, 2.0, 0.8833363950197294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1234636.733633381, 1234636.733633381, 265399.7180488225]
[2019-03-26 22:58:15,285] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:58:15,290] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.6343897e-21 1.0000000e+00 1.8253334e-19 7.6871964e-12 7.6841469e-27], sampled 0.19709717939989335
[2019-03-26 22:58:30,004] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09313957], dtype=float32), 0.07139633]
[2019-03-26 22:58:30,004] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.03333333333333, 70.33333333333334, 1.0, 2.0, 0.890653611886141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1244869.982262277, 1244869.982262277, 267387.4370143853]
[2019-03-26 22:58:30,005] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 22:58:30,008] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.8423445e-21 1.0000000e+00 1.3883279e-19 9.7706808e-12 4.7031417e-27], sampled 0.8023429875209191
[2019-03-26 22:59:13,980] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.7719 3007052355.0780 1750.0000
[2019-03-26 22:59:14,000] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.8400 2779288391.5019 933.0000
[2019-03-26 22:59:14,084] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.8717 2927447046.3306 1338.0000
[2019-03-26 22:59:14,138] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.5781 2842561580.6193 1124.0000
[2019-03-26 22:59:14,252] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7892.5285 3163800685.3968 1747.0000
[2019-03-26 22:59:15,273] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2050000, evaluation results [2050000.0, 7892.52850520845, 3163800685.3968124, 1747.0, 8254.871735174753, 2927447046.3306217, 1338.0, 8659.840039320936, 2779288391.501933, 933.0, 7999.771872764908, 3007052355.077976, 1750.0, 8495.578089850558, 2842561580.619348, 1124.0]
[2019-03-26 22:59:15,588] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.96089332e-24 1.00000000e+00 1.61259388e-23 1.07543604e-17
 1.79854758e-29], sum to 1.0000
[2019-03-26 22:59:15,597] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8935
[2019-03-26 22:59:15,610] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.00000000000001, 1.0, 2.0, 0.5234912123965862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731508.9379428031, 731508.9379428037, 187358.1546805001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5173800.0000, 
sim time next is 5174400.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5225737880560548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 730226.5195145251, 730226.5195145257, 187208.2098061929], 
processed observation next is [0.0, 0.9130434782608695, 0.5260663507109005, 0.79, 1.0, 1.0, 0.42478769645307807, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20284069986514586, 0.20284069986514602, 0.2794152385167058], 
reward next is 0.7206, 
noisyNet noise sample is [array([0.30255985], dtype=float32), 0.3924021]. 
=============================================
[2019-03-26 22:59:20,138] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.0242892e-22 1.0000000e+00 5.1745972e-21 6.8426773e-16 6.1863354e-28], sum to 1.0000
[2019-03-26 22:59:20,146] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2221
[2019-03-26 22:59:20,151] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.4, 84.0, 1.0, 2.0, 0.5624552446884938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 785976.1044698902, 785976.1044698908, 193959.6767787438], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5522400.0000, 
sim time next is 5523000.0000, 
raw observation next is [28.26666666666667, 84.5, 1.0, 2.0, 0.5625131380973192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 786057.034772072, 786057.034772072, 193969.6634648023], 
processed observation next is [1.0, 0.9565217391304348, 0.53870458135861, 0.845, 1.0, 1.0, 0.4729073952979749, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21834917632557554, 0.21834917632557554, 0.2895069603952273], 
reward next is 0.7105, 
noisyNet noise sample is [array([-1.3800908], dtype=float32), -0.5640469]. 
=============================================
[2019-03-26 22:59:20,168] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[71.54596 ]
 [71.61719 ]
 [71.65488 ]
 [71.58399 ]
 [71.689865]], R is [[71.40271759]
 [71.39920044]
 [71.39543915]
 [71.39134216]
 [71.38665009]].
[2019-03-26 22:59:30,917] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.5953199e-24 1.0000000e+00 1.2473306e-20 4.9371301e-12 2.7816946e-29], sum to 1.0000
[2019-03-26 22:59:30,926] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1003
[2019-03-26 22:59:30,931] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.8, 80.33333333333334, 1.0, 2.0, 0.6167525996765194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861882.12361638, 861882.12361638, 203909.3314807037], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5426400.0000, 
sim time next is 5427000.0000, 
raw observation next is [30.8, 81.0, 1.0, 2.0, 0.6219566251502986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 869157.4747960069, 869157.4747960076, 204908.6164966634], 
processed observation next is [1.0, 0.8260869565217391, 0.6587677725118484, 0.81, 1.0, 1.0, 0.5445260543979501, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2414326318877797, 0.24143263188777989, 0.30583375596516926], 
reward next is 0.6942, 
noisyNet noise sample is [array([-0.0170941], dtype=float32), 2.5211143]. 
=============================================
[2019-03-26 22:59:30,948] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[78.8262  ]
 [78.606064]
 [78.53433 ]
 [77.54086 ]
 [76.212234]], R is [[78.42789459]
 [78.33927155]
 [78.25299072]
 [78.16939545]
 [78.08869171]].
[2019-03-26 22:59:38,858] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4870713e-23 1.0000000e+00 3.8626331e-22 8.0554421e-18 1.8197769e-28], sum to 1.0000
[2019-03-26 22:59:38,868] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4546
[2019-03-26 22:59:38,875] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.75, 65.33333333333334, 1.0, 2.0, 0.5579412373779853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 779665.906399961, 779665.9063999616, 193172.5295775913], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5658600.0000, 
sim time next is 5659200.0000, 
raw observation next is [31.8, 65.0, 1.0, 2.0, 0.5583092521566168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780180.358338228, 780180.358338228, 193236.4637166237], 
processed observation next is [0.0, 0.5217391304347826, 0.7061611374407584, 0.65, 1.0, 1.0, 0.4678424724778515, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21671676620506333, 0.21671676620506333, 0.2884126324128712], 
reward next is 0.7116, 
noisyNet noise sample is [array([1.3966173], dtype=float32), -0.7367007]. 
=============================================
[2019-03-26 22:59:42,848] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8639574e-22 1.0000000e+00 2.3423943e-22 9.2019906e-18 8.4095532e-29], sum to 1.0000
[2019-03-26 22:59:42,859] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2855
[2019-03-26 22:59:42,868] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.61666666666667, 81.0, 1.0, 2.0, 0.5182035140574606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 724117.5684371626, 724117.5684371626, 186497.1799061705], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5727000.0000, 
sim time next is 5727600.0000, 
raw observation next is [27.8, 80.0, 1.0, 2.0, 0.5186626171841852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 724759.320264166, 724759.3202641654, 186571.6622047571], 
processed observation next is [0.0, 0.30434782608695654, 0.5165876777251186, 0.8, 1.0, 1.0, 0.4200754423905845, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20132203340671279, 0.20132203340671262, 0.2784651674697867], 
reward next is 0.7215, 
noisyNet noise sample is [array([-0.84308773], dtype=float32), -0.11286988]. 
=============================================
[2019-03-26 22:59:44,370] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.3956775e-24 1.0000000e+00 6.3229177e-23 4.3630762e-18 5.4830660e-29], sum to 1.0000
[2019-03-26 22:59:44,379] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6201
[2019-03-26 22:59:44,385] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.76666666666667, 83.66666666666667, 1.0, 2.0, 0.5383356371834498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 752259.380780187, 752259.3807801863, 189820.2847899604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5689200.0000, 
sim time next is 5689800.0000, 
raw observation next is [27.7, 84.0, 1.0, 2.0, 0.5376063055533814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 751239.8670519596, 751239.8670519596, 189697.8121916432], 
processed observation next is [0.0, 0.8695652173913043, 0.5118483412322274, 0.84, 1.0, 1.0, 0.442899163317327, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20867774084776655, 0.20867774084776655, 0.28313106297260177], 
reward next is 0.7169, 
noisyNet noise sample is [array([0.6518006], dtype=float32), 0.9752006]. 
=============================================
[2019-03-26 22:59:47,052] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.2088858e-23 1.0000000e+00 1.2818577e-22 2.5302376e-17 2.2350692e-29], sum to 1.0000
[2019-03-26 22:59:47,062] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8531
[2019-03-26 22:59:47,068] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 85.0, 1.0, 2.0, 0.5277452520860603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 737455.4527830102, 737455.4527830096, 188057.2809282167], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6305400.0000, 
sim time next is 6306000.0000, 
raw observation next is [27.3, 85.0, 1.0, 2.0, 0.5275248531119994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 737147.3669765511, 737147.3669765511, 188020.9582585785], 
processed observation next is [0.0, 1.0, 0.4928909952606636, 0.85, 1.0, 1.0, 0.430752835074698, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20476315749348642, 0.20476315749348642, 0.2806282959083261], 
reward next is 0.7194, 
noisyNet noise sample is [array([0.8771776], dtype=float32), -0.19651046]. 
=============================================
[2019-03-26 22:59:47,086] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[76.49236 ]
 [76.47242 ]
 [76.44645 ]
 [76.409645]
 [76.37231 ]], R is [[76.47005463]
 [76.42466736]
 [76.37963104]
 [76.33483887]
 [76.29019928]].
[2019-03-26 22:59:49,793] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.5779804e-23 1.0000000e+00 2.2538094e-23 8.1579520e-19 7.0300909e-29], sum to 1.0000
[2019-03-26 22:59:49,809] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0671
[2019-03-26 22:59:49,815] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.7, 64.0, 1.0, 2.0, 0.5193628575900634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 725738.1437058876, 725738.1437058869, 186685.5544897759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5738400.0000, 
sim time next is 5739000.0000, 
raw observation next is [30.85, 63.33333333333334, 1.0, 2.0, 0.520535416863393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 727377.194963408, 727377.1949634086, 186876.1747561599], 
processed observation next is [0.0, 0.43478260869565216, 0.661137440758294, 0.6333333333333334, 1.0, 1.0, 0.4223318275462566, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2020492208231689, 0.20204922082316906, 0.27891966381516403], 
reward next is 0.7211, 
noisyNet noise sample is [array([-0.37086502], dtype=float32), -0.9056729]. 
=============================================
[2019-03-26 22:59:49,827] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[73.0967  ]
 [73.07013 ]
 [73.066536]
 [73.05293 ]
 [73.0423  ]], R is [[73.11131287]
 [73.10157013]
 [73.09201813]
 [73.08262634]
 [73.07329559]].
[2019-03-26 22:59:53,618] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.8750027e-21 1.0000000e+00 1.6941958e-19 7.5462152e-14 4.0804302e-26], sum to 1.0000
[2019-03-26 22:59:53,628] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9134
[2019-03-26 22:59:53,632] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.9, 94.0, 1.0, 2.0, 0.8235487305750202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1151026.392597042, 1151026.392597041, 249772.1937324391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5806800.0000, 
sim time next is 5807400.0000, 
raw observation next is [26.08333333333333, 93.00000000000001, 1.0, 2.0, 0.7646290267128402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1068636.295664344, 1068636.295664344, 235412.9370440474], 
processed observation next is [1.0, 0.21739130434782608, 0.43522906793048954, 0.9300000000000002, 1.0, 1.0, 0.7164205141118556, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2968434154623178, 0.2968434154623178, 0.3513625926030558], 
reward next is 0.6486, 
noisyNet noise sample is [array([-0.8454448], dtype=float32), 2.0435398]. 
=============================================
[2019-03-26 22:59:55,856] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.4586448e-23 1.0000000e+00 2.3814610e-22 1.0367766e-17 6.8371789e-29], sum to 1.0000
[2019-03-26 22:59:55,866] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8055
[2019-03-26 22:59:55,871] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.43333333333333, 82.0, 1.0, 2.0, 0.5214930887779144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 728715.8697678195, 728715.8697678202, 187031.657905314], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6385200.0000, 
sim time next is 6385800.0000, 
raw observation next is [27.41666666666666, 82.0, 1.0, 2.0, 0.5203567118000646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 727127.3935614872, 727127.3935614872, 186846.5989268792], 
processed observation next is [0.0, 0.9130434782608695, 0.4984202211690361, 0.82, 1.0, 1.0, 0.4221165202410417, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20197983154485755, 0.20197983154485755, 0.2788755207863869], 
reward next is 0.7211, 
noisyNet noise sample is [array([-1.0834416], dtype=float32), 0.11825092]. 
=============================================
[2019-03-26 22:59:57,102] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.9807769e-19 1.0000000e+00 6.2991934e-19 1.2629509e-13 7.9002408e-25], sum to 1.0000
[2019-03-26 22:59:57,112] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4933
[2019-03-26 22:59:57,117] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.76666666666667, 85.66666666666666, 1.0, 2.0, 0.8356262942694533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1167915.787792461, 1167915.787792461, 252841.8606759098], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6406800.0000, 
sim time next is 6407400.0000, 
raw observation next is [26.73333333333333, 85.83333333333334, 1.0, 2.0, 0.820116806739823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1146227.202344312, 1146227.202344312, 248906.8426001412], 
processed observation next is [1.0, 0.13043478260869565, 0.4660347551342811, 0.8583333333333334, 1.0, 1.0, 0.7832732611323169, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31839644509564224, 0.31839644509564224, 0.37150275014946443], 
reward next is 0.6285, 
noisyNet noise sample is [array([-0.42070904], dtype=float32), 0.47701156]. 
=============================================
[2019-03-26 22:59:58,798] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.47371031e-22 1.00000000e+00 1.26371377e-22 1.38493866e-17
 7.15912758e-29], sum to 1.0000
[2019-03-26 22:59:58,808] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9698
[2019-03-26 22:59:58,815] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 85.0, 1.0, 2.0, 0.5414856253530441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 756662.6786049658, 756662.6786049658, 190351.7511277204], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6249600.0000, 
sim time next is 6250200.0000, 
raw observation next is [28.05, 84.00000000000001, 1.0, 2.0, 0.5419119864910849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 757258.6806813597, 757258.680681359, 190423.7908543491], 
processed observation next is [0.0, 0.34782608695652173, 0.528436018957346, 0.8400000000000002, 1.0, 1.0, 0.4480867307121504, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21034963352259992, 0.21034963352259972, 0.2842146132154464], 
reward next is 0.7158, 
noisyNet noise sample is [array([-0.88617116], dtype=float32), -0.7309177]. 
=============================================
[2019-03-26 22:59:58,983] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.0606506e-21 1.0000000e+00 3.1369733e-20 1.5224755e-15 5.9950216e-27], sum to 1.0000
[2019-03-26 22:59:58,996] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8303
[2019-03-26 22:59:59,001] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 91.0, 1.0, 2.0, 0.680065376765337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 950398.2746481972, 950398.2746481972, 216601.6165847068], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5896800.0000, 
sim time next is 5897400.0000, 
raw observation next is [27.0, 90.16666666666667, 1.0, 2.0, 0.6862671686628288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 959069.2553212187, 959069.2553212187, 217909.5682786445], 
processed observation next is [1.0, 0.2608695652173913, 0.4786729857819906, 0.9016666666666667, 1.0, 1.0, 0.6220086369431672, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2664081264781163, 0.2664081264781163, 0.32523816160991714], 
reward next is 0.6748, 
noisyNet noise sample is [array([-0.18844861], dtype=float32), -1.2172967]. 
=============================================
[2019-03-26 23:00:00,018] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3111272e-14 9.3431377e-01 3.2308014e-11 6.5686263e-02 8.6549072e-17], sum to 1.0000
[2019-03-26 23:00:00,025] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3119
[2019-03-26 23:00:00,033] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2139336.113936502 W.
[2019-03-26 23:00:00,037] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 67.0, 1.0, 2.0, 0.88878313642487, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.978741166355853, 6.9112, 168.9125543139502, 2139336.113936502, 2091420.200028358, 431921.6850374965], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6453600.0000, 
sim time next is 6454200.0000, 
raw observation next is [30.0, 67.0, 1.0, 2.0, 0.89005347561586, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.977170301797464, 6.9112, 168.9125088618964, 2141114.212904623, 2094312.734319282, 432317.6433830695], 
processed observation next is [1.0, 0.6956521739130435, 0.6208530805687204, 0.67, 1.0, 1.0, 0.8675343079709157, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.006597030179746355, 0.0, 0.8294377469930635, 0.5947539480290619, 0.5817535373109116, 0.6452502140045814], 
reward next is 0.0249, 
noisyNet noise sample is [array([0.23567638], dtype=float32), -0.57679564]. 
=============================================
[2019-03-26 23:00:00,807] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.0445186e-21 1.0000000e+00 3.2555092e-20 1.9059417e-14 2.1752168e-26], sum to 1.0000
[2019-03-26 23:00:00,816] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2291
[2019-03-26 23:00:00,820] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.73333333333333, 91.0, 1.0, 2.0, 0.5365059083643766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 749701.652275915, 749701.6522759144, 189513.5127661979], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5964600.0000, 
sim time next is 5965200.0000, 
raw observation next is [26.7, 91.0, 1.0, 2.0, 0.535181319027493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 747850.04845555, 747850.0484555494, 189291.90504616], 
processed observation next is [1.0, 0.043478260869565216, 0.46445497630331756, 0.91, 1.0, 1.0, 0.4399774928042084, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2077361245709861, 0.20773612457098595, 0.2825252314121791], 
reward next is 0.7175, 
noisyNet noise sample is [array([0.19883242], dtype=float32), 0.3439616]. 
=============================================
[2019-03-26 23:00:03,720] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.3811800e-22 1.0000000e+00 1.1656637e-21 1.7937367e-15 5.9029979e-28], sum to 1.0000
[2019-03-26 23:00:03,730] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9705
[2019-03-26 23:00:03,739] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333334, 85.83333333333334, 1.0, 2.0, 0.512221510739695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 715755.7319229649, 715755.7319229649, 185533.1848453896], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6641400.0000, 
sim time next is 6642000.0000, 
raw observation next is [26.8, 86.0, 1.0, 2.0, 0.5111532683365179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 714262.5152825058, 714262.5152825058, 185362.1584143999], 
processed observation next is [1.0, 0.9130434782608695, 0.4691943127962086, 0.86, 1.0, 1.0, 0.4110280341403829, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1984062542451405, 0.1984062542451405, 0.27665993793194016], 
reward next is 0.7233, 
noisyNet noise sample is [array([0.61561656], dtype=float32), -2.0803068]. 
=============================================
[2019-03-26 23:00:03,750] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[70.881294]
 [71.60493 ]
 [72.481064]
 [73.05777 ]
 [73.99116 ]], R is [[70.28665161]
 [70.30686951]
 [70.32662964]
 [70.34607697]
 [70.36527252]].
[2019-03-26 23:00:03,926] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.6064594e-10 7.4446535e-01 1.0120507e-08 2.5553465e-01 1.5016995e-12], sum to 1.0000
[2019-03-26 23:00:03,933] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3404
[2019-03-26 23:00:03,943] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1966143.193523376 W.
[2019-03-26 23:00:03,950] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.88333333333333, 58.5, 1.0, 2.0, 0.7031150710280691, 1.0, 1.0, 0.7031150710280691, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1966143.193523376, 1966143.193523376, 375450.6864493383], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6519000.0000, 
sim time next is 6519600.0000, 
raw observation next is [31.1, 57.0, 1.0, 2.0, 0.7817064397601432, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.965412540952734, 6.9112, 168.9126334088425, 1989471.182702432, 1951011.013866766, 404681.1287018307], 
processed observation next is [1.0, 0.4782608695652174, 0.6729857819905214, 0.57, 1.0, 1.0, 0.7369957105543894, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.005421254095273387, 0.0, 0.8294383585755867, 0.5526308840840088, 0.5419475038518794, 0.604001684629598], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.01637204], dtype=float32), -0.28961343]. 
=============================================
[2019-03-26 23:00:08,969] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.9044558e-15 1.0000000e+00 1.1772911e-14 2.7142194e-08 4.9916902e-19], sum to 1.0000
[2019-03-26 23:00:08,978] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1692
[2019-03-26 23:00:08,988] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2019296.627679042 W.
[2019-03-26 23:00:08,993] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.5, 77.0, 1.0, 2.0, 0.8030175671489339, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.981034141169562, 6.9112, 168.9124840858767, 2019296.627679042, 1969754.022991433, 409477.0771218234], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6426000.0000, 
sim time next is 6426600.0000, 
raw observation next is [28.61666666666667, 76.33333333333334, 1.0, 2.0, 0.6745863972262889, 1.0, 1.0, 0.6745863972262889, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1886297.322319656, 1886297.322319656, 363431.5042611713], 
processed observation next is [1.0, 0.391304347826087, 0.5552922590837285, 0.7633333333333334, 1.0, 1.0, 0.6079354183449264, 1.0, 0.5, 0.6079354183449264, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5239714784221267, 0.5239714784221267, 0.5424350809868229], 
reward next is 0.4576, 
noisyNet noise sample is [array([-2.2108028], dtype=float32), -0.08744722]. 
=============================================
[2019-03-26 23:00:11,519] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 23:00:11,521] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 23:00:11,523] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:00:11,525] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 23:00:11,525] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:00:11,528] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 23:00:11,530] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 23:00:11,530] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:00:11,531] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 23:00:11,530] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:00:11,535] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:00:11,562] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run84
[2019-03-26 23:00:11,589] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run84
[2019-03-26 23:00:11,614] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run84
[2019-03-26 23:00:11,615] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run84
[2019-03-26 23:00:11,636] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run84
[2019-03-26 23:00:12,857] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09240077], dtype=float32), 0.071077526]
[2019-03-26 23:00:12,858] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.4, 66.33333333333334, 1.0, 2.0, 0.9701979298382953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1477756.259014511, 1477756.259014512, 307748.2391642974]
[2019-03-26 23:00:12,859] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:00:12,862] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.1258308e-22 1.0000000e+00 1.7397713e-21 9.0099788e-17 1.2052846e-27], sampled 0.8579954336032397
[2019-03-26 23:00:22,386] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09240077], dtype=float32), 0.071077526]
[2019-03-26 23:00:22,387] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.13333333333334, 60.66666666666667, 1.0, 2.0, 0.2829318529962946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 460808.7701700378, 460808.7701700371, 164262.7029841211]
[2019-03-26 23:00:22,388] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:00:22,392] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.82250156e-23 1.00000000e+00 2.32541629e-22 1.09922295e-17
 1.35929981e-28], sampled 0.6583153838845867
[2019-03-26 23:00:22,667] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09240077], dtype=float32), 0.071077526]
[2019-03-26 23:00:22,668] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.8, 68.66666666666667, 1.0, 2.0, 0.2761213672518254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 450238.0473922736, 450238.0473922736, 163543.9327681458]
[2019-03-26 23:00:22,669] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:00:22,672] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.4921138e-22 1.0000000e+00 1.6956294e-21 3.2849926e-17 1.8561369e-27], sampled 0.961538560293396
[2019-03-26 23:00:36,062] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09240077], dtype=float32), 0.071077526]
[2019-03-26 23:00:36,065] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.18333333333333, 95.0, 1.0, 2.0, 0.4111974519779803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 606916.7836883408, 606916.7836883408, 174989.8254714457]
[2019-03-26 23:00:36,066] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:00:36,068] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.6568015e-23 1.0000000e+00 1.1713955e-22 1.5130829e-17 4.2536333e-29], sampled 0.02760671035138318
[2019-03-26 23:01:05,637] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09240077], dtype=float32), 0.071077526]
[2019-03-26 23:01:05,639] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [34.29153433666666, 63.81399743, 1.0, 2.0, 0.5871402291959522, 0.0, 2.0, 0.0, 1.0, 1.0, 1.019668407872479, 6.911200000000001, 6.9112, 168.912382931449, 1641602.85039641, 1641602.850396409, 359521.57661409]
[2019-03-26 23:01:05,641] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:01:05,642] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.5574711e-20 1.0000000e+00 5.7603669e-19 6.0769185e-13 1.0904526e-24], sampled 0.5990579476110547
[2019-03-26 23:01:11,280] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09240077], dtype=float32), 0.071077526]
[2019-03-26 23:01:11,281] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.83333333333334, 84.83333333333333, 1.0, 2.0, 0.5409090857254036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 755856.7454234919, 755856.7454234919, 190254.1651268423]
[2019-03-26 23:01:11,282] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:01:11,286] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1016165e-23 1.0000000e+00 4.8094518e-23 1.4865253e-17 1.7176138e-29], sampled 0.9170596483896715
[2019-03-26 23:01:24,807] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09240077], dtype=float32), 0.071077526]
[2019-03-26 23:01:24,808] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.5, 71.66666666666667, 1.0, 2.0, 0.5597451821351535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 782187.6631544157, 782187.6631544157, 193486.3385504835]
[2019-03-26 23:01:24,810] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:01:24,814] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.7910355e-23 1.0000000e+00 8.7951611e-23 3.8871804e-17 3.7226170e-29], sampled 0.28211170048538947
[2019-03-26 23:01:30,114] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09240077], dtype=float32), 0.071077526]
[2019-03-26 23:01:30,114] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [34.7541939, 54.98454849, 1.0, 2.0, 0.7671801514555141, 1.0, 2.0, 0.7671801514555141, 0.0, 2.0, 0.0, 6.9112, 6.9112, 171.5212843490159, 2145457.748536806, 2145457.748536806, 404412.8346289871]
[2019-03-26 23:01:30,115] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:01:30,118] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.3393221e-13 8.3967394e-01 8.3526901e-11 1.6032611e-01 4.1323873e-16], sampled 0.8099969275953741
[2019-03-26 23:01:30,120] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2145457.748536806 W.
[2019-03-26 23:01:54,310] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09240077], dtype=float32), 0.071077526]
[2019-03-26 23:01:54,312] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.25704932333334, 57.17608854333334, 1.0, 2.0, 0.9753850882715498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1390440.957771161, 1390440.957771162, 295687.9206968861]
[2019-03-26 23:01:54,313] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:01:54,317] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.1231774e-21 1.0000000e+00 1.4838093e-20 1.8383414e-15 1.5882204e-26], sampled 0.24884639421282495
[2019-03-26 23:02:05,822] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7897.0719 3163838309.7659 1747.0000
[2019-03-26 23:02:05,991] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.0841 2927540062.4576 1338.0000
[2019-03-26 23:02:06,237] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.0203 3007402931.2879 1754.0000
[2019-03-26 23:02:06,387] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.0731 2779388092.0577 933.0000
[2019-03-26 23:02:06,415] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8502.0337 2842068963.8196 1121.0000
[2019-03-26 23:02:07,434] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2075000, evaluation results [2075000.0, 7897.071915724755, 3163838309.765928, 1747.0, 8252.084055434527, 2927540062.457613, 1338.0, 8659.073089626292, 2779388092.057713, 933.0, 7996.020319766318, 3007402931.2879243, 1754.0, 8502.033718786051, 2842068963.819641, 1121.0]
[2019-03-26 23:02:09,824] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.0173994e-18 1.0000000e+00 7.3104022e-18 1.9324605e-12 4.7877783e-23], sum to 1.0000
[2019-03-26 23:02:09,833] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3917
[2019-03-26 23:02:09,837] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.63333333333333, 92.0, 1.0, 2.0, 0.8349459309149414, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.9129565103562, 1166964.353206575, 1166964.353206574, 252669.7329372721], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6144000.0000, 
sim time next is 6144600.0000, 
raw observation next is [26.61666666666667, 92.0, 1.0, 2.0, 0.7940471286807047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1109772.164176467, 1109772.164176467, 242455.0253950379], 
processed observation next is [1.0, 0.08695652173913043, 0.4605055292259086, 0.92, 1.0, 1.0, 0.7518640104586803, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3082700456045742, 0.3082700456045742, 0.36187317223139986], 
reward next is 0.6381, 
noisyNet noise sample is [array([0.2818756], dtype=float32), 0.013151765]. 
=============================================
[2019-03-26 23:02:15,556] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.3433568e-20 1.0000000e+00 7.5780691e-20 1.8100003e-14 1.8637937e-26], sum to 1.0000
[2019-03-26 23:02:15,567] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2352
[2019-03-26 23:02:15,574] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 53.00000000000001, 1.0, 2.0, 0.8744480487809202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1357212.590414606, 1357212.590414607, 281258.3527823843], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6780000.0000, 
sim time next is 6780600.0000, 
raw observation next is [28.25, 52.5, 1.0, 2.0, 0.8659127067145393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1344645.596476443, 1344645.596476443, 278803.5744350529], 
processed observation next is [1.0, 0.4782608695652174, 0.537914691943128, 0.525, 1.0, 1.0, 0.8384490442343847, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.37351266568790087, 0.37351266568790087, 0.41612473796276556], 
reward next is 0.5839, 
noisyNet noise sample is [array([-0.2655099], dtype=float32), -0.9812845]. 
=============================================
[2019-03-26 23:02:24,757] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7478617e-21 1.0000000e+00 1.5489505e-20 1.4138350e-15 4.0128480e-27], sum to 1.0000
[2019-03-26 23:02:24,764] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2984
[2019-03-26 23:02:24,771] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.06666666666667, 94.16666666666667, 1.0, 2.0, 0.8839607967448336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 169.0120118691975, 1235509.544592586, 1235509.544592586, 265578.6771098351], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6660600.0000, 
sim time next is 6661200.0000, 
raw observation next is [25.03333333333334, 94.33333333333334, 1.0, 2.0, 0.7472043357951452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1044271.784005457, 1044271.784005457, 231361.2113274533], 
processed observation next is [1.0, 0.08695652173913043, 0.3854660347551346, 0.9433333333333335, 1.0, 1.0, 0.6954269105965605, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.29007549555707135, 0.29007549555707135, 0.34531524078724374], 
reward next is 0.6547, 
noisyNet noise sample is [array([1.9201646], dtype=float32), 1.403588]. 
=============================================
[2019-03-26 23:02:27,826] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7858660e-21 1.0000000e+00 3.1652799e-21 1.8752075e-15 5.9090583e-28], sum to 1.0000
[2019-03-26 23:02:27,834] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7483
[2019-03-26 23:02:27,839] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.15, 87.16666666666667, 1.0, 2.0, 0.5316882047698023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 742967.1439800152, 742967.1439800158, 188709.9675605736], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6477000.0000, 
sim time next is 6477600.0000, 
raw observation next is [27.1, 87.33333333333334, 1.0, 2.0, 0.5325411868914179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 744159.4963270944, 744159.4963270938, 188851.6051236656], 
processed observation next is [1.0, 1.0, 0.4834123222748816, 0.8733333333333334, 1.0, 1.0, 0.4367966107125517, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20671097120197066, 0.2067109712019705, 0.28186806734875464], 
reward next is 0.7181, 
noisyNet noise sample is [array([0.14123698], dtype=float32), 1.7265025]. 
=============================================
[2019-03-26 23:02:29,388] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.7476975e-12 9.8169494e-01 1.9671929e-10 1.8305020e-02 6.3149644e-15], sum to 1.0000
[2019-03-26 23:02:29,399] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1340
[2019-03-26 23:02:29,409] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1685407.574196952 W.
[2019-03-26 23:02:29,414] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.23333333333333, 83.83333333333333, 1.0, 2.0, 0.4018664869140811, 1.0, 2.0, 0.4018664869140811, 1.0, 2.0, 0.6779674694584129, 6.9112, 6.9112, 170.5573041426782, 1685407.574196952, 1685407.574196952, 351056.3396479347], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7141800.0000, 
sim time next is 7142400.0000, 
raw observation next is [26.2, 84.0, 1.0, 2.0, 0.5905653667299701, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9894027933067254, 6.9112, 6.9112, 168.9129565104306, 1651186.739528235, 1651186.739528235, 353558.1816902609], 
processed observation next is [1.0, 0.6956521739130435, 0.44075829383886256, 0.84, 1.0, 1.0, 0.5067052611204458, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.9870765772033235, 0.0, 0.0, 0.8294399451523007, 0.4586629832022875, 0.4586629832022875, 0.5276987786421804], 
reward next is 0.4723, 
noisyNet noise sample is [array([-1.5293914], dtype=float32), 0.19687004]. 
=============================================
[2019-03-26 23:02:30,166] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1914195e-20 1.0000000e+00 2.6924233e-20 8.8538372e-15 1.9895838e-26], sum to 1.0000
[2019-03-26 23:02:30,177] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8458
[2019-03-26 23:02:30,186] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1972922.596414717 W.
[2019-03-26 23:02:30,193] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.2, 66.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.583509986230577, 6.9112, 168.9093944959482, 1972922.596414717, 1495972.811126016, 318015.7565842233], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7029000.0000, 
sim time next is 7029600.0000, 
raw observation next is [28.36666666666667, 65.0, 1.0, 2.0, 0.4206842251921287, 1.0, 1.0, 0.4206842251921287, 1.0, 1.0, 0.7012267581722841, 6.9112, 6.9112, 170.5573041426782, 1764393.182084553, 1764393.182084553, 360116.7021988141], 
processed observation next is [1.0, 0.34782608695652173, 0.543443917851501, 0.65, 1.0, 1.0, 0.30202918697846837, 1.0, 0.5, 0.30202918697846837, 1.0, 0.5, 0.6356423880149805, 0.0, 0.0, 0.8375144448122397, 0.49010921724570916, 0.49010921724570916, 0.5374876152221105], 
reward next is 0.4625, 
noisyNet noise sample is [array([0.17318995], dtype=float32), 1.1215496]. 
=============================================
[2019-03-26 23:02:36,694] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.3390460e-21 1.0000000e+00 9.6212899e-20 6.0135341e-14 2.7103973e-26], sum to 1.0000
[2019-03-26 23:02:36,702] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0911
[2019-03-26 23:02:36,706] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666666, 90.16666666666667, 1.0, 2.0, 0.8706117203170282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1216841.300810235, 1216841.300810236, 261979.8620683027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6574200.0000, 
sim time next is 6574800.0000, 
raw observation next is [26.13333333333333, 90.33333333333334, 1.0, 2.0, 0.7782420724322349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1087671.467681904, 1087671.467681904, 238638.4579322894], 
processed observation next is [1.0, 0.08695652173913043, 0.43759873617693507, 0.9033333333333334, 1.0, 1.0, 0.7328217740147408, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.30213096324497335, 0.30213096324497335, 0.35617680288401404], 
reward next is 0.6438, 
noisyNet noise sample is [array([1.0121819], dtype=float32), 0.42858714]. 
=============================================
[2019-03-26 23:02:36,938] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6333361e-20 1.0000000e+00 6.6606095e-20 1.6040356e-15 1.0305340e-26], sum to 1.0000
[2019-03-26 23:02:36,948] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3866
[2019-03-26 23:02:36,955] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.73333333333333, 88.83333333333334, 1.0, 2.0, 0.3181189687245081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 501836.8215141516, 501836.8215141523, 167138.3804371663], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7267800.0000, 
sim time next is 7268400.0000, 
raw observation next is [21.7, 89.0, 1.0, 2.0, 0.3170432704438753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 500285.8751849242, 500285.8751849248, 167024.9869583819], 
processed observation next is [1.0, 0.13043478260869565, 0.2274881516587678, 0.89, 1.0, 1.0, 0.17716056679984976, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13896829866247895, 0.13896829866247912, 0.24929102531101777], 
reward next is 0.7507, 
noisyNet noise sample is [array([-0.4081032], dtype=float32), -1.1375271]. 
=============================================
[2019-03-26 23:02:37,980] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9673170e-14 9.9999976e-01 1.9090129e-13 1.7965324e-07 2.3099217e-18], sum to 1.0000
[2019-03-26 23:02:37,990] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2173
[2019-03-26 23:02:37,998] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2012089.065493528 W.
[2019-03-26 23:02:38,005] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.18333333333334, 78.16666666666667, 1.0, 2.0, 0.7195304200646014, 1.0, 2.0, 0.7195304200646014, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2012089.065493528, 2012089.065493528, 382592.3363559183], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6599400.0000, 
sim time next is 6600000.0000, 
raw observation next is [28.36666666666667, 77.33333333333334, 1.0, 2.0, 0.6548094252367811, 1.0, 2.0, 0.6548094252367811, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1830949.150690061, 1830949.150690061, 355374.5920408241], 
processed observation next is [1.0, 0.391304347826087, 0.543443917851501, 0.7733333333333334, 1.0, 1.0, 0.5841077412491338, 1.0, 1.0, 0.5841077412491338, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5085969863027947, 0.5085969863027947, 0.5304098388669016], 
reward next is 0.4696, 
noisyNet noise sample is [array([-0.8363384], dtype=float32), -0.23945566]. 
=============================================
[2019-03-26 23:02:38,016] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[46.63313 ]
 [48.85637 ]
 [53.82233 ]
 [57.865273]
 [61.04779 ]], R is [[45.25255585]
 [45.22899628]
 [44.7767067 ]
 [44.32894135]
 [43.88565063]].
[2019-03-26 23:02:42,399] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.8193928e-23 1.0000000e+00 2.0972912e-22 1.4346965e-17 1.7593657e-29], sum to 1.0000
[2019-03-26 23:02:42,406] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4119
[2019-03-26 23:02:42,410] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.26666666666667, 52.0, 1.0, 2.0, 0.4516574988904564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 643087.5587748671, 643087.5587748665, 177912.960581691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6961200.0000, 
sim time next is 6961800.0000, 
raw observation next is [31.08333333333333, 52.0, 1.0, 2.0, 0.4441880433620905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 636648.3770958986, 636648.3770958979, 177370.571620863], 
processed observation next is [0.0, 0.5652173913043478, 0.6721958925750393, 0.52, 1.0, 1.0, 0.3303470401952897, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1768467714155274, 0.1768467714155272, 0.2647321964490492], 
reward next is 0.7353, 
noisyNet noise sample is [array([-0.70793205], dtype=float32), 0.21410309]. 
=============================================
[2019-03-26 23:02:49,636] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5296414e-23 1.0000000e+00 2.2269581e-22 1.6251961e-18 9.4347531e-30], sum to 1.0000
[2019-03-26 23:02:49,649] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6621
[2019-03-26 23:02:49,655] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 82.0, 1.0, 2.0, 0.3373104225798131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 526188.2841999789, 526188.2841999796, 168885.4356389139], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6840000.0000, 
sim time next is 6840600.0000, 
raw observation next is [23.08333333333334, 82.33333333333334, 1.0, 2.0, 0.3384398181616116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527583.3709242905, 527583.3709242905, 168987.0938982597], 
processed observation next is [0.0, 0.17391304347826086, 0.2930489731437602, 0.8233333333333335, 1.0, 1.0, 0.20293953995374894, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1465509363678585, 0.1465509363678585, 0.2522195431317309], 
reward next is 0.7478, 
noisyNet noise sample is [array([0.722668], dtype=float32), -1.052831]. 
=============================================
[2019-03-26 23:02:50,282] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.4204611e-24 1.0000000e+00 2.0604561e-22 1.1592450e-17 5.1400687e-29], sum to 1.0000
[2019-03-26 23:02:50,292] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3860
[2019-03-26 23:02:50,296] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.13333333333333, 77.0, 1.0, 2.0, 0.421005943769674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 610719.8940036541, 610719.8940036541, 175038.407498414], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7494000.0000, 
sim time next is 7494600.0000, 
raw observation next is [26.01666666666667, 77.5, 1.0, 2.0, 0.4200347975032969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 610208.4788215889, 610208.4788215889, 175016.526801844], 
processed observation next is [0.0, 0.7391304347826086, 0.43206951026856255, 0.775, 1.0, 1.0, 0.30124674397987583, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16950235522821913, 0.16950235522821913, 0.26121869671917014], 
reward next is 0.7388, 
noisyNet noise sample is [array([0.12309556], dtype=float32), -1.6979783]. 
=============================================
[2019-03-26 23:02:50,533] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.3137309e-23 1.0000000e+00 1.8513826e-22 9.1172635e-17 1.1912653e-27], sum to 1.0000
[2019-03-26 23:02:50,542] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8274
[2019-03-26 23:02:50,548] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 93.33333333333334, 1.0, 2.0, 0.3177128470433545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 501348.4929683455, 501348.4929683455, 167104.9131622994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7431600.0000, 
sim time next is 7432200.0000, 
raw observation next is [21.2, 93.0, 1.0, 2.0, 0.3175842133169536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 501227.6205230787, 501227.6205230793, 167097.5703452879], 
processed observation next is [0.0, 0.0, 0.20379146919431282, 0.93, 1.0, 1.0, 0.17781230520114888, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13922989458974408, 0.13922989458974425, 0.24939935872431032], 
reward next is 0.7506, 
noisyNet noise sample is [array([0.47789267], dtype=float32), 2.3187187]. 
=============================================
[2019-03-26 23:02:54,362] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6144518e-12 6.3484937e-01 1.2576416e-10 3.6515066e-01 1.0171369e-15], sum to 1.0000
[2019-03-26 23:02:54,372] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5846
[2019-03-26 23:02:54,381] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1900836.444301875 W.
[2019-03-26 23:02:54,387] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.9, 52.0, 1.0, 2.0, 0.6753565916142368, 1.0, 2.0, 0.6753565916142368, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1900836.444301875, 1900836.444301875, 365286.9545582164], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7052400.0000, 
sim time next is 7053000.0000, 
raw observation next is [30.7, 53.5, 1.0, 2.0, 0.76383335122378, 1.0, 2.0, 0.76383335122378, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2136498.624416153, 2136498.624416153, 402681.9885834833], 
processed observation next is [1.0, 0.6521739130434783, 0.6540284360189573, 0.535, 1.0, 1.0, 0.7154618689443133, 1.0, 1.0, 0.7154618689443133, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5934718401155981, 0.5934718401155981, 0.6010178934081841], 
reward next is 0.3990, 
noisyNet noise sample is [array([0.20647901], dtype=float32), -0.09189493]. 
=============================================
[2019-03-26 23:02:54,402] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[44.2286  ]
 [43.171734]
 [42.110466]
 [42.28812 ]
 [44.52989 ]], R is [[44.57185364]
 [44.58093262]
 [44.59052277]
 [44.59963608]
 [44.15364075]].
[2019-03-26 23:02:59,512] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.75361279e-24 1.00000000e+00 1.13729682e-23 1.41848954e-18
 1.33793855e-30], sum to 1.0000
[2019-03-26 23:02:59,520] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9279
[2019-03-26 23:02:59,526] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 61.5, 1.0, 2.0, 0.4803291918054806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 671176.7342933605, 671176.7342933611, 180571.3155602053], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6970200.0000, 
sim time next is 6970800.0000, 
raw observation next is [30.0, 61.0, 1.0, 2.0, 0.4787080597107752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 668910.7701746545, 668910.7701746545, 180327.0397785197], 
processed observation next is [0.0, 0.6956521739130435, 0.6208530805687204, 0.61, 1.0, 1.0, 0.3719374213382834, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18580854727073737, 0.18580854727073737, 0.2691448354903279], 
reward next is 0.7309, 
noisyNet noise sample is [array([-1.1396964], dtype=float32), -0.83663327]. 
=============================================
[2019-03-26 23:03:03,591] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.4447990e-15 9.9999726e-01 1.5141173e-14 2.7385488e-06 1.5229562e-19], sum to 1.0000
[2019-03-26 23:03:03,600] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8350
[2019-03-26 23:03:03,608] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1986640.074487375 W.
[2019-03-26 23:03:03,612] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.91666666666667, 58.33333333333334, 1.0, 2.0, 0.4736254652927116, 1.0, 2.0, 0.4736254652927116, 1.0, 1.0, 0.8023340556229125, 6.9112, 6.9112, 170.5573041426782, 1986640.074487375, 1986640.074487375, 393895.1478427972], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7653000.0000, 
sim time next is 7653600.0000, 
raw observation next is [31.0, 58.0, 1.0, 2.0, 0.7870010030964176, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.967846073146985, 6.9112, 168.9126186922614, 1996880.975292335, 1956694.381765994, 405905.7171184471], 
processed observation next is [1.0, 0.6086956521739131, 0.6682464454976303, 0.58, 1.0, 1.0, 0.7433747025258044, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.005664607314698511, 0.0, 0.829438286310436, 0.5546891598034264, 0.5435262171572206, 0.6058294285349957], 
reward next is 0.1109, 
noisyNet noise sample is [array([-1.107908], dtype=float32), -0.70945865]. 
=============================================
[2019-03-26 23:03:03,727] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 23:03:03,730] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 23:03:03,731] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 23:03:03,732] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:03:03,732] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 23:03:03,732] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:03:03,734] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 23:03:03,734] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:03:03,734] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 23:03:03,736] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:03:03,737] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:03:03,763] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run85
[2019-03-26 23:03:03,791] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run85
[2019-03-26 23:03:03,792] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run85
[2019-03-26 23:03:03,850] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run85
[2019-03-26 23:03:03,850] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run85
[2019-03-26 23:03:59,185] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09470502], dtype=float32), 0.07336003]
[2019-03-26 23:03:59,186] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.09964267833333, 67.967002665, 1.0, 2.0, 0.4960388645669404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 693135.4388302336, 693135.4388302336, 182977.4688651283]
[2019-03-26 23:03:59,187] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:03:59,191] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.6950114e-21 1.0000000e+00 4.9585326e-20 1.6324233e-13 1.8106869e-26], sampled 0.4571003575303114
[2019-03-26 23:04:15,558] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09470502], dtype=float32), 0.07336003]
[2019-03-26 23:04:15,559] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.38103824666667, 80.27954042333333, 1.0, 2.0, 0.4896087817167855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 690347.7650108523, 690347.7650108523, 182780.6571353152]
[2019-03-26 23:04:15,560] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:04:15,562] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.8711932e-24 1.0000000e+00 3.2152699e-23 1.0683254e-17 6.7117139e-30], sampled 0.9434202042689682
[2019-03-26 23:04:42,201] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09470502], dtype=float32), 0.07336003]
[2019-03-26 23:04:42,203] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.50703916, 76.12672724000001, 1.0, 2.0, 0.340370891165275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 536302.5433113286, 536302.5433113286, 169803.9720705909]
[2019-03-26 23:04:42,204] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:04:42,208] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.8363104e-23 1.0000000e+00 2.2604058e-22 2.6768903e-18 8.1310054e-29], sampled 0.18628043520732274
[2019-03-26 23:04:45,845] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09470502], dtype=float32), 0.07336003]
[2019-03-26 23:04:45,848] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.92052297666667, 62.69174727333334, 1.0, 2.0, 0.6243925390618335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 891681.5607427782, 891681.5607427782, 207858.1869627521]
[2019-03-26 23:04:45,849] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:04:45,851] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.3004512e-23 1.0000000e+00 3.5533241e-22 1.6484241e-17 1.3186551e-28], sampled 0.9761939968026955
[2019-03-26 23:04:50,602] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09470502], dtype=float32), 0.07336003]
[2019-03-26 23:04:50,603] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.1, 94.0, 1.0, 2.0, 0.3172457521601685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 500464.1211775286, 500464.1211775286, 167035.3215961999]
[2019-03-26 23:04:50,604] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:04:50,606] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.5451952e-24 1.0000000e+00 3.1123308e-23 2.3751515e-18 7.7317985e-30], sampled 0.3976670634078254
[2019-03-26 23:04:58,156] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.7909 2779406498.8226 933.0000
[2019-03-26 23:04:58,202] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7894.0950 3163776298.1914 1745.0000
[2019-03-26 23:04:58,262] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.5883 2927327297.4404 1338.0000
[2019-03-26 23:04:58,264] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.6944 3007226815.6485 1757.0000
[2019-03-26 23:04:58,336] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8501.8594 2842116680.0176 1122.0000
[2019-03-26 23:04:59,352] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2100000, evaluation results [2100000.0, 7894.095009439088, 3163776298.1913795, 1745.0, 8253.588267098503, 2927327297.440425, 1338.0, 8659.790908167271, 2779406498.822647, 933.0, 7996.694425456574, 3007226815.6484537, 1757.0, 8501.859384259886, 2842116680.0176015, 1122.0]
[2019-03-26 23:05:00,364] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.7658202e-24 1.0000000e+00 7.8820748e-21 3.7173471e-13 2.9941064e-29], sum to 1.0000
[2019-03-26 23:05:00,372] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7180
[2019-03-26 23:05:00,377] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 85.66666666666667, 1.0, 2.0, 0.5095597186048926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 712035.0144809416, 712035.0144809422, 185107.3575488465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7672800.0000, 
sim time next is 7673400.0000, 
raw observation next is [26.55, 86.5, 1.0, 2.0, 0.5077434834523744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709496.244525124, 709496.244525124, 184818.1776674127], 
processed observation next is [1.0, 0.8260869565217391, 0.4573459715639811, 0.865, 1.0, 1.0, 0.40691985958117394, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19708229014586776, 0.19708229014586776, 0.2758480263692727], 
reward next is 0.7242, 
noisyNet noise sample is [array([1.0834881], dtype=float32), 1.9575124]. 
=============================================
[2019-03-26 23:05:04,835] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.4783455e-20 1.0000000e+00 1.1182456e-19 3.0087562e-14 1.0660617e-25], sum to 1.0000
[2019-03-26 23:05:04,844] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4827
[2019-03-26 23:05:04,852] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2151868.761937186 W.
[2019-03-26 23:05:04,857] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.6, 71.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.865800084982329, 6.9112, 168.9075676307972, 2151868.761937186, 1474664.212596213, 314626.0437618887], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7117800.0000, 
sim time next is 7118400.0000, 
raw observation next is [27.7, 71.33333333333334, 1.0, 2.0, 0.6166416644805994, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.911694863106829, 6.9112, 168.9121673675936, 1734552.224321608, 1734201.153041923, 369882.0315017942], 
processed observation next is [1.0, 0.391304347826087, 0.5118483412322274, 0.7133333333333334, 1.0, 1.0, 0.5381224873260234, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 4.948631068293352e-05, 0.0, 0.8294360700997, 0.4818200623115578, 0.48172254251164526, 0.5520627335847674], 
reward next is 0.4455, 
noisyNet noise sample is [array([0.6536397], dtype=float32), 0.0048110127]. 
=============================================
[2019-03-26 23:05:05,849] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.4240897e-15 9.9992847e-01 5.8460056e-13 7.1497852e-05 1.2221347e-18], sum to 1.0000
[2019-03-26 23:05:05,858] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7505
[2019-03-26 23:05:05,869] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2600376.463413814 W.
[2019-03-26 23:05:05,874] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.18333333333333, 84.33333333333333, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 8.526485194790935, 6.9112, 168.9037485047203, 2600376.463413814, 1454500.021335477, 310410.2678692107], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7143000.0000, 
sim time next is 7143600.0000, 
raw observation next is [26.16666666666667, 84.66666666666667, 1.0, 2.0, 0.4827776989781664, 1.0, 1.0, 0.4827776989781664, 1.0, 1.0, 0.8154453826071709, 6.9112, 6.9112, 170.5573041426782, 2025065.75087977, 2025065.75087977, 399369.6548888495], 
processed observation next is [1.0, 0.6956521739130435, 0.4391785150078992, 0.8466666666666667, 1.0, 1.0, 0.3768406011785138, 1.0, 0.5, 0.3768406011785138, 1.0, 0.5, 0.7749333934233791, 0.0, 0.0, 0.8375144448122397, 0.5625182641332694, 0.5625182641332694, 0.5960741117744022], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.36577302], dtype=float32), -0.16486385]. 
=============================================
[2019-03-26 23:05:14,639] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:05:14,640] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:05:14,732] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run11
[2019-03-26 23:05:16,458] A3C_AGENT_WORKER-Thread-16 INFO:Local step 132500, global step 2107706: loss 201.3583
[2019-03-26 23:05:16,460] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 132500, global step 2107706: learning rate 0.0000
[2019-03-26 23:05:17,765] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:05:17,765] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:05:17,835] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run11
[2019-03-26 23:05:18,233] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8519415e-21 1.0000000e+00 2.9588990e-20 1.9837368e-15 3.7495283e-27], sum to 1.0000
[2019-03-26 23:05:18,240] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2465
[2019-03-26 23:05:18,244] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 80.0, 1.0, 2.0, 0.3771348020114152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 573922.2480009567, 573922.2480009574, 172508.0251072274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7356600.0000, 
sim time next is 7357200.0000, 
raw observation next is [24.23333333333333, 81.0, 1.0, 2.0, 0.3772160127202847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 572707.964964087, 572707.9649640864, 172363.0587321109], 
processed observation next is [1.0, 0.13043478260869565, 0.3475513428120062, 0.81, 1.0, 1.0, 0.24965784665094543, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1590855458233575, 0.15908554582335735, 0.25725829661509086], 
reward next is 0.7427, 
noisyNet noise sample is [array([0.02994931], dtype=float32), -0.38279045]. 
=============================================
[2019-03-26 23:05:19,574] A3C_AGENT_WORKER-Thread-2 INFO:Local step 132500, global step 2109215: loss 85.8958
[2019-03-26 23:05:19,578] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 132500, global step 2109216: learning rate 0.0000
[2019-03-26 23:05:21,379] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:05:21,380] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:05:21,458] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run11
[2019-03-26 23:05:22,929] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.6654681e-24 1.0000000e+00 9.3562236e-23 4.8334081e-19 3.7230554e-30], sum to 1.0000
[2019-03-26 23:05:22,938] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2516
[2019-03-26 23:05:22,943] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333333, 95.0, 1.0, 2.0, 0.3268253938745321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 511212.3303705144, 511212.3303705144, 167749.2313655075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7452600.0000, 
sim time next is 7453200.0000, 
raw observation next is [21.36666666666667, 95.0, 1.0, 2.0, 0.3275686066064395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 511935.0396896502, 511935.0396896502, 167793.3385526447], 
processed observation next is [0.0, 0.2608695652173913, 0.21169036334913136, 0.95, 1.0, 1.0, 0.1898416947065536, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14220417769156948, 0.14220417769156948, 0.2504378187352906], 
reward next is 0.7496, 
noisyNet noise sample is [array([-0.84289163], dtype=float32), -0.90344524]. 
=============================================
[2019-03-26 23:05:23,199] A3C_AGENT_WORKER-Thread-9 INFO:Local step 132500, global step 2110958: loss 89.4610
[2019-03-26 23:05:23,205] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 132500, global step 2110959: learning rate 0.0000
[2019-03-26 23:05:25,510] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.6926315e-23 1.0000000e+00 9.8724259e-22 5.7682044e-16 4.4851974e-29], sum to 1.0000
[2019-03-26 23:05:25,518] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5910
[2019-03-26 23:05:25,522] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 87.0, 1.0, 2.0, 0.5058889047323214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 706903.8834219666, 706903.8834219672, 184523.7968878408], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7858800.0000, 
sim time next is 7859400.0000, 
raw observation next is [26.38333333333333, 87.33333333333333, 1.0, 2.0, 0.5052459180020655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 706005.1073105693, 706005.10731057, 184422.1017408133], 
processed observation next is [1.0, 1.0, 0.44944707740916257, 0.8733333333333333, 1.0, 1.0, 0.40391074458080184, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19611252980849145, 0.19611252980849164, 0.27525686826987056], 
reward next is 0.7247, 
noisyNet noise sample is [array([0.9243254], dtype=float32), -1.946632]. 
=============================================
[2019-03-26 23:05:29,375] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.3300359e-24 1.0000000e+00 6.9051923e-23 8.3115578e-19 1.3039331e-29], sum to 1.0000
[2019-03-26 23:05:29,385] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5930
[2019-03-26 23:05:29,391] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 65.0, 1.0, 2.0, 0.4609718946588133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 646762.4357191233, 646762.4357191239, 178049.3615695616], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7561200.0000, 
sim time next is 7561800.0000, 
raw observation next is [29.0, 64.5, 1.0, 2.0, 0.4564778505367695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 642895.3599905617, 642895.3599905611, 177712.4757013884], 
processed observation next is [0.0, 0.5217391304347826, 0.5734597156398105, 0.645, 1.0, 1.0, 0.3451540367912885, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1785820444418227, 0.17858204444182255, 0.2652425010468484], 
reward next is 0.7348, 
noisyNet noise sample is [array([-0.7260183], dtype=float32), 1.248125]. 
=============================================
[2019-03-26 23:05:31,377] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5197240e-24 1.0000000e+00 2.2770907e-23 1.6331947e-18 2.2259043e-30], sum to 1.0000
[2019-03-26 23:05:31,385] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4254
[2019-03-26 23:05:31,390] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.86666666666667, 93.0, 1.0, 2.0, 0.4789789298341152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 669289.3830200105, 669289.3830200112, 180367.7979197154], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7600800.0000, 
sim time next is 7601400.0000, 
raw observation next is [24.8, 93.0, 1.0, 2.0, 0.4771988846944122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 666801.3002527197, 666801.3002527204, 180100.4021274055], 
processed observation next is [0.0, 1.0, 0.3744075829383887, 0.93, 1.0, 1.0, 0.37011913818603875, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18522258340353323, 0.18522258340353343, 0.2688065703394112], 
reward next is 0.7312, 
noisyNet noise sample is [array([1.1338775], dtype=float32), -0.5310367]. 
=============================================
[2019-03-26 23:05:32,109] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:05:32,111] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:05:32,183] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run11
[2019-03-26 23:05:33,056] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133000, global step 2115429: loss 0.0125
[2019-03-26 23:05:33,057] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133000, global step 2115429: learning rate 0.0000
[2019-03-26 23:05:33,847] A3C_AGENT_WORKER-Thread-14 INFO:Local step 132500, global step 2115822: loss 96.9918
[2019-03-26 23:05:33,848] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 132500, global step 2115822: learning rate 0.0000
[2019-03-26 23:05:36,359] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133000, global step 2116941: loss 0.0125
[2019-03-26 23:05:36,360] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133000, global step 2116941: learning rate 0.0000
[2019-03-26 23:05:37,090] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:05:37,092] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:05:37,162] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run11
[2019-03-26 23:05:38,822] A3C_AGENT_WORKER-Thread-19 INFO:Local step 132500, global step 2118168: loss 133.7423
[2019-03-26 23:05:38,825] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 132500, global step 2118171: learning rate 0.0000
[2019-03-26 23:05:39,840] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133000, global step 2118625: loss 0.0138
[2019-03-26 23:05:39,847] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133000, global step 2118628: learning rate 0.0000
[2019-03-26 23:05:40,854] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7818187e-15 9.9866736e-01 1.3343418e-12 1.3326640e-03 1.8429961e-19], sum to 1.0000
[2019-03-26 23:05:40,860] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6355
[2019-03-26 23:05:40,866] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.96666666666667, 65.33333333333334, 1.0, 2.0, 0.4605356573126653, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 643510.3258140581, 643510.3258140587, 177646.0505532061], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7752000.0000, 
sim time next is 7752600.0000, 
raw observation next is [29.8, 66.5, 1.0, 2.0, 0.4536057991173154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 633824.2883353025, 633824.2883353019, 176648.9047013081], 
processed observation next is [1.0, 0.7391304347826086, 0.6113744075829385, 0.665, 1.0, 1.0, 0.34169373387628366, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1760623023153618, 0.17606230231536163, 0.26365508164374346], 
reward next is 0.7363, 
noisyNet noise sample is [array([-0.09157405], dtype=float32), 2.2577896]. 
=============================================
[2019-03-26 23:05:42,906] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:05:42,907] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:05:42,988] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run11
[2019-03-26 23:05:44,671] A3C_AGENT_WORKER-Thread-17 INFO:Local step 132500, global step 2120900: loss 105.7138
[2019-03-26 23:05:44,676] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 132500, global step 2120900: learning rate 0.0000
[2019-03-26 23:05:46,075] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:05:46,077] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:05:46,167] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run11
[2019-03-26 23:05:47,890] A3C_AGENT_WORKER-Thread-10 INFO:Local step 132500, global step 2122455: loss 103.3381
[2019-03-26 23:05:47,893] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 132500, global step 2122456: learning rate 0.0000
[2019-03-26 23:05:48,906] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133500, global step 2122912: loss 0.0997
[2019-03-26 23:05:48,909] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133500, global step 2122912: learning rate 0.0000
[2019-03-26 23:05:49,795] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:05:49,796] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:05:49,843] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133000, global step 2123325: loss 0.0102
[2019-03-26 23:05:49,849] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133000, global step 2123326: learning rate 0.0000
[2019-03-26 23:05:49,880] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run11
[2019-03-26 23:05:50,578] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.1861343e-23 1.0000000e+00 2.0793036e-22 1.2128792e-15 2.7705327e-29], sum to 1.0000
[2019-03-26 23:05:50,587] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6267
[2019-03-26 23:05:50,591] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.56666666666667, 90.5, 1.0, 2.0, 0.527304807204318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 736839.7747948361, 736839.7747948361, 187984.8601255989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7944600.0000, 
sim time next is 7945200.0000, 
raw observation next is [26.5, 91.0, 1.0, 2.0, 0.5269769436579235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 736381.4693973588, 736381.4693973588, 187930.8819400518], 
processed observation next is [1.0, 1.0, 0.4549763033175356, 0.91, 1.0, 1.0, 0.4300927032023174, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.204550408165933, 0.204550408165933, 0.28049385364186835], 
reward next is 0.7195, 
noisyNet noise sample is [array([0.63386494], dtype=float32), -0.38429713]. 
=============================================
[2019-03-26 23:05:50,629] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.8462203e-24 1.0000000e+00 2.8435012e-23 1.5804727e-18 1.4519371e-29], sum to 1.0000
[2019-03-26 23:05:50,632] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7615
[2019-03-26 23:05:50,636] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.56666666666667, 84.66666666666667, 1.0, 2.0, 0.2895384935202305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 463709.1940861639, 463709.1940861645, 164512.247423915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 328800.0000, 
sim time next is 329400.0000, 
raw observation next is [21.5, 85.0, 1.0, 2.0, 0.2886586707403454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 462513.7222599693, 462513.72225997, 164432.0790236724], 
processed observation next is [0.0, 0.8260869565217391, 0.21800947867298584, 0.85, 1.0, 1.0, 0.14296225390403058, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12847603396110258, 0.12847603396110277, 0.24542101346816778], 
reward next is 0.7546, 
noisyNet noise sample is [array([0.52275246], dtype=float32), -0.1920983]. 
=============================================
[2019-03-26 23:05:51,040] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.4795377e-21 1.0000000e+00 9.6079710e-21 1.3580642e-16 7.4325994e-28], sum to 1.0000
[2019-03-26 23:05:51,047] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6237
[2019-03-26 23:05:51,051] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.03333333333333, 89.66666666666667, 1.0, 2.0, 0.2186143000393094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 363966.4045390229, 363966.4045390223, 157534.2777165281], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 531600.0000, 
sim time next is 532200.0000, 
raw observation next is [17.96666666666667, 89.83333333333333, 1.0, 2.0, 0.2167860746051304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 361039.2437686982, 361039.2437686975, 157344.371889368], 
processed observation next is [1.0, 0.13043478260869565, 0.050552922590837435, 0.8983333333333333, 1.0, 1.0, 0.05636876458449446, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10028867882463839, 0.1002886788246382, 0.23484234610353433], 
reward next is 0.7652, 
noisyNet noise sample is [array([0.8272056], dtype=float32), 0.28939414]. 
=============================================
[2019-03-26 23:05:51,172] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.6532909e-24 1.0000000e+00 7.0367661e-23 2.7510125e-18 1.3646661e-29], sum to 1.0000
[2019-03-26 23:05:51,173] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1770
[2019-03-26 23:05:51,177] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.56666666666667, 86.16666666666667, 1.0, 2.0, 0.2663470661482746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 432854.9023929001, 432854.9023928994, 162455.0226345912], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 346200.0000, 
sim time next is 346800.0000, 
raw observation next is [20.53333333333333, 86.33333333333334, 1.0, 2.0, 0.2654771746370886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 431528.6926698316, 431528.692669831, 162369.0579879229], 
processed observation next is [1.0, 0.0, 0.17219589257503945, 0.8633333333333334, 1.0, 1.0, 0.11503274052661275, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11986908129717545, 0.11986908129717527, 0.24234187759391476], 
reward next is 0.7577, 
noisyNet noise sample is [array([-0.01660208], dtype=float32), -0.1495183]. 
=============================================
[2019-03-26 23:05:51,280] A3C_AGENT_WORKER-Thread-13 INFO:Local step 132500, global step 2124109: loss 93.6354
[2019-03-26 23:05:51,282] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 132500, global step 2124110: learning rate 0.0000
[2019-03-26 23:05:51,411] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133500, global step 2124169: loss 0.0833
[2019-03-26 23:05:51,414] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133500, global step 2124169: learning rate 0.0000
[2019-03-26 23:05:51,630] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:05:51,630] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:05:51,714] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run11
[2019-03-26 23:05:51,751] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:05:51,752] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:05:51,765] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:05:51,765] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:05:51,819] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:05:51,819] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:05:51,825] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run11
[2019-03-26 23:05:51,870] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run11
[2019-03-26 23:05:51,894] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:05:51,896] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:05:51,942] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run11
[2019-03-26 23:05:51,964] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:05:51,967] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:05:51,996] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run11
[2019-03-26 23:05:52,026] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run11
[2019-03-26 23:05:52,108] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:05:52,109] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:05:52,117] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run11
[2019-03-26 23:05:52,157] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:05:52,157] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:05:52,170] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run11
[2019-03-26 23:05:52,836] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5619203e-21 1.0000000e+00 1.5576250e-20 7.1030787e-17 3.4447268e-27], sum to 1.0000
[2019-03-26 23:05:52,839] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9663
[2019-03-26 23:05:52,845] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.26666666666667, 83.66666666666667, 1.0, 2.0, 0.2273105243081364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 377038.4691451734, 377038.4691451727, 158558.7234487081], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 714000.0000, 
sim time next is 714600.0000, 
raw observation next is [19.5, 82.5, 1.0, 2.0, 0.2281350297106171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 378105.1292275349, 378105.1292275355, 158669.3260739864], 
processed observation next is [1.0, 0.2608695652173913, 0.12322274881516594, 0.825, 1.0, 1.0, 0.07004220447062301, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10502920256320415, 0.1050292025632043, 0.23681988966266626], 
reward next is 0.7632, 
noisyNet noise sample is [array([0.2816215], dtype=float32), -1.8297986]. 
=============================================
[2019-03-26 23:05:52,935] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133000, global step 2124833: loss 0.0068
[2019-03-26 23:05:52,936] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133000, global step 2124833: learning rate 0.0000
[2019-03-26 23:05:53,204] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 23:05:53,205] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 23:05:53,206] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:05:53,210] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 23:05:53,212] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 23:05:53,213] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:05:53,214] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:05:53,213] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 23:05:53,216] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:05:53,217] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 23:05:53,218] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:05:53,233] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run86
[2019-03-26 23:05:53,252] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run86
[2019-03-26 23:05:53,278] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run86
[2019-03-26 23:05:53,303] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run86
[2019-03-26 23:05:53,333] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run86
[2019-03-26 23:06:03,044] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09588176], dtype=float32), 0.075087845]
[2019-03-26 23:06:03,045] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.56904624666667, 46.05431708, 1.0, 2.0, 0.3944064989809432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 637872.9870073794, 637872.9870073787, 178327.8072668185]
[2019-03-26 23:06:03,048] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:06:03,050] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.1708322e-23 1.0000000e+00 2.5004765e-22 4.7229941e-18 8.0825767e-29], sampled 0.43085219382865747
[2019-03-26 23:06:07,969] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09588176], dtype=float32), 0.075087845]
[2019-03-26 23:06:07,970] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.54302838333334, 87.17285372333333, 1.0, 2.0, 0.3001844307545969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 488973.4510685924, 488973.4510685931, 166207.3702427229]
[2019-03-26 23:06:07,970] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:06:07,972] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.11421933e-23 1.00000000e+00 6.55183565e-23 1.30363210e-18
 1.25850404e-29], sampled 0.45753037432989807
[2019-03-26 23:06:15,890] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09588176], dtype=float32), 0.075087845]
[2019-03-26 23:06:15,892] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.64488806, 97.68252520833335, 1.0, 2.0, 0.3873328228814134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 579151.8488814154, 579151.8488814161, 172669.2959889664]
[2019-03-26 23:06:15,892] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:06:15,897] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.9573966e-23 1.0000000e+00 8.2902617e-23 5.7888059e-19 1.9607836e-29], sampled 0.9875947395563905
[2019-03-26 23:07:25,132] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09588176], dtype=float32), 0.075087845]
[2019-03-26 23:07:25,133] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.43912159, 73.44178142333334, 1.0, 2.0, 0.5027809792624207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 702559.5874874901, 702559.5874874907, 184032.8949307844]
[2019-03-26 23:07:25,134] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:07:25,138] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.2928771e-23 1.0000000e+00 7.2770790e-23 2.7416988e-18 1.5507051e-29], sampled 0.4391532413504503
[2019-03-26 23:07:39,118] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09588176], dtype=float32), 0.075087845]
[2019-03-26 23:07:39,118] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.90000000000001, 68.0, 1.0, 2.0, 0.6221006908341978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 869358.882751789, 869358.882751789, 204935.7801402254]
[2019-03-26 23:07:39,120] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 23:07:39,122] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.064082e-23 1.000000e+00 3.627989e-20 5.863236e-11 6.510933e-28], sampled 0.06294410805977368
[2019-03-26 23:07:41,847] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09588176], dtype=float32), 0.075087845]
[2019-03-26 23:07:41,848] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.5, 93.0, 1.0, 2.0, 0.4091832003651533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 602415.1954450014, 602415.1954450014, 174523.8407494047]
[2019-03-26 23:07:41,849] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:07:41,852] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.08910626e-23 1.00000000e+00 8.39659635e-23 5.16125837e-18
 1.90556715e-29], sampled 0.013232460449379757
[2019-03-26 23:07:44,507] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09588176], dtype=float32), 0.075087845]
[2019-03-26 23:07:44,508] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.11666666666667, 81.33333333333333, 1.0, 2.0, 0.5776095593173058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 807160.8208474347, 807160.8208474347, 196648.2374378775]
[2019-03-26 23:07:44,510] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 23:07:44,512] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.5495273e-23 1.0000000e+00 1.7227119e-22 7.5382637e-17 3.5883460e-29], sampled 0.7598757725128104
[2019-03-26 23:07:47,596] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8502.8931 2841995532.8062 1122.0000
[2019-03-26 23:07:47,676] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.5754 2779532749.0907 933.0000
[2019-03-26 23:07:47,942] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7890.2678 3163804029.4596 1741.0000
[2019-03-26 23:07:47,952] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8256.8317 2927419856.3153 1338.0000
[2019-03-26 23:07:47,963] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.1597 3007009550.5460 1756.0000
[2019-03-26 23:07:48,984] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 2125000, evaluation results [2125000.0, 7890.26776120526, 3163804029.4595747, 1741.0, 8256.831727253146, 2927419856.3152895, 1338.0, 8659.575449734068, 2779532749.090661, 933.0, 7996.159726787437, 3007009550.5459886, 1756.0, 8502.89311737403, 2841995532.8061743, 1122.0]
[2019-03-26 23:07:49,112] A3C_AGENT_WORKER-Thread-12 INFO:Local step 132500, global step 2125071: loss 94.8968
[2019-03-26 23:07:49,114] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 132500, global step 2125072: learning rate 0.0000
[2019-03-26 23:07:49,299] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133500, global step 2125151: loss 0.0744
[2019-03-26 23:07:49,301] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133500, global step 2125152: learning rate 0.0000
[2019-03-26 23:07:49,315] A3C_AGENT_WORKER-Thread-11 INFO:Local step 132500, global step 2125159: loss 95.1476
[2019-03-26 23:07:49,318] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 132500, global step 2125159: learning rate 0.0000
[2019-03-26 23:07:49,659] A3C_AGENT_WORKER-Thread-21 INFO:Local step 132500, global step 2125317: loss 97.2406
[2019-03-26 23:07:49,667] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 132500, global step 2125319: learning rate 0.0000
[2019-03-26 23:07:49,668] A3C_AGENT_WORKER-Thread-15 INFO:Local step 132500, global step 2125319: loss 100.2501
[2019-03-26 23:07:49,671] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 132500, global step 2125319: learning rate 0.0000
[2019-03-26 23:07:49,682] A3C_AGENT_WORKER-Thread-22 INFO:Local step 132500, global step 2125324: loss 99.1076
[2019-03-26 23:07:49,685] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 132500, global step 2125325: learning rate 0.0000
[2019-03-26 23:07:49,691] A3C_AGENT_WORKER-Thread-18 INFO:Local step 132500, global step 2125325: loss 121.4555
[2019-03-26 23:07:49,693] A3C_AGENT_WORKER-Thread-3 INFO:Local step 132500, global step 2125325: loss 102.5063
[2019-03-26 23:07:49,697] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 132500, global step 2125325: learning rate 0.0000
[2019-03-26 23:07:49,698] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 132500, global step 2125325: learning rate 0.0000
[2019-03-26 23:07:49,705] A3C_AGENT_WORKER-Thread-20 INFO:Local step 132500, global step 2125330: loss 146.0104
[2019-03-26 23:07:49,709] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 132500, global step 2125330: learning rate 0.0000
[2019-03-26 23:07:55,067] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133000, global step 2127728: loss 0.0023
[2019-03-26 23:07:55,068] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133000, global step 2127728: learning rate 0.0000
[2019-03-26 23:07:58,122] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0415110e-22 1.0000000e+00 5.3028255e-22 1.2394743e-15 4.1109528e-29], sum to 1.0000
[2019-03-26 23:07:58,132] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0674
[2019-03-26 23:07:58,141] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 96.0, 1.0, 2.0, 0.3810339500190703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 573499.0209116923, 573499.0209116916, 172282.963680865], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 150600.0000, 
sim time next is 151200.0000, 
raw observation next is [22.5, 96.0, 1.0, 2.0, 0.3826110538410947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 575872.5079116046, 575872.5079116046, 172493.9529415882], 
processed observation next is [1.0, 0.782608695652174, 0.2654028436018958, 0.96, 1.0, 1.0, 0.25615789619408996, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15996458553100126, 0.15996458553100126, 0.2574536611068481], 
reward next is 0.7425, 
noisyNet noise sample is [array([1.5108863], dtype=float32), -0.8529635]. 
=============================================
[2019-03-26 23:07:58,487] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133000, global step 2129262: loss 0.0017
[2019-03-26 23:07:58,492] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133000, global step 2129265: learning rate 0.0000
[2019-03-26 23:07:59,792] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134000, global step 2129844: loss 0.0040
[2019-03-26 23:07:59,794] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134000, global step 2129845: learning rate 0.0000
[2019-03-26 23:08:00,682] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133500, global step 2130238: loss 0.0449
[2019-03-26 23:08:00,683] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133500, global step 2130239: learning rate 0.0000
[2019-03-26 23:08:02,880] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133000, global step 2131228: loss 0.0010
[2019-03-26 23:08:02,883] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133000, global step 2131228: learning rate 0.0000
[2019-03-26 23:08:03,254] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134000, global step 2131391: loss 0.0047
[2019-03-26 23:08:03,255] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134000, global step 2131391: learning rate 0.0000
[2019-03-26 23:08:03,334] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.2986490e-24 1.0000000e+00 3.4553397e-24 3.7529208e-19 6.1036035e-31], sum to 1.0000
[2019-03-26 23:08:03,347] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6146
[2019-03-26 23:08:03,353] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 89.0, 1.0, 2.0, 0.3001949018991961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 478264.1305440522, 478264.1305440522, 165501.1985853083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 241800.0000, 
sim time next is 242400.0000, 
raw observation next is [21.23333333333333, 89.0, 1.0, 2.0, 0.2996505036284212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 477729.2055036015, 477729.2055036021, 165467.9946676845], 
processed observation next is [0.0, 0.8260869565217391, 0.2053712480252764, 0.89, 1.0, 1.0, 0.15620542605833881, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13270255708433376, 0.13270255708433393, 0.24696715622042464], 
reward next is 0.7530, 
noisyNet noise sample is [array([-0.33932608], dtype=float32), 0.14761019]. 
=============================================
[2019-03-26 23:08:05,863] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.2099928e-22 1.0000000e+00 6.5422765e-21 2.9953716e-16 1.9059971e-28], sum to 1.0000
[2019-03-26 23:08:05,875] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2548
[2019-03-26 23:08:05,882] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 85.0, 1.0, 2.0, 0.2386394219171848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 393702.6486954252, 393702.6486954258, 159774.2805548117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 435600.0000, 
sim time next is 436200.0000, 
raw observation next is [19.6, 85.00000000000001, 1.0, 2.0, 0.2389475910213506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 394263.9203123889, 394263.9203123889, 159801.1288835176], 
processed observation next is [1.0, 0.043478260869565216, 0.127962085308057, 0.8500000000000001, 1.0, 1.0, 0.08306938677271156, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.10951775564233025, 0.10951775564233025, 0.2385091475873397], 
reward next is 0.7615, 
noisyNet noise sample is [array([0.17822328], dtype=float32), 0.4084198]. 
=============================================
[2019-03-26 23:08:06,150] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133500, global step 2132676: loss 0.0565
[2019-03-26 23:08:06,153] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133500, global step 2132677: learning rate 0.0000
[2019-03-26 23:08:07,049] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133000, global step 2133081: loss 0.0018
[2019-03-26 23:08:07,051] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133000, global step 2133082: learning rate 0.0000
[2019-03-26 23:08:07,382] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134000, global step 2133199: loss 0.0033
[2019-03-26 23:08:07,390] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134000, global step 2133202: learning rate 0.0000
[2019-03-26 23:08:07,492] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133000, global step 2133249: loss 0.0013
[2019-03-26 23:08:07,495] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133000, global step 2133250: learning rate 0.0000
[2019-03-26 23:08:07,510] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133000, global step 2133254: loss 0.0009
[2019-03-26 23:08:07,512] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133000, global step 2133255: learning rate 0.0000
[2019-03-26 23:08:07,618] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133000, global step 2133304: loss 0.0013
[2019-03-26 23:08:07,624] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133000, global step 2133307: learning rate 0.0000
[2019-03-26 23:08:07,654] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133000, global step 2133319: loss 0.0011
[2019-03-26 23:08:07,656] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133000, global step 2133320: learning rate 0.0000
[2019-03-26 23:08:07,683] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133000, global step 2133333: loss 0.0013
[2019-03-26 23:08:07,685] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133000, global step 2133333: learning rate 0.0000
[2019-03-26 23:08:07,719] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133000, global step 2133346: loss 0.0011
[2019-03-26 23:08:07,720] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133000, global step 2133346: learning rate 0.0000
[2019-03-26 23:08:07,750] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133000, global step 2133359: loss 0.0013
[2019-03-26 23:08:07,755] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133000, global step 2133360: learning rate 0.0000
[2019-03-26 23:08:08,084] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.0163416e-23 1.0000000e+00 7.6195416e-22 2.0985060e-16 8.1553321e-28], sum to 1.0000
[2019-03-26 23:08:08,091] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1315
[2019-03-26 23:08:08,095] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.96666666666667, 94.33333333333334, 1.0, 2.0, 0.5010190771566627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 771455.5556118315, 771455.5556118315, 192302.9672577543], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 991200.0000, 
sim time next is 991800.0000, 
raw observation next is [21.95, 94.5, 1.0, 2.0, 0.4872704946168389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 750257.855773731, 750257.8557737304, 189943.2381051441], 
processed observation next is [1.0, 0.4782608695652174, 0.2393364928909953, 0.945, 1.0, 1.0, 0.38225360797209507, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2084049599371475, 0.20840495993714733, 0.2834973703061852], 
reward next is 0.7165, 
noisyNet noise sample is [array([1.2627199], dtype=float32), 1.7707987]. 
=============================================
[2019-03-26 23:08:08,759] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.8998493e-25 1.0000000e+00 1.2385901e-23 4.6414572e-19 1.0908695e-30], sum to 1.0000
[2019-03-26 23:08:08,772] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0487
[2019-03-26 23:08:08,778] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 86.0, 1.0, 2.0, 0.2851089079714543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 457733.6440263194, 457733.64402632, 164113.0896229131], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 331800.0000, 
sim time next is 332400.0000, 
raw observation next is [21.23333333333333, 86.0, 1.0, 2.0, 0.284091025076415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 456391.554335087, 456391.554335087, 164024.0112794014], 
processed observation next is [0.0, 0.8695652173913043, 0.2053712480252764, 0.86, 1.0, 1.0, 0.13745906635712649, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1267754317597464, 0.1267754317597464, 0.24481195713343493], 
reward next is 0.7552, 
noisyNet noise sample is [array([-1.1015929], dtype=float32), -1.630041]. 
=============================================
[2019-03-26 23:08:09,847] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.5072472e-23 1.0000000e+00 9.0353912e-22 1.6403079e-16 2.4144298e-28], sum to 1.0000
[2019-03-26 23:08:09,857] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0014
[2019-03-26 23:08:09,861] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.53333333333333, 65.33333333333333, 1.0, 2.0, 0.2477849490515559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 407927.7554038041, 407927.7554038034, 160681.1062061571], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 672000.0000, 
sim time next is 672600.0000, 
raw observation next is [22.31666666666667, 66.66666666666667, 1.0, 2.0, 0.2479955038477095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 408306.4379170497, 408306.4379170503, 160700.9683011164], 
processed observation next is [1.0, 0.782608695652174, 0.2567140600315958, 0.6666666666666667, 1.0, 1.0, 0.0939704865635054, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11341845497695824, 0.11341845497695842, 0.2398521914942036], 
reward next is 0.7601, 
noisyNet noise sample is [array([1.0026537], dtype=float32), 0.6682682]. 
=============================================
[2019-03-26 23:08:10,403] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3776033e-22 1.0000000e+00 9.5895897e-21 3.1166888e-17 4.5685533e-28], sum to 1.0000
[2019-03-26 23:08:10,406] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3144
[2019-03-26 23:08:10,415] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.11666666666667, 88.83333333333334, 1.0, 2.0, 0.25656065928945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 417798.8141201269, 417798.8141201264, 161494.3555650893], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 359400.0000, 
sim time next is 360000.0000, 
raw observation next is [20.1, 89.0, 1.0, 2.0, 0.2566723050073098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 417957.3153252194, 417957.3153252194, 161504.6466071499], 
processed observation next is [1.0, 0.17391304347826086, 0.15165876777251197, 0.89, 1.0, 1.0, 0.10442446386422867, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11609925425700539, 0.11609925425700539, 0.24105171135395506], 
reward next is 0.7589, 
noisyNet noise sample is [array([-0.05131928], dtype=float32), -0.12909886]. 
=============================================
[2019-03-26 23:08:10,450] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[72.43864]
 [72.45172]
 [72.42745]
 [72.51589]
 [72.61756]], R is [[72.3830719 ]
 [72.41820526]
 [72.45301819]
 [72.48752594]
 [72.5215683 ]].
[2019-03-26 23:08:10,570] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4502592e-22 1.0000000e+00 1.3602234e-20 2.9700907e-15 3.7004206e-27], sum to 1.0000
[2019-03-26 23:08:10,578] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0992
[2019-03-26 23:08:10,585] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 85.00000000000001, 1.0, 2.0, 0.2389475910213506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 394263.9203123889, 394263.9203123889, 159801.1288835176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 436200.0000, 
sim time next is 436800.0000, 
raw observation next is [19.6, 85.0, 1.0, 2.0, 0.2397853028395814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 395649.4862059378, 395649.4862059372, 159880.4258597444], 
processed observation next is [1.0, 0.043478260869565216, 0.127962085308057, 0.85, 1.0, 1.0, 0.08407867811997759, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10990263505720495, 0.10990263505720478, 0.2386275012832006], 
reward next is 0.7614, 
noisyNet noise sample is [array([0.30007306], dtype=float32), -2.173278]. 
=============================================
[2019-03-26 23:08:11,213] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.8690989e-22 1.0000000e+00 1.5847567e-21 2.2592824e-17 8.7669968e-29], sum to 1.0000
[2019-03-26 23:08:11,220] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6473
[2019-03-26 23:08:11,225] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.8, 82.66666666666667, 1.0, 2.0, 0.2668630131458348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 435066.5850133558, 435066.5850133558, 162563.8464363459], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 372000.0000, 
sim time next is 372600.0000, 
raw observation next is [20.85, 82.0, 1.0, 2.0, 0.2625000250971872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 428190.0392884404, 428190.0392884411, 162121.5575474764], 
processed observation next is [1.0, 0.30434782608695654, 0.18720379146919444, 0.82, 1.0, 1.0, 0.11144581337010502, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11894167758012233, 0.11894167758012253, 0.24197247395145732], 
reward next is 0.7580, 
noisyNet noise sample is [array([-0.29001772], dtype=float32), 1.116553]. 
=============================================
[2019-03-26 23:08:12,970] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133500, global step 2135682: loss 0.0466
[2019-03-26 23:08:12,975] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133500, global step 2135682: learning rate 0.0000
[2019-03-26 23:08:16,484] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133500, global step 2137253: loss 0.0349
[2019-03-26 23:08:16,487] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133500, global step 2137256: learning rate 0.0000
[2019-03-26 23:08:17,825] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134500, global step 2137852: loss 4.6657
[2019-03-26 23:08:17,828] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134500, global step 2137852: learning rate 0.0000
[2019-03-26 23:08:18,663] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134000, global step 2138225: loss 0.0065
[2019-03-26 23:08:18,665] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134000, global step 2138225: learning rate 0.0000
[2019-03-26 23:08:19,283] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3154781e-23 1.0000000e+00 3.6324306e-22 2.7072581e-17 3.0509713e-29], sum to 1.0000
[2019-03-26 23:08:19,290] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5548
[2019-03-26 23:08:19,299] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.73333333333333, 81.5, 1.0, 2.0, 0.2390725688475068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 395713.5954245069, 395713.5954245076, 159734.1476376303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 508200.0000, 
sim time next is 508800.0000, 
raw observation next is [19.66666666666667, 82.0, 1.0, 2.0, 0.2388942770793331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 395431.8616058314, 395431.8616058314, 159716.1237722852], 
processed observation next is [1.0, 0.9130434782608695, 0.1311216429699845, 0.82, 1.0, 1.0, 0.08300515310763025, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.10984218377939761, 0.10984218377939761, 0.23838227428699285], 
reward next is 0.7616, 
noisyNet noise sample is [array([-1.0156062], dtype=float32), 0.39864498]. 
=============================================
[2019-03-26 23:08:20,288] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.33574716e-14 9.99996781e-01 5.49743953e-13 3.18212847e-06
 5.95530130e-18], sum to 1.0000
[2019-03-26 23:08:20,299] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3942
[2019-03-26 23:08:20,305] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1697768.171898778 W.
[2019-03-26 23:08:20,309] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.16666666666666, 71.66666666666667, 1.0, 2.0, 0.6072170994878716, 1.0, 1.0, 0.6072170994878716, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1697768.171898778, 1697768.171898778, 336922.3717014553], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1251600.0000, 
sim time next is 1252200.0000, 
raw observation next is [28.18333333333333, 71.83333333333333, 1.0, 2.0, 0.622818700367065, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.92741104617648, 6.9112, 168.9127260738302, 1741439.190955781, 1729938.532546633, 370215.3128806357], 
processed observation next is [1.0, 0.4782608695652174, 0.5347551342812005, 0.7183333333333333, 1.0, 1.0, 0.5455646992374277, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.0016211046176479726, 0.0, 0.8294388136030985, 0.483733108598828, 0.48053848126295357, 0.5525601684785608], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.03650365], dtype=float32), 2.0488858]. 
=============================================
[2019-03-26 23:08:20,980] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133500, global step 2139262: loss 0.0244
[2019-03-26 23:08:20,981] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133500, global step 2139262: learning rate 0.0000
[2019-03-26 23:08:21,071] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134500, global step 2139298: loss 4.7804
[2019-03-26 23:08:21,073] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134500, global step 2139298: learning rate 0.0000
[2019-03-26 23:08:21,326] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5674944e-22 1.0000000e+00 1.1274966e-21 8.4629015e-16 4.9471382e-28], sum to 1.0000
[2019-03-26 23:08:21,335] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4498
[2019-03-26 23:08:21,339] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.76666666666667, 50.0, 1.0, 2.0, 0.5855047432689141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 967950.518668153, 967950.518668153, 212431.3586444625], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 751200.0000, 
sim time next is 751800.0000, 
raw observation next is [24.68333333333334, 50.0, 1.0, 2.0, 0.5838601693516999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 965929.806148052, 965929.8061480514, 212055.7982586904], 
processed observation next is [1.0, 0.6956521739130435, 0.3688783570300162, 0.5, 1.0, 1.0, 0.49862671006228904, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.26831383504112555, 0.2683138350411254, 0.3165011914308812], 
reward next is 0.6835, 
noisyNet noise sample is [array([-0.4109412], dtype=float32), -1.3859702]. 
=============================================
[2019-03-26 23:08:24,236] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134000, global step 2140707: loss 0.0100
[2019-03-26 23:08:24,239] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134000, global step 2140707: learning rate 0.0000
[2019-03-26 23:08:24,612] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.73548989e-22 1.00000000e+00 3.41717227e-22 1.07806125e-16
 3.47449649e-29], sum to 1.0000
[2019-03-26 23:08:24,618] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6830
[2019-03-26 23:08:24,622] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.93333333333333, 78.33333333333334, 1.0, 2.0, 0.2323642358406649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 385292.552640969, 385292.5526409696, 159036.8003015741], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 595200.0000, 
sim time next is 595800.0000, 
raw observation next is [19.8, 79.0, 1.0, 2.0, 0.2310095872077869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 383200.1827555802, 383200.1827555795, 158893.0554673192], 
processed observation next is [1.0, 0.9130434782608695, 0.13744075829383895, 0.79, 1.0, 1.0, 0.07350552675636973, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10644449520988337, 0.10644449520988318, 0.23715381413032718], 
reward next is 0.7628, 
noisyNet noise sample is [array([-0.3857233], dtype=float32), 0.443654]. 
=============================================
[2019-03-26 23:08:24,964] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133500, global step 2141026: loss 0.0236
[2019-03-26 23:08:24,966] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133500, global step 2141027: learning rate 0.0000
[2019-03-26 23:08:25,330] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134500, global step 2141191: loss 4.8165
[2019-03-26 23:08:25,333] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134500, global step 2141192: learning rate 0.0000
[2019-03-26 23:08:25,498] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133500, global step 2141264: loss 0.0226
[2019-03-26 23:08:25,499] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133500, global step 2141265: learning rate 0.0000
[2019-03-26 23:08:25,509] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133500, global step 2141270: loss 0.0221
[2019-03-26 23:08:25,511] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133500, global step 2141270: learning rate 0.0000
[2019-03-26 23:08:25,534] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133500, global step 2141279: loss 0.0225
[2019-03-26 23:08:25,536] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133500, global step 2141279: learning rate 0.0000
[2019-03-26 23:08:25,566] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133500, global step 2141293: loss 0.0230
[2019-03-26 23:08:25,568] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133500, global step 2141293: learning rate 0.0000
[2019-03-26 23:08:25,605] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133500, global step 2141312: loss 0.0233
[2019-03-26 23:08:25,609] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133500, global step 2141312: learning rate 0.0000
[2019-03-26 23:08:25,649] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133500, global step 2141334: loss 0.0226
[2019-03-26 23:08:25,652] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133500, global step 2141334: learning rate 0.0000
[2019-03-26 23:08:25,799] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133500, global step 2141397: loss 0.0231
[2019-03-26 23:08:25,801] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133500, global step 2141397: learning rate 0.0000
[2019-03-26 23:08:28,571] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.9992231e-25 1.0000000e+00 8.1686436e-24 1.6581157e-19 3.0002676e-30], sum to 1.0000
[2019-03-26 23:08:28,582] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3155
[2019-03-26 23:08:28,594] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.01666666666667, 68.0, 1.0, 2.0, 0.2904095887404655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 464791.6358541481, 464791.6358541474, 164583.6680689902], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 813000.0000, 
sim time next is 813600.0000, 
raw observation next is [24.2, 67.0, 1.0, 2.0, 0.2913297578531947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 466062.1251034755, 466062.1251034748, 164669.3506602364], 
processed observation next is [0.0, 0.43478260869565216, 0.3459715639810427, 0.67, 1.0, 1.0, 0.14618043114842735, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12946170141763208, 0.12946170141763189, 0.24577515023915883], 
reward next is 0.7542, 
noisyNet noise sample is [array([-0.71896315], dtype=float32), -1.4386137]. 
=============================================
[2019-03-26 23:08:28,952] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1535383e-22 1.0000000e+00 4.9263250e-22 5.3723518e-17 6.4291616e-29], sum to 1.0000
[2019-03-26 23:08:28,959] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0003
[2019-03-26 23:08:28,966] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 58.0, 1.0, 2.0, 0.2390808087388393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 393206.1058125191, 393206.1058125191, 159851.4308128346], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 668400.0000, 
sim time next is 669000.0000, 
raw observation next is [23.61666666666667, 59.0, 1.0, 2.0, 0.2432724582250208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 400281.1823143181, 400281.1823143174, 160248.1785644904], 
processed observation next is [1.0, 0.7391304347826086, 0.31832543443917877, 0.59, 1.0, 1.0, 0.08828007015062747, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1111892173095328, 0.1111892173095326, 0.23917638591714985], 
reward next is 0.7608, 
noisyNet noise sample is [array([-1.2260095], dtype=float32), -1.5103903]. 
=============================================
[2019-03-26 23:08:28,990] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[75.25078 ]
 [75.00047 ]
 [74.74767 ]
 [74.34114 ]
 [73.922966]], R is [[75.4045639 ]
 [75.4119339 ]
 [75.41947937]
 [75.42630768]
 [75.42024994]].
[2019-03-26 23:08:30,938] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134000, global step 2143692: loss 0.0114
[2019-03-26 23:08:30,943] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134000, global step 2143693: learning rate 0.0000
[2019-03-26 23:08:31,661] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.8643801e-25 1.0000000e+00 1.6514779e-23 1.9005750e-19 1.1857639e-30], sum to 1.0000
[2019-03-26 23:08:31,671] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8474
[2019-03-26 23:08:31,676] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 70.0, 1.0, 2.0, 0.4530481645940554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 639946.9700882114, 639946.9700882114, 177459.5854733691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1440000.0000, 
sim time next is 1440600.0000, 
raw observation next is [27.93333333333334, 69.83333333333334, 1.0, 2.0, 0.4519402142382168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 639298.9911641382, 639298.9911641382, 177417.5316918393], 
processed observation next is [0.0, 0.6956521739130435, 0.5229067930489735, 0.6983333333333335, 1.0, 1.0, 0.3396870051062853, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1775830531011495, 0.1775830531011495, 0.26480228610722284], 
reward next is 0.7352, 
noisyNet noise sample is [array([0.3953857], dtype=float32), -0.32156208]. 
=============================================
[2019-03-26 23:08:33,218] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2950088e-24 1.0000000e+00 5.2858958e-24 2.4676358e-20 1.4088173e-30], sum to 1.0000
[2019-03-26 23:08:33,228] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8688
[2019-03-26 23:08:33,237] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 64.0, 1.0, 2.0, 0.2917469936813316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 466636.1393664615, 466636.1393664609, 164708.0811510054], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 815400.0000, 
sim time next is 816000.0000, 
raw observation next is [24.86666666666667, 63.0, 1.0, 2.0, 0.2916183816817502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 466458.0325844144, 466458.0325844144, 164696.0388962524], 
processed observation next is [0.0, 0.43478260869565216, 0.3775671406003162, 0.63, 1.0, 1.0, 0.14652817070090385, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12957167571789288, 0.12957167571789288, 0.2458149834272424], 
reward next is 0.7542, 
noisyNet noise sample is [array([0.49192268], dtype=float32), 0.8770878]. 
=============================================
[2019-03-26 23:08:33,251] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[78.439384]
 [78.43279 ]
 [78.422714]
 [78.39959 ]
 [78.3744  ]], R is [[78.41822052]
 [78.38820648]
 [78.35847473]
 [78.32905579]
 [78.29999542]].
[2019-03-26 23:08:34,421] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134000, global step 2145247: loss 0.0123
[2019-03-26 23:08:34,423] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134000, global step 2145247: learning rate 0.0000
[2019-03-26 23:08:35,682] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.7055356e-24 1.0000000e+00 5.8611431e-23 8.8120088e-18 3.2126486e-29], sum to 1.0000
[2019-03-26 23:08:35,693] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8488
[2019-03-26 23:08:35,698] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.43333333333333, 91.66666666666666, 1.0, 2.0, 0.2594312418392346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 424664.7965696771, 424664.7965696771, 161844.985704398], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 783600.0000, 
sim time next is 784200.0000, 
raw observation next is [19.41666666666667, 91.83333333333333, 1.0, 2.0, 0.2596210836681977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 424958.8554000512, 424958.8554000505, 161864.003403954], 
processed observation next is [0.0, 0.043478260869565216, 0.11927330173775699, 0.9183333333333333, 1.0, 1.0, 0.1079772092387924, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11804412650001422, 0.11804412650001403, 0.2415880647820209], 
reward next is 0.7584, 
noisyNet noise sample is [array([-1.8391865], dtype=float32), 1.4167331]. 
=============================================
[2019-03-26 23:08:35,924] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135000, global step 2145916: loss 0.0161
[2019-03-26 23:08:35,926] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135000, global step 2145916: learning rate 0.0000
[2019-03-26 23:08:36,523] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134500, global step 2146184: loss 4.8981
[2019-03-26 23:08:36,525] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134500, global step 2146185: learning rate 0.0000
[2019-03-26 23:08:37,556] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.77556450e-24 1.00000000e+00 1.17900705e-23 1.10569827e-19
 2.19745560e-30], sum to 1.0000
[2019-03-26 23:08:37,563] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6659
[2019-03-26 23:08:37,569] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 73.0, 1.0, 2.0, 0.2874972932357521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 461288.1406071365, 461288.1406071359, 164353.5380346968], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 810000.0000, 
sim time next is 810600.0000, 
raw observation next is [23.28333333333334, 72.0, 1.0, 2.0, 0.2879159252798174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 461782.0591718462, 461782.0591718456, 164385.9963950096], 
processed observation next is [0.0, 0.391304347826087, 0.30252764612954214, 0.72, 1.0, 1.0, 0.14206737985520168, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12827279421440171, 0.12827279421440155, 0.24535223342538745], 
reward next is 0.7546, 
noisyNet noise sample is [array([-0.57550865], dtype=float32), -1.2556576]. 
=============================================
[2019-03-26 23:08:37,788] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2574048e-24 1.0000000e+00 3.6491226e-23 8.4083407e-20 5.6395972e-30], sum to 1.0000
[2019-03-26 23:08:37,796] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5450
[2019-03-26 23:08:37,800] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 98.5, 1.0, 2.0, 0.3117303422212508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 493617.1412787182, 493617.1412787182, 166563.9223591993], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1485000.0000, 
sim time next is 1485600.0000, 
raw observation next is [20.33333333333333, 98.66666666666667, 1.0, 2.0, 0.3104452244773311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 492129.4430516197, 492129.4430516197, 166464.6233860319], 
processed observation next is [0.0, 0.17391304347826086, 0.16271721958925733, 0.9866666666666667, 1.0, 1.0, 0.16921111382810974, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13670262306989436, 0.13670262306989436, 0.24845466177019684], 
reward next is 0.7515, 
noisyNet noise sample is [array([-0.7501585], dtype=float32), 0.41597572]. 
=============================================
[2019-03-26 23:08:39,009] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134000, global step 2147271: loss 0.0079
[2019-03-26 23:08:39,014] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134000, global step 2147272: learning rate 0.0000
[2019-03-26 23:08:39,427] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135000, global step 2147459: loss 0.0117
[2019-03-26 23:08:39,428] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135000, global step 2147459: learning rate 0.0000
[2019-03-26 23:08:42,100] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134500, global step 2148649: loss 4.6078
[2019-03-26 23:08:42,101] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134500, global step 2148649: learning rate 0.0000
[2019-03-26 23:08:42,855] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134000, global step 2148985: loss 0.0048
[2019-03-26 23:08:42,857] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134000, global step 2148986: learning rate 0.0000
[2019-03-26 23:08:43,292] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134000, global step 2149181: loss 0.0043
[2019-03-26 23:08:43,294] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134000, global step 2149181: learning rate 0.0000
[2019-03-26 23:08:43,432] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6631828e-24 1.0000000e+00 1.4133447e-22 7.3685851e-17 1.1084927e-29], sum to 1.0000
[2019-03-26 23:08:43,441] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3612
[2019-03-26 23:08:43,444] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.25, 88.16666666666667, 1.0, 2.0, 0.2994230330085953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 478242.5696574055, 478242.5696574049, 165515.9688794796], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1120200.0000, 
sim time next is 1120800.0000, 
raw observation next is [21.2, 88.33333333333334, 1.0, 2.0, 0.2985829738507878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 477188.8610938953, 477188.8610938959, 165444.4198335722], 
processed observation next is [1.0, 1.0, 0.20379146919431282, 0.8833333333333334, 1.0, 1.0, 0.1549192456033588, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1325524614149709, 0.1325524614149711, 0.24693196990085403], 
reward next is 0.7531, 
noisyNet noise sample is [array([-0.33995482], dtype=float32), -0.61406267]. 
=============================================
[2019-03-26 23:08:43,451] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134000, global step 2149248: loss 0.0039
[2019-03-26 23:08:43,453] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134000, global step 2149249: learning rate 0.0000
[2019-03-26 23:08:43,462] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134000, global step 2149253: loss 0.0045
[2019-03-26 23:08:43,467] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134000, global step 2149254: learning rate 0.0000
[2019-03-26 23:08:43,545] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134000, global step 2149291: loss 0.0043
[2019-03-26 23:08:43,546] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134000, global step 2149291: learning rate 0.0000
[2019-03-26 23:08:43,559] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135000, global step 2149297: loss 0.0059
[2019-03-26 23:08:43,562] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135000, global step 2149299: learning rate 0.0000
[2019-03-26 23:08:43,680] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134000, global step 2149347: loss 0.0051
[2019-03-26 23:08:43,683] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134000, global step 2149349: learning rate 0.0000
[2019-03-26 23:08:43,740] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134000, global step 2149375: loss 0.0042
[2019-03-26 23:08:43,750] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134000, global step 2149376: learning rate 0.0000
[2019-03-26 23:08:43,800] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134000, global step 2149399: loss 0.0041
[2019-03-26 23:08:43,803] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134000, global step 2149401: learning rate 0.0000
[2019-03-26 23:08:45,140] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 23:08:45,141] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 23:08:45,142] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 23:08:45,143] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:08:45,143] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:08:45,145] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 23:08:45,146] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 23:08:45,148] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 23:08:45,149] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:08:45,150] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:08:45,151] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:08:45,180] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run87
[2019-03-26 23:08:45,214] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run87
[2019-03-26 23:08:45,215] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run87
[2019-03-26 23:08:45,235] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run87
[2019-03-26 23:08:45,290] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run87
[2019-03-26 23:08:49,974] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09692997], dtype=float32), 0.076190464]
[2019-03-26 23:08:49,974] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [18.88138579, 97.55397287000001, 1.0, 2.0, 0.2747617191977456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 448112.6697354084, 448112.6697354077, 163401.3240717831]
[2019-03-26 23:08:49,975] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:08:49,978] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.9413830e-24 1.0000000e+00 2.0115579e-23 2.8132643e-19 3.2196768e-30], sampled 0.510409491816083
[2019-03-26 23:08:56,765] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09692997], dtype=float32), 0.076190464]
[2019-03-26 23:08:56,767] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.85, 76.5, 1.0, 2.0, 0.2425875134384144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 399756.4703239303, 399756.4703239303, 160167.4752617245]
[2019-03-26 23:08:56,769] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:08:56,771] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.8973692e-23 1.0000000e+00 7.7502523e-23 4.1577670e-19 1.9712232e-29], sampled 0.47636501241782325
[2019-03-26 23:09:01,590] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09692997], dtype=float32), 0.076190464]
[2019-03-26 23:09:01,593] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.43333333333333, 96.66666666666667, 1.0, 2.0, 0.3371600872445006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 522255.1675875294, 522255.1675875288, 168469.7412859084]
[2019-03-26 23:09:01,595] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:09:01,597] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.4489471e-24 1.0000000e+00 3.2314639e-23 8.2425363e-19 4.5372863e-30], sampled 0.7199356796518287
[2019-03-26 23:09:19,333] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09692997], dtype=float32), 0.076190464]
[2019-03-26 23:09:19,334] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.69706901166667, 82.57884657666668, 1.0, 2.0, 0.6711330548491133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 937909.7519094575, 937909.7519094582, 214739.8764975242]
[2019-03-26 23:09:19,335] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:09:19,338] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.313185e-24 1.000000e+00 5.606391e-23 3.615186e-18 8.239818e-30], sampled 0.8161177454459663
[2019-03-26 23:09:26,943] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09692997], dtype=float32), 0.076190464]
[2019-03-26 23:09:26,946] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.33253502666667, 94.41277731000001, 1.0, 2.0, 0.27992854331726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 452053.3028396777, 452053.3028396777, 163736.6675930346]
[2019-03-26 23:09:26,948] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:09:26,950] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0003698e-23 1.0000000e+00 4.6124656e-23 7.0040546e-19 8.6173539e-30], sampled 0.1430378049789679
[2019-03-26 23:09:35,068] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09692997], dtype=float32), 0.076190464]
[2019-03-26 23:09:35,070] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.5, 58.33333333333333, 1.0, 2.0, 0.5139017909961018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 718104.4750260015, 718104.4750260015, 185802.5288188368]
[2019-03-26 23:09:35,071] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:09:35,075] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.3760284e-25 1.0000000e+00 5.4079452e-24 1.8222870e-18 7.8865463e-31], sampled 0.7559110056499398
[2019-03-26 23:09:53,669] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09692997], dtype=float32), 0.076190464]
[2019-03-26 23:09:53,670] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.0, 71.0, 1.0, 2.0, 0.9247845665698758, 1.0, 1.0, 0.7829823227992007, 1.0, 2.0, 1.03, 7.005115462907887, 6.9112, 170.5573041426782, 3286005.142068423, 3218729.675750724, 601735.0846972367]
[2019-03-26 23:09:53,673] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:09:53,675] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.2982802e-14 9.3133241e-01 2.5057166e-11 6.8667524e-02 3.4866444e-17], sampled 0.06743553449799922
[2019-03-26 23:09:53,676] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 3286005.142068423 W.
[2019-03-26 23:10:22,020] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09692997], dtype=float32), 0.076190464]
[2019-03-26 23:10:22,021] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.43333333333333, 94.33333333333334, 1.0, 2.0, 0.4835889755826049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 681070.5732223535, 681070.5732223535, 181751.4326697218]
[2019-03-26 23:10:22,022] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:10:22,023] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.6537315e-24 1.0000000e+00 2.1612007e-23 4.9975016e-19 3.5712880e-30], sampled 0.40497735327439266
[2019-03-26 23:10:24,788] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09692997], dtype=float32), 0.076190464]
[2019-03-26 23:10:24,789] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.16598394666667, 93.12423390333333, 1.0, 2.0, 0.5047632202842258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 705330.3859888223, 705330.3859888216, 184344.8029507454]
[2019-03-26 23:10:24,790] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:10:24,793] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.4638707e-24 1.0000000e+00 3.4876535e-23 1.9478079e-18 4.3237323e-30], sampled 0.778271067284993
[2019-03-26 23:10:35,193] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.3273 2927391892.5307 1338.0000
[2019-03-26 23:10:35,229] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8500.6699 2842088183.4708 1121.0000
[2019-03-26 23:10:35,238] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.1107 2779357014.0512 933.0000
[2019-03-26 23:10:35,615] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8000.7672 3007325631.3005 1762.0000
[2019-03-26 23:10:35,623] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7889.2998 3164459697.7133 1764.0000
[2019-03-26 23:10:36,640] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2150000, evaluation results [2150000.0, 7889.299811161196, 3164459697.7132683, 1764.0, 8254.327253941756, 2927391892.530706, 1338.0, 8659.110737646277, 2779357014.0511723, 933.0, 8000.767193812355, 3007325631.3004565, 1762.0, 8500.669903488815, 2842088183.470773, 1121.0]
[2019-03-26 23:10:40,358] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134500, global step 2151665: loss 4.5311
[2019-03-26 23:10:40,361] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134500, global step 2151666: learning rate 0.0000
[2019-03-26 23:10:43,851] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134500, global step 2153221: loss 4.4704
[2019-03-26 23:10:43,855] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134500, global step 2153223: learning rate 0.0000
[2019-03-26 23:10:43,975] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.2188237e-14 7.6532826e-02 5.2125353e-11 9.2346722e-01 2.3268440e-16], sum to 1.0000
[2019-03-26 23:10:43,986] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9246
[2019-03-26 23:10:43,990] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.9, 75.5, 1.0, 2.0, 0.6919283849424457, 1.0, 2.0, 0.6919283849424457, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1934833.258293882, 1934833.258293882, 370678.8225513826], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1269000.0000, 
sim time next is 1269600.0000, 
raw observation next is [27.86666666666667, 75.66666666666667, 1.0, 2.0, 0.603746024146496, 1.0, 2.0, 0.603746024146496, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1688055.46332489, 1688055.46332489, 335631.1251912976], 
processed observation next is [1.0, 0.6956521739130435, 0.519747235387046, 0.7566666666666667, 1.0, 1.0, 0.5225855712608386, 1.0, 1.0, 0.5225855712608386, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.468904295368025, 0.468904295368025, 0.5009419778974591], 
reward next is 0.4991, 
noisyNet noise sample is [array([0.14762467], dtype=float32), -0.21080187]. 
=============================================
[2019-03-26 23:10:45,291] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135500, global step 2153865: loss 0.0138
[2019-03-26 23:10:45,294] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135500, global step 2153866: learning rate 0.0000
[2019-03-26 23:10:46,248] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135000, global step 2154287: loss 0.0023
[2019-03-26 23:10:46,250] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135000, global step 2154289: learning rate 0.0000
[2019-03-26 23:10:48,426] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134500, global step 2155259: loss 4.4422
[2019-03-26 23:10:48,429] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134500, global step 2155259: learning rate 0.0000
[2019-03-26 23:10:48,480] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.9699455e-25 1.0000000e+00 8.5253066e-24 2.2808161e-19 4.6750844e-31], sum to 1.0000
[2019-03-26 23:10:48,491] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1431
[2019-03-26 23:10:48,498] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.35, 89.5, 1.0, 2.0, 0.3446836717122636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 534035.2358530081, 534035.2358530075, 169418.3342282879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1549800.0000, 
sim time next is 1550400.0000, 
raw observation next is [22.26666666666667, 90.0, 1.0, 2.0, 0.3444579342784178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 533972.0111294887, 533972.0111294887, 169421.1715931408], 
processed observation next is [0.0, 0.9565217391304348, 0.2543443917851502, 0.9, 1.0, 1.0, 0.21019028226315398, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1483255586470802, 0.1483255586470802, 0.25286742028826986], 
reward next is 0.7471, 
noisyNet noise sample is [array([-0.38147178], dtype=float32), -2.1777318]. 
=============================================
[2019-03-26 23:10:49,076] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135500, global step 2155545: loss 0.0157
[2019-03-26 23:10:49,083] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135500, global step 2155545: learning rate 0.0000
[2019-03-26 23:10:51,752] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135000, global step 2156720: loss 0.0027
[2019-03-26 23:10:51,756] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135000, global step 2156720: learning rate 0.0000
[2019-03-26 23:10:52,251] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134500, global step 2156942: loss 4.4126
[2019-03-26 23:10:52,253] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134500, global step 2156943: learning rate 0.0000
[2019-03-26 23:10:52,672] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134500, global step 2157132: loss 4.4105
[2019-03-26 23:10:52,674] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134500, global step 2157132: learning rate 0.0000
[2019-03-26 23:10:52,813] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134500, global step 2157195: loss 4.4458
[2019-03-26 23:10:52,815] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134500, global step 2157196: learning rate 0.0000
[2019-03-26 23:10:52,823] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134500, global step 2157197: loss 4.4299
[2019-03-26 23:10:52,825] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134500, global step 2157197: learning rate 0.0000
[2019-03-26 23:10:52,855] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134500, global step 2157211: loss 4.4415
[2019-03-26 23:10:52,857] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134500, global step 2157212: learning rate 0.0000
[2019-03-26 23:10:52,860] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134500, global step 2157213: loss 4.3922
[2019-03-26 23:10:52,864] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134500, global step 2157213: learning rate 0.0000
[2019-03-26 23:10:53,064] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135500, global step 2157303: loss 0.0160
[2019-03-26 23:10:53,067] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135500, global step 2157303: learning rate 0.0000
[2019-03-26 23:10:53,201] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134500, global step 2157363: loss 4.4504
[2019-03-26 23:10:53,205] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134500, global step 2157365: learning rate 0.0000
[2019-03-26 23:10:53,306] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134500, global step 2157410: loss 4.4591
[2019-03-26 23:10:53,308] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134500, global step 2157410: learning rate 0.0000
[2019-03-26 23:10:58,139] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135000, global step 2159562: loss 0.0015
[2019-03-26 23:10:58,142] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135000, global step 2159563: learning rate 0.0000
[2019-03-26 23:10:59,157] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.4030869e-24 1.0000000e+00 7.6463798e-24 6.5483257e-19 4.6737293e-31], sum to 1.0000
[2019-03-26 23:10:59,166] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8532
[2019-03-26 23:10:59,170] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 96.0, 1.0, 2.0, 0.3572979927717415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 548995.5839576753, 548995.5839576758, 170522.2986247193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1468200.0000, 
sim time next is 1468800.0000, 
raw observation next is [21.8, 96.0, 1.0, 2.0, 0.3566330248468683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 548512.7026637949, 548512.7026637949, 170497.4604648544], 
processed observation next is [0.0, 0.0, 0.23222748815165886, 0.96, 1.0, 1.0, 0.22485906608056425, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1523646396288319, 0.1523646396288319, 0.25447382158933496], 
reward next is 0.7455, 
noisyNet noise sample is [array([0.58451116], dtype=float32), 1.8869438]. 
=============================================
[2019-03-26 23:10:59,351] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9887284e-24 1.0000000e+00 9.5568953e-23 1.5825964e-18 6.6003530e-30], sum to 1.0000
[2019-03-26 23:10:59,360] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9067
[2019-03-26 23:10:59,364] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 63.66666666666667, 1.0, 2.0, 0.345033003962754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 533590.4046474983, 533590.4046474977, 169354.2843945845], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1532400.0000, 
sim time next is 1533000.0000, 
raw observation next is [26.1, 64.83333333333333, 1.0, 2.0, 0.3440100814731696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 531925.144956696, 531925.1449566953, 169216.9894561035], 
processed observation next is [0.0, 0.7391304347826086, 0.4360189573459717, 0.6483333333333333, 1.0, 1.0, 0.20965070057008384, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14775698471019333, 0.14775698471019313, 0.2525626708300052], 
reward next is 0.7474, 
noisyNet noise sample is [array([-1.0702595], dtype=float32), -0.63997847]. 
=============================================
[2019-03-26 23:10:59,378] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[78.193405]
 [78.15533 ]
 [78.11639 ]
 [78.0761  ]
 [78.02146 ]], R is [[78.18630981]
 [78.15167999]
 [78.11743164]
 [78.08358002]
 [78.05014801]].
[2019-03-26 23:11:01,716] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135000, global step 2161159: loss 0.0006
[2019-03-26 23:11:01,720] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135000, global step 2161160: learning rate 0.0000
[2019-03-26 23:11:03,508] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136000, global step 2161963: loss 0.0131
[2019-03-26 23:11:03,511] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136000, global step 2161963: learning rate 0.0000
[2019-03-26 23:11:04,119] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135500, global step 2162233: loss 0.0203
[2019-03-26 23:11:04,121] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135500, global step 2162233: learning rate 0.0000
[2019-03-26 23:11:06,248] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.865973e-24 1.000000e+00 5.095669e-23 7.075163e-19 8.401372e-30], sum to 1.0000
[2019-03-26 23:11:06,257] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6847
[2019-03-26 23:11:06,260] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 84.0, 1.0, 2.0, 0.4177568822889548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 609179.9531312601, 609179.9531312594, 174987.1664184877], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1427400.0000, 
sim time next is 1428000.0000, 
raw observation next is [25.33333333333333, 82.33333333333334, 1.0, 2.0, 0.4220432983190036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 613200.330282592, 613200.3302825913, 175305.1974712079], 
processed observation next is [0.0, 0.5217391304347826, 0.3996840442338071, 0.8233333333333335, 1.0, 1.0, 0.3036666244807273, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17033342507849777, 0.17033342507849758, 0.2616495484644894], 
reward next is 0.7384, 
noisyNet noise sample is [array([-0.38580543], dtype=float32), -0.53244424]. 
=============================================
[2019-03-26 23:11:06,273] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[77.37134]
 [77.35607]
 [77.32447]
 [77.27253]
 [77.20675]], R is [[77.34319305]
 [77.30858612]
 [77.27485657]
 [77.24204254]
 [77.21011353]].
[2019-03-26 23:11:06,591] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135000, global step 2163331: loss 0.0009
[2019-03-26 23:11:06,597] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135000, global step 2163331: learning rate 0.0000
[2019-03-26 23:11:07,140] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136000, global step 2163542: loss 0.0113
[2019-03-26 23:11:07,142] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136000, global step 2163542: learning rate 0.0000
[2019-03-26 23:11:09,633] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135500, global step 2164652: loss 0.0271
[2019-03-26 23:11:09,636] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135500, global step 2164653: learning rate 0.0000
[2019-03-26 23:11:10,431] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135000, global step 2165008: loss 0.0001
[2019-03-26 23:11:10,432] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135000, global step 2165008: learning rate 0.0000
[2019-03-26 23:11:10,684] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135000, global step 2165118: loss 0.0002
[2019-03-26 23:11:10,689] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135000, global step 2165121: learning rate 0.0000
[2019-03-26 23:11:10,815] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135000, global step 2165181: loss 0.0002
[2019-03-26 23:11:10,819] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135000, global step 2165181: learning rate 0.0000
[2019-03-26 23:11:10,920] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4622307e-22 1.0000000e+00 4.7092730e-23 8.5732359e-19 5.1055353e-30], sum to 1.0000
[2019-03-26 23:11:10,927] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7994
[2019-03-26 23:11:10,932] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 51.0, 1.0, 2.0, 0.3428707597271431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527662.0149253301, 527662.0149253301, 168795.5129784984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1510800.0000, 
sim time next is 1511400.0000, 
raw observation next is [29.05, 51.0, 1.0, 2.0, 0.3449039851276267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 530137.3790334774, 530137.3790334767, 168974.470872795], 
processed observation next is [0.0, 0.4782608695652174, 0.575829383886256, 0.51, 1.0, 1.0, 0.21072769292485147, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14726038306485484, 0.14726038306485464, 0.25220070279521645], 
reward next is 0.7478, 
noisyNet noise sample is [array([-0.62674063], dtype=float32), 0.42853174]. 
=============================================
[2019-03-26 23:11:10,934] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135000, global step 2165226: loss 0.0002
[2019-03-26 23:11:10,937] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135000, global step 2165226: learning rate 0.0000
[2019-03-26 23:11:10,979] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135000, global step 2165250: loss 0.0002
[2019-03-26 23:11:10,983] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135000, global step 2165252: learning rate 0.0000
[2019-03-26 23:11:11,023] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135000, global step 2165269: loss 0.0002
[2019-03-26 23:11:11,025] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135000, global step 2165269: learning rate 0.0000
[2019-03-26 23:11:11,224] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136000, global step 2165356: loss 0.0062
[2019-03-26 23:11:11,225] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136000, global step 2165356: learning rate 0.0000
[2019-03-26 23:11:11,248] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135000, global step 2165362: loss 0.0002
[2019-03-26 23:11:11,251] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135000, global step 2165362: learning rate 0.0000
[2019-03-26 23:11:11,340] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135000, global step 2165399: loss 0.0002
[2019-03-26 23:11:11,342] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135000, global step 2165400: learning rate 0.0000
[2019-03-26 23:11:12,780] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0466774e-23 1.0000000e+00 5.2727099e-22 3.4369495e-16 4.9630703e-29], sum to 1.0000
[2019-03-26 23:11:12,793] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9244
[2019-03-26 23:11:12,797] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.26666666666667, 93.33333333333334, 1.0, 2.0, 0.7747718840818051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1148471.143816504, 1148471.143816504, 246683.8978784679], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1614000.0000, 
sim time next is 1614600.0000, 
raw observation next is [23.2, 94.0, 1.0, 2.0, 0.7547092638807567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1118050.769086616, 1118050.769086617, 241571.1496205619], 
processed observation next is [1.0, 0.6956521739130435, 0.29857819905213273, 0.94, 1.0, 1.0, 0.7044689926274177, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31056965807961556, 0.31056965807961584, 0.3605539546575551], 
reward next is 0.6394, 
noisyNet noise sample is [array([-1.222539], dtype=float32), 0.91895044]. 
=============================================
[2019-03-26 23:11:16,209] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135500, global step 2167573: loss 0.0295
[2019-03-26 23:11:16,214] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135500, global step 2167575: learning rate 0.0000
[2019-03-26 23:11:19,819] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135500, global step 2169180: loss 0.0264
[2019-03-26 23:11:19,821] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135500, global step 2169181: learning rate 0.0000
[2019-03-26 23:11:22,079] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136500, global step 2170175: loss 0.0061
[2019-03-26 23:11:22,081] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136500, global step 2170175: learning rate 0.0000
[2019-03-26 23:11:22,243] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136000, global step 2170248: loss 0.0059
[2019-03-26 23:11:22,248] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136000, global step 2170248: learning rate 0.0000
[2019-03-26 23:11:23,260] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1082312e-23 1.0000000e+00 3.3463646e-22 4.6274448e-16 4.5348488e-29], sum to 1.0000
[2019-03-26 23:11:23,272] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9510
[2019-03-26 23:11:23,283] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.26666666666667, 89.66666666666667, 1.0, 2.0, 0.5123012526966388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 715867.1973606171, 715867.1973606177, 185545.9182122971], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1718400.0000, 
sim time next is 1719000.0000, 
raw observation next is [26.2, 90.0, 1.0, 2.0, 0.5119653103027512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 715397.6081871933, 715397.6081871933, 185492.0489836382], 
processed observation next is [1.0, 0.9130434782608695, 0.44075829383886256, 0.9, 1.0, 1.0, 0.41200639795512184, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1987215578297759, 0.1987215578297759, 0.27685380445319135], 
reward next is 0.7231, 
noisyNet noise sample is [array([1.0358735], dtype=float32), -0.2526809]. 
=============================================
[2019-03-26 23:11:23,296] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[74.23813 ]
 [74.19743 ]
 [74.6654  ]
 [75.127106]
 [75.926674]], R is [[74.17478943]
 [74.15611267]
 [74.13786316]
 [74.12010193]
 [74.10279083]].
[2019-03-26 23:11:24,806] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135500, global step 2171385: loss 0.0340
[2019-03-26 23:11:24,809] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135500, global step 2171386: learning rate 0.0000
[2019-03-26 23:11:25,328] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136500, global step 2171615: loss 0.0094
[2019-03-26 23:11:25,329] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136500, global step 2171617: learning rate 0.0000
[2019-03-26 23:11:27,280] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136000, global step 2172488: loss 0.0029
[2019-03-26 23:11:27,283] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136000, global step 2172488: learning rate 0.0000
[2019-03-26 23:11:28,339] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135500, global step 2172959: loss 0.0411
[2019-03-26 23:11:28,343] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135500, global step 2172962: learning rate 0.0000
[2019-03-26 23:11:28,588] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135500, global step 2173065: loss 0.0403
[2019-03-26 23:11:28,590] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135500, global step 2173066: learning rate 0.0000
[2019-03-26 23:11:28,755] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135500, global step 2173141: loss 0.0401
[2019-03-26 23:11:28,760] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135500, global step 2173143: learning rate 0.0000
[2019-03-26 23:11:28,771] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135500, global step 2173149: loss 0.0404
[2019-03-26 23:11:28,773] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135500, global step 2173149: learning rate 0.0000
[2019-03-26 23:11:28,860] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135500, global step 2173188: loss 0.0392
[2019-03-26 23:11:28,862] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135500, global step 2173189: learning rate 0.0000
[2019-03-26 23:11:28,921] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135500, global step 2173217: loss 0.0391
[2019-03-26 23:11:28,923] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135500, global step 2173217: learning rate 0.0000
[2019-03-26 23:11:28,974] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135500, global step 2173239: loss 0.0397
[2019-03-26 23:11:28,975] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135500, global step 2173240: learning rate 0.0000
[2019-03-26 23:11:29,272] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135500, global step 2173375: loss 0.0398
[2019-03-26 23:11:29,275] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135500, global step 2173375: learning rate 0.0000
[2019-03-26 23:11:29,606] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136500, global step 2173523: loss 0.0378
[2019-03-26 23:11:29,609] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136500, global step 2173523: learning rate 0.0000
[2019-03-26 23:11:31,404] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.1685642e-22 1.0000000e+00 2.5102165e-21 2.4435881e-14 1.5592723e-27], sum to 1.0000
[2019-03-26 23:11:31,414] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8231
[2019-03-26 23:11:31,420] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.63333333333333, 84.33333333333334, 1.0, 2.0, 0.7969237828233532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1113794.727662552, 1113794.727662553, 243157.0469207724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2442000.0000, 
sim time next is 2442600.0000, 
raw observation next is [27.65, 84.5, 1.0, 2.0, 0.8090034999362989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1130686.541939168, 1130686.541939169, 246132.8662682403], 
processed observation next is [1.0, 0.2608695652173913, 0.509478672985782, 0.845, 1.0, 1.0, 0.7698837348630108, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31407959498310223, 0.3140795949831025, 0.3673624869675228], 
reward next is 0.6326, 
noisyNet noise sample is [array([-1.0014619], dtype=float32), 1.4215872]. 
=============================================
[2019-03-26 23:11:32,919] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-26 23:11:32,922] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 23:11:32,926] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:11:32,926] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 23:11:32,928] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:11:32,929] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 23:11:32,929] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 23:11:32,930] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:11:32,931] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 23:11:32,934] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:11:32,936] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:11:32,957] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run88
[2019-03-26 23:11:32,982] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run88
[2019-03-26 23:11:33,015] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run88
[2019-03-26 23:11:33,016] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run88
[2019-03-26 23:11:33,060] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run88
[2019-03-26 23:11:49,897] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09473894], dtype=float32), 0.074177034]
[2019-03-26 23:11:49,902] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.08095348833333, 76.06471635666666, 1.0, 2.0, 0.458885023122568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 697669.9968980218, 697669.9968980211, 184311.3284562952]
[2019-03-26 23:11:49,903] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:11:49,910] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.8649191e-23 1.0000000e+00 2.5349456e-22 3.2082576e-18 7.5494402e-29], sampled 0.23865714360044088
[2019-03-26 23:11:51,582] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09473894], dtype=float32), 0.074177034]
[2019-03-26 23:11:51,582] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.00305512, 75.93290932, 1.0, 2.0, 0.3774179090829564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 574486.1579323133, 574486.1579323133, 172561.6127301076]
[2019-03-26 23:11:51,583] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:11:51,587] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.8481070e-24 1.0000000e+00 6.4886593e-23 8.9945204e-18 1.4285983e-29], sampled 0.5566235540878764
[2019-03-26 23:12:00,155] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09473894], dtype=float32), 0.074177034]
[2019-03-26 23:12:00,156] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.96259082666667, 79.51654654666667, 1.0, 2.0, 0.3416945753259945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 548169.7474479645, 548169.7474479645, 170814.6496672063]
[2019-03-26 23:12:00,157] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:12:00,162] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.35568870e-23 1.00000000e+00 1.02346467e-22 3.41321894e-18
 2.09071763e-29], sampled 0.8808576776767507
[2019-03-26 23:12:07,508] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09473894], dtype=float32), 0.074177034]
[2019-03-26 23:12:07,510] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.72424139666667, 86.33408204666667, 1.0, 2.0, 0.5521246000002187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 771534.7976268814, 771534.797626882, 192162.9125673186]
[2019-03-26 23:12:07,512] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:12:07,515] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.6689711e-23 1.0000000e+00 1.6852659e-22 7.1648499e-18 3.7096886e-29], sampled 0.7946020160752513
[2019-03-26 23:12:17,390] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09473894], dtype=float32), 0.074177034]
[2019-03-26 23:12:17,391] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.07821582666667, 96.94603369999999, 1.0, 2.0, 0.2880746389053961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 462907.5637198846, 462907.5637198839, 164469.1153541286]
[2019-03-26 23:12:17,393] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:12:17,396] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.2251200e-24 1.0000000e+00 2.1348488e-23 1.0148670e-18 3.9166708e-30], sampled 0.2271559305367875
[2019-03-26 23:12:34,692] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09473894], dtype=float32), 0.074177034]
[2019-03-26 23:12:34,693] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [35.0, 56.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.766720666968997, 6.9112, 170.5573041426782, 3522887.896037006, 2910043.641931378, 548807.120257666]
[2019-03-26 23:12:34,694] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:12:34,697] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.4177542e-12 8.3676316e-03 2.6198005e-10 9.9163240e-01 5.4163369e-15], sampled 0.9843621559644348
[2019-03-26 23:12:34,698] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 0, 0, 1, 0] has been changed to [0, 0, 0, 0, 1] for the demand 3522887.896037006 W.
[2019-03-26 23:12:46,315] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09473894], dtype=float32), 0.074177034]
[2019-03-26 23:12:46,317] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.75, 84.0, 1.0, 2.0, 0.5068348207954212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 708226.0998996464, 708226.0998996471, 184673.5229565773]
[2019-03-26 23:12:46,319] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:12:46,321] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.9050187e-24 1.0000000e+00 2.7668025e-23 6.8751931e-18 4.4095483e-30], sampled 0.8481235266035247
[2019-03-26 23:13:18,608] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09473894], dtype=float32), 0.074177034]
[2019-03-26 23:13:18,609] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.96666666666667, 57.5, 1.0, 2.0, 1.000270505240883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1526743.240083183, 1526743.240083183, 318064.6699848701]
[2019-03-26 23:13:18,610] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:13:18,612] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.6068348e-22 1.0000000e+00 1.3161119e-21 3.5018240e-16 3.9668815e-28], sampled 0.45760637657209813
[2019-03-26 23:13:18,955] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09473894], dtype=float32), 0.074177034]
[2019-03-26 23:13:18,956] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.96666666666667, 82.66666666666667, 1.0, 2.0, 0.6189656932055545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 864976.0748285915, 864976.0748285908, 204331.9873840199]
[2019-03-26 23:13:18,957] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:13:18,959] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.7280411e-24 1.0000000e+00 7.9455534e-23 3.7015284e-16 2.6617020e-30], sampled 0.2801480171955517
[2019-03-26 23:13:27,593] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7900.5860 3163281339.4390 1725.0000
[2019-03-26 23:13:27,854] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.1157 2927265807.6381 1337.0000
[2019-03-26 23:13:27,865] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8501.3287 2842028962.8344 1121.0000
[2019-03-26 23:13:27,906] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8002.0457 3006998233.0789 1749.0000
[2019-03-26 23:13:27,965] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.5565 2779274602.4099 933.0000
[2019-03-26 23:13:28,986] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2175000, evaluation results [2175000.0, 7900.585974430086, 3163281339.4389906, 1725.0, 8254.115664828903, 2927265807.6380606, 1337.0, 8659.556548002294, 2779274602.4098973, 933.0, 8002.045696444072, 3006998233.078905, 1749.0, 8501.328714647943, 2842028962.8344493, 1121.0]
[2019-03-26 23:13:30,128] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136000, global step 2175514: loss 0.0031
[2019-03-26 23:13:30,130] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136000, global step 2175514: learning rate 0.0000
[2019-03-26 23:13:33,754] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136000, global step 2177129: loss 0.0014
[2019-03-26 23:13:33,755] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136000, global step 2177129: learning rate 0.0000
[2019-03-26 23:13:36,056] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137000, global step 2178158: loss 0.0128
[2019-03-26 23:13:36,059] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137000, global step 2178158: learning rate 0.0000
[2019-03-26 23:13:36,479] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136500, global step 2178343: loss 0.0396
[2019-03-26 23:13:36,481] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136500, global step 2178343: learning rate 0.0000
[2019-03-26 23:13:38,696] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136000, global step 2179331: loss 0.0021
[2019-03-26 23:13:38,698] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136000, global step 2179333: learning rate 0.0000
[2019-03-26 23:13:39,371] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137000, global step 2179637: loss 0.0144
[2019-03-26 23:13:39,375] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137000, global step 2179638: learning rate 0.0000
[2019-03-26 23:13:41,612] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136500, global step 2180628: loss 0.0736
[2019-03-26 23:13:41,618] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136500, global step 2180630: learning rate 0.0000
[2019-03-26 23:13:42,345] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136000, global step 2180958: loss 0.0006
[2019-03-26 23:13:42,347] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136000, global step 2180959: learning rate 0.0000
[2019-03-26 23:13:42,446] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136000, global step 2181000: loss 0.0008
[2019-03-26 23:13:42,447] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136000, global step 2181000: learning rate 0.0000
[2019-03-26 23:13:42,682] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136000, global step 2181105: loss 0.0009
[2019-03-26 23:13:42,686] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136000, global step 2181106: learning rate 0.0000
[2019-03-26 23:13:42,823] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136000, global step 2181163: loss 0.0006
[2019-03-26 23:13:42,827] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136000, global step 2181167: learning rate 0.0000
[2019-03-26 23:13:42,935] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136000, global step 2181218: loss 0.0004
[2019-03-26 23:13:42,937] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136000, global step 2181219: loss 0.0006
[2019-03-26 23:13:42,939] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136000, global step 2181219: learning rate 0.0000
[2019-03-26 23:13:42,940] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136000, global step 2181219: learning rate 0.0000
[2019-03-26 23:13:43,011] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136000, global step 2181246: loss 0.0005
[2019-03-26 23:13:43,017] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136000, global step 2181247: learning rate 0.0000
[2019-03-26 23:13:43,277] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136000, global step 2181372: loss 0.0005
[2019-03-26 23:13:43,280] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136000, global step 2181373: learning rate 0.0000
[2019-03-26 23:13:43,696] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137000, global step 2181556: loss 0.0201
[2019-03-26 23:13:43,697] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137000, global step 2181556: learning rate 0.0000
[2019-03-26 23:13:47,365] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.8146378e-19 1.0000000e+00 1.4517957e-18 2.5917232e-13 5.9405279e-25], sum to 1.0000
[2019-03-26 23:13:47,377] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6549
[2019-03-26 23:13:47,386] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2016273.342881346 W.
[2019-03-26 23:13:47,396] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.7, 80.0, 1.0, 2.0, 0.721025326219026, 1.0, 1.0, 0.721025326219026, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2016273.342881346, 2016273.342881346, 383255.7868941532], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2191200.0000, 
sim time next is 2191800.0000, 
raw observation next is [28.8, 79.5, 1.0, 2.0, 0.6868938649406324, 1.0, 2.0, 0.6868938649406324, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1920742.655042124, 1920742.655042124, 368565.4052239797], 
processed observation next is [1.0, 0.34782608695652173, 0.5639810426540285, 0.795, 1.0, 1.0, 0.6227636926995571, 1.0, 1.0, 0.6227636926995571, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.53353962640059, 0.53353962640059, 0.5500976197372831], 
reward next is 0.4499, 
noisyNet noise sample is [array([-0.43972513], dtype=float32), -0.2687789]. 
=============================================
[2019-03-26 23:13:48,406] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136500, global step 2183649: loss 0.0262
[2019-03-26 23:13:48,409] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136500, global step 2183651: learning rate 0.0000
[2019-03-26 23:13:49,803] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.5366010e-21 1.0000000e+00 3.5826042e-20 3.2634831e-14 3.1967975e-26], sum to 1.0000
[2019-03-26 23:13:49,813] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5095
[2019-03-26 23:13:49,820] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.75, 83.0, 1.0, 2.0, 0.7142453982520539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 998187.6505371014, 998187.650537102, 223949.9227639498], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2435400.0000, 
sim time next is 2436000.0000, 
raw observation next is [27.7, 83.33333333333334, 1.0, 2.0, 0.72440626249048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1012394.649632712, 1012394.649632711, 226201.2772083527], 
processed observation next is [1.0, 0.17391304347826086, 0.5118483412322274, 0.8333333333333335, 1.0, 1.0, 0.6679593523981687, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.28122073600908665, 0.28122073600908637, 0.3376138465796309], 
reward next is 0.6624, 
noisyNet noise sample is [array([0.12301504], dtype=float32), 1.4644027]. 
=============================================
[2019-03-26 23:13:49,828] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[67.77464 ]
 [67.16925 ]
 [66.454475]
 [65.80951 ]
 [65.0364  ]], R is [[68.35671997]
 [68.33890533]
 [68.31401062]
 [68.27158356]
 [68.21968842]].
[2019-03-26 23:13:52,061] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136500, global step 2185260: loss 0.2624
[2019-03-26 23:13:52,066] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136500, global step 2185261: learning rate 0.0000
[2019-03-26 23:13:53,602] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137500, global step 2185947: loss 0.0333
[2019-03-26 23:13:53,604] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137500, global step 2185948: learning rate 0.0000
[2019-03-26 23:13:54,752] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137000, global step 2186459: loss 0.0275
[2019-03-26 23:13:54,753] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137000, global step 2186459: learning rate 0.0000
[2019-03-26 23:13:56,908] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136500, global step 2187421: loss 0.0100
[2019-03-26 23:13:56,911] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136500, global step 2187421: learning rate 0.0000
[2019-03-26 23:13:57,031] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137500, global step 2187474: loss 0.0264
[2019-03-26 23:13:57,034] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137500, global step 2187474: learning rate 0.0000
[2019-03-26 23:13:57,764] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.0915953e-25 1.0000000e+00 3.0683112e-24 7.9876646e-18 1.0122244e-29], sum to 1.0000
[2019-03-26 23:13:57,773] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0835
[2019-03-26 23:13:57,778] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.349903153279406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 538978.7727720743, 538978.772772075, 169731.5328070277], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2761800.0000, 
sim time next is 2762400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3488612530156051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 537408.1714995031, 537408.1714995025, 169603.7349907542], 
processed observation next is [0.0, 1.0, 0.2417061611374408, 0.94, 1.0, 1.0, 0.21549548556097, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14928004763875086, 0.1492800476387507, 0.2531399029712749], 
reward next is 0.7469, 
noisyNet noise sample is [array([0.36527866], dtype=float32), -1.115843]. 
=============================================
[2019-03-26 23:13:59,704] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137000, global step 2188662: loss 0.0240
[2019-03-26 23:13:59,707] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137000, global step 2188662: learning rate 0.0000
[2019-03-26 23:14:00,439] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136500, global step 2188991: loss 0.0323
[2019-03-26 23:14:00,440] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136500, global step 2188991: learning rate 0.0000
[2019-03-26 23:14:00,608] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136500, global step 2189065: loss 0.0407
[2019-03-26 23:14:00,610] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136500, global step 2189065: learning rate 0.0000
[2019-03-26 23:14:00,752] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136500, global step 2189132: loss 0.0671
[2019-03-26 23:14:00,754] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136500, global step 2189132: learning rate 0.0000
[2019-03-26 23:14:00,907] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136500, global step 2189195: loss 0.1165
[2019-03-26 23:14:00,910] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136500, global step 2189197: learning rate 0.0000
[2019-03-26 23:14:00,959] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136500, global step 2189221: loss 0.0690
[2019-03-26 23:14:00,962] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136500, global step 2189221: learning rate 0.0000
[2019-03-26 23:14:01,019] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136500, global step 2189242: loss 0.2571
[2019-03-26 23:14:01,022] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136500, global step 2189242: learning rate 0.0000
[2019-03-26 23:14:01,132] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137500, global step 2189296: loss 0.0259
[2019-03-26 23:14:01,137] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137500, global step 2189297: learning rate 0.0000
[2019-03-26 23:14:01,218] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136500, global step 2189330: loss 0.0640
[2019-03-26 23:14:01,219] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136500, global step 2189330: learning rate 0.0000
[2019-03-26 23:14:01,453] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136500, global step 2189433: loss 0.0277
[2019-03-26 23:14:01,457] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136500, global step 2189437: learning rate 0.0000
[2019-03-26 23:14:06,532] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137000, global step 2191699: loss 0.0204
[2019-03-26 23:14:06,535] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137000, global step 2191699: learning rate 0.0000
[2019-03-26 23:14:10,133] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137000, global step 2193305: loss 0.0179
[2019-03-26 23:14:10,136] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137000, global step 2193305: learning rate 0.0000
[2019-03-26 23:14:10,896] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.7156099e-22 1.0000000e+00 2.2383133e-20 1.0694275e-15 5.7540408e-27], sum to 1.0000
[2019-03-26 23:14:10,906] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1673
[2019-03-26 23:14:10,911] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3387719845445776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 521876.3759363471, 521876.3759363471, 168348.8799461964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2785800.0000, 
sim time next is 2786400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3395761230537678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 523113.9895834465, 523113.9895834465, 168447.6071190568], 
processed observation next is [1.0, 0.2608695652173913, 0.2417061611374408, 0.94, 1.0, 1.0, 0.2043085819924913, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14530944155095737, 0.14530944155095737, 0.2514143389836669], 
reward next is 0.7486, 
noisyNet noise sample is [array([-1.3162528], dtype=float32), 0.04395974]. 
=============================================
[2019-03-26 23:14:10,934] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138000, global step 2193662: loss 0.0029
[2019-03-26 23:14:10,936] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138000, global step 2193662: learning rate 0.0000
[2019-03-26 23:14:11,619] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2209708e-22 1.0000000e+00 3.5029374e-21 3.3397704e-15 7.0754280e-28], sum to 1.0000
[2019-03-26 23:14:11,628] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8271
[2019-03-26 23:14:11,636] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.1, 87.0, 1.0, 2.0, 0.5330832358044094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 744917.2072691167, 744917.2072691167, 188941.636561287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2581200.0000, 
sim time next is 2581800.0000, 
raw observation next is [26.98333333333333, 87.33333333333333, 1.0, 2.0, 0.5316337481787876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742891.0211590385, 742891.0211590378, 188700.5452140872], 
processed observation next is [1.0, 0.9130434782608695, 0.4778830963665086, 0.8733333333333333, 1.0, 1.0, 0.43570331105878024, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20635861698862182, 0.20635861698862162, 0.2816426047971451], 
reward next is 0.7184, 
noisyNet noise sample is [array([-1.3864843], dtype=float32), 0.8325678]. 
=============================================
[2019-03-26 23:14:12,395] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137500, global step 2194311: loss 0.0180
[2019-03-26 23:14:12,400] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137500, global step 2194312: learning rate 0.0000
[2019-03-26 23:14:14,510] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138000, global step 2195259: loss 0.0038
[2019-03-26 23:14:14,511] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138000, global step 2195259: learning rate 0.0000
[2019-03-26 23:14:15,029] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137000, global step 2195489: loss 0.0135
[2019-03-26 23:14:15,030] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137000, global step 2195490: learning rate 0.0000
[2019-03-26 23:14:15,460] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.9132065e-22 1.0000000e+00 3.3872848e-21 6.6058405e-16 1.5845524e-27], sum to 1.0000
[2019-03-26 23:14:15,470] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7790
[2019-03-26 23:14:15,475] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 96.0, 1.0, 2.0, 0.6815411511090337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1020290.962484362, 1020290.962484362, 225630.4072453968], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3062400.0000, 
sim time next is 3063000.0000, 
raw observation next is [22.83333333333334, 95.0, 1.0, 2.0, 0.6945003252120712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1038103.871645765, 1038103.871645764, 228399.7974447252], 
processed observation next is [1.0, 0.43478260869565216, 0.2812006319115327, 0.95, 1.0, 1.0, 0.631928102665146, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.28836218656826806, 0.2883621865682678, 0.34089522006675405], 
reward next is 0.6591, 
noisyNet noise sample is [array([2.2774065], dtype=float32), 2.4080884]. 
=============================================
[2019-03-26 23:14:15,488] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[70.26038]
 [70.24341]
 [70.17356]
 [70.13664]
 [70.12866]], R is [[70.24898529]
 [70.20973206]
 [70.17746735]
 [70.14924622]
 [70.11636353]].
[2019-03-26 23:14:15,568] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.9867260e-24 1.0000000e+00 5.4107755e-23 1.0103320e-18 5.4293022e-30], sum to 1.0000
[2019-03-26 23:14:15,580] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8428
[2019-03-26 23:14:15,585] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 89.83333333333334, 1.0, 2.0, 0.4151983863922045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 612542.7685328014, 612542.768532802, 175511.5393493354], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2661000.0000, 
sim time next is 2661600.0000, 
raw observation next is [23.66666666666666, 90.66666666666667, 1.0, 2.0, 0.411376980288663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 608200.7687486969, 608200.7687486969, 175139.2544711489], 
processed observation next is [0.0, 0.8260869565217391, 0.3206951026856238, 0.9066666666666667, 1.0, 1.0, 0.29081563890200357, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16894465798574915, 0.16894465798574915, 0.26140187234499834], 
reward next is 0.7386, 
noisyNet noise sample is [array([0.56671935], dtype=float32), -0.23534743]. 
=============================================
[2019-03-26 23:14:17,048] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.2745459e-25 1.0000000e+00 6.8878286e-23 1.3944864e-17 5.7062491e-30], sum to 1.0000
[2019-03-26 23:14:17,059] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3816
[2019-03-26 23:14:17,063] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137500, global step 2196397: loss 0.0144
[2019-03-26 23:14:17,065] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3953053316863929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 589854.1961933773, 589854.1961933773, 173604.2388289574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2672400.0000, 
sim time next is 2673000.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.395570217914681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 590249.5026353665, 590249.5026353665, 173640.5113558316], 
processed observation next is [0.0, 0.9565217391304348, 0.28909952606635075, 0.94, 1.0, 1.0, 0.2717713468851578, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1639581951764907, 0.1639581951764907, 0.2591649423221367], 
reward next is 0.7408, 
noisyNet noise sample is [array([0.9572606], dtype=float32), 0.40613312]. 
=============================================
[2019-03-26 23:14:17,066] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137500, global step 2196397: learning rate 0.0000
[2019-03-26 23:14:17,073] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[77.668465]
 [77.64794 ]
 [77.61567 ]
 [77.58641 ]
 [77.58723 ]], R is [[77.65232849]
 [77.61669922]
 [77.58139038]
 [77.54641724]
 [77.5117569 ]].
[2019-03-26 23:14:18,606] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137000, global step 2197080: loss 0.0153
[2019-03-26 23:14:18,609] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137000, global step 2197081: learning rate 0.0000
[2019-03-26 23:14:18,845] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138000, global step 2197192: loss 0.0050
[2019-03-26 23:14:18,851] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138000, global step 2197193: learning rate 0.0000
[2019-03-26 23:14:18,909] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137000, global step 2197216: loss 0.0135
[2019-03-26 23:14:18,911] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137000, global step 2197216: learning rate 0.0000
[2019-03-26 23:14:19,049] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137000, global step 2197279: loss 0.0142
[2019-03-26 23:14:19,053] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137000, global step 2197279: learning rate 0.0000
[2019-03-26 23:14:19,070] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137000, global step 2197289: loss 0.0136
[2019-03-26 23:14:19,077] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137000, global step 2197290: learning rate 0.0000
[2019-03-26 23:14:19,085] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137000, global step 2197294: loss 0.0139
[2019-03-26 23:14:19,086] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137000, global step 2197294: learning rate 0.0000
[2019-03-26 23:14:19,195] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137000, global step 2197342: loss 0.0137
[2019-03-26 23:14:19,200] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137000, global step 2197343: learning rate 0.0000
[2019-03-26 23:14:19,379] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137000, global step 2197424: loss 0.0118
[2019-03-26 23:14:19,385] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137000, global step 2197426: learning rate 0.0000
[2019-03-26 23:14:19,688] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137000, global step 2197560: loss 0.0123
[2019-03-26 23:14:19,693] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137000, global step 2197562: learning rate 0.0000
[2019-03-26 23:14:23,059] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.4486288e-20 1.0000000e+00 6.9142438e-20 8.3293171e-15 4.2334375e-26], sum to 1.0000
[2019-03-26 23:14:23,068] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2290
[2019-03-26 23:14:23,075] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.05, 93.66666666666667, 1.0, 2.0, 0.9263275786067773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104028, 1294762.02654964, 1294762.02654964, 277281.6140456639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3379800.0000, 
sim time next is 3380400.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.8665246255861376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1211125.570062671, 1211125.570062671, 260894.5689907284], 
processed observation next is [1.0, 0.13043478260869565, 0.4312796208530806, 0.94, 1.0, 1.0, 0.8391862958869128, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3364237694618531, 0.3364237694618531, 0.3893948790906394], 
reward next is 0.6106, 
noisyNet noise sample is [array([0.56033224], dtype=float32), 0.13575001]. 
=============================================
[2019-03-26 23:14:24,348] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137500, global step 2199620: loss 0.0125
[2019-03-26 23:14:24,351] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137500, global step 2199621: learning rate 0.0000
[2019-03-26 23:14:24,656] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.1612087e-22 1.0000000e+00 3.3798778e-20 3.7202426e-16 1.2685791e-27], sum to 1.0000
[2019-03-26 23:14:24,668] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1455
[2019-03-26 23:14:24,676] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5208599807107414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 802332.5437939562, 802332.5437939562, 195847.4851315653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2794800.0000, 
sim time next is 2795400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.580029367333351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 893389.2896647172, 893389.2896647172, 207076.6346491899], 
processed observation next is [1.0, 0.34782608695652173, 0.2417061611374408, 0.94, 1.0, 1.0, 0.49401128594379634, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24816369157353255, 0.24816369157353255, 0.3090696039540148], 
reward next is 0.6909, 
noisyNet noise sample is [array([-1.5184231], dtype=float32), 0.026598684]. 
=============================================
[2019-03-26 23:14:25,193] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 23:14:25,195] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 23:14:25,196] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:14:25,196] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 23:14:25,197] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 23:14:25,197] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:14:25,198] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:14:25,199] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 23:14:25,201] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:14:25,201] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 23:14:25,203] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:14:25,232] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run89
[2019-03-26 23:14:25,260] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run89
[2019-03-26 23:14:25,261] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run89
[2019-03-26 23:14:25,310] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run89
[2019-03-26 23:14:25,310] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run89
[2019-03-26 23:14:44,662] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09469522], dtype=float32), 0.07428101]
[2019-03-26 23:14:44,665] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.14928068833333, 74.99286985666666, 1.0, 2.0, 0.4761294237610279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 679095.7852144026, 679095.7852144032, 181707.1647811565]
[2019-03-26 23:14:44,666] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:14:44,668] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.92624892e-24 1.00000000e+00 6.46252398e-23 2.46604924e-17
 1.20208294e-29], sampled 0.5537378651874334
[2019-03-26 23:14:46,283] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09469522], dtype=float32), 0.07428101]
[2019-03-26 23:14:46,284] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.09370811333333, 94.87490406666666, 1.0, 2.0, 0.2843135952212875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 459670.4818056362, 459670.4818056356, 164245.6041695586]
[2019-03-26 23:14:46,286] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:14:46,288] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.4103500e-23 1.0000000e+00 1.7568301e-22 5.6847094e-18 6.3382818e-29], sampled 0.5448763178482023
[2019-03-26 23:14:52,923] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09469522], dtype=float32), 0.07428101]
[2019-03-26 23:14:52,927] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.52362603, 93.43207296, 1.0, 2.0, 0.3772345324321951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 572951.7431093516, 572951.7431093516, 172390.6516317431]
[2019-03-26 23:14:52,927] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:14:52,929] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.9857531e-24 1.0000000e+00 5.0366295e-23 3.1686917e-18 9.2762295e-30], sampled 0.722361726531143
[2019-03-26 23:15:09,139] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09469522], dtype=float32), 0.07428101]
[2019-03-26 23:15:09,140] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.09920451, 87.98666190666667, 1.0, 2.0, 0.333188636910916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 520589.7954433017, 520589.7954433017, 168464.1571898556]
[2019-03-26 23:15:09,143] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:15:09,145] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.0831417e-24 1.0000000e+00 7.5785198e-23 3.7524788e-18 1.4909573e-29], sampled 0.3966632242436704
[2019-03-26 23:15:18,847] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09469522], dtype=float32), 0.07428101]
[2019-03-26 23:15:18,848] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.0, 52.0, 1.0, 2.0, 0.9983700604274255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9128057537067, 1395524.629924129, 1395524.62992413, 298432.507812037]
[2019-03-26 23:15:18,849] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:15:18,854] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.3800843e-19 1.0000000e+00 3.3385953e-17 4.9315849e-09 5.1826489e-24], sampled 0.23896206738103454
[2019-03-26 23:15:37,244] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09469522], dtype=float32), 0.07428101]
[2019-03-26 23:15:37,246] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.83333333333333, 62.16666666666666, 1.0, 2.0, 0.5468488678086753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 764159.8769620893, 764159.8769620887, 191261.752302743]
[2019-03-26 23:15:37,248] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:15:37,250] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.0338417e-24 1.0000000e+00 5.4793401e-23 2.6312215e-17 1.1268083e-29], sampled 0.9732185988604136
[2019-03-26 23:16:19,566] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.7049 2927226456.4451 1332.0000
[2019-03-26 23:16:19,852] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.8431 2779373154.2113 933.0000
[2019-03-26 23:16:20,090] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7897.2581 3163438294.9482 1727.0000
[2019-03-26 23:16:20,110] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8503.8457 2841804616.4818 1114.0000
[2019-03-26 23:16:20,112] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8001.0196 3006819242.2306 1747.0000
[2019-03-26 23:16:21,131] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2200000, evaluation results [2200000.0, 7897.258131219666, 3163438294.948203, 1727.0, 8252.704903262067, 2927226456.445065, 1332.0, 8658.843094255979, 2779373154.2112503, 933.0, 8001.0195563411, 3006819242.2306027, 1747.0, 8503.84571795106, 2841804616.4817953, 1114.0]
[2019-03-26 23:16:23,955] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137500, global step 2201261: loss 0.0112
[2019-03-26 23:16:23,957] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137500, global step 2201262: learning rate 0.0000
[2019-03-26 23:16:25,243] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138500, global step 2201844: loss 1.6200
[2019-03-26 23:16:25,246] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138500, global step 2201844: learning rate 0.0000
[2019-03-26 23:16:25,485] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.0174190e-21 1.0000000e+00 2.2820857e-20 1.6519437e-16 1.8836991e-27], sum to 1.0000
[2019-03-26 23:16:25,495] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5775
[2019-03-26 23:16:25,502] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.3578061486825639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 551189.273692111, 551189.273692111, 170746.0739588929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2877000.0000, 
sim time next is 2877600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3449059683428146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 531314.878465243, 531314.8784652436, 169107.2311510369], 
processed observation next is [1.0, 0.30434782608695654, 0.2417061611374408, 0.94, 1.0, 1.0, 0.2107300823407405, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1475874662403453, 0.14758746624034544, 0.25239885246423416], 
reward next is 0.7476, 
noisyNet noise sample is [array([-1.2839481], dtype=float32), -0.7787118]. 
=============================================
[2019-03-26 23:16:26,346] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138000, global step 2202330: loss 0.0067
[2019-03-26 23:16:26,349] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138000, global step 2202331: learning rate 0.0000
[2019-03-26 23:16:28,709] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138500, global step 2203386: loss 1.3827
[2019-03-26 23:16:28,712] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138500, global step 2203387: learning rate 0.0000
[2019-03-26 23:16:28,713] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137500, global step 2203387: loss 0.0087
[2019-03-26 23:16:28,715] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137500, global step 2203388: learning rate 0.0000
[2019-03-26 23:16:30,941] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138000, global step 2204365: loss 0.0076
[2019-03-26 23:16:30,944] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138000, global step 2204367: learning rate 0.0000
[2019-03-26 23:16:31,399] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1031959e-22 1.0000000e+00 5.4268836e-21 3.1086651e-15 2.0436287e-27], sum to 1.0000
[2019-03-26 23:16:31,408] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8435
[2019-03-26 23:16:31,414] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 89.0, 1.0, 2.0, 0.8601459056015435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1202205.102822362, 1202205.102822362, 259212.7197674778], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3394800.0000, 
sim time next is 3395400.0000, 
raw observation next is [28.16666666666667, 88.16666666666667, 1.0, 2.0, 0.8604299167453348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1202602.283125204, 1202602.283125204, 259287.6254139024], 
processed observation next is [1.0, 0.30434782608695654, 0.5339652448657191, 0.8816666666666667, 1.0, 1.0, 0.8318432731871503, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.33405618975700113, 0.33405618975700113, 0.3869964558416454], 
reward next is 0.6130, 
noisyNet noise sample is [array([-2.1146839], dtype=float32), -1.1912277]. 
=============================================
[2019-03-26 23:16:31,762] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.2109801e-15 9.9999988e-01 1.9649999e-13 8.9673975e-08 5.2786748e-19], sum to 1.0000
[2019-03-26 23:16:31,770] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5749
[2019-03-26 23:16:31,778] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2178067.949737876 W.
[2019-03-26 23:16:31,783] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.7788247966135942, 1.0, 2.0, 0.7788247966135942, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2178067.949737876, 2178067.949737876, 409688.6057419926], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3661200.0000, 
sim time next is 3661800.0000, 
raw observation next is [29.33333333333334, 73.33333333333334, 1.0, 2.0, 0.7057778701687474, 1.0, 2.0, 0.7057778701687474, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1973596.122500625, 1973596.122500625, 376605.3471249184], 
processed observation next is [1.0, 0.391304347826087, 0.5892575039494474, 0.7333333333333334, 1.0, 1.0, 0.6455155062274065, 1.0, 1.0, 0.6455155062274065, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5482211451390625, 0.5482211451390625, 0.5620975330222663], 
reward next is 0.4379, 
noisyNet noise sample is [array([-2.1543162], dtype=float32), -0.14522071]. 
=============================================
[2019-03-26 23:16:32,426] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137500, global step 2205026: loss 0.0070
[2019-03-26 23:16:32,430] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137500, global step 2205026: learning rate 0.0000
[2019-03-26 23:16:32,741] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137500, global step 2205164: loss 0.0065
[2019-03-26 23:16:32,744] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137500, global step 2205166: learning rate 0.0000
[2019-03-26 23:16:32,840] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137500, global step 2205212: loss 0.0060
[2019-03-26 23:16:32,843] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137500, global step 2205213: learning rate 0.0000
[2019-03-26 23:16:32,872] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137500, global step 2205225: loss 0.0061
[2019-03-26 23:16:32,875] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137500, global step 2205226: learning rate 0.0000
[2019-03-26 23:16:32,896] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137500, global step 2205233: loss 0.0072
[2019-03-26 23:16:32,902] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137500, global step 2205234: learning rate 0.0000
[2019-03-26 23:16:32,965] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.9448858e-25 1.0000000e+00 7.1745377e-24 9.6987208e-18 3.7019259e-30], sum to 1.0000
[2019-03-26 23:16:32,970] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5321
[2019-03-26 23:16:32,978] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 79.0, 1.0, 2.0, 0.586482220004516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 819564.4020562081, 819564.4020562088, 198254.7629639177], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3346200.0000, 
sim time next is 3346800.0000, 
raw observation next is [30.0, 79.0, 1.0, 2.0, 0.5856394901329548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 818386.2973135775, 818386.2973135775, 198101.2966264686], 
processed observation next is [0.0, 0.7391304347826086, 0.6208530805687204, 0.79, 1.0, 1.0, 0.5007704700397045, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2273295270315493, 0.2273295270315493, 0.29567357705443076], 
reward next is 0.7043, 
noisyNet noise sample is [array([-0.5253321], dtype=float32), 0.686081]. 
=============================================
[2019-03-26 23:16:33,046] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137500, global step 2205299: loss 0.0061
[2019-03-26 23:16:33,048] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137500, global step 2205301: learning rate 0.0000
[2019-03-26 23:16:33,332] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138500, global step 2205423: loss 0.7952
[2019-03-26 23:16:33,333] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137500, global step 2205423: loss 0.0064
[2019-03-26 23:16:33,335] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138500, global step 2205423: learning rate 0.0000
[2019-03-26 23:16:33,337] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137500, global step 2205424: learning rate 0.0000
[2019-03-26 23:16:33,445] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137500, global step 2205474: loss 0.0057
[2019-03-26 23:16:33,447] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137500, global step 2205474: learning rate 0.0000
[2019-03-26 23:16:36,404] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.4220568e-23 1.0000000e+00 4.9039007e-22 4.9057115e-16 2.2346527e-28], sum to 1.0000
[2019-03-26 23:16:36,413] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3025
[2019-03-26 23:16:36,417] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.540977909640847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 807130.6990653153, 807130.6990653153, 196616.662729004], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3070200.0000, 
sim time next is 3070800.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.4581022426458296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 683473.5253452257, 683473.5253452263, 182696.7856311444], 
processed observation next is [1.0, 0.5652173913043478, 0.28909952606635075, 0.94, 1.0, 1.0, 0.347111135717867, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18985375704034047, 0.18985375704034063, 0.272681769598723], 
reward next is 0.7273, 
noisyNet noise sample is [array([-0.42643684], dtype=float32), -1.1126096]. 
=============================================
[2019-03-26 23:16:38,126] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138000, global step 2207566: loss 0.0090
[2019-03-26 23:16:38,130] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138000, global step 2207568: learning rate 0.0000
[2019-03-26 23:16:41,731] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138000, global step 2209173: loss 0.0077
[2019-03-26 23:16:41,733] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138000, global step 2209173: learning rate 0.0000
[2019-03-26 23:16:42,313] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.0142629e-22 1.0000000e+00 1.4502063e-19 9.2533197e-13 1.2351580e-26], sum to 1.0000
[2019-03-26 23:16:42,321] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3763
[2019-03-26 23:16:42,330] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 86.5, 1.0, 2.0, 0.5018772838525735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 701296.3944119347, 701296.394411934, 183890.9359768337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3177000.0000, 
sim time next is 3177600.0000, 
raw observation next is [26.33333333333334, 87.33333333333333, 1.0, 2.0, 0.4983102221022667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 696310.3400400049, 696310.3400400049, 183332.0542456736], 
processed observation next is [1.0, 0.782608695652174, 0.44707740916271754, 0.8733333333333333, 1.0, 1.0, 0.3955544844605623, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19341953890000138, 0.19341953890000138, 0.2736299317099606], 
reward next is 0.7264, 
noisyNet noise sample is [array([-0.84799993], dtype=float32), 0.63789374]. 
=============================================
[2019-03-26 23:16:43,402] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139000, global step 2209910: loss 0.0167
[2019-03-26 23:16:43,405] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139000, global step 2209910: learning rate 0.0000
[2019-03-26 23:16:44,699] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138500, global step 2210494: loss 0.7426
[2019-03-26 23:16:44,701] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138500, global step 2210494: learning rate 0.0000
[2019-03-26 23:16:46,464] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138000, global step 2211261: loss 0.0051
[2019-03-26 23:16:46,465] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138000, global step 2211261: learning rate 0.0000
[2019-03-26 23:16:46,946] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139000, global step 2211478: loss 0.0127
[2019-03-26 23:16:46,947] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139000, global step 2211479: learning rate 0.0000
[2019-03-26 23:16:49,366] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138500, global step 2212555: loss 1.0779
[2019-03-26 23:16:49,369] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138500, global step 2212555: learning rate 0.0000
[2019-03-26 23:16:49,842] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3761450e-23 1.0000000e+00 1.9018196e-22 1.2235383e-17 2.1697107e-29], sum to 1.0000
[2019-03-26 23:16:49,849] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9475
[2019-03-26 23:16:49,854] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 82.33333333333334, 1.0, 2.0, 0.5683815247180498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 794260.5965296457, 794260.5965296457, 195003.5527013623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3883200.0000, 
sim time next is 3883800.0000, 
raw observation next is [29.0, 83.16666666666666, 1.0, 2.0, 0.5731412756036788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 800914.415705872, 800914.415705872, 195849.1126084233], 
processed observation next is [0.0, 0.9565217391304348, 0.5734597156398105, 0.8316666666666666, 1.0, 1.0, 0.4857123802453961, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22247622658496444, 0.22247622658496444, 0.2923121083707811], 
reward next is 0.7077, 
noisyNet noise sample is [array([0.15871096], dtype=float32), 0.05232263]. 
=============================================
[2019-03-26 23:16:50,292] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138000, global step 2212963: loss 0.0020
[2019-03-26 23:16:50,296] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138000, global step 2212964: learning rate 0.0000
[2019-03-26 23:16:50,630] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138000, global step 2213116: loss 0.0019
[2019-03-26 23:16:50,633] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138000, global step 2213117: learning rate 0.0000
[2019-03-26 23:16:50,701] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138000, global step 2213146: loss 0.0022
[2019-03-26 23:16:50,707] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138000, global step 2213149: learning rate 0.0000
[2019-03-26 23:16:50,713] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138000, global step 2213152: loss 0.0022
[2019-03-26 23:16:50,718] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138000, global step 2213154: learning rate 0.0000
[2019-03-26 23:16:50,882] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138000, global step 2213225: loss 0.0018
[2019-03-26 23:16:50,885] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138000, global step 2213227: learning rate 0.0000
[2019-03-26 23:16:50,891] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138000, global step 2213228: loss 0.0017
[2019-03-26 23:16:50,895] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138000, global step 2213228: learning rate 0.0000
[2019-03-26 23:16:51,233] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138000, global step 2213378: loss 0.0018
[2019-03-26 23:16:51,235] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138000, global step 2213378: learning rate 0.0000
[2019-03-26 23:16:51,388] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138000, global step 2213448: loss 0.0022
[2019-03-26 23:16:51,390] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138000, global step 2213449: learning rate 0.0000
[2019-03-26 23:16:51,548] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139000, global step 2213518: loss 0.0095
[2019-03-26 23:16:51,553] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139000, global step 2213518: learning rate 0.0000
[2019-03-26 23:16:53,638] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5316299e-14 2.0232407e-02 2.4627281e-10 9.7976756e-01 1.1891281e-16], sum to 1.0000
[2019-03-26 23:16:53,648] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5282
[2019-03-26 23:16:53,654] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 63.0, 1.0, 2.0, 0.9707714328151927, 1.0, 2.0, 0.9707714328151927, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2715457.041809729, 2715457.041809728, 511575.2849193522], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3758400.0000, 
sim time next is 3759000.0000, 
raw observation next is [33.16666666666666, 63.66666666666666, 1.0, 2.0, 0.9807943010549507, 1.0, 2.0, 0.9807943010549507, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2743523.950357732, 2743523.950357733, 517491.2351129817], 
processed observation next is [1.0, 0.5217391304347826, 0.7709320695102682, 0.6366666666666666, 1.0, 1.0, 0.9768606036806635, 1.0, 1.0, 0.9768606036806635, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7620899862104811, 0.7620899862104813, 0.7723749777805697], 
reward next is 0.2276, 
noisyNet noise sample is [array([0.3279308], dtype=float32), 0.11442078]. 
=============================================
[2019-03-26 23:16:53,669] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[44.005024]
 [42.919365]
 [41.028698]
 [39.08254 ]
 [37.506557]], R is [[44.91155243]
 [44.69889069]
 [44.54846191]
 [44.40162277]
 [44.23111343]].
[2019-03-26 23:16:54,269] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9206695e-18 9.9982810e-01 7.1338775e-15 1.7190348e-04 1.8279780e-22], sum to 1.0000
[2019-03-26 23:16:54,279] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0173
[2019-03-26 23:16:54,287] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 71.0, 1.0, 2.0, 0.5411116988054545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 756139.9741144745, 756139.9741144752, 190290.6392069663], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3691800.0000, 
sim time next is 3692400.0000, 
raw observation next is [30.66666666666667, 72.33333333333334, 1.0, 2.0, 0.5447880579232777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 761279.0946388913, 761279.0946388913, 190912.957292419], 
processed observation next is [1.0, 0.7391304347826086, 0.6524486571879939, 0.7233333333333334, 1.0, 1.0, 0.45155187701599714, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2114664151774698, 0.2114664151774698, 0.2849447123767448], 
reward next is 0.7151, 
noisyNet noise sample is [array([0.9196197], dtype=float32), 0.9987358]. 
=============================================
[2019-03-26 23:16:56,450] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138500, global step 2215706: loss 3.5701
[2019-03-26 23:16:56,453] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138500, global step 2215706: learning rate 0.0000
[2019-03-26 23:16:59,116] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2972993e-22 1.0000000e+00 3.2022492e-21 3.0746640e-15 3.9101958e-28], sum to 1.0000
[2019-03-26 23:16:59,130] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0604
[2019-03-26 23:16:59,138] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 82.33333333333334, 1.0, 2.0, 0.5160098924962443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 721051.2460672673, 721051.2460672673, 186142.3138149622], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3447600.0000, 
sim time next is 3448200.0000, 
raw observation next is [27.16666666666666, 83.16666666666666, 1.0, 2.0, 0.5135213175728743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 717572.6380960974, 717572.638096098, 185741.578616854], 
processed observation next is [1.0, 0.9130434782608695, 0.4865718799368086, 0.8316666666666666, 1.0, 1.0, 0.41388110550948715, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1993257328044715, 0.19932573280447166, 0.27722623674157315], 
reward next is 0.7228, 
noisyNet noise sample is [array([0.07012079], dtype=float32), -0.99278]. 
=============================================
[2019-03-26 23:16:59,785] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138500, global step 2217192: loss 0.9331
[2019-03-26 23:16:59,789] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138500, global step 2217192: learning rate 0.0000
[2019-03-26 23:17:01,733] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139500, global step 2218041: loss 124.8198
[2019-03-26 23:17:01,735] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139500, global step 2218042: learning rate 0.0000
[2019-03-26 23:17:02,058] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.6433602e-23 1.0000000e+00 2.9788527e-21 3.6786241e-17 2.3932472e-28], sum to 1.0000
[2019-03-26 23:17:02,066] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1131
[2019-03-26 23:17:02,078] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.5357262742093543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 748611.8246158515, 748611.8246158515, 189383.0216842303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3823200.0000, 
sim time next is 3823800.0000, 
raw observation next is [27.16666666666666, 88.16666666666667, 1.0, 2.0, 0.5369122529756325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 750269.6699026373, 750269.669902638, 189581.6528850384], 
processed observation next is [0.0, 0.2608695652173913, 0.4865718799368086, 0.8816666666666667, 1.0, 1.0, 0.44206295539232826, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20840824163962146, 0.20840824163962166, 0.28295769087319167], 
reward next is 0.7170, 
noisyNet noise sample is [array([-2.304114], dtype=float32), 0.17136884]. 
=============================================
[2019-03-26 23:17:02,641] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139000, global step 2218442: loss 0.0031
[2019-03-26 23:17:02,643] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139000, global step 2218443: learning rate 0.0000
[2019-03-26 23:17:03,334] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.9324877e-24 1.0000000e+00 1.0645318e-21 1.2223698e-13 2.0022500e-29], sum to 1.0000
[2019-03-26 23:17:03,340] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9519
[2019-03-26 23:17:03,348] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 77.66666666666667, 1.0, 2.0, 0.5547762969872104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 775241.6114318797, 775241.611431879, 192623.499144762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3526800.0000, 
sim time next is 3527400.0000, 
raw observation next is [29.16666666666667, 78.33333333333334, 1.0, 2.0, 0.5545144262252285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 774875.5410675411, 774875.5410675411, 192578.0990301134], 
processed observation next is [1.0, 0.8260869565217391, 0.581358609794629, 0.7833333333333334, 1.0, 1.0, 0.46327039304244394, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21524320585209475, 0.21524320585209475, 0.2874299985524081], 
reward next is 0.7126, 
noisyNet noise sample is [array([-0.22868934], dtype=float32), -0.2591615]. 
=============================================
[2019-03-26 23:17:04,456] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138500, global step 2219255: loss 1.4326
[2019-03-26 23:17:04,457] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138500, global step 2219255: learning rate 0.0000
[2019-03-26 23:17:05,157] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139500, global step 2219572: loss 144.4897
[2019-03-26 23:17:05,161] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139500, global step 2219572: learning rate 0.0000
[2019-03-26 23:17:07,221] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139000, global step 2220490: loss 0.0015
[2019-03-26 23:17:07,225] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139000, global step 2220490: learning rate 0.0000
[2019-03-26 23:17:08,441] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138500, global step 2221030: loss 0.8323
[2019-03-26 23:17:08,446] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138500, global step 2221032: learning rate 0.0000
[2019-03-26 23:17:08,446] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138500, global step 2221033: loss 4.4049
[2019-03-26 23:17:08,450] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138500, global step 2221034: learning rate 0.0000
[2019-03-26 23:17:08,652] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138500, global step 2221125: loss 1.7127
[2019-03-26 23:17:08,654] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138500, global step 2221126: learning rate 0.0000
[2019-03-26 23:17:08,712] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138500, global step 2221157: loss 5.2178
[2019-03-26 23:17:08,715] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138500, global step 2221157: learning rate 0.0000
[2019-03-26 23:17:08,809] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138500, global step 2221196: loss 1.2985
[2019-03-26 23:17:08,810] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138500, global step 2221196: learning rate 0.0000
[2019-03-26 23:17:08,898] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138500, global step 2221238: loss 1.5214
[2019-03-26 23:17:08,900] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138500, global step 2221241: learning rate 0.0000
[2019-03-26 23:17:09,241] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138500, global step 2221388: loss 4.6917
[2019-03-26 23:17:09,245] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138500, global step 2221389: learning rate 0.0000
[2019-03-26 23:17:09,292] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138500, global step 2221413: loss 0.8041
[2019-03-26 23:17:09,293] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138500, global step 2221413: learning rate 0.0000
[2019-03-26 23:17:09,411] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0973246e-16 4.7042690e-06 4.5994485e-13 9.9999535e-01 7.1432235e-20], sum to 1.0000
[2019-03-26 23:17:09,422] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0746
[2019-03-26 23:17:09,429] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.0, 51.0, 1.0, 2.0, 0.973503150951678, 1.0, 2.0, 0.973503150951678, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2723106.574334943, 2723106.574334944, 513182.7921096324], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4207200.0000, 
sim time next is 4207800.0000, 
raw observation next is [36.0, 50.5, 1.0, 2.0, 0.9611326346065024, 1.0, 2.0, 0.9611326346065024, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2688466.23437208, 2688466.234372081, 505944.2835745091], 
processed observation next is [1.0, 0.6956521739130435, 0.9052132701421801, 0.505, 1.0, 1.0, 0.9531718489234969, 1.0, 1.0, 0.9531718489234969, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7467961762144666, 0.7467961762144669, 0.7551407217529986], 
reward next is 0.2449, 
noisyNet noise sample is [array([1.3998356], dtype=float32), -0.720529]. 
=============================================
[2019-03-26 23:17:09,693] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139500, global step 2221590: loss 143.9558
[2019-03-26 23:17:09,695] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139500, global step 2221590: learning rate 0.0000
[2019-03-26 23:17:14,176] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139000, global step 2223576: loss 0.0016
[2019-03-26 23:17:14,180] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139000, global step 2223577: learning rate 0.0000
[2019-03-26 23:17:14,782] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1385612e-21 1.0000000e+00 1.5882435e-20 1.3553891e-15 7.9590938e-28], sum to 1.0000
[2019-03-26 23:17:14,787] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3246
[2019-03-26 23:17:14,795] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.4916570767816245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 687010.6072135383, 687010.6072135377, 182299.063737542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3711000.0000, 
sim time next is 3711600.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.4912694198786736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 686468.7448684189, 686468.7448684195, 182239.3287825253], 
processed observation next is [1.0, 1.0, 0.5260663507109005, 0.74, 1.0, 1.0, 0.38707159021526943, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1906857624634497, 0.19068576246344984, 0.2719989981828736], 
reward next is 0.7280, 
noisyNet noise sample is [array([0.7209645], dtype=float32), -1.6503761]. 
=============================================
[2019-03-26 23:17:17,379] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 23:17:17,384] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 23:17:17,385] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 23:17:17,386] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:17:17,387] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 23:17:17,386] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:17:17,389] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:17:17,388] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 23:17:17,389] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 23:17:17,391] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:17:17,392] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:17:17,424] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run90
[2019-03-26 23:17:17,424] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run90
[2019-03-26 23:17:17,484] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run90
[2019-03-26 23:17:17,485] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run90
[2019-03-26 23:17:17,537] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run90
[2019-03-26 23:17:40,009] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09412066], dtype=float32), 0.07243919]
[2019-03-26 23:17:40,010] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.83896775, 89.45137338333333, 1.0, 2.0, 0.3422122828996121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 538380.6882564578, 538380.6882564578, 169957.2728112095]
[2019-03-26 23:17:40,011] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:17:40,012] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.8612643e-24 1.0000000e+00 7.0479686e-23 1.0016674e-17 2.0224390e-29], sampled 0.690613365259946
[2019-03-26 23:17:42,891] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09412066], dtype=float32), 0.07243919]
[2019-03-26 23:17:42,893] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.66730335166667, 98.65754129833334, 1.0, 2.0, 0.4612807522115803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 652364.573554521, 652364.573554521, 178759.5282786439]
[2019-03-26 23:17:42,893] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:17:42,896] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.8549243e-22 1.0000000e+00 1.2097702e-21 2.1649618e-17 4.4857643e-28], sampled 0.15028242827308713
[2019-03-26 23:18:36,029] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09412066], dtype=float32), 0.07243919]
[2019-03-26 23:18:36,031] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [32.21915480333333, 83.12328404333334, 1.0, 2.0, 0.7218511444612674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1008822.045921581, 1008822.045921582, 225644.1844211007]
[2019-03-26 23:18:36,032] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:18:36,036] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.2810377e-23 1.0000000e+00 2.2884383e-22 2.0468312e-16 6.0116874e-29], sampled 0.44994620769305227
[2019-03-26 23:18:46,099] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09412066], dtype=float32), 0.07243919]
[2019-03-26 23:18:46,102] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.03333333333333, 65.0, 1.0, 2.0, 0.574940196943075, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9844641650437483, 6.911200000000001, 6.9112, 168.912956412551, 1607466.58156696, 1607466.581566959, 348807.5065880888]
[2019-03-26 23:18:46,104] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:18:46,106] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.3382240e-13 9.6192420e-01 5.2728738e-11 3.8075872e-02 1.1587269e-16], sampled 0.8035033729791095
[2019-03-26 23:18:51,872] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09412066], dtype=float32), 0.07243919]
[2019-03-26 23:18:51,873] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.66374787, 89.95558898, 1.0, 2.0, 0.5480616294998762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 765855.1861668151, 765855.1861668145, 191467.4884491322]
[2019-03-26 23:18:51,874] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:18:51,880] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.4346716e-22 1.0000000e+00 2.8848471e-21 2.6859044e-16 1.3755124e-27], sampled 0.2781025489934523
[2019-03-26 23:19:11,422] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09412066], dtype=float32), 0.07243919]
[2019-03-26 23:19:11,423] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.26848449, 66.21706123, 1.0, 2.0, 0.9164453650952121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1280940.961633598, 1280940.961633598, 274498.1792355382]
[2019-03-26 23:19:11,425] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:19:11,429] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1212302e-21 1.0000000e+00 5.5937713e-21 5.8182587e-16 2.7119990e-27], sampled 0.645332843075029
[2019-03-26 23:19:11,709] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8259.8562 2926881940.8464 1323.0000
[2019-03-26 23:19:11,988] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7920.5126 3160398165.7379 1653.0000
[2019-03-26 23:19:12,048] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8504.5359 2841239131.2591 1097.0000
[2019-03-26 23:19:12,112] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8663.3246 2778942315.8559 925.0000
[2019-03-26 23:19:12,173] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8013.2944 3004433904.3030 1687.0000
[2019-03-26 23:19:13,194] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2225000, evaluation results [2225000.0, 7920.512622243922, 3160398165.7378774, 1653.0, 8259.856205751907, 2926881940.846415, 1323.0, 8663.324561511272, 2778942315.855927, 925.0, 8013.294447870194, 3004433904.3029876, 1687.0, 8504.535937732478, 2841239131.2591367, 1097.0]
[2019-03-26 23:19:13,364] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139000, global step 2225080: loss 0.0009
[2019-03-26 23:19:13,367] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139000, global step 2225082: learning rate 0.0000
[2019-03-26 23:19:15,501] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140000, global step 2226033: loss 0.0082
[2019-03-26 23:19:15,503] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140000, global step 2226033: learning rate 0.0000
[2019-03-26 23:19:16,554] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139500, global step 2226505: loss 179.5524
[2019-03-26 23:19:16,556] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139500, global step 2226505: learning rate 0.0000
[2019-03-26 23:19:18,173] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139000, global step 2227227: loss 0.0009
[2019-03-26 23:19:18,180] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139000, global step 2227231: learning rate 0.0000
[2019-03-26 23:19:19,003] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140000, global step 2227595: loss 0.0090
[2019-03-26 23:19:19,004] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140000, global step 2227595: learning rate 0.0000
[2019-03-26 23:19:19,034] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.7473219e-23 1.0000000e+00 6.6434740e-22 1.3775949e-15 3.5053709e-28], sum to 1.0000
[2019-03-26 23:19:19,043] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1498
[2019-03-26 23:19:19,048] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.0, 58.0, 1.0, 2.0, 0.6138748972006653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 857859.0486237034, 857859.0486237034, 203359.9688358732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3853800.0000, 
sim time next is 3854400.0000, 
raw observation next is [35.0, 57.33333333333333, 1.0, 2.0, 0.6093395870336394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 851518.6419786054, 851518.6419786054, 202499.3785488599], 
processed observation next is [0.0, 0.6086956521739131, 0.8578199052132701, 0.5733333333333333, 1.0, 1.0, 0.5293248036549872, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23653295610516817, 0.23653295610516817, 0.3022378784311342], 
reward next is 0.6978, 
noisyNet noise sample is [array([-0.16290405], dtype=float32), -0.63804126]. 
=============================================
[2019-03-26 23:19:21,160] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139500, global step 2228559: loss 149.2553
[2019-03-26 23:19:21,164] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139500, global step 2228562: learning rate 0.0000
[2019-03-26 23:19:22,131] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139000, global step 2228990: loss 0.0010
[2019-03-26 23:19:22,133] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139000, global step 2228990: learning rate 0.0000
[2019-03-26 23:19:22,209] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139000, global step 2229023: loss 0.0010
[2019-03-26 23:19:22,213] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139000, global step 2229023: learning rate 0.0000
[2019-03-26 23:19:22,430] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139000, global step 2229122: loss 0.0008
[2019-03-26 23:19:22,433] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139000, global step 2229123: learning rate 0.0000
[2019-03-26 23:19:22,448] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139000, global step 2229129: loss 0.0008
[2019-03-26 23:19:22,453] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139000, global step 2229129: learning rate 0.0000
[2019-03-26 23:19:22,518] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139000, global step 2229157: loss 0.0008
[2019-03-26 23:19:22,521] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139000, global step 2229157: learning rate 0.0000
[2019-03-26 23:19:22,606] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139000, global step 2229198: loss 0.0008
[2019-03-26 23:19:22,608] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139000, global step 2229198: learning rate 0.0000
[2019-03-26 23:19:22,837] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139000, global step 2229302: loss 0.0007
[2019-03-26 23:19:22,838] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139000, global step 2229302: learning rate 0.0000
[2019-03-26 23:19:23,017] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139000, global step 2229381: loss 0.0007
[2019-03-26 23:19:23,021] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139000, global step 2229382: learning rate 0.0000
[2019-03-26 23:19:23,637] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140000, global step 2229656: loss 0.0104
[2019-03-26 23:19:23,646] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140000, global step 2229656: learning rate 0.0000
[2019-03-26 23:19:23,661] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.7442638e-22 1.0000000e+00 2.1513817e-21 1.8911327e-16 2.6633704e-28], sum to 1.0000
[2019-03-26 23:19:23,668] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0561
[2019-03-26 23:19:23,675] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.5, 65.0, 1.0, 2.0, 0.5848134190571245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 817231.4822105966, 817231.4822105971, 197950.9395632618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3925800.0000, 
sim time next is 3926400.0000, 
raw observation next is [32.66666666666667, 64.33333333333334, 1.0, 2.0, 0.5851705603348605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 817730.751615156, 817730.7516151567, 198015.9429711099], 
processed observation next is [0.0, 0.43478260869565216, 0.7472353870458138, 0.6433333333333334, 1.0, 1.0, 0.5002054943793499, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22714743100420998, 0.22714743100421017, 0.29554618353897], 
reward next is 0.7045, 
noisyNet noise sample is [array([1.5734808], dtype=float32), 1.159515]. 
=============================================
[2019-03-26 23:19:28,241] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139500, global step 2231707: loss 107.3679
[2019-03-26 23:19:28,243] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139500, global step 2231707: learning rate 0.0000
[2019-03-26 23:19:29,448] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.3684928e-14 6.8707064e-02 6.0445628e-11 9.3129295e-01 6.0643370e-17], sum to 1.0000
[2019-03-26 23:19:29,458] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5784
[2019-03-26 23:19:29,465] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.83333333333334, 60.5, 1.0, 2.0, 0.9039712774057991, 1.0, 2.0, 0.9039712774057991, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2528413.532122305, 2528413.532122306, 473668.7099740066], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4020600.0000, 
sim time next is 4021200.0000, 
raw observation next is [34.0, 60.0, 1.0, 2.0, 0.9008947025829014, 1.0, 2.0, 0.9008947025829014, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2519799.655490153, 2519799.655490154, 471986.2914917794], 
processed observation next is [1.0, 0.5652173913043478, 0.8104265402843602, 0.6, 1.0, 1.0, 0.8805960272083149, 1.0, 1.0, 0.8805960272083149, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6999443487472647, 0.699944348747265, 0.7044571514802678], 
reward next is 0.2955, 
noisyNet noise sample is [array([0.6897009], dtype=float32), 0.49518594]. 
=============================================
[2019-03-26 23:19:31,694] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139500, global step 2233234: loss 161.1322
[2019-03-26 23:19:31,698] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139500, global step 2233236: learning rate 0.0000
[2019-03-26 23:19:33,436] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140500, global step 2234014: loss 1.9830
[2019-03-26 23:19:33,440] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140500, global step 2234015: learning rate 0.0000
[2019-03-26 23:19:34,749] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140000, global step 2234597: loss 0.0136
[2019-03-26 23:19:34,752] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140000, global step 2234598: learning rate 0.0000
[2019-03-26 23:19:36,270] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139500, global step 2235267: loss 139.6304
[2019-03-26 23:19:36,272] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139500, global step 2235267: learning rate 0.0000
[2019-03-26 23:19:36,600] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.6215534e-23 1.0000000e+00 1.3002528e-21 3.1015273e-12 2.8475305e-29], sum to 1.0000
[2019-03-26 23:19:36,609] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8807
[2019-03-26 23:19:36,617] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.5, 65.5, 1.0, 2.0, 0.6084434744291457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 850265.8725331981, 850265.8725331975, 202330.8089788183], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4217400.0000, 
sim time next is 4218000.0000, 
raw observation next is [33.33333333333334, 67.33333333333333, 1.0, 2.0, 0.616656230138146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861747.397183462, 861747.397183462, 203891.3357227084], 
processed observation next is [1.0, 0.8260869565217391, 0.7788309636650873, 0.6733333333333333, 1.0, 1.0, 0.5381400363110193, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23937427699540612, 0.23937427699540612, 0.3043154264518036], 
reward next is 0.6957, 
noisyNet noise sample is [array([-0.27113974], dtype=float32), 0.37470123]. 
=============================================
[2019-03-26 23:19:36,635] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[76.98115 ]
 [77.63646 ]
 [77.645424]
 [77.4434  ]
 [77.024315]], R is [[76.52258301]
 [76.45536804]
 [76.39060211]
 [76.32735443]
 [76.26744843]].
[2019-03-26 23:19:37,004] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140500, global step 2235593: loss 8.6900
[2019-03-26 23:19:37,009] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140500, global step 2235595: learning rate 0.0000
[2019-03-26 23:19:39,142] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140000, global step 2236547: loss 0.0174
[2019-03-26 23:19:39,144] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140000, global step 2236547: learning rate 0.0000
[2019-03-26 23:19:40,199] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139500, global step 2237018: loss 104.8371
[2019-03-26 23:19:40,201] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139500, global step 2237018: learning rate 0.0000
[2019-03-26 23:19:40,212] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139500, global step 2237023: loss 141.7335
[2019-03-26 23:19:40,214] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139500, global step 2237024: learning rate 0.0000
[2019-03-26 23:19:40,339] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139500, global step 2237076: loss 100.6248
[2019-03-26 23:19:40,345] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139500, global step 2237078: learning rate 0.0000
[2019-03-26 23:19:40,396] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139500, global step 2237102: loss 157.4600
[2019-03-26 23:19:40,399] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139500, global step 2237103: learning rate 0.0000
[2019-03-26 23:19:40,601] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139500, global step 2237193: loss 139.3291
[2019-03-26 23:19:40,606] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139500, global step 2237193: learning rate 0.0000
[2019-03-26 23:19:40,608] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139500, global step 2237193: loss 138.8318
[2019-03-26 23:19:40,612] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139500, global step 2237194: learning rate 0.0000
[2019-03-26 23:19:40,870] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139500, global step 2237311: loss 116.3405
[2019-03-26 23:19:40,871] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139500, global step 2237311: learning rate 0.0000
[2019-03-26 23:19:40,936] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139500, global step 2237338: loss 170.3159
[2019-03-26 23:19:40,940] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139500, global step 2237338: learning rate 0.0000
[2019-03-26 23:19:41,501] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140500, global step 2237585: loss 6.0921
[2019-03-26 23:19:41,503] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140500, global step 2237587: learning rate 0.0000
[2019-03-26 23:19:42,246] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6926521e-17 9.9002028e-01 2.6546787e-14 9.9796867e-03 1.3479278e-21], sum to 1.0000
[2019-03-26 23:19:42,254] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2193
[2019-03-26 23:19:42,258] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.5572072783193511, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 778639.8976404067, 778639.8976404074, 193046.4696373593], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4384800.0000, 
sim time next is 4385400.0000, 
raw observation next is [32.0, 66.33333333333334, 1.0, 2.0, 0.5586632898706433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 780675.2718181075, 780675.2718181082, 193299.168127657], 
processed observation next is [1.0, 0.782608695652174, 0.7156398104265403, 0.6633333333333334, 1.0, 1.0, 0.46826902394053405, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21685424217169652, 0.21685424217169672, 0.2885062210860552], 
reward next is 0.7115, 
noisyNet noise sample is [array([0.1953122], dtype=float32), -0.35014814]. 
=============================================
[2019-03-26 23:19:44,881] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.0817240e-19 1.0000000e+00 1.4743214e-17 5.8550331e-11 7.6214269e-23], sum to 1.0000
[2019-03-26 23:19:44,889] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4511
[2019-03-26 23:19:44,896] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 84.0, 1.0, 2.0, 0.5350621608363478, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9292260256122274, 6.911200000000001, 6.9112, 168.9125977774149, 1495893.620449872, 1495893.620449871, 327835.7787916775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4608000.0000, 
sim time next is 4608600.0000, 
raw observation next is [30.33333333333333, 82.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.665254442942516, 6.9112, 168.9092066312798, 1989061.651756402, 1454121.353356712, 311356.9438172957], 
processed observation next is [1.0, 0.34782608695652173, 0.6366508688783569, 0.825, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.07540544429425156, 0.0, 0.8294215315289681, 0.5525171254878894, 0.4039225981546422, 0.4647118564437249], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.12281322], dtype=float32), 0.38361138]. 
=============================================
[2019-03-26 23:19:46,282] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140000, global step 2239698: loss 0.0165
[2019-03-26 23:19:46,286] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140000, global step 2239698: learning rate 0.0000
[2019-03-26 23:19:46,791] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.9321992e-21 1.0000000e+00 6.1118159e-20 5.2318786e-14 5.9833041e-26], sum to 1.0000
[2019-03-26 23:19:46,803] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7095
[2019-03-26 23:19:46,810] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.16666666666666, 83.16666666666666, 1.0, 2.0, 0.6186802663250422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 864577.0415515371, 864577.0415515371, 204277.9738179434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4323000.0000, 
sim time next is 4323600.0000, 
raw observation next is [30.0, 84.0, 1.0, 2.0, 0.6175920862246743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 863055.74237274, 863055.7423727392, 204069.3819201233], 
processed observation next is [1.0, 0.043478260869565216, 0.6208530805687204, 0.84, 1.0, 1.0, 0.5392675737646678, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23973770621465, 0.2397377062146498, 0.30458116704496013], 
reward next is 0.6954, 
noisyNet noise sample is [array([-0.8872743], dtype=float32), 1.6684105]. 
=============================================
[2019-03-26 23:19:47,395] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3109111e-13 8.5495189e-02 8.5088742e-11 9.1450477e-01 3.7783145e-17], sum to 1.0000
[2019-03-26 23:19:47,405] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4346
[2019-03-26 23:19:47,412] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 63.00000000000001, 1.0, 2.0, 0.7935794438921357, 1.0, 2.0, 0.7935794438921357, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2219372.671260732, 2219372.671260732, 416751.8051641284], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4983600.0000, 
sim time next is 4984200.0000, 
raw observation next is [31.0, 63.0, 1.0, 2.0, 0.8150082464013609, 1.0, 2.0, 0.8150082464013609, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2279356.417349071, 2279356.417349071, 427237.6183474888], 
processed observation next is [1.0, 0.6956521739130435, 0.6682464454976303, 0.63, 1.0, 1.0, 0.7771183691582662, 1.0, 1.0, 0.7771183691582662, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6331545603747419, 0.6331545603747419, 0.6376680870858042], 
reward next is 0.3623, 
noisyNet noise sample is [array([-1.0888721], dtype=float32), 2.0264046]. 
=============================================
[2019-03-26 23:19:49,555] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140000, global step 2241162: loss 0.0150
[2019-03-26 23:19:49,558] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140000, global step 2241162: learning rate 0.0000
[2019-03-26 23:19:51,224] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141000, global step 2241905: loss 0.0167
[2019-03-26 23:19:51,230] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141000, global step 2241906: learning rate 0.0000
[2019-03-26 23:19:52,831] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140500, global step 2242617: loss -51.0515
[2019-03-26 23:19:52,837] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140500, global step 2242618: learning rate 0.0000
[2019-03-26 23:19:54,204] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140000, global step 2243228: loss 0.0132
[2019-03-26 23:19:54,210] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140000, global step 2243228: learning rate 0.0000
[2019-03-26 23:19:54,637] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9126747e-22 1.0000000e+00 4.3655669e-21 6.5896385e-14 1.1970820e-28], sum to 1.0000
[2019-03-26 23:19:54,649] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6587
[2019-03-26 23:19:54,655] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 74.0, 1.0, 2.0, 0.4745648029814758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 669080.7530330656, 669080.753033065, 180474.7162654271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4651800.0000, 
sim time next is 4652400.0000, 
raw observation next is [26.66666666666667, 78.0, 1.0, 2.0, 0.4718766926789524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 665992.9614055092, 665992.9614055092, 180161.2066178872], 
processed observation next is [1.0, 0.8695652173913043, 0.4628751974723541, 0.78, 1.0, 1.0, 0.3637068586493402, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18499804483486365, 0.18499804483486365, 0.2688973233102794], 
reward next is 0.7311, 
noisyNet noise sample is [array([1.0271634], dtype=float32), -0.722409]. 
=============================================
[2019-03-26 23:19:54,880] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141000, global step 2243528: loss 0.0195
[2019-03-26 23:19:54,881] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141000, global step 2243528: learning rate 0.0000
[2019-03-26 23:19:55,003] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2168975e-22 1.0000000e+00 1.2909606e-22 7.2834849e-18 1.0536280e-28], sum to 1.0000
[2019-03-26 23:19:55,013] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8769
[2019-03-26 23:19:55,022] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 75.0, 1.0, 2.0, 0.632968016525192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 884551.8256887555, 884551.8256887548, 207049.2942383701], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4444200.0000, 
sim time next is 4444800.0000, 
raw observation next is [32.0, 75.0, 1.0, 2.0, 0.632362869431495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 883705.8008596677, 883705.8008596677, 206930.7413228846], 
processed observation next is [0.0, 0.43478260869565216, 0.7156398104265403, 0.75, 1.0, 1.0, 0.5570636981102349, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24547383357212993, 0.24547383357212993, 0.3088518527207233], 
reward next is 0.6911, 
noisyNet noise sample is [array([0.18869811], dtype=float32), 0.18106171]. 
=============================================
[2019-03-26 23:19:57,277] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140500, global step 2244594: loss -18.6002
[2019-03-26 23:19:57,281] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140500, global step 2244595: learning rate 0.0000
[2019-03-26 23:19:57,897] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140000, global step 2244869: loss 0.0103
[2019-03-26 23:19:57,900] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140000, global step 2244869: learning rate 0.0000
[2019-03-26 23:19:58,474] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140000, global step 2245124: loss 0.0094
[2019-03-26 23:19:58,479] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140000, global step 2245127: learning rate 0.0000
[2019-03-26 23:19:58,549] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140000, global step 2245156: loss 0.0101
[2019-03-26 23:19:58,550] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140000, global step 2245156: learning rate 0.0000
[2019-03-26 23:19:58,586] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140000, global step 2245172: loss 0.0104
[2019-03-26 23:19:58,588] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140000, global step 2245173: learning rate 0.0000
[2019-03-26 23:19:58,670] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140000, global step 2245211: loss 0.0095
[2019-03-26 23:19:58,673] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140000, global step 2245211: learning rate 0.0000
[2019-03-26 23:19:58,692] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140000, global step 2245220: loss 0.0098
[2019-03-26 23:19:58,693] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140000, global step 2245220: learning rate 0.0000
[2019-03-26 23:19:58,862] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140000, global step 2245295: loss 0.0102
[2019-03-26 23:19:58,865] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140000, global step 2245296: learning rate 0.0000
[2019-03-26 23:19:59,028] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140000, global step 2245368: loss 0.0091
[2019-03-26 23:19:59,033] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140000, global step 2245368: learning rate 0.0000
[2019-03-26 23:19:59,452] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141000, global step 2245546: loss 0.0263
[2019-03-26 23:19:59,455] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141000, global step 2245547: learning rate 0.0000
[2019-03-26 23:20:04,446] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140500, global step 2247773: loss -1.1470
[2019-03-26 23:20:04,450] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140500, global step 2247774: learning rate 0.0000
[2019-03-26 23:20:07,788] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140500, global step 2249256: loss -16.5421
[2019-03-26 23:20:07,789] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140500, global step 2249256: learning rate 0.0000
[2019-03-26 23:20:07,825] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1634247e-21 1.0000000e+00 6.7870311e-20 9.9265708e-16 1.6341415e-26], sum to 1.0000
[2019-03-26 23:20:07,835] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9358
[2019-03-26 23:20:07,843] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.5023556926498313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 701965.1180817671, 701965.1180817671, 183965.8295202671], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4667400.0000, 
sim time next is 4668000.0000, 
raw observation next is [26.33333333333334, 87.33333333333334, 1.0, 2.0, 0.5034974661537365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 703561.099982467, 703561.0999824664, 184145.8698682397], 
processed observation next is [1.0, 0.0, 0.44707740916271754, 0.8733333333333334, 1.0, 1.0, 0.4018041760888391, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19543363888401863, 0.19543363888401846, 0.27484458189289507], 
reward next is 0.7252, 
noisyNet noise sample is [array([-1.003389], dtype=float32), 0.8676203]. 
=============================================
[2019-03-26 23:20:07,859] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[68.0081 ]
 [68.5917 ]
 [69.15997]
 [69.97666]
 [70.78464]], R is [[67.59651184]
 [67.64597321]
 [67.69538879]
 [67.74524689]
 [67.79555511]].
[2019-03-26 23:20:07,965] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.1854118e-21 1.0000000e+00 2.7329770e-20 2.1406475e-15 2.6201217e-26], sum to 1.0000
[2019-03-26 23:20:07,977] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9571
[2019-03-26 23:20:07,985] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5069772357225876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 708425.1698864554, 708425.169886456, 184696.6834716284], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4669200.0000, 
sim time next is 4669800.0000, 
raw observation next is [27.0, 84.83333333333333, 1.0, 2.0, 0.5101189259999527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712816.6870251385, 712816.6870251378, 185196.9682904144], 
processed observation next is [1.0, 0.043478260869565216, 0.4786729857819906, 0.8483333333333333, 1.0, 1.0, 0.40978183855415984, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1980046352847607, 0.1980046352847605, 0.2764133855080812], 
reward next is 0.7236, 
noisyNet noise sample is [array([-0.07657277], dtype=float32), -0.22294015]. 
=============================================
[2019-03-26 23:20:09,045] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0042986e-21 1.0000000e+00 3.5711565e-20 4.2904550e-14 1.6066906e-26], sum to 1.0000
[2019-03-26 23:20:09,057] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3403
[2019-03-26 23:20:09,064] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 87.33333333333334, 1.0, 2.0, 0.9252187122812912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1293211.179463326, 1293211.179463327, 276969.1998545301], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4688400.0000, 
sim time next is 4689000.0000, 
raw observation next is [27.5, 86.5, 1.0, 2.0, 0.9592886103637915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1340861.963088486, 1340861.963088486, 286767.4255070675], 
processed observation next is [1.0, 0.2608695652173913, 0.5023696682464456, 0.865, 1.0, 1.0, 0.9509501329684236, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.37246165641346834, 0.37246165641346834, 0.42801108284636946], 
reward next is 0.5720, 
noisyNet noise sample is [array([-1.0704362], dtype=float32), -0.5351026]. 
=============================================
[2019-03-26 23:20:09,079] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[66.891655]
 [67.341034]
 [67.73678 ]
 [67.8268  ]
 [67.884285]], R is [[66.45722961]
 [66.37927246]
 [66.31866455]
 [66.3401947 ]
 [66.36386871]].
[2019-03-26 23:20:09,457] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 23:20:09,458] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 23:20:09,460] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 23:20:09,460] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:20:09,464] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:20:09,465] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 23:20:09,462] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 23:20:09,468] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 23:20:09,468] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:20:09,469] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:20:09,471] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:20:09,495] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run91
[2019-03-26 23:20:09,521] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run91
[2019-03-26 23:20:09,548] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run91
[2019-03-26 23:20:09,571] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run91
[2019-03-26 23:20:09,595] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run91
[2019-03-26 23:20:59,941] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09433937], dtype=float32), 0.07268332]
[2019-03-26 23:20:59,945] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 70.0, 1.0, 2.0, 0.534210779366559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 746493.3621376987, 746493.362137698, 189132.3836537661]
[2019-03-26 23:20:59,946] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:20:59,949] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.2202173e-21 1.0000000e+00 1.9432584e-18 1.6451398e-08 7.0052321e-26], sampled 0.5046655820565334
[2019-03-26 23:21:06,994] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09433937], dtype=float32), 0.07268332]
[2019-03-26 23:21:06,995] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.87333309833333, 74.26601601166666, 1.0, 2.0, 0.5354389579521942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 748210.1939505028, 748210.1939505034, 189333.9199520967]
[2019-03-26 23:21:06,997] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:21:06,999] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.7192984e-24 1.0000000e+00 5.0106245e-23 1.3401745e-17 1.3484585e-29], sampled 0.6844670106619571
[2019-03-26 23:21:10,119] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09433937], dtype=float32), 0.07268332]
[2019-03-26 23:21:10,120] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.83333333333334, 84.83333333333333, 1.0, 2.0, 0.5806682511980742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 811436.7183846717, 811436.7183846717, 197199.6546098688]
[2019-03-26 23:21:10,121] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:21:10,124] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.6975594e-23 1.0000000e+00 1.9753326e-22 6.6435163e-17 7.2509812e-29], sampled 0.9072399149557874
[2019-03-26 23:21:11,956] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09433937], dtype=float32), 0.07268332]
[2019-03-26 23:21:11,960] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.8, 62.33333333333334, 1.0, 2.0, 0.5442987031416904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 760595.0323927877, 760595.0323927877, 190827.9291792761]
[2019-03-26 23:21:11,960] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:21:11,963] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.7254545e-22 1.0000000e+00 1.1975384e-21 1.5344918e-16 7.8330397e-28], sampled 0.8332268313114091
[2019-03-26 23:21:12,748] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09433937], dtype=float32), 0.07268332]
[2019-03-26 23:21:12,750] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [36.40000000000001, 51.33333333333334, 1.0, 2.0, 0.5998192812116578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565094672, 838209.2872254337, 838209.2872254337, 200713.3080930683]
[2019-03-26 23:21:12,751] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:21:12,754] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.2362046e-19 1.0000000e+00 1.1636806e-16 1.7311104e-08 5.6529930e-23], sampled 0.951771350269377
[2019-03-26 23:21:31,804] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09433937], dtype=float32), 0.07268332]
[2019-03-26 23:21:31,805] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.5, 87.0, 1.0, 2.0, 0.5194312625950179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 725833.7629470523, 725833.7629470523, 186695.802563423]
[2019-03-26 23:21:31,807] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:21:31,809] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.6558184e-23 1.0000000e+00 3.2272893e-22 3.5753873e-17 1.7119434e-28], sampled 0.5154698678649576
[2019-03-26 23:21:55,430] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09433937], dtype=float32), 0.07268332]
[2019-03-26 23:21:55,431] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.05727597666667, 71.63222812333333, 1.0, 2.0, 0.3777608638548565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 569177.4447443136, 569177.4447443143, 171920.4963272333]
[2019-03-26 23:21:55,434] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:21:55,435] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0808086e-22 1.0000000e+00 6.8694381e-22 3.8966523e-17 4.1912049e-28], sampled 0.38208183977457044
[2019-03-26 23:22:03,468] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7895.0736 3163504777.9926 1733.0000
[2019-03-26 23:22:03,836] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09433937], dtype=float32), 0.07268332]
[2019-03-26 23:22:03,837] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.9496133, 65.89464912833334, 1.0, 2.0, 0.9617195343981911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1344261.97972507, 1344261.979725069, 287479.6753724451]
[2019-03-26 23:22:03,839] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:22:03,841] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.576661e-22 1.000000e+00 2.666094e-21 6.633770e-16 1.061297e-27], sampled 0.5771253766870456
[2019-03-26 23:22:04,008] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8258.6448 2926990082.5790 1328.0000
[2019-03-26 23:22:04,049] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8005.7886 3006515946.5298 1736.0000
[2019-03-26 23:22:04,062] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8507.4044 2841571407.4557 1107.0000
[2019-03-26 23:22:04,081] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.3326 2779464490.5745 933.0000
[2019-03-26 23:22:05,099] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2250000, evaluation results [2250000.0, 7895.07359686006, 3163504777.9925632, 1733.0, 8258.6447789634, 2926990082.5790195, 1328.0, 8660.33261110383, 2779464490.5744677, 933.0, 8005.788629384365, 3006515946.5298114, 1736.0, 8507.404374053407, 2841571407.455745, 1107.0]
[2019-03-26 23:22:05,156] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141500, global step 2250030: loss -66.1312
[2019-03-26 23:22:05,158] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141500, global step 2250030: learning rate 0.0000
[2019-03-26 23:22:06,504] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9942154e-22 1.0000000e+00 4.5658492e-22 2.1814841e-17 1.6301054e-28], sum to 1.0000
[2019-03-26 23:22:06,512] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8328
[2019-03-26 23:22:06,516] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4844543652788972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 676942.7853406632, 676942.7853406626, 181195.4612299172], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5108400.0000, 
sim time next is 5109000.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4830693989562231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 675067.2344215836, 675067.2344215829, 180993.0059718229], 
processed observation next is [0.0, 0.13043478260869565, 0.4312796208530806, 0.84, 1.0, 1.0, 0.3771920469352086, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18751867622821766, 0.18751867622821747, 0.27013881488331776], 
reward next is 0.7299, 
noisyNet noise sample is [array([-1.2246909], dtype=float32), 0.4527876]. 
=============================================
[2019-03-26 23:22:06,525] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[71.98677 ]
 [71.95466 ]
 [71.93395 ]
 [71.8948  ]
 [71.795845]], R is [[72.02185059]
 [72.03119659]
 [72.03961182]
 [72.04709625]
 [72.05363464]].
[2019-03-26 23:22:06,724] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141000, global step 2250724: loss 0.0267
[2019-03-26 23:22:06,729] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141000, global step 2250724: learning rate 0.0000
[2019-03-26 23:22:07,406] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.9277517e-21 1.0000000e+00 2.6350947e-20 2.3923961e-15 6.4888932e-27], sum to 1.0000
[2019-03-26 23:22:07,416] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2508
[2019-03-26 23:22:07,426] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.7242456710397478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1012170.107943948, 1012170.107943947, 226163.3074419636], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4935600.0000, 
sim time next is 4936200.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.7784100719663944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1087906.384181408, 1087906.384181408, 238677.8849038491], 
processed observation next is [1.0, 0.13043478260869565, 0.4312796208530806, 0.89, 1.0, 1.0, 0.7330241830920415, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.30219621782816886, 0.30219621782816886, 0.35623564911022254], 
reward next is 0.6438, 
noisyNet noise sample is [array([-0.93631005], dtype=float32), -0.7679494]. 
=============================================
[2019-03-26 23:22:07,992] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140500, global step 2251292: loss 16.1383
[2019-03-26 23:22:07,992] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140500, global step 2251292: learning rate 0.0000
[2019-03-26 23:22:08,470] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141500, global step 2251507: loss -66.3430
[2019-03-26 23:22:08,471] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141500, global step 2251508: learning rate 0.0000
[2019-03-26 23:22:10,873] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141000, global step 2252585: loss 0.0284
[2019-03-26 23:22:10,877] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141000, global step 2252585: learning rate 0.0000
[2019-03-26 23:22:11,583] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140500, global step 2252898: loss -9.9581
[2019-03-26 23:22:11,586] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140500, global step 2252898: learning rate 0.0000
[2019-03-26 23:22:12,119] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140500, global step 2253137: loss 4.4087
[2019-03-26 23:22:12,122] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140500, global step 2253139: learning rate 0.0000
[2019-03-26 23:22:12,149] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140500, global step 2253154: loss -51.5764
[2019-03-26 23:22:12,153] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140500, global step 2253154: learning rate 0.0000
[2019-03-26 23:22:12,245] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140500, global step 2253195: loss 5.5569
[2019-03-26 23:22:12,248] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140500, global step 2253195: learning rate 0.0000
[2019-03-26 23:22:12,270] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140500, global step 2253205: loss -55.0059
[2019-03-26 23:22:12,273] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140500, global step 2253205: learning rate 0.0000
[2019-03-26 23:22:12,382] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140500, global step 2253257: loss -51.1849
[2019-03-26 23:22:12,386] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140500, global step 2253259: learning rate 0.0000
[2019-03-26 23:22:12,438] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140500, global step 2253278: loss 3.2604
[2019-03-26 23:22:12,441] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140500, global step 2253278: learning rate 0.0000
[2019-03-26 23:22:12,578] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140500, global step 2253348: loss -28.7429
[2019-03-26 23:22:12,588] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140500, global step 2253349: learning rate 0.0000
[2019-03-26 23:22:13,172] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141500, global step 2253603: loss -66.1588
[2019-03-26 23:22:13,174] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141500, global step 2253603: learning rate 0.0000
[2019-03-26 23:22:17,778] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.3987034e-20 9.9999976e-01 7.3654921e-17 2.3188031e-07 8.8278900e-25], sum to 1.0000
[2019-03-26 23:22:17,789] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3215
[2019-03-26 23:22:17,795] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 70.0, 1.0, 2.0, 0.4822587121336495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 673873.7594510508, 673873.7594510501, 180864.0671064189], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4903200.0000, 
sim time next is 4903800.0000, 
raw observation next is [29.0, 70.0, 1.0, 2.0, 0.4885937958356684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 682728.7959970834, 682728.7959970834, 181828.9288418746], 
processed observation next is [1.0, 0.782608695652174, 0.5734597156398105, 0.7, 1.0, 1.0, 0.3838479467899619, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18964688777696762, 0.18964688777696762, 0.27138646095802177], 
reward next is 0.7286, 
noisyNet noise sample is [array([-0.01993723], dtype=float32), -1.2772409]. 
=============================================
[2019-03-26 23:22:17,900] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141000, global step 2255670: loss 0.0295
[2019-03-26 23:22:17,902] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141000, global step 2255670: learning rate 0.0000
[2019-03-26 23:22:21,341] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141000, global step 2257208: loss 0.0379
[2019-03-26 23:22:21,344] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141000, global step 2257209: learning rate 0.0000
[2019-03-26 23:22:22,856] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142000, global step 2257882: loss 0.1489
[2019-03-26 23:22:22,859] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142000, global step 2257883: learning rate 0.0000
[2019-03-26 23:22:24,718] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141500, global step 2258706: loss -66.2579
[2019-03-26 23:22:24,721] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141500, global step 2258707: learning rate 0.0000
[2019-03-26 23:22:24,918] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0316172e-23 1.0000000e+00 1.2926059e-23 5.3527312e-18 4.0415542e-30], sum to 1.0000
[2019-03-26 23:22:24,925] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7995
[2019-03-26 23:22:24,929] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 85.0, 1.0, 2.0, 0.5373561199602739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 750890.1393398107, 750890.1393398113, 189655.7173870411], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5691600.0000, 
sim time next is 5692200.0000, 
raw observation next is [27.41666666666667, 85.16666666666667, 1.0, 2.0, 0.5371257793989258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 750568.1525656576, 750568.1525656576, 189616.9457800235], 
processed observation next is [0.0, 0.9130434782608695, 0.4984202211690366, 0.8516666666666667, 1.0, 1.0, 0.4423202161432841, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20849115349046046, 0.20849115349046046, 0.28301036683585595], 
reward next is 0.7170, 
noisyNet noise sample is [array([-2.1576393], dtype=float32), 1.0185499]. 
=============================================
[2019-03-26 23:22:25,808] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141000, global step 2259190: loss 0.0454
[2019-03-26 23:22:25,811] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141000, global step 2259191: learning rate 0.0000
[2019-03-26 23:22:26,109] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142000, global step 2259325: loss 0.1319
[2019-03-26 23:22:26,112] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142000, global step 2259325: learning rate 0.0000
[2019-03-26 23:22:28,369] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.4622043e-24 1.0000000e+00 8.0979664e-24 4.3958706e-18 6.0752900e-30], sum to 1.0000
[2019-03-26 23:22:28,382] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5090
[2019-03-26 23:22:28,387] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333334, 74.83333333333334, 1.0, 2.0, 0.5248795025148314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733449.5574072966, 733449.5574072966, 187585.9269139266], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5080200.0000, 
sim time next is 5080800.0000, 
raw observation next is [28.66666666666667, 75.66666666666667, 1.0, 2.0, 0.5237618848688189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 731887.2968138687, 731887.2968138687, 187402.7654888128], 
processed observation next is [0.0, 0.8260869565217391, 0.5576619273301741, 0.7566666666666667, 1.0, 1.0, 0.4262191383961673, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2033020268927413, 0.2033020268927413, 0.2797056201325564], 
reward next is 0.7203, 
noisyNet noise sample is [array([0.88027203], dtype=float32), -1.9377493]. 
=============================================
[2019-03-26 23:22:29,120] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141500, global step 2260667: loss -67.7406
[2019-03-26 23:22:29,122] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141500, global step 2260667: learning rate 0.0000
[2019-03-26 23:22:29,630] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141000, global step 2260896: loss 0.0570
[2019-03-26 23:22:29,634] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141000, global step 2260897: learning rate 0.0000
[2019-03-26 23:22:30,213] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141000, global step 2261153: loss 0.0548
[2019-03-26 23:22:30,215] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141000, global step 2261153: learning rate 0.0000
[2019-03-26 23:22:30,259] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141000, global step 2261173: loss 0.0543
[2019-03-26 23:22:30,261] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141000, global step 2261173: learning rate 0.0000
[2019-03-26 23:22:30,367] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141000, global step 2261225: loss 0.0560
[2019-03-26 23:22:30,370] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141000, global step 2261225: learning rate 0.0000
[2019-03-26 23:22:30,400] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141000, global step 2261239: loss 0.0540
[2019-03-26 23:22:30,406] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141000, global step 2261239: learning rate 0.0000
[2019-03-26 23:22:30,504] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141000, global step 2261283: loss 0.0552
[2019-03-26 23:22:30,509] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141000, global step 2261284: learning rate 0.0000
[2019-03-26 23:22:30,542] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141000, global step 2261301: loss 0.0552
[2019-03-26 23:22:30,545] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141000, global step 2261302: learning rate 0.0000
[2019-03-26 23:22:30,791] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141000, global step 2261410: loss 0.0522
[2019-03-26 23:22:30,795] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141000, global step 2261411: learning rate 0.0000
[2019-03-26 23:22:31,014] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142000, global step 2261510: loss 0.1188
[2019-03-26 23:22:31,016] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142000, global step 2261511: learning rate 0.0000
[2019-03-26 23:22:36,147] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141500, global step 2263793: loss -66.9597
[2019-03-26 23:22:36,150] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141500, global step 2263794: learning rate 0.0000
[2019-03-26 23:22:39,495] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141500, global step 2265276: loss -66.1162
[2019-03-26 23:22:39,500] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141500, global step 2265278: learning rate 0.0000
[2019-03-26 23:22:40,445] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7054150e-21 1.0000000e+00 6.3564432e-21 2.0694908e-15 5.0678216e-27], sum to 1.0000
[2019-03-26 23:22:40,455] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4421
[2019-03-26 23:22:40,460] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 87.0, 1.0, 2.0, 0.5802270925260518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 810819.9996689438, 810819.9996689438, 197120.3107537131], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5277600.0000, 
sim time next is 5278200.0000, 
raw observation next is [28.6, 87.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.982328836201892, 6.9112, 169.8343516810795, 2932030.404485472, 1454685.347279255, 309527.7435459083], 
processed observation next is [1.0, 0.08695652173913043, 0.5545023696682465, 0.87, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.20711288362018926, 0.0, 0.8339644172567212, 0.8144528901348533, 0.4040792631331264, 0.4619817067849378], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2310336], dtype=float32), 0.62591785]. 
=============================================
[2019-03-26 23:22:40,872] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142500, global step 2265893: loss -171.8701
[2019-03-26 23:22:40,874] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142500, global step 2265893: learning rate 0.0000
[2019-03-26 23:22:41,429] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2154659e-20 1.0000000e+00 1.4220817e-18 3.5679914e-12 2.0275493e-25], sum to 1.0000
[2019-03-26 23:22:41,442] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0599
[2019-03-26 23:22:41,448] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1696244.454574997 W.
[2019-03-26 23:22:41,455] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.23333333333333, 82.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.252776829312349, 6.9112, 168.9110073288307, 1696244.454574997, 1453920.892033781, 311356.3010119724], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5298000.0000, 
sim time next is 5298600.0000, 
raw observation next is [30.36666666666667, 81.5, 1.0, 2.0, 0.3797584371375168, 1.0, 1.0, 0.3797584371375168, 1.0, 1.0, 0.6595148172736077, 6.911199999999999, 6.9112, 170.5573041426782, 1592618.643988952, 1592618.643988952, 341968.0834376134], 
processed observation next is [1.0, 0.30434782608695654, 0.6382306477093209, 0.815, 1.0, 1.0, 0.2527210085994178, 1.0, 0.5, 0.2527210085994178, 1.0, 0.5, 0.5847741674068386, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4423940677747089, 0.4423940677747089, 0.5104001245337513], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1790745], dtype=float32), 0.96231174]. 
=============================================
[2019-03-26 23:22:42,440] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142000, global step 2266590: loss 0.1381
[2019-03-26 23:22:42,442] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142000, global step 2266590: learning rate 0.0000
[2019-03-26 23:22:44,013] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142500, global step 2267287: loss -117.6312
[2019-03-26 23:22:44,015] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142500, global step 2267287: learning rate 0.0000
[2019-03-26 23:22:44,039] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141500, global step 2267296: loss -64.5669
[2019-03-26 23:22:44,041] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141500, global step 2267296: learning rate 0.0000
[2019-03-26 23:22:46,498] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8615199e-10 1.4731723e-01 3.6243535e-09 8.5268277e-01 2.8142788e-13], sum to 1.0000
[2019-03-26 23:22:46,509] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9359
[2019-03-26 23:22:46,514] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.3, 66.66666666666667, 1.0, 2.0, 0.820359229782858, 1.0, 2.0, 0.820359229782858, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2294335.399716385, 2294335.399716385, 429917.6538955713], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5390400.0000, 
sim time next is 5391000.0000, 
raw observation next is [33.5, 66.0, 1.0, 2.0, 0.8273147333488671, 1.0, 2.0, 0.8273147333488671, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2313806.176179652, 2313806.176179652, 433401.452777222], 
processed observation next is [1.0, 0.391304347826087, 0.7867298578199052, 0.66, 1.0, 1.0, 0.7919454618661049, 1.0, 1.0, 0.7919454618661049, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6427239378276811, 0.6427239378276811, 0.6468678399660029], 
reward next is 0.3531, 
noisyNet noise sample is [array([0.5865371], dtype=float32), -0.103418656]. 
=============================================
[2019-03-26 23:22:46,530] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[33.651684]
 [32.22856 ]
 [31.429468]
 [34.616863]
 [36.011036]], R is [[35.18370438]
 [35.19020081]
 [34.8382988 ]
 [34.48991776]
 [34.32432938]].
[2019-03-26 23:22:47,017] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142000, global step 2268619: loss 0.1494
[2019-03-26 23:22:47,021] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142000, global step 2268619: learning rate 0.0000
[2019-03-26 23:22:47,097] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.8780871e-12 1.6139327e-01 7.4091894e-10 8.3860672e-01 1.0579293e-14], sum to 1.0000
[2019-03-26 23:22:47,106] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4486
[2019-03-26 23:22:47,110] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.7, 65.33333333333333, 1.0, 2.0, 0.9262657093958225, 1.0, 2.0, 0.9262657093958225, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2590835.854650835, 2590835.854650835, 486034.9506473957], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5391600.0000, 
sim time next is 5392200.0000, 
raw observation next is [33.9, 64.66666666666667, 1.0, 2.0, 0.964543778865618, 1.0, 2.0, 0.964543778865618, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2698018.140456405, 2698018.140456405, 507938.4388024397], 
processed observation next is [1.0, 0.391304347826087, 0.8056872037914692, 0.6466666666666667, 1.0, 1.0, 0.9572816612838771, 1.0, 1.0, 0.9572816612838771, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7494494834601125, 0.7494494834601125, 0.7581170728394623], 
reward next is 0.2419, 
noisyNet noise sample is [array([-0.27794647], dtype=float32), -1.6241697]. 
=============================================
[2019-03-26 23:22:47,380] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4040759e-17 9.7208257e-08 2.2948784e-13 9.9999988e-01 5.2853243e-19], sum to 1.0000
[2019-03-26 23:22:47,391] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0287
[2019-03-26 23:22:47,398] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.98333333333333, 59.0, 1.0, 2.0, 0.9224916566025866, 1.0, 2.0, 0.7818358678155557, 1.0, 1.0, 1.03, 7.005115281978089, 6.9112, 170.5573041426782, 3281187.400581491, 3213912.063871166, 600822.3000095589], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5404200.0000, 
sim time next is 5404800.0000, 
raw observation next is [36.96666666666667, 58.00000000000001, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 8.802670122660206, 6.9112, 170.5573041426782, 4265845.527276194, 2910908.538329342, 541446.2044233], 
processed observation next is [1.0, 0.5652173913043478, 0.9510268562401265, 0.5800000000000001, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.18914701226602065, 0.0, 0.8375144448122397, 1.1849570909100537, 0.8085857050914839, 0.8081286633183582], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.37046576], dtype=float32), -0.9135772]. 
=============================================
[2019-03-26 23:22:47,802] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141500, global step 2268971: loss -65.3591
[2019-03-26 23:22:47,806] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141500, global step 2268971: learning rate 0.0000
[2019-03-26 23:22:47,900] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.6699023e-17 7.2265372e-08 3.1605388e-13 9.9999988e-01 3.5409074e-19], sum to 1.0000
[2019-03-26 23:22:47,907] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4663
[2019-03-26 23:22:47,913] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.98333333333333, 59.0, 1.0, 2.0, 0.9224916566025866, 1.0, 2.0, 0.7818358678155557, 1.0, 1.0, 1.03, 7.005115281978089, 6.9112, 170.5573041426782, 3281187.400581491, 3213912.063871166, 600822.3000095589], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5404200.0000, 
sim time next is 5404800.0000, 
raw observation next is [36.96666666666667, 58.00000000000001, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 8.802670122660206, 6.9112, 170.5573041426782, 4265845.527276194, 2910908.538329342, 541446.2044233], 
processed observation next is [1.0, 0.5652173913043478, 0.9510268562401265, 0.5800000000000001, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.18914701226602065, 0.0, 0.8375144448122397, 1.1849570909100537, 0.8085857050914839, 0.8081286633183582], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6127148], dtype=float32), 0.4912679]. 
=============================================
[2019-03-26 23:22:48,246] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141500, global step 2269162: loss -65.3418
[2019-03-26 23:22:48,247] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141500, global step 2269163: learning rate 0.0000
[2019-03-26 23:22:48,343] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141500, global step 2269208: loss -65.2698
[2019-03-26 23:22:48,344] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141500, global step 2269208: loss -64.9137
[2019-03-26 23:22:48,345] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141500, global step 2269208: learning rate 0.0000
[2019-03-26 23:22:48,347] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141500, global step 2269208: learning rate 0.0000
[2019-03-26 23:22:48,470] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141500, global step 2269267: loss -65.0772
[2019-03-26 23:22:48,474] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141500, global step 2269267: learning rate 0.0000
[2019-03-26 23:22:48,566] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141500, global step 2269302: loss -64.8202
[2019-03-26 23:22:48,569] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141500, global step 2269303: learning rate 0.0000
[2019-03-26 23:22:48,624] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141500, global step 2269332: loss -38.5417
[2019-03-26 23:22:48,626] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141500, global step 2269333: learning rate 0.0000
[2019-03-26 23:22:48,632] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5576833e-15 2.1694519e-04 3.4824617e-13 9.9978310e-01 8.3191431e-19], sum to 1.0000
[2019-03-26 23:22:48,640] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5696
[2019-03-26 23:22:48,649] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.09999999999999, 54.0, 1.0, 2.0, 0.9622065841148877, 1.0, 2.0, 0.9622065841148877, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2691473.506183254, 2691473.506183253, 506575.1436447324], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5488800.0000, 
sim time next is 5489400.0000, 
raw observation next is [36.2, 53.0, 1.0, 2.0, 0.950823110009963, 1.0, 2.0, 0.950823110009963, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2659597.887254532, 2659597.887254532, 499986.218565984], 
processed observation next is [1.0, 0.5217391304347826, 0.9146919431279622, 0.53, 1.0, 1.0, 0.9407507349517626, 1.0, 1.0, 0.9407507349517626, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7387771909040367, 0.7387771909040367, 0.7462480874119164], 
reward next is 0.2538, 
noisyNet noise sample is [array([1.3894044], dtype=float32), 1.2520585]. 
=============================================
[2019-03-26 23:22:48,887] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141500, global step 2269449: loss -65.0754
[2019-03-26 23:22:48,889] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141500, global step 2269449: learning rate 0.0000
[2019-03-26 23:22:48,944] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142500, global step 2269474: loss -244.4232
[2019-03-26 23:22:48,945] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142500, global step 2269474: learning rate 0.0000
[2019-03-26 23:22:52,114] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.0914605e-20 1.0000000e+00 6.6025303e-19 2.2584738e-12 3.7180121e-25], sum to 1.0000
[2019-03-26 23:22:52,124] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6021
[2019-03-26 23:22:52,136] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1671305.411091168 W.
[2019-03-26 23:22:52,141] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.81666666666667, 76.83333333333333, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.217646707954934, 6.9112, 168.9112068621746, 1671305.411091168, 1453903.821316813, 311355.5728239223], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5471400.0000, 
sim time next is 5472000.0000, 
raw observation next is [31.0, 76.0, 1.0, 2.0, 0.5530087933209966, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9603933911960068, 6.911200000000001, 6.9112, 168.9127069883284, 1546104.24421114, 1546104.244211139, 338408.6810583982], 
processed observation next is [1.0, 0.34782608695652173, 0.6682464454976303, 0.76, 1.0, 1.0, 0.4614563774951766, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.9516992575561058, 8.881784197001253e-17, 0.0, 0.8294387198845472, 0.4294734011697611, 0.4294734011697608, 0.5050875836692511], 
reward next is 0.4949, 
noisyNet noise sample is [array([-1.0434953], dtype=float32), -0.7442233]. 
=============================================
[2019-03-26 23:22:52,168] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[62.000484]
 [61.570263]
 [61.056683]
 [60.173607]
 [59.6516  ]], R is [[58.57746506]
 [57.99169159]
 [57.9473114 ]
 [57.94800568]
 [57.94807053]].
[2019-03-26 23:22:54,022] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142000, global step 2271730: loss 0.1670
[2019-03-26 23:22:54,025] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142000, global step 2271731: learning rate 0.0000
[2019-03-26 23:22:54,364] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.2253384e-23 1.0000000e+00 3.0918839e-22 6.6006449e-18 2.7797019e-28], sum to 1.0000
[2019-03-26 23:22:54,374] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8716
[2019-03-26 23:22:54,378] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.86666666666667, 90.33333333333333, 1.0, 2.0, 0.5101268170908337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712827.7173717354, 712827.7173717354, 185197.4327948444], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5717400.0000, 
sim time next is 5718000.0000, 
raw observation next is [25.83333333333334, 90.66666666666667, 1.0, 2.0, 0.5101049899327499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 712797.2068732105, 712797.2068732111, 185193.977232375], 
processed observation next is [0.0, 0.17391304347826086, 0.42338072669826254, 0.9066666666666667, 1.0, 1.0, 0.4097650481117468, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19799922413144735, 0.19799922413144752, 0.2764089212423508], 
reward next is 0.7236, 
noisyNet noise sample is [array([1.6109915], dtype=float32), 0.6489837]. 
=============================================
[2019-03-26 23:22:54,391] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[72.064186]
 [72.14689 ]
 [72.15892 ]
 [72.25658 ]
 [72.25372 ]], R is [[72.02485657]
 [72.02819824]
 [72.03154755]
 [72.03444672]
 [72.03707123]].
[2019-03-26 23:22:55,047] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9986437e-15 6.2831074e-01 1.0184748e-11 3.7168923e-01 1.1691634e-17], sum to 1.0000
[2019-03-26 23:22:55,055] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1838
[2019-03-26 23:22:55,063] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2218352.783278264 W.
[2019-03-26 23:22:55,067] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.96666666666667, 74.33333333333334, 1.0, 2.0, 0.9452363959251254, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.000626396998275, 6.9112, 168.9124250126296, 2218352.783278264, 2154910.819054357, 447110.363380797], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5924400.0000, 
sim time next is 5925000.0000, 
raw observation next is [29.83333333333333, 74.66666666666666, 1.0, 2.0, 0.5178520903260454, 1.0, 1.0, 0.5178520903260454, 1.0, 2.0, 0.8993378245931203, 6.911199999999999, 6.9112, 170.5573041426782, 2172338.43607252, 2172338.436072521, 427710.4369426022], 
processed observation next is [1.0, 0.5652173913043478, 0.6129541864139019, 0.7466666666666666, 1.0, 1.0, 0.4190989040072836, 1.0, 0.5, 0.4190989040072836, 1.0, 1.0, 0.8772412495038052, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6034273433534778, 0.603427343353478, 0.6383737864814959], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.47475734], dtype=float32), -0.97342646]. 
=============================================
[2019-03-26 23:22:55,098] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[51.631702]
 [52.802658]
 [52.52211 ]
 [52.37008 ]
 [51.386105]], R is [[48.29879761]
 [47.81581116]
 [47.72428131]
 [47.64695358]
 [47.65630341]].
[2019-03-26 23:22:57,179] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.5869787e-20 1.0000000e+00 2.4109538e-18 6.4435653e-13 4.0587914e-25], sum to 1.0000
[2019-03-26 23:22:57,185] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0813
[2019-03-26 23:22:57,190] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 92.0, 1.0, 2.0, 0.7281494251620947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1017628.416584788, 1017628.416584788, 227038.7783839238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6146400.0000, 
sim time next is 6147000.0000, 
raw observation next is [26.6, 92.0, 1.0, 2.0, 0.7233181724426507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1010873.264611454, 1010873.264611454, 225959.1443214668], 
processed observation next is [1.0, 0.13043478260869565, 0.4597156398104266, 0.92, 1.0, 1.0, 0.6666484005333141, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.28079812905873724, 0.28079812905873724, 0.33725245421114447], 
reward next is 0.6627, 
noisyNet noise sample is [array([-0.2439391], dtype=float32), 0.7052865]. 
=============================================
[2019-03-26 23:22:57,218] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[63.021828]
 [62.34376 ]
 [61.71685 ]
 [60.78032 ]
 [59.930065]], R is [[63.68902969]
 [63.71327591]
 [63.7206192 ]
 [63.73046112]
 [63.7312851 ]].
[2019-03-26 23:22:57,271] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142000, global step 2273166: loss 0.1502
[2019-03-26 23:22:57,275] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142000, global step 2273167: learning rate 0.0000
[2019-03-26 23:22:58,358] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4315787e-14 1.7632091e-01 2.9694490e-11 8.2367909e-01 9.5905115e-18], sum to 1.0000
[2019-03-26 23:22:58,366] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0946
[2019-03-26 23:22:58,375] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2161894.730507915 W.
[2019-03-26 23:22:58,382] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.51666666666667, 52.83333333333334, 1.0, 2.0, 0.7730474719820348, 1.0, 1.0, 0.7730474719820348, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2161894.730507915, 2161894.730507915, 406959.9500476016], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5575800.0000, 
sim time next is 5576400.0000, 
raw observation next is [33.6, 52.0, 1.0, 2.0, 0.5015616342405657, 1.0, 2.0, 0.5015616342405657, 1.0, 1.0, 0.8639723240079695, 6.9112, 6.9112, 170.5573041426782, 2103934.468375012, 2103934.468375012, 414942.8002412812], 
processed observation next is [1.0, 0.5652173913043478, 0.7914691943127963, 0.52, 1.0, 1.0, 0.3994718484826092, 1.0, 1.0, 0.3994718484826092, 1.0, 0.5, 0.8341125902536214, 0.0, 0.0, 0.8375144448122397, 0.5844262412152811, 0.5844262412152811, 0.6193176123004197], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.3092637], dtype=float32), 0.3627508]. 
=============================================
[2019-03-26 23:22:58,832] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143000, global step 2273863: loss 0.2184
[2019-03-26 23:22:58,834] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143000, global step 2273863: learning rate 0.0000
[2019-03-26 23:23:00,453] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142500, global step 2274587: loss -69.8612
[2019-03-26 23:23:00,455] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142500, global step 2274588: learning rate 0.0000
[2019-03-26 23:23:01,380] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 23:23:01,383] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 23:23:01,384] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 23:23:01,385] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:23:01,387] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:23:01,386] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 23:23:01,389] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 23:23:01,388] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 23:23:01,390] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:23:01,391] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:23:01,391] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:23:01,418] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run92
[2019-03-26 23:23:01,445] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run92
[2019-03-26 23:23:01,446] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run92
[2019-03-26 23:23:01,473] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run92
[2019-03-26 23:23:01,497] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run92
[2019-03-26 23:23:36,153] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09294999], dtype=float32), 0.0736703]
[2019-03-26 23:23:36,154] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.58333333333334, 81.83333333333334, 1.0, 2.0, 0.5696185654754428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 795989.8942661026, 795989.8942661026, 195216.3794261136]
[2019-03-26 23:23:36,156] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 23:23:36,158] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.0603094e-23 1.0000000e+00 3.7631222e-22 7.5154611e-18 1.4240667e-28], sampled 0.6644894959834292
[2019-03-26 23:23:36,616] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09294999], dtype=float32), 0.0736703]
[2019-03-26 23:23:36,617] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.432578095, 82.63045571500001, 1.0, 2.0, 0.5631488146800748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 786945.6596165206, 786945.6596165199, 194083.3490388197]
[2019-03-26 23:23:36,618] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:23:36,621] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.9609618e-24 1.0000000e+00 8.3877927e-23 2.7015221e-17 1.8637979e-29], sampled 0.8800797840323026
[2019-03-26 23:23:56,069] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09294999], dtype=float32), 0.0736703]
[2019-03-26 23:23:56,071] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.0, 63.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.129436704174134, 6.9112, 168.9117126963059, 2444934.964271044, 2290111.475274994, 475930.6638319917]
[2019-03-26 23:23:56,073] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:23:56,075] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.4195118e-13 9.5241463e-01 8.0167151e-11 4.7585364e-02 3.2525147e-16], sampled 0.6893164279708085
[2019-03-26 23:23:56,077] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2444934.964271044 W.
[2019-03-26 23:24:46,977] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09294999], dtype=float32), 0.0736703]
[2019-03-26 23:24:46,977] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.375079195, 72.65525178499999, 1.0, 2.0, 0.3714033428217304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 568237.5945044268, 568237.5945044268, 172096.1903265459]
[2019-03-26 23:24:46,977] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:24:46,978] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.3660952e-23 1.0000000e+00 2.8835143e-22 2.8528536e-17 1.6456064e-28], sampled 0.9582292944860742
[2019-03-26 23:24:51,398] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09294999], dtype=float32), 0.0736703]
[2019-03-26 23:24:51,399] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.86666666666667, 72.5, 1.0, 2.0, 0.5548503936092994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 775345.1914697418, 775345.1914697423, 192635.4384005584]
[2019-03-26 23:24:51,400] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 23:24:51,402] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.0989088e-24 1.0000000e+00 5.6595305e-23 1.3137220e-17 1.5512258e-29], sampled 0.7734774728125969
[2019-03-26 23:24:55,743] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.2545 2779491169.1806 933.0000
[2019-03-26 23:24:55,918] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7899.2474 3162573518.2904 1718.0000
[2019-03-26 23:24:55,979] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8502.3524 2841752148.4150 1120.0000
[2019-03-26 23:24:56,120] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.9959 2927290556.9280 1332.0000
[2019-03-26 23:24:56,176] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8009.1919 3005874739.3923 1729.0000
[2019-03-26 23:24:57,194] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2275000, evaluation results [2275000.0, 7899.247433022717, 3162573518.2903585, 1718.0, 8253.995884367927, 2927290556.927973, 1332.0, 8658.254538499907, 2779491169.1805525, 933.0, 8009.1918752586325, 3005874739.39233, 1729.0, 8502.35237418181, 2841752148.4149823, 1120.0]
[2019-03-26 23:24:57,435] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142000, global step 2275109: loss 0.1382
[2019-03-26 23:24:57,437] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142000, global step 2275110: learning rate 0.0000
[2019-03-26 23:24:57,677] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143000, global step 2275218: loss 0.2229
[2019-03-26 23:24:57,681] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143000, global step 2275218: learning rate 0.0000
[2019-03-26 23:24:59,882] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0454483e-21 1.0000000e+00 5.1342103e-21 4.9762436e-15 1.9120498e-27], sum to 1.0000
[2019-03-26 23:24:59,892] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1069
[2019-03-26 23:24:59,897] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.35, 87.0, 1.0, 2.0, 0.6820130727227623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 953121.4209567029, 953121.4209567023, 217011.0333146342], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6071400.0000, 
sim time next is 6072000.0000, 
raw observation next is [27.5, 86.33333333333334, 1.0, 2.0, 0.7476511577549068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1044896.55704804, 1044896.557048039, 231467.3212886032], 
processed observation next is [1.0, 0.2608695652173913, 0.5023696682464456, 0.8633333333333334, 1.0, 1.0, 0.6959652503071165, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2902490436244555, 0.2902490436244553, 0.3454736138635869], 
reward next is 0.6545, 
noisyNet noise sample is [array([1.6478342], dtype=float32), -0.72212315]. 
=============================================
[2019-03-26 23:24:59,919] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[67.98904]
 [68.07369]
 [68.20721]
 [68.35769]
 [68.45615]], R is [[67.77786255]
 [67.77618408]
 [67.77513885]
 [67.76726532]
 [67.7652359 ]].
[2019-03-26 23:25:00,855] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142500, global step 2276637: loss 18.1945
[2019-03-26 23:25:00,857] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142500, global step 2276637: learning rate 0.0000
[2019-03-26 23:25:01,560] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142000, global step 2276951: loss 0.1224
[2019-03-26 23:25:01,564] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142000, global step 2276953: learning rate 0.0000
[2019-03-26 23:25:01,927] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142000, global step 2277114: loss 0.1293
[2019-03-26 23:25:01,930] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142000, global step 2277114: learning rate 0.0000
[2019-03-26 23:25:02,044] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142000, global step 2277166: loss 0.1312
[2019-03-26 23:25:02,046] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142000, global step 2277166: learning rate 0.0000
[2019-03-26 23:25:02,192] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142000, global step 2277235: loss 0.1313
[2019-03-26 23:25:02,196] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142000, global step 2277235: learning rate 0.0000
[2019-03-26 23:25:02,207] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142000, global step 2277242: loss 0.1308
[2019-03-26 23:25:02,208] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142000, global step 2277242: learning rate 0.0000
[2019-03-26 23:25:02,353] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142000, global step 2277306: loss 0.1297
[2019-03-26 23:25:02,354] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142000, global step 2277306: learning rate 0.0000
[2019-03-26 23:25:02,373] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142000, global step 2277314: loss 0.1287
[2019-03-26 23:25:02,375] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142000, global step 2277315: learning rate 0.0000
[2019-03-26 23:25:02,623] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3552137e-22 1.0000000e+00 8.6608900e-22 3.0079571e-15 4.9422531e-28], sum to 1.0000
[2019-03-26 23:25:02,635] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5791
[2019-03-26 23:25:02,641] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.4, 87.0, 1.0, 2.0, 0.5402887407433934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 754989.5782987179, 754989.5782987179, 190149.2567552365], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6039000.0000, 
sim time next is 6039600.0000, 
raw observation next is [27.33333333333334, 87.33333333333334, 1.0, 2.0, 0.5401113560650096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 754741.616140158, 754741.6161401586, 190119.3144044394], 
processed observation next is [1.0, 0.9130434782608695, 0.4944707740916275, 0.8733333333333334, 1.0, 1.0, 0.44591729646386696, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20965044892782167, 0.20965044892782184, 0.28376017075289467], 
reward next is 0.7162, 
noisyNet noise sample is [array([1.0539724], dtype=float32), -1.4794737]. 
=============================================
[2019-03-26 23:25:02,706] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142000, global step 2277461: loss 0.1287
[2019-03-26 23:25:02,710] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142000, global step 2277462: learning rate 0.0000
[2019-03-26 23:25:02,841] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143000, global step 2277520: loss 0.2408
[2019-03-26 23:25:02,843] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143000, global step 2277521: learning rate 0.0000
[2019-03-26 23:25:03,562] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.57880612e-15 4.63579923e-01 1.06511145e-11 5.36420107e-01
 8.77118912e-18], sum to 1.0000
[2019-03-26 23:25:03,569] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9131
[2019-03-26 23:25:03,576] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.33333333333334, 78.66666666666667, 1.0, 2.0, 0.8046480198375884, 1.0, 2.0, 0.8046480198375884, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2250355.594621844, 2250355.594621844, 422148.6734642821], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5935200.0000, 
sim time next is 5935800.0000, 
raw observation next is [30.36666666666666, 78.83333333333334, 1.0, 2.0, 0.8022917379592786, 1.0, 2.0, 0.8022917379592786, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2243759.875940918, 2243759.875940918, 420997.2099477171], 
processed observation next is [1.0, 0.6956521739130435, 0.6382306477093204, 0.7883333333333334, 1.0, 1.0, 0.7617972746497332, 1.0, 1.0, 0.7617972746497332, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6232666322058106, 0.6232666322058106, 0.6283540446980852], 
reward next is 0.3716, 
noisyNet noise sample is [array([-0.20444663], dtype=float32), 0.63356274]. 
=============================================
[2019-03-26 23:25:08,258] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142500, global step 2279933: loss -106.0530
[2019-03-26 23:25:08,259] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142500, global step 2279933: learning rate 0.0000
[2019-03-26 23:25:08,297] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7062708e-21 1.0000000e+00 3.5737185e-20 1.9569565e-15 1.6981821e-26], sum to 1.0000
[2019-03-26 23:25:08,307] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9005
[2019-03-26 23:25:08,313] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.38333333333333, 91.00000000000001, 1.0, 2.0, 1.002744314557542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1401643.011032975, 1401643.011032975, 299762.3359514407], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6487800.0000, 
sim time next is 6488400.0000, 
raw observation next is [26.36666666666667, 91.0, 1.0, 2.0, 0.8897702990469574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1243634.649434489, 1243634.64943449, 267138.3405819759], 
processed observation next is [1.0, 0.08695652173913043, 0.4486571879936811, 0.91, 1.0, 1.0, 0.8671931313818764, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.34545406928735806, 0.3454540692873583, 0.39871394116712816], 
reward next is 0.6013, 
noisyNet noise sample is [array([-0.59956247], dtype=float32), 0.30597508]. 
=============================================
[2019-03-26 23:25:09,875] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.9902339e-15 3.0430406e-01 2.3521898e-11 6.9569588e-01 5.6245697e-18], sum to 1.0000
[2019-03-26 23:25:09,885] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4012
[2019-03-26 23:25:09,892] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.65, 62.66666666666666, 1.0, 2.0, 0.8011668598829849, 1.0, 2.0, 0.8011668598829849, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2240611.122608191, 2240611.122608192, 420443.7796108596], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5836200.0000, 
sim time next is 5836800.0000, 
raw observation next is [32.7, 62.33333333333334, 1.0, 2.0, 0.9909175737276076, 1.0, 2.0, 0.9909175737276076, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2771872.660232319, 2771872.660232318, 523519.745421416], 
processed observation next is [1.0, 0.5652173913043478, 0.7488151658767774, 0.6233333333333334, 1.0, 1.0, 0.9890573177441055, 1.0, 1.0, 0.9890573177441055, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7699646278423108, 0.7699646278423106, 0.7813727543603224], 
reward next is 0.2186, 
noisyNet noise sample is [array([0.78272426], dtype=float32), 0.6445949]. 
=============================================
[2019-03-26 23:25:10,951] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142500, global step 2281126: loss -172.7327
[2019-03-26 23:25:10,955] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142500, global step 2281127: learning rate 0.0000
[2019-03-26 23:25:12,443] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5584742e-21 1.0000000e+00 7.5288545e-20 8.3742709e-15 1.6109990e-26], sum to 1.0000
[2019-03-26 23:25:12,452] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2076
[2019-03-26 23:25:12,460] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.91666666666666, 94.83333333333333, 1.0, 2.0, 0.817234511469615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104292, 1142196.62750742, 1142196.62750742, 248184.5119213736], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5885400.0000, 
sim time next is 5886000.0000, 
raw observation next is [25.9, 95.0, 1.0, 2.0, 0.7774507243969447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1086564.913465274, 1086564.913465275, 238450.4391852209], 
processed observation next is [1.0, 0.13043478260869565, 0.42654028436018954, 0.95, 1.0, 1.0, 0.7318683426469214, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3018235870736872, 0.3018235870736875, 0.3558961778883894], 
reward next is 0.6441, 
noisyNet noise sample is [array([1.8154997], dtype=float32), -1.1659143]. 
=============================================
[2019-03-26 23:25:12,469] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[67.43001 ]
 [67.37293 ]
 [67.445015]
 [67.49605 ]
 [67.850235]], R is [[67.51570892]
 [67.47013092]
 [67.40934753]
 [67.31506348]
 [67.0032959 ]].
[2019-03-26 23:25:12,862] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143500, global step 2281976: loss 104.6624
[2019-03-26 23:25:12,865] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143500, global step 2281978: learning rate 0.0000
[2019-03-26 23:25:14,333] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143000, global step 2282632: loss 0.2281
[2019-03-26 23:25:14,335] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143000, global step 2282632: learning rate 0.0000
[2019-03-26 23:25:14,595] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0241742e-23 1.0000000e+00 1.1312970e-20 3.6216293e-12 6.2785057e-29], sum to 1.0000
[2019-03-26 23:25:14,605] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3233
[2019-03-26 23:25:14,611] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.2, 80.0, 1.0, 2.0, 0.5251802323519601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733869.9326706474, 733869.9326706467, 187635.8053387474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6116400.0000, 
sim time next is 6117000.0000, 
raw observation next is [28.03333333333333, 81.0, 1.0, 2.0, 0.525454711778383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 734253.6139373227, 734253.613937322, 187680.8262562323], 
processed observation next is [1.0, 0.8260869565217391, 0.5276461295418641, 0.81, 1.0, 1.0, 0.42825868888961804, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20395933720481188, 0.20395933720481169, 0.2801206362033318], 
reward next is 0.7199, 
noisyNet noise sample is [array([0.7948465], dtype=float32), -0.7093921]. 
=============================================
[2019-03-26 23:25:14,628] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[75.98919 ]
 [75.32333 ]
 [74.858604]
 [73.97208 ]
 [72.15921 ]], R is [[75.80338287]
 [75.76529694]
 [75.72753143]
 [75.69007111]
 [75.65310669]].
[2019-03-26 23:25:15,337] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142500, global step 2283079: loss -53.1386
[2019-03-26 23:25:15,338] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142500, global step 2283079: learning rate 0.0000
[2019-03-26 23:25:15,850] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143500, global step 2283307: loss 61.8269
[2019-03-26 23:25:15,855] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143500, global step 2283308: learning rate 0.0000
[2019-03-26 23:25:19,040] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143000, global step 2284708: loss 0.2291
[2019-03-26 23:25:19,044] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143000, global step 2284709: learning rate 0.0000
[2019-03-26 23:25:19,524] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142500, global step 2284925: loss 18.1250
[2019-03-26 23:25:19,527] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142500, global step 2284926: learning rate 0.0000
[2019-03-26 23:25:19,793] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142500, global step 2285047: loss -75.2750
[2019-03-26 23:25:19,799] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142500, global step 2285049: learning rate 0.0000
[2019-03-26 23:25:20,075] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142500, global step 2285173: loss -175.1856
[2019-03-26 23:25:20,076] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142500, global step 2285173: learning rate 0.0000
[2019-03-26 23:25:20,117] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142500, global step 2285190: loss -159.3569
[2019-03-26 23:25:20,120] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142500, global step 2285192: learning rate 0.0000
[2019-03-26 23:25:20,160] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142500, global step 2285211: loss -17.3827
[2019-03-26 23:25:20,163] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142500, global step 2285212: learning rate 0.0000
[2019-03-26 23:25:20,320] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142500, global step 2285288: loss -5.0974
[2019-03-26 23:25:20,322] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142500, global step 2285288: learning rate 0.0000
[2019-03-26 23:25:20,345] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142500, global step 2285299: loss -136.6604
[2019-03-26 23:25:20,348] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142500, global step 2285299: learning rate 0.0000
[2019-03-26 23:25:20,655] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142500, global step 2285436: loss -19.6430
[2019-03-26 23:25:20,659] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142500, global step 2285436: learning rate 0.0000
[2019-03-26 23:25:20,851] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143500, global step 2285521: loss 15.8922
[2019-03-26 23:25:20,855] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143500, global step 2285522: learning rate 0.0000
[2019-03-26 23:25:22,936] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.8079443e-22 1.0000000e+00 5.5340039e-21 2.8556560e-14 1.2189532e-26], sum to 1.0000
[2019-03-26 23:25:22,946] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1621
[2019-03-26 23:25:22,951] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.36666666666667, 85.66666666666666, 1.0, 2.0, 0.5305047447765191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 741312.8309831853, 741312.8309831853, 188513.7156267586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6208800.0000, 
sim time next is 6209400.0000, 
raw observation next is [27.33333333333333, 85.83333333333334, 1.0, 2.0, 0.5306538950960878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 741521.3223099911, 741521.3223099911, 188538.4028576358], 
processed observation next is [1.0, 0.8695652173913043, 0.494470774091627, 0.8583333333333334, 1.0, 1.0, 0.4345227651760094, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20597814508610865, 0.20597814508610865, 0.28140060128005345], 
reward next is 0.7186, 
noisyNet noise sample is [array([0.1514061], dtype=float32), -1.4365066]. 
=============================================
[2019-03-26 23:25:22,959] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1571246e-22 1.0000000e+00 1.6934520e-20 1.7721426e-15 3.4733603e-27], sum to 1.0000
[2019-03-26 23:25:22,968] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5215
[2019-03-26 23:25:22,977] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 93.0, 1.0, 2.0, 0.6839299149466307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 955801.4363278971, 955801.4363278977, 217414.0147875368], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6063600.0000, 
sim time next is 6064200.0000, 
raw observation next is [26.1, 93.0, 1.0, 2.0, 0.7299022786947874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1020079.30127493, 1020079.30127493, 227431.2087076436], 
processed observation next is [1.0, 0.17391304347826086, 0.4360189573459717, 0.93, 1.0, 1.0, 0.6745810586684186, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.28335536146525836, 0.28335536146525836, 0.3394495652352889], 
reward next is 0.6606, 
noisyNet noise sample is [array([-0.20932238], dtype=float32), -0.14229494]. 
=============================================
[2019-03-26 23:25:26,105] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143000, global step 2287857: loss 0.2333
[2019-03-26 23:25:26,108] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143000, global step 2287857: learning rate 0.0000
[2019-03-26 23:25:26,957] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.10044515e-13 4.63918597e-01 8.40724539e-12 5.36081433e-01
 2.20768947e-17], sum to 1.0000
[2019-03-26 23:25:26,965] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0415
[2019-03-26 23:25:26,976] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2222914.548662787 W.
[2019-03-26 23:25:26,980] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 68.0, 1.0, 2.0, 0.7948447850914451, 1.0, 2.0, 0.7948447850914451, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2222914.548662787, 2222914.548662787, 417363.2142156731], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6447000.0000, 
sim time next is 6447600.0000, 
raw observation next is [30.0, 68.0, 1.0, 2.0, 0.8057599873109632, 1.0, 2.0, 0.8057599873109632, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2253468.232880837, 2253468.232880837, 422678.7936047356], 
processed observation next is [1.0, 0.6521739130434783, 0.6208530805687204, 0.68, 1.0, 1.0, 0.7659758883264617, 1.0, 1.0, 0.7659758883264617, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6259633980224547, 0.6259633980224547, 0.6308638710518442], 
reward next is 0.3691, 
noisyNet noise sample is [array([-0.23824102], dtype=float32), -0.17278239]. 
=============================================
[2019-03-26 23:25:28,929] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143000, global step 2289115: loss 0.2480
[2019-03-26 23:25:28,930] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143000, global step 2289115: learning rate 0.0000
[2019-03-26 23:25:29,092] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9899675e-17 1.0000000e+00 1.7925123e-15 4.6104029e-10 1.6719413e-21], sum to 1.0000
[2019-03-26 23:25:29,098] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2576
[2019-03-26 23:25:29,103] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2129937.661096368 W.
[2019-03-26 23:25:29,114] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.13333333333333, 85.0, 1.0, 2.0, 0.7616316549085643, 1.0, 2.0, 0.7616316549085643, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2129937.661096368, 2129937.661096369, 401625.6697651451], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6165600.0000, 
sim time next is 6166200.0000, 
raw observation next is [28.21666666666667, 84.5, 1.0, 2.0, 0.7323074517542776, 1.0, 2.0, 0.7323074517542776, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2047852.803981987, 2047852.803981987, 388263.5741339164], 
processed observation next is [1.0, 0.34782608695652173, 0.5363349131121644, 0.845, 1.0, 1.0, 0.6774788575352741, 1.0, 1.0, 0.6774788575352741, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5688480011061076, 0.5688480011061076, 0.5794978718416662], 
reward next is 0.4205, 
noisyNet noise sample is [array([-0.8057531], dtype=float32), 1.6349802]. 
=============================================
[2019-03-26 23:25:30,338] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.8825238e-14 1.5860269e-02 1.9394956e-11 9.8413968e-01 8.5031156e-18], sum to 1.0000
[2019-03-26 23:25:30,347] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9701
[2019-03-26 23:25:30,350] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 71.66666666666667, 1.0, 2.0, 0.8251849485772433, 1.0, 2.0, 0.8251849485772433, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2307844.165386606, 2307844.165386606, 432315.9869074691], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6189600.0000, 
sim time next is 6190200.0000, 
raw observation next is [29.9, 72.0, 1.0, 2.0, 0.8301687723786543, 1.0, 2.0, 0.8301687723786543, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2321795.671976353, 2321795.671976353, 434822.9233801428], 
processed observation next is [1.0, 0.6521739130434783, 0.6161137440758293, 0.72, 1.0, 1.0, 0.7953840631068124, 1.0, 1.0, 0.7953840631068124, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6449432422156536, 0.6449432422156536, 0.6489894378808101], 
reward next is 0.3510, 
noisyNet noise sample is [array([-0.03203228], dtype=float32), 0.3905455]. 
=============================================
[2019-03-26 23:25:30,423] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144000, global step 2289780: loss 0.6569
[2019-03-26 23:25:30,426] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144000, global step 2289781: learning rate 0.0000
[2019-03-26 23:25:32,201] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143500, global step 2290563: loss 39.3387
[2019-03-26 23:25:32,203] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143500, global step 2290564: learning rate 0.0000
[2019-03-26 23:25:33,388] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143000, global step 2291095: loss 0.2613
[2019-03-26 23:25:33,392] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143000, global step 2291096: learning rate 0.0000
[2019-03-26 23:25:33,679] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144000, global step 2291227: loss 0.6852
[2019-03-26 23:25:33,680] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144000, global step 2291227: learning rate 0.0000
[2019-03-26 23:25:36,988] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143500, global step 2292703: loss 61.0856
[2019-03-26 23:25:36,989] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143500, global step 2292703: learning rate 0.0000
[2019-03-26 23:25:37,485] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143000, global step 2292927: loss 0.2699
[2019-03-26 23:25:37,488] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143000, global step 2292927: learning rate 0.0000
[2019-03-26 23:25:37,866] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143000, global step 2293092: loss 0.2694
[2019-03-26 23:25:37,871] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143000, global step 2293092: learning rate 0.0000
[2019-03-26 23:25:38,018] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143000, global step 2293161: loss 0.2736
[2019-03-26 23:25:38,021] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143000, global step 2293161: learning rate 0.0000
[2019-03-26 23:25:38,078] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143000, global step 2293187: loss 0.2688
[2019-03-26 23:25:38,084] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143000, global step 2293188: learning rate 0.0000
[2019-03-26 23:25:38,098] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143000, global step 2293196: loss 0.2700
[2019-03-26 23:25:38,101] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143000, global step 2293197: learning rate 0.0000
[2019-03-26 23:25:38,359] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143000, global step 2293313: loss 0.2592
[2019-03-26 23:25:38,362] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143000, global step 2293313: learning rate 0.0000
[2019-03-26 23:25:38,613] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143000, global step 2293426: loss 0.2659
[2019-03-26 23:25:38,615] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143000, global step 2293427: learning rate 0.0000
[2019-03-26 23:25:38,655] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143000, global step 2293441: loss 0.2606
[2019-03-26 23:25:38,657] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143000, global step 2293441: learning rate 0.0000
[2019-03-26 23:25:38,949] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144000, global step 2293573: loss 0.6793
[2019-03-26 23:25:38,953] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144000, global step 2293576: learning rate 0.0000
[2019-03-26 23:25:39,930] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3462115e-23 1.0000000e+00 1.1823045e-22 1.6530460e-17 6.1365280e-29], sum to 1.0000
[2019-03-26 23:25:39,943] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1326
[2019-03-26 23:25:39,947] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.7, 67.33333333333334, 1.0, 2.0, 0.5388889283201594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 753032.8127313006, 753032.8127312999, 189913.72367448], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6345600.0000, 
sim time next is 6346200.0000, 
raw observation next is [30.85, 66.66666666666666, 1.0, 2.0, 0.539469530378493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 753844.4225476262, 753844.4225476262, 190011.4529554805], 
processed observation next is [0.0, 0.43478260869565216, 0.661137440758294, 0.6666666666666665, 1.0, 1.0, 0.4451440125042084, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20940122848545173, 0.20940122848545173, 0.2835991835156425], 
reward next is 0.7164, 
noisyNet noise sample is [array([0.755297], dtype=float32), 0.23073095]. 
=============================================
[2019-03-26 23:25:44,325] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143500, global step 2295968: loss 213.2871
[2019-03-26 23:25:44,329] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143500, global step 2295970: learning rate 0.0000
[2019-03-26 23:25:47,022] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143500, global step 2297168: loss 90.2734
[2019-03-26 23:25:47,024] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143500, global step 2297168: learning rate 0.0000
[2019-03-26 23:25:48,633] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144500, global step 2297872: loss 189.5325
[2019-03-26 23:25:48,637] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144500, global step 2297873: learning rate 0.0000
[2019-03-26 23:25:50,230] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144000, global step 2298585: loss 0.6721
[2019-03-26 23:25:50,232] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144000, global step 2298585: learning rate 0.0000
[2019-03-26 23:25:51,511] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143500, global step 2299163: loss 68.7324
[2019-03-26 23:25:51,515] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143500, global step 2299164: learning rate 0.0000
[2019-03-26 23:25:51,895] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144500, global step 2299334: loss 109.8535
[2019-03-26 23:25:51,898] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144500, global step 2299334: learning rate 0.0000
[2019-03-26 23:25:53,386] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 23:25:53,388] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 23:25:53,389] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 23:25:53,391] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:25:53,391] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 23:25:53,392] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 23:25:53,394] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:25:53,395] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:25:53,391] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:25:53,395] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 23:25:53,398] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:25:53,418] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run93
[2019-03-26 23:25:53,446] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run93
[2019-03-26 23:25:53,481] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run93
[2019-03-26 23:25:53,482] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run93
[2019-03-26 23:25:53,502] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run93
[2019-03-26 23:25:58,524] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09220988], dtype=float32), 0.074652955]
[2019-03-26 23:25:58,526] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.73333333333333, 54.5, 1.0, 2.0, 0.2611161273820422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 427977.7193577571, 427977.7193577571, 162023.6650950422]
[2019-03-26 23:25:58,527] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 23:25:58,530] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.6805418e-23 1.0000000e+00 1.3116855e-22 1.7112468e-18 6.4593494e-29], sampled 0.3807601240703834
[2019-03-26 23:26:20,831] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09220988], dtype=float32), 0.074652955]
[2019-03-26 23:26:20,832] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [18.95572465, 86.89906184166668, 1.0, 2.0, 0.3423716716561459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 568432.2636729954, 568432.263672996, 171268.7106342899]
[2019-03-26 23:26:20,833] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:26:20,835] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.83865601e-23 1.00000000e+00 3.32998863e-22 1.31545706e-17
 9.75912337e-29], sampled 0.3554860825599726
[2019-03-26 23:26:37,640] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09220988], dtype=float32), 0.074652955]
[2019-03-26 23:26:37,642] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.13333333333333, 81.33333333333334, 1.0, 2.0, 0.8160346154318081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1140518.708584022, 1140518.708584022, 247884.8193217326]
[2019-03-26 23:26:37,642] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:26:37,644] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.4437626e-22 1.0000000e+00 1.1195163e-21 1.7363016e-16 3.1551904e-28], sampled 0.3801322235426543
[2019-03-26 23:26:39,575] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09220988], dtype=float32), 0.074652955]
[2019-03-26 23:26:39,577] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.16666666666667, 59.33333333333334, 1.0, 2.0, 0.5715445449522957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 798682.2864628147, 798682.2864628147, 195564.3081307177]
[2019-03-26 23:26:39,578] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:26:39,580] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.3376626e-23 1.0000000e+00 6.5612679e-22 6.9102532e-15 5.9331781e-29], sampled 0.7934562924667448
[2019-03-26 23:26:49,432] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09220988], dtype=float32), 0.074652955]
[2019-03-26 23:26:49,433] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.48565551666667, 70.57735472666667, 1.0, 2.0, 0.8648038884627004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1208719.158390329, 1208719.158390329, 260443.4790411713]
[2019-03-26 23:26:49,434] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:26:49,437] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.1296830e-22 1.0000000e+00 3.5312191e-21 3.7382118e-15 2.2426799e-28], sampled 0.3673548840867449
[2019-03-26 23:26:53,911] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09220988], dtype=float32), 0.074652955]
[2019-03-26 23:26:53,912] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.5, 61.0, 1.0, 2.0, 0.6519194525714807, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.00597228055087, 6.9112, 168.9123178068059, 1807849.225581518, 1740614.762180444, 374589.5166489935]
[2019-03-26 23:26:53,914] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 23:26:53,917] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.2737997e-20 1.0000000e+00 8.8483500e-19 5.7488378e-13 1.4674036e-24], sampled 0.8815798947656565
[2019-03-26 23:26:53,919] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1807849.225581518 W.
[2019-03-26 23:26:53,950] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09220988], dtype=float32), 0.074652955]
[2019-03-26 23:26:53,953] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.1648447, 95.098507485, 1.0, 2.0, 0.5577039626681581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779334.2175851611, 779334.2175851611, 193126.6761184985]
[2019-03-26 23:26:53,955] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:26:53,956] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.4993277e-23 1.0000000e+00 3.6561610e-22 5.0070096e-17 5.0151797e-29], sampled 0.1659341777287342
[2019-03-26 23:27:19,337] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09220988], dtype=float32), 0.074652955]
[2019-03-26 23:27:19,338] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.75, 91.0, 1.0, 2.0, 0.7339436682632908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1025730.097202064, 1025730.097202065, 228345.4535149916]
[2019-03-26 23:27:19,341] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 23:27:19,344] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.5116949e-23 1.0000000e+00 5.9118493e-22 7.1331106e-17 1.4733911e-28], sampled 0.9487977208251724
[2019-03-26 23:27:47,623] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8251.8288 2927587600.7104 1331.0000
[2019-03-26 23:27:48,104] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8508.8035 2841239926.4358 1104.0000
[2019-03-26 23:27:48,134] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.0630 2779644385.9013 933.0000
[2019-03-26 23:27:48,210] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8003.9904 3006874331.1739 1740.0000
[2019-03-26 23:27:48,239] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7905.4483 3162293046.0922 1712.0000
[2019-03-26 23:27:49,254] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2300000, evaluation results [2300000.0, 7905.448293469367, 3162293046.0921564, 1712.0, 8251.82883792347, 2927587600.7103915, 1331.0, 8658.063001974835, 2779644385.901259, 933.0, 8003.990404116935, 3006874331.1739397, 1740.0, 8508.803528198468, 2841239926.4358373, 1104.0]
[2019-03-26 23:27:50,569] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144000, global step 2300587: loss 0.6949
[2019-03-26 23:27:50,573] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144000, global step 2300588: learning rate 0.0000
[2019-03-26 23:27:50,786] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4062954e-20 1.0000000e+00 1.3331673e-19 7.6288541e-13 1.0422799e-26], sum to 1.0000
[2019-03-26 23:27:50,797] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2645
[2019-03-26 23:27:50,807] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.43333333333333, 63.66666666666666, 1.0, 2.0, 0.9300627192083291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1393479.296318984, 1393479.296318984, 291926.1386995112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7318200.0000, 
sim time next is 7318800.0000, 
raw observation next is [27.4, 64.0, 1.0, 2.0, 0.935395200527112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1400284.95157299, 1400284.951572989, 293400.163965357], 
processed observation next is [1.0, 0.7391304347826086, 0.4976303317535545, 0.64, 1.0, 1.0, 0.9221628922013397, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.38896804210360836, 0.3889680421036081, 0.4379106924856075], 
reward next is 0.5621, 
noisyNet noise sample is [array([0.5821144], dtype=float32), 0.10037514]. 
=============================================
[2019-03-26 23:27:51,158] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143500, global step 2300850: loss 80.0437
[2019-03-26 23:27:51,160] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143500, global step 2300850: learning rate 0.0000
[2019-03-26 23:27:51,852] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143500, global step 2301157: loss 59.6155
[2019-03-26 23:27:51,855] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143500, global step 2301157: loss 148.2660
[2019-03-26 23:27:51,856] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143500, global step 2301157: learning rate 0.0000
[2019-03-26 23:27:51,856] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143500, global step 2301157: learning rate 0.0000
[2019-03-26 23:27:51,992] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143500, global step 2301220: loss 132.5612
[2019-03-26 23:27:51,993] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143500, global step 2301220: learning rate 0.0000
[2019-03-26 23:27:52,066] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143500, global step 2301251: loss 20.0900
[2019-03-26 23:27:52,068] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143500, global step 2301252: learning rate 0.0000
[2019-03-26 23:27:52,136] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143500, global step 2301280: loss 64.8490
[2019-03-26 23:27:52,137] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143500, global step 2301280: learning rate 0.0000
[2019-03-26 23:27:52,376] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143500, global step 2301386: loss 170.5186
[2019-03-26 23:27:52,379] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143500, global step 2301388: learning rate 0.0000
[2019-03-26 23:27:52,558] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.15787346e-14 8.82719994e-01 5.39064149e-12 1.17279969e-01
 4.87180760e-18], sum to 1.0000
[2019-03-26 23:27:52,563] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2448
[2019-03-26 23:27:52,568] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1986123.415999768 W.
[2019-03-26 23:27:52,578] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.5, 73.5, 1.0, 2.0, 0.7102536078836439, 1.0, 2.0, 0.7102536078836439, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1986123.415999768, 1986123.415999768, 378543.6084552158], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6622200.0000, 
sim time next is 6622800.0000, 
raw observation next is [29.0, 77.0, 1.0, 2.0, 0.7372945963186348, 1.0, 2.0, 0.7372945963186348, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2061812.468297871, 2061812.46829787, 390497.5288169356], 
processed observation next is [1.0, 0.6521739130434783, 0.5734597156398105, 0.77, 1.0, 1.0, 0.6834874654441383, 1.0, 1.0, 0.6834874654441383, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5727256856382975, 0.5727256856382972, 0.5828321325625905], 
reward next is 0.4172, 
noisyNet noise sample is [array([2.102045], dtype=float32), 1.3819237]. 
=============================================
[2019-03-26 23:27:52,635] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143500, global step 2301500: loss 49.3788
[2019-03-26 23:27:52,637] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143500, global step 2301500: learning rate 0.0000
[2019-03-26 23:27:52,843] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144500, global step 2301589: loss 160.0505
[2019-03-26 23:27:52,846] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144500, global step 2301589: learning rate 0.0000
[2019-03-26 23:27:53,558] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.9628080e-18 9.9993563e-01 9.8439975e-15 6.4368258e-05 1.6471634e-22], sum to 1.0000
[2019-03-26 23:27:53,566] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4498
[2019-03-26 23:27:53,577] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.4, 85.0, 1.0, 2.0, 0.4902158884792679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 684996.1322331115, 684996.1322331122, 182079.864823917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6629400.0000, 
sim time next is 6630000.0000, 
raw observation next is [27.36666666666667, 85.0, 1.0, 2.0, 0.4994401385573466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 697889.7396247077, 697889.7396247084, 183510.3536257456], 
processed observation next is [1.0, 0.7391304347826086, 0.49605055292259104, 0.85, 1.0, 1.0, 0.39691582958716454, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19385826100686326, 0.19385826100686346, 0.27389605018768], 
reward next is 0.7261, 
noisyNet noise sample is [array([0.28402692], dtype=float32), 0.13348636]. 
=============================================
[2019-03-26 23:27:53,593] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[62.813137]
 [58.77025 ]
 [54.35991 ]
 [51.64947 ]
 [51.149235]], R is [[66.07687378]
 [66.14434814]
 [66.20981598]
 [66.15651703]
 [65.49494934]].
[2019-03-26 23:27:57,086] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.0365075e-18 1.0000000e+00 5.2606890e-17 1.0199782e-11 6.2428918e-23], sum to 1.0000
[2019-03-26 23:27:57,095] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5392
[2019-03-26 23:27:57,102] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1875691.351636603 W.
[2019-03-26 23:27:57,107] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.53333333333333, 82.0, 1.0, 2.0, 0.4471978386266375, 1.0, 1.0, 0.4471978386266375, 1.0, 1.0, 0.7647242655402325, 6.9112, 6.9112, 170.5573041426782, 1875691.351636603, 1875691.351636603, 378642.4849703318], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6686400.0000, 
sim time next is 6687000.0000, 
raw observation next is [27.7, 81.0, 1.0, 2.0, 0.6714400865071644, 1.0, 2.0, 0.6714400865071644, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1877491.812147554, 1877491.812147554, 362133.0705560027], 
processed observation next is [1.0, 0.391304347826087, 0.5118483412322274, 0.81, 1.0, 1.0, 0.6041446825387522, 1.0, 1.0, 0.6041446825387522, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5215255033743206, 0.5215255033743206, 0.5404971202328399], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.56238776], dtype=float32), -1.2671942]. 
=============================================
[2019-03-26 23:27:57,128] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[57.792427]
 [63.887856]
 [63.80842 ]
 [63.792145]
 [68.084114]], R is [[54.57461929]
 [54.46373367]
 [53.9190979 ]
 [53.3799057 ]
 [53.32625961]].
[2019-03-26 23:27:57,846] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144000, global step 2303808: loss 0.7205
[2019-03-26 23:27:57,849] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144000, global step 2303808: learning rate 0.0000
[2019-03-26 23:28:00,587] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144000, global step 2305012: loss 0.7425
[2019-03-26 23:28:00,592] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144000, global step 2305012: learning rate 0.0000
[2019-03-26 23:28:02,268] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145000, global step 2305764: loss 0.0002
[2019-03-26 23:28:02,270] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145000, global step 2305764: learning rate 0.0000
[2019-03-26 23:28:04,214] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.8925764e-22 1.0000000e+00 5.1123995e-21 2.5506591e-15 8.9730222e-28], sum to 1.0000
[2019-03-26 23:28:04,231] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1037
[2019-03-26 23:28:04,235] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.91666666666666, 61.16666666666667, 1.0, 2.0, 0.3242004567002977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 511178.0306159031, 511178.0306159037, 167842.3541795695], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6814200.0000, 
sim time next is 6814800.0000, 
raw observation next is [25.8, 62.0, 1.0, 2.0, 0.3237298596240198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 510070.4290974017, 510070.4290974011, 167750.061073115], 
processed observation next is [1.0, 0.9130434782608695, 0.42180094786729866, 0.62, 1.0, 1.0, 0.1852166983421925, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1416862303048338, 0.14168623030483363, 0.2503732254822612], 
reward next is 0.7496, 
noisyNet noise sample is [array([0.11509958], dtype=float32), 0.06041783]. 
=============================================
[2019-03-26 23:28:04,363] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144500, global step 2306695: loss 29.5386
[2019-03-26 23:28:04,364] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144500, global step 2306695: learning rate 0.0000
[2019-03-26 23:28:05,317] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144000, global step 2307120: loss 0.7739
[2019-03-26 23:28:05,323] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144000, global step 2307120: learning rate 0.0000
[2019-03-26 23:28:05,454] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145000, global step 2307182: loss 0.0001
[2019-03-26 23:28:05,456] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145000, global step 2307182: learning rate 0.0000
[2019-03-26 23:28:08,117] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.80934163e-23 1.00000000e+00 3.56527075e-23 1.60656309e-17
 1.11009225e-29], sum to 1.0000
[2019-03-26 23:28:08,131] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0374
[2019-03-26 23:28:08,138] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.7, 37.0, 1.0, 2.0, 0.2719459181547744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 440749.8059422675, 440749.8059422681, 162980.1806510437], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6879600.0000, 
sim time next is 6880200.0000, 
raw observation next is [29.65, 38.0, 1.0, 2.0, 0.2775613735108938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 448367.320643843, 448367.320643843, 163490.4800756555], 
processed observation next is [0.0, 0.6521739130434783, 0.6042654028436019, 0.38, 1.0, 1.0, 0.1295920162781853, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12454647795662305, 0.12454647795662305, 0.24401564190396344], 
reward next is 0.7560, 
noisyNet noise sample is [array([-0.9639578], dtype=float32), -0.7647137]. 
=============================================
[2019-03-26 23:28:08,268] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.4016582e-23 1.0000000e+00 8.1618888e-23 3.5405452e-18 4.6616262e-29], sum to 1.0000
[2019-03-26 23:28:08,276] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8270
[2019-03-26 23:28:08,283] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.23333333333333, 39.33333333333333, 1.0, 2.0, 0.2861820342438035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 461700.470572328, 461700.4705723287, 164388.0575221332], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6871200.0000, 
sim time next is 6871800.0000, 
raw observation next is [29.31666666666667, 38.16666666666667, 1.0, 2.0, 0.2806612041765062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 454205.2490424214, 454205.2490424214, 163873.6512266393], 
processed observation next is [0.0, 0.5217391304347826, 0.5884676145339655, 0.3816666666666667, 1.0, 1.0, 0.13332675201988697, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12616812473400593, 0.12616812473400593, 0.24458753914423778], 
reward next is 0.7554, 
noisyNet noise sample is [array([1.0140234], dtype=float32), -0.7576681]. 
=============================================
[2019-03-26 23:28:09,029] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144500, global step 2308767: loss 148.7096
[2019-03-26 23:28:09,032] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144500, global step 2308767: learning rate 0.0000
[2019-03-26 23:28:09,117] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144000, global step 2308802: loss 0.8472
[2019-03-26 23:28:09,121] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144000, global step 2308803: learning rate 0.0000
[2019-03-26 23:28:09,797] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144000, global step 2309107: loss 0.8573
[2019-03-26 23:28:09,799] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144000, global step 2309107: learning rate 0.0000
[2019-03-26 23:28:10,002] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144000, global step 2309196: loss 0.8520
[2019-03-26 23:28:10,003] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144000, global step 2309196: learning rate 0.0000
[2019-03-26 23:28:10,056] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144000, global step 2309221: loss 0.8596
[2019-03-26 23:28:10,059] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144000, global step 2309221: learning rate 0.0000
[2019-03-26 23:28:10,075] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144000, global step 2309230: loss 0.8497
[2019-03-26 23:28:10,078] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144000, global step 2309230: learning rate 0.0000
[2019-03-26 23:28:10,123] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144000, global step 2309249: loss 0.8524
[2019-03-26 23:28:10,126] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144000, global step 2309251: learning rate 0.0000
[2019-03-26 23:28:10,671] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144000, global step 2309493: loss 0.8447
[2019-03-26 23:28:10,672] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144000, global step 2309493: learning rate 0.0000
[2019-03-26 23:28:10,679] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144000, global step 2309496: loss 0.8487
[2019-03-26 23:28:10,681] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144000, global step 2309496: learning rate 0.0000
[2019-03-26 23:28:10,790] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145000, global step 2309544: loss 0.0011
[2019-03-26 23:28:10,795] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145000, global step 2309547: learning rate 0.0000
[2019-03-26 23:28:12,897] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9684915e-24 1.0000000e+00 7.7762538e-23 1.0354718e-18 8.1655969e-30], sum to 1.0000
[2019-03-26 23:28:12,907] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9773
[2019-03-26 23:28:12,913] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.81666666666667, 52.0, 1.0, 2.0, 0.4724327452287946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 660139.3914418204, 660139.3914418198, 179389.367344515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6959400.0000, 
sim time next is 6960000.0000, 
raw observation next is [31.63333333333333, 52.0, 1.0, 2.0, 0.4622469387438832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 649180.906625034, 649180.906625034, 178316.582657033], 
processed observation next is [0.0, 0.5652173913043478, 0.6982622432859398, 0.52, 1.0, 1.0, 0.35210474547455806, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18032802961806502, 0.18032802961806502, 0.26614415321945223], 
reward next is 0.7339, 
noisyNet noise sample is [array([-0.50472724], dtype=float32), -0.5855338]. 
=============================================
[2019-03-26 23:28:12,926] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[75.89614 ]
 [75.849236]
 [75.805984]
 [75.7895  ]
 [75.76064 ]], R is [[75.91923523]
 [75.89229584]
 [75.86508179]
 [75.8388443 ]
 [75.81343842]].
[2019-03-26 23:28:16,337] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144500, global step 2311996: loss 38.7698
[2019-03-26 23:28:16,339] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144500, global step 2311997: learning rate 0.0000
[2019-03-26 23:28:18,956] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144500, global step 2313159: loss 107.4379
[2019-03-26 23:28:18,958] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144500, global step 2313159: learning rate 0.0000
[2019-03-26 23:28:20,528] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145500, global step 2313859: loss -247.5522
[2019-03-26 23:28:20,531] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145500, global step 2313859: learning rate 0.0000
[2019-03-26 23:28:22,003] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145000, global step 2314514: loss 0.0008
[2019-03-26 23:28:22,009] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145000, global step 2314517: learning rate 0.0000
[2019-03-26 23:28:23,435] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145500, global step 2315154: loss -318.9338
[2019-03-26 23:28:23,438] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145500, global step 2315154: learning rate 0.0000
[2019-03-26 23:28:23,547] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144500, global step 2315202: loss 88.3511
[2019-03-26 23:28:23,548] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144500, global step 2315203: learning rate 0.0000
[2019-03-26 23:28:26,676] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145000, global step 2316600: loss 0.0007
[2019-03-26 23:28:26,679] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145000, global step 2316603: learning rate 0.0000
[2019-03-26 23:28:27,204] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144500, global step 2316835: loss -17.6599
[2019-03-26 23:28:27,208] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144500, global step 2316835: learning rate 0.0000
[2019-03-26 23:28:28,015] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144500, global step 2317192: loss 1.7576
[2019-03-26 23:28:28,018] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144500, global step 2317193: learning rate 0.0000
[2019-03-26 23:28:28,105] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144500, global step 2317230: loss 56.0930
[2019-03-26 23:28:28,109] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144500, global step 2317231: learning rate 0.0000
[2019-03-26 23:28:28,203] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144500, global step 2317276: loss 14.8211
[2019-03-26 23:28:28,205] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144500, global step 2317276: learning rate 0.0000
[2019-03-26 23:28:28,249] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144500, global step 2317295: loss -69.4643
[2019-03-26 23:28:28,251] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144500, global step 2317296: learning rate 0.0000
[2019-03-26 23:28:28,316] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144500, global step 2317326: loss -182.0630
[2019-03-26 23:28:28,320] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2874842e-18 9.9996793e-01 9.1388778e-16 3.2024844e-05 7.5054038e-23], sum to 1.0000
[2019-03-26 23:28:28,321] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144500, global step 2317327: learning rate 0.0000
[2019-03-26 23:28:28,328] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3592
[2019-03-26 23:28:28,332] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333333, 96.5, 1.0, 2.0, 0.95654268645536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1337021.38436136, 1337021.384361359, 285961.7353312891], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7217400.0000, 
sim time next is 7218000.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.8504309034423084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1188619.079260518, 1188619.079260517, 256662.4954904313], 
processed observation next is [1.0, 0.5652173913043478, 0.3364928909952607, 1.0, 1.0, 1.0, 0.8197962692076005, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.330171966461255, 0.3301719664612547, 0.38307835147825564], 
reward next is 0.6169, 
noisyNet noise sample is [array([0.18596622], dtype=float32), -0.5477579]. 
=============================================
[2019-03-26 23:28:28,356] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[66.77387 ]
 [63.364235]
 [59.955418]
 [55.494473]
 [53.283558]], R is [[69.41745758]
 [69.29647064]
 [69.16208649]
 [69.02710724]
 [68.86022186]].
[2019-03-26 23:28:28,742] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144500, global step 2317512: loss 152.0224
[2019-03-26 23:28:28,744] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144500, global step 2317512: learning rate 0.0000
[2019-03-26 23:28:28,770] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145500, global step 2317523: loss -332.3672
[2019-03-26 23:28:28,771] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145500, global step 2317523: learning rate 0.0000
[2019-03-26 23:28:28,904] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144500, global step 2317582: loss 98.8714
[2019-03-26 23:28:28,906] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144500, global step 2317583: learning rate 0.0000
[2019-03-26 23:28:29,475] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.7005521e-19 1.0000000e+00 1.3592400e-17 4.7587285e-11 8.2002083e-24], sum to 1.0000
[2019-03-26 23:28:29,484] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7636
[2019-03-26 23:28:29,493] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.73333333333333, 60.66666666666667, 1.0, 2.0, 0.9441248442790209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104187, 1425410.601498198, 1425410.601498198, 297737.2515036025], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7312800.0000, 
sim time next is 7313400.0000, 
raw observation next is [27.7, 61.0, 1.0, 2.0, 0.9084323506664213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1370361.680089252, 1370361.680089252, 286622.4847359256], 
processed observation next is [1.0, 0.6521739130434783, 0.5118483412322274, 0.61, 1.0, 1.0, 0.8896775309233991, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.38065602224701445, 0.38065602224701445, 0.4277947533372024], 
reward next is 0.5722, 
noisyNet noise sample is [array([-2.0788915], dtype=float32), 0.61051553]. 
=============================================
[2019-03-26 23:28:29,899] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:28:29,899] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:28:29,984] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run12
[2019-03-26 23:28:30,567] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.8234015e-23 1.0000000e+00 2.6741802e-22 4.6276210e-16 4.6368322e-29], sum to 1.0000
[2019-03-26 23:28:30,572] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7395
[2019-03-26 23:28:30,575] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.26666666666667, 90.66666666666667, 1.0, 2.0, 0.3510720950930421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 542896.435930813, 542896.4359308124, 170114.1408661366], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7255200.0000, 
sim time next is 7255800.0000, 
raw observation next is [22.25, 90.5, 1.0, 2.0, 0.3492429228341323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 540633.8206291805, 540633.8206291811, 169943.5434723931], 
processed observation next is [1.0, 1.0, 0.2535545023696683, 0.905, 1.0, 1.0, 0.21595532871582201, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15017606128588348, 0.15017606128588365, 0.25364707980954193], 
reward next is 0.7464, 
noisyNet noise sample is [array([0.17306846], dtype=float32), -1.0597669]. 
=============================================
[2019-03-26 23:28:31,475] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.5029473e-23 1.0000000e+00 3.9844276e-21 4.3132713e-15 2.7321006e-28], sum to 1.0000
[2019-03-26 23:28:31,484] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9497
[2019-03-26 23:28:31,494] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.9, 88.0, 1.0, 2.0, 0.494073798632051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 690388.6793581739, 690388.6793581746, 182672.5519115474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7678800.0000, 
sim time next is 7679400.0000, 
raw observation next is [25.86666666666667, 88.00000000000001, 1.0, 2.0, 0.4925865389700069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 688309.7998596545, 688309.7998596552, 182442.4780367959], 
processed observation next is [1.0, 0.9130434782608695, 0.42496050552922615, 0.8800000000000001, 1.0, 1.0, 0.3886584806867553, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1911971666276818, 0.191197166627682, 0.2723022060250685], 
reward next is 0.7277, 
noisyNet noise sample is [array([1.3791698], dtype=float32), -2.0222454]. 
=============================================
[2019-03-26 23:28:32,319] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:28:32,320] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:28:32,399] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run12
[2019-03-26 23:28:33,147] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145000, global step 2319654: loss 0.0015
[2019-03-26 23:28:33,151] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145000, global step 2319655: learning rate 0.0000
[2019-03-26 23:28:33,512] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.9615811e-22 1.0000000e+00 1.4218842e-21 1.3121807e-15 8.2207376e-28], sum to 1.0000
[2019-03-26 23:28:33,518] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2775
[2019-03-26 23:28:33,524] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 91.66666666666667, 1.0, 2.0, 0.4926362209958013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 786271.4478508017, 786271.4478508023, 193419.6816024164], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7395600.0000, 
sim time next is 7396200.0000, 
raw observation next is [20.8, 91.5, 1.0, 2.0, 0.4855258533818431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 775839.4433837334, 775839.4433837341, 192245.6599153558], 
processed observation next is [1.0, 0.6086956521739131, 0.1848341232227489, 0.915, 1.0, 1.0, 0.3801516305805339, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2155109564954815, 0.2155109564954817, 0.2869338207691878], 
reward next is 0.7131, 
noisyNet noise sample is [array([-0.79566276], dtype=float32), -2.321697]. 
=============================================
[2019-03-26 23:28:33,964] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.0422768e-24 1.0000000e+00 3.6043416e-22 2.1439481e-16 4.1970585e-29], sum to 1.0000
[2019-03-26 23:28:33,973] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7637
[2019-03-26 23:28:33,978] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.76666666666667, 77.66666666666666, 1.0, 2.0, 0.3771479680363486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 571253.0646516632, 571253.0646516638, 172195.2143893151], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7339800.0000, 
sim time next is 7340400.0000, 
raw observation next is [24.7, 78.0, 1.0, 2.0, 0.3764203951355077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 570445.5446265574, 570445.5446265574, 172133.074487773], 
processed observation next is [1.0, 1.0, 0.3696682464454976, 0.78, 1.0, 1.0, 0.2486992712475996, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15845709572959926, 0.15845709572959926, 0.25691503654891495], 
reward next is 0.7431, 
noisyNet noise sample is [array([0.20724003], dtype=float32), -1.5895885]. 
=============================================
[2019-03-26 23:28:35,719] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145000, global step 2320855: loss 0.0019
[2019-03-26 23:28:35,722] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145000, global step 2320855: learning rate 0.0000
[2019-03-26 23:28:37,472] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:28:37,473] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:28:37,566] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run12
[2019-03-26 23:28:38,187] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.6888861e-22 1.0000000e+00 6.4208792e-21 3.8069133e-15 1.9827410e-27], sum to 1.0000
[2019-03-26 23:28:38,193] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2046
[2019-03-26 23:28:38,199] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 96.0, 1.0, 2.0, 0.8055072414105805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1199470.901769697, 1199470.901769696, 255338.0040801441], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 130200.0000, 
sim time next is 130800.0000, 
raw observation next is [22.8, 96.0, 1.0, 2.0, 0.5897005694951256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 878133.0604781511, 878133.0604781511, 205617.59681179], 
processed observation next is [1.0, 0.5217391304347826, 0.2796208530805688, 0.96, 1.0, 1.0, 0.5056633367411152, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24392585013281975, 0.24392585013281975, 0.30689193553998506], 
reward next is 0.6931, 
noisyNet noise sample is [array([0.00846979], dtype=float32), -1.6745019]. 
=============================================
[2019-03-26 23:28:38,591] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2241977e-23 1.0000000e+00 7.0117966e-22 1.2159407e-16 2.2597266e-28], sum to 1.0000
[2019-03-26 23:28:38,598] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5928
[2019-03-26 23:28:38,602] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 90.83333333333333, 1.0, 2.0, 0.3089452171142616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 491210.6600636904, 491210.6600636904, 166421.9512078323], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7423800.0000, 
sim time next is 7424400.0000, 
raw observation next is [21.13333333333333, 91.66666666666667, 1.0, 2.0, 0.3108518866575624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 493494.2795078528, 493494.2795078522, 166577.7748135375], 
processed observation next is [1.0, 0.9565217391304348, 0.20063191153238533, 0.9166666666666667, 1.0, 1.0, 0.1697010682621234, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1370817443077369, 0.13708174430773673, 0.24862354449781715], 
reward next is 0.7514, 
noisyNet noise sample is [array([-1.2643445], dtype=float32), -0.15606444]. 
=============================================
[2019-03-26 23:28:38,825] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145500, global step 2322360: loss -231.5393
[2019-03-26 23:28:38,829] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145500, global step 2322360: learning rate 0.0000
[2019-03-26 23:28:39,890] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145000, global step 2322828: loss 0.0028
[2019-03-26 23:28:39,894] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145000, global step 2322828: learning rate 0.0000
[2019-03-26 23:28:41,760] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.4054254e-24 1.0000000e+00 3.2563863e-23 1.0767362e-19 8.9097078e-30], sum to 1.0000
[2019-03-26 23:28:41,774] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0776
[2019-03-26 23:28:41,778] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.28333333333333, 95.0, 1.0, 2.0, 0.3253127911839967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 509433.2232813542, 509433.2232813542, 167627.651623421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7451400.0000, 
sim time next is 7452000.0000, 
raw observation next is [21.3, 95.0, 1.0, 2.0, 0.3260327838163428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 510341.9986282933, 510341.9986282933, 167691.857100295], 
processed observation next is [0.0, 0.2608695652173913, 0.2085308056872039, 0.95, 1.0, 1.0, 0.18799130580282267, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14176166628563702, 0.14176166628563702, 0.2502863538810373], 
reward next is 0.7497, 
noisyNet noise sample is [array([-0.5781656], dtype=float32), 2.2762835]. 
=============================================
[2019-03-26 23:28:41,791] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[76.20268 ]
 [76.175186]
 [76.13516 ]
 [76.09757 ]
 [76.05614 ]], R is [[76.24271393]
 [76.23009491]
 [76.21766663]
 [76.20537567]
 [76.19327545]].
[2019-03-26 23:28:43,698] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145500, global step 2324526: loss -216.1022
[2019-03-26 23:28:43,703] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145500, global step 2324528: learning rate 0.0000
[2019-03-26 23:28:43,724] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145000, global step 2324538: loss 0.0028
[2019-03-26 23:28:43,728] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145000, global step 2324540: learning rate 0.0000
[2019-03-26 23:28:44,511] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145000, global step 2324890: loss 0.0032
[2019-03-26 23:28:44,514] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145000, global step 2324890: learning rate 0.0000
[2019-03-26 23:28:44,713] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145000, global step 2324980: loss 0.0027
[2019-03-26 23:28:44,715] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145000, global step 2324980: learning rate 0.0000
[2019-03-26 23:28:44,717] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145000, global step 2324980: loss 0.0025
[2019-03-26 23:28:44,719] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145000, global step 2324982: learning rate 0.0000
[2019-03-26 23:28:44,763] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 23:28:44,765] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 23:28:44,766] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:28:44,767] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 23:28:44,769] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:28:44,770] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 23:28:44,772] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:28:44,773] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 23:28:44,775] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 23:28:44,777] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:28:44,778] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:28:44,801] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run94
[2019-03-26 23:28:44,802] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run94
[2019-03-26 23:28:44,855] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run94
[2019-03-26 23:28:44,876] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run94
[2019-03-26 23:28:44,878] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run94
[2019-03-26 23:28:48,849] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0913505], dtype=float32), 0.07693904]
[2019-03-26 23:28:48,851] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.762837645, 91.08360443500001, 1.0, 2.0, 0.3896819886939106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 588990.5623705331, 588990.5623705337, 173743.5563302592]
[2019-03-26 23:28:48,852] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:28:48,855] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.6631285e-24 1.0000000e+00 4.7995913e-23 3.7672788e-19 9.9508783e-30], sampled 0.8509752739940071
[2019-03-26 23:28:55,063] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0913505], dtype=float32), 0.07693904]
[2019-03-26 23:28:55,064] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [17.2502648, 83.85968898, 1.0, 2.0, 0.1926626511123559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 322276.3289110357, 322276.3289110357, 140313.7896285462]
[2019-03-26 23:28:55,065] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:28:55,067] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.3643898e-23 1.0000000e+00 2.7873235e-22 4.3460638e-19 7.9873148e-29], sampled 0.13929413069769037
[2019-03-26 23:30:05,740] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0913505], dtype=float32), 0.07693904]
[2019-03-26 23:30:05,741] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.73333333333333, 95.0, 1.0, 2.0, 0.6998789823207824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 978100.7408167449, 978100.7408167449, 220818.0815244658]
[2019-03-26 23:30:05,743] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:30:05,745] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.1815587e-23 1.0000000e+00 4.7623157e-22 1.2169755e-16 5.1520040e-29], sampled 0.11357397172399364
[2019-03-26 23:30:08,524] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0913505], dtype=float32), 0.07693904]
[2019-03-26 23:30:08,526] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [36.01666666666667, 50.0, 1.0, 2.0, 0.5869892985736627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 820273.2795008229, 820273.2795008229, 198347.2648218295]
[2019-03-26 23:30:08,527] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 23:30:08,529] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.4053888e-24 1.0000000e+00 2.9301844e-23 9.2822685e-18 4.7398953e-30], sampled 0.03286696980607173
[2019-03-26 23:30:09,563] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0913505], dtype=float32), 0.07693904]
[2019-03-26 23:30:09,564] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.16666666666666, 88.00000000000001, 1.0, 2.0, 0.6075769833200171, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.938964590555127, 6.9112, 168.9126907120898, 1698788.308476909, 1679091.183348728, 366002.5107894193]
[2019-03-26 23:30:09,566] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:30:09,571] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.8966789e-17 1.0000000e+00 4.3410997e-16 5.0645799e-10 3.4484715e-21], sampled 0.4409952114725125
[2019-03-26 23:30:09,573] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1698788.308476909 W.
[2019-03-26 23:30:17,872] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0913505], dtype=float32), 0.07693904]
[2019-03-26 23:30:17,875] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.49651482833333, 80.83443317833333, 1.0, 2.0, 0.4556606810308507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 659385.5001043497, 659385.500104349, 179834.2590162315]
[2019-03-26 23:30:17,877] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:30:17,879] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.7798704e-24 1.0000000e+00 1.2126064e-22 2.0669875e-17 2.4277927e-29], sampled 0.1767784454785758
[2019-03-26 23:30:27,478] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0913505], dtype=float32), 0.07693904]
[2019-03-26 23:30:27,479] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.6, 92.66666666666667, 1.0, 2.0, 0.569235914044757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 802345.5808369551, 802345.5808369551, 196039.0806612568]
[2019-03-26 23:30:27,480] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:30:27,482] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.2591273e-23 1.0000000e+00 1.2583117e-22 1.2057736e-17 2.0295183e-29], sampled 0.3094876626129014
[2019-03-26 23:30:34,977] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0913505], dtype=float32), 0.07693904]
[2019-03-26 23:30:34,979] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.5, 83.0, 1.0, 2.0, 0.5623906333035926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 785885.7829878939, 785885.7829878945, 193948.2225550309]
[2019-03-26 23:30:34,982] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:30:34,985] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.4170204e-24 1.0000000e+00 1.1018986e-22 3.4009385e-17 2.1353067e-29], sampled 0.4752923472791081
[2019-03-26 23:30:38,916] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8002.9654 3007111749.6020 1744.0000
[2019-03-26 23:30:39,325] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7894.1742 3163096891.3174 1730.0000
[2019-03-26 23:30:39,487] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.2692 2779208046.7960 930.0000
[2019-03-26 23:30:39,584] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.5624 2927613617.6943 1337.0000
[2019-03-26 23:30:39,669] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8503.5607 2841813744.2920 1117.0000
[2019-03-26 23:30:40,688] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2325000, evaluation results [2325000.0, 7894.174208378808, 3163096891.317415, 1730.0, 8255.562354296355, 2927613617.694256, 1337.0, 8660.269198098447, 2779208046.7959805, 930.0, 8002.9653901178, 3007111749.6020417, 1744.0, 8503.560712134282, 2841813744.291966, 1117.0]
[2019-03-26 23:30:40,828] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145000, global step 2325067: loss 0.0034
[2019-03-26 23:30:40,829] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145000, global step 2325067: learning rate 0.0000
[2019-03-26 23:30:40,868] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145000, global step 2325082: loss 0.0026
[2019-03-26 23:30:40,872] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145000, global step 2325083: learning rate 0.0000
[2019-03-26 23:30:41,245] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145000, global step 2325247: loss 0.0023
[2019-03-26 23:30:41,247] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145000, global step 2325248: learning rate 0.0000
[2019-03-26 23:30:41,273] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145000, global step 2325261: loss 0.0026
[2019-03-26 23:30:41,274] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145000, global step 2325262: learning rate 0.0000
[2019-03-26 23:30:41,283] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2271566e-24 1.0000000e+00 9.9787339e-24 4.0962902e-19 1.4132957e-30], sum to 1.0000
[2019-03-26 23:30:41,291] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7496
[2019-03-26 23:30:41,295] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 92.5, 1.0, 2.0, 0.4017426776871507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 594625.5350755848, 594625.5350755848, 173898.9743302296], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7525800.0000, 
sim time next is 7526400.0000, 
raw observation next is [23.36666666666667, 92.33333333333333, 1.0, 2.0, 0.3984910285097117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 590974.3716383805, 590974.3716383805, 173596.6020012604], 
processed observation next is [0.0, 0.08695652173913043, 0.30647709320695127, 0.9233333333333333, 1.0, 1.0, 0.27529039579483333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1641595476773279, 0.1641595476773279, 0.25909940597203046], 
reward next is 0.7409, 
noisyNet noise sample is [array([-0.32498676], dtype=float32), -0.9334853]. 
=============================================
[2019-03-26 23:30:44,237] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:30:44,238] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:30:44,325] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run12
[2019-03-26 23:30:46,189] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.5722967e-18 1.0000000e+00 2.6271307e-16 5.6121812e-11 1.1309420e-22], sum to 1.0000
[2019-03-26 23:30:46,197] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9351
[2019-03-26 23:30:46,209] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1695739.304878218 W.
[2019-03-26 23:30:46,216] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.3, 79.0, 1.0, 2.0, 0.4043280243649596, 1.0, 2.0, 0.4043280243649596, 1.0, 1.0, 0.6943603125510205, 6.9112, 6.9112, 170.5573041426782, 1695739.304878218, 1695739.304878218, 354185.4504493998], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7808400.0000, 
sim time next is 7809000.0000, 
raw observation next is [28.41666666666667, 78.33333333333334, 1.0, 2.0, 0.403592529386316, 1.0, 2.0, 0.403592529386316, 1.0, 2.0, 0.6934620786595429, 6.9112, 6.9112, 170.5573041426782, 1692652.225410782, 1692652.225410782, 353830.928724755], 
processed observation next is [1.0, 0.391304347826087, 0.5458135860979465, 0.7833333333333334, 1.0, 1.0, 0.28143678239315184, 1.0, 1.0, 0.28143678239315184, 1.0, 1.0, 0.6261732666579791, 0.0, 0.0, 0.8375144448122397, 0.4701811737252172, 0.4701811737252172, 0.528105863768291], 
reward next is 0.4719, 
noisyNet noise sample is [array([0.8478142], dtype=float32), -0.901411]. 
=============================================
[2019-03-26 23:30:46,245] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[57.837627]
 [62.859444]
 [65.6703  ]
 [69.28851 ]
 [70.11049 ]], R is [[53.62687683]
 [53.56197357]
 [53.50786209]
 [53.41712189]
 [52.88294983]].
[2019-03-26 23:30:46,461] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145500, global step 2327681: loss -252.5835
[2019-03-26 23:30:46,462] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145500, global step 2327681: learning rate 0.0000
[2019-03-26 23:30:48,765] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:30:48,766] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:30:48,834] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run12
[2019-03-26 23:30:49,002] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145500, global step 2328806: loss -281.3216
[2019-03-26 23:30:49,004] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145500, global step 2328806: learning rate 0.0000
[2019-03-26 23:30:53,103] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145500, global step 2330759: loss -361.7398
[2019-03-26 23:30:53,104] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145500, global step 2330759: learning rate 0.0000
[2019-03-26 23:30:55,343] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:30:55,344] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:30:55,424] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run12
[2019-03-26 23:30:56,484] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145500, global step 2332379: loss -249.5445
[2019-03-26 23:30:56,486] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145500, global step 2332379: learning rate 0.0000
[2019-03-26 23:30:57,177] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145500, global step 2332704: loss -325.0587
[2019-03-26 23:30:57,180] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145500, global step 2332705: learning rate 0.0000
[2019-03-26 23:30:57,289] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145500, global step 2332753: loss -392.7741
[2019-03-26 23:30:57,291] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145500, global step 2332755: learning rate 0.0000
[2019-03-26 23:30:57,379] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145500, global step 2332796: loss -245.7169
[2019-03-26 23:30:57,381] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145500, global step 2332797: learning rate 0.0000
[2019-03-26 23:30:57,550] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145500, global step 2332874: loss -287.8619
[2019-03-26 23:30:57,552] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145500, global step 2332874: learning rate 0.0000
[2019-03-26 23:30:57,555] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:30:57,555] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:30:57,638] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run12
[2019-03-26 23:30:57,700] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145500, global step 2332918: loss -310.6751
[2019-03-26 23:30:57,703] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145500, global step 2332919: learning rate 0.0000
[2019-03-26 23:30:57,824] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145500, global step 2332981: loss -104.6096
[2019-03-26 23:30:57,828] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145500, global step 2332981: learning rate 0.0000
[2019-03-26 23:30:57,938] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145500, global step 2333046: loss -201.3762
[2019-03-26 23:30:57,942] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145500, global step 2333047: learning rate 0.0000
[2019-03-26 23:30:59,927] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.1558157e-24 1.0000000e+00 5.0459976e-22 6.4423881e-16 2.7734724e-29], sum to 1.0000
[2019-03-26 23:30:59,935] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3459
[2019-03-26 23:30:59,941] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 87.0, 1.0, 2.0, 0.5058889047323214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 706903.8834219666, 706903.8834219672, 184523.7968878408], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7858800.0000, 
sim time next is 7859400.0000, 
raw observation next is [26.38333333333333, 87.33333333333333, 1.0, 2.0, 0.5052459180020655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 706005.1073105693, 706005.10731057, 184422.1017408133], 
processed observation next is [1.0, 1.0, 0.44944707740916257, 0.8733333333333333, 1.0, 1.0, 0.40391074458080184, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19611252980849145, 0.19611252980849164, 0.27525686826987056], 
reward next is 0.7247, 
noisyNet noise sample is [array([-0.93805915], dtype=float32), 0.35284397]. 
=============================================
[2019-03-26 23:31:01,653] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:31:01,654] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:31:01,723] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run12
[2019-03-26 23:31:05,113] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:31:05,115] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:31:05,135] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run12
[2019-03-26 23:31:05,547] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.0472417e-23 1.0000000e+00 5.4766917e-21 4.6122357e-16 6.0801386e-29], sum to 1.0000
[2019-03-26 23:31:05,548] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8252
[2019-03-26 23:31:05,551] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.31666666666667, 66.66666666666667, 1.0, 2.0, 0.2479955038477095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 408306.4379170497, 408306.4379170503, 160700.9683011164], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 672600.0000, 
sim time next is 673200.0000, 
raw observation next is [22.1, 68.0, 1.0, 2.0, 0.2483964544502939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 409016.1123429117, 409016.1123429111, 160739.05740801], 
processed observation next is [1.0, 0.8260869565217391, 0.24644549763033188, 0.68, 1.0, 1.0, 0.09445355957866734, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11361558676191992, 0.11361558676191974, 0.2399090409074776], 
reward next is 0.7601, 
noisyNet noise sample is [array([0.28514862], dtype=float32), 0.3670598]. 
=============================================
[2019-03-26 23:31:05,690] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:31:05,690] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:31:05,754] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run12
[2019-03-26 23:31:05,823] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:31:05,824] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:31:05,871] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run12
[2019-03-26 23:31:05,917] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:31:05,918] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:31:05,967] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run12
[2019-03-26 23:31:06,124] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:31:06,124] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:31:06,183] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run12
[2019-03-26 23:31:06,210] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:31:06,212] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:31:06,212] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:31:06,219] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:31:06,250] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run12
[2019-03-26 23:31:06,281] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run12
[2019-03-26 23:31:06,476] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 23:31:06,476] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:31:06,504] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run12
[2019-03-26 23:31:06,553] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4657715e-21 1.0000000e+00 1.5479286e-20 1.4823810e-16 1.2567974e-27], sum to 1.0000
[2019-03-26 23:31:06,557] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5003
[2019-03-26 23:31:06,561] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.93333333333333, 90.0, 1.0, 2.0, 0.2147865918908541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 357865.0006242922, 357865.0006242922, 157127.2389302956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 710400.0000, 
sim time next is 711000.0000, 
raw observation next is [18.15, 89.0, 1.0, 2.0, 0.2173185904862084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 361838.8124192937, 361838.812419293, 157413.731950183], 
processed observation next is [1.0, 0.21739130434782608, 0.059241706161137435, 0.89, 1.0, 1.0, 0.05701034998338362, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10051078122758157, 0.10051078122758138, 0.23494586858236266], 
reward next is 0.7651, 
noisyNet noise sample is [array([-1.1851357], dtype=float32), 0.24234791]. 
=============================================
[2019-03-26 23:31:06,574] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[70.84037]
 [70.82579]
 [70.79124]
 [70.75428]
 [70.74296]], R is [[70.88401794]
 [70.94065857]
 [70.99651337]
 [71.05250549]
 [71.10770416]].
[2019-03-26 23:31:08,634] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.8920865e-23 1.0000000e+00 2.6218780e-21 4.2553006e-16 1.8589917e-28], sum to 1.0000
[2019-03-26 23:31:08,645] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0697
[2019-03-26 23:31:08,650] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 82.50000000000001, 1.0, 2.0, 0.2573163386722432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 422445.1565407084, 422445.1565407078, 161640.7203193426], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 767400.0000, 
sim time next is 768000.0000, 
raw observation next is [20.26666666666667, 83.0, 1.0, 2.0, 0.2571927438817255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 422256.5592356881, 422256.5592356881, 161628.2295664809], 
processed observation next is [1.0, 0.9130434782608695, 0.15955766192733034, 0.83, 1.0, 1.0, 0.10505149865268135, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11729348867658003, 0.11729348867658003, 0.24123616353206107], 
reward next is 0.7588, 
noisyNet noise sample is [array([-0.63942057], dtype=float32), 1.530678]. 
=============================================
[2019-03-26 23:31:08,679] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[73.87297 ]
 [73.70424 ]
 [73.548874]
 [73.460655]
 [73.43972 ]], R is [[74.07629395]
 [74.09427643]
 [74.11215973]
 [74.13002014]
 [74.14777374]].
[2019-03-26 23:31:08,698] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0315946e-21 1.0000000e+00 8.9264517e-21 8.5719411e-16 2.1027573e-27], sum to 1.0000
[2019-03-26 23:31:08,704] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0359
[2019-03-26 23:31:08,711] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.85, 65.16666666666667, 1.0, 2.0, 0.4540023735049609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 744831.6158958232, 744831.6158958225, 187877.8875763478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 472200.0000, 
sim time next is 472800.0000, 
raw observation next is [23.0, 64.33333333333334, 1.0, 2.0, 0.4487163907517874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 736011.6630349646, 736011.6630349639, 187009.2207271415], 
processed observation next is [1.0, 0.4782608695652174, 0.28909952606635075, 0.6433333333333334, 1.0, 1.0, 0.33580288042384016, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20444768417637904, 0.20444768417637885, 0.279118239891256], 
reward next is 0.7209, 
noisyNet noise sample is [array([-0.7168633], dtype=float32), -0.46724993]. 
=============================================
[2019-03-26 23:31:10,720] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.7912443e-16 9.9999976e-01 1.9215015e-14 2.5321907e-07 2.4041820e-20], sum to 1.0000
[2019-03-26 23:31:10,731] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7646
[2019-03-26 23:31:10,738] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666667, 67.5, 1.0, 2.0, 0.9648228124987546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104139, 1425515.003732727, 1425515.003732727, 299919.2912780253], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 57000.0000, 
sim time next is 57600.0000, 
raw observation next is [27.1, 68.0, 1.0, 2.0, 0.9720047126799344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1435826.232991534, 1435826.232991534, 302128.6942973188], 
processed observation next is [1.0, 0.6956521739130435, 0.4834123222748816, 0.68, 1.0, 1.0, 0.9662707381685957, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3988406202754261, 0.3988406202754261, 0.45093834969749075], 
reward next is 0.5491, 
noisyNet noise sample is [array([-1.2901782], dtype=float32), 0.5489836]. 
=============================================
[2019-03-26 23:31:13,783] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8484822e-22 1.0000000e+00 9.4550452e-21 2.1142792e-16 2.0583757e-28], sum to 1.0000
[2019-03-26 23:31:13,791] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1029
[2019-03-26 23:31:13,798] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 91.66666666666666, 1.0, 2.0, 0.6899812295964433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1041901.524199216, 1041901.524199216, 228628.4966481672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 117600.0000, 
sim time next is 118200.0000, 
raw observation next is [22.91666666666666, 91.83333333333333, 1.0, 2.0, 0.6901428479089019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1041999.03035852, 1041999.03035852, 228648.5417650107], 
processed observation next is [1.0, 0.34782608695652173, 0.2851500789889413, 0.9183333333333333, 1.0, 1.0, 0.6266781300107251, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.28944417509958886, 0.28944417509958886, 0.34126648024628464], 
reward next is 0.6587, 
noisyNet noise sample is [array([-1.5341928], dtype=float32), -0.87103575]. 
=============================================
[2019-03-26 23:31:16,982] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9975404e-24 1.0000000e+00 2.0465272e-23 3.3337033e-20 3.7249020e-30], sum to 1.0000
[2019-03-26 23:31:16,993] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9128
[2019-03-26 23:31:17,001] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 81.33333333333333, 1.0, 2.0, 0.2841238818640062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 457103.4032941213, 457103.4032941206, 164075.5186033361], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 805200.0000, 
sim time next is 805800.0000, 
raw observation next is [21.95, 80.66666666666667, 1.0, 2.0, 0.2856790956101199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 459085.7913686127, 459085.7913686133, 164207.8462848188], 
processed observation next is [0.0, 0.30434782608695654, 0.2393364928909953, 0.8066666666666668, 1.0, 1.0, 0.13937240434954204, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12752383093572575, 0.12752383093572592, 0.24508633773853553], 
reward next is 0.7549, 
noisyNet noise sample is [array([0.05818024], dtype=float32), -0.6412745]. 
=============================================
[2019-03-26 23:31:19,935] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.1181090e-24 1.0000000e+00 4.4801493e-23 2.2175601e-19 1.2336017e-30], sum to 1.0000
[2019-03-26 23:31:19,948] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3578
[2019-03-26 23:31:19,956] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.78333333333333, 92.16666666666667, 1.0, 2.0, 0.3010305345907621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 480659.1345238702, 480659.1345238708, 165686.503816592], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 211800.0000, 
sim time next is 212400.0000, 
raw observation next is [20.8, 92.0, 1.0, 2.0, 0.3002782339955276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 479492.7533179404, 479492.753317941, 165603.6485975491], 
processed observation next is [0.0, 0.4782608695652174, 0.1848341232227489, 0.92, 1.0, 1.0, 0.15696172770545494, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13319243147720566, 0.13319243147720583, 0.24716962477246132], 
reward next is 0.7528, 
noisyNet noise sample is [array([-0.24153955], dtype=float32), -0.7453461]. 
=============================================
[2019-03-26 23:31:21,664] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.9657702e-24 1.0000000e+00 1.8091992e-22 4.5862496e-17 1.7607891e-29], sum to 1.0000
[2019-03-26 23:31:21,672] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4983
[2019-03-26 23:31:21,680] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.91666666666667, 87.33333333333334, 1.0, 2.0, 0.2361683106435371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 391235.6798511617, 391235.6798511617, 159430.0451352234], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 687000.0000, 
sim time next is 687600.0000, 
raw observation next is [18.8, 88.0, 1.0, 2.0, 0.2349968896338142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 389433.2932708868, 389433.2932708875, 159306.2788507443], 
processed observation next is [1.0, 1.0, 0.09004739336492901, 0.88, 1.0, 1.0, 0.07830950558290868, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10817591479746856, 0.10817591479746876, 0.2377705654488721], 
reward next is 0.7622, 
noisyNet noise sample is [array([0.6054047], dtype=float32), 0.30337813]. 
=============================================
[2019-03-26 23:31:26,075] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.7822114e-25 1.0000000e+00 5.8282759e-24 1.1045727e-19 5.4688977e-31], sum to 1.0000
[2019-03-26 23:31:26,084] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7472
[2019-03-26 23:31:26,089] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.26666666666667, 77.33333333333334, 1.0, 2.0, 0.3122301602290706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 492632.268274088, 492632.268274088, 166453.4960338545], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 314400.0000, 
sim time next is 315000.0000, 
raw observation next is [23.2, 77.5, 1.0, 2.0, 0.3108384143471128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 490909.443054163, 490909.443054163, 166337.0988665487], 
processed observation next is [0.0, 0.6521739130434783, 0.29857819905213273, 0.775, 1.0, 1.0, 0.1696848365627865, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13636373418171194, 0.13636373418171194, 0.24826432666649062], 
reward next is 0.7517, 
noisyNet noise sample is [array([0.3558221], dtype=float32), -0.11521858]. 
=============================================
[2019-03-26 23:31:26,105] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[78.75983]
 [78.71559]
 [78.65831]
 [78.59809]
 [78.5641 ]], R is [[78.76446533]
 [78.72838593]
 [78.69248199]
 [78.6567688 ]
 [78.6212616 ]].
[2019-03-26 23:31:27,894] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.7562862e-23 1.0000000e+00 1.1524877e-21 9.2187195e-17 4.5702068e-29], sum to 1.0000
[2019-03-26 23:31:27,905] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3119
[2019-03-26 23:31:27,909] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.05, 89.5, 1.0, 2.0, 0.2566018689352981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 417774.758054382, 417774.758054382, 161494.9195042748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 361800.0000, 
sim time next is 362400.0000, 
raw observation next is [20.03333333333333, 89.66666666666667, 1.0, 2.0, 0.2571424099729964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 418631.7409646709, 418631.7409646703, 161548.2531185804], 
processed observation next is [1.0, 0.17391304347826086, 0.14849921011058448, 0.8966666666666667, 1.0, 1.0, 0.1049908553891523, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11628659471240858, 0.11628659471240842, 0.24111679569937375], 
reward next is 0.7589, 
noisyNet noise sample is [array([-0.8346223], dtype=float32), 1.4261136]. 
=============================================
[2019-03-26 23:31:30,510] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1029963e-22 1.0000000e+00 2.2816145e-21 1.0143731e-15 1.9555034e-28], sum to 1.0000
[2019-03-26 23:31:30,518] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6367
[2019-03-26 23:31:30,525] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 80.0, 1.0, 2.0, 0.5961380829508031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 954474.4791067817, 954474.479106781, 213665.3531353726], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 404400.0000, 
sim time next is 405000.0000, 
raw observation next is [22.15, 80.5, 1.0, 2.0, 0.5874190559732858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 940185.5759398754, 940185.5759398754, 211811.7673065752], 
processed observation next is [1.0, 0.6956521739130435, 0.24881516587677724, 0.805, 1.0, 1.0, 0.502914525269019, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.26116265998329874, 0.26116265998329874, 0.3161369661292167], 
reward next is 0.6839, 
noisyNet noise sample is [array([-1.5579174], dtype=float32), 1.2414382]. 
=============================================
[2019-03-26 23:31:30,546] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[73.533104]
 [73.46968 ]
 [73.523605]
 [73.43834 ]
 [73.36446 ]], R is [[73.57927704]
 [73.52458191]
 [73.45246124]
 [73.42166138]
 [73.39299011]].
[2019-03-26 23:31:31,142] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.8513360e-23 1.0000000e+00 7.0859603e-21 3.2836947e-14 6.1866662e-28], sum to 1.0000
[2019-03-26 23:31:31,259] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0842
[2019-03-26 23:31:31,265] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 58.16666666666666, 1.0, 2.0, 0.9141797596363661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1402541.308959579, 1402541.308959579, 291385.2435093187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1180200.0000, 
sim time next is 1180800.0000, 
raw observation next is [27.6, 58.0, 1.0, 2.0, 0.9273329028324265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1423921.034399745, 1423921.034399745, 295614.1797955311], 
processed observation next is [1.0, 0.6956521739130435, 0.5071090047393366, 0.58, 1.0, 1.0, 0.9124492805209958, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.39553362066659586, 0.39553362066659586, 0.44121519372467327], 
reward next is 0.5588, 
noisyNet noise sample is [array([-2.337966], dtype=float32), -1.7868118]. 
=============================================
[2019-03-26 23:31:33,732] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.3520847e-22 1.0000000e+00 7.4390929e-21 2.5760436e-15 1.0097687e-27], sum to 1.0000
[2019-03-26 23:31:33,741] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5716
[2019-03-26 23:31:33,747] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.03333333333334, 53.0, 1.0, 2.0, 0.5232164997916068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 857609.5708894643, 857609.5708894636, 200104.891505163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 487200.0000, 
sim time next is 487800.0000, 
raw observation next is [25.0, 53.0, 1.0, 2.0, 0.5412676434937735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 887544.5930901167, 887544.5930901167, 203569.2083189036], 
processed observation next is [1.0, 0.6521739130434783, 0.38388625592417064, 0.53, 1.0, 1.0, 0.4473104138479199, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24654016474725465, 0.24654016474725465, 0.3038346392819457], 
reward next is 0.6962, 
noisyNet noise sample is [array([0.02580426], dtype=float32), -0.20982894]. 
=============================================
[2019-03-26 23:31:34,954] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 23:31:34,956] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 23:31:34,959] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:31:34,959] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 23:31:34,960] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 23:31:34,962] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:31:34,962] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:31:34,964] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 23:31:34,963] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 23:31:34,966] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:31:34,968] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:31:34,986] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run95
[2019-03-26 23:31:35,014] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run95
[2019-03-26 23:31:35,015] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run95
[2019-03-26 23:31:35,036] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run95
[2019-03-26 23:31:35,061] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run95
[2019-03-26 23:31:50,049] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08967046], dtype=float32), 0.078857444]
[2019-03-26 23:31:50,050] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.20946699666667, 97.91221734166668, 1.0, 2.0, 0.4187671206173548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 610878.1844904417, 610878.1844904411, 175155.5574585883]
[2019-03-26 23:31:50,051] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:31:50,054] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.6560436e-25 1.0000000e+00 2.2217289e-24 3.4890047e-19 1.8106339e-31], sampled 0.8984085859498191
[2019-03-26 23:31:58,817] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08967046], dtype=float32), 0.078857444]
[2019-03-26 23:31:58,819] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.26251315, 78.90164598, 1.0, 2.0, 0.3712631464769138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 567197.3185806463, 567197.318580647, 171982.7167531843]
[2019-03-26 23:31:58,820] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:31:58,823] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.5238515e-25 1.0000000e+00 4.1512902e-24 5.0631467e-19 4.9110856e-31], sampled 0.6121948941673041
[2019-03-26 23:32:26,519] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08967046], dtype=float32), 0.078857444]
[2019-03-26 23:32:26,521] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.06079249, 65.27602099, 1.0, 2.0, 0.9417977133996689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1316398.607006631, 1316398.607006631, 281689.7951104146]
[2019-03-26 23:32:26,522] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:32:26,526] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.5097374e-19 9.9999130e-01 3.6613603e-16 8.7353255e-06 1.9677260e-23], sampled 0.06966771769693247
[2019-03-26 23:32:36,982] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08967046], dtype=float32), 0.078857444]
[2019-03-26 23:32:36,983] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.6, 52.0, 1.0, 2.0, 0.9654252116742219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129099086413, 1349444.953654705, 1349444.953654705, 288572.6019751587]
[2019-03-26 23:32:36,985] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:32:36,989] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.3973496e-24 1.0000000e+00 1.0416227e-21 3.0220475e-14 1.6751904e-29], sampled 0.4289068684436297
[2019-03-26 23:32:38,415] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08967046], dtype=float32), 0.078857444]
[2019-03-26 23:32:38,417] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [37.0, 45.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.41124035280669, 6.9112, 168.9100169743342, 1808737.562266664, 1453997.899448858, 311353.6022592237]
[2019-03-26 23:32:38,418] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:32:38,419] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.5727952e-22 1.0000000e+00 3.3067745e-21 1.0904249e-14 9.3838298e-28], sampled 0.04853976527652526
[2019-03-26 23:32:38,420] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1808737.562266664 W.
[2019-03-26 23:32:42,589] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08967046], dtype=float32), 0.078857444]
[2019-03-26 23:32:42,591] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.85, 51.83333333333333, 1.0, 2.0, 0.5195172380397252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 725953.9428611128, 725953.9428611135, 186709.5921711856]
[2019-03-26 23:32:42,593] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:32:42,595] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.0660647e-25 1.0000000e+00 4.0602182e-24 4.4816306e-18 3.8986469e-31], sampled 0.17219169633088294
[2019-03-26 23:32:45,696] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08967046], dtype=float32), 0.078857444]
[2019-03-26 23:32:45,699] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.66666666666667, 64.0, 1.0, 2.0, 0.9333494522803606, 1.0, 1.0, 0.9333494522803606, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2610670.324490519, 2610670.324490519, 490008.8061329293]
[2019-03-26 23:32:45,701] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:32:45,704] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.7507524e-14 6.0463744e-01 7.8933787e-12 3.9536262e-01 6.7771156e-18], sampled 0.5085910557821955
[2019-03-26 23:32:45,705] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2610670.324490519 W.
[2019-03-26 23:33:29,954] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8502.4437 2842065621.5470 1125.0000
[2019-03-26 23:33:30,054] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7893.4788 3163097227.8174 1744.0000
[2019-03-26 23:33:30,072] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7004 2779289399.8544 932.0000
[2019-03-26 23:33:30,119] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8000.5720 3007099821.4731 1754.0000
[2019-03-26 23:33:30,126] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8257.2765 2927126750.7424 1330.0000
[2019-03-26 23:33:31,149] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2350000, evaluation results [2350000.0, 7893.478753398105, 3163097227.8173513, 1744.0, 8257.27649751873, 2927126750.74242, 1330.0, 8660.700364324584, 2779289399.8544455, 932.0, 8000.571989281277, 3007099821.473064, 1754.0, 8502.443695473232, 2842065621.547012, 1125.0]
[2019-03-26 23:33:38,579] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.60072831e-23 1.00000000e+00 7.51398027e-23 1.06662386e-16
 7.40440544e-30], sum to 1.0000
[2019-03-26 23:33:38,590] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6372
[2019-03-26 23:33:38,594] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.26666666666667, 81.5, 1.0, 2.0, 0.2289954706381522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 380504.1474334769, 380504.1474334762, 158613.0745081647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 598200.0000, 
sim time next is 598800.0000, 
raw observation next is [19.13333333333333, 82.0, 1.0, 2.0, 0.2283519834090758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 379638.9429128517, 379638.9429128511, 158517.9449274642], 
processed observation next is [1.0, 0.9565217391304348, 0.10584518167456543, 0.82, 1.0, 1.0, 0.07030359446876602, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10545526192023658, 0.10545526192023642, 0.23659394765293165], 
reward next is 0.7634, 
noisyNet noise sample is [array([0.88886446], dtype=float32), 1.5075865]. 
=============================================
[2019-03-26 23:33:41,015] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.326101e-23 1.000000e+00 1.282098e-21 8.526926e-18 8.177352e-29], sum to 1.0000
[2019-03-26 23:33:41,022] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6000
[2019-03-26 23:33:41,030] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.6, 89.0, 1.0, 2.0, 0.2198288230664026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 367157.5882223534, 367157.5882223534, 157216.274623464], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 624600.0000, 
sim time next is 625200.0000, 
raw observation next is [17.83333333333333, 88.0, 1.0, 2.0, 0.212748809646652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 355133.0624680157, 355133.0624680163, 156705.7068903017], 
processed observation next is [1.0, 0.21739130434782608, 0.044233807266982464, 0.88, 1.0, 1.0, 0.05150458993572528, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.09864807290778214, 0.0986480729077823, 0.2338891147616443], 
reward next is 0.7661, 
noisyNet noise sample is [array([0.86049837], dtype=float32), 2.3960786]. 
=============================================
[2019-03-26 23:33:51,557] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8571095e-23 1.0000000e+00 3.6980451e-22 4.4626626e-17 4.8556895e-29], sum to 1.0000
[2019-03-26 23:33:51,565] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4486
[2019-03-26 23:33:51,571] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 85.83333333333334, 1.0, 2.0, 0.3784540091892027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 585719.1605597021, 585719.1605597021, 173782.2049204879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1581000.0000, 
sim time next is 1581600.0000, 
raw observation next is [23.0, 85.66666666666667, 1.0, 2.0, 0.4049383960172848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 625351.7038911121, 625351.7038911128, 177324.7254142032], 
processed observation next is [1.0, 0.30434782608695654, 0.28909952606635075, 0.8566666666666667, 1.0, 1.0, 0.28305830845456004, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17370880663642002, 0.17370880663642022, 0.2646637692749301], 
reward next is 0.7353, 
noisyNet noise sample is [array([0.32967362], dtype=float32), 0.37456083]. 
=============================================
[2019-03-26 23:33:54,548] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3824279e-22 1.0000000e+00 3.6449367e-22 1.1387074e-16 5.9074777e-29], sum to 1.0000
[2019-03-26 23:33:54,558] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1271
[2019-03-26 23:33:54,564] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.56666666666667, 96.83333333333334, 1.0, 2.0, 0.3545090253303371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 546747.7960604882, 546747.7960604876, 170392.7842107117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1048200.0000, 
sim time next is 1048800.0000, 
raw observation next is [21.43333333333333, 96.66666666666667, 1.0, 2.0, 0.3371600872445006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 522255.1675875294, 522255.1675875288, 168469.7412859084], 
processed observation next is [1.0, 0.13043478260869565, 0.21484992101105835, 0.9666666666666667, 1.0, 1.0, 0.2013976954753019, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14507087988542483, 0.14507087988542466, 0.25144737505359466], 
reward next is 0.7486, 
noisyNet noise sample is [array([-1.0187067], dtype=float32), -0.23464963]. 
=============================================
[2019-03-26 23:33:56,809] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.0247331e-25 1.0000000e+00 5.7578701e-24 1.3376194e-19 2.4963394e-30], sum to 1.0000
[2019-03-26 23:33:56,817] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8358
[2019-03-26 23:33:56,825] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 74.0, 1.0, 2.0, 0.2965594300636533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 472648.2819308657, 472648.2819308657, 165105.7264027745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 907200.0000, 
sim time next is 907800.0000, 
raw observation next is [23.45, 73.33333333333334, 1.0, 2.0, 0.2975666348156158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 473890.9216368221, 473890.9216368227, 165187.7114412063], 
processed observation next is [0.0, 0.5217391304347826, 0.3104265402843602, 0.7333333333333334, 1.0, 1.0, 0.15369474074170578, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13163636712133947, 0.13163636712133964, 0.24654882304657658], 
reward next is 0.7535, 
noisyNet noise sample is [array([0.65100974], dtype=float32), -0.33843046]. 
=============================================
[2019-03-26 23:33:58,785] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3386938e-23 1.0000000e+00 1.4211954e-21 1.7528860e-16 2.1899169e-29], sum to 1.0000
[2019-03-26 23:33:58,794] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0646
[2019-03-26 23:33:58,802] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 93.83333333333334, 1.0, 2.0, 0.3206230442502246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 506670.1759969085, 506670.1759969085, 167521.2245619837], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1363800.0000, 
sim time next is 1364400.0000, 
raw observation next is [21.1, 94.0, 1.0, 2.0, 0.3215548565950076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 507499.2158023393, 507499.2158023393, 167571.6449226296], 
processed observation next is [1.0, 0.8260869565217391, 0.1990521327014219, 0.94, 1.0, 1.0, 0.18259621276506938, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1409720043895387, 0.1409720043895387, 0.2501069327203427], 
reward next is 0.7499, 
noisyNet noise sample is [array([-0.93588257], dtype=float32), 2.1169872]. 
=============================================
[2019-03-26 23:34:13,206] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0272807e-23 1.0000000e+00 3.6709608e-22 6.3443472e-16 6.2842564e-29], sum to 1.0000
[2019-03-26 23:34:13,217] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5589
[2019-03-26 23:34:13,225] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.46666666666667, 88.66666666666666, 1.0, 2.0, 0.3459292872044848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 535871.303702833, 535871.3037028336, 169564.7609892271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1212000.0000, 
sim time next is 1212600.0000, 
raw observation next is [22.43333333333333, 88.83333333333334, 1.0, 2.0, 0.3455641444637538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 535479.6854406107, 535479.6854406114, 169537.7444667488], 
processed observation next is [1.0, 0.0, 0.2622432859399683, 0.8883333333333334, 1.0, 1.0, 0.21152306561898046, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1487443570668363, 0.1487443570668365, 0.25304140965186384], 
reward next is 0.7470, 
noisyNet noise sample is [array([-0.1133338], dtype=float32), 1.3115487]. 
=============================================
[2019-03-26 23:34:13,605] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.43782244e-22 1.00000000e+00 1.49516175e-20 1.39437945e-14
 6.18529735e-28], sum to 1.0000
[2019-03-26 23:34:13,613] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5243
[2019-03-26 23:34:13,624] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 60.66666666666667, 1.0, 2.0, 0.9738410104176051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1474473.84463667, 1474473.844636671, 307746.788348244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1174200.0000, 
sim time next is 1174800.0000, 
raw observation next is [27.6, 60.33333333333334, 1.0, 2.0, 0.9746844197968386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1478238.822412414, 1478238.822412414, 308355.7544564822], 
processed observation next is [1.0, 0.6086956521739131, 0.5071090047393366, 0.6033333333333334, 1.0, 1.0, 0.9694993009600466, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.41062189511455943, 0.41062189511455943, 0.46023246933803313], 
reward next is 0.5398, 
noisyNet noise sample is [array([-1.0678729], dtype=float32), -0.44698063]. 
=============================================
[2019-03-26 23:34:14,408] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7022652e-22 1.0000000e+00 6.4800578e-21 4.7666584e-15 2.2253803e-28], sum to 1.0000
[2019-03-26 23:34:14,418] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6573
[2019-03-26 23:34:14,426] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 57.83333333333334, 1.0, 2.0, 0.8785985113006702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1350195.598470133, 1350195.598470133, 280907.5849148553], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1181400.0000, 
sim time next is 1182000.0000, 
raw observation next is [27.6, 57.66666666666667, 1.0, 2.0, 0.8817825880218564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1356244.2926832, 1356244.2926832, 281994.2797926581], 
processed observation next is [1.0, 0.6956521739130435, 0.5071090047393366, 0.5766666666666667, 1.0, 1.0, 0.8575693831588631, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.37673452574533334, 0.37673452574533334, 0.42088698476516134], 
reward next is 0.5791, 
noisyNet noise sample is [array([1.4472058], dtype=float32), 0.56686145]. 
=============================================
[2019-03-26 23:34:14,442] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[71.80267 ]
 [71.549866]
 [71.36703 ]
 [71.180626]
 [70.98029 ]], R is [[71.92152405]
 [71.78304291]
 [71.62400055]
 [71.47285461]
 [71.32067108]].
[2019-03-26 23:34:15,916] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.9137011e-23 1.0000000e+00 1.3563677e-21 5.0036703e-16 1.7981985e-28], sum to 1.0000
[2019-03-26 23:34:15,927] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0733
[2019-03-26 23:34:15,932] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.53333333333333, 88.33333333333334, 1.0, 2.0, 0.3474276772837944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 537843.0262861188, 537843.0262861188, 169715.7440230381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1210800.0000, 
sim time next is 1211400.0000, 
raw observation next is [22.5, 88.5, 1.0, 2.0, 0.3466011648988677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 536737.8478110825, 536737.8478110818, 169630.4587974352], 
processed observation next is [1.0, 0.0, 0.2654028436018958, 0.885, 1.0, 1.0, 0.2127724878299611, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1490938466141896, 0.1490938466141894, 0.25317978924990325], 
reward next is 0.7468, 
noisyNet noise sample is [array([-1.1406555], dtype=float32), 0.20325418]. 
=============================================
[2019-03-26 23:34:16,443] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2296664e-23 1.0000000e+00 1.0870652e-21 7.6582591e-17 9.2687708e-29], sum to 1.0000
[2019-03-26 23:34:16,453] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9878
[2019-03-26 23:34:16,458] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.73333333333333, 82.66666666666667, 1.0, 2.0, 0.7353700167537872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1090409.627690335, 1090409.627690334, 236977.5782757195], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1239600.0000, 
sim time next is 1240200.0000, 
raw observation next is [24.95, 82.0, 1.0, 2.0, 0.8591566237255565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1268366.061671476, 1268366.061671476, 268510.3462463649], 
processed observation next is [1.0, 0.34782608695652173, 0.3815165876777251, 0.82, 1.0, 1.0, 0.8303091852115138, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.35232390601985447, 0.35232390601985447, 0.40076171081546996], 
reward next is 0.5992, 
noisyNet noise sample is [array([-0.59081507], dtype=float32), 0.027674899]. 
=============================================
[2019-03-26 23:34:27,435] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 23:34:27,437] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 23:34:27,437] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 23:34:27,438] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:34:27,439] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 23:34:27,438] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 23:34:27,440] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:34:27,441] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 23:34:27,442] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:34:27,443] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:34:27,445] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:34:27,473] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run96
[2019-03-26 23:34:27,474] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run96
[2019-03-26 23:34:27,525] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run96
[2019-03-26 23:34:27,526] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run96
[2019-03-26 23:34:27,526] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run96
[2019-03-26 23:34:30,533] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09091076], dtype=float32), 0.077445626]
[2019-03-26 23:34:30,535] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.93333333333333, 49.66666666666667, 1.0, 2.0, 0.2489152953403828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 411294.8574549766, 411294.8574549766, 160733.0591127872]
[2019-03-26 23:34:30,536] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 23:34:30,539] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.6754872e-24 1.0000000e+00 1.0515192e-22 1.0494141e-17 2.3816343e-29], sampled 0.4160132713157113
[2019-03-26 23:34:32,342] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09091076], dtype=float32), 0.077445626]
[2019-03-26 23:34:32,343] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.43333333333333, 76.83333333333334, 1.0, 2.0, 0.3138066617509504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 494246.5703175248, 494246.5703175254, 166552.6161048481]
[2019-03-26 23:34:32,344] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:34:32,346] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.7555939e-24 1.0000000e+00 3.7180444e-23 6.9584615e-19 8.0005763e-30], sampled 0.4897530556406492
[2019-03-26 23:35:03,345] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09091076], dtype=float32), 0.077445626]
[2019-03-26 23:35:03,347] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.1, 80.5, 1.0, 2.0, 0.4369424381393265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 645880.960456427, 645880.960456427, 178772.0647673996]
[2019-03-26 23:35:03,350] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:35:03,353] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1421881e-23 1.0000000e+00 9.9045974e-23 2.8959548e-18 1.8742216e-29], sampled 0.2588288540225805
[2019-03-26 23:35:25,271] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09091076], dtype=float32), 0.077445626]
[2019-03-26 23:35:25,273] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.58042166833334, 82.47272778166668, 1.0, 2.0, 0.5347401339531687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 747233.3297509454, 747233.3297509454, 189214.9597502749]
[2019-03-26 23:35:25,273] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:35:25,276] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.6230731e-24 1.0000000e+00 1.0444114e-22 8.0939497e-17 1.6423508e-29], sampled 0.5568637582047619
[2019-03-26 23:35:26,132] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09091076], dtype=float32), 0.077445626]
[2019-03-26 23:35:26,133] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.06287019666667, 88.14133631, 1.0, 2.0, 0.5432454399148835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 759122.6918651568, 759122.6918651568, 190645.9655998074]
[2019-03-26 23:35:26,135] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:35:26,139] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.7643235e-24 1.0000000e+00 3.4571628e-22 6.4370849e-15 2.6246980e-30], sampled 0.8722882789783272
[2019-03-26 23:35:46,139] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09091076], dtype=float32), 0.077445626]
[2019-03-26 23:35:46,140] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.7266155, 78.06960807666667, 1.0, 2.0, 0.5146348961772783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 719129.2317388775, 719129.2317388768, 185920.1341255768]
[2019-03-26 23:35:46,141] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:35:46,143] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.07382271e-25 1.00000000e+00 1.04458216e-23 6.31688262e-18
 1.11048556e-30], sampled 0.1959370831283913
[2019-03-26 23:36:16,777] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09091076], dtype=float32), 0.077445626]
[2019-03-26 23:36:16,778] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.17078584333333, 93.04944754333333, 1.0, 2.0, 0.5910381032830455, 0.0, 2.0, 0.0, 1.0, 2.0, 1.026437726115101, 6.911200000000001, 6.9112, 168.9129067517354, 1652509.513076481, 1652509.513076481, 361992.1930392255]
[2019-03-26 23:36:16,780] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:36:16,784] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.4631627e-15 9.9999976e-01 1.4115135e-13 2.1888781e-07 1.5243499e-18], sampled 0.5890823178751556
[2019-03-26 23:36:17,371] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8010.5374 3005630533.7110 1712.0000
[2019-03-26 23:36:17,791] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.4744 2779340845.4595 932.0000
[2019-03-26 23:36:17,856] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7901.6239 3162901698.9018 1705.0000
[2019-03-26 23:36:17,886] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8498.8748 2841848650.6568 1115.0000
[2019-03-26 23:36:17,892] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8257.3430 2927348084.7988 1327.0000
[2019-03-26 23:36:18,909] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2375000, evaluation results [2375000.0, 7901.623866187894, 3162901698.901802, 1705.0, 8257.343029539408, 2927348084.798773, 1327.0, 8660.474399313072, 2779340845.4594517, 932.0, 8010.5373987072535, 3005630533.7109976, 1712.0, 8498.874835374763, 2841848650.656794, 1115.0]
[2019-03-26 23:36:22,751] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.1081535e-25 1.0000000e+00 1.0225827e-22 1.9301743e-18 8.9360531e-30], sum to 1.0000
[2019-03-26 23:36:22,762] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5849
[2019-03-26 23:36:22,771] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.4, 96.0, 1.0, 2.0, 0.3378606917707816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 525551.4582235864, 525551.4582235857, 168795.3772389832], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1476000.0000, 
sim time next is 1476600.0000, 
raw observation next is [21.33333333333333, 96.16666666666666, 1.0, 2.0, 0.3359527023222311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 523185.4357217235, 523185.4357217235, 168624.0252234735], 
processed observation next is [0.0, 0.08695652173913043, 0.21011058451816728, 0.9616666666666666, 1.0, 1.0, 0.19994301484606158, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14532928770047873, 0.14532928770047873, 0.2516776495872739], 
reward next is 0.7483, 
noisyNet noise sample is [array([-0.10336542], dtype=float32), 1.0538536]. 
=============================================
[2019-03-26 23:36:40,476] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.3165085e-22 1.0000000e+00 2.4591690e-20 3.3700199e-14 4.1187113e-27], sum to 1.0000
[2019-03-26 23:36:40,483] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2018
[2019-03-26 23:36:40,489] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 93.33333333333334, 1.0, 2.0, 0.5371679581402501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 851030.6025076078, 851030.6025076078, 201084.4899458381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1784400.0000, 
sim time next is 1785000.0000, 
raw observation next is [21.0, 93.66666666666667, 1.0, 2.0, 0.5309232420199458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 840383.3991394218, 840383.3991394218, 199840.6788662375], 
processed observation next is [1.0, 0.6521739130434783, 0.19431279620853087, 0.9366666666666668, 1.0, 1.0, 0.43484727954210334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23343983309428382, 0.23343983309428382, 0.2982696699496082], 
reward next is 0.7017, 
noisyNet noise sample is [array([0.22568464], dtype=float32), -0.3453242]. 
=============================================
[2019-03-26 23:36:40,502] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.9876  ]
 [70.891975]
 [70.785614]
 [70.68055 ]
 [70.63047 ]], R is [[71.05982208]
 [71.04910278]
 [71.02851868]
 [71.00952911]
 [70.97662354]].
[2019-03-26 23:36:43,794] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.8232264e-23 1.0000000e+00 2.1275261e-21 4.0542431e-17 1.6378719e-28], sum to 1.0000
[2019-03-26 23:36:43,803] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6334
[2019-03-26 23:36:43,808] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.91666666666667, 97.5, 1.0, 2.0, 0.3832576915613302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 584746.9237708475, 584746.9237708475, 173507.6793236924], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1833000.0000, 
sim time next is 1833600.0000, 
raw observation next is [22.03333333333333, 97.0, 1.0, 2.0, 0.3606247084474044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 549235.8589680403, 549235.8589680396, 170393.7417863672], 
processed observation next is [1.0, 0.21739130434782608, 0.2432859399684044, 0.97, 1.0, 1.0, 0.22966832343060772, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1525655163800112, 0.152565516380011, 0.2543190175915928], 
reward next is 0.7457, 
noisyNet noise sample is [array([-0.5154728], dtype=float32), 0.24546349]. 
=============================================
[2019-03-26 23:36:53,339] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.7496888e-22 1.0000000e+00 1.3243065e-20 3.5802910e-15 9.3099215e-27], sum to 1.0000
[2019-03-26 23:36:53,346] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3011
[2019-03-26 23:36:53,350] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 97.0, 1.0, 2.0, 0.558473430911198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780409.8657194518, 780409.8657194518, 193259.4443489104], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2178000.0000, 
sim time next is 2178600.0000, 
raw observation next is [24.71666666666667, 96.16666666666667, 1.0, 2.0, 0.5331504626619314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 745011.1813455194, 745011.1813455194, 188950.06243114], 
processed observation next is [1.0, 0.21739130434782608, 0.3704581358609796, 0.9616666666666667, 1.0, 1.0, 0.43753067790594147, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2069475503737554, 0.2069475503737554, 0.2820150185539403], 
reward next is 0.7180, 
noisyNet noise sample is [array([-1.7299474], dtype=float32), -1.5984548]. 
=============================================
[2019-03-26 23:36:54,855] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.4268236e-23 1.0000000e+00 5.5478878e-22 1.3322077e-17 1.3038691e-28], sum to 1.0000
[2019-03-26 23:36:54,865] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0722
[2019-03-26 23:36:54,871] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 97.0, 1.0, 2.0, 0.4695583185565638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 658112.1932833813, 658112.1932833806, 179221.2954939674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2007000.0000, 
sim time next is 2007600.0000, 
raw observation next is [24.3, 96.66666666666667, 1.0, 2.0, 0.4723316300925153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 660230.6871954617, 660230.6871954617, 179404.5169101899], 
processed observation next is [0.0, 0.21739130434782608, 0.3507109004739337, 0.9666666666666667, 1.0, 1.0, 0.36425497601507867, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18339741310985047, 0.18339741310985047, 0.2677679356868506], 
reward next is 0.7322, 
noisyNet noise sample is [array([0.3548488], dtype=float32), -0.36550716]. 
=============================================
[2019-03-26 23:36:56,734] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0090105e-24 1.0000000e+00 1.0820998e-22 2.3561195e-18 1.2673107e-29], sum to 1.0000
[2019-03-26 23:36:56,745] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0949
[2019-03-26 23:36:56,750] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.05, 96.5, 1.0, 2.0, 0.4581625852114105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 647824.8115850058, 647824.8115850058, 178285.9516952029], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2086200.0000, 
sim time next is 2086800.0000, 
raw observation next is [24.03333333333333, 96.66666666666666, 1.0, 2.0, 0.4587731826357281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 648564.1280802464, 648564.128080247, 178359.3039740096], 
processed observation next is [0.0, 0.13043478260869565, 0.3380726698262243, 0.9666666666666666, 1.0, 1.0, 0.3479194971514796, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18015670224451288, 0.18015670224451305, 0.26620791637911884], 
reward next is 0.7338, 
noisyNet noise sample is [array([2.6321936], dtype=float32), -0.21062428]. 
=============================================
[2019-03-26 23:37:01,548] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.3080502e-22 1.0000000e+00 3.0365279e-21 3.7889319e-16 3.6212820e-28], sum to 1.0000
[2019-03-26 23:37:01,558] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6149
[2019-03-26 23:37:01,564] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3452222761097398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 531806.5372556637, 531806.537255663, 169147.2347606855], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2878200.0000, 
sim time next is 2878800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.349769538257583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 538812.3884591636, 538812.3884591636, 169719.0486665015], 
processed observation next is [1.0, 0.30434782608695654, 0.2417061611374408, 0.94, 1.0, 1.0, 0.21658980512961806, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14967010790532323, 0.14967010790532323, 0.2533120129350769], 
reward next is 0.7467, 
noisyNet noise sample is [array([0.06357101], dtype=float32), -0.1735297]. 
=============================================
[2019-03-26 23:37:02,222] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9357735e-23 1.0000000e+00 2.4840480e-22 5.6378275e-17 2.1199832e-29], sum to 1.0000
[2019-03-26 23:37:02,231] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3299
[2019-03-26 23:37:02,235] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.1, 76.66666666666667, 1.0, 2.0, 0.5696814698117408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 796077.8302688397, 796077.8302688404, 195234.1858322718], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2125200.0000, 
sim time next is 2125800.0000, 
raw observation next is [30.15, 76.5, 1.0, 2.0, 0.5709930509376296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 797911.3335308209, 797911.3335308209, 195466.9819729782], 
processed observation next is [0.0, 0.6086956521739131, 0.6279620853080569, 0.765, 1.0, 1.0, 0.4831241577561803, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2216420370918947, 0.2216420370918947, 0.2917417641387734], 
reward next is 0.7083, 
noisyNet noise sample is [array([1.4879446], dtype=float32), 0.14572488]. 
=============================================
[2019-03-26 23:37:02,790] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.28127530e-23 1.00000000e+00 3.34746246e-22 1.10866495e-16
 3.85323001e-29], sum to 1.0000
[2019-03-26 23:37:02,800] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4049
[2019-03-26 23:37:02,807] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.61666666666667, 73.66666666666667, 1.0, 2.0, 0.5722373320912588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 799650.7588290756, 799650.7588290762, 195688.1862268141], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2135400.0000, 
sim time next is 2136000.0000, 
raw observation next is [30.43333333333333, 74.33333333333334, 1.0, 2.0, 0.5707263209780628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 797538.4625146578, 797538.4625146583, 195419.3752981677], 
processed observation next is [0.0, 0.7391304347826086, 0.6413902053712479, 0.7433333333333334, 1.0, 1.0, 0.4828027963591117, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22153846180962716, 0.22153846180962733, 0.2916707094002503], 
reward next is 0.7083, 
noisyNet noise sample is [array([0.8264673], dtype=float32), -0.2184159]. 
=============================================
[2019-03-26 23:37:02,822] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[76.057655]
 [76.01976 ]
 [75.98141 ]
 [75.96832 ]
 [75.94335 ]], R is [[76.03620911]
 [75.98377991]
 [75.93215942]
 [75.88117981]
 [75.83084106]].
[2019-03-26 23:37:07,655] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.7918838e-22 1.0000000e+00 7.5968163e-22 6.4419455e-16 7.7751327e-29], sum to 1.0000
[2019-03-26 23:37:07,667] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6852
[2019-03-26 23:37:07,673] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 90.66666666666666, 1.0, 2.0, 0.3801367411656116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 574636.3834327939, 574636.3834327933, 172459.7204804295], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2846400.0000, 
sim time next is 2847000.0000, 
raw observation next is [23.0, 89.83333333333333, 1.0, 2.0, 0.3751271718381625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 569005.6995006318, 569005.6995006318, 172022.369611899], 
processed observation next is [1.0, 0.9565217391304348, 0.28909952606635075, 0.8983333333333333, 1.0, 1.0, 0.24714117088935242, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1580571387501755, 0.1580571387501755, 0.25674980539089404], 
reward next is 0.7433, 
noisyNet noise sample is [array([1.3960412], dtype=float32), -1.1557815]. 
=============================================
[2019-03-26 23:37:07,688] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[72.62962 ]
 [72.61126 ]
 [72.59008 ]
 [72.561264]
 [72.51953 ]], R is [[72.65450287]
 [72.67055511]
 [72.68595886]
 [72.70083618]
 [72.715271  ]].
[2019-03-26 23:37:07,795] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.1089251e-23 1.0000000e+00 1.1301965e-21 3.2871394e-15 1.2797431e-28], sum to 1.0000
[2019-03-26 23:37:07,806] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7950
[2019-03-26 23:37:07,814] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.71666666666667, 84.16666666666667, 1.0, 2.0, 0.5362253578679649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 749309.478857817, 749309.4788578164, 189466.5266259519], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2239800.0000, 
sim time next is 2240400.0000, 
raw observation next is [27.63333333333333, 84.33333333333334, 1.0, 2.0, 0.533385824450514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 745340.1854358703, 745340.1854358697, 188992.3759554533], 
processed observation next is [1.0, 0.9565217391304348, 0.5086887835703, 0.8433333333333334, 1.0, 1.0, 0.4378142463259204, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20703894039885287, 0.2070389403988527, 0.2820781730678407], 
reward next is 0.7179, 
noisyNet noise sample is [array([-0.3787316], dtype=float32), 1.161841]. 
=============================================
[2019-03-26 23:37:15,150] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 23:37:15,152] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 23:37:15,153] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:37:15,154] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 23:37:15,155] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 23:37:15,156] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:37:15,157] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 23:37:15,160] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 23:37:15,161] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:37:15,157] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:37:15,162] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:37:15,193] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run97
[2019-03-26 23:37:15,217] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run97
[2019-03-26 23:37:15,255] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run97
[2019-03-26 23:37:15,280] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run97
[2019-03-26 23:37:15,305] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run97
[2019-03-26 23:37:29,823] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09003999], dtype=float32), 0.07605567]
[2019-03-26 23:37:29,824] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.15808493, 93.54274582666667, 1.0, 2.0, 0.374854992695384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 563927.4398124989, 563927.4398124989, 171432.1741641879]
[2019-03-26 23:37:29,829] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:37:29,834] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.0222967e-23 1.0000000e+00 4.6599536e-22 3.3954163e-17 1.5386089e-28], sampled 0.16083875768453426
[2019-03-26 23:38:28,877] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09003999], dtype=float32), 0.07605567]
[2019-03-26 23:38:28,880] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.82201118166667, 85.57382828166668, 1.0, 2.0, 0.5188942955621453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 725083.1692672656, 725083.169267265, 186608.9107372342]
[2019-03-26 23:38:28,881] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:38:28,883] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.0372429e-23 1.0000000e+00 3.3049314e-22 2.5474281e-17 7.7436389e-29], sampled 0.6447491651886825
[2019-03-26 23:38:39,241] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09003999], dtype=float32), 0.07605567]
[2019-03-26 23:38:39,243] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [34.43249249500001, 49.98437270166667, 1.0, 2.0, 0.5862243858436813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 819203.9594341287, 819203.9594341281, 198204.2399144103]
[2019-03-26 23:38:39,244] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:38:39,246] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.2952811e-23 1.0000000e+00 1.8398995e-22 1.1110358e-16 4.6980446e-29], sampled 0.6638153617047393
[2019-03-26 23:38:53,266] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09003999], dtype=float32), 0.07605567]
[2019-03-26 23:38:53,268] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.5, 85.0, 1.0, 2.0, 0.5118677268215588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 715261.2034522272, 715261.2034522272, 185475.4920738704]
[2019-03-26 23:38:53,270] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 23:38:53,274] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.0056056e-24 1.0000000e+00 1.0420157e-22 8.1432543e-17 1.8008405e-29], sampled 0.7188462314659989
[2019-03-26 23:39:06,711] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09003999], dtype=float32), 0.07605567]
[2019-03-26 23:39:06,712] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [34.01682688, 63.45662046, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.301529099611711, 6.9112, 168.9110644703816, 1730854.376410947, 1453944.580832392, 311357.3196561759]
[2019-03-26 23:39:06,715] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:39:06,719] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.8418601e-22 1.0000000e+00 1.0075984e-20 1.1534813e-14 2.5585954e-27], sampled 0.06098172459275064
[2019-03-26 23:39:06,720] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1730854.376410947 W.
[2019-03-26 23:39:09,838] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8662.3360 2778930238.3581 927.0000
[2019-03-26 23:39:09,850] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8515.7675 2839781468.7245 1072.0000
[2019-03-26 23:39:10,125] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8261.0801 2926230087.0899 1307.0000
[2019-03-26 23:39:10,145] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7928.3684 3159077000.5918 1602.0000
[2019-03-26 23:39:10,149] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8033.5019 3001472618.6104 1619.0000
[2019-03-26 23:39:11,167] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2400000, evaluation results [2400000.0, 7928.368410997644, 3159077000.591757, 1602.0, 8261.080113117741, 2926230087.0898924, 1307.0, 8662.33595176639, 2778930238.358101, 927.0, 8033.501908887711, 3001472618.6103725, 1619.0, 8515.76749642214, 2839781468.7244725, 1072.0]
[2019-03-26 23:39:15,116] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.3449892e-23 1.0000000e+00 3.1251574e-22 5.7498764e-18 2.9202665e-29], sum to 1.0000
[2019-03-26 23:39:15,130] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2956
[2019-03-26 23:39:15,138] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 83.16666666666666, 1.0, 2.0, 0.499595863403963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 698107.4123252076, 698107.4123252076, 183533.1453478362], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2638200.0000, 
sim time next is 2638800.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5036098937985236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 703718.2525470251, 703718.2525470251, 184164.0102108445], 
processed observation next is [0.0, 0.5652173913043478, 0.4786729857819906, 0.84, 1.0, 1.0, 0.40193963108255854, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19547729237417363, 0.19547729237417363, 0.2748716570311112], 
reward next is 0.7251, 
noisyNet noise sample is [array([-0.5327188], dtype=float32), -2.5381684]. 
=============================================
[2019-03-26 23:39:15,555] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.77930742e-22 1.00000000e+00 1.22684537e-20 4.99267674e-13
 1.52418635e-27], sum to 1.0000
[2019-03-26 23:39:15,563] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8048
[2019-03-26 23:39:15,571] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.4913679868666576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 686606.5206404879, 686606.5206404879, 182254.3936055178], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3182400.0000, 
sim time next is 3183000.0000, 
raw observation next is [25.0, 94.00000000000001, 1.0, 2.0, 0.4893401349047127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 683772.0167078648, 683772.0167078648, 181942.5830266677], 
processed observation next is [1.0, 0.8695652173913043, 0.38388625592417064, 0.9400000000000002, 1.0, 1.0, 0.38474715048760566, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18993667130774022, 0.18993667130774022, 0.2715560940696533], 
reward next is 0.7284, 
noisyNet noise sample is [array([1.0230309], dtype=float32), -0.22310364]. 
=============================================
[2019-03-26 23:39:15,586] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[72.06452 ]
 [71.98128 ]
 [72.229225]
 [72.54134 ]
 [72.491425]], R is [[71.93965912]
 [71.94824219]
 [71.95658875]
 [71.96498871]
 [71.97306061]].
[2019-03-26 23:39:16,942] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3488838e-15 2.1004826e-01 6.3475258e-12 7.8995174e-01 4.2301901e-18], sum to 1.0000
[2019-03-26 23:39:16,953] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2714
[2019-03-26 23:39:16,958] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.86666666666667, 71.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.356518861651758, 6.9112, 168.9104130336046, 2612277.430637699, 2296357.660654035, 475735.3167214724], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2560800.0000, 
sim time next is 2561400.0000, 
raw observation next is [29.8, 71.5, 1.0, 2.0, 0.866774112651927, 1.0, 1.0, 0.866774112651927, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2424271.894456149, 2424271.894456149, 453683.734941226], 
processed observation next is [1.0, 0.6521739130434783, 0.6113744075829385, 0.715, 1.0, 1.0, 0.8394868827131651, 1.0, 0.5, 0.8394868827131651, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6734088595711525, 0.6734088595711525, 0.6771399028973523], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.06352016], dtype=float32), 0.5091856]. 
=============================================
[2019-03-26 23:39:24,752] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4592273e-22 1.0000000e+00 7.2119456e-22 6.5148950e-17 2.4167334e-28], sum to 1.0000
[2019-03-26 23:39:24,761] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6929
[2019-03-26 23:39:24,768] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.4875325137219749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 681245.3547433444, 681245.3547433438, 181665.7820411038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3312000.0000, 
sim time next is 3312600.0000, 
raw observation next is [28.16666666666667, 73.33333333333334, 1.0, 2.0, 0.4878208114317547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 681648.3319470783, 681648.331947079, 181710.0035530568], 
processed observation next is [0.0, 0.34782608695652173, 0.5339652448657191, 0.7333333333333334, 1.0, 1.0, 0.3829166402792225, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18934675887418842, 0.18934675887418861, 0.2712089605269504], 
reward next is 0.7288, 
noisyNet noise sample is [array([1.2479517], dtype=float32), -0.4048748]. 
=============================================
[2019-03-26 23:39:38,692] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.9089417e-21 9.9999964e-01 6.9002042e-18 3.8576252e-07 2.9013380e-26], sum to 1.0000
[2019-03-26 23:39:38,708] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8737
[2019-03-26 23:39:38,712] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.5296032489674175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 740052.6665533786, 740052.6665533786, 188367.214608155], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3433200.0000, 
sim time next is 3433800.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.5342107793664643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 746493.362137565, 746493.3621375657, 189132.3836543553], 
processed observation next is [1.0, 0.7391304347826086, 0.6682464454976303, 0.7, 1.0, 1.0, 0.43880816791140276, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20735926726043474, 0.20735926726043494, 0.2822871397826199], 
reward next is 0.7177, 
noisyNet noise sample is [array([-1.3049872], dtype=float32), -1.3620895]. 
=============================================
[2019-03-26 23:39:53,066] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.2514949e-23 1.0000000e+00 1.0366361e-21 4.1000194e-15 3.2248674e-28], sum to 1.0000
[2019-03-26 23:39:53,078] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4765
[2019-03-26 23:39:53,087] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5210283407119982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 728066.2248126034, 728066.2248126034, 186956.1836537216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3802800.0000, 
sim time next is 3803400.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5200806170125459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 726741.4568506749, 726741.4568506742, 186801.982092354], 
processed observation next is [0.0, 0.0, 0.5260663507109005, 0.79, 1.0, 1.0, 0.42178387591873, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20187262690296526, 0.20187262690296506, 0.27880892849605077], 
reward next is 0.7212, 
noisyNet noise sample is [array([0.1615879], dtype=float32), 1.8942653]. 
=============================================
[2019-03-26 23:40:04,597] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6505583e-23 1.0000000e+00 7.6403192e-23 1.5430965e-17 1.6527080e-29], sum to 1.0000
[2019-03-26 23:40:04,607] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0870
[2019-03-26 23:40:04,613] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.66666666666667, 63.0, 1.0, 2.0, 0.5639949699404903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 788128.5179131179, 788128.5179131179, 194231.0397517385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3246000.0000, 
sim time next is 3246600.0000, 
raw observation next is [32.83333333333333, 63.0, 1.0, 2.0, 0.5693407449678668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 795601.5200955024, 795601.5200955024, 195174.2476920109], 
processed observation next is [0.0, 0.5652173913043478, 0.7551342812006318, 0.63, 1.0, 1.0, 0.48113342767212863, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22100042224875066, 0.22100042224875066, 0.2913048473015088], 
reward next is 0.7087, 
noisyNet noise sample is [array([0.4372943], dtype=float32), -0.39737925]. 
=============================================
[2019-03-26 23:40:05,701] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.6184417e-24 1.0000000e+00 2.7123590e-21 2.5164656e-15 1.8640904e-28], sum to 1.0000
[2019-03-26 23:40:05,711] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2993
[2019-03-26 23:40:05,717] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5115172011573851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 714771.2296816761, 714771.2296816761, 185420.167520429], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3449400.0000, 
sim time next is 3450000.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5126816872501607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 716398.979103515, 716398.979103515, 185606.722174719], 
processed observation next is [1.0, 0.9565217391304348, 0.4786729857819906, 0.84, 1.0, 1.0, 0.412869502711037, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19899971641764308, 0.19899971641764308, 0.27702495846972985], 
reward next is 0.7230, 
noisyNet noise sample is [array([-0.31338158], dtype=float32), 0.5055889]. 
=============================================
[2019-03-26 23:40:05,734] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[73.28112]
 [73.39011]
 [73.58019]
 [73.4213 ]
 [73.25941]], R is [[73.12065125]
 [73.11269379]
 [73.10486603]
 [73.09658813]
 [73.08779907]].
[2019-03-26 23:40:07,347] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 23:40:07,349] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 23:40:07,349] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:40:07,351] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 23:40:07,352] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 23:40:07,353] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:40:07,355] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 23:40:07,356] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:40:07,357] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:40:07,354] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 23:40:07,358] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:40:07,387] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run98
[2019-03-26 23:40:07,418] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run98
[2019-03-26 23:40:07,445] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run98
[2019-03-26 23:40:07,446] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run98
[2019-03-26 23:40:07,470] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run98
[2019-03-26 23:40:16,539] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09123069], dtype=float32), 0.0764525]
[2019-03-26 23:40:16,541] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [20.83333333333334, 70.66666666666667, 1.0, 2.0, 0.2249555656532257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 373593.1618074473, 373593.1618074473, 158280.3728358238]
[2019-03-26 23:40:16,542] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 23:40:16,544] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.1931460e-23 1.0000000e+00 5.2265112e-22 3.5322622e-18 2.1116305e-28], sampled 0.06967114734343449
[2019-03-26 23:40:28,319] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09123069], dtype=float32), 0.0764525]
[2019-03-26 23:40:28,321] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.92620872333334, 91.68208466666667, 1.0, 2.0, 0.3479182777762119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 541936.3607375318, 541936.3607375324, 170135.4658926834]
[2019-03-26 23:40:28,321] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:40:28,325] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.6886746e-24 1.0000000e+00 8.8459353e-23 8.9123798e-18 1.8309589e-29], sampled 0.4800796730156631
[2019-03-26 23:40:47,658] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09123069], dtype=float32), 0.0764525]
[2019-03-26 23:40:47,659] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.22023783, 89.09638067, 1.0, 2.0, 0.5193032801335682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 725654.8639706591, 725654.8639706585, 186677.6533625675]
[2019-03-26 23:40:47,661] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:40:47,664] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.5049336e-23 1.0000000e+00 2.1539507e-22 5.8449256e-18 5.1613671e-29], sampled 0.6125132923177578
[2019-03-26 23:41:09,249] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09123069], dtype=float32), 0.0764525]
[2019-03-26 23:41:09,250] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [36.5, 51.5, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.56655010492025, 6.9112, 170.5573041426782, 3379330.520376191, 2909876.58228395, 550040.7445247141]
[2019-03-26 23:41:09,251] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:41:09,256] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0737466e-17 5.1996625e-07 3.7815698e-14 9.9999952e-01 1.0037276e-19], sampled 0.34953168704681126
[2019-03-26 23:41:09,258] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 0, 0, 1, 0] has been changed to [0, 0, 0, 0, 1] for the demand 3379330.520376191 W.
[2019-03-26 23:41:21,245] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09123069], dtype=float32), 0.0764525]
[2019-03-26 23:41:21,246] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.34655860666667, 66.05724431666667, 1.0, 2.0, 0.5328998266934872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 744660.8261203379, 744660.8261203374, 188910.5530667763]
[2019-03-26 23:41:21,246] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:41:21,249] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.8181134e-23 1.0000000e+00 2.4031349e-22 2.5905171e-17 6.9018005e-29], sampled 0.07651288352807639
[2019-03-26 23:41:21,372] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09123069], dtype=float32), 0.0764525]
[2019-03-26 23:41:21,374] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.07388347333333, 65.10918772333333, 1.0, 2.0, 0.5058125098738493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 706797.0975488012, 706797.0975488012, 184511.8399282613]
[2019-03-26 23:41:21,375] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:41:21,377] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.8977892e-23 1.0000000e+00 2.0566082e-22 4.0085080e-17 5.9795304e-29], sampled 0.06513577425247108
[2019-03-26 23:41:31,283] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09123069], dtype=float32), 0.0764525]
[2019-03-26 23:41:31,284] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.25, 93.0, 1.0, 2.0, 0.6121332042753821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 855424.1409120486, 855424.1409120486, 203027.6285493631]
[2019-03-26 23:41:31,286] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 23:41:31,288] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.2648813e-23 1.0000000e+00 3.2694198e-22 3.6119205e-17 6.3474763e-29], sampled 0.4524488505152189
[2019-03-26 23:41:54,684] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09123069], dtype=float32), 0.0764525]
[2019-03-26 23:41:54,685] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.3, 88.33333333333333, 1.0, 2.0, 0.6825302177955817, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.00597447308643, 6.9112, 168.9118167401938, 1850682.674148045, 1783446.854743626, 380898.2557627829]
[2019-03-26 23:41:54,686] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 23:41:54,690] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.7457485e-19 9.9999952e-01 1.9970296e-16 4.7681939e-07 2.0204626e-23], sampled 0.814675849034722
[2019-03-26 23:41:54,691] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1850682.674148045 W.
[2019-03-26 23:42:00,448] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09123069], dtype=float32), 0.0764525]
[2019-03-26 23:42:00,451] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.93333333333333, 63.33333333333334, 1.0, 2.0, 0.3454334000685582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 539311.4723025097, 539311.4723025103, 169950.2119440523]
[2019-03-26 23:42:00,452] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:42:00,455] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.14716595e-23 1.00000000e+00 1.64456332e-22 4.45174676e-17
 3.94445649e-29], sampled 0.41734412799856957
[2019-03-26 23:42:02,015] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8663.9007 2778947070.2066 924.0000
[2019-03-26 23:42:02,306] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7940.4727 3157559201.9871 1581.0000
[2019-03-26 23:42:02,350] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8515.7108 2839760930.9501 1065.0000
[2019-03-26 23:42:02,507] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8042.9760 3001147855.9426 1602.0000
[2019-03-26 23:42:02,550] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8267.6965 2925973020.8582 1300.0000
[2019-03-26 23:42:03,567] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2425000, evaluation results [2425000.0, 7940.472696888252, 3157559201.9870505, 1581.0, 8267.696500570646, 2925973020.858217, 1300.0, 8663.900726633772, 2778947070.206619, 924.0, 8042.975987847864, 3001147855.942567, 1602.0, 8515.71075732594, 2839760930.950061, 1065.0]
[2019-03-26 23:42:03,934] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5791463e-21 1.0000000e+00 2.3688693e-20 7.4074041e-14 4.4204179e-27], sum to 1.0000
[2019-03-26 23:42:03,947] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5749
[2019-03-26 23:42:03,956] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 83.16666666666667, 1.0, 2.0, 0.5053608650818036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 706165.7819381937, 706165.7819381937, 184440.2943835043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3633000.0000, 
sim time next is 3633600.0000, 
raw observation next is [27.0, 82.33333333333334, 1.0, 2.0, 0.5028516509297312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 702658.3730042048, 702658.3730042048, 184043.9675892136], 
processed observation next is [1.0, 0.043478260869565216, 0.4786729857819906, 0.8233333333333335, 1.0, 1.0, 0.4010260854575074, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1951828813900569, 0.1951828813900569, 0.2746924889391248], 
reward next is 0.7253, 
noisyNet noise sample is [array([0.5434715], dtype=float32), -0.6312587]. 
=============================================
[2019-03-26 23:42:04,278] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.3722614e-23 1.0000000e+00 5.4388180e-22 2.5764243e-17 1.2746274e-28], sum to 1.0000
[2019-03-26 23:42:04,288] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3759
[2019-03-26 23:42:04,296] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4792880274897444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 669721.429146401, 669721.4291464004, 180414.0429977915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3286800.0000, 
sim time next is 3287400.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4782232211128876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 668336.4610090401, 668336.4610090401, 180267.3459203605], 
processed observation next is [0.0, 0.043478260869565216, 0.4312796208530806, 0.84, 1.0, 1.0, 0.37135327844926214, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1856490169469556, 0.1856490169469556, 0.26905574017964257], 
reward next is 0.7309, 
noisyNet noise sample is [array([0.3612322], dtype=float32), 0.10064136]. 
=============================================
[2019-03-26 23:42:06,800] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5012304e-21 1.0000000e+00 3.2385523e-20 3.4194358e-14 8.9656014e-27], sum to 1.0000
[2019-03-26 23:42:06,805] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.0910390e-21 1.0000000e+00 2.8605427e-20 3.2587248e-14 5.6386807e-27], sum to 1.0000
[2019-03-26 23:42:06,811] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7643
[2019-03-26 23:42:06,815] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.00000000000001, 1.0, 2.0, 0.8375912802156392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1170663.670720548, 1170663.670720547, 253346.4939416902], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3384600.0000, 
sim time next is 3385200.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.7587179448055117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1060370.914289656, 1060370.914289656, 234029.2175515963], 
processed observation next is [1.0, 0.17391304347826086, 0.4312796208530806, 0.94, 1.0, 1.0, 0.7092987286813394, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2945474761915711, 0.2945474761915711, 0.3492973396292482], 
reward next is 0.6507, 
noisyNet noise sample is [array([1.9581391], dtype=float32), 0.408318]. 
=============================================
[2019-03-26 23:42:06,815] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2548
[2019-03-26 23:42:06,823] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.7939722997936991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1109667.527557437, 1109667.527557437, 242435.3599111704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3567600.0000, 
sim time next is 3568200.0000, 
raw observation next is [28.16666666666667, 78.16666666666667, 1.0, 2.0, 0.8070051035911043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1127892.042392526, 1127892.042392526, 245636.3879014691], 
processed observation next is [1.0, 0.30434782608695654, 0.5339652448657191, 0.7816666666666667, 1.0, 1.0, 0.7674760284230172, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.313303345109035, 0.313303345109035, 0.36662147447980464], 
reward next is 0.6334, 
noisyNet noise sample is [array([-0.08990125], dtype=float32), -1.0631342]. 
=============================================
[2019-03-26 23:42:08,043] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.5760729e-21 1.0000000e+00 8.0093501e-20 2.6893329e-13 2.2158442e-26], sum to 1.0000
[2019-03-26 23:42:08,056] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6189
[2019-03-26 23:42:08,063] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 78.16666666666667, 1.0, 2.0, 0.8500554522355913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1188094.02996442, 1188094.02996442, 256566.9197807291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3481800.0000, 
sim time next is 3482400.0000, 
raw observation next is [28.0, 77.33333333333334, 1.0, 2.0, 0.855749390220978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1196056.738696544, 1196056.738696544, 258053.4722672796], 
processed observation next is [1.0, 0.30434782608695654, 0.5260663507109005, 0.7733333333333334, 1.0, 1.0, 0.8262040846035879, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3322379829712622, 0.3322379829712622, 0.3851544362198203], 
reward next is 0.6148, 
noisyNet noise sample is [array([-0.06612821], dtype=float32), -1.1111951]. 
=============================================
[2019-03-26 23:42:10,315] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5221854e-15 3.5752516e-02 2.4383904e-12 9.6424747e-01 1.7484301e-18], sum to 1.0000
[2019-03-26 23:42:10,323] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6686
[2019-03-26 23:42:10,326] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.8979972281594881, 1.0, 2.0, 0.8979972281594881, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2511687.283253718, 2511687.283253717, 470403.021752708], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3585600.0000, 
sim time next is 3586200.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.8721607826345186, 1.0, 2.0, 0.8721607826345186, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2439352.523481549, 2439352.523481549, 456534.5623808643], 
processed observation next is [1.0, 0.5217391304347826, 0.7156398104265403, 0.67, 1.0, 1.0, 0.8459768465476127, 1.0, 1.0, 0.8459768465476127, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6775979231893192, 0.6775979231893192, 0.6813948692251706], 
reward next is 0.3186, 
noisyNet noise sample is [array([0.9578336], dtype=float32), -0.77844614]. 
=============================================
[2019-03-26 23:42:19,444] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1073855e-22 1.0000000e+00 1.4761200e-20 6.9393903e-15 3.0219470e-27], sum to 1.0000
[2019-03-26 23:42:19,452] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8246
[2019-03-26 23:42:19,459] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 78.16666666666667, 1.0, 2.0, 0.5143106731378517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 718676.0227941895, 718676.0227941902, 185868.5921187371], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3543000.0000, 
sim time next is 3543600.0000, 
raw observation next is [28.0, 77.33333333333334, 1.0, 2.0, 0.5112727953489912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 714429.59310311, 714429.5931031107, 185380.9944871597], 
processed observation next is [1.0, 0.0, 0.5260663507109005, 0.7733333333333334, 1.0, 1.0, 0.41117204258914597, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19845266475086387, 0.19845266475086407, 0.2766880514733727], 
reward next is 0.7233, 
noisyNet noise sample is [array([1.0656055], dtype=float32), -0.0057939757]. 
=============================================
[2019-03-26 23:42:21,099] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.41490490e-22 1.00000000e+00 1.27997775e-20 4.74684336e-15
 4.47573331e-27], sum to 1.0000
[2019-03-26 23:42:21,107] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0958
[2019-03-26 23:42:21,112] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5173818242852076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 722968.9801625565, 722968.9801625558, 186364.3259060515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3805200.0000, 
sim time next is 3805800.0000, 
raw observation next is [28.0, 79.00000000000001, 1.0, 2.0, 0.5175360039345714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 723184.498069246, 723184.4980692466, 186389.2707194568], 
processed observation next is [0.0, 0.043478260869565216, 0.5260663507109005, 0.7900000000000001, 1.0, 1.0, 0.4187180770296041, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20088458279701277, 0.20088458279701296, 0.2781929413723236], 
reward next is 0.7218, 
noisyNet noise sample is [array([-0.81714374], dtype=float32), 0.34313807]. 
=============================================
[2019-03-26 23:42:27,371] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4990924e-23 1.0000000e+00 4.8597467e-22 6.2743506e-18 9.9122023e-29], sum to 1.0000
[2019-03-26 23:42:27,381] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3215
[2019-03-26 23:42:27,386] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 85.66666666666667, 1.0, 2.0, 0.565386746059028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 790074.113987782, 790074.1139877826, 194474.783560228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3912000.0000, 
sim time next is 3912600.0000, 
raw observation next is [28.66666666666667, 84.83333333333333, 1.0, 2.0, 0.5721265898930277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 799495.9482186974, 799495.9482186969, 195668.1644147278], 
processed observation next is [0.0, 0.2608695652173913, 0.5576619273301741, 0.8483333333333333, 1.0, 1.0, 0.4844898673409972, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22208220783852706, 0.22208220783852692, 0.29204203643989224], 
reward next is 0.7080, 
noisyNet noise sample is [array([1.2817199], dtype=float32), -0.19479744]. 
=============================================
[2019-03-26 23:42:27,561] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3185012e-15 3.8381630e-01 1.7275296e-12 6.1618370e-01 1.0054270e-18], sum to 1.0000
[2019-03-26 23:42:27,569] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8224
[2019-03-26 23:42:27,574] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 63.0, 1.0, 2.0, 0.7905634226005966, 1.0, 2.0, 0.7905634226005966, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2210930.17045634, 2210930.17045634, 415310.1643916215], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3675600.0000, 
sim time next is 3676200.0000, 
raw observation next is [33.0, 62.33333333333333, 1.0, 2.0, 0.8460257950695147, 1.0, 2.0, 0.8460257950695147, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2366186.190085002, 2366186.190085002, 442905.0382627108], 
processed observation next is [1.0, 0.5652173913043478, 0.7630331753554502, 0.6233333333333333, 1.0, 1.0, 0.8144889097223068, 1.0, 1.0, 0.8144889097223068, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6572739416902784, 0.6572739416902784, 0.6610522959144938], 
reward next is 0.3389, 
noisyNet noise sample is [array([-0.44377154], dtype=float32), -0.09970423]. 
=============================================
[2019-03-26 23:42:30,435] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2281640e-23 1.0000000e+00 4.5810077e-23 1.9899279e-16 9.9183624e-30], sum to 1.0000
[2019-03-26 23:42:30,444] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1384
[2019-03-26 23:42:30,452] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666667, 74.33333333333333, 1.0, 2.0, 0.610584911719432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 853259.6139355367, 853259.6139355374, 202733.9930727872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3964200.0000, 
sim time next is 3964800.0000, 
raw observation next is [31.33333333333334, 73.66666666666667, 1.0, 2.0, 0.6046563939403528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 844971.5333202941, 844971.5333202948, 201616.6447879491], 
processed observation next is [0.0, 0.9130434782608695, 0.6840442338072673, 0.7366666666666667, 1.0, 1.0, 0.5236824023377744, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23471431481119281, 0.234714314811193, 0.30092036535514793], 
reward next is 0.6991, 
noisyNet noise sample is [array([-0.65298486], dtype=float32), 0.093902]. 
=============================================
[2019-03-26 23:42:33,024] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.3425685e-15 7.0441434e-05 5.7090123e-12 9.9992955e-01 5.3653350e-18], sum to 1.0000
[2019-03-26 23:42:33,031] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0803
[2019-03-26 23:42:33,037] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.83333333333334, 60.0, 1.0, 2.0, 0.8929775654713279, 1.0, 2.0, 0.7670788222499266, 1.0, 1.0, 1.03, 7.005112953193682, 6.9112, 170.5573041426782, 3219175.608346144, 3151901.939838818, 589213.5751886483], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3766200.0000, 
sim time next is 3766800.0000, 
raw observation next is [34.66666666666667, 60.00000000000001, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.673011144707516, 6.9112, 170.5573041426782, 3455681.742289127, 2909965.430839048, 549394.9468617527], 
processed observation next is [1.0, 0.6086956521739131, 0.8420221169036337, 0.6000000000000001, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.0761811144707516, 0.0, 0.8375144448122397, 0.959911595080313, 0.8083237307886244, 0.8199924580026159], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.40502352], dtype=float32), 0.4856376]. 
=============================================
[2019-03-26 23:42:34,741] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4079036e-23 1.0000000e+00 8.0260065e-23 1.1784935e-17 1.2271447e-28], sum to 1.0000
[2019-03-26 23:42:34,754] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9553
[2019-03-26 23:42:34,760] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.16666666666667, 66.33333333333334, 1.0, 2.0, 0.5918863171088204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 827119.1581125371, 827119.1581125365, 199243.5834757283], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3924600.0000, 
sim time next is 3925200.0000, 
raw observation next is [32.33333333333334, 65.66666666666667, 1.0, 2.0, 0.5855827289608689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 818306.9473715558, 818306.9473715564, 198090.7564418991], 
processed observation next is [0.0, 0.43478260869565216, 0.7314375987361774, 0.6566666666666667, 1.0, 1.0, 0.5007020830853842, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22730748538098774, 0.22730748538098788, 0.2956578454356703], 
reward next is 0.7043, 
noisyNet noise sample is [array([0.6697838], dtype=float32), 0.30300057]. 
=============================================
[2019-03-26 23:42:38,150] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.3246500e-22 1.0000000e+00 2.1743606e-20 7.6307714e-14 3.0235498e-27], sum to 1.0000
[2019-03-26 23:42:38,158] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2745
[2019-03-26 23:42:38,166] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.5435752090157918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 759583.6708194437, 759583.6708194437, 190705.1947949817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4050600.0000, 
sim time next is 4051200.0000, 
raw observation next is [28.0, 84.0, 1.0, 2.0, 0.5446465093164412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 761081.2257639385, 761081.2257639385, 190886.9765032092], 
processed observation next is [1.0, 0.9130434782608695, 0.5260663507109005, 0.84, 1.0, 1.0, 0.45138133652583273, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21141145160109404, 0.21141145160109404, 0.28490593507941675], 
reward next is 0.7151, 
noisyNet noise sample is [array([0.3582326], dtype=float32), 2.2363553]. 
=============================================
[2019-03-26 23:42:40,209] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8697151e-22 1.0000000e+00 6.0125115e-22 3.6382226e-17 1.7220168e-28], sum to 1.0000
[2019-03-26 23:42:40,218] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7928
[2019-03-26 23:42:40,222] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333333, 88.16666666666667, 1.0, 2.0, 0.5484333746407883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 766374.8460644378, 766374.8460644378, 191532.1340111812], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3910200.0000, 
sim time next is 3910800.0000, 
raw observation next is [27.66666666666667, 87.33333333333334, 1.0, 2.0, 0.5539799636984588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 774128.413790344, 774128.413790344, 192485.5205019995], 
processed observation next is [0.0, 0.2608695652173913, 0.5102685624012641, 0.8733333333333334, 1.0, 1.0, 0.46262646228729976, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21503567049731778, 0.21503567049731778, 0.2872918216447754], 
reward next is 0.7127, 
noisyNet noise sample is [array([1.3232828], dtype=float32), 0.25846988]. 
=============================================
[2019-03-26 23:42:40,864] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.9389512e-22 1.0000000e+00 3.5909232e-20 7.9063146e-14 2.2247108e-27], sum to 1.0000
[2019-03-26 23:42:40,873] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1324
[2019-03-26 23:42:40,887] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 86.0, 1.0, 2.0, 0.462441118112689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 656257.5409933337, 656257.5409933343, 179218.7617788287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4653600.0000, 
sim time next is 4654200.0000, 
raw observation next is [24.66666666666666, 90.0, 1.0, 2.0, 0.4572043061861639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 651777.7078058596, 651777.7078058602, 178824.3913709563], 
processed observation next is [1.0, 0.8695652173913043, 0.36808846761453373, 0.9, 1.0, 1.0, 0.3460292845616432, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18104936327940546, 0.1810493632794056, 0.2669020766730691], 
reward next is 0.7331, 
noisyNet noise sample is [array([1.2923105], dtype=float32), -0.0364246]. 
=============================================
[2019-03-26 23:42:48,065] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3156082e-22 1.0000000e+00 2.0338756e-20 3.6070832e-12 8.2585224e-27], sum to 1.0000
[2019-03-26 23:42:48,073] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8828
[2019-03-26 23:42:48,078] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 79.0, 1.0, 2.0, 0.8641396242585072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1207790.201490409, 1207790.201490408, 260265.107691575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4254600.0000, 
sim time next is 4255200.0000, 
raw observation next is [29.0, 79.0, 1.0, 2.0, 0.8512771823772495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1189802.557988619, 1189802.557988619, 256888.0568795293], 
processed observation next is [1.0, 0.2608695652173913, 0.5734597156398105, 0.79, 1.0, 1.0, 0.8208158823822282, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33050071055239416, 0.33050071055239416, 0.38341501026795416], 
reward next is 0.6166, 
noisyNet noise sample is [array([-0.07437403], dtype=float32), 0.23195124]. 
=============================================
[2019-03-26 23:42:53,414] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.2745220e-19 5.6454726e-03 2.0533310e-14 9.9435449e-01 5.9272015e-22], sum to 1.0000
[2019-03-26 23:42:53,424] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1627
[2019-03-26 23:42:53,429] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.33333333333334, 69.66666666666666, 1.0, 2.0, 0.3070657812658462, 1.0, 2.0, 0.3070657812658462, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 858214.5274797505, 858214.5274797505, 251276.3828185393], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4124400.0000, 
sim time next is 4125000.0000, 
raw observation next is [33.16666666666666, 70.33333333333334, 1.0, 2.0, 0.3080417010571517, 1.0, 2.0, 0.3080417010571517, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 860943.2090077649, 860943.2090077649, 251468.9591065016], 
processed observation next is [1.0, 0.7391304347826086, 0.7709320695102682, 0.7033333333333335, 1.0, 1.0, 0.166315302478496, 1.0, 1.0, 0.166315302478496, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.2391508913910458, 0.2391508913910458, 0.37532680463656953], 
reward next is 0.6247, 
noisyNet noise sample is [array([1.6282076], dtype=float32), -0.5069762]. 
=============================================
[2019-03-26 23:42:53,446] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[60.8995  ]
 [56.89153 ]
 [52.566814]
 [47.01485 ]
 [41.638294]], R is [[63.63243103]
 [63.62107086]
 [63.61030197]
 [63.59877014]
 [62.96278381]].
[2019-03-26 23:42:57,508] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.5241695e-22 1.0000000e+00 1.0495721e-21 1.6048725e-17 3.3366666e-28], sum to 1.0000
[2019-03-26 23:42:57,516] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2295
[2019-03-26 23:42:57,520] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5131814695597957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 717097.5887832848, 717097.5887832848, 185686.9122256765], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4521600.0000, 
sim time next is 4522200.0000, 
raw observation next is [27.16666666666666, 82.33333333333333, 1.0, 2.0, 0.5121153137839244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 715607.2869993902, 715607.2869993909, 185515.7498447493], 
processed observation next is [0.0, 0.34782608695652173, 0.4865718799368086, 0.8233333333333333, 1.0, 1.0, 0.41218712504087274, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19877980194427505, 0.19877980194427525, 0.27688917887276016], 
reward next is 0.7231, 
noisyNet noise sample is [array([-0.35846627], dtype=float32), 1.2777716]. 
=============================================
[2019-03-26 23:42:59,914] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 23:42:59,917] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 23:42:59,918] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:42:59,918] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 23:42:59,919] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:42:59,919] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 23:42:59,921] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 23:42:59,922] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 23:42:59,923] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:42:59,924] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:42:59,924] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:42:59,950] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run99
[2019-03-26 23:42:59,977] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run99
[2019-03-26 23:43:00,000] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run99
[2019-03-26 23:43:00,001] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run99
[2019-03-26 23:43:00,052] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run99
[2019-03-26 23:43:37,449] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09383491], dtype=float32), 0.074509114]
[2019-03-26 23:43:37,451] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.1, 86.33333333333334, 1.0, 2.0, 0.4661428686762633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 667614.9156463323, 667614.9156463316, 180543.9464751036]
[2019-03-26 23:43:37,453] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:43:37,456] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.3628656e-23 1.0000000e+00 7.8359621e-22 2.0679035e-16 2.5724422e-28], sampled 0.2704625216256633
[2019-03-26 23:43:59,432] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09383491], dtype=float32), 0.074509114]
[2019-03-26 23:43:59,433] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.6, 49.66666666666667, 1.0, 2.0, 0.5501805234435035, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9425022225519712, 6.911199999999999, 6.9112, 168.9126908725824, 1538191.226302037, 1538191.226302037, 334062.6247132498]
[2019-03-26 23:43:59,435] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:43:59,438] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.1812688e-16 1.0000000e+00 1.5115787e-15 6.9944783e-09 1.6603302e-20], sampled 0.35195406504576254
[2019-03-26 23:44:31,182] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09383491], dtype=float32), 0.074509114]
[2019-03-26 23:44:31,182] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [32.50837848, 63.42974886666667, 1.0, 2.0, 0.5827450966976688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 814340.0538348922, 814340.0538348922, 197574.9328675517]
[2019-03-26 23:44:31,183] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:44:31,187] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.3458395e-23 1.0000000e+00 4.1875259e-22 1.0877068e-16 1.8121707e-28], sampled 0.7376103632880239
[2019-03-26 23:44:37,008] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09383491], dtype=float32), 0.074509114]
[2019-03-26 23:44:37,009] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.14982354, 83.45859894333333, 1.0, 2.0, 0.8805937688952661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104154, 1230801.151117273, 1230801.151117273, 264651.3595690264]
[2019-03-26 23:44:37,011] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:44:37,013] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.6310892e-21 1.0000000e+00 6.7044294e-20 1.5474728e-14 5.2748922e-26], sampled 0.6364659987704796
[2019-03-26 23:44:38,554] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09383491], dtype=float32), 0.074509114]
[2019-03-26 23:44:38,554] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.56666666666667, 63.66666666666667, 1.0, 2.0, 0.3230403350281488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 508310.362703042, 508310.362703042, 167600.9344674215]
[2019-03-26 23:44:38,557] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:44:38,559] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.6050470e-23 1.0000000e+00 8.7932197e-22 1.2664588e-16 3.7496840e-28], sampled 0.3144263149064812
[2019-03-26 23:44:42,892] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09383491], dtype=float32), 0.074509114]
[2019-03-26 23:44:42,893] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.92573832, 69.56489009, 1.0, 2.0, 0.6081051869463666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 897327.3538777948, 897327.3538777942, 208291.796789201]
[2019-03-26 23:44:42,895] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:44:42,897] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.1110491e-22 1.0000000e+00 2.0330678e-21 3.2827143e-16 9.5659168e-28], sampled 0.11492239228994272
[2019-03-26 23:44:45,147] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09383491], dtype=float32), 0.074509114]
[2019-03-26 23:44:45,148] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.08333333333334, 80.16666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.147778295568751, 6.9112, 168.911905155119, 1621705.610315626, 1453869.869699578, 311352.5305920899]
[2019-03-26 23:44:45,149] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 23:44:45,153] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.7943442e-22 1.0000000e+00 4.3671493e-21 1.1080863e-15 2.1067156e-27], sampled 0.9226550219840223
[2019-03-26 23:44:50,105] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09383491], dtype=float32), 0.074509114]
[2019-03-26 23:44:50,108] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.78098411833333, 97.66064219333335, 1.0, 2.0, 0.4195345276615037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 604409.9383972819, 604409.9383972825, 174307.0350728247]
[2019-03-26 23:44:50,110] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:44:50,115] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.7929299e-22 1.0000000e+00 1.1260093e-21 1.5704070e-17 5.3811412e-28], sampled 0.5902147611661148
[2019-03-26 23:44:54,534] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7939.8919 3158156411.7781 1590.0000
[2019-03-26 23:44:54,888] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8517.9730 2839763891.6902 1067.0000
[2019-03-26 23:44:54,922] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8263.3360 2926242058.6796 1295.0000
[2019-03-26 23:44:54,983] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8046.3758 3001125007.1707 1605.0000
[2019-03-26 23:44:55,010] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.2713 2779311779.9389 929.0000
[2019-03-26 23:44:56,027] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 2450000, evaluation results [2450000.0, 7939.891865705755, 3158156411.7780733, 1590.0, 8263.33602280147, 2926242058.679626, 1295.0, 8661.27128549362, 2779311779.9389486, 929.0, 8046.375793114538, 3001125007.1706944, 1605.0, 8517.972961277503, 2839763891.6902385, 1067.0]
[2019-03-26 23:45:08,988] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.5025393e-24 1.0000000e+00 9.8836118e-23 3.5096188e-17 6.2740526e-29], sum to 1.0000
[2019-03-26 23:45:08,994] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3502
[2019-03-26 23:45:09,001] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.83333333333333, 71.66666666666667, 1.0, 2.0, 0.6404039290390139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 894947.6451074779, 894947.6451074779, 208515.4691915082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4449000.0000, 
sim time next is 4449600.0000, 
raw observation next is [33.0, 71.0, 1.0, 2.0, 0.6423674400303991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 897692.7597030667, 897692.7597030667, 208905.309976897], 
processed observation next is [0.0, 0.5217391304347826, 0.7630331753554502, 0.71, 1.0, 1.0, 0.5691173976269869, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2493590999175185, 0.2493590999175185, 0.31179897011477165], 
reward next is 0.6882, 
noisyNet noise sample is [array([0.9481485], dtype=float32), -0.5438196]. 
=============================================
[2019-03-26 23:45:26,870] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.0530760e-23 1.0000000e+00 6.4486908e-21 7.7678063e-15 8.6475266e-28], sum to 1.0000
[2019-03-26 23:45:26,876] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3710
[2019-03-26 23:45:26,884] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5113348595370742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 714516.3479738876, 714516.3479738869, 185390.992328483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4748400.0000, 
sim time next is 4749000.0000, 
raw observation next is [27.16666666666666, 82.33333333333333, 1.0, 2.0, 0.5090420893356211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 711311.4612790997, 711311.4612790997, 185024.7927164774], 
processed observation next is [1.0, 1.0, 0.4865718799368086, 0.8233333333333333, 1.0, 1.0, 0.408484444982676, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19758651702197214, 0.19758651702197214, 0.2761564070395185], 
reward next is 0.7238, 
noisyNet noise sample is [array([-0.74647284], dtype=float32), 0.41484234]. 
=============================================
[2019-03-26 23:45:26,911] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[71.062035]
 [71.01568 ]
 [70.99637 ]
 [70.97282 ]
 [70.956764]], R is [[71.11212158]
 [71.1242981 ]
 [71.13607025]
 [71.1473999 ]
 [71.15828705]].
[2019-03-26 23:45:52,319] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 23:45:52,322] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 23:45:52,323] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 23:45:52,323] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:45:52,325] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:45:52,325] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 23:45:52,327] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 23:45:52,324] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 23:45:52,328] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:45:52,329] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:45:52,330] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:45:52,350] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run100
[2019-03-26 23:45:52,379] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run100
[2019-03-26 23:45:52,402] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run100
[2019-03-26 23:45:52,402] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run100
[2019-03-26 23:45:52,402] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run100
[2019-03-26 23:45:56,386] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09208353], dtype=float32), 0.07647993]
[2019-03-26 23:45:56,387] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.35, 58.83333333333333, 1.0, 2.0, 0.272449006663985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 444634.2210617263, 444634.221061727, 163164.972501827]
[2019-03-26 23:45:56,390] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:45:56,393] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.5792779e-23 1.0000000e+00 1.2253662e-22 5.1388203e-19 6.3779132e-29], sampled 0.27701116399507775
[2019-03-26 23:46:14,597] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09208353], dtype=float32), 0.07647993]
[2019-03-26 23:46:14,600] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.78333333333333, 53.16666666666666, 1.0, 2.0, 0.2837473846762157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 460503.7281899367, 460503.7281899373, 164279.7572189154]
[2019-03-26 23:46:14,601] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:46:14,603] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.1443903e-24 1.0000000e+00 4.8218517e-23 1.4842637e-18 2.0117897e-29], sampled 0.44218202263578477
[2019-03-26 23:46:25,376] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09208353], dtype=float32), 0.07647993]
[2019-03-26 23:46:25,377] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.784334225, 74.21464455333333, 1.0, 2.0, 0.5679178212648639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 793612.3717805897, 793612.3717805897, 194915.3734009454]
[2019-03-26 23:46:25,378] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:46:25,381] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.3923498e-23 1.0000000e+00 1.9376436e-22 1.2074214e-17 5.4712823e-29], sampled 0.5439203866042847
[2019-03-26 23:46:39,247] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09208353], dtype=float32), 0.07647993]
[2019-03-26 23:46:39,249] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.0, 84.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.178258254331141, 6.9112, 168.9113953379555, 1643343.24801837, 1453884.682040886, 311346.367822728]
[2019-03-26 23:46:39,252] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:46:39,254] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.3207407e-23 1.0000000e+00 8.5919176e-22 2.3555467e-16 2.2559368e-28], sampled 0.20390521360148584
[2019-03-26 23:46:41,128] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09208353], dtype=float32), 0.07647993]
[2019-03-26 23:46:41,131] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.75, 63.5, 1.0, 2.0, 0.5886536016172972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 822599.9181053381, 822599.9181053381, 198650.9055273824]
[2019-03-26 23:46:41,131] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 23:46:41,133] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.3701212e-23 1.0000000e+00 1.1167518e-22 9.0674869e-18 3.7517281e-29], sampled 0.8043848719979804
[2019-03-26 23:46:55,142] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09208353], dtype=float32), 0.07647993]
[2019-03-26 23:46:55,143] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [33.30536969666667, 77.23836580333332, 1.0, 2.0, 0.9278377663703811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1296874.160608949, 1296874.160608948, 277721.6974559791]
[2019-03-26 23:46:55,146] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:46:55,149] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.4823302e-23 1.0000000e+00 2.1813797e-21 5.7433522e-15 5.2884032e-29], sampled 0.10995286974890572
[2019-03-26 23:47:05,917] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09208353], dtype=float32), 0.07647993]
[2019-03-26 23:47:05,918] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.7, 60.0, 1.0, 2.0, 0.5844599982115509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 816737.4140543292, 816737.4140543292, 197884.6926496763]
[2019-03-26 23:47:05,919] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:47:05,924] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.9725986e-24 1.0000000e+00 9.6960007e-22 3.1624144e-13 1.2811638e-29], sampled 0.7007281935236848
[2019-03-26 23:47:21,323] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09208353], dtype=float32), 0.07647993]
[2019-03-26 23:47:21,323] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.54240059333333, 97.80964503333334, 1.0, 2.0, 0.6129711517309208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 856595.6008624723, 856595.6008624723, 203181.1567779877]
[2019-03-26 23:47:21,326] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:47:21,331] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.29708723e-23 1.00000000e+00 1.96844234e-22 1.04198254e-17
 4.35822780e-29], sampled 0.20296186522487192
[2019-03-26 23:47:40,375] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.09208353], dtype=float32), 0.07647993]
[2019-03-26 23:47:40,376] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.88818996166667, 98.56579448, 1.0, 2.0, 0.3841128952679825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 580119.9387539009, 580119.9387539004, 172931.948594873]
[2019-03-26 23:47:40,378] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 23:47:40,380] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.2792143e-23 1.0000000e+00 1.2128702e-22 1.3942842e-17 4.4858477e-29], sampled 0.6272285120894855
[2019-03-26 23:47:46,647] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7911.1186 3161991281.2509 1702.0000
[2019-03-26 23:47:46,719] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8504.6164 2841558669.9201 1111.0000
[2019-03-26 23:47:46,849] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8656.5920 2779393771.5019 932.0000
[2019-03-26 23:47:47,068] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8007.9394 3005696901.7243 1719.0000
[2019-03-26 23:47:47,123] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8259.6690 2926886576.3133 1328.0000
[2019-03-26 23:47:48,141] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2475000, evaluation results [2475000.0, 7911.118552593387, 3161991281.2509217, 1702.0, 8259.668955807772, 2926886576.3132915, 1328.0, 8656.591990210927, 2779393771.5019264, 932.0, 8007.939445996526, 3005696901.724291, 1719.0, 8504.616399225404, 2841558669.920094, 1111.0]
[2019-03-26 23:47:48,991] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5067260e-22 1.0000000e+00 1.0240744e-21 3.5395628e-16 5.1857431e-28], sum to 1.0000
[2019-03-26 23:47:49,000] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3714
[2019-03-26 23:47:49,005] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333333, 88.83333333333334, 1.0, 2.0, 0.5379146463188768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 751670.888473976, 751670.8884739766, 189749.3929585985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5791800.0000, 
sim time next is 5792400.0000, 
raw observation next is [26.9, 89.0, 1.0, 2.0, 0.5372087543229461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 750684.140932508, 750684.1409325086, 189630.9578230292], 
processed observation next is [1.0, 0.043478260869565216, 0.4739336492890995, 0.89, 1.0, 1.0, 0.44242018593126037, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20852337248125224, 0.20852337248125238, 0.2830312803328794], 
reward next is 0.7170, 
noisyNet noise sample is [array([0.4732092], dtype=float32), -0.91931045]. 
=============================================
[2019-03-26 23:47:52,104] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.0657898e-12 1.8827821e-01 3.8993489e-10 8.1172180e-01 3.9225079e-15], sum to 1.0000
[2019-03-26 23:47:52,112] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9810
[2019-03-26 23:47:52,121] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 68.66666666666667, 1.0, 2.0, 0.85911730789127, 1.0, 2.0, 0.85911730789127, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2402836.063908087, 2402836.063908087, 449677.5763100079], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5222400.0000, 
sim time next is 5223000.0000, 
raw observation next is [31.0, 69.33333333333333, 1.0, 2.0, 0.8619218580285221, 1.0, 2.0, 0.8619218580285221, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2410687.581168726, 2410687.581168726, 451143.3499563925], 
processed observation next is [1.0, 0.43478260869565216, 0.6682464454976303, 0.6933333333333332, 1.0, 1.0, 0.8336407928054482, 1.0, 1.0, 0.8336407928054482, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6696354392135351, 0.6696354392135351, 0.6733482835170037], 
reward next is 0.3267, 
noisyNet noise sample is [array([-0.2898683], dtype=float32), 0.39024726]. 
=============================================
[2019-03-26 23:47:52,143] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[40.368916]
 [38.474125]
 [36.847965]
 [39.423767]
 [38.697815]], R is [[42.08470535]
 [41.99269867]
 [41.57277298]
 [41.45464706]
 [41.37305832]].
[2019-03-26 23:47:55,796] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2473821e-17 9.9990237e-01 4.9192141e-15 9.7647877e-05 5.0130816e-22], sum to 1.0000
[2019-03-26 23:47:55,806] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5939
[2019-03-26 23:47:55,814] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1752851.342558997 W.
[2019-03-26 23:47:55,820] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.6, 86.0, 1.0, 2.0, 0.4179345536196775, 1.0, 1.0, 0.4179345536196775, 1.0, 1.0, 0.7015715782617974, 6.9112, 6.9112, 170.5573041426782, 1752851.342558997, 1752851.342558997, 359368.6861335348], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6012000.0000, 
sim time next is 6012600.0000, 
raw observation next is [26.16666666666667, 84.83333333333334, 1.0, 2.0, 0.6130162522374224, 1.0, 2.0, 0.6130162522374224, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1713995.466560028, 1713995.466560028, 339098.8913727985], 
processed observation next is [1.0, 0.6086956521739131, 0.4391785150078992, 0.8483333333333334, 1.0, 1.0, 0.5337545207679788, 1.0, 1.0, 0.5337545207679788, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.47610985182223003, 0.47610985182223003, 0.5061177483176097], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5237212], dtype=float32), 1.618543]. 
=============================================
[2019-03-26 23:47:57,033] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0590407e-23 1.0000000e+00 1.8179924e-22 2.3251282e-18 5.2121376e-29], sum to 1.0000
[2019-03-26 23:47:57,038] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0644
[2019-03-26 23:47:57,042] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 74.5, 1.0, 2.0, 0.5343508299725349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 746689.1342887529, 746689.1342887529, 189153.5522643041], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5647800.0000, 
sim time next is 5648400.0000, 
raw observation next is [29.5, 74.0, 1.0, 2.0, 0.5374214912078328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 750981.5200375767, 750981.520037576, 189667.3210718998], 
processed observation next is [0.0, 0.391304347826087, 0.5971563981042655, 0.74, 1.0, 1.0, 0.4426764954311238, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20860597778821574, 0.20860597778821555, 0.2830855538386564], 
reward next is 0.7169, 
noisyNet noise sample is [array([0.26790142], dtype=float32), 1.21151]. 
=============================================
[2019-03-26 23:47:59,182] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.7857388e-13 1.7595695e-01 4.8953234e-11 8.2404304e-01 1.5985349e-16], sum to 1.0000
[2019-03-26 23:47:59,191] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8507
[2019-03-26 23:47:59,197] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.5, 62.0, 1.0, 2.0, 0.8376306081905549, 1.0, 2.0, 0.8376306081905549, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2342684.312268197, 2342684.312268198, 438608.4378806097], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5569200.0000, 
sim time next is 5569800.0000, 
raw observation next is [32.6, 61.16666666666667, 1.0, 2.0, 0.9331727519773599, 1.0, 2.0, 0.9331727519773599, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2610175.560068244, 2610175.560068244, 489911.1589143045], 
processed observation next is [1.0, 0.4782608695652174, 0.7440758293838864, 0.6116666666666667, 1.0, 1.0, 0.9194852433462168, 1.0, 1.0, 0.9194852433462168, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7250487666856233, 0.7250487666856233, 0.7312106849467231], 
reward next is 0.2688, 
noisyNet noise sample is [array([-1.0604792], dtype=float32), 2.1578498]. 
=============================================
[2019-03-26 23:48:03,341] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.0431622e-16 3.2510884e-02 1.4090148e-12 9.6748918e-01 3.8249540e-19], sum to 1.0000
[2019-03-26 23:48:03,347] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0256
[2019-03-26 23:48:03,355] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2823584.609258214 W.
[2019-03-26 23:48:03,359] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.2, 63.66666666666667, 1.0, 2.0, 1.009383224837457, 1.0, 2.0, 1.009383224837457, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2823584.609258214, 2823584.609258214, 534678.3627698718], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5847600.0000, 
sim time next is 5848200.0000, 
raw observation next is [32.15, 64.0, 1.0, 2.0, 0.9946231853699279, 1.0, 2.0, 0.9946231853699279, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2782249.831824433, 2782249.831824434, 525741.989664697], 
processed observation next is [1.0, 0.6956521739130435, 0.7227488151658767, 0.64, 1.0, 1.0, 0.9935219100842505, 1.0, 1.0, 0.9935219100842505, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7728471755067869, 0.7728471755067872, 0.7846895368129806], 
reward next is 0.2153, 
noisyNet noise sample is [array([2.1328745], dtype=float32), -1.2477666]. 
=============================================
[2019-03-26 23:48:07,404] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.2235785e-23 1.0000000e+00 2.5796940e-21 3.3294510e-13 2.2282077e-29], sum to 1.0000
[2019-03-26 23:48:07,413] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3670
[2019-03-26 23:48:07,419] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.75, 83.5, 1.0, 2.0, 0.5296092229843834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740061.0173844877, 740061.0173844884, 188365.6451705839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6204600.0000, 
sim time next is 6205200.0000, 
raw observation next is [27.66666666666666, 84.0, 1.0, 2.0, 0.5296840628485503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740165.6329392651, 740165.6329392645, 188378.0031029248], 
processed observation next is [1.0, 0.8260869565217391, 0.5102685624012636, 0.84, 1.0, 1.0, 0.4333542925886148, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20560156470535143, 0.20560156470535126, 0.2811611986610818], 
reward next is 0.7188, 
noisyNet noise sample is [array([0.02398026], dtype=float32), 0.012606382]. 
=============================================
[2019-03-26 23:48:16,845] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3203069e-24 1.0000000e+00 1.6760209e-22 4.8254706e-18 4.6657892e-29], sum to 1.0000
[2019-03-26 23:48:16,858] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4490
[2019-03-26 23:48:16,862] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666667, 69.5, 1.0, 2.0, 0.5489081798708574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 767038.5732999502, 767038.5732999496, 191614.1336950899], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5652600.0000, 
sim time next is 5653200.0000, 
raw observation next is [30.83333333333334, 69.0, 1.0, 2.0, 0.5511122417426166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 770119.6229159021, 770119.6229159026, 191992.1628533276], 
processed observation next is [0.0, 0.43478260869565216, 0.6603475513428123, 0.69, 1.0, 1.0, 0.459171375593514, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21392211747663947, 0.2139221174766396, 0.28655546694526507], 
reward next is 0.7134, 
noisyNet noise sample is [array([-0.7239933], dtype=float32), 0.36125997]. 
=============================================
[2019-03-26 23:48:20,734] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.7658246e-16 3.0702982e-02 2.1218806e-12 9.6929705e-01 3.8647799e-19], sum to 1.0000
[2019-03-26 23:48:20,744] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3502
[2019-03-26 23:48:20,749] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.95, 76.33333333333334, 1.0, 2.0, 0.8400637331451299, 1.0, 2.0, 0.8400637331451299, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2349495.670294348, 2349495.670294348, 439849.2174584514], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5929800.0000, 
sim time next is 5930400.0000, 
raw observation next is [30.0, 76.66666666666667, 1.0, 2.0, 0.8562025203316224, 1.0, 2.0, 0.8562025203316224, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2394675.982220328, 2394675.982220328, 448162.7273236198], 
processed observation next is [1.0, 0.6521739130434783, 0.6208530805687204, 0.7666666666666667, 1.0, 1.0, 0.8267500244959306, 1.0, 1.0, 0.8267500244959306, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.66518777283898, 0.66518777283898, 0.6688995930203281], 
reward next is 0.3311, 
noisyNet noise sample is [array([-0.5967846], dtype=float32), -1.0153999]. 
=============================================
[2019-03-26 23:48:21,356] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.8702172e-24 1.0000000e+00 1.0694889e-22 2.9575253e-18 8.9198121e-29], sum to 1.0000
[2019-03-26 23:48:21,367] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8646
[2019-03-26 23:48:21,373] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.36666666666667, 88.0, 1.0, 2.0, 0.5112322650033273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 714372.9387784209, 714372.9387784209, 185374.4662645817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5722800.0000, 
sim time next is 5723400.0000, 
raw observation next is [26.53333333333333, 87.0, 1.0, 2.0, 0.5118142065993034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 715186.3914972004, 715186.3914972009, 185467.6518458023], 
processed observation next is [0.0, 0.21739130434782608, 0.45655608214849913, 0.87, 1.0, 1.0, 0.41182434530036555, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1986628865270001, 0.19866288652700026, 0.2768173908146303], 
reward next is 0.7232, 
noisyNet noise sample is [array([-0.28209493], dtype=float32), 0.5508804]. 
=============================================
[2019-03-26 23:48:25,926] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.6273866e-24 1.0000000e+00 2.4736356e-23 1.3571571e-17 6.8689382e-30], sum to 1.0000
[2019-03-26 23:48:25,940] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1635
[2019-03-26 23:48:25,944] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.13333333333333, 87.66666666666667, 1.0, 2.0, 0.5386799251324969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 752740.6522951062, 752740.6522951062, 189878.0200447449], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5787600.0000, 
sim time next is 5788200.0000, 
raw observation next is [27.11666666666667, 87.83333333333334, 1.0, 2.0, 0.5385871617696738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 752610.9806883385, 752610.9806883378, 189862.4496862481], 
processed observation next is [0.0, 1.0, 0.4842022116903636, 0.8783333333333334, 1.0, 1.0, 0.4440809177947877, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2090586057467607, 0.2090586057467605, 0.2833767905764897], 
reward next is 0.7166, 
noisyNet noise sample is [array([0.7858265], dtype=float32), -0.08407376]. 
=============================================
[2019-03-26 23:48:27,294] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.5019045e-14 9.8062448e-02 4.9820301e-11 9.0193754e-01 5.3079617e-17], sum to 1.0000
[2019-03-26 23:48:27,305] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4515
[2019-03-26 23:48:27,310] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 66.33333333333334, 1.0, 2.0, 0.5781379905412053, 1.0, 2.0, 0.5781379905412053, 1.0, 1.0, 1.004034496414999, 6.911199999999999, 6.9112, 170.5573041426782, 2425483.768087609, 2425483.768087609, 473384.726946562], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5829600.0000, 
sim time next is 5830200.0000, 
raw observation next is [32.05, 66.0, 1.0, 2.0, 0.8673385589638904, 1.0, 2.0, 0.8673385589638904, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2425852.121104646, 2425852.121104647, 453988.6270714144], 
processed observation next is [1.0, 0.4782608695652174, 0.7180094786729857, 0.66, 1.0, 1.0, 0.8401669385107113, 1.0, 1.0, 0.8401669385107113, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6738478114179572, 0.6738478114179575, 0.6775949657782304], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0271106], dtype=float32), 0.82560164]. 
=============================================
[2019-03-26 23:48:32,500] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.2428108e-15 3.1815056e-02 2.1908336e-11 9.6818495e-01 3.3227920e-18], sum to 1.0000
[2019-03-26 23:48:32,508] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7219
[2019-03-26 23:48:32,513] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.96666666666667, 70.33333333333334, 1.0, 2.0, 0.9259589299150199, 1.0, 2.0, 0.9259589299150199, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2589976.879661315, 2589976.879661315, 485858.0303450777], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5915400.0000, 
sim time next is 5916000.0000, 
raw observation next is [31.83333333333334, 70.66666666666667, 1.0, 2.0, 0.947695292971011, 1.0, 2.0, 0.947695292971011, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2650839.622267289, 2650839.622267288, 498185.8136339817], 
processed observation next is [1.0, 0.4782608695652174, 0.7077409162717223, 0.7066666666666667, 1.0, 1.0, 0.936982280687965, 1.0, 1.0, 0.936982280687965, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7363443395186914, 0.7363443395186912, 0.7435609158716144], 
reward next is 0.2564, 
noisyNet noise sample is [array([0.73845655], dtype=float32), -1.3047652]. 
=============================================
[2019-03-26 23:48:32,529] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[48.85571 ]
 [47.244164]
 [45.225307]
 [43.128345]
 [40.960644]], R is [[49.96518326]
 [49.74036789]
 [49.53398132]
 [49.36578369]
 [49.20775223]].
[2019-03-26 23:48:38,312] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2159747e-21 1.0000000e+00 2.4672311e-20 1.0579894e-14 8.8685892e-27], sum to 1.0000
[2019-03-26 23:48:38,328] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5433
[2019-03-26 23:48:38,334] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.95, 86.5, 1.0, 2.0, 0.7215532050365911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1008405.463406446, 1008405.463406446, 225567.9730546769], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5987400.0000, 
sim time next is 5988000.0000, 
raw observation next is [28.1, 86.0, 1.0, 2.0, 0.7260829362993917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1014739.006210879, 1014739.00621088, 226577.8577497597], 
processed observation next is [1.0, 0.30434782608695654, 0.5308056872037916, 0.86, 1.0, 1.0, 0.6699794413245683, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2818719461696886, 0.2818719461696889, 0.3381759070891936], 
reward next is 0.6618, 
noisyNet noise sample is [array([1.5093793], dtype=float32), 1.3495417]. 
=============================================
[2019-03-26 23:48:38,344] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[67.59955 ]
 [67.48108 ]
 [67.3859  ]
 [67.57915 ]
 [67.792595]], R is [[67.63059235]
 [67.61761475]
 [67.59835052]
 [67.56824493]
 [67.54540253]].
[2019-03-26 23:48:41,555] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1937446e-23 1.0000000e+00 5.9548282e-23 1.7625606e-17 2.6009476e-29], sum to 1.0000
[2019-03-26 23:48:41,563] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4866
[2019-03-26 23:48:41,570] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.1, 83.0, 1.0, 2.0, 0.5125969023207223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 716280.4644052545, 716280.4644052538, 185593.0189704876], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6393600.0000, 
sim time next is 6394200.0000, 
raw observation next is [27.1, 83.0, 1.0, 2.0, 0.5126055159279782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 716292.5047409645, 716292.5047409652, 185594.4002182946], 
processed observation next is [1.0, 0.0, 0.4834123222748816, 0.83, 1.0, 1.0, 0.41277773003370866, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1989701402058235, 0.19897014020582368, 0.277006567489992], 
reward next is 0.7230, 
noisyNet noise sample is [array([0.37152907], dtype=float32), 0.059949167]. 
=============================================
[2019-03-26 23:48:41,713] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.5476196e-21 1.0000000e+00 1.2154704e-19 2.1828181e-15 4.5001658e-26], sum to 1.0000
[2019-03-26 23:48:41,723] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6281
[2019-03-26 23:48:41,728] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.13333333333333, 62.66666666666667, 1.0, 2.0, 0.892804598005513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1391396.86081757, 1391396.86081757, 287437.4119942768], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6774000.0000, 
sim time next is 6774600.0000, 
raw observation next is [26.36666666666667, 61.33333333333333, 1.0, 2.0, 0.891837052721122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1390055.033050526, 1390055.033050526, 287160.9570079824], 
processed observation next is [1.0, 0.391304347826087, 0.4486571879936811, 0.6133333333333333, 1.0, 1.0, 0.8696831960495446, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.38612639806959054, 0.38612639806959054, 0.4285984432954961], 
reward next is 0.5714, 
noisyNet noise sample is [array([-0.8020565], dtype=float32), 0.9012802]. 
=============================================
[2019-03-26 23:48:42,227] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9074177e-21 1.0000000e+00 3.8789830e-20 6.4523555e-14 1.8913396e-26], sum to 1.0000
[2019-03-26 23:48:42,235] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6921
[2019-03-26 23:48:42,241] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.56666666666667, 50.5, 1.0, 2.0, 0.9403810267632208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1463864.095074482, 1463864.095074482, 302138.8370573138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6783000.0000, 
sim time next is 6783600.0000, 
raw observation next is [28.63333333333334, 50.00000000000001, 1.0, 2.0, 0.8191776710525683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1276319.984959819, 1276319.984959818, 265824.3529516124], 
processed observation next is [1.0, 0.5217391304347826, 0.5560821484992104, 0.5000000000000001, 1.0, 1.0, 0.7821417723524919, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.35453332915550523, 0.354533329155505, 0.39675276559942146], 
reward next is 0.6032, 
noisyNet noise sample is [array([0.4838089], dtype=float32), 0.17619139]. 
=============================================
[2019-03-26 23:48:42,691] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.7519528e-21 1.0000000e+00 9.9846561e-20 2.6178961e-13 5.0427160e-26], sum to 1.0000
[2019-03-26 23:48:42,705] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3849
[2019-03-26 23:48:42,711] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.35, 46.0, 1.0, 2.0, 0.9997152701477372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1565343.841780062, 1565343.841780062, 322826.0142518128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6791400.0000, 
sim time next is 6792000.0000, 
raw observation next is [29.33333333333333, 46.33333333333334, 1.0, 2.0, 0.9857671889398422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1541469.847570342, 1541469.847570342, 317853.5814304147], 
processed observation next is [1.0, 0.6086956521739131, 0.5892575039494469, 0.46333333333333343, 1.0, 1.0, 0.9828520348672797, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.42818606876953946, 0.42818606876953946, 0.4744083304931563], 
reward next is 0.5256, 
noisyNet noise sample is [array([0.88368046], dtype=float32), -0.7709274]. 
=============================================
[2019-03-26 23:48:42,734] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[66.19282]
 [66.22369]
 [66.27339]
 [66.28154]
 [66.3362 ]], R is [[66.02086639]
 [65.87882996]
 [65.74659729]
 [65.62828827]
 [65.51557159]].
[2019-03-26 23:48:44,378] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 23:48:44,383] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 23:48:44,383] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 23:48:44,384] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:48:44,385] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 23:48:44,385] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:48:44,387] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:48:44,389] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 23:48:44,386] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 23:48:44,392] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:48:44,392] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 23:48:45,569] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run101
[2019-03-26 23:48:45,756] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run101
[2019-03-26 23:48:46,132] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run101
[2019-03-26 23:48:46,344] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run101
[2019-03-26 23:48:46,346] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/6/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run101
[2019-03-26 23:48:50,956] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09252661], dtype=float32), 0.076429285]
[2019-03-26 23:48:50,957] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.33333333333334, 80.33333333333334, 1.0, 2.0, 0.2961812381097969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 472566.5188263085, 472566.5188263085, 165107.7572076377]
[2019-03-26 23:48:50,957] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:48:50,960] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.7880682e-24 1.0000000e+00 4.0010407e-23 1.1205050e-18 1.2281134e-29], sampled 0.20778699131618106
[2019-03-26 23:49:05,083] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09252661], dtype=float32), 0.076429285]
[2019-03-26 23:49:05,085] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.79298439666667, 74.91273316333333, 1.0, 2.0, 0.6554565989469894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 915992.4266432336, 915992.426643233, 211526.1471167415]
[2019-03-26 23:49:05,087] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:49:05,089] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.8443797e-23 1.0000000e+00 2.7477346e-22 4.5408834e-17 8.1713657e-29], sampled 0.10484025341211045
[2019-03-26 23:49:12,463] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09252661], dtype=float32), 0.076429285]
[2019-03-26 23:49:12,465] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.56666666666667, 89.66666666666667, 1.0, 2.0, 0.319945060754221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 505384.0424212043, 505384.0424212049, 167419.6411399539]
[2019-03-26 23:49:12,466] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 23:49:12,470] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0715874e-23 1.0000000e+00 1.3950787e-22 1.6798850e-17 3.5317168e-29], sampled 0.40778787716105414
[2019-03-26 23:49:39,555] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09252661], dtype=float32), 0.076429285]
[2019-03-26 23:49:39,557] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.55163584, 68.002597355, 1.0, 2.0, 0.5759917875262675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 804899.2641431774, 804899.2641431767, 196358.3483046939]
[2019-03-26 23:49:39,558] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:49:39,560] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.9186870e-24 1.0000000e+00 5.1327193e-22 1.3545215e-14 1.0308981e-29], sampled 0.4750961061025506
[2019-03-26 23:49:54,168] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09252661], dtype=float32), 0.076429285]
[2019-03-26 23:49:54,170] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.35, 65.16666666666666, 1.0, 2.0, 0.5310510138326152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742076.4390692267, 742076.4390692267, 188603.0771804479]
[2019-03-26 23:49:54,170] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 23:49:54,172] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.0200418e-23 1.0000000e+00 5.7001150e-22 1.0112354e-16 2.5338649e-28], sampled 0.23722508516877416
[2019-03-26 23:50:11,454] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09252661], dtype=float32), 0.076429285]
[2019-03-26 23:50:11,455] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.95, 88.16666666666667, 1.0, 2.0, 0.9248439532995888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1292687.046577757, 1292687.046577758, 276865.3091758964]
[2019-03-26 23:50:11,456] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 23:50:11,459] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.3809581e-21 1.0000000e+00 2.2458739e-20 3.2255364e-14 6.3497109e-27], sampled 0.6852789421567083
[2019-03-26 23:50:16,211] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09252661], dtype=float32), 0.076429285]
[2019-03-26 23:50:16,213] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.73382579666666, 81.02104880666667, 1.0, 2.0, 0.6038099695821332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 843788.235521721, 843788.235521721, 201457.0529207877]
[2019-03-26 23:50:16,214] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 23:50:16,215] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0019051e-23 1.0000000e+00 1.6275069e-22 1.5894105e-16 3.4850097e-29], sampled 0.8031454162316584
[2019-03-26 23:50:30,722] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09252661], dtype=float32), 0.076429285]
[2019-03-26 23:50:30,722] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.45, 73.33333333333334, 1.0, 2.0, 0.6020533606468816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 841332.5076057634, 841332.5076057634, 201126.8852149801]
[2019-03-26 23:50:30,723] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 23:50:30,726] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.6224788e-23 1.0000000e+00 4.1329496e-22 4.4902259e-16 5.5785548e-29], sampled 0.13430745797410282
[2019-03-26 23:50:37,930] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8503.0082 2841165429.3063 1098.0000
[2019-03-26 23:50:39,453] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7911.6694 3161448906.4915 1687.0000
[2019-03-26 23:50:40,044] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.2542 2779283142.1739 932.0000
[2019-03-26 23:50:40,076] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8259.5536 2926761837.1958 1318.0000
[2019-03-26 23:50:40,301] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8009.9546 3005005239.1693 1705.0000
[2019-03-26 23:50:41,334] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2500000, evaluation results [2500000.0, 7911.669433070246, 3161448906.4914556, 1687.0, 8259.553567636936, 2926761837.1958227, 1318.0, 8658.25421623151, 2779283142.173928, 932.0, 8009.954601424949, 3005005239.1692758, 1705.0, 8503.008161247082, 2841165429.306346, 1098.0]
